<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">95764</article-id><article-id pub-id-type="doi">10.7554/eLife.95764</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.95764.4</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Shortcutting from self-motion signals reveals a cognitive map in mice</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Xu</surname><given-names>Jiayun</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9505-9253</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Girardi-Schappo</surname><given-names>Mauricio</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9111-4905</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="pa1">‡</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Beique</surname><given-names>Jean-Claude</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7278-4906</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Longtin</surname><given-names>André</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0678-9893</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Maler</surname><given-names>Leonard</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7666-2754</contrib-id><email>lmaler@uottawa.ca</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03c4mmv16</institution-id><institution>Department of Cellular and Molecular Medicine, University of Ottawa</institution></institution-wrap><addr-line><named-content content-type="city">Ottawa</named-content></addr-line><country>Canada</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03c4mmv16</institution-id><institution>Department of Physics, University of Ottawa</institution></institution-wrap><addr-line><named-content content-type="city">Ottawa</named-content></addr-line><country>Canada</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03c4mmv16</institution-id><institution>Brain and Mind Institute, University of Ottawa</institution></institution-wrap><addr-line><named-content content-type="city">Ottawa</named-content></addr-line><country>Canada</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03c4mmv16</institution-id><institution>Center for Neural Dynamics and Artificial Intelligence, University of Ottawa</institution></institution-wrap><addr-line><named-content content-type="city">Ottawa</named-content></addr-line><country>Canada</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Cowan</surname><given-names>Noah J</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00za53h95</institution-id><institution>Johns Hopkins University</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Wassum</surname><given-names>Kate M</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/046rm7j60</institution-id><institution>University of California, Los Angeles</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn><fn fn-type="present-address" id="pa1"><label>‡</label><p>Departamento de Física, Universidade Federal de Santa Catarina, Santa Catarina, Brazil</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>11</day><month>11</month><year>2024</year></pub-date><volume>13</volume><elocation-id>RP95764</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-01-12"><day>12</day><month>01</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-12-28"><day>28</day><month>12</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.02.24.529984"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-05-09"><day>09</day><month>05</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.95764.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-09-20"><day>20</day><month>09</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.95764.2"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-10-17"><day>17</day><month>10</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.95764.3"/></event></pub-history><permissions><copyright-statement>© 2024, Xu, Girardi-Schappo et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Xu, Girardi-Schappo et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-95764-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-95764-figures-v1.pdf"/><related-article related-article-type="commentary" ext-link-type="doi" xlink:href="10.7554/eLife.104500" id="ra1"/><abstract><p>Animals navigate by learning the spatial layout of their environment. We investigated spatial learning of mice in an open maze where food was hidden in one of a hundred holes. Mice leaving from a stable entrance learned to efficiently navigate to the food without the need for landmarks. We developed a quantitative framework to reveal how the mice estimate the food location based on analyses of trajectories and active hole checks. After learning, the computed ‘target estimation vector’ (TEV) closely approximated the mice’s route and its hole check distribution. The TEV required learning both the direction and distance of the start to food vector, and our data suggests that different learning dynamics underlie these estimates. We propose that the TEV can be precisely connected to the properties of hippocampal place cells. Finally, we provide the first demonstration that, after learning the location of two food sites, the mice took a shortcut between the sites, demonstrating that they had generated a cognitive map.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>spatial learning</kwd><kwd>cognitive map</kwd><kwd>shortcut</kwd><kwd>open maze</kwd><kwd>active sensing</kwd><kwd>trajectory analysis</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000024</institution-id><institution>Canadian Institutes of Health Research</institution></institution-wrap></funding-source><award-id>RGPIN/04336-2017</award-id><principal-award-recipient><name><surname>Maler</surname><given-names>Leonard</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000024</institution-id><institution>Canadian Institutes of Health Research</institution></institution-wrap></funding-source><award-id>153143</award-id><principal-award-recipient><name><surname>Longtin</surname><given-names>André</given-names></name><name><surname>Maler</surname><given-names>Leonard</given-names></name><name><surname>Beique</surname><given-names>Jean-Claude</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution>Brockhouse</institution></institution-wrap></funding-source><award-id>493076–2017</award-id><principal-award-recipient><name><surname>Longtin</surname><given-names>André</given-names></name><name><surname>Maler</surname><given-names>Leonard</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000038</institution-id><institution>Natural Sciences and Engineering Research Council of Canada</institution></institution-wrap></funding-source><award-id>RGPIN/06204–2014</award-id><principal-award-recipient><name><surname>Longtin</surname><given-names>André</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000038</institution-id><institution>Natural Sciences and Engineering Research Council of Canada</institution></institution-wrap></funding-source><award-id>RGPIN/2017-147489-2017</award-id><principal-award-recipient><name><surname>Maler</surname><given-names>Leonard</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004089</institution-id><institution>Krembil Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Longtin</surname><given-names>André</given-names></name><name><surname>Maler</surname><given-names>Leonard</given-names></name><name><surname>Beique</surname><given-names>Jean-Claude</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Mice can use self-motion cues to learn a cognitive map thereby permitting them to take shortcut trajectories in an open maze without requiring prior experience of such routes.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Animals must learn the spatial layout of their environment to successfully forage and then return home. Local (<xref ref-type="bibr" rid="bib65">Rosenberg et al., 2021</xref>) or distal (<xref ref-type="bibr" rid="bib13">Chan et al., 2012</xref>) landmark(s) are typically important spatial cues. Landmarks can act as simple beacons, as stimuli for response learning or for more flexible ‘place’ learning strategies (<xref ref-type="bibr" rid="bib13">Chan et al., 2012</xref>; <xref ref-type="bibr" rid="bib27">Goodman, 2020</xref>; <xref ref-type="bibr" rid="bib58">Nyberg et al., 2022</xref>; <xref ref-type="bibr" rid="bib75">Tolman et al., 1946a</xref>). Experimental studies addressing this issue have used one (<xref ref-type="bibr" rid="bib16">Collett et al., 1986</xref>) or many (<xref ref-type="bibr" rid="bib56">Morris, 1981</xref>) distal landmarks that provide allocentric coordinates for learning trajectories from a start site to a hidden location. A second source of spatial information derives from idiothetic cues that provide a reference frame via path integration of self-motion signals (<xref ref-type="bibr" rid="bib48">McNaughton et al., 1996</xref>; <xref ref-type="bibr" rid="bib52">Mittelstaedt and Mittelstaedt, 1980</xref>). Research on the interaction of landmark and self-motion cues has concluded that a ‘spatial map’ can be generated by self-motion cues anchored to stable landmarks (<xref ref-type="bibr" rid="bib48">McNaughton et al., 1996</xref>; <xref ref-type="bibr" rid="bib11">Burgess, 2006</xref>; <xref ref-type="bibr" rid="bib15">Chen et al., 2013</xref>; <xref ref-type="bibr" rid="bib41">Knierim and Hamilton, 2011</xref>). This spatial map can link start sites to important locations via efficient trajectories. However, it is not clear whether such a map is sufficient for flexible navigation using entirely novel routes.</p><p>We designed a circular open maze where navigation trajectories are unconstrained, the mice’s allocentric reference frame is determined by large visual cues and food is hidden in one of 100 holes. We found that mice did not use the landmarks but required only minimal cues, namely a stable start location, self-motion signals and active sensing (hole checks), to learn to find food. Trajectories and hole checking strategies dramatically changed as the mice learned to efficiently navigate to the hidden food. Averaged trajectory directions converged to a ‘mean displacement direction’, and hole checking became concentrated near the expected food hole. These analyses resulted in a computed target estimation vector (TEV) that closely approximated the most direct route between the start location and food. When, after learning, the mice were transferred to another start site, their TEVs also rotated and then pointed to the ‘rotationally equivalent location’ (REL) instead of the target, therefore demonstrating that they were utilizing self-motion cues for navigation. We propose ways to link the mean displacement and hole checking components of the TEV to the properties of hippocampal place cells and suggest a neural equivalent of the TEV that might be computed by downstream hippocampal targets.</p><p>The cognitive map hypothesis proposes that animals can learn a metric map of their environment and use it to flexibly guide their navigation, that is, they can take shortcuts, detours and novel routes when needed (<xref ref-type="bibr" rid="bib56">Morris, 1981</xref>; <xref ref-type="bibr" rid="bib77">Tolman, 1948</xref>; <xref ref-type="bibr" rid="bib76">Tolman et al., 1946b</xref>). It is further proposed that the hippocampus and closely connected cortical areas generate a cognitive map (<xref ref-type="bibr" rid="bib49">McNaughton et al., 2006</xref>; <xref ref-type="bibr" rid="bib59">O’Keefe and Nadel, 1978</xref>). We found that, after training to find food in two distinct sites, mice were able to take an unrehearsed shortcut between the sites on a final probe (i.e<italic>.</italic> no food) trial. The trajectories and hole check analyses demonstrated that the computed TEVs were accurate and efficient. To the best of our knowledge, this is the first demonstration that a stable start location and self-motion cues are sufficient for a rodent to compute a cognitive map. It is not clear whether current theories based on electrophysiological studies of the hippocampus and associated cortices can account for the cognitive map we have observed (<xref ref-type="bibr" rid="bib49">McNaughton et al., 2006</xref>; <xref ref-type="bibr" rid="bib4">Banino et al., 2018</xref>).</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We designed a behavioral framework, the Hidden Food Maze (HFM), to tease apart the roles of idiothetic and allothetic cues for navigation in a foraging task (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Mice are trained to find a food reward hidden inside one hole (the target) out of 100 in a large, circular open maze (120 cm in diameter). The target hole has a ‘rotationally equivalent location’ (REL) in each of the arena’s quadrants (<xref ref-type="fig" rid="fig1">Figure 1B</xref>; see ‘REL’ in Materials and methods for a description). In the mouse’s perspective, the displacement from the entrance location to the target is the same as from the entrance in any quadrant to their respective REL. The HFM has several unique features such as 90<sup>o</sup> rotational symmetry to eliminate geometric cues and control for distal cues, movable home cage entranceways, and experimenter-controlled visual cues (see Materials and methods). More importantly, our framework gives the mice freedom to explore the arena with minimum stress, yielding variable trajectories due to the nonstereotyped environment. These features allow us to control whether mice orient to allothetic or idiothetic cues, enabling us to investigate the respective role of landmarks versus path integration in spatial navigation.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Hidden Food Maze and experimental setup.</title><p>(<bold>A</bold>) The floor of the arena is 120 cm in diameter, and the walls are 45 cm tall. Note 20 cm scale bar in this panel. The home cage has a 10.5x6.5 cm<sup>2</sup> floor area. The door slides upward (mice enter without handling). The floor is washed and rotated between every trial to avoid predictable scratch marks and odor trails. The subfloor containing food is not illustrated. (<bold>B</bold>) Camera view of a mouse searching for hidden food (target, pointed by the target vector). The REL of the target is marked for each entrance (from the mouse’s perspective, the displacement from the start in each quadrant to its respective REL is the same for any entrance; e.g<italic>.</italic> ‘70cm forward +30 cm to the left’; and it is equal to the displacement from the trained start to target). (<bold>C</bold>) ‘Random entrances’ experiment. Mice enter from any of the four entrances randomly over trials to search for food (‘A’-labeled star) always in front of the X landmark. Arrows show the four possible displacements. (<bold>D</bold>) ‘Static entrances’ experiment. Mice start from the same entrance (labeled ‘Start’) in every trial to search for food in front of the same landmark. Blue/cyan arrows = food vector (start→food); Orange arrow = REL vector (start→REL). After training, the start position in a probe trial can be rotated (‘180<sup>o</sup> Start’) to check whether mice follow idiothetic (start→REL; ignoring landmarks) or allothetic (start→A; following landmarks) cues; going via the REL vector is regarded as evidence of path integration. (<bold>E</bold>) ‘Two food location’ experiment. Mice start from a static entrance to search for food (red vector to target A). Afterwards, mice are trained to find food in a different location (blue vector to target B). After learning both targets, a probe trial (i.e. a trial without food) is designed to check whether mice can compute shortcuts from B to A (B-A vector, orange arrow).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95764-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Pre-training trajectories and active sensing from the mouse perspective in random entrance experiment.</title><p>(<bold>A</bold>) Example trajectories of a mouse during pretraining (see Materials and methods). The mice are habituated to their home cage (Day 1) and the maze (Day 2, no food). On Day 3, mice start exploring an arena with randomly selected 50% of the holes filled with food (panel <bold>A1</bold>). On Day 4 25% of the holes are filled with food (panel <bold>A2</bold>). Most trajectories are confined near the maze walls on Days 3 and 4. During the final pre-training Day 5, only the four central wells (panel <bold>A3</bold>, red circles) have food and the mice now explored the entire maze. Circles indicate hole checks (with or without food) with color and size indicating the time course of checking – small, blue circles occur early along the trajectory and pink large circles later in the trajectory. Food locations are only illustrated for Day 5 where they are confined to four central holes. The mice can re-enter their home cage at any time during the food search resulting in multiple blue and magenta lines converging at the Start location. (<bold>B-F</bold>). Active sensing from the mouse perspective in random entrance experiment. B. The mouse can enter the arena from each of the four quadrants of the circle. Due to the circular symmetry, we can rotate each entrance setup so that it always aligns to the top of the screen, as shown. This is the mouse perspective of the experiment, where now the mouse has to find one of four possible target locations. (<bold>C–F</bold>) show the hole checks of trial 14 of the Random Entrance experiment as an example (target = red ‘A’ label). The previous spots of the target are shown with a green ‘A<sub>trial 13</sub>’ label and depend on the specific entrance a particular mouse took in trial 13. Quadrants are defined in main <xref ref-type="fig" rid="fig1">Figure 1</xref>. Starting from Quadrant 1 is linked to the configuration in panel <bold>C</bold>; quadrant 2 in panel <bold>D</bold>; quadrant 3 in panel <bold>E</bold>; and quadrant 4 in panel <bold>F</bold>. Moreover, notice that the configuration of targets for panel <bold>D</bold> is rotated 90°Clockwise relative to panel <bold>C</bold>; panel <bold>E</bold> is 180°Clockwise relative to <bold>C</bold>; and F is 270°Clockwise relative to panel <bold>C</bold>. Thus, we can reverse these rotations and align all panels to the configuration in <bold>C</bold> (see Experiment alignment in Materials and methods). We do that consistently for every trial, increasing the sample for the active sensing at each trial. The data shown in panels <bold>C</bold> to <bold>F</bold> refer to the frequency of hole checks in the arena: number of checks accumulated over mice divided by total number of checks, normalized between zero (smaller circles colored in light pink) and one (larger circles colored in dark pink). Larger balls represent higher normalized check rates.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95764-fig1-figsupp1-v1.tif"/></fig></fig-group><p>We first analyzed the effects of randomizing the entrance location taken by the mouse on successive trials (<xref ref-type="fig" rid="fig1">Figure 1C</xref>), versus maintaining a static entrance throughout training (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). We quantified the geometric and kinetic features of the trajectories and the behavior of hole checking throughout the arena. The variability of the trajectories resulted in the development of statistical methods to directly infer the mice estimation of the target location (the ‘target estimation vector’, or TEV). We showed that it coincides with the actual target vector only for the static entrance protocol. In order to eliminate the effect of visual cues, we performed rotated probe trials after training in static entrance, where mice went either to the target (following landmarks) or to the REL (ignoring landmarks; see <xref ref-type="fig" rid="fig1">Figure 1D</xref>).</p><p>Finally, we investigated the features of the mice trajectories and active sensing behavior when trained on two targets consecutively under the static entrance protocol (<xref ref-type="fig" rid="fig1">Figure 1E</xref>). In this case, the TEV method was employed to demonstrate the learning of both target directions and the use of shortcuts, one manifestation of a cognitive map (<xref ref-type="bibr" rid="bib76">Tolman et al., 1946b</xref>). See Materials and methods and the figure supplements for the definition of all measured quantities and details on experimental protocols.</p><sec id="s2-1"><title>Pretraining trials</title><p>Initially, naïve mice were introduced to our maze. In agreement with previous work (<xref ref-type="bibr" rid="bib25">Fonio et al., 2009</xref>), we observed that mice initially explored the maze by following the wall (thigmotaxis) on round trips of increasing complexity before they explored the maze center. Our pretraining protocol induced the mice to explore the arena center (see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>, Materials and methods). Thigmotaxis was still observed after pretraining (see, e.g. <xref ref-type="fig" rid="fig2">Figures 2A, B ,</xref>, <xref ref-type="fig" rid="fig3">3A and B</xref>), although now the mice spent more time in the central regions of the maze. In the Static trial experiments, there was not a distinct class of thigmotactic trajectories, but rather a continuum of trajectory distances from the wall. Furthermore, the mice were initially equally likely to take trajectories at any angle from the start-to-food line as evidenced by the variation of the TEV deviation from the target vector in trial 1 of <xref ref-type="fig" rid="fig4">Figure 4I</xref>.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Mouse spatial learning with random entrances.</title><p>(<bold>A</bold>) Two examples of mouse search trajectories during early learning (trial 3) when the entrance changes from trial to trial. They are irregular and vary unpredictably across trials. (<bold>A, B</bold>) Star = target location. Yellow Square = entrance site. (<bold>B</bold>) Two examples of mouse search trajectories during late learning (trial 14) after starting from different entrances. Trajectories look as irregular as in early trials. (<bold>C</bold>) <bold>Top:</bold> Heatmap of the first 2 min of a probe trial done after trial 18 (red = more time in a given region). <bold>Bottom:</bold> Mice spent about the same time (25%) in each of the four sectors, regardless of being close to the target (blue) or to its REL (white). (<bold>D</bold>) Some significant reduction in latency to reach target is seen across trials (p=0.008; N=8). (<bold>D–I</bold>) Error bars = S.E. Shaded area = data range. (<bold>E</bold>) Some significant increase in speed is seen (p=0.002; N=8). (<bold>F</bold>) Average normalized distance traveled to reach target (<italic>d</italic><sub>total</sub>/<italic>d</italic><sub>target</sub>=1 is optimal; p=0.05, N=8). (<bold>G</bold>) Hole-checking density (number of hole checks per distance traveled) in each half of the trajectory. The density remains constant for both halves and across trials, suggesting that mice remained uncertain as to the food location. G-inset. The S.D. of the density over the mice sample remains constant for both halves (N=8). (<bold>H</bold>) The average distance of the checked holes to the food <italic>d</italic><sub>(<italic>checks→food</italic>)</sub> remains almost constant across trials. Horizontal lines are just guides to the eye. (<bold>I</bold>) The probability density of the distance of hole checks to the food <italic>d</italic><sub>(<italic>checks→food</italic>)</sub> for the first and last learning trials (the corresponding averages over trials are in panel <bold>H</bold>). The density remains unaltered. Vertical dotted lines mark the same distances as the horizontal lines in panel (<bold>H</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95764-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Hole check distribution in Random Entrance protocol for the four target holes from the mouse’s perspective.</title><p>(<bold>A</bold>) Red bar: hole checks in the target hole (labeled ‘0’). Green shaded bars: hole checks in the previous positions of the target in the mouse’s perspective (see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B</xref>; ‘–1’ for the position of the target in the previous trial; ‘–2’ for the trial before previous; and ‘–3’ for the trial before ‘–2’). Since, there are training trials, each of the target holes (0,–1, –2, and –3) had food in their respective trial (i.e. ‘0’ has food in the trial; –1 had food in the previous trial; –2 had food in the trial before previous; and –3 had food in the trial before –2). Gray bars: randomized hole checks for each corresponding position: all detected hole checks in a given trial were uniformly distributed across the 100 holes of the arena, and then we counted the number of checks in each of the four targets’ positions. Whiskers: standard deviation (n=8). Gray bars were compared to the corresponding colored bars via a paired t-test. Significant differences were rarely found (Trial 8 only) between randomized data and actual hole checks, suggesting that the mice are performing randomly. n.s.=not significant. (<bold>B</bold>) <bold>Left:</bold> Distribution of the distance of the hole checks to the center of the arena (to be compared with <xref ref-type="fig" rid="fig2">Figure 2I</xref> and <xref ref-type="fig" rid="fig3">Figure 3I</xref> in the main text). The distance of the active sensing to the center of the arena is almost uniform, indicating that the mice have no preferential distance to check for food. <bold>Right:</bold> The density of checks near the center (&lt;20 cm away) is the same as farther away. This suggests that there is no obvious spatial learning feature relating the target with the central spot of the maze.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95764-fig2-figsupp1-v1.tif"/></fig></fig-group><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Mouse spatial learning with static entrances.</title><p>(<bold>A</bold>) Two examples of mouse search trajectories during early learning (trial 3). They are irregular and variable similarly to those in the random entrance experiments. (<bold>A, B</bold>) Star = target location. Yellow Square = entrance site. (<bold>B</bold>) Two examples of mouse search trajectories during late learning (trial 14). They go directly towards the food or go along the wall before turning to the food, creating variation across mice and trials. (<bold>C</bold>) (Top) Heatmap of the first 2 min of a probe trial done after trial 14 (red = more time in a given region). (Bottom) Mice spent almost 50% of the time within 15 cm radius of the target (blue) compared to the RELs (white). (<bold>D</bold>) Latency dramatically decreases (p&lt;10<sup>–7</sup>; N=8). (<bold>D–I</bold>) Error bars = S.E. Shaded area = data range. (<bold>E</bold>) Speed significantly increases during trials (p=0.0001; N=8). (<bold>F</bold>) Normalized distance to reach target <italic>d</italic><sub>(t<italic>otal→target</italic>)</sub>=1 is optimal becomes almost optimal (p&lt;10<sup>–7</sup>; N=8). (<bold>G</bold>) Hole-checking density over distance in each half of the trajectory. It significantly decreases in the first half (p=0.05), and stays constant in the second. G-inset: The S.D. of the density is larger in the second half. (<bold>H</bold>) The average distance of the checked holes to the food <italic>d</italic><sub>(<italic>checks→food</italic>)</sub> decreases for both halves of the trajectory. After learning, the hole checks happen closer to the food <italic>d</italic><sub>(<italic>checks→food</italic>)</sub> is almost zero, although there are more checks per distance. (<bold>I</bold>) The probability density of the distance of hole checks to the food <italic>d</italic><sub>(<italic>checks→food</italic>)</sub> for the first and last trials (the corresponding averages over trials are in panel <bold>H</bold>). After learning (trial 14), the density is larger closer to the food, a feature that does not appear in the random entrance experiments.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95764-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Location of hole checks in the last 3 s before finding the target in Static Entrance protocol.</title><p>(<bold>A</bold>) Pink spots: hole checks in the last 3 s before finding the target; gray spots: earlier hole checks. Dashed ellipsis (x=mean): dispersion (covariance) of the spatial distribution of hole checks. The distribution of hole checks migrates towards the target (labeled A) as the mice learn. All mice (n=8) pooled together. (<bold>B</bold>) Density of hole checks (<inline-formula><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>k</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> per traveled distance) in the last 3 s (pink spots), compared with that density for the earlier path (gray spots), as a function of trial. There is significant increase over trials (<italic>R</italic>=0.7, p=0.00545) for the static entrance case, implying that the hole checks are converging to be temporally ‘close’ to the food as the mice learn – in the first few trials, holes are checked throughout the entire duration of the run. We hypothesize that the pink spots might act as anchors for place fields. Shade behind the curve marks the full extent of the sample (n=8 mice). Stars: significant difference between first and last trial (paired t-test, p&lt;0.05).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95764-fig3-figsupp1-v1.tif"/></fig></fig-group><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Trajectory directionality and active sensing for random and static experiments.</title><p>Arenas on the top row (mean displacement vector – see color scale between panels <bold>B</bold> and <bold>E</bold>) correspond to the ones immediately below them (hole checking spatial distribution); the red ‘A’ label marks the target (food site), which is pointed by the food (target) vector (purple arrow). Top row (<bold>A, B, E, F</bold>): the color and arrows indicate the most probable route taken (red = more probable; only p&lt;0.001 displacements shown; pink arrow = inferred target position, or TEV; shaded pink sector = S.D. of TEV; see Materials and methods, and <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). Bottom row (<bold>C, D, G, H</bold>): spatial distribution of hole-checks; size and color of circles = normalized frequency that a hole was checked (larger pink circles = higher frequency); Black ellipse (x=mean): covariance of spatial distribution. Green ellipse (+=mean): covariance of spatial distribution restricted to ≤20 cm of the target. Random entrance experiments (N=8; panels <bold>A, C</bold>: trial 1; <bold>B, D</bold>: trial 14): regardless of training stage, no significant preferred routes and the TEV does not point to target (<bold>A, B</bold>); hole checks are randomly distributed throughout the arena, and shift from the walls (<bold>C</bold>) to near the center (<bold>D</bold>) after learning. Static entrance experiments (N=8; panels <bold>E, G</bold>: trial 1; <bold>F, H</bold>: trial 14): after learning (<bold>F</bold>) the TEV and significant displacements go straight to the target (although individual trajectories are variable); and hole checks align along the start-target path (<bold>H</bold>). (<bold>I</bold>) Deviation between the TEV (pink arrow) and the target vector (purple arrow) illustrated in top panels. Directionality is quickly learned (static case). (<bold>J, K</bold>) Hole-check area density corresponding to the spatial profiles in bottom panels. Density after learning is larger near the target (static case), supporting the path integration hypothesis. Asterisks/star: p&lt;0.05 (paired t-test). Note the presence of more significant displacements in late learning for static entrances only, and the associated alignment of the TEV and food vector.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95764-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Definition of a hole-checking event as active sensing and target estimation vector (TEV).</title><p>(<bold>A</bold>) Observed trajectory with hole-checking events identified by the two criteria sets of our method, applied subsequently to avoid missed checks. (<bold>B</bold>) The velocity profile with dots representing the hole-checking events shown in panel <bold>A</bold>. The color from cyan to magenta represents the time order of the events, as presented in panel <bold>A</bold>. See Hole-checking Event detection in Materials and methods for details of the detection criteria. A video is also available at <ext-link ext-link-type="uri" xlink:href="https://bit.ly/mouseCogMapVideo">https://bit.ly/mouseCogMapVideo</ext-link> to illustrate the operation of the hole check algorithm and the mouse behavior. (<bold>C-E</bold>)<bold>:</bold> Arena lattice, box size scaling and step map definition. (<bold>C</bold>) A square lattice with <inline-formula><mml:math id="inf2"><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> boxes is overlayed on top of the arena recording to build the step map. There are <inline-formula><mml:math id="inf3"><mml:mi>L</mml:mi></mml:math></inline-formula> boxes along both the <inline-formula><mml:math id="inf4"><mml:mi>x</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf5"><mml:mi>y</mml:mi></mml:math></inline-formula> axes. <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is an odd number, such that the center box is aligned with the center of the arena. For <inline-formula><mml:math id="inf7"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>11</mml:mn></mml:math></inline-formula>, each lattice site (box) measures approximately 11 cm by 11 cm. This lattice is used to calculate the step maps (see Step map calculation in Materials and methods). (<bold>D</bold>) To generate the step maps, we start by counting the number of steps a mouse takes between any two adjacent sites in the lattice; for example, when the mouse lies in the box marked by the gray circle, it can choose to take a step up, down, left or right. If no trajectories pass over that site towards a given direction, then that particular direction is assumed to have null probability <inline-formula><mml:math id="inf8"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. (<bold>E</bold>) An example showing three trajectories that eventually pass by the marked spot, two times going up (cyan and magenta) and one time going down. The step map vector <inline-formula><mml:math id="inf9"><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover><mml:mfenced separators="|"><mml:mrow><mml:mn>3,3</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula> is then pointing up. See Materials and methods for the detailed calculation of this vector. (<bold>F</bold>) We count the number of boxes <inline-formula><mml:math id="inf10"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mi>o</mml:mi><mml:mi>x</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for each trajectory (exemplified in panel <bold>A</bold>) and plot it versus the lattice lateral size <inline-formula><mml:math id="inf11"><mml:mi>L</mml:mi></mml:math></inline-formula>, yielding the box dimension<sup>1</sup> equal 1 for all trajectories in every trial and experimental setup. The observed robust scaling allows us to use moderately small <inline-formula><mml:math id="inf12"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>11</mml:mn></mml:math></inline-formula> for our experimental analysis; thus, larger <inline-formula><mml:math id="inf13"><mml:mi>L</mml:mi></mml:math></inline-formula> yields qualitatively the same results.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95764-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Estimation of significance for the mean displacement direction calculation.</title><p>The jackknife sampling procedure is obtained by the ‘leave-one-out’ rule, yielding N unique jackknife samples of N-1 points from an original sample of N points (see Materials and methods). (<bold>A</bold>) Illustration of a jackknife sample with N-1=10 vectors for a single site in the arena for both static (blue, strong directionality) and random (red, weak directionality due to a more uniform direction distribution) entrance experiments (pale-colored arrows = sample; bold-colored arrows = mean; the means make up the displacement maps shown in main <xref ref-type="fig" rid="fig4">Figures 4</xref>, <xref ref-type="fig" rid="fig5">5</xref>, <xref ref-type="fig" rid="fig7">7</xref> and <xref ref-type="fig" rid="fig8">8</xref>, and <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). (<bold>B</bold>) The same sample from panel <bold>A</bold>, but all vectors’ angles (i.e. directions) were shifted such that the mean angle of each condition (static and random entrances) is zero degrees. This procedure does not change the distribution of angles, but makes all angles distributed with zero mean between –180<sup>o</sup> and 180<sup>o</sup>. (<bold>C</bold>) The angles of the mean displacement vectors of a typical site in the static experiment are narrowly distributed around 0<sup>o</sup> (S.D.=2.9<sup>o</sup> for this particular site, after the unbiasing in panel <bold>B</bold>); the angles of the random entrance experiments are widely distributed (S.D.=106<sup>o</sup> for this particular site), reflecting weak directionality. (<bold>D</bold>) The probability density of observing some particular value for the S.D. of a collection of N=8 uniformly distributed angles between –180<sup>o</sup> and 180<sup>o</sup>. It was calculated numerically (shaded area is the error of the estimated probability density function from 10,000 independent realizations). (<bold>E</bold>) The p-value represents the significance of a given S.D. shown in panel <bold>D</bold> (i.e. probability of observing the S.D.); it is the integral of the probability density in panel <bold>D</bold> up to S.D. (see Materials and methods). This p-value shows that the probability of observing an S.D. &lt; 15<sup>o</sup> is negligibly small (p&lt;0.0001). This means that observing such an S.D. in the static entrance experiments cannot be due to chance. These p-values are the ones shown for the displacement maps in main <xref ref-type="fig" rid="fig4">Figures 4</xref>, <xref ref-type="fig" rid="fig5">5</xref>, <xref ref-type="fig" rid="fig7">7</xref> and <xref ref-type="fig" rid="fig8">8</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95764-fig4-figsupp2-v1.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>Kinetic and geometric features and correlation with active sensing.</title><p>(<bold>A</bold>) Definition of the geometric features that measure performance across trials. <italic>Food line:</italic> the straight line that connects the food hole (target) to the entrance; this line defines the optimal trajectory and minimum distance from start to target, <inline-formula><mml:math id="inf14"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. <italic>Distance to food line</italic>: minimum (perpendicular) distance from the mouse center to the food line (it can be regarded as the trajectory ‘error’, or deviation, from the optimal trajectory). <italic>M-T line</italic>: a line that connects the mouse center to the target. <italic>Mouse vector</italic>: a vector that points from the mouse center to its nose. <italic>Heading angle</italic>: angle between the mouse vector and the M-T line (heading angle = 0 means going straight to the target). (<bold>B</bold>) The total traveled distance <inline-formula><mml:math id="inf15"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> correlates with the number of checked holes <inline-formula><mml:math id="inf16"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>k</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for every trial, sampling all mice together in both random and static entrance experiments. (<bold>C</bold>) The total trial time spent before reaching the food almost linearly correlates with the number of checked holes <inline-formula><mml:math id="inf17"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>k</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for every trial: regardless of how long the mouse runs, they keep checking the arena for food. This is evidence of path integration because even after learning, the mice are still uncertain, so they keep checking. In the main text and in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>, we showed that these checks in later trials accumulate near (&lt;20 cm) the target. (<bold>D, E, F</bold>) Comparison of the evolution of kinetic and geometric parameters across trials, averaging each performance feature over mice (N=8; symbols = mean; shaded region = full extent of the sample; error bars = standard deviation). (<bold>D</bold>) The traveled distance <inline-formula><mml:math id="inf18"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (<bold>D</bold>) becomes quasi-optimal in the static entrance case, approaching <inline-formula><mml:math id="inf19"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. (<bold>E</bold>) The heading angle to the food line decreases significantly only in the static case. (<bold>F</bold>) The heading angle decreases significantly only in the static case. Asterisks mark significant differences between random and static cases (q&lt;0.05, FDR-corrected); stars mark significant differences between first and last trials of the same case (p&lt;0.05). (<bold>G</bold>) Heading angle averaged over mice displayed as a function of trials for different segments of the trajectory: (<bold>i</bold>) 0–5%; (ii) 20–25%; and (iii) 80–85%. A segment is defined as the percentage of the latency (i.e. total trial time). For example, the 0–5% comprises only the part of the trajectory between the start and 5% of the total trial time shown in <bold>C</bold>. Only in the last parts of the trajectories the mice turn to the food (evidenced by a significant decrease of the heading angle vs. trials in the 80–85% segment), suggesting that the mice tend to keep their trajectories variable.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95764-fig4-figsupp3-v1.tif"/></fig><fig id="fig4s4" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 4.</label><caption><title>Covariance between geometric and kinetic features, and active sensing.</title><p>The definition of each of these parameters is given in <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>. Small filled symbols = average over trajectory for each mouse; large empty symbols = average over mice (N=8) of small symbols. Dashed ellipsis = covariance across mice. <bold>Left column</bold>: full trajectory analysis – each feature is averaged over the whole trajectory of each mouse. <bold>Center and right columns</bold>: half trajectory analysis – each feature is averaged over the first and second half of the trajectory for trial 1 (center) and trial 14 (right). The four large empty symbols give the average over the eight mice for each case. Horizontal dotted lines are there for reference values.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95764-fig4-figsupp4-v1.tif"/></fig><fig id="fig4s5" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 5.</label><caption><title>Control experiments for path-integration.</title><p>(<bold>A</bold>) Comparison in learning rate between mice with 2D cues on the wall (blue) and mice with no cues (red). N=4 mice per group, Error = SE. No significant difference in performance. (<bold>B</bold>) Example trajectories of mice trained with and without 2D visual cues. (<bold>C</bold>) Comparison in learning rate between two groups of mice trained in the light. N=4 mice per group, Error = SE. No significant difference in performance. (<bold>D</bold>) An example trajectory of a mouse trained in the light successfully navigating towards the target in darkness (blue line). A control trajectory of a mouse navigating in the light is shown (red line). (<bold>E</bold>) Comparison in learning rate between mice trained and tested in complete darkness versus mice trained in light and tested in light. The trained and tested in darkness mice had additional controls for potential odor cues (see Materials and methods). N=4 mice per group, Error = SE. No significant difference in performance. (<bold>F</bold>) Example trajectories of mice trained and tested in darkness versus trained and tested in light successfully traveling towards the target in both darkness (blue line) and light (red line), respectively.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95764-fig4-figsupp5-v1.tif"/></fig></fig-group></sec><sec id="s2-2"><title>Mice used self-motion sensory input but did not utilize 2D wall cues for spatial learning</title><sec id="s2-2-1"><title>Random Entrance experiments</title><p>Mice were trained with their cage being moved randomly between quadrant entrances from trial to trial without directly manipulating the animals. Thus, they never entered from the same start position for consecutive trials, making the wall pictures their only reliable orienting landmarks. These cues were 15x15 cm black shapes on a white background (see Materials and methods). The configuration of the 4 cues varied relative to the entrance, but the food was always placed in the same hole and nearest the X-shaped landmark (<xref ref-type="fig" rid="fig2">Figure 2</xref>, Materials and methods). The food-restricted mice showed persistent complex search trajectories throughout the learning period (<xref ref-type="fig" rid="fig2">Figure 2A and B</xref>). The latency to reach the food target was significantly negatively correlated with trial number (statistics in <xref ref-type="fig" rid="fig2">Figure 2D</xref>) but with a non-significant difference between the first and last trials (N=8; First trial mean ± SD = 151.34±148.91 s; Last trial mean ± SD = 80.38±43.86 s; p=0.2602). Despite the decrease in latency, mice did not appear to exhibit spatial search strategies (<xref ref-type="fig" rid="fig2">Figure 2C</xref>) given that the time spent in each quadrant during the probe trial is similar (target quadrant = 28.78%, other quadrants = 24.93%, 28.04%, 18.25%; one-way ANOVA: p=0.070574, F-ratio=2.71621; see Behavioral analysis in Materials and methods). This suggests latency decreased for reasons independent of spatial learning.</p><p>We found a corresponding significant positive correlation of speed and trial number (<xref ref-type="fig" rid="fig2">Figure 2E</xref>) with non-significant differences between first and last trials (N=8; First trial mean ± SD = 6.68±3.79 cm/s; Last trial mean ± SD = 11.40±5.07 cm/s; p=0.0704). Since the distance from start to target (<italic>d<sub>target</sub></italic>) varies over trials due to changing entrance location, we defined the normalized trajectory length (<xref ref-type="fig" rid="fig2">Figure 2F</xref>). It is the ratio between total traveled distance (<italic>d<sub>total</sub></italic>) and <italic>d<sub>target</sub>; d<sub>total</sub></italic>/<italic>d<sub>target</sub></italic> = 1 is optimal. There is no significant correlation of this quantity and trial number (p=0.295). The first and last normalized trajectory lengths were not significantly different either (N=8; First trial mean ± SD = 11.79±8.25; Last trial mean ± SD = 15.51±9.92; p=0.4241).</p><p>Fitting the function <italic>d<sub>total</sub></italic> = <italic>B</italic><sub>*</sub>exp(-Trial/<italic>K</italic>) reveals the characteristic timescale of learning, <italic>K</italic>, in trial units (<xref ref-type="fig" rid="fig2">Figure 2F</xref>). We obtained K=26 ± 24 giving a coefficient of variation (CV) of 0.92. The mean, K=26, is therefore very uncertain and far greater than the actual number of trials. Thus, we hypothesize that the mice did not significantly reduce their distance travelled (<xref ref-type="fig" rid="fig2">Figure 2A, B and F</xref>) because they had not learned the food location – the decrease in latency (<xref ref-type="fig" rid="fig2">Figure 2D</xref>) was due to its increased running speed and familiarity with non-spatial task parameters.</p><p>We next examined hole checking as an active sensing indicator of the mouse’s expectation of the food location (see Materials and methods, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplements 1</xref>–<xref ref-type="fig" rid="fig4s4">4</xref> and the Shortcut Video) for hole-check detection after spatial learning. Even though hole check counts increase with the total trajectory length and latency (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3B and C</xref>), we expected that the mice would increase the number of hole checks near the expected food location, or along their path toward it. Thus, we split the trajectories into two halves of same duration to identify whether hole checks would increase in the second half (being closer to the target). However, the hole checking density (ratio between number of checks and distance travelled) remains constant between the first and second halves of any trial (<xref ref-type="fig" rid="fig2">Figure 2G</xref>), suggesting mice did not anticipate where the food is placed. Mice also did not increase their hole sampling rate as they approached the target as shown by the distance of hole checks to the target, <italic>d<sub>checks</sub></italic><sub>→<italic>food</italic></sub> (<xref ref-type="fig" rid="fig2">Figure 2H, I</xref>), again suggesting no expectation of its location. Mice do not appear to learn a landmark-based allocentric spatial map.</p></sec><sec id="s2-2-2"><title>Static entrance experiments</title><p>We tested whether the mice might acquire an allocentric spatial map if, contrary to the random entrance case, they had a single stable view of the landmarks and could associate one cue configuration with the food location (see Materials and methods). For this, each mouse entered the arena from the same entrance during the training trials (hence ‘static entrance’). Mice greatly improved their trajectory efficiency after training (<xref ref-type="fig" rid="fig3">Figure 3A and B</xref>), with distance and latency to food plateauing around trial 7. During early learning, mice showed random search trajectories that transformed to stereotyped trajectories towards food by late learning (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). Typical trajectories were either (i) directly to the food, (ii) initially displaced towards the maze center then returning to a food-oriented trajectory, or (iii) initially along the wall and then turning and heading to the food (<xref ref-type="fig" rid="fig3">Figure 3B</xref>).</p><p>During the probe trial, mice spent the most time searching in the target quadrant (44.26%; <xref ref-type="fig" rid="fig3">Figure 3C</xref>), compared to the time spent in the other quadrants, respectively 19.38% (p=0.007), 16.55% (p=0.0065), 19.81% (p=0.007; p-values obtained for a pairwise t-test and adjusted for multiple comparisons via the Benjamini-Hochberg method). The latency to target strongly decreased over trials (<xref ref-type="fig" rid="fig3">Figure 3D</xref>) and the last trial latency was significantly reduced compared to the first (N=8; First trial mean ± SD = 255.39±153.28 s; Last trial mean ± SD = 7.38±4.03 s; p=0.004). The speed dramatically increased over trials (<xref ref-type="fig" rid="fig3">Figure 3E</xref>) and the ending speed was significantly greater than the initial speed (N=8, First trial mean ± SD = 6.04±2.48 cm/s; Last trial mean ± SD = 17.25±4.64 cm/s; p=0.0002). The normalized trajectory length strongly negatively correlated with trial number (<xref ref-type="fig" rid="fig3">Figure 3F</xref>) and the final normalized length greatly reduced (N=8; First trial mean ± SD = 18.02±11.36; Last trial mean ± SD = 1.40±0.50; p=0.0061), becoming almost optimal (<xref ref-type="bibr" rid="bib65">Rosenberg et al., 2021</xref>).</p><p>Now the fitting of the function <italic>d<sub>total</sub></italic> = <italic>B</italic> exp(-Trial/<italic>K</italic>) yielded <italic>K</italic>=5.6 ± 0.5 with a CV = 0.08; the mean is therefore a reliable estimate of total distance travelled. We interpret this to indicate that it takes a minimum number of K=6 trials for learning the distance to the target (see also <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3D, E, F and G</xref>). Learning is still not complete because it takes 14 trials before the trajectories become near optimal.</p><p>Hole checking density varied across trajectories and differed between early and late learning trials. The density significantly decreased with trial number in the first half of trajectories (<italic>R</italic>=−0.54; p=0.0455, <xref ref-type="fig" rid="fig3">Figure 3G</xref>) but not the second half (<italic>R</italic>=0.17; p=0.559, <xref ref-type="fig" rid="fig3">Figure 3G</xref>). The hole checks also happened significantly closer to the target in the second half of the trajectory (<xref ref-type="fig" rid="fig3">Figure 3H</xref>; First trial mean ± SD = 48.06±11.50 cm; Last trial mean ± SD = 3.13±5.70 cm; p=3 × 10<sup>–6</sup>). A remarkable effect of learning is that the probability of checking holes increases as the mouse approaches the food (<xref ref-type="fig" rid="fig3">Figure 3I</xref>). These results (<xref ref-type="fig" rid="fig3">Figure 3H, I</xref>) suggest that the mice may be predicting the food location and checking their prediction as they approach the estimated food location (see also <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplements 3</xref> and <xref ref-type="fig" rid="fig4s4">4</xref> for other quantities and scatter plots of trajectory features vs. hole checking). Hole checking near the food site also implies that the mice are not using odorant or visual cues to sense the precise food location, but instead rely on a memory-based estimate of the food-containing hole (see also <xref ref-type="fig" rid="fig4">Figure 4G and H</xref>). This motivated us to look at the spatial configuration of these variables to get a detailed picture of the random vs. static condition.</p></sec><sec id="s2-2-3"><title>Revealing the mouse estimate of target position from behavior</title><p>Although quantitative, the analysis so far only showed a broad comparison between random versus static entrance experimental conditions. We developed a method to map out the directions that the mice stepped towards more frequently from each particular location in the arena, yielding a <italic>displacement map</italic> (see Statistical analysis of trajectories in Materials and methods). This map can generate a precise estimate of the mean directionality of the trajectories for each experimental condition (<xref ref-type="fig" rid="fig4">Figure 4A, B, E, F</xref> and p-values in <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). Additionally, we also made a frequency plot of the checks for each particular hole in the arena, yielding the spatial distribution of hole checks (<xref ref-type="fig" rid="fig4">Figure 4C, D, G and H</xref>). These two maps are combined to give the Target Estimation Vector (TEV). The TEV is interpreted as the mouse’s estimate of the target position (pink vectors in <xref ref-type="fig" rid="fig4">Figure 4A, B, E and F</xref>).</p><p>In random entrance training, no significant directionality was found in the arena (<xref ref-type="fig" rid="fig4">Figure 4A and B</xref>), again consistent with a random search. The spatial distribution of hole checks migrated from near the walls towards the center of the arena but remained random and displaced from the target (<xref ref-type="fig" rid="fig4">Figure 4C and D</xref>, and also <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>), consistent with the broad results of <xref ref-type="fig" rid="fig2">Figure 2</xref>. Conversely, there was a clear and significant flow of trajectories for mice trained with static entrance (<xref ref-type="fig" rid="fig4">Figure 4E and F</xref>; p&lt;0.0001; see Materials and methods for the definition of the p-values assigned to directions). The hole checks reflected this and became solely concentrated along the route from start to target (<xref ref-type="fig" rid="fig4">Figure 4G and H</xref>). In the static entrance condition, the entropy (uncertainty) of the number of hole checks near (&lt;20 cm) the target was lower than that for the far (&gt;20 cm) condition (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). In other words, mice were more consistent in the number of their hole checks near the target compared to far from the target, suggesting that they had an internal representation of their proximity to the food site.</p><p>We compared the deviation between the TEV and the true target vector (that points from start directly to the food hole; <xref ref-type="fig" rid="fig4">Figure 4I</xref>). While the random entrance mice had a persistent deviation between TEV and target of more than 70<sup>o</sup>, the static entrance mice were able to learn the direction of the target almost perfectly by trial 6 (TEV-target deviation in first trial mean ± SD = 57.27<sup>o</sup> ± 41.61<sup>o</sup>; last trial mean ± SD = 5.16<sup>o</sup> ± 0.20<sup>o</sup>; p=0.0166). A minimum of 6 trials is sufficient for learning both the direction and distance to food (<xref ref-type="fig" rid="fig4">Figure 4I</xref>) (<xref ref-type="fig" rid="fig3">Figure 3F</xref>) (see Discussion). The kinetics of learning direction to food are clearly different from learning distance to food since the direction to food remains stable after Trial 6 while the distance to food continues to approach the optimal value.</p><p>Under the path integration hypothesis, it is expected that error accumulates as the mouse walks (<xref ref-type="bibr" rid="bib49">McNaughton et al., 2006</xref>). This motivated us to investigate the frequency of hole checks per area near the target (within 20 cm) vs. far (further from 20 cm away), <xref ref-type="fig" rid="fig4">Figure 4J and K</xref>. The density of hole checks in both conditions remained constant for random entrance mice, regardless of training duration. However, static entrance mice had significantly higher density of hole checks near the target (<xref ref-type="fig" rid="fig4">Figure 4K</xref>; p-values: random-far vs. static-far=0.005; static-far vs. random-near=0.03; random-near vs. static-near=0.01). The mean position of hole checks near (≤20 cm) the target is interpreted as the mouse estimated target (<xref ref-type="fig" rid="fig4">Figure 4C, D, G and H</xref>; green + sign = mean position; green ellipses = covariance of spatial hole check distribution restricted to 20 cm near the target). This finding together with the displacement and spatial hole check maps (<xref ref-type="fig" rid="fig4">Figure 4F and H</xref>, respectively) corroborates the heatmap of time spent in the target quadrant (<xref ref-type="fig" rid="fig3">Figure 3C</xref>), suggesting a positive correlation between hole checks and time searching (see also <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3C</xref>). Thus, we use the distance from this point to the entrance as the magnitude of the TEV. This definition reveals that the TEV is nearly coincident with the direct route between start location and the food-containing hole (pink vectors in <xref ref-type="fig" rid="fig4">Figure 4F</xref>), consistent with the near optimal normalized trajectory length previously discussed (<xref ref-type="fig" rid="fig3">Figure 3F</xref>).</p></sec><sec id="s2-2-4"><title>Ruling out landmarks</title><p>These results demonstrated that mice can learn the spatial location of the food target from a static entrance. We next investigated whether the performance gain can be attributed to the cues by manipulating the mouse’s entrance. Well-trained static entrance mice were subject to rotation of their home cage by 180°,+90°, or –90° for probe trials in order to start from a different location. We used a different cohort of N=8 mice for each rotation. The mice were not directly handled during the rotation procedure. If the mice were using the distal landmarks, they would still be expected to find the correct food location. If they relied on self-motion cues, they should travel to the REL, since this is the spot where the target would have been if the mouse had been trained from that entrance. In other words, going to the REL means that the trajectory is anchored to the mouse’s start point and not to the wall cues. As illustrated in <xref ref-type="fig" rid="fig1">Figure 1B</xref>, the displacement between each start-REL pair is exactly equal from the mouse’s point of view (e.g. going 70 cm forward then 30 cm to the left reaches the respective REL of the target).</p><p>Following all rotations, mice searched at the REL instead of the correct location for the food reward regardless of the arena having wall cues (<xref ref-type="fig" rid="fig5">Figure 5A, B and C</xref>), meaning that they were not using landmarks to compensate for rotation. In fact, the trajectory kinetics of the 180<sup>o</sup>-rotated probe for reaching the REL target (mean ± SD latency = 4.80 ± 3.06 s; speed = 14.60 ± 5.21 cm/s; normalized distance to REL = 1.96 ± 0.90) is indistinguishable (within one SD or less) from the kinetics of the last trial of static entrance for reaching the true target. The criterion for reaching the REL target was getting within 5 cm of its position (the average inter-hole distance is 10 cm).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Changing start position after training in static protocol.</title><p>Mice are trained in the static entrance protocol to find food at the target labeled ‘A’ (blue circle), and a probe trial is executed with mice entering from a rotated entrance after 18 trials. (<bold>A, B, C</bold>) show the comparison between trajectories from the last learning trial (blue) versus the probe (red). The training was performed without landmarks (<bold>A</bold>) N=8, –90<sup>o</sup> rotation and with landmarks (<bold>B</bold>) N=8, 90<sup>o</sup> rotation; (<bold>C</bold>) N=8, 180<sup>o</sup> rotation. In all instances, mice ignored landmarks and went to the REL location (“REL A” label, red triangle), something that is expected under the path integration hypothesis. (<bold>D</bold>) Trajectory directionality analysis and TEV (pink arrow; shaded sector: S.D.) show that significant paths of all mice (p&lt;0.001; N=8; see Materials and methods) point to the REL-A location in the same way that it pointed to the target without rotated entrance in <xref ref-type="fig" rid="fig4">Figure 4F</xref>. (<bold>E</bold>) The spatial distribution shows that hole checks accumulate along the start-REL vector, instead of the start-target vector of the case without rotation in <xref ref-type="fig" rid="fig4">Figure 4H</xref>. Black ellipse (x=mean): covariance of hole check distribution. Green ellipse (+=mean): covariance of the data within 20 cm of the REL-A location. This suggests that mice follow trajectories anchored to their start location (idiothetic frame of reference).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95764-fig5-v1.tif"/></fig><p>We also show the displacement maps (mean trajectory directionality), hole check spatial profile and TEV for the 180<sup>o</sup>-rotated probe trial (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). The TEV now points to the REL, and the hole checks accumulate along the route to the REL. These maps are also very similar to the static entrance maps in <xref ref-type="fig" rid="fig4">Figure 4</xref>. Thus, the mice failed to use allothetic cues for navigation in the novel start location test.</p></sec><sec id="s2-2-5"><title>Further controls</title><p>It is possible that mice, like gerbils (<xref ref-type="bibr" rid="bib16">Collett et al., 1986</xref>), choose one landmark and learn the food location relative to that landmark (e.g. the ‘X’ in <xref ref-type="fig" rid="fig3">Figure 3B</xref>); in this case, the mice would only have to associate their initial orientation to that landmark without identifying the image on it. We used two additional controls to assess this possibility. Mice were trained without any cues on the wall, eliminating the possibility that they provided orienting guides. The learning curve of mice with or without the 2D wall cues were not significantly different (<xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5</xref>).</p><p>Mice that were well trained in the lighted maze were given trials in complete darkness. These mice still showed the same learning curve compared to untrained mice or mice following rotation (<xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5</xref>).</p><p>Finally, to completely rule out both landmark and possible olfactory cues, we trained and tested mice in total darkness. Head direction tuning may be impaired in sighted mice navigating in darkness (<xref ref-type="bibr" rid="bib3">Asumbisa et al., 2022</xref>), but spatial learning was not affected in our experiments. Mice can also use localized odor sources as landmarks for spatial learning (<xref ref-type="bibr" rid="bib24">Fischler-Ruiz et al., 2021</xref>) and we therefore attempted to eliminate such cues (see Discussion and Materials and methods). The mice were still able to learn the food location in the absence of visual and olfactory cues (<xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5</xref>). These experiments demonstrate that the mice can learn to efficiently navigate from a fixed start location to the food location using path integration of self-motion cues.</p><p>Furthermore, the location of the targets in all instances of the experiment was carefully chosen to avoid cues from the arena’s circular geometry. If the target was placed near the center of the arena, the learning task would be trivial and would involve little spatial inference. Conversely, if the target was placed too close to the wall, thigmotaxis would be sufficient to get near the food. Also, the line going through the center of the arena that is perpendicular to the line connecting start to center has to be avoided (see <xref ref-type="fig" rid="fig1">Figure 1B</xref> for reference), otherwise the system would be symmetric to rotation or could be simplified to a left-or-right choice that would involve little spatial learning. Finally, the target cannot be placed near the start positions. Thus, in the static entrance experiments, the chosen target position is always more than 35 cm away from the wall, and more than 60 cm away from the start. In the random entrance case, the target is placed more than 30 cm away from the wall, and more than 40 cm away from the closest starting location.</p></sec><sec id="s2-2-6"><title>Mice can use a shortcut to navigate between remembered targets</title><p>Our results established that mice learn the spatial location of a food reward using path integration of self-motion cues. Have the mice learned a flexible cognitive map? A test of cognitive mapping would be if mice could take a short cut and navigate from one remembered location to another along a novel, unreinforced path. The ‘two food location experiment’ set out to test this possibility by training mice to travel to food from their home cage to two very differently located sites (chosen according to the rules mentioned in the previous section). The two locations were trained sequentially so that one site was trained first (target A) followed by training on the second site (target B). A probe trial without food after training target A was designed to check if mice had learned it successfully. Only one hole was filled with food in any given training trial. In a second probe trial after training on B, mice were tested to see whether they can travel between the two remembered locations (food is absent; probe B-A trial) despite no prior training nor reinforced experience on the short cut route (<xref ref-type="fig" rid="fig1">Figure 1E</xref>).</p><p>Mice successfully learned the location of target A, evidenced by their direct search trajectories and significant decreases in distance traveled (<xref ref-type="fig" rid="fig6">Figure 6A</xref>), with the same performance as in the static entrance case. During the learning of target A, the distance of the mouse to the future location of target B was always larger than that expected by chance, that is to a randomly chosen location in the maze (see Materials and methods, <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>). In fact, the trajectories stayed, on average, approximately 40 cm away from the forthcoming target B position. In other words, the mice did not learn, by chance, direct unreinforced routes from ‘near B to A’. In <xref ref-type="fig" rid="fig6">Figure 6A</xref>, for example, the mouse passed within 16 cm of the future target B site in an early learning trial, but this close approach does not appear to constitute a B-&gt;A trajectory. The first probe trial (without food) confirmed that mice had learned the location of target A. After not finding food in A, the mice re-initiated a random search (<xref ref-type="fig" rid="fig6">Figure 6B</xref>).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Two food location experiment.</title><p>(<bold>A-D</bold>) Trajectory exemplars of four sequential stages of the experiment (all trials done with static entrance, N=8): (<bold>A</bold>) training target A (trials 1 A and 16 A for early and late learning, respectively); (<bold>B</bold>) probe A (no food is found, triggering a random search); (<bold>C</bold>) training target B (keeping A empty; trials 1-B and 8-B for early and late learning); (<bold>D</bold>) probe B-A (where both targets are trained and empty, and the mice take a shortcut from B to A; see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> for all exemplars). Filled circles = filled target hole; empty circles = empty target. In the A and B learning stages, the trajectories evolve from random to going straight from start to the respective target. (<bold>E,F</bold>) Standard boxplot statistics of learning versus probe (diamonds are averages; asterisks: p&lt;0.05 in a paired t-test comparison). Quantities are defined in <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3A</xref>. Significant differences between early and late learning were observed for the traveled distance (<bold>E</bold>), heading angle (<bold>F</bold>), and distance to the food line (<bold>G</bold>). Density of hole checks (<bold>H</bold>) remained nearly constant, as expected. In all instances, the values of all quantities in the B-A probe resembled the values of the late learning trials, whereas the randomized B-A probe (gray) had values that resembled early learning, suggesting the B-A behavior is not random. In the Probe B→A trials, the ‘food line’ is the straight line that connects B to A, along which the reference distance <inline-formula><mml:math id="inf20"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is measured between A and B. In the other trials, the food line is a straight line from start to the specific target, either A or B, along which <inline-formula><mml:math id="inf21"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is measured between start and target.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95764-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Target estimation vector (TEV) in detail for the random, static and two-target experiments.</title><p>Black arrows point to the mean displacement direction starting from any given site in the arena. Panels (<bold>A-D</bold>) and (<bold>H-K</bold>) green arrows are the target (food) vectors (point from start to target; or from B-&gt;A in the Probe B-A trial) and are to be compared with the TEVs. These panels have the same data as in <xref ref-type="fig" rid="fig4">Figures 4</xref> and <xref ref-type="fig" rid="fig7">7</xref>, respectively, although here all the mean displacement vectors are displayed without censoring large p values. Here, the color of the arrows corresponds to p-values (brown = 1; orange = 0). In the main text, only displacements with very small p-values are shown (see main text and Materials and methods). Panels <bold>A</bold> and <bold>B</bold> show the random entrance condition. The TEV (red) reflects the learned target position, and does not correspond with the food vector, highlighting a random search pattern. Panels <bold>C</bold> and <bold>D</bold> show the static entrance condition. The TEV (blue) becomes closely aligned with the food vector during late training (panel <bold>D</bold>). The big black arrow highlights how trajectories are still variable even after learning the TEV. The variation observed in trajectories result in a TEV pointing almost directly to the food; error is 11 cm – the size of the lattice site, corresponding roughly to the average distance between nearest holes. (<bold>E</bold>) The angle between food vector and TEV in both random and static conditions as training progresses. Angle differences decrease in the static case but not in the random case. N=8 per group, significant differences are marked with an asterisk (FDR corrected, q&lt;0.01). The star marks significant difference between first and last trials only for the static entrance case. (<bold>F</bold>) Distribution of the number of hole checks, P(n<sub>checks</sub>) near the target (≤20 cm) vs. far for all experiments in static entrance experiment (N=36 mice). (<bold>G</bold>) Entropy related to the distributions in panel <bold>F, H</bold> = -ΣP(n<sub>checks</sub>)log[P(n<sub>checks</sub>)], where the sum runs over all values of n<sub>checks</sub>. The entropy of the number of hole checks is always lower for the near compared to far hole checks. In other words, the mice are more consistent in choosing the numbers of holes to check when near the food site (&lt;20 cm) versus further from the food (&gt;20 cm). The entropy decays for both far and near the target conditions consistent with learning food location over trials, but the decay is twice as steep for the far condition. The cumulative densities are shown next to the probability densities. (<bold>H</bold>) In the static condition the TEV (red) points to the learned location of the target A (analogous to Static target in panel <bold>D</bold>). (<bold>I,J</bold>) First and last training trials of target B (after completing training of target A). The TEV (in blue) starts pointing to A (trial 1B), but ends up pointing to B (trial 8B). Panel K. No food probe trial. The mean displacement generates a TEV (orange vector) that points from site B to A, highlighting the shortcut route. Panel L. Learning vs. shortcut. The difference in angle between the food vector and the TEV. The difference becomes significantly lower as training progresses, going back up as the target is switched from A to B, and then going down again as the mice learn the new target. During the probe trial, the TEV-target angle is as small as the late learning trials of either target B or target A (i.e. when the mice know their route). The TEV for the probe trial is significantly smaller than a TEV generated using a random step map (gray box, see Materials and methods for how a random step map was generated).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95764-fig6-figsupp1-v1.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 2.</label><caption><title>Minimum distance to alternative target in 2-target condition, and short cut trajectories.</title><p>(<bold>A and B</bold>) Black squares are the minimum distances expected by chance for each trial; they are calculated with respect to a random point, and then averaged over ten such random points. Shaded area represents the range of values, and bars represent the standard deviation. (<bold>A</bold>) During the learning of target A (no previous target has been presented), the mice keep consistently farther than expected by chance from the location where Target B will be placed (blue circles; asterisks show significant differences to chance). (<bold>B</bold>) The same pattern repeats when learning target B (target A has been already learned and is not present anymore): the mice keep consistently farther than expected by chance from the location where the previous Target A was found (red circles; asterisks show significant differences to chance). During the learning of B, some mice did visit the A location sporadically, making the shaded area larger in panel <bold>B</bold>. However, they did not rely on target A to find B. (<bold>C</bold>) Short cuts and active sensing for the Probe B→A trial. For each mouse, the plots in the top arenas contain trajectories split into two parts: before (blue) and after (orange) the visit to the first target (either A or B, whichever comes first, colored in blue). The bottom arenas of each mouse contain the time course blue is early and pink is late with hole checks in squares (blue is early and pink is late) to give a sense of when each event happened. We cut off the trajectories after visit to the last target (either A or B, whichever comes later, to ensure we observe its visit to both A and B locations). The orange trajectories are the ones that the mice took after realizing there is no food in either A or B (whichever comes earlier). We expect that mice perform the sequence Start→B→A, since B was trained last. Notice in the time course plots that mice 33, 35, 36, 57, and 59 do exactly this without ever going back to Start. Mice 34, 58, and 60 perform Start→A→B, but only mouse 34 visits the Start before heading from A to B.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95764-fig6-figsupp2-v1.tif"/></fig></fig-group><p>After the probe trial, mice were trained to learn target B. During this training, three mice (Mouse 33, 35, 36) first learned a route to target B but, on subsequent searches, they would sometimes first check the site of the previous target A and then travel to the correct target B along a direct short cut route (see Discussion). Nevertheless, on average the mice kept farther from the previous site A than the expected by chance (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>). A first visit to B then to A was never observed during training because mice go back home after getting the food in B.</p><p>After learning the location of target B (<xref ref-type="fig" rid="fig6">Figure 6C</xref>), food was also omitted from this target for Probe B-A. As illustrated in <xref ref-type="fig" rid="fig6">Figure 6D</xref> and the Shortcut video (<xref ref-type="video" rid="video1">Video 1</xref>) (all mice shown in <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>), five of eight mice were observed to go from B to A via varying trajectories (namely, mice numbered 33, 35, 36, 57, and 59). Two (number 58 and 60) of the remaining three mice went first to A and subsequently to B via direct or indirect routes; these mice had previously taken direct routes to B, suggesting that going to A first is not due to a learning deficiency. The remaining one, mouse 34, went from B to the start location and then, to A. This mouse had previously taken the B-A route during training. In all cases, the mice clearly remembered the location of both targets, even though target A had not been presented or rewarded for 4 days.</p><media mimetype="video" mime-subtype="mp4" xlink:href="elife-95764-video1.mp4" id="video1"><label>Video 1.</label><caption><title>The Shortcut video illustrates a two-food site experiment including hole checks; there were no landmarks.</title><p>The mouse was first trained with food at Site A (6 days, 18 trials) and, after training was complete, trained with food at Site B (3 days, 9 trials). The video was taken on a probe trial (Day 10) with no food at either Site A or Site B. The mouse is observed to proceed along a TEV to Site B with a departure from the TEV at the second hole check, followed by a third hole check as it loops back to Site B. After hole checking Site B, the mouse goes on a TEV to Site A with a departure after its third hole check. It then returns to the TEV with further hole checks. Just before reaching Site A the mouse turns and moves very slowly to a hole 16 cm from Site A; this hole check was missed by our algorithm and had to be manually added for statistics. The mouse spends ~2 s at this hole, although it had never contained food; other holes were visited for &lt;1 s. Over the course of the experiment, the mouse visited this hole five times prior to finding the food, but did not visit it in the four trials preceding this Probe trial. Other holes within 15 cm of the target were visited at equal or greater rates. In other words, there was no special sensory input that would have made this hole interesting.</p><p>We hypothesize that this was the hole predicted by the mouse’s cognitive map to be Site A. The mouse subsequently continued to check Site A and a site near the wall. At this point the experiment was terminated. Our ‘wash and rotate the floor’ protocol to eliminate odor trails or ‘floor scratch cues’ results in the floor of the maze being washed and rotated 108 times from the first Site A learning trial to the final Probe trial when Site B and Site A were empty. The floor rotation results in the same configuration of hole positions relative to every entrance, making the environment identical at every trial for all the mice (see Materials and methods).</p><p>Note that the mouse makes its first hole check at a hole near the entrance and a final hole check near the maze wall far from an entrance. Food was never given at either site and there were no features differentiating these holes to make them ‘interesting’. These ‘near the wall’ hole checks were also seen in other mice, but we have no compelling hypothesis as to why they occur at these holes.</p></caption></media><p>The geometric and kinetic features of these experiments for early and late learning of each target, and for Probe B-A, are presented in <xref ref-type="fig" rid="fig6">Figure 6E–H</xref>. For defining the trajectory quantities in the Probe B-A trial, the ‘start’ position is taken as target B, and the ‘target’ is the A site (e.g. the normalized trajectory length is the ratio between total traveled and direct B-A distances). The quantities in probe B-A are statistically indistinguishable from late learning of targets (i.e. trials 14 A and 8-B). Conversely, all the Probe B-A values are significantly different both from trial 1-B and from randomized B-A trajectories (see Materials and methods; p&lt;0.05; except for the density of hole checks which is statistically equal for all considered trials, <xref ref-type="fig" rid="fig6">Figure 6H</xref>). Therefore, the behavior of the mice when going from B to A in the probe is compatible with the behavior of an animal that acquired spatial memory about the trajectory, even though this trajectory was never reinforced. This suggests that the mouse computed the shortcuts without prior experience (see Shortcut video <xref ref-type="video" rid="video1">Video 1</xref>) for an example of shortcutting and associated hole checks.</p><p>We calculated the displacement and hole check maps and the TEV for the whole training protocol, including the probe B-A (<xref ref-type="fig" rid="fig7">Figure 7</xref>). Again, the data show that, after training for A, the TEV pointed directly to A and hole checks accumulated along its path (<xref ref-type="fig" rid="fig7">Figure 7A and B</xref>). The beginning of training for B (trial 1-B) generated random search patterns, while the TEV and hole checks tended towards A. After learning B, we see that the TEV and hole checks completely shifted to it (<xref ref-type="fig" rid="fig7">Figure 7C, D, E and F</xref>). Remarkably, the probe B-A trajectories revealed a strong directed flow with a TEV pointing from B to A, whilst hole checks visibly accumulated along this route (<xref ref-type="fig" rid="fig7">Figure 7G and H</xref>). The TEV-target deviation remained close to zero in late learning and probe B-A (<xref ref-type="fig" rid="fig7">Figure 7I</xref>), whereas the area density of hole checks is increased near the target compared to far only after learning and in probe B-A (<xref ref-type="fig" rid="fig7">Figure 7J</xref>). These maps suggest the emergence of a cognitive map guiding the mice when taking the B to A unrehearsed shortcut routes.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Trajectory directionality and active sensing in two food location experiment.</title><p>Arenas on the top row (mean displacement vector) correspond to the ones immediately below them (hole checking spatial distribution); the red ‘A’ and blue ‘B’ labels mark the targets (food sites), which are pointed by the target vector (purple arrow). Top row (<bold>A, C, D, G</bold>): the color and arrows indicate the most probable route taken (red = more probable; only p&lt;0.001 displacements shown; pink arrow = inferred target position, or TEV; shaded pink sector = S.D. of TEV; see Materials and methods, and <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). Bottom row (<bold>B, E, F, H</bold>): spatial distribution of hole-checks; size and color of circles = normalized frequency at which a hole was checked (larger pink circles = higher frequency); Black ellipse (x=mean): covariance of spatial distribution. Green ellipse (+=mean): covariance of spatial distribution restricted to ≤20 cm of the target. Three stages of the experiment are shown (N=8; all training done in <italic>static entrance with no landmarks</italic>): after learning the target A (<bold>A, B</bold> trial 16 A; significant routes and hole checks are observed only along the target vector, as expected); training of the target B (<bold>C, E</bold>: trial 1-B; <bold>D, F</bold>: trial 8-B); it shows the evolution of the TEV from pointing to A to pointing to B, and the hole checks distribution becomes limited to the newly learned target vector towards B; probe B-A (<bold>G, H</bold>) shows significant routes from B to A (shortcuts; N=5 out of 8 performed the route Start→B→A; see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> for all samples); hole-checks accumulated along the B-A path suggesting that mice remember both locations. (<bold>I, J</bold>) TEV-target deviation and hole-check area density, respectively. Probe B-A measures are compatible with trials where trajectories have already been learned. Standard boxplot statistics. Diamond: mean. Asterisks/star: p&lt;0.05 (t-test).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95764-fig7-v1.tif"/></fig><p>As a stringent control, we performed a two-food-locations experiment with a 180<sup>o</sup>-rotated probe B-A trial (<xref ref-type="fig" rid="fig8">Figure 8</xref>; N=8). Landmarks were never present (neither for training nor for probe). In the rotated probe B-A, the mice went to the REL of B and then to the REL of A. The displacement map, hole check spatial distribution and TEV now all pointed from REL B to REL A (instead of B to A). This is consistent with both the independent experiments of the rotated probe with static entrance training and of the two-food location. Mice can thus take a novel short cut and have therefore computed a cognitive map based on a fixed starting point and self-motion cues alone.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Two food location training with 180° rotated probe.</title><p>Mice (N=8) are trained to find food in the target labeled ‘A’ (red circle, panel <bold>A</bold>), and in target labeled ‘B’ (blue circle, panel <bold>B</bold>) afterwards; then a 180<sup>o</sup> rotated probe trial (no food; panel <bold>C</bold>) is realized to check whether the mice are able to generalize and take the shortcut from REL-B (blue triangle) to REL-A (red triangle), instead of the A and B targets. No landmarks are present. Panels <bold>A, C, E</bold> show exemplars of trajectories in three stages of the experiment, and <bold>B, D, F</bold> show their time course and hole-check locations marked with circles that increase with elapsed time. (<bold>G</bold>) Trajectory directionality analysis and TEV (pink arrow; shaded sector: S.D.) show that significant paths (p&lt;0.001; N=8; see Materials and methods) point from REL-B to REL-A in the same way that it pointed from B to A without rotated entrance in <xref ref-type="fig" rid="fig7">Figure 7G</xref>. (<bold>H</bold>) The spatial density shows that hole checks accumulate along the REL-B to REL-A direction, instead of the B-A direction in the case without rotation in <xref ref-type="fig" rid="fig7">Figure 7H</xref>. Black ellipse (x=mean): covariance of hole check density. Green ellipse (+=mean): covariance of the same data restricted to ≤20 cm of the REL-A location. This suggests that mice follow shortcut trajectories anchored to their start location (idiothetic frame of reference).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-95764-fig8-v1.tif"/></fig></sec></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We have shown that mice can learn the location of a hidden food site when their entrance to an open maze remains the same across trials. Trajectories initially appeared random and took on average, over 100 s and covered a distance of about 10-fold that of the direct route between start and food sites (<xref ref-type="fig" rid="fig3">Figure 3</xref>). After a maximum of 14 trials, mice reached asymptotic performance taking, on average, &lt;10 s to reach the food site and with trajectories reaching a near optimal distance: 1.4 times greater than the direct route (<xref ref-type="fig" rid="fig3">Figure 3F</xref>). In the spatial learning trials, mice frequently checked holes for food along their start to food trajectories. Analyses of hole checks demonstrated the distribution of hole check sites was also modified during learning (<xref ref-type="fig" rid="fig4">Figure 4G and H</xref>). Hole check density decreased with learning in the first half of trajectories but remained constant during the second half. At higher spatial resolution, hole checks occurred most frequently closer to the food site after learning (<xref ref-type="fig" rid="fig4">Figure 4K</xref>). Finally, the number of holes sampled near the food site became more consistent with learning (lower entropy: see <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). We conclude that, given a static entrance, the mice can learn an accurate estimate of food location that guides their trajectories and associated hole check distribution.</p><p>Similar results have been reported for rats trained to find food in a virtual reality (VR) 2D spatial navigation task (<xref ref-type="bibr" rid="bib19">Cushman et al., 2013</xref>). During spatial learning, the reward check rate increased as the rat approached the reward edge for both visual and auditory reward location cues. Navigation (trajectories) and reward checking were, however, in register only for distal visual cues. In our experiments, hole checking at a reward site was not dependent on distal visual cues (see REL discussion below) suggesting that a different source (or sources) of spatial sensory input permits registration of trajectories and hole checking during real world (RW) spatial learning.</p><sec id="s3-1"><title>What cues are required for learning the food location?</title><p>A number of exogenous (tactile, localized and global visual, odorant) and self-motion (optic flow, proprioceptive and vestibular) cues might contribute to the spatial learning we observed. For any cue to be effective, it must be stable under the experimental perturbations we impose, and therefore provide unambiguous information about the location of the food reward relative to the mouse’s starting point. Below we describe which cues might be relevant for spatial learning.</p><sec id="s3-1-1"><title>Allothetic cues</title><sec id="s3-1-1-1"><title>Tactile</title><p>There were no obvious scratches on the maze floor, but we cannot exclude fine scratches detectable by the mice. We wash the floor and randomly turn it between trials so that any scratches or odor trails are not consistently correlated with the food location. We also performed a specific control experiment with an exhaust fan to eliminate food scent. We conclude that tactile cues are likely not used for spatial learning under our experimental conditions.</p></sec><sec id="s3-1-1-2"><title>Localized visual landmarks</title><p>Rodent vision is important for tasks such as navigating complex environments, finding shelter, prey capture and predator avoidance (see <xref ref-type="bibr" rid="bib68">Saleem and Busse, 2023</xref> for a review). Previous behavioral and physiological studies suggested that our wall cues could be resolved by the mouse visual system (<xref ref-type="bibr" rid="bib33">Jacobs et al., 2009</xref>; <xref ref-type="bibr" rid="bib45">Long et al., 2015</xref>; <xref ref-type="bibr" rid="bib62">Prusky and Douglas, 2004</xref>; <xref ref-type="bibr" rid="bib61">Prusky et al., 2000</xref>; <xref ref-type="bibr" rid="bib66">Saleem et al., 2018</xref>). It was therefore surprising that the mice were unable to find the food site when its start location was randomly switched between trials. A comparison of static versus random start sites after learning revealed that, unlike the static case, there was no reduction of trajectory length or increase of hole checks near the food site in the random start experiments. We considered whether the mice were learning slowly and simply needed more trials to learn the random start site task. We therefore checked if there was any improvement in target estimation over four successive trials. As shown in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>, actual hole checks over the four trials are no different from randomized hole checks suggesting that the mice are randomly choosing holes to check.</p><p>The random start task requires the mouse to learn the relative location of food with respect to a changing view of the landmarks. Rats have been shown to be able to solve this task in the Morris Water Maze (MWM; <xref ref-type="bibr" rid="bib56">Morris, 1981</xref>). Previous studies showed that mice can use distal cues for spatial learning under different experimental conditions, such as in a one-dimensional T-maze, linear track, or when there are multiple highly salient cues (<xref ref-type="bibr" rid="bib56">Morris, 1981</xref>; <xref ref-type="bibr" rid="bib14">Chapillon and Roullet, 1996</xref>; <xref ref-type="bibr" rid="bib31">Hébert et al., 2017</xref>; <xref ref-type="bibr" rid="bib64">Rogers et al., 2017</xref>; <xref ref-type="bibr" rid="bib82">Youngstrom and Strowbridge, 2012</xref>). Our random start task would therefore seem to have all the requirements for spatial learning. The simplest explanation is that, unlike some of the cited papers, the cues we used were not sufficiently salient.</p><p>An alternate factor might be the lack of reliability of distal spatial cues in predicting the food location. The mice, during pretraining trials, learned to find multiple food locations without landmarks. In the random trials, the continuous change of relative landmark location may lead the mice to not identifying them as ‘stable landmarks’. This view is supported by behavioral experiments that showed the importance of landmark stability for spatial learning (<xref ref-type="bibr" rid="bib8">Biegler and Morris, 1996</xref>; <xref ref-type="bibr" rid="bib7">Biegler and Morris, 1993</xref>) and that place cells are not controlled by ‘unreliable landmarks’ (<xref ref-type="bibr" rid="bib35">Jeffery, 1998</xref>; <xref ref-type="bibr" rid="bib40">Knierim et al., 1995</xref>; <xref ref-type="bibr" rid="bib71">Save et al., 2000</xref>; <xref ref-type="bibr" rid="bib83">Zhang et al., 2014</xref>). Control experiments without landmarks (<xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5A and B</xref>) or in the dark (<xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5C–F</xref>) confirmed that the mice did not need landmarks for spatial learning of the food location.</p></sec><sec id="s3-1-1-3"><title>Arena geometry</title><p>The mice might use the distance and bearing from its start location to the three other maze entrances. Triangulation might then enable it to estimate the food location based on such global features and continuously update its position by using the relative location of the entrances. Our control experiments (<xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5</xref>) showed that such information is not needed for spatial learning but do not rule out that this information is an additional cue available to the mice under more natural foraging conditions.</p></sec><sec id="s3-1-1-4"><title>Odor cues</title><p>The mouse’s cage will be saturated by its own odor. Transferring the mouse to a different cage might enable it to recognize the change in its starting point. However, our maze was designed to eliminate this ‘self-cage’ odor cue as each mouse stays in its own home cage during the entire experiment. In the Random trials, the entire cage + mouse is moved to a different entrance on each trial. In the Static trials, the cage +mouse is only moved to a different entrance on the REL trials.</p><p>Odor cues might come from odor trails left during a preceding trajectory to food, from the odor of the hidden food or from an odor gradient emerging from the mouse’s home as it leaves to find food. The odor trails were reduced by washing the floor between trials. Any remaining odour was made unreliable as the floor was rotated between trials. A subfloor beneath the maze floor was covered with crumbled fragments of the same food within the capped hole. We assume that the entire maze was saturated with the food odor and that this would mask the odor coming from the accessible food. Mice would search in holes adjacent to the food without successfully locating the food, suggesting no detectable odour at that distance. In addition, the mouse ran to and searched at the food hole on probe trials confirming that it did not require a food odor to find the food hole.</p><p>Mice can also use localized odor sources as landmarks for spatial learning (<xref ref-type="bibr" rid="bib24">Fischler-Ruiz et al., 2021</xref>), and might therefore use odor gradients emanating from their home cage as a cue. We reduced this potential cue by applying negative pressure via exhaust fans covering the cage top that were turned on 5 min before an experiment commenced and its full air volume evacuated 30 times/minute (150 evacuations) to equilibrate it to the room air. After the door to the maze was opened, the fans induced negative pressure to draw air from the maze into the cage and thereby reduce a potential outward gradient (see Materials and methods). The mice were still able to learn the food location after such reduction of olfactory cues (<xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5E and F</xref>) suggesting that odor gradients are not required for spatial learning under our experimental conditions.</p></sec></sec></sec><sec id="s3-2"><title>Idiothetic cues</title><sec id="s3-2-1"><title>Optic flow cues</title><p>Although the mice can take varying trajectories, the TEV suggests that they continuously update their knowledge of the direction from start to food throughout their trajectories. This further suggests that the neurons coding for head direction are essential for spatial learning in our maze. Heading direction can be derived from optic flow signals (<xref ref-type="bibr" rid="bib12">Burlingham and Heeger, 2020</xref>; <xref ref-type="bibr" rid="bib32">Horrocks et al., 2023</xref>). In the static entrance experiments, the heading direction is constantly updated throughout the entire run (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3G</xref>), having the mouse veer toward the food only in the last segment of the trajectory (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3Giii</xref>). Hippocampal neurons of rats randomly foraging in a real world or virtual reality environment can develop directional responses based on rich and stable optic flow signals and without requiring vestibular input (<xref ref-type="bibr" rid="bib1">Acharya et al., 2016</xref>). In our maze, landmarks and home cage openings may drive optic flow signaling irrespective of whether they act as local visual cues. This is consistent with the hypothesis that visual input can guide navigation via a central retinal stream for landmarks and a peripheral retinal stream for optic flow input (<xref ref-type="bibr" rid="bib67">Saleem, 2020</xref>). Our in the dark experiments suggest that other sensory input might also drive the head direction network.</p></sec><sec id="s3-2-2"><title>Vestibular and proprioceptive cues</title><p>The vestibular system encodes natural motion (<xref ref-type="bibr" rid="bib18">Cullen, 2019</xref>; <xref ref-type="bibr" rid="bib53">Mohammadi et al., 2024</xref>) and contributes to the generation of head direction responses (<xref ref-type="bibr" rid="bib17">Cullen and Taube, 2017</xref>; <xref ref-type="bibr" rid="bib74">Taube, 2007</xref>). We hypothesize that, in the ‘dark’ experiments, vestibular cues are a major signal supporting spatial learning. In agreement with VR studies (<xref ref-type="bibr" rid="bib47">Mao et al., 2020</xref>; <xref ref-type="bibr" rid="bib81">Yang et al., 2024</xref>), we hypothesize that contextual visual cues of the starting point and arena boundary anchor directional information derived from optic flow, vestibular and perhaps proprioceptive signals to fixed environmental features.</p></sec></sec><sec id="s3-3"><title>A fixed start location and self-motion cues are required for spatial learning</title><p>We also considered that mice, unlike rats (<xref ref-type="bibr" rid="bib56">Morris, 1981</xref>), may be unable to learn the random entrance task because it requires associating four different spatial cue configurations with a food location. This would hold when the visual cues were local. In the static entrance task, the mice might be learning a unique configuration of the cues or even the relative location of a single cue and the food location (<xref ref-type="bibr" rid="bib16">Collett et al., 1986</xref>). In the REL experiments we therefore first fully trained the mice with a static entrance and, in a probe trial, randomly switched them to another entrance rotated by 90°, 180°, or –90°. Unlike rats in the MWM (<xref ref-type="bibr" rid="bib56">Morris, 1981</xref>), the mice ran to the REL location (<xref ref-type="fig" rid="fig5">Figure 5</xref>) clearly demonstrating that they assume that their start location has not changed and that the local visual cues did not guide the mice. We hypothesize that the optic flow signals emanating from the distinct landmarks, derived from low-resolution peripheral retina (<xref ref-type="bibr" rid="bib67">Saleem, 2020</xref>), are invariant to and thus cannot differentiate between the mouse’s start sites. Additional control experiments made without landmarks or in darkness also showed that visual input is not required for spatial learning in our maze (<xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5</xref>). We hypothesize that the minimal conditions for the mice learning the heading direction from start to food is based on self-motion cues (optic flow, proprioception, and vestibular) and one fixed local cue – the start site.</p></sec><sec id="s3-4"><title>Combining trajectory direction and hole check locations yields a target estimation vector</title><p>Here we follow a review by <xref ref-type="bibr" rid="bib41">Knierim and Hamilton, 2011</xref> that hypothesized independent mechanisms for extraction of target direction versus target distance information. Our data strongly supports their hypothesis. Target direction is nearly perfectly estimated at trial 6 (<xref ref-type="fig" rid="fig4">Figure 4I</xref> and Results). The deviation of the TEV from the start to food vector is rapidly reduced to its minimal value (5.16<sup>o</sup>) and with minimal variability (SD=0.20<sup>o</sup>). Learning the distance from start to food is also evident at trial 6 but only reaches an asymptotic near optimal value at trial 14 (<xref ref-type="fig" rid="fig3">Figure 3F</xref>). The learning dynamics are therefore very different for target direction versus target distance. As noted below, the food direction is likely estimated from the activity of head direction cells. The neural mechanisms by which distance from start to food is estimated are not known (but see <xref ref-type="bibr" rid="bib20">Engelmann et al., 2021</xref>).</p><p>Averaging across trajectories gave a mean displacement direction, an estimate of the average heading direction as the mouse ran from start to food. The heading direction must be continuously updated as the mice runs towards the food (which is suggested in <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3G</xref>), given that the mean displacement direction remains straight despite the variation across individual trajectories. Heading direction might be extracted from optic flow and/or vestibular system and be encoded by head direction cells. However, the distance from home to food is not encoded by head direction signals.</p><p>The mice, after learning with static entrances, made the greatest number of hole checks in the vicinity of the food-containing hole. We therefore used the mean of the ‘near food’ hole check distribution (see <xref ref-type="fig" rid="fig4">Figure 4</xref>) to give a magnitude to the displacement direction, thus generating the TEV. With learning, the TEV rapidly converged to closely align with the direct start-to-food vector (<xref ref-type="fig" rid="fig4">Figure 4E, F, and I</xref>). In REL trials, the calculated TEV pointed to the REL despite the lack of food at the hole check sites (<xref ref-type="fig" rid="fig5">Figure 5</xref>). A close analysis of individual trajectories revealed that, while some closely aligned to the TEV and went directly to food, others deviated from the TEV/direct route and then returned to it (<xref ref-type="fig" rid="fig4">Figure 4F</xref> and <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). The standard assumption is that deviations from a direct route are due to path integration errors (<xref ref-type="bibr" rid="bib21">Etienne et al., 1996</xref>). It is not obvious why errors only occur on some routes. A second possibility is that the deviations are intended and meant to prevent route predictability and therefore predation (<xref ref-type="bibr" rid="bib37">Jun et al., 2014</xref>). It is not clear why the mouse does hole checks if it is only reducing route predictability. A plausible hypothesis is that the mice deliberately deviate from the TEV in order to continue exploring for food-containing holes, <italic>en route</italic> to exploit the food reward. We hypothesize, following <xref ref-type="bibr" rid="bib41">Knierim and Hamilton, 2011</xref>, that a path integration mechanism operates continuously to return the mouse to its current TEV estimate no matter what the reason for the deviations from the TEV.</p><p>We hypothesize that path integration over trajectories is used to estimate the distance from start to food. The stimuli used for integration might include proprioception or acceleration (vestibular) signals as neither depends on visual input. Our conclusion is in accord with a literature survey that concluded that the distance of a target from a start location was based on path integration and separate from the coding of target heading direction (<xref ref-type="bibr" rid="bib41">Knierim and Hamilton, 2011</xref>). Our ‘in the dark’ experiments reveal the minimal stimuli required for spatial learning – an anchoring starting point and directional information based on vestibular and perhaps proprioceptive signals. This view is in accord with recent studies using VR (<xref ref-type="bibr" rid="bib47">Mao et al., 2020</xref>; <xref ref-type="bibr" rid="bib81">Yang et al., 2024</xref>).</p><p>Path integration uses self-motion signals to update the animal’s estimated location on its internal cognitive map. Path integration gain has been shown to be plastic and regulated by landmarks (<xref ref-type="bibr" rid="bib34">Jayakumar et al., 2019</xref>). Remarkably, a recent study has revealed that path integration gain can also be directly recalibrated by self-motion signals (<xref ref-type="bibr" rid="bib46">Madhav et al., 2024</xref>), albeit not as effectively as by landmarks (<xref ref-type="bibr" rid="bib34">Jayakumar et al., 2019</xref>; <xref ref-type="bibr" rid="bib46">Madhav et al., 2024</xref>). An interesting question for future research is whether self-motion signals can also recalibrate the coordinates of a cognitive map. From this perspective, the Target B to Target A shortcut requires transformation of the cognitive map coordinates so that the start point is now Target B.</p><p>Extensive research has shown that external cues can control hippocampal neuron place fields (<xref ref-type="bibr" rid="bib15">Chen et al., 2013</xref>; <xref ref-type="bibr" rid="bib41">Knierim and Hamilton, 2011</xref>; <xref ref-type="bibr" rid="bib57">Muller and Kubie, 1987</xref>) and the gain of the path integrator (<xref ref-type="bibr" rid="bib34">Jayakumar et al., 2019</xref>), making the failure of mice in our study to use such cues puzzling. The failure to use landmarks may be related to our task being low stakes and our pretraining procedure teaching the mouse that such cues are not necessary. Our results may not generalize to more natural conditions where many reliable prominent cues are available, and where there is urgency to find food or water while avoiding predation (<xref ref-type="bibr" rid="bib43">Lai et al., 2024</xref>). Under these more naturalistic conditions, the use of distal cues to rapidly find a food reward is more likely to be observed.</p></sec><sec id="s3-5"><title>Implications for theories of hippocampal representations of spatial maps</title><p>The TEV is learned using self-motion cues alone and we hypothesize that it guides locomotion to the food hole via a path integration mechanism. This conclusion is in accord with an extensive literature that emphasizes the importance of self-motion cues and path integration for spatial learning (<xref ref-type="bibr" rid="bib48">McNaughton et al., 1996</xref>; <xref ref-type="bibr" rid="bib22">Etienne and Jeffery, 2004</xref>). The conclusion is also not surprising given studies on weakly electric fish that demonstrate that, with a fixed initial location, active sensing and self-motion cues are sufficient for learning the location of a food site in the dark (<xref ref-type="bibr" rid="bib20">Engelmann et al., 2021</xref>; <xref ref-type="bibr" rid="bib38">Jun et al., 2016</xref>), and that accumulation of path integration error degrades performance as a function of trajectory length (<xref ref-type="bibr" rid="bib51">Mirmiran et al., 2022</xref>; <xref ref-type="bibr" rid="bib80">Wallach et al., 2018</xref>). Given the presumed accumulation of error by the mammalian path integration mechanism (<xref ref-type="bibr" rid="bib21">Etienne et al., 1996</xref>), it is generally assumed that proximal and/or distal exogenous cues must calibrate the putative path integrator in order to determine not only target direction but also target distance from a start site (<xref ref-type="bibr" rid="bib48">McNaughton et al., 1996</xref>; <xref ref-type="bibr" rid="bib41">Knierim and Hamilton, 2011</xref>; <xref ref-type="bibr" rid="bib34">Jayakumar et al., 2019</xref>; <xref ref-type="bibr" rid="bib22">Etienne and Jeffery, 2004</xref>). Path integration gain of hippocampal neurons is a plastic variable that can be altered by conflicts between self-motion cues and cues and feedback from landmarks (<xref ref-type="bibr" rid="bib34">Jayakumar et al., 2019</xref>). The independence of the TEV from landmark cues (REL experiments) again demonstrates that, in absence of such ‘conflicts’, self-motion provides consistent cues for path integration and spatial map formation.</p><p>The use of hole checking to compute a mouse’s estimate of the food location allows us to refine these conclusions. The TEV provides not only an estimate of the food location, but also of the distance from start to food site; this is especially clear in the REL experiments where, given the lack of food, a mouse’s search is clearly centered at the expected food location (<xref ref-type="fig" rid="fig5">Figure 5</xref>). Sophisticated analyses have been used to link the spatial coding neurons of entorhinal, subicular and hippocampal neurons to behavioral studies on the interaction of exogenous and self-motion signals (<xref ref-type="bibr" rid="bib49">McNaughton et al., 2006</xref>; <xref ref-type="bibr" rid="bib72">Savelli and Knierim, 2019</xref>). Here, we provide strong behavioral evidence to support the role of hippocampal place cells in encoding the trajectories and food site locations observed in our study. Two studies suggest that, in the rat, CA1 place fields will remain stable in the absence of visual cues. Many place cells responses observed in the presence of visual cues will remain after these cues are removed; the authors conclude that self-motion cues are sufficient to maintain normal place fields (<xref ref-type="bibr" rid="bib15">Chen et al., 2013</xref>). Experiments with blind rats have shown vision is not necessary for the development of normal firing of hippocampal place cells (<xref ref-type="bibr" rid="bib70">Save et al., 1998</xref>). Together, these studies suggest that mice CA1 cells will exhibit place fields in our open maze. Analyses of spatial learning in VR versus RW (rats) suggested that distal visual cues, and self-motion (i.e. proprioceptive, vestibular) cues may be required to activate place cells representing allocentric space. In the absence of distal visual cues, CA1 cells preferentially encoded distance traveled during learned trajectories toward a food goal (<xref ref-type="bibr" rid="bib2">Aghajan et al., 2015</xref>; <xref ref-type="bibr" rid="bib63">Ravassard et al., 2013</xref>).</p><p>Rats can learn to navigate, in VR, from different start locations to a hidden goal using very salient distal visual cues (<xref ref-type="bibr" rid="bib55">Moore et al., 2021</xref>). Unlike RW spatial learning, CA1 pyramidal cells then only weakly encoded allocentric spatial information (place fields) but instead, primarily encoded trajectory distance and head direction – thus, these cells may comprise a possible neural implementation of the behavioral TEV. These experiments demonstrate great flexibility in the hippocampal encoding of trajectories and location both across pyramidal cells and, for individual cells, across the learned trajectory. An important question is how CA1 pyramidal cells will discharge as a mouse runs along the stereotyped trajectories learned with only self-motion cues as in our experiments. A stringent prediction of the discussion above is that mouse CA1 cells activated along trajectories towards the hidden food should be activated at equivalent locations in REL experiments, and in response to the same multiplexed cues: trajectory distance, head direction and allocentric location.</p><p>A subset of hippocampal (CA1) neurons in the bat were reported to encode the direction and/or distance of a hidden goal (<xref ref-type="bibr" rid="bib69">Sarel et al., 2017</xref>). The vectorial representation of goals by such cells could be the substrate of the start-to-food location trajectories we have observed. Recently described CA1 convergence sink (ConSink) place cells (<xref ref-type="bibr" rid="bib60">Ormond and O’Keefe, 2022</xref>) may also have the properties needed to account for the learned start-to-food trajectories we observed. ConSink cells are directional place cells that can encode local direction towards a goal. ConSink cells will, with training, shift their direction tuning to a new goal. The ConSink population vector average, like the TEV, then points directly from start to goal. In both cited studies, landmarks were present, and it is unknown whether such cells will be found in the absence of visual cues.</p><p>ConSink-like cells were reported in the CA1 of a mouse foraging in an open field, but their direction tuning was not pointed towards a singular goal (<xref ref-type="bibr" rid="bib36">Jercog et al., 2019</xref>). We hypothesize that in the pretraining foraging phase of our spatial learning task, ConSink cells will also have random direction tuning. Upon fixed start location training, we hypothesize that the ConSink direction tuning will become aligned with the mouse’s trajectories and their population average will closely approximate the computed behavioral TEV. The TEV and the ConSink cell population average are statistical measures derived from behavioral and electrophysiological data respectively. An important question is whether an explicit TEV is computed and defines the spatial map guiding the mouse’s food-finding trajectories. An equally plausible hypothesis is that the ‘spatial map’ remains a distributed computation in the CA1 targeted neural networks. Experimental tests of these alternatives address an essential question: how is spatial information represented in neural networks?</p><p>Numerous studies have reported that goal sites are overrepresented by CA1 place cells (<xref ref-type="bibr" rid="bib58">Nyberg et al., 2022</xref>). The requirements for such overrepresentation are that there are stereotyped trajectories directed towards an invisible memory-based goal associated with reward (<xref ref-type="bibr" rid="bib58">Nyberg et al., 2022</xref>). The stereotyped trajectories and the hidden memory-based goal of our study imply that these requirements are met. Interestingly, the ‘goal-related place cells’ are activated before the goal is reached (<xref ref-type="bibr" rid="bib58">Nyberg et al., 2022</xref>), just as hole checks mostly occur as the mice approach the food containing hole from any direction (<xref ref-type="fig" rid="fig4">Figure 4F and H</xref>). We hypothesize that, after learning, CA1 place cells will overrepresent the maze region containing the goal location, and that their place fields therefore overlap the hole check sites surrounding the hidden food hole.</p><p>Behavioral time scale plasticity (BTSP) has been proposed to be the cellular mechanism that generates new CA1 place fields at important locations, including those associated with reward (<xref ref-type="bibr" rid="bib9">Bittner et al., 2015</xref>; <xref ref-type="bibr" rid="bib10">Bittner et al., 2017</xref>; <xref ref-type="bibr" rid="bib50">Milstein et al., 2021</xref>). BTSP operates up to a ~3 s time frame. If BTSP is operating during spatial learning in our maze, there will be excessive place fields within the &lt;3 s search time before it finds the food hole. BTSP is bidirectional and can result in CA1 place fields translocating with experience (<xref ref-type="bibr" rid="bib50">Milstein et al., 2021</xref>) and the location of CA1 cell place fields may therefore evolve during static entrance training. We note that the cited experiments were done with virtual movement constrained to 1D and in the presence of landmarks. It remains to be shown whether similar results obtain in our unconstrained 2D maze and with only self-motion cues available.</p><p>The putative emergent CA1 place fields might be randomly distributed but might also be connected with the ‘special’ hole check locations. We plotted the evolution of &lt;3 s from target hole checks in the static and random entrance experiments (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). With spatial learning (static entrance), temporally ‘close to target’ hole checks increase relative to temporally distant hole checks and converge to the target site. Active sensing is critical for electric fish spatial learning (<xref ref-type="bibr" rid="bib20">Engelmann et al., 2021</xref>), and is also known to potentiate or induce CA1 cell place fields (<xref ref-type="bibr" rid="bib54">Monaco et al., 2014</xref>). We hypothesize that the persistent &lt;3 s hole checks near the food site that increase during training will, via the BTSP mechanism, drive the emergence and translocation of CA1 cell place fields so that they accumulate centered on checked holes near the rewarded food site (<xref ref-type="bibr" rid="bib58">Nyberg et al., 2022</xref>). This leads to the prediction that a place cell discharging during a hole check near the food site should also discharge after the mouse start site has been rotated and it checks an empty REL hole.</p></sec><sec id="s3-6"><title>Shortcutting – evidence for a cognitive map derived from self-motion signals</title><p>The O’Keefe and Nadel text (<xref ref-type="bibr" rid="bib59">O’Keefe and Nadel, 1978</xref>) connected hippocampal place cells to the abstract concept of a cognitive map developed by <xref ref-type="bibr" rid="bib77">Tolman, 1948</xref>, and this linkage has been generally supported with few dissenting views (<xref ref-type="bibr" rid="bib6">Bennett, 1996</xref>; <xref ref-type="bibr" rid="bib29">Grieves and Dudchenko, 2013</xref>; <xref ref-type="bibr" rid="bib5">Benhamou, 1996</xref>; <xref ref-type="bibr" rid="bib73">Shamash et al., 2021</xref>). The criteria for a cognitive map are of animals taking unrehearsed shortcuts (<xref ref-type="bibr" rid="bib76">Tolman et al., 1946b</xref>), detours (<xref ref-type="bibr" rid="bib77">Tolman, 1948</xref>) or novel routes (<xref ref-type="bibr" rid="bib56">Morris, 1981</xref>). In this literature, animals typically have both landmark and self-motion cues available for spatial learning. To the best of our knowledge, unrehearsed shortcut behavior using only self-motion cues and a fixed start location has only been shown in humans (<xref ref-type="bibr" rid="bib22">Etienne and Jeffery, 2004</xref>; <xref ref-type="bibr" rid="bib44">Landau et al., 1984</xref>). Our result on shortcutting after spatial learning based entirely on a fixed start location and self-motion cues (<xref ref-type="fig" rid="fig7">Figure 7</xref>) is therefore the first behavioral demonstration of a rodent cognitive map learned without exogenous cues and using the strict Tolman definition. The TEV for the shortcut trajectories well approximates the direct route between the Site B and Site A food locations (<xref ref-type="fig" rid="fig7">Figure 7G and H</xref>) demonstrating the accuracy of the putative cognitive map food location estimate.</p><p>The shortcut trajectory from Site B to Site A (<xref ref-type="fig" rid="fig7">Figure 7G and H</xref>) might be formally computed in two ways. For the three mice that had taken the Site A to Site B route during training, the following vector arithmetic is required for the final probe trial when it went from Site B to Site A:</p><p>where <inline-formula><mml:math id="inf22"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>T</mml:mi><mml:mi>E</mml:mi><mml:mi>V</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>→</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>T</mml:mi><mml:mi>E</mml:mi><mml:mi>V</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>→</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. For the 4 mice that had never taken the Site A to Site B route during training, the following vector arithmetic is required for the final Site B to Site A shortcut:<disp-formula id="equ1"><mml:math id="m1"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>T</mml:mi><mml:mi>E</mml:mi><mml:mi>V</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>B</mml:mi><mml:mo>→</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>T</mml:mi><mml:mi>E</mml:mi><mml:mi>V</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>→</mml:mo><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>T</mml:mi><mml:mi>E</mml:mi><mml:mi>V</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mo>→</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math></disp-formula></p><p>The TEVs for Start→A and Start→B appear to be still remembered by the mice in the probe trial, since the accumulation of hole checks at both sites is still evident (<xref ref-type="fig" rid="fig7">Figure 7H</xref>). The hypothesized ConSink place cells directed to Targets A and B and the accumulation of cells with place fields at both sites will therefore, as described above, still encode the trajectories to each location. To our knowledge, neurons that might compute the required vector arithmetic have not been identified in any part of the rodent brain.</p><p>We hypothesize that the TEVs estimated by neural networks downstream of goal vector cells, CA1 ConSink cells and goal location place field cells will be used to compute the shortcut trajectories. Discovering the networks that do these putative computation(s) may provide insight into the neural bases of the spatial cognitive map.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Animals</title><p>All animals were housed in the University of Ottawa Animal Care and Veterinary Services (ACVS) facility. C57Bl/6 wild-type male and female mice were ordered from Charles River, arriving at 8–9 weeks old. Mice were individually housed in 12 hr light/12 hr dark cycles (lights on at 11:00PM EST, lights off at 11:00AM EST). Animals had had food and water available ad libitum. The temperature of the room was kept at 22.5 °C and the humidity was 40%. Mice were habituated in ACVS facilities for 1 week and began testing when they were 10–11 weeks old. Testing of each cohort took place over the course of approximately 2 weeks, 1 hr after the lights turned off. Subjects weighed 22–27 grams at the start of behavioral training. Both male and female mice were used; the same results were obtained in both sexes and were therefore pooled. All animal procedures were conducted with the approval of the University of Ottawa’s Animal Care Committee and in accordance with guidelines set out by the Canadian Council of Animal Care.</p></sec><sec id="s4-2"><title>Apparatus design and setup</title><p>The Hidden Food Maze (HFM) is a framework that trains mice to search for a food reward hidden in an open, circular arena (<xref ref-type="fig" rid="fig1">Figure 1</xref>). The protocol for the task was inspired by an open maze protocol used to study electric fish spatial learning (<xref ref-type="bibr" rid="bib38">Jun et al., 2016</xref>) and by the Cheese Board spatial task in which rats are placed inside an arena with many holes in the floor, one of which contains a food reward (<xref ref-type="bibr" rid="bib39">Kesner et al., 1991</xref>). Unlike the Kesner et al task, the HFM does not require the animal to be handled, and the pattern of holes is arbitrary rather than grid-like. This task design was also chosen to mirror the setup of the Morris Water Maze (MWM; <xref ref-type="bibr" rid="bib56">Morris, 1981</xref>), which can test allothetic or idiothetic navigation. Like the MWM and the electric fish arena, mice are searching for a food reward location in a circular environment after starting from one of four starting home locations. External landmarks can, if desired, be placed on the maze walls or local cues placed in the maze. In contrast to the MWM, this spatial learning task is a dry maze that is food motivated, which is more naturalistic and less stressful than motivation by the aversion to swimming and fear of drowning. Notably, the task has specific design features to control for against unwanted cues, such as odours, visual cues, and handling.</p><p>The maze has a removable floor that is washed &amp; rotated between trials to eliminate odor trails which mice from previous trials might leave behind. The circular floor is 120 cm in diameter and has 100 holes (1.2 cm diameter) randomly dispersed throughout the surface, with 25 holes in each quadrant. The distance between each hole is, on average, 10 cm. The pattern of the holes is rotationally symmetrical, so the pattern looks the same regardless of whether the floor is rotated 90°, 180°, or 270° with respect to the mouse’s entrance. This ensures that the mouse will have the same initial view of the holes regardless of which entrance it starts from and how the floor is rotated. Each hole is encircled by a 1 cm plastic rib, sticking downwards, which can be capped at the bottom to hold food that remains invisible from the surface. Thus, the mice cannot discern the contents of the hole just by looking across the floor from their home, but instead need to approach the hole and look inside. The surface of the floor is sanded to be matte to avoid generating reflections from the lights which might interfere with the cameras or distract the mice.</p><p>The maze floor is circular and uniform from the inside so as not to provide any directional cues. The floor of the arena is encircled by tall black walls. The walls are made of solid black PVC plastic which forms a cylinder around the maze and is open at the top. The walls are 1 cm thick and 45 cm tall, which is tall enough so the mice cannot jump out. The walls are symmetrical and designed to eliminate geometric cues that would give away directional information from asymmetries in the environment shape. Mice can use odors as landmarks for spatial learning (<xref ref-type="bibr" rid="bib24">Fischler-Ruiz et al., 2021</xref>) and we wanted to eliminate local food odour from a filled hole as a landmark. The arena is resting on a subfloor that contains crumbled food; food odor will diffuse through the open holes and saturate the maze thus masking the odor from a food-filled hole.</p><p>The home cages attach to the main arena by being slotted into each entrance. The home cages are 27cm x 16.5 cm x 45 cm and are open at the top. They contain a food hopper and a water bottle feeder. The dimensions of the home cage are based on commercial mouse cages and comply with the Canadian Council on Animal Care mouse housing standards.</p><p>When moving mice to a different starting quadrant, the home cages are designed to slide out from the maze and into a new entrance so the mice do not need to be handled and will therefore not be stressed. The home cages include their own doors, separate from the doors that provide entry into the maze, so the home cage can be freely moved and the mice remain securely confined. The detachable home cages allow the mice to be moved to different starting locations, allowing us to control against navigational strategies that rely solely on response learning or path-integration from a fixed starting point.</p><p>Mice can perform the entirety of the trial without experimenter handling. The maze doors are designed to slide upwards and provide access to the main arena. When the trial is finished, the experimenter can slide the doors back into place and the mouse is confined to its home cage once again. To not disturb the mice, the doors are left open while they navigate.</p><p>Four LED flashlights were aimed at a white ceiling in order to create dim, diffuse lighting throughout the maze. The illuminance is measured to be 50 lux at the surface of the arena. Dim light was used to allow the mice to properly see all visual cues as well as the maze details. This procedure is assumed to not perturb the nocturnal cycle of mice (<xref ref-type="bibr" rid="bib42">Kronfeld-Schor et al., 2013</xref>; <xref ref-type="bibr" rid="bib79">Upham and Hafner, 2013</xref>). Black curtains surrounded the maze to prevent the interference of non-controlled visual cues.</p><p>We used additional experiments to control for possible visual or odorant cues from the open home door. We did some experiments in total darkness using infrared LEDs with emission spectra detected by our camera. In order to exclude any potential olfactory cues emanating from the open cage door we did experiments where odor absorbent kitty litter was placed on the cage floor and two connected exhaust fans (AC Infinity MULTIFAN S5, Quiet Dual 80 mm USB Fan) placed above the home cage. At their lowest (quiet) setting, the fans drew air from the home cage and blew it to the outside; replacement air from the outside came in via small openings at the bottom of the home cage. The home cage air volume was evacuated 30 times/min, effectively equilibrating the cage and open maze air before the doors were slid upwards. Fans were turned on for 5 min (150 evacuations) before the trial started and for the duration of the trial. After the door was opened, the fans induced negative pressure to eliminate diffusion of odors from the home cage to the maze. The two fans were placed over each home cage and turned on to eliminate a potential directional noise cue.</p></sec><sec id="s4-3"><title>Behavioral training</title><sec id="s4-3-1"><title>Pre-training</title><p>Five days before training, mice are transferred from standard animal facility cages to the experimental home cages for habituation. On the first day, mice are allowed to habituate to their new home cages. On the second day, the door dividing the home cage and the arena is removed and each mouse is given free access to explore the empty arena for 10 min. There are no extra-maze landmarks present during pretraining. Animals are food restricted, with 10% of their body weight in food given back each day which they could consume ad libitum. On day 3, randomly chosen 50% of the holes in the arena are filled with food treats (a piece of Cheerio), and each mouse is given 10 min to forage for food. This is repeated on day 4, where 25% of the arena’s holes are filled with food treats. On day 5, only four holes placed at the maze center contained treats. Mice pass the pre-training stage when they successfully found treats at all locations within 20 min. Mice mostly confined their search to circular trajectories near the wall of the maze for Days 3 and 4 but, after training with food near the maze center (Day 5), they checked holes throughout the maze (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>). Training in the spatial learning task then commenced.</p></sec><sec id="s4-3-2"><title>Visual cues + randomized entrances training</title><p>The mice are trained to locate a food reward that has a fixed relationship with four visual cues on the walls. The protocol mimics classic Morris Water Maze setups to test allocentric landmark-based learning. One of the holes in the area is capped from the bottom with a food-containing insert that is not visible from the surface. Extra-maze landmarks (described in the Visual Cues section) are placed on the walls of the maze to serve as location cues. At the start of the trial, the door is slid upwards so the mice can enter the maze, and the mice are given a maximum of 20 min to find the target hole. The home door is kept open to permit the mice free access to return to their home cage during the trial; preliminary experiments indicated that closing the door perturbed the mice. The door is re-inserted after the mouse has found the food reward and returned home. If the mouse has not returned home by itself after 1 min of finishing the food reward, it is gently guided back by the experimenter. There is an inter-trial interval of approximately 20 min.</p><p>Initial experiments used two trials per day but this was increased to speed up learning; our analyses and graphs are truncated at 14 trials to permit averaging over all the mice. In most experiments, three trials a day were given, over 6 days; at the end of each trial the mouse’s home is moved to a different entrance. The home location was changed for each trial; the floor was washed and rotated by 90°, 180°, or 270° between trials, independent on whether the home entrance was the same (static trials) or rotated (random trials). The location of the entrance is randomized with the following constraints: no two trials in a row have the same entrance, and all entrances are selected the same number of times so there is no bias. On the 7th day, a probe trial is given where the mouse is allowed to search for food in the absence of any food. Learning continues over 1 more day and, on the 9th day, a reversal trial is given where the visual landmarks are rotated by 180°. The location of the home cage is randomized before every trial. In this task, the mouse would have to learn the invariant relation between the food hole and up to four visual cues in order to locate the food.</p></sec><sec id="s4-3-3"><title>Visual cues</title><p>Four black symbols on white backgrounds: a square, a cross, vertical bars, and horizontal bars. The cues are taped 5 cm above the floor. The square was 15 by 15 cm. The cross consisted of two 2.5 cm wide and 14 cm long bars. The four vertical and four horizontal bars were 2.5 cm wide and 14 cm long. Previous behavioral studies have shown that mice can discriminate the visual stimuli we use (<xref ref-type="bibr" rid="bib33">Jacobs et al., 2009</xref>; <xref ref-type="bibr" rid="bib62">Prusky and Douglas, 2004</xref>; <xref ref-type="bibr" rid="bib61">Prusky et al., 2000</xref>). Recording of neurons in mouse V1 have additionally shown that orientation selective cells in mice visual cortex can discriminate our visual stimuli (<xref ref-type="bibr" rid="bib45">Long et al., 2015</xref>).</p></sec><sec id="s4-3-4"><title>Visual cues + static entrance training</title><p>This protocol allows mice to navigate by potentially using visual cues in cooperation with path integration or by path integration alone. The setup is the same as visual cues training, except mice enter from the same entrance each trial instead of a randomized entrance. Mice are considered well trained once their latency learning curve has plateaued for three successive trials. The mice’s latencies had plateaued by 14 trials but training continued till 18 trials.</p><p>After 18 trials, reversal trials were done with no food present and the mouse’s home cage rotated 180°. The mouse was allowed to search for food for 10 min. If the mice were able to learn the invariant landmark/food spatial relationship, we would expect them to search at the learned food site. If they had used path integration of self-motion cues to navigate from the fixed entrance to the food, we would expect them to search at the rotationally equivalent location (REL).</p></sec><sec id="s4-3-5"><title>Rotationally equivalent location (REL)</title><p>The four quadrants of the arena’s floor are identical. This means that the position of the holes in the second quadrant (Q2, <xref ref-type="fig" rid="fig1">Figure 1B</xref>; also <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3A</xref>) is equal to the position of the holes in the first quadrant (Q1) rotated by 90°Counter clockwise (CCW) about the center of the arena. Q3 is Q1 rotated by 180<sup>o</sup> (CCW) and Q4 is Q1 rotated by –90<sup>o</sup> (i.e. 90°CW). In other words, every hole in Q1 has an REL in each quadrant achieved by the respective rotation. The REL target works in the same way: it is the position (relative to the entrance used in the trial) where the food would have been had the mouse been trained from the entrance it used in the trial. To illustrate this, consider <xref ref-type="fig" rid="fig1">Figure 1D</xref>: we put the food (target) in a particular hole in Q1 for a mouse that is trained to enter from Q2 (such as the example in <xref ref-type="fig" rid="fig1">Figure 1B</xref>) in the static entrance protocol. The vector that points from the mouse’s start point (in Q2) to the target in Q1 (i.e. the target vector) is ‘anchored’ to the start position at Q2. For example, in the mouse’s perspective, the target vector is equivalent to going forward for 70 cm, and then turn left and follow for another 30 cm. If in a probe trial, we now let the mouse enter from Q4 instead, there are two options: either the mouse uses the landmarks and searches for the food in Q1 (where the food actually used to be), or it follows the target vector (70 cm forward +30 cm left) and goes to the REL location of the target in Q3. Following the target vector is a sign of path integration using self-motion signals (idiothetic cues).</p></sec></sec><sec id="s4-4"><title>Control experiments</title><sec id="s4-4-1"><title>Rotations following static entrances – with and without visual cues</title><p>We performed additional tests for the use of visual landmarks in the Visual Cues + Static Entrance protocol. Well-trained mice had their home cages rotated to another quadrant and tested on how well they found the food from a new starting location. Mice were rotated 180°, 90°, and then –90° with respect to their original location (<xref ref-type="fig" rid="fig5">Figure 5A, B and C</xref>). Mice were given six consecutive trials at each new location. One control group of mice had the visual cues on the arena wall removed during rotation training. If mice were able to use visual cues, we would expect them to improve their search efficiency when visual cues were available. Lack of improvement or similar performance compared to the control group without visual cues suggests that the mice do not rely on the type of visual cues we provided for spatial learning and navigation.</p></sec><sec id="s4-4-2"><title>Navigating and training without visual cues and in darkness</title><p>To control for the effects of all visual information, one cohort (four mice) was trained and tested without any cues (<xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5A and B</xref>). A second cohort (four mice) was trained in the light according to the Visual Cues +Static Entrance protocol, then the lights are turned off and the mice are given a trial in darkness (<xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5C and D</xref>). The lights were opened in between trials so the mice did not acclimatize to the darkness. Mice were tracked using infrared LEDs with emission spectra detected by our camera. The following conditions were tested: darkness during a regular trial with food present in the arena and during a probe trial where there is no food present in the arena; both conditions gave the same results.</p><p>We additionally both trained and tested a cohort (four mice) in darkness and with control of potential odors. A recent study has shown that placing sighted mice in darkness impairs entorhinal cortex head direction cell tuning (<xref ref-type="bibr" rid="bib3">Asumbisa et al., 2022</xref>), but here the mice successfully learned to find food and with the same time course of learning (<xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5E and F</xref>).</p></sec><sec id="s4-4-3"><title>Two food location training</title><p>This protocol aims to test flexibility of spatial learning using only path integration (N=8 mice). No visual cues are placed on the arena walls. Mice entered the arena from the same entrance each trial. Food was placed in a target well in ‘Target A’ and mice were trained to find this location for 18 trials, 3 trials a day. A probe trial (‘Probe A’) was done after trial 18. For trials 19–26, the food was moved to a different location, ‘Target B’, and mice are trained to find the new location. We were careful to choose Target B so that Target A and B were not symmetric with respect to the mouse’s entrance. A second probe trial (‘Probe B-A’) was done after trial 26. The purpose of the ‘Probe B-A’ trial is to check whether mice take a shortcut between B (latest learned target position) and A (first learned target position). For some cohorts, the training continued until trial 34 and a third probe was given.</p></sec><sec id="s4-4-4"><title>Two food location training with rotated probe</title><p>The mice (N=8) were trained exactly as in the ‘Two food location’ experiment described above. However, the mice start location was rotated by 180<sup>o</sup> prior to the second probe trial. This protocol joins the ‘Static entrances with rotated probe’ protocol with the ‘Two food location protocol’, and is designed to provide further support for our path integration hypothesis. Each of the trained targets have their REL counterparts (180<sup>o</sup> rotated around the center of the arena). Now, the purpose of the rotated ‘Probe B-A’ trial is to check which of the two options will happen: either mice take shortcuts between B (latest learned target position) and A (first learned target position); or they take shortcuts between REL B and REL A, supporting path integration via self-motion cues.</p></sec></sec><sec id="s4-5"><title>Behavioral analysis</title><p>Path tracking was done with Ethovision XT15 (Noldus) based on contrast detection. Mice were tracked according to 3 body points at 30 frames per second on a 1080 P USB camera with OV2710 CMOS. Videos were first recorded on AMCap webcam recording software and imported into Ethovision in order to preserve high quality videos. Trajectory plotting was done in Python.</p><p>Latency to target was calculated from when the nose point of the mouse enters the arena until the nose of the mouse enters the target hole. Trajectory analyses are based on the nose point sequence of the mouse. Speed and distance were calculated based on trajectory coordinates exported from Ethovision.</p><p>Search bias during probe trials is calculated by totalling the time a mouse spent within a 30x30 cm square centered around the target vs. the RELs in the other 3 quadrants during a 2-min trial (<xref ref-type="fig" rid="fig2">Figure 2C</xref>, <xref ref-type="fig" rid="fig3">Figure 3C</xref>).</p></sec><sec id="s4-6"><title>Statistical tests</title><p>Significance testing was conducted in a manner that was appropriate for each dataset. Paired comparisons utilized the t-test for parametric data and the Wilcoxon signed-rank test for non-parametric data. The significance cut-off was set at 0.05. Statistics were calculated either using R (URL <ext-link ext-link-type="uri" xlink:href="http://www.R-project.org/">http://www.R-project.org/</ext-link>) or scipy 1.8.0 in python 3.8.2. The statistical significance testing of the trajectory directionality analysis was developed from first principles, since it involves angular variables (the direction of each vector). It is presented in the ‘Analysis of trajectories’ section ahead.</p><p>Figures showing a quantity evolution over trials <xref ref-type="fig" rid="fig2">Figure 2D–I</xref>; <xref ref-type="fig" rid="fig3">Figure 3D–I</xref>; <xref ref-type="fig" rid="fig4">Figure 4I</xref>; <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref> have symbols as averages, error bars as standard error, and the shading around the curve corresponds to the full data range (lower and upper shading limits correspond to minimum and maximum sampled data points, respectively).</p><p>Boxplot figures <xref ref-type="fig" rid="fig4">Figure 4J and K</xref>; <xref ref-type="fig" rid="fig6">Figure 6E–H</xref>; <xref ref-type="fig" rid="fig7">Figure 7I and J</xref> have the diamond symbol as the average, the thick black line as the median, the box covering the interquartile range (IQR), and the whiskers extend from the box limits to ± 1.5 IQR in both directions. No outliers were detected in any of these plots.</p></sec><sec id="s4-7"><title>Randomized trials</title><p>For the Two Food Location experiment, we calculated a randomized version of the Probe B-A trial for comparison. It consisted of extracting ten random pieces of the trajectory. Each piece was defined by randomly selecting a pair of points in the trial trajectory that are separated by the B to A distance. Then, the particular quantity of interest was averaged over each piece of the trajectory, and these averages were then averaged to obtain a single value for the ‘Probe B-A Rand’. condition in <xref ref-type="fig" rid="fig6">Figures 6</xref> and <xref ref-type="fig" rid="fig7">7</xref>. See <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref> for a definition of the quantities.</p></sec><sec id="s4-8"><title>Statistical analysis of trajectories</title><sec id="s4-8-1"><title>Experiment alignment</title><p>The procedure described in this section is applied to calculate trajectory directionality (and hence the target estimation vector, TEV) and the hole checking spatial distributions. Each mouse in the Random Entrance experiment started from a different quadrant of the arena, for each consecutive trial, and the target was fixed relative to the arena (global reference frame). However, in order to increase sampling, we need to coherently align the mice entrances, generating the mouse’s perspective reference frame (see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B–F</xref>). Each experiment batch was performed with four mice, such that at any given trial, a given mouse entered from quadrant 1 (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C</xref>), another entered from quadrant 2 (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1D</xref>), the next entered from quadrant 3 (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1E</xref>), and the last entered the arena from quadrant 4 (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1F</xref>). Most of the experiments, then, consisted of two different batches of four mice that had to be conveniently aligned to increase sampling. In this figure, we aligned all the entrances to the Start point at the top of the arena (trajectories were rotated accordingly), emphasizing the four possible positions of the target from the mouse’s perspective.</p><p>We had to find a way to align all the targets in a given trial to one of the four possible positions, such that the experiment stays coherent over trials (i.e. the target randomly switches in between these four positions from trial to trial). For example, in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B–F</xref>, we show trial 14. The target position for each starting quadrant is labeled with a red letter A and a red circle, whereas the target for the previous trial is labeled with a green circle and a green letter A subscripted with ‘trial 13’. These two positions (trial and previous trial) must always be different to keep the random characteristic of the experiment.</p><p>Notice that the target positions in each of the panels D, E, and F in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> are simply rotated relative to the target positions in panel C. The target configuration in panel D is 90°Clockwise rotated relative to the target configuration in panel C. The configuration in panel E is 180°Clockwise rotated, and panel F, 270°Clockwise rotated; both angles are relative to the configuration in panel C. Thus, in order to sample all the mice together, we simply rotate the trajectories from the mice that started in quadrant 2 [panel D] counter-clockwise by 90<sup>o</sup>; the trajectories from the mice that started in quadrant 3 [panel E] are rotated by 180°Counter-clockwise; and the trajectories starting from quadrant 4 [panel F] are rotated by 270°Counter-clockwise. This reduces all the experiments to the first quadrant, allowing us to sample all the trajectories of all the mice together in each individual trial.</p></sec><sec id="s4-8-2"><title>Active sensing and hole-check detection</title><p>We developed an algorithm to detect the mouse’s behavior of sniffing holes to detect food as a measure of active sensing. The hole checking events are used to infer the mouse’s memory and uncertainty about its environment. The procedure described here is applied independently to each trial. We compute the spatial distribution <inline-formula><mml:math id="inf23"><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> for the count of hole checks for each hole <inline-formula><mml:math id="inf24"><mml:mi>i</mml:mi></mml:math></inline-formula> positioned in <inline-formula><mml:math id="inf25"><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> in the arena, accumulated across all mice in a given experiment (<xref ref-type="fig" rid="fig4">Figure 4C, D, G and H</xref>; <xref ref-type="fig" rid="fig5">Figure 5C</xref>; <xref ref-type="fig" rid="fig7">Figure 7B, E, F and H</xref>; <xref ref-type="fig" rid="fig8">Figure 8C</xref>; and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B–F</xref>; usually N=8 mice for each experiment), and normalized by the total count. The frequency of checks in each hole is coded both in the color and size of the filled circles: larger and darker shaded circles correspond to larger number of checks in that particular hole (lighter shaded pink small circles are a small number of checks). The black ellipsis marks the covariance of the <inline-formula><mml:math id="inf26"><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> spatial distribution (‘x’ in the figures marking the mean position of hole checks). It is constructed from the eigenvalues and eigenvectors of the covariance matrix <inline-formula><mml:math id="inf27"><mml:mi>C</mml:mi></mml:math></inline-formula> of the hole check coordinates <inline-formula><mml:math id="inf28"><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> weighted by <inline-formula><mml:math id="inf29"><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula>: the eigenvectors give the directions of the ellipsis semi-axes, whereas the eigenvalues give the width of each semi-axes. The center of the ellipsis (mean of the ellipsis’ foci) is aligned with the mean of the spatial distribution.</p><p>Under the path integration hypothesis, it is expected that error accumulates as the mouse walks (<xref ref-type="bibr" rid="bib49">McNaughton et al., 2006</xref>). This is consistent with the increase in number of hole checks per unit area near the target (<xref ref-type="fig" rid="fig4">Figure 4J and K</xref>; ‘near’ = less than 20 cm away from the target). We consider that the change in number of hole checks measures the variability of the mouse’s estimate of the target position.</p><p>We therefore calculate the mean and covariance of the distribution of hole check events restricted to within 20 cm of the target (again, the green ‘x’=mean). The distance from the start to this restricted mean is used to scale the TEV vector (see Target Estimation Vector).</p><p>The arena design forces the mouse to put its nose very close to the hole to be able to see the food or detect any food odour. With that in mind, we defined two methods for detecting a hole check (see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A and B</xref>, and the Shortcut video <xref ref-type="video" rid="video1">Video 1</xref>). The two methods are complementary, and the second can find hole-check events missed by the first method: we apply the first method, then perform a visual check on the data to see if there were potential hole-checks that were missed. Then, we apply the second method to capture any remaining events.</p><p>The first method is the minimum velocity criterion and provides a high threshold for hole check identification. Four conditions must be satisfied simultaneously to detect an event: (i) the nose of the mouse must be within 3 cm of an arena hole; (ii) the velocity has to be less than 20% its maximum value; (iii) the velocity must be at a minimum; and (iv) the velocity has to have dropped by at least 5 cm/s to reach that minimum.</p><p>The second method is more inclusive and defines a hole-checking event by a simple slowing down event, provided that: the nose is within 3 cm of an arena hole, and the slowing down is enough for the velocity to drop past the 20% threshold of its maximum.</p><p>The detected events by the application of these two methods in sequence are marked for all trajectory samples of the Probe B-A in as examples. A particular case is shown in more details in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, and in the Shortcut video (<xref ref-type="video" rid="video1">Video 1</xref>) with the recording of a mouse’s performance. It is worth mentioning, there is a clear hole-check missed by our algorithm in the 25–27 s range. This is because the velocity of the mouse was already below the 20% maximum before and after the hole check, hence the two sets of criteria defined above were not met for this particular event and it was counted by the manual check. Otherwise, we clearly see that all the other events are captured by sequential use our two methods.</p></sec><sec id="s4-8-3"><title>Trajectory directionality (displacement map)</title><p>This analysis is a way to visualize mouse trajectories and directionality across all the mice for each trial. It is related to a velocity map of the arena, except that here, the arrows point in the direction of most probable movement instead of the direction of the velocity. <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1B</xref> shows a scheme for how we compute this map, and we detail it below. We call this quantity as the ‘displacement map’, since it gives the displacement of the mouse for each position in the arena.</p><p>In this section, we explain how to calculate the displacement map for a single sample of <inline-formula><mml:math id="inf30"><mml:mi>N</mml:mi></mml:math></inline-formula> mice. The procedure here is applied to each individual trial independently (either during learning, or for a probe trial). This map is used for inferring the learned directionality of the target (relative to entrance). The error, average and significance of this quantity is estimated from first principles by a jackknife procedure explained in the next section. In the figures we show the average displacement map vectors that were found to be significant. These maps are then used to compute the target estimation vector (TEV; detailed in the last section).</p><p>We start by overlaying a lattice of size <inline-formula><mml:math id="inf31"><mml:mi>L</mml:mi></mml:math></inline-formula> on top of the arena recording. This means that there are <inline-formula><mml:math id="inf32"><mml:mi>L</mml:mi></mml:math></inline-formula> boxes on the <inline-formula><mml:math id="inf33"><mml:mi>x</mml:mi></mml:math></inline-formula> (horizontal) direction, and <inline-formula><mml:math id="inf34"><mml:mi>L</mml:mi></mml:math></inline-formula> boxes on the <inline-formula><mml:math id="inf35"><mml:mi>y</mml:mi></mml:math></inline-formula> (vertical) direction, making a total of <inline-formula><mml:math id="inf36"><mml:msup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> boxes in the lattice. Each box defines a lattice site with coordinates <inline-formula><mml:math id="inf37"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, such that <inline-formula><mml:math id="inf38"><mml:mi>x</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf39"><mml:mi>y</mml:mi></mml:math></inline-formula> are integers between 1 and <inline-formula><mml:math id="inf40"><mml:mi>L</mml:mi></mml:math></inline-formula>. Each mouse corresponds to an independent observation of a trajectory, so we overlay all mice trajectories for each trial separately in the calculations below. Next, we map the coordinates of the trajectories into the lattice coordinates in order to obtain a temporal sequence of visited lattice sites in each trial. We are interested in counting the number of times that each subsequent pair of adjacent lattice sites appears in this sequence, regardless of what mouse it came from. This will be used to define the displacement map, detailed in what follows.</p><p>The displacement map <inline-formula><mml:math id="inf41"><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is a vector field defined on the lattice that assigns to each site the preferential direction of movement. This direction is estimated from the trajectories data. Mathematically, it can be written as <inline-formula><mml:math id="inf42"><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:math></inline-formula>, where <inline-formula><mml:math id="inf43"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the horizontal component and <inline-formula><mml:math id="inf44"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the vertical component. The horizontal component expresses the trend to move to the left or right (along the lattice <inline-formula><mml:math id="inf45"><mml:mi>x</mml:mi></mml:math></inline-formula>-axis), and the vertical component in the perpendicular direction, that is ‘up’ or ‘down’ in the top view of the lattice of <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1D</xref> (along the lattice <inline-formula><mml:math id="inf46"><mml:mi>y</mml:mi></mml:math></inline-formula>-axis). Each component is a function of the lattice coordinates, <inline-formula><mml:math id="inf47"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>. The vector <inline-formula><mml:math id="inf48"><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:math></inline-formula> is defined as the spatial gradient of the probabilities to move out of <inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> towards one of its adjacent sites. Thus, its components are given by<disp-formula id="equ2"><label>(1)</label><mml:math id="m2"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">←</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>v</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">↑</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">↓</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is the probability of stepping right, that is from <inline-formula><mml:math id="inf51"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> to <inline-formula><mml:math id="inf52"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>; <inline-formula><mml:math id="inf53"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>←</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is the probability of stepping left [from <inline-formula><mml:math id="inf54"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> to <inline-formula><mml:math id="inf55"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>]; <inline-formula><mml:math id="inf56"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>↑</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is the probability of stepping up [from <inline-formula><mml:math id="inf57"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> to <inline-formula><mml:math id="inf58"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula>]; and <inline-formula><mml:math id="inf59"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>↓</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is the probability of stepping down [from <inline-formula><mml:math id="inf60"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> to <inline-formula><mml:math id="inf61"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula>]. The probabilities of stepping out of <inline-formula><mml:math id="inf62"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> must be normalized, therefore <inline-formula><mml:math id="inf63"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>→</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>←</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>↑</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>↓</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>. If there is no trajectory going through a particular site, the probability of going from that site into each of the directions is equal to the ‘null’ probability, <inline-formula><mml:math id="inf64"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. Time sequences where the mouse does not move are ignored, since we are only interested in the movement between adjacent sites.</p><p>The stepping-out probabilities are computed from the mouse trajectory in the following way. This procedure is applied to all mice overlayed together in each individual trial. First, a step is defined as moving from a box at <inline-formula><mml:math id="inf65"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> to one of its four adjacent boxes, say the one on the right <inline-formula><mml:math id="inf66"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>. Now, if we wanted to calculate the probability of going right from a position <inline-formula><mml:math id="inf67"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, we need to go through the sequence of visited lattice sites looking for <inline-formula><mml:math id="inf68"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> in an instant followed by <inline-formula><mml:math id="inf69"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> in the immediately next instant. We count the number of times <inline-formula><mml:math id="inf70"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mo>→</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> that this pair appears. The count of the transitions of <inline-formula><mml:math id="inf71"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> to <inline-formula><mml:math id="inf72"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, in this example, is made regardless of when these transitions happened during the trajectory. The only condition is that the position <inline-formula><mml:math id="inf73"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> must be immediately followed by <inline-formula><mml:math id="inf74"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>. The same counting is made for the transitions from <inline-formula><mml:math id="inf75"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> to <inline-formula><mml:math id="inf76"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> and stored in <inline-formula><mml:math id="inf77"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mo>←</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, from <inline-formula><mml:math id="inf78"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> to <inline-formula><mml:math id="inf79"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula> in <inline-formula><mml:math id="inf80"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mo>↑</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, and from <inline-formula><mml:math id="inf81"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> to <inline-formula><mml:math id="inf82"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula> in <inline-formula><mml:math id="inf83"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mo>↓</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>.</p><p>With these sums of steps performed, we can calculate the probability of stepping right, left, up, or down. First, note that initially the chance of going to any direction is <inline-formula><mml:math id="inf84"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, assuming we know nothing about the trajectories. Now, given that we observed <inline-formula><mml:math id="inf85"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mo>→</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> steps going to the right, we need to update the chance of going to the right using the union (i.e. sum) of the observed chance <inline-formula><mml:math id="inf86"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mo>→</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="inf87"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, where <inline-formula><mml:math id="inf88"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the total number of steps counted toward any direction in all lattice sites in a given trial:<disp-formula id="equ3"><label>(2)</label><mml:math id="m3"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf89"><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mo>→</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is the direction weight of the action ‘step to the right from <inline-formula><mml:math id="inf90"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>’. Alternatively, this can be written as a weighted sum of memory-driven stepping with probability 1 and random stepping with probability <inline-formula><mml:math id="inf91"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>:<disp-formula id="equ4"><mml:math id="m4"><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mo>→</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mo>→</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mo>→</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math></disp-formula></p><p>We employ <xref ref-type="disp-formula" rid="equ3">Equation 2</xref> because the mouse could, in principle, have chosen any of the other three directions. This ensures that every time the memory is increased (adding <inline-formula><mml:math id="inf92"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mo>→</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> to the weight), the random contribution for that step decreases; this justifies the last term in <xref ref-type="disp-formula" rid="equ3">Equation 2</xref>, where the intersection between the memory term and the ‘null’ probability, <inline-formula><mml:math id="inf93"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mo>→</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, is subtracted from the aforementioned union. One can easily see that the formula guarantees that the null probability is automatically recovered, that is <inline-formula><mml:math id="inf94"><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mo>→</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , when there are zero observed steps in a given direction at position <inline-formula><mml:math id="inf95"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, and that <inline-formula><mml:math id="inf96"><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mo>→</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> if all steps are to the right at position <inline-formula><mml:math id="inf97"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>.</p><p>Finally, we use these weights to calculate the probabilities, first defining the total weight of stepping out of <inline-formula><mml:math id="inf98"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>,<disp-formula id="equ5"><label>(3)</label><mml:math id="m5"><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mo>→</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mo>←</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mo>↑</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mo>↓</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math></disp-formula></p><p>and then calculating the probabilities by<disp-formula id="equ6"><label>(4)</label><mml:math id="m6"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="false">→</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The same is made for the other directions (left, up and down). <xref ref-type="disp-formula" rid="equ6">Equation 4</xref> ensures that the probability of stepping out of <inline-formula><mml:math id="inf99"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is always normalized. This is then applied to <xref ref-type="disp-formula" rid="equ2">Equation 1</xref> to obtain the displacement map.</p><p>Let us go through the simple example shown in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1C–F</xref>. In this case, the accumulated trajectories in the center box located at <inline-formula><mml:math id="inf100"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mn>3,3</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula> are such that there are two passes going up and one pass going down. Thus, each direction has the following weight [given by <xref ref-type="disp-formula" rid="equ3">Equation 2</xref>]: <inline-formula><mml:math id="inf101"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mo stretchy="false">↑</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>2</mml:mn><mml:mn>3</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mn>2</mml:mn><mml:mn>3</mml:mn></mml:mfrac><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>3</mml:mn><mml:mn>4</mml:mn></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf102"><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mo>↓</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>3,3</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:math></inline-formula>, and <inline-formula><mml:math id="inf103"><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mo>→</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>3,3</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mo>←</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>3,3</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:mfrac></mml:math></inline-formula>. Applying <xref ref-type="disp-formula" rid="equ6">Equation 4</xref>, we obtain the probabilities <inline-formula><mml:math id="inf104"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>↑</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>3,3</mml:mn></mml:mrow></mml:mfenced><mml:mo>≈</mml:mo><mml:mn>0.43</mml:mn></mml:math></inline-formula>, <inline-formula><mml:math id="inf105"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>↓</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>3,3</mml:mn></mml:mrow></mml:mfenced><mml:mo>≈</mml:mo><mml:mn>0.29</mml:mn></mml:math></inline-formula>, and <inline-formula><mml:math id="inf106"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>→</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>3,3</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mo>←</mml:mo></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mn>3,3</mml:mn></mml:mrow></mml:mfenced><mml:mo>≈</mml:mo><mml:mn>0.14</mml:mn></mml:math></inline-formula>. This results in a step map vector <inline-formula><mml:math id="inf107"><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover><mml:mfenced separators="|"><mml:mrow><mml:mn>3,3</mml:mn></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfenced open="[" close="]" separators="|"><mml:mrow><mml:mn>0,0.14</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula>. This vector represents the preferred direction of movement out of site <inline-formula><mml:math id="inf108"><mml:mfenced separators="|"><mml:mrow><mml:mn>3,3</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula>, meaning the mice are likely to pass in the vertical direction, going from bottom to top (hence a positive vertical quantity); and are not picky regarding left or right (hence a null horizontal quantity).</p><p>The trajectories of the mice obey box-scaling independently of trial or experimental condition. Box- scaling is a standard method to measure the dimensionality of curves, and is described in <xref ref-type="bibr" rid="bib23">Falconer, 2004</xref>. In other words, the number of boxes needed to cover any trajectory scales linearly with the lattice dimension <inline-formula><mml:math id="inf109"><mml:mi>L</mml:mi></mml:math></inline-formula>; see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1F</xref>. This means that the choice of <inline-formula><mml:math id="inf110"><mml:mi>L</mml:mi></mml:math></inline-formula> is somewhat arbitrary, and we chose <inline-formula><mml:math id="inf111"><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>11</mml:mn></mml:math></inline-formula> to make each box the size of a few centimeters as expected for the size of a place field from a DG cell (<xref ref-type="bibr" rid="bib28">GoodSmith et al., 2017</xref>).</p></sec><sec id="s4-8-4"><title>Trajectory directionality statistical significance</title><p>The method above gives a single displacement map <inline-formula><mml:math id="inf112"><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> and enables the calculation of the TEV <inline-formula><mml:math id="inf113"><mml:mover accent="true"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:math></inline-formula> (see below) for each trial of an experiment containing <inline-formula><mml:math id="inf114"><mml:mi>N</mml:mi></mml:math></inline-formula> mice. We have to generate multiple samples for the same experiment using different mice to estimate the significance of the mean displacement direction calculation. We employ a jackknife procedure to achieve this goal. It consists of the ‘leave one out’ rule: this means that a sample of <inline-formula><mml:math id="inf115"><mml:mi>N</mml:mi></mml:math></inline-formula> mice give <inline-formula><mml:math id="inf116"><mml:mi>N</mml:mi></mml:math></inline-formula> unique jackknife samples, each of which containing <inline-formula><mml:math id="inf117"><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> unique mice. Then, we get <inline-formula><mml:math id="inf118"><mml:mi>N</mml:mi></mml:math></inline-formula> estimates <inline-formula><mml:math id="inf119"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, with <inline-formula><mml:math id="inf120"><mml:mi>k</mml:mi></mml:math></inline-formula> from 1 to <inline-formula><mml:math id="inf121"><mml:mi>N</mml:mi></mml:math></inline-formula>, by applying the previously described procedure to each jackknife sample of <inline-formula><mml:math id="inf122"><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> mice (instead of the whole sample). Finally, we calculate the average, <inline-formula><mml:math id="inf123"><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula> for the displacement map. This is the vector map that we show as small arrows colored from blue to red (<xref ref-type="fig" rid="fig4">Figure 4A, B, E and F</xref>; <xref ref-type="fig" rid="fig5">Figure 5C</xref>; <xref ref-type="fig" rid="fig7">Figure 7A, C, D and G</xref>; <xref ref-type="fig" rid="fig8">Figure 8C</xref>; and ; we only show statistically significant averages).</p><p>The statistical significance of the average <inline-formula><mml:math id="inf124"><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> map in each lattice position <inline-formula><mml:math id="inf125"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is built from first principles as follows (see <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). The main feature of each of the vectors in this map is its direction (i.e. the angle it makes with the positive x-axis). Strong directionality means that the vectors <inline-formula><mml:math id="inf126"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> all pointed roughly in the same direction (i.e. roughly same angles), whereas weak directionality means uniformly distributed angles around the circle (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2A and B</xref>). The stronger the directionality of the sample <inline-formula><mml:math id="inf127"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> the more significant the average <inline-formula><mml:math id="inf128"><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>. A simple measure of the spread of the angles (i.e. the directionality strength) is the standard deviation (S.D.) of the sample angles that <inline-formula><mml:math id="inf129"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> make with the positive x-axis: stronger directionality implies a smaller S.D. (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2C</xref>). Thus, the significance (<inline-formula><mml:math id="inf130"><mml:mi>p</mml:mi></mml:math></inline-formula>) of directionality is how likely it is for a sample of <inline-formula><mml:math id="inf131"><mml:mi>N</mml:mi></mml:math></inline-formula> uniformly distributed angles to display a given S.D. value collectively.</p><p>The S.D. of <inline-formula><mml:math id="inf132"><mml:mi>N</mml:mi></mml:math></inline-formula> angles (with zero average) is <inline-formula><mml:math id="inf133"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msubsup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:msqrt></mml:math></inline-formula>, where the <inline-formula><mml:math id="inf134"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are uniformly distributed from –180<sup>o</sup> to 180<sup>o</sup>. If we could determine the probability density function <inline-formula><mml:math id="inf135"><mml:mi>ρ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, then the significance would be given by <xref ref-type="bibr" rid="bib30">Hair et al., 2013</xref> <inline-formula><mml:math id="inf136"><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>S</mml:mi><mml:mo>.</mml:mo><mml:mi>D</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mo stretchy="false">∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mo>.</mml:mo><mml:mi>D</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msubsup><mml:mrow><mml:mi>ρ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mfenced><mml:mi>d</mml:mi><mml:mi>σ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, which is the probability of observing a given S.D. from the sample. In other words, <inline-formula><mml:math id="inf137"><mml:mi>p</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>S</mml:mi><mml:mo>.</mml:mo><mml:mi>D</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mfenced></mml:math></inline-formula> is the probability that an observed S.D. came from a set of <inline-formula><mml:math id="inf138"><mml:mi>N</mml:mi></mml:math></inline-formula> uniformly distributed angles with zero mean. Thus, given an experimental observation S.D. from the jackknife sample, we will know what is the probability <inline-formula><mml:math id="inf139"><mml:mi>p</mml:mi></mml:math></inline-formula> that the angles from the sample were uniformly distributed in the circle (i.e. have weak directionality). A small <inline-formula><mml:math id="inf140"><mml:mi>p</mml:mi></mml:math></inline-formula> value, therefore, indicates strong directionality (since having small S.D. is very unlikely for uniformly distributed angles – <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2D</xref>).</p><p>We need to estimate <inline-formula><mml:math id="inf141"><mml:mi>ρ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> to be able to calculate <inline-formula><mml:math id="inf142"><mml:mi>p</mml:mi></mml:math></inline-formula> for any S.D. Although it has an integral representation similar to the Chi distribution (<xref ref-type="bibr" rid="bib78">Tomé and Oliveira, 2015</xref>), it is easier to make a numerical estimation: we fix, for instance, <inline-formula><mml:math id="inf143"><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>8</mml:mn></mml:math></inline-formula> (since we have 8 jackknife samples) and generate 10,000 independent <inline-formula><mml:math id="inf144"><mml:mi>σ</mml:mi></mml:math></inline-formula> values applying the S.D. formula above to <inline-formula><mml:math id="inf145"><mml:mi>N</mml:mi></mml:math></inline-formula> independent uniform angles <inline-formula><mml:math id="inf146"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> from –180<sup>o</sup> to 180<sup>o</sup>. The normalized histogram of all the observed <inline-formula><mml:math id="inf147"><mml:mi>σ</mml:mi></mml:math></inline-formula> is a good estimate of <inline-formula><mml:math id="inf148"><mml:mi>ρ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2D</xref>). The <inline-formula><mml:math id="inf149"><mml:mi>p</mml:mi></mml:math></inline-formula> value is obtained by numerically integrating <inline-formula><mml:math id="inf150"><mml:mi>ρ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> from 0 to the observed S.D. value (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2E</xref>).</p><p>Now, it suffices to calculate the S.D. of the angles of the vectors <inline-formula><mml:math id="inf151"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> in the jackknife sample (unbiased to make the average vector <inline-formula><mml:math id="inf152"><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> have <inline-formula><mml:math id="inf153"><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula>). An observed <italic>S.D</italic>.=30°Corresponds to p=10<sup>–4</sup> (i.e. the sample has very strong directionality). We only show in the figures the displacement vectors that have <italic>S.D</italic>.≤5<sup>o</sup>, yielding vanishing p&lt;10<sup>–7</sup> (all vectors regardless of significance are shown in for comparison for random and static entrance experiments). Comparing to <xref ref-type="fig" rid="fig4">Figure 4</xref>, we notice that, as expected, only vectors from trials that are supposed to have random directionality vanish (i.e. trials for random entrance experiments, and trial 1 for static entrance). The vectors in strongly directed flow trials (such as trial 14 in static entrance experiments) remain. The same happens for the two-food location experiment.</p></sec><sec id="s4-8-5"><title>Target Estimation Vector (TEV)</title><p>The target estimation vector (TEV) is an estimate of the position of the target based only on the observed trajectories and hole checks of the mice. We write the average TEV as <inline-formula><mml:math id="inf154"><mml:mover accent="true"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf155"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the TEV for a particular jackknife sample <inline-formula><mml:math id="inf156"><mml:mi>k</mml:mi></mml:math></inline-formula>. The magnitude <inline-formula><mml:math id="inf157"><mml:mi>D</mml:mi></mml:math></inline-formula> is inferred from the hole checks and the direction <inline-formula><mml:math id="inf158"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is calculated from the displacement map <inline-formula><mml:math id="inf159"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> as follows. The total sum of the displacement map <inline-formula><mml:math id="inf160"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> over all arena sites <inline-formula><mml:math id="inf161"><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> gives the estimate of the learned direction <inline-formula><mml:math id="inf162"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>, with <inline-formula><mml:math id="inf163"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mo stretchy="false">∑</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>. The magnitude <inline-formula><mml:math id="inf164"><mml:mi>D</mml:mi></mml:math></inline-formula> is the distance from start to the average of the hole check distribution restricted to 20 cm around the target (i.e. <inline-formula><mml:math id="inf165"><mml:mi>D</mml:mi></mml:math></inline-formula> is the distance from the start to the ‘x’ in the green ellipsis in <xref ref-type="fig" rid="fig4">Figure 4G and H</xref>; <xref ref-type="fig" rid="fig5">Figure 5C</xref>; <xref ref-type="fig" rid="fig7">Figure 7B, F and H</xref>; <xref ref-type="fig" rid="fig8">Figure 8C</xref>; and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B–F</xref>). In the case of the Probe B-A trial, we use <inline-formula><mml:math id="inf166"><mml:mi>D</mml:mi></mml:math></inline-formula> as the distance from B (instead of ‘start’) to the restricted average of the hole check distribution around target A. In trials where no preferred direction is detected (such as in the random entrances experiment, or in the first trial after switching from target A to B), the magnitude <inline-formula><mml:math id="inf167"><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math></inline-formula> is already roughly the distance from start to the arena’s center (expressing the randomness in the displacement map), and hence we take the TEV to be just <inline-formula><mml:math id="inf168"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> instead.</p><p>The error in the magnitude <inline-formula><mml:math id="inf169"><mml:mi>D</mml:mi></mml:math></inline-formula> of the TEV is obtained from the covariance matrix <inline-formula><mml:math id="inf170"><mml:mi>C</mml:mi></mml:math></inline-formula> of the spatial distribution of hole checks restricted to less than 20 cm of the target. It is given by <inline-formula><mml:math id="inf171"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:msqrt></mml:math></inline-formula>, where <inline-formula><mml:math id="inf172"><mml:msub><mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mrow><mml:mn>1,2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> are the eigenvalues of <inline-formula><mml:math id="inf173"><mml:mi>C</mml:mi></mml:math></inline-formula>. In the plots [<xref ref-type="fig" rid="fig4">Figures 4</xref>, <xref ref-type="fig" rid="fig5">5</xref>, <xref ref-type="fig" rid="fig7">7</xref> and <xref ref-type="fig" rid="fig8">8</xref>], we simply represent the covariance matrix by the green ellipses in the same way we do for the uncensored distribution (see Active sensing and hole-check detection). The error in the direction of <inline-formula><mml:math id="inf174"><mml:mover accent="true"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:math></inline-formula> is simply the S.D. of the angles of <inline-formula><mml:math id="inf175"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> with respect to the positive x-axis (calculated by shifting <inline-formula><mml:math id="inf176"><mml:mover accent="true"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:math></inline-formula> to 0<sup>o</sup>, and making the angles of <inline-formula><mml:math id="inf177"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mo>→</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> between –180<sup>o</sup> and 180<sup>o</sup>, similarly to what is done for the displacement map). This gives the pink shaded circular sector accompanying the TEV in the figures of the displacement maps and the error bars in the TEV-target deviation plot (<xref ref-type="fig" rid="fig4">Figures 4I</xref> and <xref ref-type="fig" rid="fig7">7I</xref>).</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Investigation, Methodology, Writing - original draft</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Software, Formal analysis, Visualization, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Writing - original draft</p></fn><fn fn-type="con" id="con4"><p>Formal analysis, Writing - original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Formal analysis, Supervision, Funding acquisition, Validation, Visualization, Methodology, Writing - original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All animal procedures were conducted with the approval of the University of Ottawa's Animal Care Committee and in accordance with guidelines set out by the Canadian Council of Animal Care.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-95764-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All data generated and analyzed data in this study is included in this manuscript. All codes and raw data sets are available in <ext-link ext-link-type="uri" xlink:href="https://github.com/neuro-physics/mouse-cogmap">https://github.com/neuro-physics/mouse-cogmap</ext-link> (copy archived at <xref ref-type="bibr" rid="bib26">Girardi Schappo, 2024</xref>).</p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Dr. Érik Harvey-Girard for technical support, and William Moldenhauer de Jesus for joining the short cut experiment video with the hole check data. This work was supported by the Canadian Institutes for Health Research Grant # 153143 to AL and LM and J-C B, a Brockhouse award (493076–2017) to AL and LM, an NSERC award (RGPIN/06204–2014) to AL, an NSERC award to LM (RGPIN/2017-147489-2017) and a grant from the Krembil Foundation to AL, LM and J-C B.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Acharya</surname><given-names>L</given-names></name><name><surname>Aghajan</surname><given-names>ZM</given-names></name><name><surname>Vuong</surname><given-names>C</given-names></name><name><surname>Moore</surname><given-names>JJ</given-names></name><name><surname>Mehta</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Causal influence of visual cues on hippocampal directional selectivity</article-title><source>Cell</source><volume>164</volume><fpage>197</fpage><lpage>207</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2015.12.015</pub-id><pub-id pub-id-type="pmid">26709045</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aghajan</surname><given-names>ZM</given-names></name><name><surname>Acharya</surname><given-names>L</given-names></name><name><surname>Moore</surname><given-names>JJ</given-names></name><name><surname>Cushman</surname><given-names>JD</given-names></name><name><surname>Vuong</surname><given-names>C</given-names></name><name><surname>Mehta</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Impaired spatial selectivity and intact phase precession in two-dimensional virtual reality</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>121</fpage><lpage>128</lpage><pub-id pub-id-type="doi">10.1038/nn.3884</pub-id><pub-id pub-id-type="pmid">25420065</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Asumbisa</surname><given-names>K</given-names></name><name><surname>Peyrache</surname><given-names>A</given-names></name><name><surname>Trenholm</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Flexible cue anchoring strategies enable stable head direction coding in both sighted and blind animals</article-title><source>Nature Communications</source><volume>13</volume><elocation-id>5483</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-022-33204-0</pub-id><pub-id pub-id-type="pmid">36123333</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Banino</surname><given-names>A</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Uria</surname><given-names>B</given-names></name><name><surname>Blundell</surname><given-names>C</given-names></name><name><surname>Lillicrap</surname><given-names>T</given-names></name><name><surname>Mirowski</surname><given-names>P</given-names></name><name><surname>Pritzel</surname><given-names>A</given-names></name><name><surname>Chadwick</surname><given-names>MJ</given-names></name><name><surname>Degris</surname><given-names>T</given-names></name><name><surname>Modayil</surname><given-names>J</given-names></name><name><surname>Wayne</surname><given-names>G</given-names></name><name><surname>Soyer</surname><given-names>H</given-names></name><name><surname>Viola</surname><given-names>F</given-names></name><name><surname>Zhang</surname><given-names>B</given-names></name><name><surname>Goroshin</surname><given-names>R</given-names></name><name><surname>Rabinowitz</surname><given-names>N</given-names></name><name><surname>Pascanu</surname><given-names>R</given-names></name><name><surname>Beattie</surname><given-names>C</given-names></name><name><surname>Petersen</surname><given-names>S</given-names></name><name><surname>Sadik</surname><given-names>A</given-names></name><name><surname>Gaffney</surname><given-names>S</given-names></name><name><surname>King</surname><given-names>H</given-names></name><name><surname>Kavukcuoglu</surname><given-names>K</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Hadsell</surname><given-names>R</given-names></name><name><surname>Kumaran</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Vector-based navigation using grid-like representations in artificial agents</article-title><source>Nature</source><volume>557</volume><fpage>429</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0102-6</pub-id><pub-id pub-id-type="pmid">29743670</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benhamou</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>No evidence for cognitive mapping in rats</article-title><source>Animal Behaviour</source><volume>52</volume><fpage>201</fpage><lpage>212</lpage><pub-id pub-id-type="doi">10.1006/anbe.1996.0165</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bennett</surname><given-names>AT</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Do animals have cognitive maps?</article-title><source>The Journal of Experimental Biology</source><volume>199</volume><fpage>219</fpage><lpage>224</lpage><pub-id pub-id-type="doi">10.1242/jeb.199.1.219</pub-id><pub-id pub-id-type="pmid">8576693</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Biegler</surname><given-names>R</given-names></name><name><surname>Morris</surname><given-names>RG</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Landmark stability is a prerequisite for spatial but not discrimination learning</article-title><source>Nature</source><volume>361</volume><fpage>631</fpage><lpage>633</lpage><pub-id pub-id-type="doi">10.1038/361631a0</pub-id><pub-id pub-id-type="pmid">8437622</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Biegler</surname><given-names>R</given-names></name><name><surname>Morris</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Landmark stability: studies exploring whether the perceived stability of the environment influences spatial representation</article-title><source>The Journal of Experimental Biology</source><volume>199</volume><fpage>187</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1242/jeb.199.1.187</pub-id><pub-id pub-id-type="pmid">9317604</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bittner</surname><given-names>KC</given-names></name><name><surname>Grienberger</surname><given-names>C</given-names></name><name><surname>Vaidya</surname><given-names>SP</given-names></name><name><surname>Milstein</surname><given-names>AD</given-names></name><name><surname>Macklin</surname><given-names>JJ</given-names></name><name><surname>Suh</surname><given-names>J</given-names></name><name><surname>Tonegawa</surname><given-names>S</given-names></name><name><surname>Magee</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Conjunctive input processing drives feature selectivity in hippocampal CA1 neurons</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1133</fpage><lpage>1142</lpage><pub-id pub-id-type="doi">10.1038/nn.4062</pub-id><pub-id pub-id-type="pmid">26167906</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bittner</surname><given-names>KC</given-names></name><name><surname>Milstein</surname><given-names>AD</given-names></name><name><surname>Grienberger</surname><given-names>C</given-names></name><name><surname>Romani</surname><given-names>S</given-names></name><name><surname>Magee</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Behavioral time scale synaptic plasticity underlies CA1 place fields</article-title><source>Science</source><volume>357</volume><fpage>1033</fpage><lpage>1036</lpage><pub-id pub-id-type="doi">10.1126/science.aan3846</pub-id><pub-id pub-id-type="pmid">28883072</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Spatial memory: how egocentric and allocentric combine</article-title><source>Trends in Cognitive Sciences</source><volume>10</volume><fpage>551</fpage><lpage>557</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2006.10.005</pub-id><pub-id pub-id-type="pmid">17071127</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burlingham</surname><given-names>CS</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Heading perception depends on time-varying evolution of optic flow</article-title><source>PNAS</source><volume>117</volume><fpage>33161</fpage><lpage>33169</lpage><pub-id pub-id-type="doi">10.1073/pnas.2022984117</pub-id><pub-id pub-id-type="pmid">33328275</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chan</surname><given-names>E</given-names></name><name><surname>Baumann</surname><given-names>O</given-names></name><name><surname>Bellgrove</surname><given-names>MA</given-names></name><name><surname>Mattingley</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>From objects to landmarks: the function of visual location information in spatial navigation</article-title><source>Frontiers in Psychology</source><volume>3</volume><elocation-id>304</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2012.00304</pub-id><pub-id pub-id-type="pmid">22969737</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chapillon</surname><given-names>P</given-names></name><name><surname>Roullet</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Use of proximal and distal cues in place navigation by mice changes during ontogeny</article-title><source>Developmental Psychobiology</source><volume>29</volume><fpage>529</fpage><lpage>545</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1098-2302(199609)29:6&lt;529::AID-DEV5&gt;3.0.CO;2-O</pub-id><pub-id pub-id-type="pmid">8872426</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>King</surname><given-names>JA</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>How vision and movement combine in the hippocampal place code</article-title><source>PNAS</source><volume>110</volume><fpage>378</fpage><lpage>383</lpage><pub-id pub-id-type="doi">10.1073/pnas.1215834110</pub-id><pub-id pub-id-type="pmid">23256159</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Collett</surname><given-names>TS</given-names></name><name><surname>Cartwright</surname><given-names>BA</given-names></name><name><surname>Smith</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Landmark learning and visuo-spatial memories in gerbils</article-title><source>Journal of Comparative Physiology. A, Sensory, Neural, and Behavioral Physiology</source><volume>158</volume><fpage>835</fpage><lpage>851</lpage><pub-id pub-id-type="doi">10.1007/BF01324825</pub-id><pub-id pub-id-type="pmid">3735168</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cullen</surname><given-names>KE</given-names></name><name><surname>Taube</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Our sense of direction: progress, controversies and challenges</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1465</fpage><lpage>1473</lpage><pub-id pub-id-type="doi">10.1038/nn.4658</pub-id><pub-id pub-id-type="pmid">29073639</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cullen</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Vestibular processing during natural self-motion: implications for perception and action</article-title><source>Nature Reviews. Neuroscience</source><volume>20</volume><fpage>346</fpage><lpage>363</lpage><pub-id pub-id-type="doi">10.1038/s41583-019-0153-1</pub-id><pub-id pub-id-type="pmid">30914780</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cushman</surname><given-names>JD</given-names></name><name><surname>Aharoni</surname><given-names>DB</given-names></name><name><surname>Willers</surname><given-names>B</given-names></name><name><surname>Ravassard</surname><given-names>P</given-names></name><name><surname>Kees</surname><given-names>A</given-names></name><name><surname>Vuong</surname><given-names>C</given-names></name><name><surname>Popeney</surname><given-names>B</given-names></name><name><surname>Arisaka</surname><given-names>K</given-names></name><name><surname>Mehta</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Multisensory control of multimodal behavior: do the legs know what the tongue is doing?</article-title><source>PLOS ONE</source><volume>8</volume><elocation-id>e80465</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0080465</pub-id><pub-id pub-id-type="pmid">24224054</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engelmann</surname><given-names>J</given-names></name><name><surname>Wallach</surname><given-names>A</given-names></name><name><surname>Maler</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Linking active sensing and spatial learning in weakly electric fish</article-title><source>Current Opinion in Neurobiology</source><volume>71</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2021.07.002</pub-id><pub-id pub-id-type="pmid">34392168</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Etienne</surname><given-names>AS</given-names></name><name><surname>Maurer</surname><given-names>R</given-names></name><name><surname>Séguinot</surname><given-names>V</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Path integration in mammals and its interaction with visual landmarks</article-title><source>The Journal of Experimental Biology</source><volume>199</volume><fpage>201</fpage><lpage>209</lpage><pub-id pub-id-type="doi">10.1242/jeb.199.1.201</pub-id><pub-id pub-id-type="pmid">8576691</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Etienne</surname><given-names>AS</given-names></name><name><surname>Jeffery</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Path integration in mammals</article-title><source>Hippocampus</source><volume>14</volume><fpage>180</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1002/hipo.10173</pub-id><pub-id pub-id-type="pmid">15098724</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Falconer</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2004">2004</year><source>Fractal geometry: mathematical foundations and application</source><publisher-name>John Wiley and Sons</publisher-name><pub-id pub-id-type="doi">10.1002/0470013850</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischler-Ruiz</surname><given-names>W</given-names></name><name><surname>Clark</surname><given-names>DG</given-names></name><name><surname>Joshi</surname><given-names>NR</given-names></name><name><surname>Devi-Chou</surname><given-names>V</given-names></name><name><surname>Kitch</surname><given-names>L</given-names></name><name><surname>Schnitzer</surname><given-names>M</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Axel</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Olfactory landmarks and path integration converge to form a cognitive spatial map</article-title><source>Neuron</source><volume>109</volume><fpage>4036</fpage><lpage>4049</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.09.055</pub-id><pub-id pub-id-type="pmid">34710366</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fonio</surname><given-names>E</given-names></name><name><surname>Benjamini</surname><given-names>Y</given-names></name><name><surname>Golani</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Freedom of movement and the stability of its unfolding in free exploration of mice</article-title><source>PNAS</source><volume>106</volume><fpage>21335</fpage><lpage>21340</lpage><pub-id pub-id-type="doi">10.1073/pnas.0812513106</pub-id><pub-id pub-id-type="pmid">19934049</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Girardi Schappo</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Mouse-cogmap</data-title><version designator="swh:1:rev:553c98fc0d49b5f8747e7603fa3e30f0a77486e2">swh:1:rev:553c98fc0d49b5f8747e7603fa3e30f0a77486e2</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:272ea6b4a5f20dfdc240b75ee76180473f4027b7;origin=https://github.com/neuro-physics/mouse-cogmap;visit=swh:1:snp:d2489ee458bad96c23c431693259da547f11974c;anchor=swh:1:rev:553c98fc0d49b5f8747e7603fa3e30f0a77486e2">https://archive.softwareheritage.org/swh:1:dir:272ea6b4a5f20dfdc240b75ee76180473f4027b7;origin=https://github.com/neuro-physics/mouse-cogmap;visit=swh:1:snp:d2489ee458bad96c23c431693259da547f11974c;anchor=swh:1:rev:553c98fc0d49b5f8747e7603fa3e30f0a77486e2</ext-link></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodman</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Place vs. response learning: history, controversy, and neurobiology</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>14</volume><elocation-id>598570</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2020.598570</pub-id><pub-id pub-id-type="pmid">33643005</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>GoodSmith</surname><given-names>D</given-names></name><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Kim</surname><given-names>SH</given-names></name><name><surname>Song</surname><given-names>H</given-names></name><name><surname>Burgalossi</surname><given-names>A</given-names></name><name><surname>Christian</surname><given-names>KM</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Spatial representations of granule cells and mossy cells of the dentate gyrus</article-title><source>Neuron</source><volume>93</volume><fpage>677</fpage><lpage>690</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.12.026</pub-id><pub-id pub-id-type="pmid">28132828</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grieves</surname><given-names>RM</given-names></name><name><surname>Dudchenko</surname><given-names>PA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cognitive maps and spatial inference in animals: Rats fail to take a novel shortcut, but can take a previously experienced one</article-title><source>Learning and Motivation</source><volume>44</volume><fpage>81</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1016/j.lmot.2012.08.001</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hair</surname><given-names>JF</given-names></name><name><surname>Black</surname><given-names>WC</given-names></name><name><surname>Babin</surname><given-names>BJ</given-names></name><name><surname>Anderson</surname><given-names>RE</given-names></name></person-group><year iso-8601-date="2013">2013</year><source>Multivariate Data Analysis</source><publisher-name>Udmey</publisher-name></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hébert</surname><given-names>M</given-names></name><name><surname>Bulla</surname><given-names>J</given-names></name><name><surname>Vivien</surname><given-names>D</given-names></name><name><surname>Agin</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Are distal and proximal visual cues equally important during spatial learning in mice? a pilot study of overshadowing in the spatial domain</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>11</volume><elocation-id>109</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2017.00109</pub-id><pub-id pub-id-type="pmid">28634446</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horrocks</surname><given-names>EAB</given-names></name><name><surname>Mareschal</surname><given-names>I</given-names></name><name><surname>Saleem</surname><given-names>AB</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Walking humans and running mice: perception and neural encoding of optic flow during self-motion</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>378</volume><elocation-id>20210450</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2021.0450</pub-id><pub-id pub-id-type="pmid">36511417</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacobs</surname><given-names>AL</given-names></name><name><surname>Fridman</surname><given-names>G</given-names></name><name><surname>Douglas</surname><given-names>RM</given-names></name><name><surname>Alam</surname><given-names>NM</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Prusky</surname><given-names>GT</given-names></name><name><surname>Nirenberg</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Ruling out and ruling in neural codes</article-title><source>PNAS</source><volume>106</volume><fpage>5936</fpage><lpage>5941</lpage><pub-id pub-id-type="doi">10.1073/pnas.0900573106</pub-id><pub-id pub-id-type="pmid">19297621</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jayakumar</surname><given-names>RP</given-names></name><name><surname>Madhav</surname><given-names>MS</given-names></name><name><surname>Savelli</surname><given-names>F</given-names></name><name><surname>Blair</surname><given-names>HT</given-names></name><name><surname>Cowan</surname><given-names>NJ</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Recalibration of path integration in hippocampal place cells</article-title><source>Nature</source><volume>566</volume><fpage>533</fpage><lpage>537</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-0939-3</pub-id><pub-id pub-id-type="pmid">30742074</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jeffery</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Learning of landmark stability and instability by hippocampal place cells</article-title><source>Neuropharmacology</source><volume>37</volume><fpage>677</fpage><lpage>687</lpage><pub-id pub-id-type="doi">10.1016/s0028-3908(98)00053-7</pub-id><pub-id pub-id-type="pmid">9705005</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jercog</surname><given-names>PE</given-names></name><name><surname>Ahmadian</surname><given-names>Y</given-names></name><name><surname>Woodruff</surname><given-names>C</given-names></name><name><surname>Deb-Sen</surname><given-names>R</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Kandel</surname><given-names>ER</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Heading direction with respect to a reference point modulates place-cell activity</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>2333</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-10139-7</pub-id><pub-id pub-id-type="pmid">31133685</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jun</surname><given-names>JJ</given-names></name><name><surname>Longtin</surname><given-names>A</given-names></name><name><surname>Maler</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Enhanced sensory sampling precedes self-initiated locomotion in an electric fish</article-title><source>The Journal of Experimental Biology</source><volume>217</volume><fpage>3615</fpage><lpage>3628</lpage><pub-id pub-id-type="doi">10.1242/jeb.105502</pub-id><pub-id pub-id-type="pmid">25320268</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jun</surname><given-names>JJ</given-names></name><name><surname>Longtin</surname><given-names>A</given-names></name><name><surname>Maler</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Active sensing associated with spatial learning reveals memory-based attention in an electric fish</article-title><source>Journal of Neurophysiology</source><volume>115</volume><fpage>2577</fpage><lpage>2592</lpage><pub-id pub-id-type="doi">10.1152/jn.00979.2015</pub-id><pub-id pub-id-type="pmid">26961107</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kesner</surname><given-names>RP</given-names></name><name><surname>Farnsworth</surname><given-names>G</given-names></name><name><surname>Kametani</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Role of parietal cortex and hippocampus in representing spatial information</article-title><source>Cerebral Cortex</source><volume>1</volume><fpage>367</fpage><lpage>373</lpage><pub-id pub-id-type="doi">10.1093/cercor/1.5.367</pub-id><pub-id pub-id-type="pmid">1822746</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knierim</surname><given-names>JJ</given-names></name><name><surname>Kudrimoti</surname><given-names>HS</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Place cells, head direction cells, and the learning of landmark stability</article-title><source>The Journal of Neuroscience</source><volume>15</volume><fpage>1648</fpage><lpage>1659</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.15-03-01648.1995</pub-id><pub-id pub-id-type="pmid">7891125</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knierim</surname><given-names>JJ</given-names></name><name><surname>Hamilton</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Framing spatial cognition: neural representations of proximal and distal frames of reference and their roles in navigation</article-title><source>Physiological Reviews</source><volume>91</volume><fpage>1245</fpage><lpage>1279</lpage><pub-id pub-id-type="doi">10.1152/physrev.00021.2010</pub-id><pub-id pub-id-type="pmid">22013211</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kronfeld-Schor</surname><given-names>N</given-names></name><name><surname>Dominoni</surname><given-names>D</given-names></name><name><surname>de la Iglesia</surname><given-names>H</given-names></name><name><surname>Levy</surname><given-names>O</given-names></name><name><surname>Herzog</surname><given-names>ED</given-names></name><name><surname>Dayan</surname><given-names>T</given-names></name><name><surname>Helfrich-Forster</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Chronobiology by moonlight</article-title><source>Proceedings. Biological Sciences</source><volume>280</volume><elocation-id>20123088</elocation-id><pub-id pub-id-type="doi">10.1098/rspb.2012.3088</pub-id><pub-id pub-id-type="pmid">23825199</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lai</surname><given-names>AT</given-names></name><name><surname>Espinosa</surname><given-names>G</given-names></name><name><surname>Wink</surname><given-names>GE</given-names></name><name><surname>Angeloni</surname><given-names>CF</given-names></name><name><surname>Dombeck</surname><given-names>DA</given-names></name><name><surname>MacIver</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>A robot-rodent interaction arena with adjustable spatial complexity for ethologically relevant behavioral studies</article-title><source>Cell Reports</source><volume>43</volume><elocation-id>113671</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2023.113671</pub-id><pub-id pub-id-type="pmid">38280195</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Landau</surname><given-names>B</given-names></name><name><surname>Spelke</surname><given-names>E</given-names></name><name><surname>Gleitman</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Spatial knowledge in a young blind child</article-title><source>Cognition</source><volume>16</volume><fpage>225</fpage><lpage>260</lpage><pub-id pub-id-type="doi">10.1016/0010-0277(84)90029-5</pub-id><pub-id pub-id-type="pmid">6541105</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Long</surname><given-names>M</given-names></name><name><surname>Jiang</surname><given-names>W</given-names></name><name><surname>Liu</surname><given-names>D</given-names></name><name><surname>Yao</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Contrast-dependent orientation discrimination in the mouse</article-title><source>Scientific Reports</source><volume>5</volume><elocation-id>15830</elocation-id><pub-id pub-id-type="doi">10.1038/srep15830</pub-id><pub-id pub-id-type="pmid">26510881</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Madhav</surname><given-names>MS</given-names></name><name><surname>Jayakumar</surname><given-names>RP</given-names></name><name><surname>Li</surname><given-names>BY</given-names></name><name><surname>Lashkari</surname><given-names>SG</given-names></name><name><surname>Wright</surname><given-names>K</given-names></name><name><surname>Savelli</surname><given-names>F</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name><name><surname>Cowan</surname><given-names>NJ</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Control and recalibration of path integration in place cells using optic flow</article-title><source>Nature Neuroscience</source><volume>27</volume><fpage>1599</fpage><lpage>1608</lpage><pub-id pub-id-type="doi">10.1038/s41593-024-01681-9</pub-id><pub-id pub-id-type="pmid">38937582</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mao</surname><given-names>D</given-names></name><name><surname>Molina</surname><given-names>LA</given-names></name><name><surname>Bonin</surname><given-names>V</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Vision and locomotion combine to drive path integration sequences in mouse retrosplenial cortex</article-title><source>Current Biology</source><volume>30</volume><fpage>1680</fpage><lpage>1688</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2020.02.070</pub-id><pub-id pub-id-type="pmid">32197086</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Barnes</surname><given-names>CA</given-names></name><name><surname>Gerrard</surname><given-names>JL</given-names></name><name><surname>Gothard</surname><given-names>K</given-names></name><name><surname>Jung</surname><given-names>MW</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name><name><surname>Kudrimoti</surname><given-names>H</given-names></name><name><surname>Qin</surname><given-names>Y</given-names></name><name><surname>Skaggs</surname><given-names>WE</given-names></name><name><surname>Suster</surname><given-names>M</given-names></name><name><surname>Weaver</surname><given-names>KL</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Deciphering the hippocampal polyglot: the hippocampus as a path integration system</article-title><source>The Journal of Experimental Biology</source><volume>199</volume><fpage>173</fpage><lpage>185</lpage><pub-id pub-id-type="doi">10.1242/jeb.199.1.173</pub-id><pub-id pub-id-type="pmid">8576689</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Battaglia</surname><given-names>FP</given-names></name><name><surname>Jensen</surname><given-names>O</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Path integration and the neural basis of the “cognitive map.”</article-title><source>Nature Reviews. Neuroscience</source><volume>7</volume><fpage>663</fpage><lpage>678</lpage><pub-id pub-id-type="doi">10.1038/nrn1932</pub-id><pub-id pub-id-type="pmid">16858394</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Milstein</surname><given-names>AD</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Bittner</surname><given-names>KC</given-names></name><name><surname>Grienberger</surname><given-names>C</given-names></name><name><surname>Soltesz</surname><given-names>I</given-names></name><name><surname>Magee</surname><given-names>JC</given-names></name><name><surname>Romani</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Bidirectional synaptic plasticity rapidly modifies hippocampal representations</article-title><source>eLife</source><volume>10</volume><elocation-id>e73046</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.73046</pub-id><pub-id pub-id-type="pmid">34882093</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mirmiran</surname><given-names>C</given-names></name><name><surname>Fraser</surname><given-names>M</given-names></name><name><surname>Maler</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Finding food in the dark: how trajectories of a gymnotiform fish change with spatial learning</article-title><source>The Journal of Experimental Biology</source><volume>225</volume><elocation-id>jeb244590</elocation-id><pub-id pub-id-type="doi">10.1242/jeb.244590</pub-id><pub-id pub-id-type="pmid">36366924</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mittelstaedt</surname><given-names>ML</given-names></name><name><surname>Mittelstaedt</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Homing by path integration in a mammal</article-title><source>Naturwissenschaften</source><volume>67</volume><fpage>566</fpage><lpage>567</lpage><pub-id pub-id-type="doi">10.1007/BF00450672</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mohammadi</surname><given-names>M</given-names></name><name><surname>Carriot</surname><given-names>J</given-names></name><name><surname>Mackrous</surname><given-names>I</given-names></name><name><surname>Cullen</surname><given-names>KE</given-names></name><name><surname>Chacron</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Neural populations within macaque early vestibular pathways are adapted to encode natural self-motion</article-title><source>PLOS Biology</source><volume>22</volume><elocation-id>e3002623</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3002623</pub-id><pub-id pub-id-type="pmid">38687807</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Monaco</surname><given-names>JD</given-names></name><name><surname>Rao</surname><given-names>G</given-names></name><name><surname>Roth</surname><given-names>ED</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Attentive scanning behavior drives one-trial potentiation of hippocampal place fields</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>725</fpage><lpage>731</lpage><pub-id pub-id-type="doi">10.1038/nn.3687</pub-id><pub-id pub-id-type="pmid">24686786</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moore</surname><given-names>JJ</given-names></name><name><surname>Cushman</surname><given-names>JD</given-names></name><name><surname>Acharya</surname><given-names>L</given-names></name><name><surname>Popeney</surname><given-names>B</given-names></name><name><surname>Mehta</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Linking hippocampal multiplexed tuning, Hebbian plasticity and navigation</article-title><source>Nature</source><volume>599</volume><fpage>442</fpage><lpage>448</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-03989-z</pub-id><pub-id pub-id-type="pmid">34671157</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morris</surname><given-names>RGM</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Spatial localization does not require the presence of local cues</article-title><source>Learning and Motivation</source><volume>12</volume><fpage>239</fpage><lpage>260</lpage><pub-id pub-id-type="doi">10.1016/0023-9690(81)90020-5</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muller</surname><given-names>RU</given-names></name><name><surname>Kubie</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>The effects of changes in the environment on the spatial firing of hippocampal complex-spike cells</article-title><source>The Journal of Neuroscience</source><volume>7</volume><fpage>1951</fpage><lpage>1968</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.07-07-01951.1987</pub-id><pub-id pub-id-type="pmid">3612226</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nyberg</surname><given-names>N</given-names></name><name><surname>Duvelle</surname><given-names>É</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Spiers</surname><given-names>HJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Spatial goal coding in the hippocampal formation</article-title><source>Neuron</source><volume>110</volume><fpage>394</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.12.012</pub-id><pub-id pub-id-type="pmid">35032426</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1978">1978</year><source>The Hippocampus as a Cognitive Map</source><publisher-loc>Oxford, UK</publisher-loc><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ormond</surname><given-names>J</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Hippocampal place cells have goal-oriented vector fields during navigation</article-title><source>Nature</source><volume>607</volume><fpage>741</fpage><lpage>746</lpage><pub-id pub-id-type="doi">10.1038/s41586-022-04913-9</pub-id><pub-id pub-id-type="pmid">35794477</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prusky</surname><given-names>GT</given-names></name><name><surname>West</surname><given-names>PW</given-names></name><name><surname>Douglas</surname><given-names>RM</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Behavioral assessment of visual acuity in mice and rats</article-title><source>Vision Research</source><volume>40</volume><fpage>2201</fpage><lpage>2209</lpage><pub-id pub-id-type="doi">10.1016/s0042-6989(00)00081-x</pub-id><pub-id pub-id-type="pmid">10878281</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prusky</surname><given-names>GT</given-names></name><name><surname>Douglas</surname><given-names>RM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Characterization of mouse cortical spatial vision</article-title><source>Vision Research</source><volume>44</volume><fpage>3411</fpage><lpage>3418</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2004.09.001</pub-id><pub-id pub-id-type="pmid">15536009</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ravassard</surname><given-names>P</given-names></name><name><surname>Kees</surname><given-names>A</given-names></name><name><surname>Willers</surname><given-names>B</given-names></name><name><surname>Ho</surname><given-names>D</given-names></name><name><surname>Aharoni</surname><given-names>DA</given-names></name><name><surname>Cushman</surname><given-names>J</given-names></name><name><surname>Aghajan</surname><given-names>ZM</given-names></name><name><surname>Mehta</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Multisensory control of hippocampal spatiotemporal selectivity</article-title><source>Science</source><volume>340</volume><fpage>1342</fpage><lpage>1346</lpage><pub-id pub-id-type="doi">10.1126/science.1232655</pub-id><pub-id pub-id-type="pmid">23641063</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rogers</surname><given-names>J</given-names></name><name><surname>Churilov</surname><given-names>L</given-names></name><name><surname>Hannan</surname><given-names>AJ</given-names></name><name><surname>Renoir</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Search strategy selection in the Morris water maze indicates allocentric map formation during learning that underpins spatial memory formation</article-title><source>Neurobiology of Learning and Memory</source><volume>139</volume><fpage>37</fpage><lpage>49</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2016.12.007</pub-id><pub-id pub-id-type="pmid">27988312</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenberg</surname><given-names>M</given-names></name><name><surname>Zhang</surname><given-names>T</given-names></name><name><surname>Perona</surname><given-names>P</given-names></name><name><surname>Meister</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Mice in a labyrinth show rapid learning, sudden insight, and efficient exploration</article-title><source>eLife</source><volume>10</volume><elocation-id>e66175</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.66175</pub-id><pub-id pub-id-type="pmid">34196271</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saleem</surname><given-names>AB</given-names></name><name><surname>Diamanti</surname><given-names>EM</given-names></name><name><surname>Fournier</surname><given-names>J</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Coherent encoding of subjective spatial position in visual cortex and hippocampus</article-title><source>Nature</source><volume>562</volume><fpage>124</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0516-1</pub-id><pub-id pub-id-type="pmid">30202092</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saleem</surname><given-names>AB</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Two stream hypothesis of visual processing for navigation in mouse</article-title><source>Current Opinion in Neurobiology</source><volume>64</volume><fpage>70</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2020.03.009</pub-id><pub-id pub-id-type="pmid">32294570</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saleem</surname><given-names>AB</given-names></name><name><surname>Busse</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Interactions between rodent visual and spatial systems during navigation</article-title><source>Nature Reviews. Neuroscience</source><volume>24</volume><fpage>487</fpage><lpage>501</lpage><pub-id pub-id-type="doi">10.1038/s41583-023-00716-7</pub-id><pub-id pub-id-type="pmid">37380885</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sarel</surname><given-names>A</given-names></name><name><surname>Finkelstein</surname><given-names>A</given-names></name><name><surname>Las</surname><given-names>L</given-names></name><name><surname>Ulanovsky</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Vectorial representation of spatial goals in the hippocampus of bats</article-title><source>Science</source><volume>355</volume><fpage>176</fpage><lpage>180</lpage><pub-id pub-id-type="doi">10.1126/science.aak9589</pub-id><pub-id pub-id-type="pmid">28082589</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Save</surname><given-names>E</given-names></name><name><surname>Cressant</surname><given-names>A</given-names></name><name><surname>Thinus-Blanc</surname><given-names>C</given-names></name><name><surname>Poucet</surname><given-names>B</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Spatial firing of hippocampal place cells in blind rats</article-title><source>The Journal of Neuroscience</source><volume>18</volume><fpage>1818</fpage><lpage>1826</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.18-05-01818.1998</pub-id><pub-id pub-id-type="pmid">9465006</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Save</surname><given-names>E</given-names></name><name><surname>Nerad</surname><given-names>L</given-names></name><name><surname>Poucet</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Contribution of multiple sensory information to place field stability in hippocampal place cells</article-title><source>Hippocampus</source><volume>10</volume><fpage>64</fpage><lpage>76</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1098-1063(2000)10:1&lt;64::AID-HIPO7&gt;3.0.CO;2-Y</pub-id><pub-id pub-id-type="pmid">10706218</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Savelli</surname><given-names>F</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Origin and role of path integration in the cognitive representations of the hippocampus: computational insights into open questions</article-title><source>The Journal of Experimental Biology</source><volume>222</volume><elocation-id>jeb188912</elocation-id><pub-id pub-id-type="doi">10.1242/jeb.188912</pub-id><pub-id pub-id-type="pmid">30728236</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shamash</surname><given-names>P</given-names></name><name><surname>Olesen</surname><given-names>SF</given-names></name><name><surname>Iordanidou</surname><given-names>P</given-names></name><name><surname>Campagner</surname><given-names>D</given-names></name><name><surname>Banerjee</surname><given-names>N</given-names></name><name><surname>Branco</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Mice learn multi-step routes by memorizing subgoal locations</article-title><source>Nature Neuroscience</source><volume>24</volume><fpage>1270</fpage><lpage>1279</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00884-8</pub-id><pub-id pub-id-type="pmid">34326540</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taube</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The head direction signal: origins and sensory-motor integration</article-title><source>Annual Review of Neuroscience</source><volume>30</volume><fpage>181</fpage><lpage>207</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.29.051605.112854</pub-id><pub-id pub-id-type="pmid">17341158</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tolman</surname><given-names>EC</given-names></name><name><surname>Ritchie</surname><given-names>BF</given-names></name><name><surname>Kalish</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1946">1946a</year><article-title>Studies in spatial learning; place learning versus response learning</article-title><source>Journal of Experimental Psychology</source><volume>36</volume><fpage>221</fpage><lpage>229</lpage><pub-id pub-id-type="doi">10.1037/h0060262</pub-id><pub-id pub-id-type="pmid">20985357</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tolman</surname><given-names>EC</given-names></name><name><surname>Ritchie</surname><given-names>BF</given-names></name><name><surname>Kalish</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1946">1946b</year><article-title>Studies in spatial learning: orientation and the short-cut</article-title><source>Journal of Experimental Psychology</source><volume>36</volume><fpage>13</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1037/h0053944</pub-id><pub-id pub-id-type="pmid">21015338</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tolman</surname><given-names>EC</given-names></name></person-group><year iso-8601-date="1948">1948</year><article-title>Cognitive maps in rats and men</article-title><source>Psychological Review</source><volume>55</volume><fpage>189</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1037/h0061626</pub-id><pub-id pub-id-type="pmid">18870876</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tomé</surname><given-names>T</given-names></name><name><surname>Oliveira</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><source>Stochastic Dynamics and Irreversibility</source><publisher-name>Springer International Publishing</publisher-name><pub-id pub-id-type="doi">10.1007/978-3-319-11770-6</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Upham</surname><given-names>NS</given-names></name><name><surname>Hafner</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Do nocturnal rodents in the Great Basin Desert avoid moonlight?</article-title><source>Journal of Mammalogy</source><volume>94</volume><fpage>59</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1644/12-MAMM-A-076.1</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wallach</surname><given-names>A</given-names></name><name><surname>Harvey-Girard</surname><given-names>E</given-names></name><name><surname>Jun</surname><given-names>JJ</given-names></name><name><surname>Longtin</surname><given-names>A</given-names></name><name><surname>Maler</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A time-stamp mechanism may provide temporal information necessary for egocentric to allocentric spatial transformations</article-title><source>eLife</source><volume>7</volume><elocation-id>e36769</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.36769</pub-id><pub-id pub-id-type="pmid">30465523</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>X</given-names></name><name><surname>Cacucci</surname><given-names>F</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>Wills</surname><given-names>TJ</given-names></name><name><surname>Chen</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Visual boundary cues suffice to anchor place and grid cells in virtual reality</article-title><source>Current Biology</source><volume>34</volume><fpage>2256</fpage><lpage>2264</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2024.04.026</pub-id><pub-id pub-id-type="pmid">38701787</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Youngstrom</surname><given-names>IA</given-names></name><name><surname>Strowbridge</surname><given-names>BW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Visual landmarks facilitate rodent spatial navigation in virtual reality environments</article-title><source>Learning &amp; Memory</source><volume>19</volume><fpage>84</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1101/lm.023523.111</pub-id><pub-id pub-id-type="pmid">22345484</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Schönfeld</surname><given-names>F</given-names></name><name><surname>Wiskott</surname><given-names>L</given-names></name><name><surname>Manahan-Vaughan</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Spatial representations of place cells in darkness are supported by path integration and border information</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>8</volume><elocation-id>222</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2014.00222</pub-id><pub-id pub-id-type="pmid">25009477</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.95764.4.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Cowan</surname><given-names>Noah J</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Johns Hopkins University</institution><country>United States</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Compelling</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Fundamental</kwd></kwd-group></front-stub><body><p>This <bold>fundamental</bold> work provides creative and thoughtful analysis of rodent foraging behavior and its dependence on body reference frame-based vs world reference frame-based cues. <bold>Compelling</bold> evidence demonstrates that a robust map, capable of supporting taking novel shortcuts, can be learned primarily if not exclusively based on self-motion cues, which has rarely if ever been reported outside of the human literature. The work, which will be of interest to a broad audience of neuroscientists, provides a rich discussion about the role of the hippocampus in supporting the behavior that should guide future neurophysiological investigations.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.95764.4.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Assessment:</p><p>This fundamental work advances our understanding of navigation and path integration in mammals by using a clever behavioral paradigm. The paper provides compelling evidence that mice are able to create and use a cognitive map to find &quot;short cuts&quot; in an environment, using only the location of rewards relative to the point of entry to the environment and path integration, and need not rely on visual landmarks.</p><p>Summary:</p><p>The authors have designed a novel experimental apparatus called the 'Hidden Food Maze (HFM)' and a beautiful suite of behavioral experiments using this apparatus to investigate the interplay between allothetic and idiothetic cues in navigation. The results presented provide a clear demonstration of the central claim of the paper, namely that mice only need a fixed start location and path integration to develop a cognitive map. The experiments and analyses conducted to test the main claim of the paper -- that the animals have formed a cognitive map -- are conclusive and include many thoughtfully designed control experiments to eliminate alternatives.</p><p>Strengths:</p><p>The 90 degree rotationally symmetric design and use of 4 distal landmarks and 4 quadrants with their corresponding rotationally equivalent locations (REL) lends itself to teasing apart the influence of path integration and landmark-based navigation in a clever way. The authors use a complete set of experiments and associated controls to show that mice can use a start location and path integration to develop a cognitive map and generate shortcut routes to new locations.</p><p>Weaknesses:</p><p>There were no major weaknesses identified that were not addressed during revisions.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.95764.4.sa2</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>How is it that animals find learned food locations in their daily life? Do they use landmarks to home in on these learned locations or do they learn a path based on self-motion (turn left, take ten steps forward, turn right, etc.). This study carefully examines this question in a well-designed behavioral apparatus. A key finding is that to support the observed behavior in the hidden food arena, mice appear to not use the distal cues that are present in the environment for performing this task. Removal of such cues did not change the learning rate, for example. In a clever analysis of whether the resulting cognitive map based on self-motion cues could allow a mouse to take a shortcut, it was found that indeed they are. The work nicely shows the evolution of the rodent's learning of the task, and the role of active sensing in the targeted reduction of uncertainty of food location proximal to its expected location.</p><p>Strengths:</p><p>A convincing demonstration that mice can synthesize a cognitive map for the finding of a static reward using body frame-based cues. Showing that uncertainty of final target location is resolved by an active sensing process of probing holes proximal to the expected location. Showing that changing the position of entry into the arena rotates the anticipated location of the reward in a manner consistent with failure to use distal cues.</p><p>Weaknesses:</p><p>Weaknesses: The Reviewing Editor felt that previously identified weaknesses from Reviewer #3 were adequately addressed in the final manuscript.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.95764.4.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Xu</surname><given-names>Jiayun</given-names></name><role specific-use="author">Author</role><aff><institution>University of Ottawa</institution><addr-line><named-content content-type="city">Ottawa</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Girardi-Schappo</surname><given-names>Mauricio</given-names></name><role specific-use="author">Author</role><aff><institution>University of Ottawa</institution><addr-line><named-content content-type="city">Ottawa</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Beique</surname><given-names>Jean-Claude</given-names></name><role specific-use="author">Author</role><aff><institution>University of Ottawa</institution><addr-line><named-content content-type="city">Ottawa</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Longtin</surname><given-names>André</given-names></name><role specific-use="author">Author</role><aff><institution>University of Ottawa</institution><addr-line><named-content content-type="city">Ottawa</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Maler</surname><given-names>Leonard</given-names></name><role specific-use="author">Author</role><aff><institution>University of Ottawa</institution><addr-line><named-content content-type="city">Ottawa</named-content></addr-line><country>Canada</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the previous reviews.</p><p>I have added a paragraph that addresses the issue of how landmarks might be used and why they are not. The suggestions made in the &quot;Weaknesses&quot; paragraph were concise and excellent and have directly incorporated them into my revised manuscript. This text appears on Page 21 and is shown below. I hope that this is what the editors and reviewers were looking.</p><p>The requested revision is the second paragraph.</p><p>The first paragraph was not written in response to reviews but inspired by a recent paper by Mahdev et al (2024) - <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41593-024-01681-9">https://doi.org/10.1038/s41593-024-01681-9</ext-link>. I had already requested to add this reference and was encouraged to do so by the Editors. The Mahdev et al paper was very surprising in that it showed that path integration is not constant but that its &quot;gain&quot; can be recalibrated by selfmotion signals. I wondered whether this unexpected capacity extended to path integration also recalibrating the cognitive map and thereby generating the shortcutting behavior we observe. I suggested that, at an abstract level, this would correspond to &quot;coordinate transformation&quot; of the cognitive map. I realize that this is entirely speculative. If the Editors feel that it does not add much to the manuscript and that the speculation goes to far, I will remove the first paragraph and re-submit.</p><p>Added text. P21 and just before the heading: &quot; Implications for theories of hippocampal representations of spatial maps&quot; There were no other changes made in the paper.</p><p>&quot;Path integration uses self-motion signals to update the animal's estimated location on its internal cognitive map. Path integration gain has been shown to be plastic and regulated by landmarks (<italic>52</italic>). Remarkably, a recent study has revealed that path integration gain can also be directly recalibrated by self-motion signals alone (<italic>53</italic>), albeit not as effectively as by landmarks (<italic>52, 53</italic>). An interesting question for future research is whether self-motion signals can also recalibrate the coordinates of a cognitive map. From this perspective, the Target B to Target A shortcut requires a transformation of the cognitive map coordinates so that the start point is now Target B.</p><p>Extensive research has shown that external cues can control hippocampal neuron place fields (<italic>11, 12, 54</italic>) and the gain of the path integrator (<italic>52</italic>), making the failure of mice in our study to use such cues puzzling. The failure to use landmarks may be related to our task being low stakes and our pretraining procedure teaching the mouse that such cues are not necessary. Our results may not generalize to more natural conditions where many reliable prominent cues are available, and where there is urgency to find food or water while avoiding predation (<italic>55</italic>). Under these more naturalistic conditions the use of distal cues to rapidly find a food reward is more likely to be observed.&quot;</p></body></sub-article></article>