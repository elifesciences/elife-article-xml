<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">102475</article-id><article-id pub-id-type="doi">10.7554/eLife.102475</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.102475.4</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Sequence action representations contextualize during early skill learning</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Dash</surname><given-names>Debadatta</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0543-0304</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Iwane</surname><given-names>Fumiaki</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Hayward</surname><given-names>William</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Salamanca-Giron</surname><given-names>Roberto F</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0008-5743-6805</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Bönstrup</surname><given-names>Marlene</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Buch</surname><given-names>Ethan R</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5443-8222</contrib-id><email>ethan.buch@nih.gov</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Cohen</surname><given-names>Leonardo G</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1705-8773</contrib-id><email>cohenl@ninds.nih.gov</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01cwqze88</institution-id><institution>Human Cortical Physiology and Neurorehabilitation Section, NINDS, NIH</institution></institution-wrap><addr-line><named-content content-type="city">Bethesda</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03s7gtk40</institution-id><institution>Department of Neurology, University of Leipzig Medical Center</institution></institution-wrap><addr-line><named-content content-type="city">Leipzig</named-content></addr-line><country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Gallego</surname><given-names>Juan Alvaro</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/041kmwe10</institution-id><institution>Imperial College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>12</day><month>09</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP102475</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-08-28"><day>28</day><month>08</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-08-15"><day>15</day><month>08</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.08.15.608189"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-11-11"><day>11</day><month>11</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.102475.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-03-17"><day>17</day><month>03</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.102475.2"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-07-02"><day>02</day><month>07</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.102475.3"/></event></pub-history><permissions><ali:free_to_read/><license xlink:href="http://creativecommons.org/publicdomain/zero/1.0/"><ali:license_ref>http://creativecommons.org/publicdomain/zero/1.0/</ali:license_ref><license-p>This is an open-access article, free of all copyright, and may be freely reproduced, distributed, transmitted, modified, built upon, or otherwise used by anyone for any lawful purpose. The work is made available under the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">Creative Commons CC0 public domain dedication</ext-link>.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-102475-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-102475-figures-v1.pdf"/><abstract><p>Activities of daily living rely on our ability to acquire new motor skills composed of precise action sequences. Here, we asked in humans if the millisecond-level neural representation of an action performed at different contextual sequence locations within a skill differentiates or remains stable during early motor learning. We first optimized machine learning decoders predictive of sequence-embedded finger movements from magnetoencephalographic (MEG) activity. Using this approach, we found that the neural representation of the same action performed in different contextual sequence locations progressively differentiated—primarily during rest intervals of early learning (offline)—correlating with skill gains. In contrast, representational differentiation during practice (online) did not reflect learning. The regions contributing to this representational differentiation evolved with learning, shifting from the contralateral pre- and post-central cortex during early learning (trials 1–11) to increased involvement of the superior and middle frontal cortex once skill performance plateaued (trials 12–36). Thus, the neural substrates supporting finger movements and their representational differentiation during early skill learning differ from those supporting stable performance during the subsequent skill plateau period. Representational contextualization extended to Day 2, exhibiting specificity for the practiced skill sequence. Altogether, our findings indicate that sequence action representations in the human brain contextually differentiate during early skill learning, an issue relevant to brain-computer interface applications in neurorehabilitation.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>brain-computer interface</kwd><kwd>consolidation</kwd><kwd>magnetoencephalography</kwd><kwd>memory</kwd><kwd>motor learning</kwd><kwd>skill</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><award-id>NINDS Intramural Research Program</award-id><principal-award-recipient><name><surname>Cohen</surname><given-names>Leonardo G</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>When learning a new skill, neural representations of individual actions rapidly incorporate contextual information pertaining to the encompassing skill sequence-primarily during rest breaks interleaved with practice.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Motor learning is required to perform a wide array of activities of daily living, intricate athletic endeavors, and professional skills. Whether it’s learning to type more quickly on a keyboard (<xref ref-type="bibr" rid="bib4">Bönstrup et al., 2019a</xref>), improve one’s tennis game (<xref ref-type="bibr" rid="bib69">Schmidt, 2018</xref>), or play a piece of music on the piano (<xref ref-type="bibr" rid="bib24">Doyon and Benali, 2005</xref>) – all these skills require the ability to execute sequences of actions with precise temporal coordination. Action sequences thus form the building blocks of fine motor skills (<xref ref-type="bibr" rid="bib20">Dehaene et al., 2015</xref>). Practicing a new motor skill elicits rapid performance improvements (early learning; <xref ref-type="bibr" rid="bib4">Bönstrup et al., 2019a</xref>) that precede skill performance plateaus (<xref ref-type="bibr" rid="bib76">Walker and Stickgold, 2004</xref>). Skill gains during early learning accumulate over rest periods (micro-offline) interspersed with practice (<xref ref-type="bibr" rid="bib4">Bönstrup et al., 2019a</xref>; <xref ref-type="bibr" rid="bib10">Buch et al., 2021</xref>; <xref ref-type="bibr" rid="bib38">Jacobacci et al., 2020</xref>; <xref ref-type="bibr" rid="bib57">Mylonas et al., 2024</xref>; <xref ref-type="bibr" rid="bib35">Hayward et al., 2024</xref>; <xref ref-type="bibr" rid="bib8">Brooks et al., 2024</xref>), and are up to four times larger than offline performance improvements reported following overnight sleep (<xref ref-type="bibr" rid="bib4">Bönstrup et al., 2019a</xref>). During this initial interval of prominent learning, retroactive interference immediately following each practice interval reduces learning rates relative to interference after passage of time, consistent with stabilization of the motor memory (<xref ref-type="bibr" rid="bib6">Bönstrup et al., 2020</xref>). Micro-offline gains observed during early learning are reproducible (<xref ref-type="bibr" rid="bib38">Jacobacci et al., 2020</xref>; <xref ref-type="bibr" rid="bib8">Brooks et al., 2024</xref>; <xref ref-type="bibr" rid="bib6">Bönstrup et al., 2020</xref>; <xref ref-type="bibr" rid="bib12">Chen et al., 2024</xref>; <xref ref-type="bibr" rid="bib71">Sjøgård, 2024</xref>) and are similar in magnitude even when practice periods are reduced by half to 5 seconds in length, thereby confirming that they are not merely a result of recovery from performance fatigue (<xref ref-type="bibr" rid="bib6">Bönstrup et al., 2020</xref>). Additionally, they are unaffected by the random termination of practice periods, which eliminates the possibility of predictive motor slowing as a contributing factor (<xref ref-type="bibr" rid="bib6">Bönstrup et al., 2020</xref>). Collectively, these behavioral findings point towards the interpretation that micro-offline gains during early learning represent a form of memory consolidation (<xref ref-type="bibr" rid="bib4">Bönstrup et al., 2019a</xref>).</p><p>This interpretation has been further supported by brain imaging and electrophysiological studies linking known memory-related networks and consolidation mechanisms to rapid offline performance improvements. In humans, the rate of hippocampo-neocortical neural replay predicts micro-offline gains (<xref ref-type="bibr" rid="bib10">Buch et al., 2021</xref>). Consistent with these findings, <xref ref-type="bibr" rid="bib12">Chen et al., 2024</xref> and <xref ref-type="bibr" rid="bib71">Sjøgård, 2024</xref> furnished direct evidence from intracranial human EEG studies, demonstrating a connection between the density of hippocampal sharp-wave ripples (80–120 Hz)—recognized markers of neural replay—and micro-offline gains during early learning. Further, Griffin et al. reported that neural replay of task-related ensembles in the motor cortex of macaques during brief rest periods—akin to those observed in humans (<xref ref-type="bibr" rid="bib4">Bönstrup et al., 2019a</xref>; <xref ref-type="bibr" rid="bib10">Buch et al., 2021</xref>; <xref ref-type="bibr" rid="bib38">Jacobacci et al., 2020</xref>; <xref ref-type="bibr" rid="bib57">Mylonas et al., 2024</xref>; <xref ref-type="bibr" rid="bib77">Wamsley et al., 2023</xref>)—is not merely correlated with, but are causal drivers of micro-offline learning (<xref ref-type="bibr" rid="bib32">Griffin et al., 2025</xref>). Specifically, the same reach directions that were replayed the most during rest breaks showed the greatest reduction in path length (i.e. more efficient movement path between two locations in the reach sequence) during subsequent trials, while stimulation applied during rest intervals preceding performance plateau reduced reactivation rates and virtually abolished micro-offline gains (<xref ref-type="bibr" rid="bib32">Griffin et al., 2025</xref>). Thus, converging evidence in humans and non-human primates across indirect non-invasive and direct invasive recording techniques links hippocampal activity, neural replay dynamics, and offline skill gains in early motor learning that precede performance plateau.</p><p>During skill learning, the neural representation of a sequential skill binds discrete individual actions (e.g. single piano keypress) into complex, temporally and spatially precise sequence representations (e.g. a refrain from a piece of music; <xref ref-type="bibr" rid="bib39">Karni et al., 1995</xref>; <xref ref-type="bibr" rid="bib72">Song and Cohen, 2014</xref>; <xref ref-type="bibr" rid="bib58">Natraj et al., 2022</xref>; <xref ref-type="bibr" rid="bib29">Ghilardi et al., 2009</xref>; <xref ref-type="bibr" rid="bib80">Yokoi and Diedrichsen, 2019</xref>). After a skill is learned over extended periods (i.e. weeks), the neural representation of the sequence changes significantly (<xref ref-type="bibr" rid="bib80">Yokoi and Diedrichsen, 2019</xref>), while the representation of its individual action components (e.g. finger movements) does not (<xref ref-type="bibr" rid="bib3">Beukema et al., 2019</xref>). On the other hand, it is not known whether individual sequence action representations differentiate or remain stable during the early stages of skill learning, when the memory is still not fully formed (<xref ref-type="bibr" rid="bib4">Bönstrup et al., 2019a</xref>). Furthermore, it is unknown whether the neural representations of identical movements, performed at different positions within a skill sequence (i.e. the skill <italic>context</italic>), differentiate with learning—an important consideration for advancing robust brain-computer interface (BCI) applications (<xref ref-type="bibr" rid="bib54">Merino et al., 2023</xref>; <xref ref-type="bibr" rid="bib50">Liu et al., 2023</xref>; <xref ref-type="bibr" rid="bib46">Lee et al., 2022</xref>; <xref ref-type="bibr" rid="bib82">Zhao et al., 2022</xref>; <xref ref-type="bibr" rid="bib79">Yao et al., 2022</xref>).</p><p>Examining the millisecond-level differentiation of discrete action representations during learning is challenging, as evolving neural dynamics concurrently encode skill sequences and their individual action components (<xref ref-type="bibr" rid="bib80">Yokoi and Diedrichsen, 2019</xref>; <xref ref-type="bibr" rid="bib36">Hikosaka et al., 1999</xref>) across multiple spatial scales (<xref ref-type="bibr" rid="bib56">Munn et al., 2024</xref>). To address this problem, we first optimized a multi-scale decoder aimed at predicting keypress actions from magnetoencephalographic (MEG) neural activity. Using this optimized approach, we report that an individual sequence action representation differentiates depending on the sequence context and correlates with early skill learning. This representational contextualization developed predominantly over rest rather than during practice intervals—in parallel with rapid consolidation of skill.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>Participants engaged in a well-characterized sequential skill learning task (<xref ref-type="bibr" rid="bib4">Bönstrup et al., 2019a</xref>; <xref ref-type="bibr" rid="bib10">Buch et al., 2021</xref>; <xref ref-type="bibr" rid="bib6">Bönstrup et al., 2020</xref>) that involved repetitive typing of a sequence (4-1-3-2-4) performed with their (non-dominant) left hand over 36 trials with alternating periods of 10 s <italic>practice</italic> and 10 s <italic>rest</italic> (<italic>inter-practice rest; Day 1 Training</italic>; <xref ref-type="fig" rid="fig1">Figure 1A</xref>), a practice schedule that minimizes reactive inhibition effects (<xref ref-type="bibr" rid="bib6">Bönstrup et al., 2020</xref>; <xref ref-type="bibr" rid="bib60">Pan and Rickard, 2015</xref>; see Materials and methods). Individual keypress times and finger keypress identities were recorded and used to quantify skill as the correct sequence speed (keypresses/s; <xref ref-type="bibr" rid="bib4">Bönstrup et al., 2019a</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Experimental design and behavioral performance.</title><p>(<bold>A</bold>) Skill learning task. Participants engaged in a procedural motor skill learning task, which required them to repeatedly type a keypress sequence, &quot;4-1-3-2-4&quot; (1=little finger, 2=ring finger, 3=middle finger, and 4=index finger) with their non-dominant, left hand. The <italic>Day 1 Training</italic> session included 36 trials, with each trial consisting of alternating 10 s practice and rest intervals. The rationale for this task design was to minimize reactive inhibition effects during the period of steep performance improvements (early learning; <xref ref-type="bibr" rid="bib6">Bönstrup et al., 2020</xref>; <xref ref-type="bibr" rid="bib60">Pan and Rickard, 2015</xref>; see Materials and methods). After a 24-hr break, participants were retested on performance of the same sequence (4-1-3-2-4) for nine trials (<italic>Day 2 Retest</italic>) to inform on the generalizability of the findings over time and MEG recording sessions, as well as single-trial performance on nine different control sequences (<italic>Day 2 Control</italic>; 2-1-3-4-2, 4-2-4-3-1, 3-4-2-3-1, 1-4-3-4-2, 3-2-4-3-1, 1-4-2-3-1, 3-2-4-2-1, 3-2-1-4-2, and 4-2-3-1-4) to inform on specificity of the findings to the learned skill. MEG was recorded during both Day 1 and Day 2 sessions with a 275-channel CTF magnetoencephalography (MEG) system (CTF Systems, Inc, Canada). (<bold>B</bold>)<italic> Skill Learning</italic>. As reported previously<sup>1</sup>, participants on average reached 95% of peak performance by trial 11 of the <italic>Day 1 Training</italic> session (see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref> for results over all <italic>Day 1 Training</italic> and <italic>Day 2 Retest</italic> trials). Shaded regions in main plot indicate the 95% confidence interval of the group mean. At the group level, total early learning was exclusively accounted for by micro-offline gains during inter-practice rest intervals (<bold>B, inset</bold>; F [2,75]=14.79, p=3.86 × 10<sup>–6</sup>; micro-online vs. micro-offline: p=7.98 × 10<sup>–6</sup>; micro-online vs. total: p=0.0002; micro-offline vs. total: p=0.669). These results were not impacted by potential preplanning effects on initial skill performance (<xref ref-type="bibr" rid="bib1">Ariani and Diedrichsen, 2019</xref>) since alternative measurements of cumulative micro-online and -offline gains remain unchanged after omission of the first 3 keypresses in each trial from the correct sequence speed computation (paired t-tests; micro-online: <italic>t<sub>25</sub></italic>=–0.0223, p=0.982; micro-offline: <italic>t<sub>25</sub></italic>=–0.879, p=0.388). Center line of box plots shown in inset indicate the group median, while box limits indicate the 1st and 3rd quartiles. Whisker lengths are set at the extreme value ≤1.5×IQR. (<bold>C</bold>) Keypress transition time (KTT) variability. Distribution of KTTs normalized to the median correct sequence time for each participant and centered on the mid-point for each full sequence iteration during early learning (see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B</xref> for results over all <italic>Day 1 Training</italic> and <italic>Day 2 Retest</italic> trials). Note the initial variability of the relative KTT composition of the sequence (i.e., – 4–1, 1–3, 3–2, 2–4, 4–4), before it stabilizes in the early learning period.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Behavioral performance during skill learning.</title><p>(<bold>A</bold>) Total Skill Learning over Day 1 Training (36 trials) and Day 2 Retest (9 trials). As reported previously (<xref ref-type="bibr" rid="bib4">Bönstrup et al., 2019a</xref>), participants on average reached 95% of peak performance during <italic>Day 1 Training</italic> by trial 11. Note that after trial 11, performance stabilizes around a plateau through trial 36. Following a 24-hr break, participants displayed an upward shift in performance during the <italic>Day 2 Retest</italic> – indicative of an overnight skill consolidation effect. Shaded regions indicate the 95% confidence interval of the group mean. (<bold>B</bold>) Keypress transition time (KTT) variability. Distribution of KTTs normalized to the median correct sequence time for each participant and centered on the mid-point for each full sequence iteration during early learning. Note that the initial variability of the five component transitions in the sequence (i.e. 4–1, 1–3, 3–2, 2–4, 4–4) stabilize by trial 6 in the early learning period and remain stable throughout the rest of <italic>Day 1 Training</italic> (through trial 36) and <italic>Day 2 Retest</italic>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig1-figsupp1-v1.tif"/></fig></fig-group><p>Participants reached 95% of maximal skill (i.e., - Early Learning) within the initial 11 practice trials (<xref ref-type="fig" rid="fig1">Figure 1B</xref>), with improvements developing over inter-practice rest periods (micro-offline gains) accounting for almost all total learning across participants (<xref ref-type="fig" rid="fig1">Figure 1B</xref><bold>, inset</bold>; <xref ref-type="bibr" rid="bib4">Bönstrup et al., 2019a</xref>). In addition to the reduction in sequence duration during early learning, individual keypress transition times became more consistent across repeated sequence iterations (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). On average across subjects, 2.32% ± 1.48% (mean ± SD) of all keypresses performed were errors, which were evenly distributed across the four possible keypress responses. While errors increased progressively over practice trials, they did so in proportion to the increase in correct keypresses, so that the overall ratio of correct-to-incorrect keypresses remained stable over the training session.</p><p>On the following day, participants were retested on performance of the same sequence (4-1-3-2-4) over 9 trials (<italic>Day 2 Retest</italic>), as well as on the single-trial performance of 9 different untrained control sequences (<italic>Day 2 Controls</italic>: 2-1-3-4-2, 4-2-4-3-1, 3-4-2-3-1, 1-4-3-4-2, 3-2-4-3-1, 1-4-2-3-1, 3-2-4-2-1, 3-2-1-4-2, and 4-2-3-1-4). As expected, an upward shift in performance of the trained sequence (0.68 ± SD 0.56 keypresses/s; <italic>t</italic>=7.21, p&lt;0.001) was observed during <italic>Day 2 Retest</italic>, indicative of an overnight skill consolidation effect (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>).</p><sec id="s2-1"><title>Keypress actions are represented in multi-scale hybrid-space manifolds</title><p>We investigated the differentiation of neural representations of the same index finger keypress performed at different positions of the skill sequence. A set of decoders was constructed to predict keypress actions from MEG activity as a function of both the learning state and the ordinal position of the keypress within the sequence. We first characterized the spectral and spatial features of keypress state representations by comparing performance of decoders constructed around broadband (1–100 Hz) or narrowband [delta- (1–3 Hz), theta- (4–7 Hz), alpha- (8–14 Hz), beta- (15–24 Hz), gamma- (25–50 Hz), and high gamma-band (51–100 Hz)] MEG oscillatory activity. We found that decoders trained on broadband activity consistently outperformed those trained on narrowband activity. Whole-brain parcel-space (70.11% ± SD 7.11% accuracy; n=148 brain regions; <italic>t</italic>=1.89, p=0.035, df = 25, Cohen’s <italic>d</italic>=0.17, <xref ref-type="fig" rid="fig2">Figure 2A</xref>; also see <xref ref-type="fig" rid="fig2">Figure 2B</xref> for topographic map of feature importance scores) and voxel-space (74.51% ± SD 7.34% accuracy; n=15684; <italic>t</italic>=7.18, p&lt;0.001, df = 25, Cohen’s <italic>d</italic>=0.76, <xref ref-type="fig" rid="fig2">Figure 2A</xref>; also see <xref ref-type="fig" rid="fig2">Figure 2C</xref> for topographic map of feature importance scores; <xref ref-type="bibr" rid="bib22">Destrieux et al., 2010</xref>) decoders exhibited greater accuracy than all regional voxel-space decoders constructed from individual brain areas (<xref ref-type="fig" rid="fig2">Figure 2D</xref>; maximum accuracy of 68.77% ± SD 7.6%; see also <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplements 1</xref> and <xref ref-type="fig" rid="fig2s2">2</xref>). Thus, optimal decoding required information from multiple brain regions, predominantly contralateral to the hand engaged in the skill task (<xref ref-type="fig" rid="fig2">Figure 2B and C</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Spatial and oscillatory contributions to neural decoding of finger identities.</title><p>(<bold>A</bold>) Contribution of whole-brain oscillatory frequencies to decoding. When trained on broadband activity relative to narrow frequency band features, decoding accuracy (i.e. test sample performance) was highest for whole-brain voxel-space (74.51% ± SD 7.34%, <italic>t</italic>=8.08, p&lt;0.001) and parcel-space (70.11% ± SD 7.11%, <italic>t</italic>=13.22, p&lt;0.001) MEG activity. Thus, decoders trained on whole-brain broadband data consistently outperformed those trained on narrowband activity. Dots depict decoding accuracy for each participant. Center line of box plots indicate the group median, while notches represent the 95% confidence interval of the group median. Box limits indicate the 1st and 3rd quartiles while whisker lengths are set at the extreme value ≤1.5×IQR. Outlier values located outside of the whisker range are marked with “+” symbols. *p&lt;0.05, **p&lt;0.01, ***p&lt;0.001, n.s. - no statistical significance (p&gt;0.05). (<bold>B</bold>) Whole-brain parcel-space decoding. Color-coded brain surface plot displaying the relative importance of individual brain regions (parcels) to broadband whole-brain parcel-space decoding performance (far-left light gray box plot in <bold>A</bold>). (<bold>C</bold>) Whole-brain voxel space decoding. Color-coded brain surface plot displaying the relative importance of individual voxels to broadband whole-brain voxel-space decoding performance (far-left dark gray box plot in <bold>A</bold>). (<bold>D</bold>) Regional voxel-space decoding. Broadband voxel-space decoding performance for top-ranked brain regions across the group is displayed on a standard (FreeSurfer fsaverage) brain surface and color-coded by accuracy. Note that while whole-brain parcel- and voxel-space decoders relied more on information from brain regions contralateral to the engaged hand, regional voxel-space decoders performed similarly for bilateral sensorimotor regions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Oscillatory contributions at individual brain regions.</title><p>Decoding performance of regional voxel-space activity patterns within individual brain areas for broadband and each narrowband oscillatory range is displayed in the form of a heatmap for both the left and right hemisphere. Optimal decoding performance for broadband regional voxel-space decoders was obtained from bilateral superior frontal (Left: 68.77% ± SD 7.6%; Right: 67.52%% ± SD 6.78%), middle frontal (Left: 63.41% ± SD 7.58%; Right: 62.78%% ± SD 76.94%), pre-central (Left: 62.37%% ± SD 6.32%; Right: 62.69% ± SD 5.94%), and post-central (Left: 61.71% ± SD 6.62%; Right: 61.09% ± SD 6.2%) brain regions. Superior parietal, central, paracentral, anterior cingulate, and precuneus regions also showed broadband decoding performance exceeding 60%. With respect to decoders constructed from narrowband oscillatory input features, only Delta-band voxel-space activity from bilateral superior frontal regions achieved at least 60% decoding accuracy of keypresses.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig2-figsupp1-v1.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Distribution of correlation coefficients between parcel-space time-series and their constituent voxels.</title><p>Data is shown for all subjects. Parcels represented in the regional voxel-space features of the hybrid-space decoder are marked with red vertical boxes (bilateral superior frontal, middle frontal, pre-central, and post-central regions). The y-axis indicates the absolute correlation coefficients for each voxel time series with the time series of the parcel it is a member of (1=complete redundancy; 0=orthogonality). Note that while signal in some voxels correlates strongly with parcel-space time series, others are fully orthogonal. That is, the degree to which information obtained at the two different spatial scales is complementary (or redundant) varies substantially over the regional voxel space. This finding is consistent with the documented increase in correlational structure of neural activity across larger spatial scales that does not reflect perfect dependency or orthogonality (<xref ref-type="bibr" rid="bib56">Munn et al., 2024</xref>). The normalized cumulative distributions of parcel-to-voxel-space correlations depicted on the right show that voxels included in the hybrid-space decoder (red) are correlated less overall (two-sample Kolmogorov-Smirnov test: <italic>D</italic>=0.2484, p&lt;1 × 10<sup>–10</sup>) with their respective parcel-space time-series relative to excluded voxels (gray).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig2-figsupp2-v1.tif"/></fig></fig-group><p>Next, given that the brain simultaneously processes information more efficiently across multiple spatial and temporal scales (<xref ref-type="bibr" rid="bib56">Munn et al., 2024</xref>; <xref ref-type="bibr" rid="bib9">Buch et al., 2017</xref>; <xref ref-type="bibr" rid="bib49">Lisman and Buzsáki, 2008</xref>), we asked if the combination of lower resolution whole-brain and higher resolution regional brain activity patterns further improve keypress prediction accuracy. We constructed hybrid-space decoders (N=1295 ± 20 features; <xref ref-type="fig" rid="fig3">Figure 3A</xref>) combining whole-brain parcel-space activity (n=148 features; <xref ref-type="fig" rid="fig2">Figure 2B</xref>) with regional voxel-space activity from a data-driven subset of brain areas (n=1147 ± 20 features; <xref ref-type="fig" rid="fig2">Figure 2D</xref>). This subset covers brain regions showing the highest regional voxel-space decoding performances (top regions across all subjects shown in <xref ref-type="fig" rid="fig2">Figure 2D</xref>; Materials and methods <italic>– Hybrid Spatial Approach</italic>). Accuracy was higher for hybrid- (78.15% ± SD 7.03%; weighted mean F1 score of 0.78 ± SD 0.07) than for voxel- (74.51% ± SD 7.34%; paired <italic>t</italic>-test: <italic>t</italic>=6.30, p&lt;0.001, df = 25, Cohen’s <italic>d</italic>=0.39) and parcel-space decoders (70.11% ± SD 7.48%; paired <italic>t</italic>-test: <italic>t</italic>=12.08, p&lt;0.001, df = 25, Cohen’s <italic>d</italic>=0.98, <xref ref-type="fig" rid="fig3">Figure 3B</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplements 1</xref> and <xref ref-type="fig" rid="fig3s6">6</xref>). Note that while features from contralateral brain regions were more important for whole-brain decoding (in both parcel- and voxel-spaces), regional voxel-space decoders performed best for bilateral sensorimotor areas on average across the group. Thus, a multi-scale hybrid-space representation best characterizes the keypress action manifolds.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Hybrid spatial approach for neural decoding during skill learning.</title><p>(<bold>A</bold>) Pipeline. Sensor-space MEG data (<italic>N</italic>=272 channels) were source-localized (voxel-space features; <italic>N</italic>=15,684 voxels), and then parcellated (parcel-space features; <italic>N</italic>=148) by averaging the activity of all voxels located within an individual region defined in a standard template space (Desikan-Killiany Atlas). Individual regional voxel-space decoders were then constructed and ranked. The final hybrid-space keypress state (i.e. 4-class) decoder was constructed using all whole-brain parcel-space features and top-ranked regional voxel-space features (see Materials and methods). (<bold>B</bold>) Decoding performance across parcel, voxel, and hybrid spaces. Note that decoding performance was highest for the hybrid space approach compared to performance obtained for whole-brain voxel- and parcel spaces. Addition of linear discriminant analysis (LDA)-based dimensionality reduction further improved decoding performance for both parcel- and hybrid-space approaches. Each dot represents accuracy for a single participant and method. Center line of box plots indicates the group median, while notches (and shaded areas) represent the 95% confidence interval of the group median. Box limits indicate the 1st and 3rd quartiles while whisker lengths are set at the extreme value ≤1.5×IQR. Outlier values located outside of the whisker range are marked with “+” symbols. ***p&lt;0.001 and *p&lt;0.05. (<bold>C</bold>) Confusion matrix of individual finger identity decoding for hybrid-space manifold features. True predictions are located on the main diagonal. Off-diagonal elements in each row depict false-negative predictions for each finger, while off-diagonal elements in each column indicate false-positive predictions. Please note that the index finger keypress had the highest false-negative misclassification rate (11.55%).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Contribution of whole-brain oscillatory frequencies to decoding.</title><p>Accuracy for decoders trained on four different input feature spaces—sensor, whole-brain parcel, whole-brain voxel, and hybrid (combination of whole-brain parcel plus regional voxel)—was highest for broadband MEG activity, followed by Delta-band activity. The hybrid approach resulted in the highest decoding accuracy, regardless of whether input features were broadband or narrowband-limited. Sensor-, parcel-, and voxel-space decoders displayed similar accuracy with respect to one another for broadband MEG activity, and also for all narrowband ranges assessed. Dots depict decoding accuracy for each participant. Center line of box plots indicates the group median, while notches represent the 95% confidence interval of the group median. Box limits indicate the 1st and 3rd quartiles while whisker lengths are set at the extreme value ≤1.5×IQR. Outlier values located outside of the whisker range are marked with “+” symbols. ***p&lt;0.001, n.s. - no statistical significance (p&gt;0.05).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Comparison of different dimensionality reduction techniques.</title><p>Dimensionality reduction was applied to the input features for each approach (parcel-space: N=148; voxel-space: N=15684; hybrid-space: N=1295; <xref ref-type="bibr" rid="bib51">Maaten and Postma, 2009</xref>). The results with principal component analysis (PCA, in green), multi-dimensional scaling (MDS, in blue), minimum redundant maximum relevance algorithm (MRMR, in red), linear discriminant analysis (LDA, in black) are shown in comparison to performance obtained using all input features (in magenta). For parcel-space input features, all these approaches increased the mean decoding accuracy with PCA and LDA (both of which result in extraction of orthogonal features) showing statistically significant improvement (one-way ANOVA: <italic>F</italic>=13.05, p&lt;0.001; post hoc Tukey tests: p=0.032; PCA: p&lt;0.001; LDA: p&gt;0.05). For voxel-space features, there was no statistically significant improvement with any of the approaches (p&gt;0.05). While MRMR resulted in the largest voxel-space decoding accuracy improvement, it was not statistically significant (post hoc Tukey test: p=0.14), and application of LDA dimensionality reduction actually reduced performance dramatically. Uniquely for hybrid-space features—all dimensionality reduction techniques improved decoding performance significantly (one-way ANOVA: <italic>F</italic>=21.32; post hoc Tukey tests: p&lt;0.05) with the best largest improvement observed following application of LDA. Center line of box plots indicates the group median, while notches represent the 95% confidence interval of the group median. Box limits indicate the 1st and 3rd quartiles while whisker lengths are set at the extreme value ≤1.5×IQR. Outlier values located outside of the whisker range are marked with “+” symbols. ***p&lt;0.001, **p&lt;0.01, *p&lt;0.05, n.s. - no statistical significance (<italic>p</italic>&gt;0.05).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig3-figsupp2-v1.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>ICA artefacts do not contribute to decoding.</title><p>(<bold>A</bold>) Example of ICA component time-series for components labeled as artifacts from a single subject during MEG data pre-processing. The features of these components are consistent with known motion and physiological artifacts in MEG data. (<bold>B</bold>) 4-class confusion matrix and (<bold>C</bold>) decoding performance of keypress action labels from ICA components labeled as artifacts and removed from the MEG data during pre-processing. These components failed to predict keypress labels above empirically determined chance levels (as shown by decoding performance after random label shuffling). Note that in all cases, decoding performance from movement and physiological artifacts was substantially lower than 4-class MEG hybrid-space decoding for all participants. (<bold>D</bold>) Head position was assessed at the beginning and at the end of each recording and used to measure head movement. The mean measured head movement across the study group was 1.159 mm (±1.077 SD). Center line of the box plot indicates the group median, while notches represent the 95% confidence interval of the group median. Box limits indicate the 1st and 3rd quartiles while whisker lengths are set at the extreme value ≤1.5×IQR. Outlier values located outside of the whisker range are marked with “+” symbols.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig3-figsupp3-v1.tif"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 4.</label><caption><title>Confusion matrices for decoding performance on <italic>Day 2 Retest</italic> (<bold>A</bold>) and <italic>Day 2 Control</italic> (<bold>B</bold>) data.</title><p>Note that the hybrid-space decoding strategy generalized to Day 2 data with 87.11% overall accuracy for keypresses embedded within the trained sequence (<italic>Day 2 Retest</italic>) and 79.44% overall accuracy for keypresses embedded within untrained control sequences (<italic>Day 2 Control</italic>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig3-figsupp4-v1.tif"/></fig><fig id="fig3s5" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 5.</label><caption><title>Decoding performance across temporal scales.</title><p>(<bold>A</bold>) Average decoding accuracies across participants with varying window parameters. The x-axis indicates the onset of the time window (in ms) used to relate MEG activity time series to individual keypresses (i.e. KeyDown event = 0ms), while the y-axis indicates the window duration (in ms). The heatmap color denotes the decoding accuracy for all window onset/duration pairings. The best decoding accuracy across subjects was obtained using a window duration of 200ms with the leading edge aligned to the KeyDown event (i.e. 0ms; marked by the dashed lines and open circle). (<bold>B</bold>) Decoder window parameters (onset and duration) used for each subject in reported decoder accuracy comparisons (<xref ref-type="fig" rid="fig2">Figures 2</xref>—<xref ref-type="fig" rid="fig4">4</xref>). Please note that the group-optimal set of parameters (window onset = 0ms; window duration = 200ms; LDA dimensionality reduction) was utilized for all contextualization analyses (<xref ref-type="fig" rid="fig5">Figure 5</xref>) to allow for comparison across participants. Center line of box plots indicates the group median, while notches represent the 95% confidence interval of the group median. Box limits indicate the 1st and 3rd quartiles while whisker lengths are set at the extreme value ≤1.5×IQR. Outlier values located outside of the whisker range are marked with “+” symbols.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig3-figsupp5-v1.tif"/></fig><fig id="fig3s6" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 6.</label><caption><title>Comparison of decoding performances with two different hybrid approaches.</title><p>Hybrid<sub>Overlap</sub> (regional voxel-space features from top-ranked parcels combined with all whole-brain parcel-space features as shown in <xref ref-type="fig" rid="fig3">Figure 3B</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplements 1; 3</xref>–<xref ref-type="fig" rid="fig3s5">5</xref> of the manuscript) and Hybrid<sub>Non-overlap</sub> (regional voxel-space features of top-ranked parcels and spatially <italic>non-overlapping</italic> whole-brain parcel-space features). Filled circle markers represent decoding accuracy for individual subjects. Dashed lines indicate within-subject performance changes between decoding approaches. Note that the Hybrid<sub>Overlap</sub> (the approach used in our manuscript) significantly outperforms the Hybrid<sub>Non-overlap</sub> approach (Wilcoxon signed rank test, <italic>z</italic>=3.7410, p=1.8326e-04), despite the removed features (n=8) only comprising less than 1% of the overall input feature space. These results indicate that the spatially overlapping <italic>whole-brain</italic> (lower resolution) <italic>parcel-space</italic> and <italic>regional</italic> (higher resolution) <italic>voxel-space</italic> features provide complementary—as opposed to redundant—information to the hybrid-space decoder. Center line of box plots indicates the group median, while notches represent the 95% confidence interval of the group median. Box limits indicate the 1st and 3rd quartiles while whisker lengths are set at the extreme value ≤1.5×IQR.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig3-figsupp6-v1.tif"/></fig><fig id="fig3s7" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 7.</label><caption><title>Comparison of different decoder methods.</title><p>Performance for all different machine learning decoders assessed is shown for each participant. The results show that the linear discriminant analysis (LDA) classifier outperformed other methods, on average, across the group. Decoding analysis performance comparisons reported in the current study utilized the LDA decoder for all subjects. Center line of box plots indicates the group median, while notches represent the 95% confidence interval of the group median. Box limits indicate the 1st and 3rd quartiles while whisker lengths are set at the extreme value ≤1.5×IQR. Outlier values located outside of the whisker range are marked with “+” symbols.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig3-figsupp7-v1.tif"/></fig></fig-group><p>We implemented different dimensionality reduction or manifold extraction strategies including principal component analysis (PCA), multi-dimensional scaling (MDS), minimum redundant maximum relevance (MRMR), and linear discriminant analysis (LDA; <xref ref-type="bibr" rid="bib51">Maaten and Postma, 2009</xref>) to map the input feature (parcel, voxel, or hybrid) space to a low-dimensional latent space (<xref ref-type="bibr" rid="bib58">Natraj et al., 2022</xref>). LDA-based manifold extraction led to the greatest classifier performance gains, improving keypress decoding accuracy to 90.47% ± SD 3.44% (<xref ref-type="fig" rid="fig3">Figure 3B</xref>; weighted mean F1 score = 0.91 ± SD 0.05). In comparison to the hybrid-space decoder, whole-brain parcel-space decoder performance also improved following LDA-based dimensionality reduction (82.95% ± SD 5.48%), while whole-brain voxel-space decoder accuracy dropped substantially (40.38% ± SD 6.78%; also see <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>).</p><p>Notably, decoding of index finger keypresses (executed at two different ordinal positions in the sequence) exhibited the highest false negative (0.115 per keypress) and false positive (0.067 per prediction) misclassification rates compared with all other digits (false negative rate range = [0.067 0.114]; false positive rate range = [0.085 0.131]; <xref ref-type="fig" rid="fig3">Figure 3C</xref>), raising the hypothesis that the same action could be differentially represented when executed within different contexts (i.e. at different locations within the skill sequence). Testing the keypress state (4-class) hybrid decoder performance on Day 1 after randomly shuffling keypress labels for held-out test data resulted in a performance drop approaching expected chance levels (22.12% ± SD 9.1%; <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3C</xref>). An alternate decoder trained on ICA components labeled as movement or physiological artifacts (e.g. head movement, ECG, eye movements, and blinks; <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3A, D</xref>) and removed from the original input feature set during the pre-processing stage approached chance-level performance (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>), indicating that the 4-class hybrid decoder results were not driven by task-related artifacts.</p><p>Utilizing the highest performing decoders that included LDA-based manifold extraction, we assessed the robustness of hybrid-space decoding over multiple sessions by applying it to data collected on the following day during the <italic>Day 2 Retest</italic> (9-trial retest of the trained sequence) and <italic>Day 2 Control</italic> (single-trial performance of 9 different untrained sequences) blocks. The decoding accuracy for <italic>Day 2</italic> MEG data remained high (87.11% ± SD 8.54% for the trained sequence during <italic>Retest</italic>, and 79.44% ± SD 5.54% for the untrained <italic>Control</italic> sequences; <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>). Thus, index finger classifiers constructed using the hybrid decoding approach robustly generalized from Day 1 to Day 2 across trained and untrained keypress sequences.</p></sec><sec id="s2-2"><title>Inclusion of keypress sequence context location optimized decoding performance</title><p>Next, we tracked the trial-by-trial evolution of keypress action manifolds as training progressed. Within-subject keypress neural representations progressively differentiated during early learning. A representative example in <xref ref-type="fig" rid="fig4">Figure 4A</xref> (top row) depicts increased four-digit representation clustering across trials 1, 11, and 36. The cortical representation of these clusters changed over the course of training, beginning with predominant involvement of contralateral pre-central areas in trial 1 before transitioning to greater contralateral post-central, superior frontal, and middle frontal cortex contributions in trials 11 and 36 (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, bottom row), paralleling improvements in decoding performance (see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> for trial-by-trial quantitative feature importance score changes during skill learning).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Evolution of keypress neural representations with skill learning.</title><p>(<bold>A</bold>) Keypress neural representations differentiate during early learning. t-SNE distribution of neural representation of each keypress (top scatter plots) is shown for trial 1 (start of training; top-left), 11 (end of early learning; top-center), and 36 (end of training; top-right) for a single representative participant. Individual keypress manifold representation clustering in trial 11 (top-center; end of early learning) depicts sub-clustering for the index finger keypress performed at the two different ordinal positions in the sequence (Index<sub>OP1</sub> and Index<sub>OP5</sub>), which remains present by trial 36 (top-right). Spatial distribution of regional contributions to decoding (bottom brain surface maps). The surface color heatmap indicates feature importance scores across the brain. Note that decoding contributions shifted from contralateral right pre-central cortex at trial 1 (bottom-left) to contralateral superior and middle frontal cortex at trials 11 (bottom-center) and 36 (bottom-right). (<bold>B</bold>) Confusion matrix for 5-class decoding of individual sequence items. Decoders were trained to classify contextual representations of the keypresses (i.e. 5-class classification of the sequence elements 4-1-2-3-4). Note that the decoding accuracy increased to 94.15% ± SD 4.84% and the misclassification of keypress 4 was significantly reduced (from 141 to 82). (<bold>C</bold>) Trial-by-trial classification accuracy for 2-class decoder (Index<sub>OP1</sub> vs. Index<sub>OP5</sub>). A decoder (200ms window duration aligned to the KeyDown event) was trained to differentiate between the two index finger keypresses embedded at different positions within the practiced skill sequence (Index<sub>OP1</sub>=index finger keypress at ordinal position 1 of the sequence; Index<sub>OP5</sub>=index finger keypress at ordinal position 5 of the sequence). Decoder accuracy progressively improved over early learning, stabilizing around 96% by trial 11 (end of early learning). Similar results were observed for other decoding window sizes (50, 100, 150, 250, and 300ms; see <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). Taken together, these findings indicate that the neural feature space evolves over early learning to incorporate sequence location information. Shaded region indicates the 95% confidence interval of the group mean.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Quantification of trial-by-trial parcel-space feature importance scores during skill learning.</title><p>Trial-by-trial changes in parcel-space feature importance scores are shown for right superior frontal, middle frontal, pre-central, and post-central cortex (i.e. the contralateral regions showing the highest regional voxel-space decoding accuracy). Note that the feature importance is initially higher for the contralateral pre-central cortex in early trials before shifting towards the contralateral middle and superior frontal cortex during later trials, as can be seen with the divergence of line plots beginning around trial 11.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Trial-by-trial classification accuracy for 2-class decoder (Index<sub>OP1</sub> vs. Index<sub>OP5</sub>)<italic>.</italic></title><p>Several decoders (with varying window durations aligned to the KeyDown event) were trained to differentiate between the two index finger keypresses embedded at different positions within the practiced skill sequence (Index<sub>OP1</sub> at ordinal position 1 vs. Index<sub>OP5</sub> at ordinal position 5). Decoding accuracy for the 200ms duration windows (i.e. the optimal window size for 5-class decoding of individual keypresses) progressively improves over early learning, stabilizing around 96% by trial 11 (end of early learning). Similar results were observed for all other decoding window sizes (50, 100, 150, 250, and 300ms), with overall accuracy slightly lower compared to 200ms. These findings indicate that the neural representations of the skill action are updated over early learning to incorporate sequence location information. Shaded regions indicate the 95% confidence interval of the group mean.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig4-figsupp2-v1.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>Eye movement features do not contribute to decoding.</title><p>(<bold>A</bold>) Scatter plot of gaze positions at the KeyDown event and 200ms after the KeyDown event (i.e. beginning and ending of window used for decoding keypress labels from MEG input features) from a representative participant. Transparent gray dots indicate all sampled gaze positions during practice trials. The overall mean gaze position during practice trials is indicated by the black filled circle marker. Colored right-pointing triangle markers indicate the gaze position at the KeyDown event for each ordinal position keypress (Index<sub>OP1</sub> – magenta; Little<sub>OP2</sub> – yellow; Middle<sub>OP3</sub> – blue; Ring<sub>OP4</sub> – green; Index<sub>OP5</sub> – brown), while left-pointing triangle markers indicate the gaze position 200ms after the KeyDown event. The mean gaze position for these two time points is indicated by the larger-sized triangle markers. On average, gaze position is largely fixed for the OP1 and OP3 keypresses, moves from left to right for OP2 and OP4 keypresses, and from right to left for OP5 keypresses (which is when the asterisk moves leftward from the last sequence item back to the first). (<bold>B</bold>) Confusion matrix showing that three eye movement features fail to predict asterisk position on the task display above chance levels (Fold 1 test accuracy = 0.21718; Fold 2 test accuracy = 0.22023; Fold 3 test accuracy = 0.21859; Fold 4 test accuracy = 0.22113; Fold 5 test accuracy = 0.21373; Overall cross-validated accuracy = 0.2181). Since the ordinal position of the asterisk on the display is highly correlated with the ordinal position of individual keypresses in the sequence, this analysis provides strong evidence that keypress decoding performance from MEG features is not explained by systematic relationships between finger movement behavior and eye movements (i.e. behavioral artifacts). (<bold>C</bold>) 5-class decoding of ordinal position keypress labels from eye movement recording features approached empirically determined chance levels (as shown by decoding performance after random label shuffling). Note that all decoding performances from eye movement data were substantially lower than MEG hybrid-space decoding for all participants. Sample distribution means are indicated by the solid blue horizontal line with the 95% confidence interval of the group mean indicated by the shaded blue rectangular box.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig4-figsupp3-v1.tif"/></fig></fig-group><p>The trained skill sequence required pressing the index finger twice (<bold>4</bold>-1-3-2-<bold>4</bold>) at two contextually different ordinal positions (sequence positions 1 and 5). Inclusion of sequence location information (i.e. sequence context) for each keypress action (five sequence elements with the one keypress represented twice at two different locations) improved decoding accuracy (<italic>t</italic>=7.09, p&lt;0.001, df = 25, Cohen’s <italic>d</italic>=0.86, <xref ref-type="fig" rid="fig4">Figure 4B</xref>) from 90.47% (± SD 3.44%) to 94.15% (± SD 4.84%; weighted mean F1 score: 0.94), and reduced overall misclassifications by 54.3% (from 219 to 119; <xref ref-type="fig" rid="fig3">Figures 3C</xref> and <xref ref-type="fig" rid="fig4">4B</xref>). The improved decoding accuracy is supported by greater differentiation in neural representations of the index finger keypresses performed at positions 1 and 5 of the sequence (<xref ref-type="fig" rid="fig4">Figure 4A</xref>), and by the trial-by-trial increase in 2-class decoding accuracy over early learning (<xref ref-type="fig" rid="fig4">Figure 4C</xref>) across different decoder window durations (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). As expected, the 5-class hybrid-space decoder performance approached chance levels when tested with randomly shuffled keypress labels (18.41% ± SD 7.4% for Day 1 data; <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3C</xref>). Task-related eye movements did not explain these results since an alternate 5-class decoder constructed from three eye movement features (gaze position at the KeyDown event, gaze position 200ms later, and peak eye movement velocity within this window; <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3A</xref>) performed at chance levels (cross-validated test accuracy = 0.2181; <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3B, C</xref>).</p><p>On Day 2, incorporating contextual information into the hybrid-space decoder enhanced classification accuracy for the trained sequence only (improving from 87.11% for 4-class to 90.22% for 5-class), while performing at or below-chance levels for the control sequences (≤30.22% ± SD 0.44%). Thus, the accuracy improvements resulting from inclusion of contextual information in the decoding framework were specific to the trained skill sequence.</p></sec><sec id="s2-3"><title>Neural representation of keypress sequence location diverged during early skill learning</title><p>We used a Euclidean distance measure to evaluate the differentiation of the neural representation manifold of the same action (i.e. an index-finger keypress) executed within different local sequence contexts (i.e. ordinal position 1 vs. ordinal position 5; <xref ref-type="fig" rid="fig5">Figure 5</xref>). To make these distance measures comparable across participants, a new set of classifiers was then trained with group-optimal parameters (i.e. broadband hybrid-space MEG data with subsequent manifold extraction <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>) and LDA classifiers (<xref ref-type="fig" rid="fig3s7">Figure 3—figure supplement 7</xref>) trained on 200ms duration windows aligned to the KeyDown event (see Materials and methods, <xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref>).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Neural representation distance between index finger keypresses performed at two different ordinal positions within a sequence.</title><p>(<bold>A</bold>) Contextualization increases over Early Learning during Day 1 Training. Online (green) and offline (purple) neural representation distances (contextualization) between two index finger key presses performed at ordinal positions 1 and 5 of the trained sequence (4-1-3-2-4) are shown for each trial during Day 1 Training. Both online and offline contextualization between the two index finger representations increases sharply over Early Learning before stabilizing across later Day 1 Training trials. Shaded regions indicate the 95% confidence interval of the group mean. (<bold>B</bold>) Contextualization develops predominantly during rest periods (offline) on Day 1. The cumulative neural representation differences during early learning were significantly greater over rest (Offline contextualization; right) than during practice (Online contextualization; left) periods (t=4.84, p&lt;0.001, df = 25, Cohen’s d=1.2). Center line of box plot indicates the group median, while notches represent the 95% confidence interval of the group median. Box limits indicate the 1st and 3rd quartiles while whisker lengths are set at the extreme value ≤1.5×IQR. (<bold>C</bold>) Contextualization acquired on Day 1 was retained on Day 2 specifically for the trained sequence. The neural representation differences assessed across both rest and practice for the trained sequence (4-1-3-2-4) were retained at Day 2 Retest. This is in stark contrast with the reduction in contextualization for several untrained sequences controlling for: (1) index finger keypresses located at the same ordinal positions 1 and 5 but within a different intervening sequence pattern (Pattern Specificity Control: 4-2-3-1-4, 51.05% lower contextualization); (2) use of a finger different than the index (little or ring finger) in both ordinal positions 1 and 5 (Finger Specificity Control: 2-1-3-4-2, 1-4-2-3-1 and 2-3-1-4-2; 35.80% lower contextualization); and (3) multiple index finger keypresses occurring at ordinal positions other than 1 and 5 (Position Specificity Control: 4-2-4-3-1 and 1-4-3-4-2; 22.06% lower contextualization). Note that offline contextualization cannot be measured for the Day 2 Control sequences as each sequence was only performed over a single trial. Error bars indicate S.E.M.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Relationship between offline neural representational changes and micro-offline learning.</title><p>(<bold>A</bold>) Relationship between offline neuronal representational changes and micro-offline learning. Offline contextualization—calculated as the Euclidian distance between the neural representations observed for the first Index<sub>OP1</sub> keypress from practice trial, <italic>n</italic>, and the last Index<sub>OP5</sub> keypress from practice trial, <italic>n-1</italic>—increased over early learning. A linear regression analysis (shown in the inset) revealed a strong temporal relationship (correlation coefficient [<italic>r</italic>]=0.903 and coefficient of variance explained [R<sup>2</sup>]=0.816) between contextualization and cumulative micro-offline gains over early learning. Shaded regions indicate the 95% confidence interval of the group mean. (<bold>B</bold>) Changes in offline contextualization for different decoding window durations as a function of rest breaks. We constructed decoders from different MEG input feature time windows (window durations of 50, 100, 150, 200, 250, and 300ms; all aligned to the KeyDown event), to assess the robustness of the offline contextualization finding with respect to this parameter selection. Offline contextualization showed similar trends for all options tested. (<bold>C</bold>) Relationship between offline neural representational changes and micro-offline learning across all window durations. The linear regression analysis from (<bold>A</bold>) was repeated for all contextualization measures from (<bold>B</bold>) obtained after varying the MEG input feature window size (50–300ms). This strong temporal relationship was observed for all window durations (0.598 ≥ R<sup>2</sup>≥0.816), except for 300ms (R<sup>2</sup>=0.284) where temporal overlap of individual keypress features was most prominent.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig5-figsupp1-v1.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Trial-by-trial trends for different measurement approaches of offline and online contextualization changes.</title><p>(<bold>A</bold>) Offline contextualization between the last sequence of a preceding trial and the <underline>second</underline> sequence of the subsequent one (skipping the first sequence of that trial) rendered a comparable result to the measure reported in <xref ref-type="fig" rid="fig5">Figure 5</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> which use the first sequence—inconsistent with a possible confounding effect of pre-planning (<xref ref-type="bibr" rid="bib1">Ariani and Diedrichsen, 2019</xref>). Shaded regions indicate the 95% confidence interval of the group mean. (<bold>B</bold>) Two different measurement approaches were used to characterize online contextualization changes. The <italic>sequence-based</italic> approach calculated the mean distance between Index<sub>OP1</sub> and Index<sub>OP5</sub> for each correct sequence iteration within a trial (green). A second <italic>trial-based</italic> approach was also implemented, which controlled for the passage of time between observations used in both online and offline distance measures (10 s between Index<sub>OP1</sub> and Index<sub>OP5</sub> observations in both cases). Note that the <italic>trial-based</italic> approach showed no increase in online contextualization over early learning. Importantly, the overall magnitude of online contextualization by the end of early learning was similar for both measurement approaches, and both showed reduced online relative to offline contextualization. Shaded regions indicate the 95% confidence interval of the group mean.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig5-figsupp2-v1.tif"/></fig><fig id="fig5s3" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 3.</label><caption><title>Online contextualization versus micro-online learning.</title><p>The relationship between online contextualization and online learning is shown for both <italic>sequence-</italic> (<bold>A</bold>, left) and <italic>trial-based</italic> (<bold>B</bold>, right) distance measurement approaches. There was no significant relationship between online learning and online contextualization regardless of the measurement approach. Shaded regions indicate the 95% confidence interval of the group mean.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig5-figsupp3-v1.tif"/></fig><fig id="fig5s4" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 4.</label><caption><title>Within-subject correlations between online and offline contextualization changes versus learning.</title><p>Pirate plots displaying individual subject correlation coefficients for offline (i.e. over rest) and online (i.e. during practice) contextualization changes versus micro-offline and -online performance gains. Zero correlation is marked by the horizontal dashed line. Distribution means are indicated by the solid black horizontal line with the 95% confidence interval of the group mean indicated by the shaded rectangular box. Within-subject correlations were significantly greater for offline contextualization changes versus micro-offline performance gains than for online contextualization changes versus either micro-offline or -online performance gains. The average correlation between offline contextualization and micro-offline gains within individuals was significantly greater than zero (<bold>left;</bold> <italic>t</italic>=3.87, p=0.00035, df = 25, Cohen’s d=0.76) and stronger than correlations between online contextualization and either micro-online (<bold>middle</bold>; <italic>t</italic>=3.28, p=0.0015, df = 25, Cohen’s <italic>d</italic>=1.2) or micro-offline gains (<bold>right</bold>; <italic>t</italic>=3.7021, p=5.3013e-04, df = 25, Cohen’s <italic>d</italic>=0.69).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig5-figsupp4-v1.tif"/></fig><fig id="fig5s5" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 5.</label><caption><title>Online versus offline changes in keypress transition patterns.</title><p>(<bold>A</bold>) Trial-by-trial Euclidean distance between the relative share of each keypress transition time to the full sequence duration (i.e. differences in typing rhythm). This distance was calculated for the first and last sequence of each trial (online pattern distance; green) and the last sequence of a trial versus the first sequence of the next (offline pattern distance; purple). Shaded regions indicate the 95% confidence interval of the group mean. (<bold>B</bold>) Cumulative online (green; left) and offline (purple; right) pattern distances recorded over all forty-five trials covering Days 1 and 2. Note the comparable online and offline typing rhythm changes do not explain differences between online and offline contextualization, which is fully developed by trial 11 (<xref ref-type="fig" rid="fig5">Figure 5</xref>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig5-figsupp5-v1.tif"/></fig><fig id="fig5s6" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 6.</label><caption><title>The relationship between adjacent index finger transitions and online contextualization.</title><p>Scatter plot showing that the sum of adjacent index finger keypress transition times (i.e. the 4–4 transition at the conclusion of one sequence iteration and the 4–1 transition at the beginning of the next sequence iteration) versus online contextualization distances measured during practice trials. Both the keypress transition times and online contextualization scores were z-score normalized within individual subjects and then concatenated into a single data superset. A simple linear regression between keypress transition time predictor and the online contextualization response variable showed a very weak linear relationship between the two (R<sup>2</sup>=0.00507, F[1,3202]=16.3). This result shows that contextualization of index finger representations does not reflect the amount of overlap between adjacent keypresses.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig5-figsupp6-v1.tif"/></fig><fig id="fig5s7" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 7.</label><caption><title>Between-subject differences in typing speed versus online contextualization.</title><p>(<bold>A</bold>) Between-subject relationship between plateau performance speed and online contextualization. The plateau performance typing speed showed no significant relationship with the degree of online contextualization (<italic>R<sup>2</sup></italic>=0.028, p=0.41). Each dot represents the maximum speed attained and the corresponding degree of contextualization of each participant. Thus, the magnitude of online contextualization was not dependent on how fast individuals could perform the task at the end of early learning. (<bold>B</bold>) Trial-by-trial relationship between typing speed and degree of online contextualization. We also performed a trial-by-trial regression analysis that related the degree of online contextualization for each trial with the median typing speed for that trial. The R<sup>2</sup> values obtained for regression analyses performed on individual trials were also low and not statistically significant (mean <italic>R<sup>2</sup></italic>=0.06; p&gt;0.05). Red and black horizontal lines indicate the group median and mean R<sup>2</sup> values, respectively.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-fig5-figsupp7-v1.tif"/></fig></fig-group><p>The Euclidean distance between neural representations of Index<sub>OP1</sub> (i.e. index finger keypress at ordinal position 1 of the sequence) and Index<sub>OP5</sub> (i.e. index finger keypress at ordinal position 5 of the sequence) increased progressively during early learning (<xref ref-type="fig" rid="fig5">Figure 5A</xref>)—predominantly during rest intervals (<italic>offline contextualization</italic>) rather than during practice (<italic>online</italic>) (<italic>t</italic>=4.84, p&lt;0.001, df = 25, Cohen’s <italic>d</italic>=1.2; <xref ref-type="fig" rid="fig5">Figure 5B</xref>; <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1A</xref>). An alternative online contextualization determination equaling the time interval between online and offline comparisons (<italic>Trial-based;</italic> 10 s between Index<sub>OP1</sub> and Index<sub>OP5</sub> observations in both cases) rendered a similar result (<xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2B</xref>).</p><p>Offline contextualization strongly correlated with cumulative micro-offline gains (<italic>r</italic>=0.903, <italic>R²</italic>=0.816, p&lt;0.001; <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1A</xref>, inset) across decoder window durations ranging from 50 to 250 ms (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1B, C</xref>). The offline contextualization between the final sequence of each trial and the second sequence of the subsequent trial (excluding the first sequence) yielded comparable results. This indicates that pre-planning at the start of each practice trial did not directly influence the offline contextualization measure (<xref ref-type="bibr" rid="bib1">Ariani and Diedrichsen, 2019</xref>; <xref ref-type="fig" rid="fig5s2 fig5s1">Figure 5—figure supplements 2A</xref> <italic>1<sup>st</sup> vs. 2<sup>nd</sup> Sequence approaches</italic>). Conversely, online contextualization (using either measurement approach) did not explain early online learning gains (i.e. <xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>). Within-subject correlations were consistent with these group-level findings. The average correlation between offline contextualization and micro-offline gains within individuals was significantly greater than zero (<xref ref-type="fig" rid="fig5s4">Figure 5—figure supplement 4</xref>, left; <italic>t</italic>=3.87, p=0.00035, df = 25, Cohen’s <italic>d</italic>=0.76) and stronger than correlations between online contextualization and either micro-online (<xref ref-type="fig" rid="fig5s4">Figure 5—figure supplement 4</xref>, middle; <italic>t</italic>=3.28, p=0.0015, df = 25, Cohen’s <italic>d</italic>=1.2) or micro-offline gains (<xref ref-type="fig" rid="fig5s4">Figure 5—figure supplement 4</xref>, right; <italic>t</italic>=3.7021, p=5.3013e-04, df = 25, Cohen’s <italic>d</italic>=0.69). These findings were not explained by behavioral changes of typing rhythm (<italic>t</italic>=–0.03, p=0.976; <xref ref-type="fig" rid="fig5s5">Figure 5—figure supplement 5</xref>), adjacent keypress transition times (<italic>R<sup>2</sup></italic>=0.00507, F [1,3202]=16.3; <xref ref-type="fig" rid="fig5s6">Figure 5—figure supplement 6</xref>), or overall typing speed (between-subject; <italic>R<sup>2</sup></italic>=0.028, p=0.41; <xref ref-type="fig" rid="fig5s7">Figure 5—figure supplement 7</xref>).</p><p>Finally, contextualization of Index<sub>OP1</sub> vs. Index<sub>OP5</sub> representations observed on <italic>Day 1</italic> generalized to <italic>Day 2 Retest</italic> of the trained skill sequence. Distances between representations for the same keypress performed twice within untrained sequences were lower in magnitude (<italic>Day 2 Control</italic>)—pointing to specificity of the contextualization effect (<xref ref-type="fig" rid="fig5">Figure 5C</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>The main findings of this study during which subjects engaged in a naturalistic, self-paced task were that individual sequence action representations differentiate during early skill learning in a manner reflecting the local sequence context in which they were performed, and that the degree of representational differentiation—particularly prominent over rest intervals—correlated with skill gains.</p><sec id="s3-1"><title>Optimizing decoding of sequential finger movements from MEG activity</title><p>The initial phase of the study focused on optimizing the accuracy of decoding individual finger keypresses from MEG brain activity. Recent work showed that the brain simultaneously processes information more efficiently across multiple—rather than a single—spatial scale(s) (<xref ref-type="bibr" rid="bib56">Munn et al., 2024</xref>; <xref ref-type="bibr" rid="bib9">Buch et al., 2017</xref>). To this effect, we developed a novel hybrid-space approach designed to integrate neural representation dynamics over two different spatial scales: (1) <italic>whole-brain parcel-space</italic> (i.e. spatial activity patterns across all cortical brain regions) and (2) <italic>regional voxel-space</italic> (i.e. spatial activity patterns within select brain regions) activity. We found consistent spatial differences between whole-brain parcel-space feature importance (predominantly contralateral frontoparietal, <xref ref-type="fig" rid="fig2">Figure 2B</xref>) and regional voxel-space decoder accuracy (bilateral sensorimotor regions, <xref ref-type="fig" rid="fig2">Figure 2D</xref>). The <italic>whole-brain parcel-space</italic> decoder likely emphasized more stable activity patterns in contralateral frontoparietal regions that differed between individual finger movements (<xref ref-type="bibr" rid="bib3">Beukema et al., 2019</xref>; <xref ref-type="bibr" rid="bib47">Lemon, 2008</xref>), while the <italic>regional voxel-space</italic> decoder likely incorporated information related to adaptive interhemispheric interactions operating during motor sequence learning (<xref ref-type="bibr" rid="bib9">Buch et al., 2017</xref>; <xref ref-type="bibr" rid="bib83">Zimerman et al., 2014</xref>; <xref ref-type="bibr" rid="bib78">Waters et al., 2017</xref>), particularly pertinent when the skill is performed with the non-dominant hand (<xref ref-type="bibr" rid="bib68">Sawamura et al., 2019</xref>; <xref ref-type="bibr" rid="bib45">Lee et al., 2019</xref>; <xref ref-type="bibr" rid="bib30">Grafton et al., 2002</xref>). The observation of increased cross-validated test accuracy (as shown in <xref ref-type="fig" rid="fig3s6">Figure 3—figure supplement 6</xref>) indicates that the spatially overlapping information in parcel- and voxel-space time-series in the hybrid decoder was complementary, rather than redundant (<xref ref-type="bibr" rid="bib81">Yu and Liu, 2004</xref>). The hybrid-space decoder, which achieved an accuracy exceeding 90%—and robustly generalized to Day 2 across trained and untrained sequences—surpassed the performance of both parcel-space and voxel-space decoders and compared favorably to other neuroimaging-based finger movement decoding strategies (<xref ref-type="bibr" rid="bib10">Buch et al., 2021</xref>; <xref ref-type="bibr" rid="bib46">Lee et al., 2022</xref>; <xref ref-type="bibr" rid="bib48">Liao et al., 2014</xref>; <xref ref-type="bibr" rid="bib62">Quandt et al., 2012</xref>; <xref ref-type="bibr" rid="bib42">Kornysheva et al., 2019</xref>).</p><p>Evaluation of individual brain oscillatory activity revealed that low-frequency oscillations (LFOs) result in higher decoding accuracy compared to other narrow-band activity (<xref ref-type="bibr" rid="bib58">Natraj et al., 2022</xref>; <xref ref-type="bibr" rid="bib64">Reddy et al., 2021</xref>). Task-related movements—which also express in lower frequency ranges—did not explain these results given the near chance-level performance of alternative decoders trained on (a) artifact-related ICA components removed during MEG pre-processing (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3A–C</xref>) and on (b) task-related eye movement features (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3B, C</xref>). This explanation is also inconsistent with the minimal average head motion of 1.159 mm (±1.077 SD) across the MEG recording (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3D</xref>). How could LFOs contribute to keypress decoding accuracy? LFOs, observed during movement onset in the cerebral cortex of animals (<xref ref-type="bibr" rid="bib2">Bansal et al., 2011</xref>; <xref ref-type="bibr" rid="bib55">Mollazadeh et al., 2011</xref>) and humans (<xref ref-type="bibr" rid="bib5">Bönstrup et al., 2019b</xref>; <xref ref-type="bibr" rid="bib15">Cruikshank et al., 2012</xref>; <xref ref-type="bibr" rid="bib74">Tomassini et al., 2017</xref>), encode information about movement trajectories and velocity (<xref ref-type="bibr" rid="bib2">Bansal et al., 2011</xref>; <xref ref-type="bibr" rid="bib55">Mollazadeh et al., 2011</xref>). They also contain information related to movement timing (<xref ref-type="bibr" rid="bib63">Ramanathan et al., 2018</xref>; <xref ref-type="bibr" rid="bib34">Hall et al., 2014</xref>; <xref ref-type="bibr" rid="bib73">Stefanics et al., 2010</xref>), preparation (<xref ref-type="bibr" rid="bib25">Flint et al., 2012</xref>; <xref ref-type="bibr" rid="bib43">Krasoulis et al., 2014</xref>), sensorimotor integration (<xref ref-type="bibr" rid="bib15">Cruikshank et al., 2012</xref>), kinematics (<xref ref-type="bibr" rid="bib25">Flint et al., 2012</xref>; <xref ref-type="bibr" rid="bib43">Krasoulis et al., 2014</xref>) and may contribute to the precise temporal coordination of movements required for sequencing (<xref ref-type="bibr" rid="bib13">Churchland et al., 2012</xref>). Within clinical contexts, LFOs in the frontoparietal regions, resulting in high decoding accuracy in the present study, have been linked to recovery of motor function after brain lesions like stroke (<xref ref-type="bibr" rid="bib5">Bönstrup et al., 2019b</xref>; <xref ref-type="bibr" rid="bib63">Ramanathan et al., 2018</xref>; <xref ref-type="bibr" rid="bib26">Frohlich et al., 2021</xref>).</p></sec><sec id="s3-2"><title>Neural representations of individual sequence actions differentiate during early skill learning</title><p>Next, we exploited the hybrid decoding approach to investigate if individual sequence action representations differentiate or remain stable during early skill learning, when the memory is not yet fully formed (<xref ref-type="bibr" rid="bib4">Bönstrup et al., 2019a</xref>). The first hint of representational differentiation was the highest false-negative and lowest false-positive misclassification rates for index finger keypresses performed at different locations in the sequence compared with all other digits (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). This was further supported by the progressive differentiation of neural representations of the index finger keypress (<xref ref-type="fig" rid="fig4">Figure 4A</xref>) and by the robust trial-by-trial increase in 2-class (Index<sub>OP1</sub> vs Index<sub>OP5</sub>) decoding accuracy across time windows ranging between 50 and 250ms (<xref ref-type="fig" rid="fig4">Figure 4C</xref>; <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). Further, the 5-class classifier—which directly incorporated information about the sequence location context of each keypress into the decoding pipeline—improved decoding accuracy relative to the 4-class classifier (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). Importantly, testing on Day 2 revealed specificity of this representational differentiation for the trained skill but not for the same keypresses performed during various unpracticed control sequences (<xref ref-type="fig" rid="fig5">Figure 5C</xref>).</p><p>The main region contributing information to representational differentiation during early practice (trials 1–10) was the primary motor cortex, followed by the somatosensory cortex (trial 11), both of which are known to be actively engaged in skill acquisition (<xref ref-type="bibr" rid="bib10">Buch et al., 2021</xref>; <xref ref-type="bibr" rid="bib39">Karni et al., 1995</xref>; <xref ref-type="bibr" rid="bib14">Classen et al., 1998</xref>; <xref ref-type="bibr" rid="bib40">Kleim et al., 1998</xref>; <xref ref-type="bibr" rid="bib44">Kumar et al., 2019</xref>; <xref ref-type="bibr" rid="bib61">Pavlides et al., 1993</xref>). Concurrently, information from the superior frontal and middle frontal cortex—which encodes hierarchical structures of skill sequences (<xref ref-type="bibr" rid="bib80">Yokoi and Diedrichsen, 2019</xref>)—steadily increased in importance and emerged as the two most crucial decoding contributors once skill performance plateau had been reached (trials 15–36; <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>; <xref ref-type="bibr" rid="bib36">Hikosaka et al., 1999</xref>; <xref ref-type="bibr" rid="bib19">Dayan and Cohen, 2011</xref>). Thus, the neural substrates supporting finger movements and their representational differentiation during early skill learning (the time period during which 95% skill gains in the training session occur <xref ref-type="bibr" rid="bib4">Bönstrup et al., 2019a</xref>; <xref ref-type="bibr" rid="bib60">Pan and Rickard, 2015</xref>, trials 1–11 in this study) differed from those supporting stable performance during the subsequent skill plateau period (<xref ref-type="bibr" rid="bib39">Karni et al., 1995</xref>; <xref ref-type="bibr" rid="bib66">Robertson and Cohen, 2006</xref>; trials 12–36 in this study).</p></sec><sec id="s3-3"><title>Differentiation of neural representations developed predominantly during rest periods interspersed with practice</title><p>We then focused on the timeline of differentiation of index finger keypress neural representations—which we refer to as contextualization—over early learning. We found that contextualization increased progressively during early learning—predominantly during short rest breaks (offline) rather than during practice (online; <xref ref-type="fig" rid="fig5">Figure 5</xref>, <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2B</xref>). Offline contextualization consistently correlated with early learning gains across a range of decoding windows (50–250ms; <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). This result remained unchanged when measuring offline contextualization between the last and second sequence of consecutive trials, inconsistent with a possible confounding effect of pre-planning (<xref ref-type="bibr" rid="bib1">Ariani and Diedrichsen, 2019</xref>; <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2A</xref>). On the other hand, online contextualization did not predict learning (<xref ref-type="fig" rid="fig5s3">Figure 5—figure supplement 3</xref>). Consistent with these results, the average within-subject correlation between offline contextualization and micro-offline gains was significantly stronger than within-subject correlations between online contextualization and either micro-online or micro-offline gains (<xref ref-type="fig" rid="fig5s4">Figure 5—figure supplement 4</xref>).</p><p>Offline contextualization was not driven by trial-by-trial behavioral differences, including typing rhythm (<xref ref-type="fig" rid="fig5s5">Figure 5—figure supplement 5</xref>) and adjacent keypress transition times (<xref ref-type="fig" rid="fig5s6">Figure 5—figure supplement 6</xref>) nor by between-subject differences in overall typing speed (<xref ref-type="fig" rid="fig5s7">Figure 5—figure supplement 7</xref>)—ruling out a reliance on differences in the temporal overlap of keypresses. Importantly, offline contextualization documented on Day 1 stabilized once a performance plateau was reached (trials 11–36) and was retained on Day 2, documenting overnight consolidation of the differentiated neural representations. A possible neural mechanism supporting contextualization could be the emergence and stabilization of conjunctive ‘what–where’ representations of procedural memories (<xref ref-type="bibr" rid="bib41">Komorowski et al., 2009</xref>) with the corresponding modulation of neuronal population dynamics (<xref ref-type="bibr" rid="bib28">Georgopoulos, 1994</xref>; <xref ref-type="bibr" rid="bib27">Georgopoulos et al., 1982</xref>) during early learning. Exploring the link between contextualization and neural replay could provide additional insights into this issue (<xref ref-type="bibr" rid="bib10">Buch et al., 2021</xref>; <xref ref-type="bibr" rid="bib12">Chen et al., 2024</xref>; <xref ref-type="bibr" rid="bib71">Sjøgård, 2024</xref>; <xref ref-type="bibr" rid="bib32">Griffin et al., 2025</xref>).</p><p>In this study, classifiers were trained on MEG activity recorded during or immediately after each keypress, emphasizing neural representations related to action execution, memory consolidation, and recall over those related to planning. An important direction for future research is determining whether separate decoders can be developed to distinguish the representations or networks separately supporting these processes. Ongoing work in our lab is addressing this question. The present accuracy results across varied decoding window durations and alignment with each keypress action support the feasibility of this approach (<xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref>).</p></sec><sec id="s3-4"><title>Limitations</title><p>One limitation of this study is that contextualization was investigated for only one finger movement (index finger or digit 4) embedded within a relatively short 5-item skill sequence. Determining if representational contextualization is exhibited across multiple finger movements embedded within, for example, longer sequences (e.g. two index finger and two little finger keypresses performed within a short piece of piano music) will be an important extension to the present results. While a supervised manifold learning approach (LDA) was used here because it optimized hybrid-space decoder performance, unsupervised strategies (e.g. PCA and MDS, which also substantially improved decoding accuracy in the present study; <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>), are likely more suitable for real-time BCI applications. Finally, caution should be exercised when extrapolating findings during early skill learning, a period of steep performance improvements, to findings reported after insufficient practice (<xref ref-type="bibr" rid="bib17">Das et al., 2024</xref>), post-plateau performance periods (<xref ref-type="bibr" rid="bib33">Gupta and Rickard, 2022</xref>), or non-learning situations (e.g. performance of non-repeating keypress sequences in <xref ref-type="bibr" rid="bib17">Das et al., 2024</xref>) when reactive inhibition or contextual interference effects are prominent. Ultimately, it will be important to develop new paradigms allowing one to independently estimate the different coincident or antagonistic features (e.g. memory consolidation, planning, working memory, and reactive inhibition) contributing to micro-online and micro-offline gains during and after early skill learning within a unifying framework.</p></sec><sec id="s3-5"><title>Summary</title><p>In summary, individual sequence action representations contextualize during early learning of a new skill, and the degree of differentiation parallels skill gains. Differentiation of the neural representations developed during rest intervals of early learning to a larger extent than during practice in parallel with rapid consolidation of skill. It is possible that the systematic inclusion of contextualized information into sequence skill practice environments could improve learning in areas as diverse as music education, sports training, and rehabilitation of motor skills after brain lesions.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Study participants</title><p>The study was approved by the Combined Neuroscience Institutional Review Board of the National Institutes of Health (NIH). A total of thirty-three young and healthy adults (16 females) with a mean age of 26.6 years (±0.87 SEM) participated in the study after providing written informed consent and undergoing a standard neurological examination. No participants were actively engaged in playing musical instruments in their daily lives, as per guidelines outlined in prior research (<xref ref-type="bibr" rid="bib67">Ruiz et al., 2009</xref>; <xref ref-type="bibr" rid="bib52">Maidhof et al., 2009</xref>). All study scientific data were de-identified and permanently unlinked from all personal identifiable information (PII) before the analysis. These data are publicly available (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.18112/openneuro.ds006502.v1.0.0">https://doi.org/10.18112/openneuro.ds006502.v1.0.0</ext-link>; Accession Number: ds006502). Two participants were excluded from the analysis due to MEG system malfunction during data acquisition. An additional 5 subjects were excluded because they failed to generate any correct sequences in two or more consecutive trials. The study was powered to determine the minimum sample size needed to detect a significant change in skill performance following training using a one-sample t-test (two-sided; alpha = 0.05; 95% statistical power; Cohen’s <italic>d</italic> effect size = 0.8115 calculated from previously acquired data in our lab <xref ref-type="bibr" rid="bib11">Censor et al., 2014</xref>). The calculated minimum sample size was 22. The included study sample size (n=26) exceeded this minimum (<xref ref-type="bibr" rid="bib4">Bönstrup et al., 2019a</xref>).</p></sec><sec id="s4-2"><title>Experimental setup</title><p>Participants practiced a procedural motor skill learning task that involved repetitively typing a 5-item numerical sequence (4-1-3-2-4) displayed on a computer screen. They were instructed to perform the task as quickly and accurately as possible on a response pad (Cedrus LS-LINE, Cedrus Corp) using their non-dominant, left hand. Each numbered sequence item corresponded to a specific finger keypress: 1 for the little finger, 2 for the ring finger, 3 for the middle finger, and 4 for the index finger. Individual keypress times and identities were recorded and used to assess skill learning and performance. The response pad was positioned in a manner that minimized wrist, arm, or more proximal body movements during the task. The head was restrained with an inflatable air bladder, and head position was assessed at the beginning and at the end of each recording. The mean measured head movement across the study group was 1.159 mm (±1.077 SD; <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>).</p><p>Participants practiced the skill for 36 trials. Each trial spanned a total of 20 s and included a 10 s practice round followed by a 10 s rest break. The study design followed specific recommendations by <xref ref-type="bibr" rid="bib60">Pan and Rickard, 2015</xref>: (1) utilizing 10 s practice trials and (2) constraining analysis of micro-offline gains to early learning trials (where performance monotonically increases and 95% of overall performance gains occur) that precede the emergence of ‘scalloped’ performance dynamics strongly linked to reactive inhibition effects (<xref ref-type="bibr" rid="bib60">Pan and Rickard, 2015</xref>; <xref ref-type="bibr" rid="bib7">Brawn et al., 2010</xref>). This is precisely the portion of the learning curve Pan and Rickard referred to when they stated “…<italic>rapid learning during that period masks any reactive inhibition effect”</italic> (<xref ref-type="bibr" rid="bib60">Pan and Rickard, 2015</xref>)<italic>.</italic></p><p>The five-item sequence was displayed on the computer screen for the duration of each practice round, and participants were directed to fix their gaze on the sequence. Small asterisks were displayed above a sequence item after each successive keypress, signaling the participants' present position within the sequence. Inclusion of this feedback minimizes working memory loads during task performance (<xref ref-type="bibr" rid="bib75">Walker et al., 2002</xref>). Following the completion of a full sequence iteration, the asterisk returned to the first sequence item. The asterisk did not provide error feedback as it appeared for both correct and incorrect keypresses. At the end of each practice round, the displayed number sequence was replaced by a string of five ‘X’ symbols displayed on the computer screen, which remained for the duration of the rest break. Participants were instructed to focus their gaze on the screen during this time. The behavior in this explicit, motor learning task consists of generative action sequences rather than sequences of stimulus-induced responses as in the serial reaction time task (SRTT). A similar real-world example would be manually inputting a long password into a secure online application in which one intrinsically generates the sequence from memory and receives similar feedback about the password sequence position (also provided as asterisks), which is typically ignored by the user.</p><p>On the next day, participants were tested (<italic>Day 2 Retest</italic>) with the same trained sequence (4-1-3-2-4) for nine trials as well as for nine different unpracticed control sequences (<italic>Day 2 Control</italic>; 2-1-3-4-2; 4-2-4-3-1; 3-4-2-3-1; 1-4-3-4-2; 3-2-4-3-1; 1-4-2-3-1; 3-2-4-2-1; 2-3-1-4-2; 4-2-3-1-4) each for one trial. The practice schedule structure for Day 2 was the same as Day 1, with 10 s practice trials interleaved with 10 s rest breaks.</p></sec><sec id="s4-3"><title>Behavioral data analysis</title><sec id="s4-3-1"><title>Skill</title><p>Skill, in the context of the present task, is quantified as the <italic>correct sequence typing speed</italic>, (i.e. the number of correctly typed sequence keypresses per second; kp/s). That is, improvements in the speed/accuracy trade-off equate to greater skill. Keypress transition times (KTT) were calculated as the difference in time between the <italic>keyDown</italic> events recorded for consecutive keypresses. Since the sequence was repeatedly typed within a single trial, individual keypresses were marked as correct if they were members of a five consecutive keypress set that matched any possible circular shift of the displayed five-item sequence. The instantaneous correct sequence speed was calculated as the inverse of the average KTT across a single correct sequence iteration and was updated for each correct keypress. Trial-by-trial skill changes were assessed by computing the median correct sequence typing speed for each trial.</p></sec><sec id="s4-3-2"><title>Early learning</title><p>The <italic>early learning</italic> period was defined as the trial range (1 T trials) over which 95% of the total skill performance was first attained at the group level. We quantified this by fitting the group average trial-by-trial correct sequence speed data with an exponential model of the form:<disp-formula id="equ1"><alternatives><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:mn>2</mml:mn><mml:mtext> </mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>k</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="t1">\begin{document}$$\displaystyle L\left (t\right)=C1+C2\ \left (1-e^{-kt}\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>Here, the trial number is denoted by <italic>t</italic>, and <italic>L(t)</italic> signifies the group-averaged performance at trial <italic>t</italic>. Parameters <italic>C1</italic> and <italic>C2</italic> correspond to the pre-training performance baseline and asymptote, respectively, while <italic>k</italic> denotes the learning rate. The values for <italic>C1</italic>, <italic>C2</italic>, and <italic>k</italic> were computed using a constrained nonlinear least-squares method (MATLAB’s lsqcurvefit function, trust-region-reflective algorithm) and were determined to be 0.5, 0.15, and 0.2, respectively. The early learning trial cut-off, denoted as <italic>T</italic>, was identified as the first trial where 95% of the learning had been achieved. In this study, <italic>T</italic> was determined to be trial 11.</p></sec><sec id="s4-3-3"><title>Micro-offline and -online gains</title><p>Performance improvements over each 10 s rest break (<italic>micro-offline gains)</italic> were calculated as the net performance change (instantaneous correct sequence typing speed) from the end of one practice period to the onset of the next, while <italic>micro-online gains</italic> were computed as the net performance change over a single practice trial. Total early learning was derived as the sum of all <italic>micro-online</italic> and <italic>micro-offline</italic> gains over trials 1–11. Cumulative micro-offline gains, micro-online gains, and total early learning were statistically compared using one-way ANOVAs and post-hoc Tukey tests. Possible pre-planning effects on initial skill performance (<xref ref-type="bibr" rid="bib1">Ariani and Diedrichsen, 2019</xref>) were assessed by using paired t-tests to statistically compare cumulative micro-offline and -online computed for all keypresses with their measurement counterparts calculated after omitting the first 3 keypresses in each trial from the correct sequence speed computation.</p></sec></sec><sec id="s4-4"><title>MRI acquisition</title><p>We acquired T1-weighted high-resolution anatomical MRI volumes images (1 mm<sup>3</sup> isotropic MPRAGE sequence) for each participant on a 3T MRI scanner (GE Excite HDxt or Siemens Skyra) equipped with a 32-channel head coil. These data allowed for spatial co-registration of an individual participant’s brain with the MEG sensors, and individual head models required for surface-based cortical dipole estimation from MEG signals (i.e. MEG source-space modeling).</p></sec><sec id="s4-5"><title>MEG acquisition</title><p>We recorded continuous magnetoencephalography (MEG) at a sampling frequency of 600 Hz using a CTF 275 MEG system (CTF Systems, Inc, Canada) while participants were seated in an upright position. The MEG system comprises a whole-head array featuring 275 radial 1<sup>st</sup>-order gradiometer/SQUID channels housed in a magnetically shielded room (Vacuumschmelze, Germany). Three of the gradiometers (two non-functional and one with high channel noise after visual inspection) were excluded from the analysis resulting in a total of 272 useable MEG sensor channels. Synthetic third-order gradient balancing was applied to eliminate background noise in real-time data collection. Temporal alignment of behavioral and MEG data was achieved using a TTL trigger. Head position in the scanner coordinate space was assessed at the beginning and end of each recording using head localization coils at the nasion, left, and right pre-auricular locations. These fiducial positions were co-registered in the participants’ T1-MRI coordinate space using a stereotactic neuronavigation system (BrainSight, Rogue Research Inc). MEG data was acquired starting 6 min before the task (resting-state baseline) and continued through the end of the 12 min training session.</p></sec><sec id="s4-6"><title>MEG data analysis</title><sec id="s4-6-1"><title>Preprocessing</title><p>MEG data were preprocessed using the FieldTrip (<xref ref-type="bibr" rid="bib59">Oostenveld et al., 2011</xref>) and EEGLAB (<xref ref-type="bibr" rid="bib21">Delorme and Makeig, 2004</xref>) toolboxes on MATLAB 2022a. Continuous raw MEG data were band-pass filtered between 1–100 Hz with a fourth-order noncausal Butterworth filter. 60 Hz line noise was removed with a narrow-band discrete Fourier transform (DFT) notch filter. Independent component analysis (ICA) was used to remove typical MEG signal artifacts associated with eye blinks or movement, muscle contraction or cardiac pulsation. All recordings were visually inspected and marked to denoise segments containing other large amplitude artifacts due to movements. Eye movements were simultaneously recorded with MEG (EyeLink 1000 Plus).</p></sec><sec id="s4-6-2"><title>Source reconstruction and parcellation</title><p>For each participant, individual volume conduction models were computed to estimate the propagation of brain-generated currents through tissue resulting in externally measurable magnetic fields. This was accomplished through a single-shell head corrected-sphere approach based on the brain volume segmentation of the participant’s high-resolution T1 MRI. Source models and surface labels from the Desikan-Killiany Atlas (<xref ref-type="bibr" rid="bib22">Destrieux et al., 2010</xref>) were created for each participant using inner-skull and pial layer surfaces obtained through FreeSurfer segmentation (<xref ref-type="bibr" rid="bib16">Dale et al., 1999</xref>; <xref ref-type="bibr" rid="bib53">Marcus et al., 2011</xref>) and Connectome Workbench resampling (<xref ref-type="bibr" rid="bib16">Dale et al., 1999</xref>; <xref ref-type="bibr" rid="bib53">Marcus et al., 2011</xref>). Aligning sensor positions in the MEG helmet to individual head space involved rigid-body registration of the mean MEG head coil position to the same fiducial locations marked in the MRI and applying the same affine transformation to all MEG sensors.</p><p>The individual source, volume conduction model, and sensor positions were then utilized to generate the forward solution at each source dipole location, describing the propagation of source activity from each cortical location on the grid to each MEG sensor. The Linearly Constrained Minimum-Variance (LCMV) beamformer was employed for computing the inverse solution. Each trial of MEG activity contributed to calculating the inverse solution data covariance matrix. The individual sample noise covariance matrix was derived from 6 min of pre-training rest MEG data recorded in the same subject during the same session. A total of 15,684 surface-based cortical dipoles (i.e. source-space voxels) were estimated.</p><p>Source-space parcellation was carried out by averaging all voxel time-series located within distinct anatomical regions defined in the Desikan-Killiany Atlas (<xref ref-type="bibr" rid="bib22">Destrieux et al., 2010</xref>). Since source time-series estimated with beamforming approaches are inherently sign-ambiguous, a custom Matlab-based implementation of the <italic>mne.extract_label_time_course</italic> with ‘<italic>mean_flip’</italic> sign-flipping procedure in MNE-Python (<xref ref-type="bibr" rid="bib31">Gramfort et al., 2013</xref>) was applied prior to averaging to prevent within-parcel signal cancellation. All voxel time-series within each parcel were extracted, and the time series sign was flipped at locations where the orientation difference was greater than 90° from the parcel mode. A mean time series was then computed across all voxels within the parcel after sign-flipping.</p></sec></sec><sec id="s4-7"><title>Feature selection for decoding</title><p>Several MEG activity features were extracted over different spatial, spectral, and temporal scales.</p><sec id="s4-7-1"><title>Oscillatory analysis</title><p>MEG signals were constrained to broadband (1–100 Hz) or standard neural oscillatory frequency bands defined as delta (1–3 Hz), theta (4–7 Hz), alpha (8–14 Hz), beta (15–24 Hz), gamma (25–50 Hz), and high-gamma (51–100 Hz) using a fourth-order non-causal Butterworth filter. Subsequent decoding analyses were independently conducted for each band of MEG activity.</p></sec><sec id="s4-7-2"><title>Spatial analysis</title><p>Decoding was performed in both sensor and source spaces. The sensor-space decoding feature dimension was 272 (corresponding to the 272 usable MEG channels), while source-space decoding was carried out at both the higher feature dimension voxel (i.e. higher spatially sampled; N=15,684) and lower feature dimension parcel space (i.e. lower spatially sampled; N=148) across all oscillatory frequency bands (i.e. broadband, delta, theta, alpha, beta, gamma, and high-gamma) for comprehensive comparison.</p></sec><sec id="s4-7-3"><title>Temporal analysis</title><p>MEG activity time series corresponding to each keypress was defined using the time window, [t + △t], where t ∈ [0 : 10ms: 100ms] and △t ∈ [25ms: 25ms: 350ms]. In other words, a sliding window of variable width (from 25 ms to 350 ms with 25ms increments), and with onsets ranging from the <italic>keyDown</italic> event (i.e. t=0ms) to +100ms after the <italic>keyDown</italic> event (with increments of 10ms) was used. This approach generated a set of 140 different time windows associated with each keypress for each participant. MEG activity was averaged over time within each of these windows and independently analyzed for decoding. The optimal time window was selected for each subject that resulted in the maximum cross-validation performance (<xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref>). This window optimization analysis was performed for each frequency band and spatial scale.</p></sec><sec id="s4-7-4"><title>Hybrid spatial approach</title><p>First, we evaluated the decoding performance of each individual brain region in accurately decoding finger keypresses from regional voxel-space (i.e. all voxels within a brain region as defined by the Desikan-Killiany Atlas) activity. Brain regions were then ranked from 1 to 148 based on their decoding accuracy at the group level. In a stepwise manner, we then constructed a ‘hybrid-space’ decoder by incrementally concatenating regional voxel-space activity of brain regions—starting with the top-ranked region—with whole-brain parcel-level features and assessed decoding accuracy. Subsequently, we added the regional voxel-space features of the second-ranked brain region and continued this process until decoding accuracy reached saturation. The optimal ‘hybrid-space’ input feature set over the group included the 148 parcel-space features and regional voxel-space features from a total of 8 brain regions (bilateral superior frontal, middle frontal, pre-central, and post-central; N=1295 ± 20 features).</p></sec><sec id="s4-7-5"><title>Dimension reduction</title><p>We independently applied several supervised and unsupervised dimension reduction techniques as an additional feature extraction step for each broadband MEG activity space (i.e. sensor, parcel, voxel, and hybrid), including: linear discriminant analysis (LDA), minimum redundant maximum relevance (MRMR), principal component analysis (PCA), Autoencoder, Diffusion maps, factor analysis, large margin nearest neighbor (LMNN), multi-dimensional scaling (MDS), neighbor component analysis (NCA), spatial predictor envelope (SPE; <xref ref-type="bibr" rid="bib51">Maaten and Postma, 2009</xref>). Among these techniques, PCA, MDS, MRMR, and LDA emerged as particularly effective in significantly improving decoding performance across all broadband MEG activity spaces.</p><p>PCA, a method for unsupervised dimensionality reduction, transforms the high-dimensional dataset into a new coordinate system of orthogonal principal components. These components, capturing the maximum variance in the data, were iteratively added to reconstruct the feature space and execution of decoding. MDS finds a configuration of points in a lower-dimensional space such that the distances between these points reflect the dissimilarities or similarities between the corresponding objects in the original high-dimensional space. MRMR, an approach combining relevance and redundancy metrics, ranks features based on their significance to the target variable and their non-redundancy with other features. The decoding process started with the highest-ranked feature and iteratively incorporated subsequent features until decoding accuracy reached saturation. LDA finds the linear combinations of features (dimensions) that best separate different classes in a dataset. It projects the original features onto a lower-dimensional space (number of classes –1) while preserving the class-discriminatory information. This transformation maximizes the ratio of the between-class variance to the within-class variance. In our study, LDA transformed the features to a 3/4-dimensional hyperdimensional space that was used for decoding. Dimension reduction was first applied to training data, and then with the tuned parameters of the dimension reduction model, an independent test data subset was transformed for decoder metrics evaluation. Decoding accuracies were systematically compared between the original and reduced dimension feature spaces, providing insight into the effectiveness of each dimension reduction technique. By rigorously assessing the impact of dimension reduction on decoding accuracy, the study aimed to identify techniques that not only reduced the computational burden associated with high-dimensional data but also enhanced the discriminative power of the selected features. This comprehensive approach aimed at optimizing the neural representation of each finger keypress for decoding performance across various spatial contexts.</p></sec></sec><sec id="s4-8"><title>Decoding analysis</title><p>Decoding analysis was conducted for each participant individually, employing a randomized split of the data into independent training (90%) and test (10%) samples over eight iterations. For each iteration, an eightfold cross-validation was applied to the training samples to optimize decoder configuration, allowing for the fine-tuning of hyperparameters and selection of the most effective model. On average, the total number of individual keypress samples for the entire duration of training was 219 ± SD: 66 (keypress 1: little), 205 ± SD: 66 (keypress 2: ring), 209±66 (keypress 3: middle), and 426 ± SD: 131 (keypress 4: index) across participants. Only keypresses belonging to correctly typed sequence iterations (94.64% ± 4.04% of all keypresses) were considered. The total number of index finger keypresses (i.e. keypress 4) was approximately twice that of the others, as it was the only action that occurred more than once in the trained sequence (4-1-3-2-4), albeit at two different ordinal positions. Considering the higher (2 x) number of samples for one-class, we independently oversampled the keypresses 1, 2, and 3 to avoid overfitting to the over-represented class. Importantly, oversampling was applied independently for each keypress class, ensuring that validation folds were never oversampled, and training folds did not share common oversampled patterns. The decoder configuration demonstrating the best validation performance was selected for each iteration, and subsequently, test accuracy was evaluated on the independent/unseen test samples. This process was repeated for the eight different iterations of train-test splitting, and the average test accuracy over all iterations was reported. This rigorous methodology aimed at generalizing decoding performance to ensure robust and reliable results across participants. Finally, decoding evaluation was also performed on the Day 2 data, for both the trained (<italic>Day 2 Retest;</italic> 9 trials) and untrained sequences (<italic>Day 2 Control</italic>; 9 different single-trial tests).</p><sec id="s4-8-1"><title>Machine learning classifiers</title><p>We employed a diverse set of machine learning-based decoders—including Naïve Bayes (NB), decision trees (DT), ensembles (EN), k-nearest neighbor (KNN), linear discriminant analysis (LDA), support vector machines (SVM), and artificial neural network (ANN)—to train features generated over all possible combinations of spatial and temporal scales and oscillation frequency-bands in order to carry out a comprehensive comparative analysis. The hyperparameters of these decoders underwent fine-tuning using Bayesian optimization search.</p><p>All NB classifiers were configured with a normal distribution predictor and Gaussian Kernel, while KNN classifiers had a K value of 4 (for keypress decoding) and utilized the Euclidean distance metric. For DT classifiers, the maximum number of splits was set to 4 (for keypress decoding), with leaves being merged based on the sum of risk values greater than or equal to the risk associated with the parent node. The optimal sequence of pruned trees was estimated, and the predictor selection method was 'Standard CART’, selecting the split predictor that maximizes the split-criterion gain over all possible splits of all predictors. The split criterion used was 'gdi' (Gini’s diversity index). EN classifiers employed the bagging method with random predictor selections at each split, forming a random forest. The maximum number of learning cycles was set to 100 with a weak learner based on discriminant analysis. For SVM, the RBF kernel was selected through cross-validation (CV), and the 'C' parameter and kernel scale were optimized using Bayesian optimization search. In the case of LDA, the linear coefficient threshold and the amount of regularization were computed based on Bayesian optimization search. Finally, all ANN decoders consisted of one hidden layer with 128 nodes, followed by a sigmoid and a softmax layer, each with four nodes (for keypress decoding). Training utilized a scaled conjugate gradient optimizer with backpropagation, employing a learning rate of 0.01 (coarse to fine tuning) for a maximum of 100 epochs, with early stopping validation patience set to 6 epochs.</p></sec><sec id="s4-8-2"><title>Decoding performance metric</title><p>Decoding performance was assessed using several metrics, including accuracy (%), which indicates the proportion of correct classifications among all test samples. Confusion matrices provide a detailed comparison of the number of correctly predicted samples for each class against the ground truth. The F1 score—defined as the harmonic mean of the precision (percentage of true predictions that are actually true positive) and recall (percentage of true positives that were correctly predicted as true) scores—was used as a comprehensive metric for each one-versus-all keypress state decoder to assess class-wise performance that accounts for both false-positive and false-negative prediction tendencies (<xref ref-type="bibr" rid="bib65">Rijsbergen, 1979</xref>; <xref ref-type="bibr" rid="bib70">Schütze et al., 2008</xref>). A weighted mean F1 score was then computed across all classes to assess the overall prediction performance of the multi-class model. Test accuracies based on the best decoder performance (LDA in our case) were reported and used for statistical comparisons.</p></sec><sec id="s4-8-3"><title>Decoding during skill learning progression</title><p>We systematically assessed decoding performance of a 2-class decoder (Index<sub>OP1</sub> vs Index<sub>OP5</sub>; i.e. decoding of two index finger keypresses occurring at different locations within the training sequence) at each trial during the skill learning process to capture the evolving relationship between differentiated index finger decoding proficiency and the acquired skill. Our approach involved evaluating decoder performance individually for each <italic>Day 1 Training</italic> trial. We ensured an equal number of samples (first <italic>k</italic> keypresses) in each trial were used to mitigate the influence of increasing samples available in later trials.</p><p>We used t-distributed stochastic neighborhood estimation (t-SNE) to visualize the evolution of neural representations corresponding to each keypress at each trial of the learning period. Within t-SNE distributions, index finger keypresses were separately labeled based upon their sequence location (i.e. Index<sub>OP1</sub> and Index<sub>OP5</sub> for ordinal positions 1 and 5, respectively).</p></sec><sec id="s4-8-4"><title>Decoding sequence elements</title><p>We performed 5-class decoding of each action based on its location within the sequence (i.e. Index<sub>OP1</sub>, Little, Middle, Ring, and Index<sub>OP5</sub>). The same decoding strategy was utilized as for the above 4-class keypress-based decoding (i.e. 90%–10% split for train and test, 8-fold cross-validation of training samples to select best decoder configuration, hybrid spatial features, and LDA-based dimension reduction). Note, oversampling was not needed after sub-grouping the index finger keypresses into two separate classes based on their sequence context. 5-class sequence-based decoding was evaluated for both <italic>Day 1 Training</italic>, <italic>Day 2 Retest,</italic> and <italic>Day 2 Control</italic> data.</p></sec><sec id="s4-8-5"><title>Feature importance scores</title><p>The relative contribution of source-space voxels and parcels to decoding performance (i.e. feature importance score) was calculated using minimum redundant maximum relevance (MRMR; <xref ref-type="bibr" rid="bib23">Ding and Peng, 2005</xref>) and highlighted in topography plots. MRMR, an approach that combines both relevance and redundancy metrics, ranked individual features based upon their significance to the target variable (i.e. keypress state identity) prediction accuracy and their non-redundancy with other features.</p></sec></sec><sec id="s4-9"><title>Neural representation analysis</title><p>We evaluated the <italic>online</italic> (within-trial) and <italic>offline</italic> (between-trial) changes in the neural representation of the contextual actions (Index<sub>OP1</sub> and Index<sub>OP5</sub>) for each trial during training. For offline differentiation, we evaluated the Euclidean distance between the hybrid spatial features of the last index finger keypress of a trial (Index<sub>OP5</sub>) to the first index finger keypress (Index<sub>OP1</sub>) of the subsequent trial, mirroring the approach used to calculate micro-offline gains in skill. This offline distance provided insight into the net change in contextual representation of the index finger keypress over each interleaved rest break. For online differentiation, we calculated either the mean Euclidean distance between Index<sub>OP1</sub> and Index<sub>OP5</sub> of all the correctly typed sequences (<italic>sequence-based</italic>) or the distance between the first Index<sub>OP1</sub> and last Index<sub>OP5</sub> (<italic>trial-based</italic>) within the same practice trial. Online differentiation informed on the net change in the contextual representation of the index finger keypress occurring within each practice trial. Cumulative offline and online representation distances across participants were statistically compared using paired <italic>t</italic>-tests. As a control analysis, we computed the difference in neural representation between Index<sub>OP1</sub> and Index<sub>OP5</sub> on <italic>Day 2 Retest</italic> data for the same sequence (<bold>4</bold>-1-3-2-<bold>4</bold>) as well as for different <italic>Day 2 Control</italic> untrained sequences where the same action was performed at ordinal positions 1 and 5 (<bold>2</bold>-1-3-4-<bold>2; 1</bold>-4-2-3-<bold>1; 2</bold>-3-1-4-<bold>2; 4</bold>-2-3-1-<bold>4</bold>). We also assessed for specificity of contextualization to the trained sequence, by evaluating differentiation between index finger keypress representations performed at two different positions within untrained sequences (<bold>4</bold>-2-<bold>4</bold>-3-1 and 1-<bold>4</bold>-3-<bold>4</bold>-2). The cumulative differences were compared across participants with paired <italic>t</italic>-tests.</p><p>Finally, we computed trial-by-trial differences in offline and online representations during early learning, exploring their temporal relationships with cumulative micro-offline and -online gains in skill, respectively, through regression analysis and Pearson correlation analysis. Linear regression models were trained utilizing the <italic>fitlm</italic> function in MATLAB. The model employed M-estimation, formulating estimating equations and solving them through the Iteratively Reweighted Least Squares (IRLS) method (<xref ref-type="bibr" rid="bib37">Holland and Welsch, 1977</xref>). Key metrics such as the square root of the mean squared error (RMSE), which estimates the standard deviation of the prediction error distribution, the coefficient of explained variance (<italic>R<sup>2</sup></italic>), the F-statistic as a test statistic for the F-test on the regression model, examining whether the model significantly outperforms a degenerate model consisting only of a constant term, and the p-value for the F-test on the model were computed and compared across different models. This multifaceted approach aimed to uncover the nuanced dynamics of neural representation changes in response to skill acquisition.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Data curation, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con7"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: The study was approved by the Combined Neuroscience Institutional Review Board of the National Institutes of Health (NIH). All participants provided written informed consent for the study.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-102475-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All de-identified and permanently unlinked from all personal identifiable information (PII) data are publicly available on the <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.18112/openneuro.ds006502.v1.0.0">OpenNeuro platform</ext-link>. All custom analysis code is available in a publicly accessible repository hosted on <ext-link ext-link-type="uri" xlink:href="https://github.com/hcps-ninds/SequenceActionRepresentationsContextualizeDuringEarlySkillLearning">GitHub</ext-link> (copy archived at <xref ref-type="bibr" rid="bib18">Dash and hcps-ninds, 2025</xref>).</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Bönstrup</surname><given-names>M</given-names></name><name><surname>Buch</surname><given-names>ER</given-names></name><name><surname>Cohen</surname><given-names>LG</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>Skill learning and consolidation in healthy humans</data-title><source>OpenNeuro</source><pub-id pub-id-type="doi">10.18112/openneuro.ds006502.v1.0.0</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Ms. Tasneem Malik, Ms. Michele Richman, NIMH MEG Core Facility staff, and NIH NMRF and FMRIF Core Facility staff for their support. This work utilized the computational resources of the NIH HPC Biowulf cluster (<ext-link ext-link-type="uri" xlink:href="http://hpc.nih.gov">http://hpc.nih.gov</ext-link>). This research was supported by the Intramural Research Program of the National Institutes of Health (NIH). The contributions of the NIH author(s) were made as part of their official duties as NIH federal employees, are in compliance with agency policy requirements, and are considered works of the United States Government. However, the findings and conclusions presented in this paper are those of the author(s) and do not necessarily reflect the views of the NIH or the U.S. Department of Health and Human Services.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ariani</surname><given-names>G</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Sequence learning is driven by improvements in motor planning</article-title><source>Journal of Neurophysiology</source><volume>121</volume><fpage>2088</fpage><lpage>2100</lpage><pub-id pub-id-type="doi">10.1152/jn.00041.2019</pub-id><pub-id pub-id-type="pmid">30969809</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bansal</surname><given-names>AK</given-names></name><name><surname>Vargas-Irwin</surname><given-names>CE</given-names></name><name><surname>Truccolo</surname><given-names>W</given-names></name><name><surname>Donoghue</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Relationships among low-frequency local field potentials, spiking activity, and three-dimensional reach and grasp kinematics in primary motor and ventral premotor cortices</article-title><source>Journal of Neurophysiology</source><volume>105</volume><fpage>1603</fpage><lpage>1619</lpage><pub-id pub-id-type="doi">10.1152/jn.00532.2010</pub-id><pub-id pub-id-type="pmid">21273313</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beukema</surname><given-names>P</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name><name><surname>Verstynen</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Binding during sequence learning does not alter cortical representations of individual actions</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>6968</fpage><lpage>6977</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2669-18.2019</pub-id><pub-id pub-id-type="pmid">31296537</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bönstrup</surname><given-names>M</given-names></name><name><surname>Iturrate</surname><given-names>I</given-names></name><name><surname>Thompson</surname><given-names>R</given-names></name><name><surname>Cruciani</surname><given-names>G</given-names></name><name><surname>Censor</surname><given-names>N</given-names></name><name><surname>Cohen</surname><given-names>LG</given-names></name></person-group><year iso-8601-date="2019">2019a</year><article-title>A rapid form of offline consolidation in skill learning</article-title><source>Current Biology</source><volume>29</volume><fpage>1346</fpage><lpage>1351</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.02.049</pub-id><pub-id pub-id-type="pmid">30930043</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bönstrup</surname><given-names>M</given-names></name><name><surname>Krawinkel</surname><given-names>L</given-names></name><name><surname>Schulz</surname><given-names>R</given-names></name><name><surname>Cheng</surname><given-names>B</given-names></name><name><surname>Feldheim</surname><given-names>J</given-names></name><name><surname>Thomalla</surname><given-names>G</given-names></name><name><surname>Cohen</surname><given-names>LG</given-names></name><name><surname>Gerloff</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019b</year><article-title>Low-frequency brain oscillations track motor recovery in human stroke</article-title><source>Annals of Neurology</source><volume>86</volume><fpage>853</fpage><lpage>865</lpage><pub-id pub-id-type="doi">10.1002/ana.25615</pub-id><pub-id pub-id-type="pmid">31604371</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bönstrup</surname><given-names>M</given-names></name><name><surname>Iturrate</surname><given-names>I</given-names></name><name><surname>Hebart</surname><given-names>MN</given-names></name><name><surname>Censor</surname><given-names>N</given-names></name><name><surname>Cohen</surname><given-names>LG</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Mechanisms of offline motor learning at a microscale of seconds in large-scale crowdsourced data</article-title><source>NPJ Science of Learning</source><volume>5</volume><elocation-id>7</elocation-id><pub-id pub-id-type="doi">10.1038/s41539-020-0066-9</pub-id><pub-id pub-id-type="pmid">32550003</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brawn</surname><given-names>TP</given-names></name><name><surname>Fenn</surname><given-names>KM</given-names></name><name><surname>Nusbaum</surname><given-names>HC</given-names></name><name><surname>Margoliash</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Consolidating the effects of waking and sleep on motor-sequence learning</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>13977</fpage><lpage>13982</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3295-10.2010</pub-id><pub-id pub-id-type="pmid">20962219</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brooks</surname><given-names>E</given-names></name><name><surname>Wallis</surname><given-names>S</given-names></name><name><surname>Hendrikse</surname><given-names>J</given-names></name><name><surname>Coxon</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Micro-consolidation occurs when learning an implicit motor sequence, but is not influenced by HIIT exercise</article-title><source>NPJ Science of Learning</source><volume>9</volume><elocation-id>23</elocation-id><pub-id pub-id-type="doi">10.1038/s41539-024-00238-6</pub-id><pub-id pub-id-type="pmid">38509108</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buch</surname><given-names>ER</given-names></name><name><surname>Liew</surname><given-names>SL</given-names></name><name><surname>Cohen</surname><given-names>LG</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Plasticity of sensorimotor networks: multiple overlapping mechanisms</article-title><source>The Neuroscientist</source><volume>23</volume><fpage>185</fpage><lpage>196</lpage><pub-id pub-id-type="doi">10.1177/1073858416638641</pub-id><pub-id pub-id-type="pmid">26985069</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buch</surname><given-names>ER</given-names></name><name><surname>Claudino</surname><given-names>L</given-names></name><name><surname>Quentin</surname><given-names>R</given-names></name><name><surname>Bönstrup</surname><given-names>M</given-names></name><name><surname>Cohen</surname><given-names>LG</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Consolidation of human skill linked to waking hippocampo-neocortical replay</article-title><source>Cell Reports</source><volume>35</volume><elocation-id>109193</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2021.109193</pub-id><pub-id pub-id-type="pmid">34107255</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Censor</surname><given-names>N</given-names></name><name><surname>Horovitz</surname><given-names>SG</given-names></name><name><surname>Cohen</surname><given-names>LG</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Interference with existing memories alters offline intrinsic functional brain connectivity</article-title><source>Neuron</source><volume>81</volume><fpage>69</fpage><lpage>76</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.10.042</pub-id><pub-id pub-id-type="pmid">24411732</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>PC</given-names></name><name><surname>Stritzelberger</surname><given-names>J</given-names></name><name><surname>Walther</surname><given-names>K</given-names></name><name><surname>Hamer</surname><given-names>H</given-names></name><name><surname>Staresina</surname><given-names>BP</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Hippocampal ripples during offline periods predict human motor sequence learning</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2024.10.06.614680</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Foster</surname><given-names>JD</given-names></name><name><surname>Nuyujukian</surname><given-names>P</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural population dynamics during reaching</article-title><source>Nature</source><volume>487</volume><fpage>51</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1038/nature11129</pub-id><pub-id pub-id-type="pmid">22722855</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Classen</surname><given-names>J</given-names></name><name><surname>Liepert</surname><given-names>J</given-names></name><name><surname>Wise</surname><given-names>SP</given-names></name><name><surname>Hallett</surname><given-names>M</given-names></name><name><surname>Cohen</surname><given-names>LG</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Rapid plasticity of human cortical movement representation induced by practice</article-title><source>Journal of Neurophysiology</source><volume>79</volume><fpage>1117</fpage><lpage>1123</lpage><pub-id pub-id-type="doi">10.1152/jn.1998.79.2.1117</pub-id><pub-id pub-id-type="pmid">9463469</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cruikshank</surname><given-names>LC</given-names></name><name><surname>Singhal</surname><given-names>A</given-names></name><name><surname>Hueppelsheuser</surname><given-names>M</given-names></name><name><surname>Caplan</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Theta oscillations reflect a putative neural mechanism for human sensorimotor integration</article-title><source>Journal of Neurophysiology</source><volume>107</volume><fpage>65</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1152/jn.00893.2010</pub-id><pub-id pub-id-type="pmid">21975453</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Sereno</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Cortical surface-based analysis</article-title><source>NeuroImage</source><volume>9</volume><fpage>179</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1006/nimg.1998.0395</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Das</surname><given-names>A</given-names></name><name><surname>Karagiorgis</surname><given-names>A</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name><name><surname>Stenner</surname><given-names>MP</given-names></name><name><surname>Azañón</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>“Micro-offline gains” convey no benefit for motor skill learning</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2024.07.11.602795</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Dash</surname><given-names>D</given-names></name><collab>hcps-ninds</collab></person-group><year iso-8601-date="2025">2025</year><data-title>SequenceActionRepresentationsContextualizeDuringEarlySkillLearning</data-title><version designator="swh:1:rev:11d27bc37017e6073e9cf44bf80d0e8856fecc64">swh:1:rev:11d27bc37017e6073e9cf44bf80d0e8856fecc64</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:0ba807c448770f0dbd2c76a7770968460c9c9457;origin=https://github.com/hcps-ninds/SequenceActionRepresentationsContextualizeDuringEarlySkillLearning;visit=swh:1:snp:365eeff833452df5c3212515d79528071d0c3e44;anchor=swh:1:rev:11d27bc37017e6073e9cf44bf80d0e8856fecc64">https://archive.softwareheritage.org/swh:1:dir:0ba807c448770f0dbd2c76a7770968460c9c9457;origin=https://github.com/hcps-ninds/SequenceActionRepresentationsContextualizeDuringEarlySkillLearning;visit=swh:1:snp:365eeff833452df5c3212515d79528071d0c3e44;anchor=swh:1:rev:11d27bc37017e6073e9cf44bf80d0e8856fecc64</ext-link></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>E</given-names></name><name><surname>Cohen</surname><given-names>LG</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Neuroplasticity subserving motor skill learning</article-title><source>Neuron</source><volume>72</volume><fpage>443</fpage><lpage>454</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.10.008</pub-id><pub-id pub-id-type="pmid">22078504</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Wacongne</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Pallier</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The neural representation of sequences: From transition probabilities to algebraic patterns and linguistic trees</article-title><source>Neuron</source><volume>88</volume><fpage>2</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.019</pub-id><pub-id pub-id-type="pmid">26447569</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delorme</surname><given-names>A</given-names></name><name><surname>Makeig</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>EEGLAB: an open source toolbox for analysis of single-trial EEG dynamics including independent component analysis</article-title><source>Journal of Neuroscience Methods</source><volume>134</volume><fpage>9</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2003.10.009</pub-id><pub-id pub-id-type="pmid">15102499</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Destrieux</surname><given-names>C</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Dale</surname><given-names>A</given-names></name><name><surname>Halgren</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Automatic parcellation of human cortical gyri and sulci using standard anatomical nomenclature</article-title><source>NeuroImage</source><volume>53</volume><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.06.010</pub-id><pub-id pub-id-type="pmid">20547229</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>C</given-names></name><name><surname>Peng</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Minimum redundancy feature selection from microarray gene expression data</article-title><source>Journal of Bioinformatics and Computational Biology</source><volume>3</volume><fpage>185</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1142/s0219720005001004</pub-id><pub-id pub-id-type="pmid">15852500</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doyon</surname><given-names>J</given-names></name><name><surname>Benali</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Reorganization and plasticity in the adult brain during learning of motor skills</article-title><source>Current Opinion in Neurobiology</source><volume>15</volume><fpage>161</fpage><lpage>167</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2005.03.004</pub-id><pub-id pub-id-type="pmid">15831397</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flint</surname><given-names>RD</given-names></name><name><surname>Ethier</surname><given-names>C</given-names></name><name><surname>Oby</surname><given-names>ER</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name><name><surname>Slutzky</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Local field potentials allow accurate decoding of muscle activity</article-title><source>Journal of Neurophysiology</source><volume>108</volume><fpage>18</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1152/jn.00832.2011</pub-id><pub-id pub-id-type="pmid">22496527</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frohlich</surname><given-names>J</given-names></name><name><surname>Toker</surname><given-names>D</given-names></name><name><surname>Monti</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Consciousness among delta waves: a paradox?</article-title><source>Brain</source><volume>144</volume><fpage>2257</fpage><lpage>2277</lpage><pub-id pub-id-type="doi">10.1093/brain/awab095</pub-id><pub-id pub-id-type="pmid">33693596</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Georgopoulos</surname><given-names>AP</given-names></name><name><surname>Kalaska</surname><given-names>JF</given-names></name><name><surname>Caminiti</surname><given-names>R</given-names></name><name><surname>Massey</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>On the relations between the direction of two-dimensional arm movements and cell discharge in primate motor cortex</article-title><source>The Journal of Neuroscience</source><volume>2</volume><fpage>1527</fpage><lpage>1537</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.02-11-01527.1982</pub-id><pub-id pub-id-type="pmid">7143039</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Georgopoulos</surname><given-names>AP</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Population activity in the control of movement</article-title><source>International Review of Neurobiology</source><volume>37</volume><fpage>103</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1016/s0074-7742(08)60241-x</pub-id><pub-id pub-id-type="pmid">7883475</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghilardi</surname><given-names>MF</given-names></name><name><surname>Moisello</surname><given-names>C</given-names></name><name><surname>Silvestri</surname><given-names>G</given-names></name><name><surname>Ghez</surname><given-names>C</given-names></name><name><surname>Krakauer</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Learning of a sequential motor skill comprises explicit and implicit components that consolidate differently</article-title><source>Journal of Neurophysiology</source><volume>101</volume><fpage>2218</fpage><lpage>2229</lpage><pub-id pub-id-type="doi">10.1152/jn.01138.2007</pub-id><pub-id pub-id-type="pmid">19073794</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grafton</surname><given-names>ST</given-names></name><name><surname>Hazeltine</surname><given-names>E</given-names></name><name><surname>Ivry</surname><given-names>RB</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Motor sequence learning with the nondominant left hand: a PET functional imaging study</article-title><source>Experimental Brain Research</source><volume>146</volume><fpage>369</fpage><lpage>378</lpage><pub-id pub-id-type="doi">10.1007/s00221-002-1181-y</pub-id><pub-id pub-id-type="pmid">12232693</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Luessi</surname><given-names>M</given-names></name><name><surname>Larson</surname><given-names>E</given-names></name><name><surname>Engemann</surname><given-names>DA</given-names></name><name><surname>Strohmeier</surname><given-names>D</given-names></name><name><surname>Brodbeck</surname><given-names>C</given-names></name><name><surname>Goj</surname><given-names>R</given-names></name><name><surname>Jas</surname><given-names>M</given-names></name><name><surname>Brooks</surname><given-names>T</given-names></name><name><surname>Parkkonen</surname><given-names>L</given-names></name><name><surname>Hämäläinen</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>MEG and EEG data analysis with MNE-Python</article-title><source>Frontiers in Neuroscience</source><volume>7</volume><elocation-id>267</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2013.00267</pub-id><pub-id pub-id-type="pmid">24431986</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffin</surname><given-names>S</given-names></name><name><surname>Khanna</surname><given-names>P</given-names></name><name><surname>Choi</surname><given-names>H</given-names></name><name><surname>Thiesen</surname><given-names>K</given-names></name><name><surname>Novik</surname><given-names>L</given-names></name><name><surname>Morecraft</surname><given-names>RJ</given-names></name><name><surname>Ganguly</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>Ensemble reactivations during brief rest drive fast learning of sequences</article-title><source>Nature</source><volume>638</volume><fpage>1034</fpage><lpage>1042</lpage><pub-id pub-id-type="doi">10.1038/s41586-024-08414-9</pub-id><pub-id pub-id-type="pmid">39814880</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gupta</surname><given-names>MW</given-names></name><name><surname>Rickard</surname><given-names>TC</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Dissipation of reactive inhibition is sufficient to explain post-rest improvements in motor sequence learning</article-title><source>NPJ Science of Learning</source><volume>7</volume><elocation-id>25</elocation-id><pub-id pub-id-type="doi">10.1038/s41539-022-00140-z</pub-id><pub-id pub-id-type="pmid">36202812</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hall</surname><given-names>TM</given-names></name><name><surname>Nazarpour</surname><given-names>K</given-names></name><name><surname>Jackson</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Real-time estimation and biofeedback of single-neuron firing rates using local field potentials</article-title><source>Nature Communications</source><volume>5</volume><elocation-id>5462</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms6462</pub-id><pub-id pub-id-type="pmid">25394574</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayward</surname><given-names>W</given-names></name><name><surname>Buch</surname><given-names>ER</given-names></name><name><surname>Norato</surname><given-names>G</given-names></name><name><surname>Iwane</surname><given-names>F</given-names></name><name><surname>Dash</surname><given-names>D</given-names></name><name><surname>Salamanca-Girón</surname><given-names>RF</given-names></name><name><surname>Bartrum</surname><given-names>E</given-names></name><name><surname>Walitt</surname><given-names>B</given-names></name><name><surname>Nath</surname><given-names>A</given-names></name><name><surname>Cohen</surname><given-names>LG</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Procedural motor memory deficits in patients with long-COVID</article-title><source>Neurology</source><volume>102</volume><elocation-id>e208073</elocation-id><pub-id pub-id-type="doi">10.1212/WNL.0000000000208073</pub-id><pub-id pub-id-type="pmid">38237090</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hikosaka</surname><given-names>O</given-names></name><name><surname>Nakahara</surname><given-names>H</given-names></name><name><surname>Rand</surname><given-names>MK</given-names></name><name><surname>Sakai</surname><given-names>K</given-names></name><name><surname>Lu</surname><given-names>X</given-names></name><name><surname>Nakamura</surname><given-names>K</given-names></name><name><surname>Miyachi</surname><given-names>S</given-names></name><name><surname>Doya</surname><given-names>K</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Parallel neural networks for learning sequential procedures</article-title><source>Trends in Neurosciences</source><volume>22</volume><fpage>464</fpage><lpage>471</lpage><pub-id pub-id-type="doi">10.1016/s0166-2236(99)01439-3</pub-id><pub-id pub-id-type="pmid">10481194</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holland</surname><given-names>PW</given-names></name><name><surname>Welsch</surname><given-names>RE</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>Robust regression using iteratively reweighted least-squares</article-title><source>Communications in Statistics - Theory and Methods</source><volume>6</volume><fpage>813</fpage><lpage>827</lpage><pub-id pub-id-type="doi">10.1080/03610927708827533</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jacobacci</surname><given-names>F</given-names></name><name><surname>Armony</surname><given-names>JL</given-names></name><name><surname>Yeffal</surname><given-names>A</given-names></name><name><surname>Lerner</surname><given-names>G</given-names></name><name><surname>Amaro</surname><given-names>E</given-names><suffix>Jr</suffix></name><name><surname>Jovicich</surname><given-names>J</given-names></name><name><surname>Doyon</surname><given-names>J</given-names></name><name><surname>Della-Maggiore</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Rapid hippocampal plasticity supports motor sequence learning</article-title><source>PNAS</source><volume>117</volume><fpage>23898</fpage><lpage>23903</lpage><pub-id pub-id-type="doi">10.1073/pnas.2009576117</pub-id><pub-id pub-id-type="pmid">32900965</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karni</surname><given-names>A</given-names></name><name><surname>Meyer</surname><given-names>G</given-names></name><name><surname>Jezzard</surname><given-names>P</given-names></name><name><surname>Adams</surname><given-names>MM</given-names></name><name><surname>Turner</surname><given-names>R</given-names></name><name><surname>Ungerleider</surname><given-names>LG</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Functional MRI evidence for adult motor cortex plasticity during motor skill learning</article-title><source>Nature</source><volume>377</volume><fpage>155</fpage><lpage>158</lpage><pub-id pub-id-type="doi">10.1038/377155a0</pub-id><pub-id pub-id-type="pmid">7675082</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kleim</surname><given-names>JA</given-names></name><name><surname>Barbay</surname><given-names>S</given-names></name><name><surname>Nudo</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Functional reorganization of the rat motor cortex following motor skill learning</article-title><source>Journal of Neurophysiology</source><volume>80</volume><fpage>3321</fpage><lpage>3325</lpage><pub-id pub-id-type="doi">10.1152/jn.1998.80.6.3321</pub-id><pub-id pub-id-type="pmid">9862925</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Komorowski</surname><given-names>RW</given-names></name><name><surname>Manns</surname><given-names>JR</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Robust conjunctive item-place coding by hippocampal neurons parallels learning what happens where</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>9918</fpage><lpage>9929</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1378-09.2009</pub-id><pub-id pub-id-type="pmid">19657042</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kornysheva</surname><given-names>K</given-names></name><name><surname>Bush</surname><given-names>D</given-names></name><name><surname>Meyer</surname><given-names>SS</given-names></name><name><surname>Sadnicka</surname><given-names>A</given-names></name><name><surname>Barnes</surname><given-names>G</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neural competitive queuing of ordinal structure underlies skilled sequential action</article-title><source>Neuron</source><volume>101</volume><fpage>1166</fpage><lpage>1180</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.01.018</pub-id><pub-id pub-id-type="pmid">30744987</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Krasoulis</surname><given-names>A</given-names></name><name><surname>Hall</surname><given-names>TM</given-names></name><name><surname>Vijayakumar</surname><given-names>S</given-names></name><name><surname>Jackson</surname><given-names>A</given-names></name><name><surname>Nazarpour</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Generalizability of EMG decoding using local field potentials</article-title><conf-name>Annual International Conference of the IEEE Engineering in Medicine and Biology Society</conf-name><fpage>1630</fpage><lpage>1633</lpage><pub-id pub-id-type="doi">10.1109/EMBC.2014.6943917</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>N</given-names></name><name><surname>Manning</surname><given-names>TF</given-names></name><name><surname>Ostry</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Somatosensory cortex participates in the consolidation of human motor memory</article-title><source>PLOS Biology</source><volume>17</volume><elocation-id>e3000469</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3000469</pub-id><pub-id pub-id-type="pmid">31613874</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>SH</given-names></name><name><surname>Jin</surname><given-names>SH</given-names></name><name><surname>An</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The difference in cortical activation pattern for complex motor skills: A functional near- infrared spectroscopy study</article-title><source>Scientific Reports</source><volume>9</volume><elocation-id>14066</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-019-50644-9</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>HS</given-names></name><name><surname>Schreiner</surname><given-names>L</given-names></name><name><surname>Jo</surname><given-names>S-H</given-names></name><name><surname>Sieghartsleitner</surname><given-names>S</given-names></name><name><surname>Jordan</surname><given-names>M</given-names></name><name><surname>Pretl</surname><given-names>H</given-names></name><name><surname>Guger</surname><given-names>C</given-names></name><name><surname>Park</surname><given-names>H-S</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Individual finger movement decoding using a novel ultra-high-density electroencephalography-based brain-computer interface system</article-title><source>Frontiers in Neuroscience</source><volume>16</volume><elocation-id>1009878</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2022.1009878</pub-id><pub-id pub-id-type="pmid">36340769</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lemon</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Descending pathways in motor control</article-title><source>Annual Review of Neuroscience</source><volume>31</volume><fpage>195</fpage><lpage>218</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.31.060407.125547</pub-id><pub-id pub-id-type="pmid">18558853</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liao</surname><given-names>K</given-names></name><name><surname>Xiao</surname><given-names>R</given-names></name><name><surname>Gonzalez</surname><given-names>J</given-names></name><name><surname>Ding</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Decoding individual finger movements from one hand using human EEG signals</article-title><source>PLOS ONE</source><volume>9</volume><elocation-id>e85192</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0085192</pub-id><pub-id pub-id-type="pmid">24416360</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lisman</surname><given-names>J</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A neural coding scheme formed by the combined function of gamma and theta oscillations</article-title><source>Schizophrenia Bulletin</source><volume>34</volume><fpage>974</fpage><lpage>980</lpage><pub-id pub-id-type="doi">10.1093/schbul/sbn060</pub-id><pub-id pub-id-type="pmid">18559405</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>C</given-names></name><name><surname>You</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>K</given-names></name><name><surname>Zhang</surname><given-names>S</given-names></name><name><surname>Huang</surname><given-names>Y</given-names></name><name><surname>Xu</surname><given-names>M</given-names></name><name><surname>Ming</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Decoding the EEG patterns induced by sequential finger movement for brain-computer interfaces</article-title><source>Frontiers in Neuroscience</source><volume>17</volume><elocation-id>17</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2023.1180471</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maaten</surname><given-names>L</given-names></name><name><surname>Postma</surname><given-names>EO</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Dimensionality reduction: A comparative review</article-title><source>Journal of Machine Learning Research</source><volume>10</volume><elocation-id>13</elocation-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maidhof</surname><given-names>C</given-names></name><name><surname>Rieger</surname><given-names>M</given-names></name><name><surname>Prinz</surname><given-names>W</given-names></name><name><surname>Koelsch</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Nobody is perfect: ERP effects prior to performance errors in musicians indicate fast monitoring processes</article-title><source>PLOS ONE</source><volume>4</volume><elocation-id>e5032</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0005032</pub-id><pub-id pub-id-type="pmid">19337379</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marcus</surname><given-names>DS</given-names></name><name><surname>Harwell</surname><given-names>J</given-names></name><name><surname>Olsen</surname><given-names>T</given-names></name><name><surname>Hodge</surname><given-names>M</given-names></name><name><surname>Glasser</surname><given-names>MF</given-names></name><name><surname>Prior</surname><given-names>F</given-names></name><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Laumann</surname><given-names>T</given-names></name><name><surname>Curtiss</surname><given-names>SW</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Informatics and data mining tools and strategies for the human connectome project</article-title><source>Frontiers in Neuroinformatics</source><volume>5</volume><elocation-id>4</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2011.00004</pub-id><pub-id pub-id-type="pmid">21743807</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merino</surname><given-names>EC</given-names></name><name><surname>Faes</surname><given-names>A</given-names></name><name><surname>Van Hulle</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>The role of distinct ECoG frequency features in decoding finger movement</article-title><source>Journal of Neural Engineering</source><volume>20</volume><elocation-id>ad0c5e</elocation-id><pub-id pub-id-type="doi">10.1088/1741-2552/ad0c5e</pub-id><pub-id pub-id-type="pmid">37963397</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mollazadeh</surname><given-names>M</given-names></name><name><surname>Aggarwal</surname><given-names>V</given-names></name><name><surname>Davidson</surname><given-names>AG</given-names></name><name><surname>Law</surname><given-names>AJ</given-names></name><name><surname>Thakor</surname><given-names>NV</given-names></name><name><surname>Schieber</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Spatiotemporal variation of multiple neurophysiological signals in the primary motor cortex during dexterous reach-to-grasp movements</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>15531</fpage><lpage>15543</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2999-11.2011</pub-id><pub-id pub-id-type="pmid">22031899</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Munn</surname><given-names>BR</given-names></name><name><surname>Müller</surname><given-names>EJ</given-names></name><name><surname>Favre-Bulle</surname><given-names>I</given-names></name><name><surname>Scott</surname><given-names>E</given-names></name><name><surname>Lizier</surname><given-names>JT</given-names></name><name><surname>Breakspear</surname><given-names>M</given-names></name><name><surname>Shine</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Multiscale organization of neuronal activity unifies scale-dependent theories of brain function</article-title><source>Cell</source><volume>187</volume><fpage>7303</fpage><lpage>7313</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2024.10.004</pub-id><pub-id pub-id-type="pmid">39481379</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mylonas</surname><given-names>D</given-names></name><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Verfaellie</surname><given-names>M</given-names></name><name><surname>Baxter</surname><given-names>B</given-names></name><name><surname>Vangel</surname><given-names>M</given-names></name><name><surname>Stickgold</surname><given-names>R</given-names></name><name><surname>Manoach</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Maintenance of procedural motor memory across brief rest periods requires the hippocampus</article-title><source>The Journal of Neuroscience</source><volume>44</volume><elocation-id>e1839232024</elocation-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1839-23.2024</pub-id><pub-id pub-id-type="pmid">38351000</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Natraj</surname><given-names>N</given-names></name><name><surname>Silversmith</surname><given-names>DB</given-names></name><name><surname>Chang</surname><given-names>EF</given-names></name><name><surname>Ganguly</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Compartmentalized dynamics within a common multi-area mesoscale manifold represent a repertoire of human hand movements</article-title><source>Neuron</source><volume>110</volume><fpage>154</fpage><lpage>174</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.10.002</pub-id><pub-id pub-id-type="pmid">34678147</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oostenveld</surname><given-names>R</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Schoffelen</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>FieldTrip: Open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data</article-title><source>Computational Intelligence and Neuroscience</source><volume>2011</volume><elocation-id>156869</elocation-id><pub-id pub-id-type="doi">10.1155/2011/156869</pub-id><pub-id pub-id-type="pmid">21253357</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pan</surname><given-names>SC</given-names></name><name><surname>Rickard</surname><given-names>TC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Sleep and motor learning: Is there room for consolidation?</article-title><source>Psychological Bulletin</source><volume>141</volume><fpage>812</fpage><lpage>834</lpage><pub-id pub-id-type="doi">10.1037/bul0000009</pub-id><pub-id pub-id-type="pmid">25822130</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pavlides</surname><given-names>C</given-names></name><name><surname>Miyashita</surname><given-names>E</given-names></name><name><surname>Asanuma</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Projection from the sensory to the motor cortex is important in learning motor skills in the monkey</article-title><source>Journal of Neurophysiology</source><volume>70</volume><fpage>733</fpage><lpage>741</lpage><pub-id pub-id-type="doi">10.1152/jn.1993.70.2.733</pub-id><pub-id pub-id-type="pmid">8410169</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Quandt</surname><given-names>F</given-names></name><name><surname>Reichert</surname><given-names>C</given-names></name><name><surname>Hinrichs</surname><given-names>H</given-names></name><name><surname>Heinze</surname><given-names>HJ</given-names></name><name><surname>Knight</surname><given-names>RT</given-names></name><name><surname>Rieger</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Single trial discrimination of individual finger movements on one hand: a combined MEG and EEG study</article-title><source>NeuroImage</source><volume>59</volume><fpage>3316</fpage><lpage>3324</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.11.053</pub-id><pub-id pub-id-type="pmid">22155040</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramanathan</surname><given-names>DS</given-names></name><name><surname>Guo</surname><given-names>L</given-names></name><name><surname>Gulati</surname><given-names>T</given-names></name><name><surname>Davidson</surname><given-names>G</given-names></name><name><surname>Hishinuma</surname><given-names>AK</given-names></name><name><surname>Won</surname><given-names>S-J</given-names></name><name><surname>Knight</surname><given-names>RT</given-names></name><name><surname>Chang</surname><given-names>EF</given-names></name><name><surname>Swanson</surname><given-names>RA</given-names></name><name><surname>Ganguly</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Low-frequency cortical activity is a neuromodulatory target that tracks recovery after stroke</article-title><source>Nature Medicine</source><volume>24</volume><fpage>1257</fpage><lpage>1267</lpage><pub-id pub-id-type="doi">10.1038/s41591-018-0058-y</pub-id><pub-id pub-id-type="pmid">29915259</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reddy</surname><given-names>L</given-names></name><name><surname>Self</surname><given-names>MW</given-names></name><name><surname>Zoefel</surname><given-names>B</given-names></name><name><surname>Poncet</surname><given-names>M</given-names></name><name><surname>Possel</surname><given-names>JK</given-names></name><name><surname>Peters</surname><given-names>JC</given-names></name><name><surname>Baayen</surname><given-names>JC</given-names></name><name><surname>Idema</surname><given-names>S</given-names></name><name><surname>VanRullen</surname><given-names>R</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Theta-phase dependent neuronal coding during sequence learning in human single neurons</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>4839</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-25150-0</pub-id><pub-id pub-id-type="pmid">34376673</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rijsbergen</surname><given-names>V</given-names></name></person-group><year iso-8601-date="1979">1979</year><source>Reviews: Van Rijsbergen</source><publisher-name>goodreads</publisher-name></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robertson</surname><given-names>EM</given-names></name><name><surname>Cohen</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Understanding consolidation through the architecture of memories</article-title><source>The Neuroscientist</source><volume>12</volume><fpage>261</fpage><lpage>271</lpage><pub-id pub-id-type="doi">10.1177/1073858406287935</pub-id><pub-id pub-id-type="pmid">16684970</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruiz</surname><given-names>MH</given-names></name><name><surname>Jabusch</surname><given-names>HC</given-names></name><name><surname>Altenmüller</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Detecting wrong notes in advance: neuronal correlates of error monitoring in pianists</article-title><source>Cerebral Cortex</source><volume>19</volume><fpage>2625</fpage><lpage>2639</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhp021</pub-id><pub-id pub-id-type="pmid">19276327</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sawamura</surname><given-names>D</given-names></name><name><surname>Sakuraba</surname><given-names>S</given-names></name><name><surname>Suzuki</surname><given-names>Y</given-names></name><name><surname>Asano</surname><given-names>M</given-names></name><name><surname>Yoshida</surname><given-names>S</given-names></name><name><surname>Honke</surname><given-names>T</given-names></name><name><surname>Kimura</surname><given-names>M</given-names></name><name><surname>Iwase</surname><given-names>Y</given-names></name><name><surname>Horimoto</surname><given-names>Y</given-names></name><name><surname>Yoshida</surname><given-names>K</given-names></name><name><surname>Sakai</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Acquisition of chopstick-operation skills with the non-dominant hand and concomitant changes in brain activity</article-title><source>Scientific Reports</source><volume>9</volume><elocation-id>20397</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-019-56956-0</pub-id><pub-id pub-id-type="pmid">31892724</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Schmidt</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2018">2018</year><source>Motor Control and Learning: A Behavioral Emphasis</source><publisher-name>Human kinetics</publisher-name></element-citation></ref><ref id="bib70"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Schütze</surname><given-names>H</given-names></name><name><surname>Manning</surname><given-names>CD</given-names></name><name><surname>Raghavan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2008">2008</year><source>Introduction to Information Retrieval</source><publisher-name>Cambridge University Press</publisher-name></element-citation></ref><ref id="bib71"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Sjøgård</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Hippocampal ripples mediate motor learning during brief rest breaks in humans</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2024.05.02.592200</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>S</given-names></name><name><surname>Cohen</surname><given-names>LG</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Practice and sleep form different aspects of skill</article-title><source>Nature Communications</source><volume>5</volume><elocation-id>3407</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms4407</pub-id><pub-id pub-id-type="pmid">24647040</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stefanics</surname><given-names>G</given-names></name><name><surname>Hangya</surname><given-names>B</given-names></name><name><surname>Hernádi</surname><given-names>I</given-names></name><name><surname>Winkler</surname><given-names>I</given-names></name><name><surname>Lakatos</surname><given-names>P</given-names></name><name><surname>Ulbert</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Phase entrainment of human delta oscillations can mediate the effects of expectation on reaction speed</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>13578</fpage><lpage>13585</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0703-10.2010</pub-id><pub-id pub-id-type="pmid">20943899</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tomassini</surname><given-names>A</given-names></name><name><surname>Ambrogioni</surname><given-names>L</given-names></name><name><surname>Medendorp</surname><given-names>WP</given-names></name><name><surname>Maris</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Theta oscillations locked to intended actions rhythmically modulate perception</article-title><source>eLife</source><volume>6</volume><elocation-id>e25618</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.25618</pub-id><pub-id pub-id-type="pmid">28686161</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker</surname><given-names>MP</given-names></name><name><surname>Brakefield</surname><given-names>T</given-names></name><name><surname>Morgan</surname><given-names>A</given-names></name><name><surname>Hobson</surname><given-names>JA</given-names></name><name><surname>Stickgold</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Practice with sleep makes perfect: sleep-dependent motor skill learning</article-title><source>Neuron</source><volume>35</volume><fpage>205</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(02)00746-8</pub-id><pub-id pub-id-type="pmid">12123620</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker</surname><given-names>MP</given-names></name><name><surname>Stickgold</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Sleep-dependent learning and memory consolidation</article-title><source>Neuron</source><volume>44</volume><fpage>121</fpage><lpage>133</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2004.08.031</pub-id><pub-id pub-id-type="pmid">15450165</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wamsley</surname><given-names>EJ</given-names></name><name><surname>Arora</surname><given-names>M</given-names></name><name><surname>Gibson</surname><given-names>H</given-names></name><name><surname>Powell</surname><given-names>P</given-names></name><name><surname>Collins</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Memory consolidation during ultra-short offline states</article-title><source>Journal of Cognitive Neuroscience</source><volume>35</volume><fpage>1617</fpage><lpage>1634</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_02035</pub-id><pub-id pub-id-type="pmid">37584585</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waters</surname><given-names>S</given-names></name><name><surname>Wiestler</surname><given-names>T</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Cooperation not competition: Bihemispheric tDCS and fMRI Show role for ipsilateral hemisphere in motor learning</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>7500</fpage><lpage>7512</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3414-16.2017</pub-id><pub-id pub-id-type="pmid">28674174</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yao</surname><given-names>L</given-names></name><name><surname>Zhu</surname><given-names>B</given-names></name><name><surname>Shoaran</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Fast and accurate decoding of finger movements from ECoG through Riemannian features and modern machine learning techniques</article-title><source>Journal of Neural Engineering</source><volume>19</volume><elocation-id>016037</elocation-id><pub-id pub-id-type="doi">10.1088/1741-2552/ac4ed1</pub-id><pub-id pub-id-type="pmid">35078156</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yokoi</surname><given-names>A</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neural organization of hierarchical motor sequence representations in the human neocortex</article-title><source>Neuron</source><volume>103</volume><fpage>1178</fpage><lpage>1190</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.06.017</pub-id><pub-id pub-id-type="pmid">31345643</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>L</given-names></name><name><surname>Liu</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Efficient feature selection via analysis of relevance and redundancy</article-title><source>Journal of Machine Learning Research</source><volume>5</volume><fpage>1205</fpage><lpage>1224</lpage></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>X</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Zhao</surname><given-names>H</given-names></name><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Gao</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Decoding finger movement patterns from microscopic neural drive information based on deep learning</article-title><source>Medical Engineering &amp; Physics</source><volume>104</volume><elocation-id>103797</elocation-id><pub-id pub-id-type="doi">10.1016/j.medengphy.2022.103797</pub-id><pub-id pub-id-type="pmid">35641068</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zimerman</surname><given-names>M</given-names></name><name><surname>Heise</surname><given-names>K-F</given-names></name><name><surname>Gerloff</surname><given-names>C</given-names></name><name><surname>Cohen</surname><given-names>LG</given-names></name><name><surname>Hummel</surname><given-names>FC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Disrupting the ipsilateral motor cortex interferes with training of a complex motor task in older adults</article-title><source>Cerebral Cortex</source><volume>24</volume><fpage>1030</fpage><lpage>1036</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhs385</pub-id><pub-id pub-id-type="pmid">23242199</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.102475.4.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Gallego</surname><given-names>Juan Alvaro</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Imperial College London</institution><country>United Kingdom</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Valuable</kwd></kwd-group></front-stub><body><p>This <bold>valuable</bold> study asks how the neural representation of individual finger movements changes during the early periods of sequence learning. By combining a new method for extracting features from human magnetoencephalography data and decoding analyses, the authors provide <bold>solid</bold> evidence of an early, swift change in the brain regions correlated with sequence learning, including a set of previously unreported frontal cortical regions. The authors also show that offline contextualization during short rest periods is the basis for improved performance. Further confirmation of these results on multiple movement sequences would further strengthen the key claims.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.102475.4.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This study addresses the issue of rapid skill learning and whether individual sequence elements (here: finger presses) are differentially represented in human MEG data. The authors use a decoding approach to classify individual finger elements, and accomplish an accuracy of around 94%. A relevant finding is that the neural representations of individual finger elements dynamically change over the course of learning. This would be highly relevant for any attempts to develop better brain machine interfaces - one now can decode individual elements within a sequence with high precision, but these representations are not static but develop over the course of learning.</p><p>Strengths:</p><p>The work follows from a large body of work from the same group on the behavioural and neural foundations of sequence learning. The behavioural task is well established a neatly designed to allow for tracking learning and how individual sequence elements contribute. The inclusion of short offline rest periods between learning epochs has been influential because it has revealed that a lot, if not most of the gains in behaviour (ie speed of finger movements) occur in these so-called micro-offline rest periods.</p><p>The authors use a range of new decoding techniques, and exhaustively interrogate their data in different ways, using different decoding approaches. Regardless of the approach, impressively high decoding accuracies are observed, but when using a hybrid approach that combines the MEG data in different ways, the authors observe decoding accuracies of individual sequence elements from the MEG data of up to 94%.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.102475.4.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>The current paper consists of two parts. The first part is the rigorous feature optimization of the MEG signal to decode individual finger identity performed in a sequence (4-1-3-2-4; 1~4 corresponds to little~index fingers of the left hand). By optimizing various parameters for the MEG signal, in terms of (i) reconstructed source activity in voxel- and parcel-level resolution and their combination, (ii) frequency bands, and (iii) time window relative to press onset for each finger movement, as well as the choice of decoders, the resultant &quot;hybrid decoder&quot; achieved extremely high decoding accuracy (~95%).</p><p>In the second part of the paper, armed with the successful 'hybrid decoder,' the authors asked how neural representation of individual finger movement that is embedded in a sequence, changes during a very early period of skill learning and whether and how such representational change can predict skill learning. They assessed the difference in MEG feature patterns between the first and the last press 4 in sequence 41324 at each training trial and found that the pattern differentiation progressively increased over the course of early learning trials. Additionally, they found that this pattern differentiation specifically occurred during the rest period rather than during the practice trial. With a significant correlation between the trial-by-trial profile of this pattern differentiation and that for accumulation of offline learning, the authors argue that such &quot;contextualization&quot; of finger movement in a sequence (e.g., what-where association) underlies the early improvement of sequential skill. This is an important and timely topic for the field of motor learning and beyond.</p><p>Strengths:</p><p>The use of temporally rich neural information (MEG signal) has a significant advantage over previous studies testing sequential representations using fMRI. This allowed the authors to examine the earliest period (= the first few minutes of training) of skill learning with finer temporal resolution. Through the optimization of MEG feature extraction, the current study achieved extremely high decoding accuracy (approx. 94%) compared to previous works. The finding of the early &quot;contextualization&quot; of the finger movement in a sequence and its correlation to early (offline) skill improvement is interesting and important. The comparison between &quot;online&quot; and &quot;offline&quot; pattern distance is a neat idea.</p><p>Weaknesses:</p><p>One potential weakness, in terms of the generality, is that the study assessed the single sequence, the &quot;41324&quot; across all participants. Future confirmation test of using different sequences would be important.</p></body></sub-article><sub-article article-type="referee-report" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.102475.4.sa3</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>One goal of this paper is to introduce a new approach for highly accurate decoding of finger movements from human magnetoencephalography data via dimension reduction of a &quot;multi-scale, hybrid&quot; feature space. Following this decoding approach, the authors aim to show that early skill learning involves &quot;contextualization&quot; of the neural coding of individual movements, relative to their position in a sequence of consecutive movements. Furthermore, they aim to show that this &quot;contextualization&quot; develops primarily during short rest periods interspersed with skill training, and correlates with a performance metric which the authors interpret as an indicator of offline learning.</p><p>Strengths:</p><p>A strength of the paper is the innovative decoding approach, which achieves impressive decoding accuracies via dimension reduction of a &quot;multi-scale, hybrid space&quot;. This hybrid-space approach follows the neurobiologically plausible idea of concurrent distribution of neural coding across local circuits as well as large-scale networks.</p><p>Weaknesses:</p><p>A clear weakness of the paper lies in the authors' conclusions regarding &quot;contextualization&quot;. Several potential confounds, which partly arise from the experimental design, and which are described below, question the neurobiological implications proposed by the authors, and offer a simpler explanation of the results. Furthermore, the paper follows the assumption that short breaks result in offline skill learning, while recent evidence casts doubt on this assumption.</p><p>Specifically:</p><p>The authors interpret the ordinal position information captured by their decoding approach as a reflection of neural coding dedicated to the local context of a movement (Figure 4). One way to dissociate ordinal position information from information about the moving effectors is to train a classifier on one sequence, and test the classifier on other sequences that require the same movements, but in different positions (Kornysheva et al., Neuron 2019). In the present study, however, participants trained to repeat a single sequence (4-1-3-2-4). As a result, ordinal position information is potentially confounded by the fixed finger transitions around each of the two critical positions (first and fifth press). Across consecutive correct sequences, the first keypress in a given sequence was always preceded by a movement of the index finger (=last movement of the preceding sequence), and followed by a little finger movement. The last keypress, on the other hand, was always preceded by a ring finger movement, and followed by an index finger movement (=first movement of the next sequence). Figure 3 - supplement 5 shows that finger identity can be decoded with high accuracy (&gt;70%) across a large time window around the time of the keypress, up to at least {plus minus}100 ms (and likely beyond, given that decoding accuracy is still high at the boundaries of the window depicted in that figure). This time window approaches the keypress transition times in this study. Given that distinct finger transitions characterized the first and fifth keypress, the classifier could thus rely on persistent (or &quot;lingering&quot;) information from the preceding finger movement, and/or &quot;preparatory&quot; information about the subsequent finger movement, in order to dissociate the first and fifth keypress. Currently, the manuscript provides little evidence that the context information captured by the decoding approach is more than a by-product of temporally extended, and therefore overlapping, but independent neural representations of consecutive keypresses that are executed in close temporal proximity - rather than a neural representation dedicated to context.</p><p>During the review process, the authors pointed out that a &quot;mixing&quot; of temporally overlapping information from consecutive keypresses, as described above, should result in systematic misclassifications and therefore be detectable in the confusion matrices in Figures 3C and 4B, which indeed do not provide any evidence that consecutive keypresses are systematically confused. However, such absence of evidence (of systematic misclassification) should be interpreted with caution. The authors also reported that there was only a weak relation between inter-press intervals and &quot;online contextualization&quot; (Figure 5 - figure supplement 6), however, their analysis suprisingly includes a keypress transition that is shared between OP1 and OP5 (&quot;4-4&quot;), rather than focusing solely on the two distinctive transitions (&quot;2-4&quot; and &quot;4-1&quot;).</p><p>Such temporal overlap of consecutive, independent finger representations may also account for the dynamics of &quot;ordinal coding&quot;/&quot;contextualization&quot;, i.e., the increase in 2-class decoding accuracy, across Day 1 (Figure 4C). As learning progresses, both tapping speed and the consistency of keypress transition times increase (Figure 1), i.e., consecutive keypresses are closer in time, and more consistently so. As a result, information related to a given keypress is increasingly overlapping in time with information related to the preceding and subsequent keypresses. Furthermore, learning should increase the number of (consecutively) correct sequences, and, thus, the consistency of finger transitions. Therefore, the increase in 2-class decoding accuracy may simply reflect an increasing overlap in time of increasingly consistent information from consecutive keypresses, which allows the classifier to dissociate the first and fifth keypress more reliably as learning progresses, simply based on the characteristic finger transitions associated with each. In other words, given that the physical context of a given keypress changes as learning progresses - keypresses move closer together in time, and are more consistently correct - it seems problematic to conclude that the mental representation of that context changes. During the review process, authors pointed at absence of evidence of a relation between tapping speed and &quot;ordinal coding&quot; (Figure 5 - figure supplement 7). However, a rigorous test of the idea that the mental representation of context changes would require a task design in which the physical context remains constant.</p><p>A similar difference in physical context may explain why neural representation distances (&quot;differentiation&quot;) differ between rest and practice (Figure 5). The authors define &quot;offline differentiation&quot; by comparing the hybrid space features of the last index finger movement of a trial (ordinal position 5) and the first index finger movement of the next trial (ordinal position 1). However, the latter is not only the first movement in the sequence, but also the very first movement in that trial (at least in trials that started with a correct sequence), i.e., not preceded by any recent movement. In contrast, the last index finger of the last correct sequence in the preceding trial includes the characteristic finger transition from the fourth to the fifth movement. Thus, there is more overlapping information arising from the consistent, neighbouring keypresses for the last index finger movement, compared to the first index finger movement of the next trial. A strong difference (larger neural representation distance) between these two movements is, therefore, not surprising, given the task design, and this difference is also expected to increase with learning, given the increase in tapping speed, and the consequent stronger overlap in representations for consecutive keypresses.</p><p>A further complication in interpreting the results stems from the visual feedback that participants received during the task. Each keypress generated an asterisk shown above the string on the screen. It is not clear why the authors introduced this complicating visual feedback in their task, besides consistency with their previous studies. The resulting systematic link between the pattern of visual stimulation (the number of asterisks on the screen) and the ordinal position of a keypress makes the interpretation of &quot;contextual information&quot; that differentiates between ordinal positions difficult. While the authors report the surprising finding that their eye-tracking data could not predict asterisk position on the task display above chance level, the mean gaze position seemed to vary systematically as a function of ordinal position of a movement - see Figure 4 - figure supplement 3.</p><p>The authors report a significant correlation between &quot;offline differentiation&quot; and cumulative micro-offline gains. However, to reach the conclusion that &quot;the degree of representational differentiation -particularly prominent over rest intervals - correlated with skill gains.&quot;, the critical question is rather whether &quot;offline differentiation&quot; correlates with micro-offline gains (not with cumulative micro-offline gains). That is, does the degree to which representations differentiate &quot;during&quot; a given rest period correlate with the degree to which performance improves from before to after the same rest period (not: does &quot;offline differentiation&quot; in a given rest period correlate with the degree to which performance has improved &quot;during&quot; all rest periods up to the current rest period - but this is what Figure 5 - figure supplements 1 and 4 show).</p><p>The authors follow the assumption that micro-offline gains reflect offline learning. However, there is no compelling evidence in the literature, and no evidence in the present manuscript, that micro-offline gains (during any training phase) reflect offline learning. Instead, emerging evidence in the literature indicates that they do not (Das et al., bioRxiv 2024), and instead reflect transient performance benefits when participants train with breaks, compared to participants who train without breaks, however, these benefits vanish within seconds after training if both groups of participants perform under comparable conditions (Das et al., bioRxiv 2024). During the review process, the authors argued that differences in the design between Das et al. (2024) on the one hand (Experiments 1 and 2), and the study by Bönstrup et al. (2019) on the other hand, may have prevented Das et al. (2024) from finding the assumed (lasting) learning benefit by micro-offline consolidation. However, the Supplementary Material of Das et al. (2024) includes an experiment (Experiment S1) whose design closely follows the early learning phase of Bönstrup et al. (2019), and which, nevertheless, demonstrates that there is no lasting benefit of taking breaks for the acquired skill level, despite the presence of micro-offline gains.</p><p>Along these lines, the authors argue that their practice schedule &quot;minimizes reactive inhibition effects&quot;, in particular their short practice periods of 10 seconds each. However, 10 seconds are sufficient to result in motor slowing, as report in Bächinger et al., elife 2019, or Rodrigues et al., Exp Brain Res 2009.</p><p>An important conceptual problem with the current study is that the authors conclude that performance improves, and representation manifolds differentiate, &quot;during&quot; rest periods. However, micro-offline gains (as well as offline contextualization) are computed from data obtained during practice, not rest, and may, thus, just as well reflect a change that occurs &quot;online&quot;, e.g., at the very onset of practice (like pre-planning) or throughout practice (like fatigue, or reactive inhibition).</p><p>The authors' conclusion that &quot;low-frequency oscillations (LFOs) result in higher decoding accuracy compared to other narrow-band activity&quot; should be taken with caution, given that the critical decoding analysis for this conclusion was based on data averaged across a time window of 200 ms (Figure 2), essentially smoothing out higher frequency components.</p></body></sub-article><sub-article article-type="author-comment" id="sa4"><front-stub><article-id pub-id-type="doi">10.7554/eLife.102475.4.sa4</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Dash</surname><given-names>Debadatta</given-names></name><role specific-use="author">Author</role><aff><institution>National Institutes of Health</institution><addr-line><named-content content-type="city">Stephenville</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Iwane</surname><given-names>Fumiaki</given-names></name><role specific-use="author">Author</role><aff><institution>National Institutes of Health</institution><addr-line><named-content content-type="city">Bethesda</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Hayward</surname><given-names>William</given-names></name><role specific-use="author">Author</role><aff><institution>National Institutes of Health</institution><addr-line><named-content content-type="city">Bethesda</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Salamanca-Giron</surname><given-names>Roberto F</given-names></name><role specific-use="author">Author</role><aff><institution>National Institutes of Health</institution><addr-line><named-content content-type="city">Bethesda</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Bönstrup</surname><given-names>Marlene</given-names></name><role specific-use="author">Author</role><aff><institution>University of Leipzig Medical Center</institution><addr-line><named-content content-type="city">Leipzig</named-content></addr-line><country>Germany</country></aff></contrib><contrib contrib-type="author"><name><surname>Buch</surname><given-names>Ethan R</given-names></name><role specific-use="author">Author</role><aff><institution>National Institutes of Health</institution><addr-line><named-content content-type="city">Bethesda</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Cohen</surname><given-names>Leonardo</given-names></name><role specific-use="author">Author</role><aff><institution>National Institutes of Health</institution><addr-line><named-content content-type="city">Bethesda</named-content></addr-line><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the previous reviews</p><disp-quote content-type="editor-comment"><p>Overview of reviewer's concerns after peer review:</p><p>As for the initial submission, the reviewers' unanimous opinion is that the authors should perform additional controls to show that their key findings may not be affected by experimental or analysis artefacts, and clarify key aspects of their core methods, chiefly:</p><p>(1) The fact that their extremely high decoding accuracy is driven by frequency bands that would reflect the key press movements and that these are located bilaterally in frontal brain regions (with the task being unilateral) are seen as key concerns,</p></disp-quote><p>The above statement that decoding was driven by bilateral frontal brain regions is not entirely consistent with our results. The confusion was likely caused by the way we originally presented our data in Figure 2. We have revised that figure to make it more clear that decoding performance at both the parcel- (Figure 2B) and voxel-space (Figure 2C) level is predominantly driven by contralateral (as opposed to ipsilateral) sensorimotor regions. Figure 2D, which highlights bilateral sensorimotor and premotor regions, displays accuracy of individual regional voxel-space decoders assessed independently. This was the criteria used to determine which regional voxel-spaces were included in the hybridspace decoder. This result is not surprising given that motor and premotor regions are known to display adaptive interhemispheric interactions during motor sequence learning [1, 2], and particularly so when the skill is performed with the non-dominant hand [3-5]. We now discuss this important detail in the revised manuscript:</p><p>Discussion (lines 348-353)</p><p>“The whole-brain parcel-space decoder likely emphasized more stable activity patterns in contralateral frontoparietal regions that differed between individual finger movements [21,35], while the regional voxel-space decoder likely incorporated information related to adaptive interhemispheric interactions operating during motor sequence learning [32,36,37], particularly pertinent when the skill is performed with the non-dominant hand [38-40].”</p><p>We now also include new control analyses that directly address the potential contribution of movement-related artefact to the results. These changes are reported in the revised manuscript as follows:</p><p>Results (lines 207-211):</p><p>“An alternate decoder trained on ICA components labeled as movement or physiological artefacts (e.g. – head movement, ECG, eye movements and blinks; Figure 3 – figure supplement 3A, D) and removed from the original input feature set during the pre-processing stage approached chance-level performance (Figure 4 – figure supplement 3), indicating that the 4-class hybrid decoder results were not driven by task-related artefacts.”</p><p>Results (lines 261-268):</p><p>“As expected, the 5-class hybrid-space decoder performance approached chance levels when tested with randomly shuffled keypress labels (18.41%± SD 7.4% for Day 1 data; Figure 4 – figure supplement 3C). Task-related eye movements did not explain these results since an alternate 5-class hybrid decoder constructed from three eye movement features (gaze position at the KeyDown event, gaze position 200ms later, and peak eye movement velocity within this window; Figure 4 – figure supplement 3A) performed at chance levels (cross-validated test accuracy = 0.2181; Figure 4 – figure supplement 3B, C). “</p><p>Discussion (Lines 362-368):</p><p>“Task-related movements—which also express in lower frequency ranges—did not explain these results given the near chance-level performance of alternative decoders trained on (a) artefact-related ICA components removed during MEG preprocessing (Figure 3 – figure supplement 3A-C) and on (b) task-related eye movement features (Figure 4 – figure supplement 3B, C). This explanation is also inconsistent with the minimal average head motion of 1.159 mm (± 1.077 SD) across the MEG recording (Figure 3 – figure supplement 3D).“</p><disp-quote content-type="editor-comment"><p>(2) Relatedly, the use of a wide time window (~200 ms) for a 250-330 ms typing speed makes it hard to pinpoint the changes underpinning learning,</p></disp-quote><p>The revised manuscript now includes analyses carried out with decoding time windows ranging from 50 to 250ms in duration. These additional results are now reported in:</p><p>Results (lines 258-261):</p><p>“The improved decoding accuracy is supported by greater differentiation in neural representations of the index finger keypresses performed at positions 1 and 5 of the sequence (Figure 4A), and by the trial-by-trial increase in 2-class decoding accuracy over early learning (Figure 4C) across different decoder window durations (Figure 4 – figure supplement 2).”</p><p>Results (lines 310-312):</p><p>“Offline contextualization strongly correlated with cumulative micro-offline gains (r = 0.903, R<sup>2</sup> = 0.816, p &lt; 0.001; Figure 5 – figure supplement 1A, inset) across decoder window durations ranging from 50 to 250ms (Figure 5 – figure supplement 1B, C).“</p><p>Discussion (lines 382-385):</p><p>“This was further supported by the progressive differentiation of neural representations of the index finger keypress (Figure 4A) and by the robust trial-bytrial increase in 2-class decoding accuracy across time windows ranging between 50 and 250ms (Figure 4C; Figure 4 – figure supplement 2).”</p><p>Discussion (lines 408-9):</p><p>“Offline contextualization consistently correlated with early learning gains across a range of decoding windows (50–250ms; Figure 5 – figure supplement 1).”</p><disp-quote content-type="editor-comment"><p>(3) These concerns make it hard to conclude from their data that learning is mediated by &quot;contextualisation&quot; ---a key claim in the manuscript;</p></disp-quote><p>We believe the revised manuscript now addresses all concerns raised in Editor points 1 and 2.</p><disp-quote content-type="editor-comment"><p>(4) The hybrid voxel + parcel space decoder ---a key contribution of the paper--- is not clearly explained;</p></disp-quote><p>We now provide additional details regarding the hybrid-space decoder approach in the following sections of the revised manuscript:</p><p>Results (lines 158-172):</p><p>“Next, given that the brain simultaneously processes information more efficiently across multiple spatial and temporal scales [28, 32, 33], we asked if the combination of lower resolution whole-brain and higher resolution regional brain activity patterns further improve keypress prediction accuracy. We constructed hybrid-space decoders (N = 1295 ± 20 features; Figure 3A) combining whole-brain parcel-space activity (n = 148 features; Figure 2B) with regional voxel-space activity from a datadriven subset of brain areas (n = 1147 ± 20 features; Figure 2D). This subset covers brain regions showing the highest regional voxel-space decoding performances (top regions across all subjects shown in Figure 2D; Methods – Hybrid Spatial Approach).</p><p>[…]</p><p>Note that while features from contralateral brain regions were more important for whole-brain decoding (in both parcel- and voxel-spaces), regional voxel-space decoders performed best for bilateral sensorimotor areas on average across the group. Thus, a multi-scale hybrid-space representation best characterizes the keypress action manifolds.”</p><p>Results (lines 275-282):</p><p>“We used a Euclidian distance measure to evaluate the differentiation of the neural representation manifold of the same action (i.e. - an index-finger keypress) executed within different local sequence contexts (i.e. - ordinal position 1 vs. ordinal position 5; Figure 5). To make these distance measures comparable across participants, a new set of classifiers was then trained with group-optimal parameters (i.e. – broadband hybrid-space MEG data with subsequent manifold extraction Figure 3 – figure supplements 2) and LDA classifiers (Figure 3 – figure supplements 7) trained on 200ms duration windows aligned to the KeyDown event (see Methods, Figure 3 – figure supplements 5). “</p><p>Discussion (lines 341-360):</p><p>“The initial phase of the study focused on optimizing the accuracy of decoding individual finger keypresses from MEG brain activity. Recent work showed that the brain simultaneously processes information more efficiently across multiple—rather than a single—spatial scale(s) [28, 32]. To this effect, we developed a novel hybridspace approach designed to integrate neural representation dynamics over two different spatial scales: (1) whole-brain parcel-space (i.e. – spatial activity patterns across all cortical brain regions) and (2) regional voxel-space (i.e. – spatial activity patterns within select brain regions) activity. We found consistent spatial differences between whole-brain parcel-space feature importance (predominantly contralateral frontoparietal, Figure 2B) and regional voxel-space decoder accuracy (bilateral sensorimotor regions, Figure 2D). The <italic>whole-brain parcel-space</italic> decoder likely emphasized more stable activity patterns in contralateral frontoparietal regions that differed between individual finger movements [21, 35], while the <italic>regional voxelspace</italic> decoder likely incorporated information related to adaptive interhemispheric interactions operating during motor sequence learning [32, 36, 37], particularly pertinent when the skill is performed with the non-dominant hand [38-40]. The observation of increased cross-validated test accuracy (as shown in Figure 3 – Figure Supplement 6) indicates that the spatially overlapping information in parcel- and voxel-space time-series in the hybrid decoder was complementary, rather than redundant [41]. The hybrid-space decoder which achieved an accuracy exceeding 90%—and robustly generalized to Day 2 across trained and untrained sequences— surpassed the performance of both parcel-space and voxel-space decoders and compared favorably to other neuroimaging-based finger movement decoding strategies [6, 24, 42-44].”</p><p>Methods (lines 636-647):</p><p>“Hybrid Spatial Approach. First, we evaluated the decoding performance of each individual brain region in accurately labeling finger keypresses from regional voxelspace (i.e. - all voxels within a brain region as defined by the Desikan-Killiany Atlas) activity. Brain regions were then ranked from 1 to 148 based on their decoding accuracy at the group level. In a stepwise manner, we then constructed a “hybridspace” decoder by incrementally concatenating regional voxel-space activity of brain regions—starting with the top-ranked region—with whole-brain parcel-level features and assessed decoding accuracy. Subsequently, we added the regional voxel-space features of the second-ranked brain region and continued this process until decoding accuracy reached saturation. The optimal “hybrid-space” input feature set over the group included the 148 parcel-space features and regional voxelspace features from a total of 8 brain regions (bilateral superior frontal, middle frontal, pre-central and post-central; N = 1295 ± 20 features).”</p><disp-quote content-type="editor-comment"><p>(5) More controls are needed to show that their decoder approach is capturing a neural representation dedicated to context rather than independent representations of consecutive keypresses;</p></disp-quote><p>These controls have been implemented and are now reported in the manuscript:</p><p>Results (lines 318-328):</p><p>“Within-subject correlations were consistent with these group-level findings. The average correlation between offline contextualization and micro-offline gains within individuals was significantly greater than zero (Figure 5 – figure supplement 4, left; t = 3.87, p = 0.00035, df = 25, Cohen's d = 0.76) and stronger than correlations between online contextualization and either micro-online (Figure 5 – figure supplement 4, middle; t = 3.28, p = 0.0015, df = 25, Cohen's d = 1.2) or micro-offline gains (Figure 5 – figure supplement 4, right; t = 3.7021, p = 5.3013e-04, df = 25, Cohen's d = 0.69). These findings were not explained by behavioral changes of typing rhythm (t = -0.03, <italic>p</italic> = 0.976; Figure 5 – figure supplement 5), adjacent keypress transition times (R2 = 0.00507, F[1,3202] = 16.3; Figure 5 – figure supplement 6), or overall typing speed (between-subject; R2 = 0.028, <italic>p</italic> = 0.41; Figure 5 – figure supplement 7).”</p><p>Results (lines 385-390):</p><p>“Further, the 5-class classifier—which directly incorporated information about the sequence location context of each keypress into the decoding pipeline—improved decoding accuracy relative to the 4-class classifier (Figure 4C). Importantly, testing on Day 2 revealed specificity of this representational differentiation for the trained skill but not for the same keypresses performed during various unpracticed control sequences (Figure 5C).”</p><p>Discussion (lines 408-423):</p><p>“Offline contextualization consistently correlated with early learning gains across a range of decoding windows (50–250ms; Figure 5 – figure supplement 1). This result remained unchanged when measuring offline contextualization between the last and second sequence of consecutive trials, inconsistent with a possible confounding effect of pre-planning [30] (Figure 5 – figure supplement 2A). On the other hand, online contextualization did not predict learning (Figure 5 – figure supplement 3). Consistent with these results the average within-subject correlation between offline contextualization and micro-offline gains was significantly stronger than withinsubject correlations between online contextualization and either micro-online or micro-offline gains (Figure 5 – figure supplement 4).</p><p>Offline contextualization was not driven by trial-by-trial behavioral differences, including typing rhythm (Figure 5 – figure supplement 5) and adjacent keypress transition times (Figure 5 – figure supplement 6) nor by between-subject differences in overall typing speed (Figure 5 – figure supplement 7)—ruling out a reliance on differences in the temporal overlap of keypresses. Importantly, offline contextualization documented on Day 1 stabilized once a performance plateau was reached (trials 11-36), and was retained on Day 2, documenting overnight consolidation of the differentiated neural representations.”</p><disp-quote content-type="editor-comment"><p>(6) The need to show more convincingly that their data is not affected by head movements, e.g., by regressing out signal components that are correlated with the fiducial signal;</p></disp-quote><p>We now include data in Figure 3 – figure supplement 3D showing that head movement was minimal in all participants (mean of 1.159 mm ± 1.077 SD). Further, the requested additional control analyses have been carried out and are reported in the revised manuscript:</p><p>Results (lines 204-211):</p><p>“Testing the keypress state (4-class) hybrid decoder performance on Day 1 after randomly shupling keypress labels for held-out test data resulted in a performance drop approaching expected chance levels (22.12%± SD 9.1%; Figure 3 – figure supplement 3C). An alternate decoder trained on ICA components labeled as movement or physiological artefacts (e.g. – head movement, ECG, eye movements and blinks; Figure 3 – figure supplement 3A, D) and removed from the original input feature set during the pre-processing stage approached chance-level performance (Figure 4 – figure supplement 3), indicating that the 4-class hybrid decoder results were not driven by task-related artefacts.” Results (lines 261-268):</p><p>“As expected, the 5-class hybrid-space decoder performance approached chance levels when tested with randomly shuffled keypress labels (18.41%± SD 7.4% for Day 1 data; Figure 4 – figure supplement 3C). Task-related eye movements did not explain these results since an alternate 5-class hybrid decoder constructed from three eye movement features (gaze position at the KeyDown event, gaze position 200ms later, and peak eye movement velocity within this window; Figure 4 – figure supplement 3A) performed at chance levels (cross-validated test accuracy = 0.2181; Figure 4 – figure supplement 3B, C). “</p><p>Discussion (Lines 362-368):</p><p>“Task-related movements—which also express in lower frequency ranges—did not explain these results given the near chance-level performance of alternative decoders trained on (a) artefact-related ICA components removed during MEG preprocessing (Figure 3 – figure supplement 3A-C) and on (b) task-related eye movement features (Figure 4 – figure supplement 3B, C). This explanation is also inconsistent with the minimal average head motion of 1.159 mm (± 1.077 SD) across the MEG recording (Figure 3 – figure supplement 3D). “</p><disp-quote content-type="editor-comment"><p>(7) The offline neural representation analysis as executed is a bit odd, since it seems to be based on comparing the last key press to the first key press of the next sequence, rather than focus on the inter-sequence interval</p></disp-quote><p>While we previously evaluated replay of skill sequences during rest intervals, identification of how offline reactivation patterns of a single keypress state representation evolve with learning presents non-trivial challenges. First, replay events tend to occur in clusters with irregular temporal spacing as previously shown by our group and others. Second, replay of experienced sequences is intermixed with replay of sequences that have never been experienced but are possible. Finally, and perhaps the most significant issue, replay is temporally compressed up to 20x with respect to the behavior [6]. That means our decoders would need to accurately evaluate spatial pattern changes related to individual keypresses over much smaller time windows (i.e. - less than 10 ms) than evaluated here. This future work, which is undoubtably of great interest to our research group, will require more substantial tool development before we can apply them to this question. We now articulate this future direction in the Discussion:</p><p>Discussion (lines 423-427):</p><p>“A possible neural mechanism supporting contextualization could be the emergence and stabilization of conjunctive “what–where” representations of procedural memories [64] with the corresponding modulation of neuronal population dynamics [65, 66] during early learning. Exploring the link between contextualization and neural replay could provide additional insights into this issue [6, 12, 13, 15].”</p><disp-quote content-type="editor-comment"><p>(8) And this analysis could be confounded by the fact that they are comparing the last element in a sequence vs the first movement in a new one.</p></disp-quote><p>We have now addressed this control analysis in the revised manuscript:</p><p>Results (Lines 310-316)</p><p>“Offline contextualization strongly correlated with cumulative micro-offline gains (r = 0.903, R<sup>2</sup> = 0.816, p &lt; 0.001; Figure 5 – figure supplement 1A, inset) across decoder window durations ranging from 50 to 250ms (Figure 5 – figure supplement 1B, C). The offline contextualization between the final sequence of each trial and the second sequence of the subsequent trial (excluding the first sequence) yielded comparable results. This indicates that pre-planning at the start of each practice trial did not directly influence the offline contextualization measure [30] (Figure 5 – figure supplement 2A, <italic>1st vs. 2nd Sequence approaches</italic>).”</p><p>Discussion (lines 408-416):</p><p>“Offline contextualization consistently correlated with early learning gains across a range of decoding windows (50–250ms; Figure 5 – figure supplement 1). This result remained unchanged when measuring offline contextualization between the last and second sequence of consecutive trials, inconsistent with a possible confounding effect of pre-planning [30] (Figure 5 – figure supplement 2A). On the other hand, online contextualization did not predict learning (Figure 5 – figure supplement 3). Consistent with these results the average within-subject correlation between offline contextualization and micro-offline gains was significantly stronger than within-subject correlations between online contextualization and either micro-online or micro-offline gains (Figure 5 – figure supplement 4).”</p><p>It also seems to be the case that many analyses suggested by the reviewers in the first round of revisions that could have helped strengthen the manuscript have not been included (they are only in the rebuttal). Moreover, some of the control analyses mentioned in the rebuttal seem not to be described anywhere, neither in the manuscript, nor in the rebuttal itself; please double check that.</p><p>All suggested analyses carried out and mentioned are now in the revised manuscript.</p><disp-quote content-type="editor-comment"><p><bold>eLife Assessment</bold></p><p>This valuable study investigates how the neural representation of individual finger movements changes during the early period of sequence learning. By combining a new method for extracting features from human magnetoencephalography data and decoding analyses, the authors provide incomplete evidence of an early, swift change in the brain regions correlated with sequence learning…</p></disp-quote><p>We have now included all the requested control analyses supporting “an early, swift change in the brain regions correlated with sequence learning”:</p><disp-quote content-type="editor-comment"><p>The addition of more control analyses to rule out that head movement artefacts influence the findings,</p></disp-quote><p>We now include data in Figure 3 – figure supplement 3D showing that head movement was minimal in all participants (mean of 1.159 mm ± 1.077 SD). Further, we have implemented the requested additional control analyses addressing this issue:</p><p>Results (lines 207-211):</p><p>“An alternate decoder trained on ICA components labeled as movement or physiological artefacts (e.g. – head movement, ECG, eye movements and blinks; Figure 3 – figure supplement 3A, D) and removed from the original input feature set during the pre-processing stage approached chance-level performance (Figure 4 – figure supplement 3), indicating that the 4-class hybrid decoder results were not driven by task-related artefacts.”</p><p>Results (lines 261-268):</p><p>“As expected, the 5-class hybrid-space decoder performance approached chance levels when tested with randomly shuffled keypress labels (18.41%± SD 7.4% for Day 1 data; Figure 4 – figure supplement 3C). Task-related eye movements did not explain these results since an alternate 5-class hybrid decoder constructed from three eye movement features (gaze position at the KeyDown event, gaze position 200ms later, and peak eye movement velocity within this window; Figure 4 – figure supplement 3A) performed at chance levels (cross-validated test accuracy = 0.2181; Figure 4 – figure supplement 3B, C). “</p><p>Discussion (Lines 362-368):</p><p>“Task-related movements—which also express in lower frequency ranges—did not explain these results given the near chance-level performance of alternative decoders trained on (a) artefact-related ICA components removed during MEG preprocessing (Figure 3 – figure supplement 3A-C) and on (b) task-related eye movement features (Figure 4 – figure supplement 3B, C). This explanation is also inconsistent with the minimal average head motion of 1.159 mm (± 1.077 SD) across the MEG recording (Figure 3 – figure supplement 3D).“</p><disp-quote content-type="editor-comment"><p>and to further explain the proposal of offline contextualization during short rest periods as the basis for improvement performance would strengthen the manuscript.</p></disp-quote><p>We have edited the manuscript to clarify that the degree of representational differentiation (contextualization) parallels skill learning. We have no evidence at this point to indicate that “offline contextualization during short rest periods is the basis for improvement in performance”. The following areas of the revised manuscript now clarify this point:</p><p>Summary (Lines 455-458):</p><p>“In summary, individual sequence action representations contextualize during early learning of a new skill and the degree of differentiation parallels skill gains. Differentiation of the neural representations developed during rest intervals of early learning to a larger extent than during practice in parallel with rapid consolidation of skill.”</p><p>Additional control analyses are also provided supporting a link between offline contextualization and early learning:</p><p>Results (lines 302-318):</p><p>“The Euclidian distance between neural representations of Index<sub>OP1</sub> (i.e. - index finger keypress at ordinal position 1 of the sequence) and Index<sub>OP5</sub> (i.e. - index finger keypress at ordinal position 5 of the sequence) increased progressively during early learning (Figure 5A)—predominantly during rest intervals (offline contextualization) rather than during practice (online) (t = 4.84, p &lt; 0.001, df = 25, Cohen's d = 1.2; Figure 5B; Figure 5 – figure supplement 1A). An alternative online contextualization determination equaling the time interval between online and offline comparisons (<italic>Trial-based;</italic> 10 seconds between Index<sub>OP1</sub> and Index<sub>OP5</sub> observations in both cases) rendered a similar result (Figure 5 – figure supplement 2B).</p><p>Offline contextualization strongly correlated with cumulative micro-offline gains (r = 0.903, R<sup>2</sup> = 0.816, p &lt; 0.001; Figure 5 – figure supplement 1A, inset) across decoder window durations ranging from 50 to 250ms (Figure 5 – figure supplement 1B, C). The offline contextualization between the final sequence of each trial and the second sequence of the subsequent trial (excluding the first sequence) yielded comparable results. This indicates that pre-planning at the start of each practice trial did not directly influence the offline contextualization measure [30] (Figure 5 – figure supplement 2A, 1st vs. 2nd Sequence approaches). Conversely, online contextualization (using either measurement approach) did not explain early online learning gains (i.e. – Figure 5 – figure supplement 3).”</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public review):</bold></p><p>Summary:</p><p>This study addresses the issue of rapid skill learning and whether individual sequence elements (here: finger presses) are differentially represented in human MEG data. The authors use a decoding approach to classify individual finger elements and accomplish an accuracy of around 94%. A relevant finding is that the neural representations of individual finger elements dynamically change over the course of learning. This would be highly relevant for any attempts to develop better brain machine interfaces - one now can decode individual elements within a sequence with high precision, but these representations are not static but develop over the course of learning.</p><p>Strengths:</p><p>The work follows a large body of work from the same group on the behavioural and neural foundations of sequence learning. The behavioural task is well established a neatly designed to allow for tracking learning and how individual sequence elements contribute. The inclusion of short offline rest periods between learning epochs has been influential because it has revealed that a lot, if not most of the gains in behaviour (ie speed of finger movements) occur in these so-called micro-offline rest periods.</p><p>The authors use a range of new decoding techniques, and exhaustively interrogate their data in different ways, using different decoding approaches. Regardless of the approach, impressively high decoding accuracies are observed, but when using a hybrid approach that combines the MEG data in different ways, the authors observe decoding accuracies of individual sequence elements from the MEG data of up to 94%.</p><p>Weaknesses:</p><p>A formal analysis and quantification of how head movement may have contributed to the results should be included in the paper or supplemental material. The type of correlated head movements coming from vigorous key presses aren't necessarily visible to the naked eye, and even if arms etc are restricted, this will not preclude shoulder, neck or head movement necessarily; if ICA was conducted, for example, the authors are in the position to show the components that relate to such movement; but eye-balling the data would not seem sufficient. The related issue of eye movements is addressed via classifier analysis. A formal analysis which directly accounts for finger/eye movements in the same analysis as the main result (ie any variance related to these factors) should be presented.</p></disp-quote><p>We now present additional data related to head (Figure 3 – figure supplement 3; note that average measured head movement across participants was 1.159 mm ± 1.077 SD) and eye movements (Figure 4 – figure supplement 3) and have implemented the requested control analyses addressing this issue. They are reported in the revised manuscript in the following locations: Results (lines 207-211), Results (lines 261-268), Discussion (Lines 362-368).</p><disp-quote content-type="editor-comment"><p>This reviewer recommends inclusion of a formal analysis that the intra-vs inter parcels are indeed completely independent. For example, the authors state that the inter-parcel features reflect &quot;lower spatially resolved whole-brain activity patterns or global brain dynamics&quot;. A formal quantitative demonstration that the signals indeed show &quot;complete independence&quot; (as claimed by the authors) and are orthogonal would be helpful.</p></disp-quote><p>Please note that we never claim in the manuscript that the parcel-space and regional voxelspace features show “complete independence”. More importantly, input feature orthogonality is not a requirement for the machine learning-based decoding methods utilized in the present study while non-redundancy is [7] (a requirement satisfied by our data, see below). Finally, our results show that the hybrid space decoder out-performed all other methods even after input features were fully orthogonalized with LDA (the procedure used in all contextualization analyses) or PCA dimensionality reduction procedures prior to the classification step (Figure 3 – figure supplement 2).</p><p>Relevant to this issue, please note that if spatially overlapping parcel- and voxel-space timeseries only provided redundant information, inclusion of both as input features should increase model over-fitting to the training dataset and decrease overall cross-validated test accuracy [8]. In the present study however, we see the opposite effect on decoder performance. First, Figure 3 – figure supplement 1 &amp; 2 clearly show that decoders constructed from hybrid-space features outperform the other input feature (sensor-, wholebrain parcel- and whole-brain voxel-) spaces in every case (e.g. – wideband, all narrowband frequency ranges, and even after the input space is fully orthogonalized through dimensionality reduction procedures prior to the decoding step). Furthermore, Figure 3 – figure supplement 6 shows that hybrid-space decoder performance supers when parceltime series that spatially overlap with the included regional voxel-spaces are removed from the input feature set.</p><p>We state in the Discussion (lines 353-356)</p><p>“The observation of increased cross-validated test accuracy (as shown in Figure 3 – Figure Supplement 6) indicates that the spatially overlapping information in parcel- and voxel-space time-series in the hybrid decoder was complementary, rather than redundant [41].”</p><p>To gain insight into the complimentary information contributed by the two spatial scales to the hybrid-space decoder, we first independently computed the matrix rank for whole-brain parcel- and voxel-space input features for each participant (shown in Author response image 1). The results indicate that whole-brain parcel-space input features are full rank (rank = 148) for all participants (i.e. - MEG activity is orthogonal between all parcels). The matrix rank of voxelspace input features (rank = 267± 17 SD), exceeded the parcel-space rank for all participants and approached the number of useable MEG sensor channels (n = 272). Thus, voxel-space features provide both additional and complimentary information to representations at the parcel-space scale.</p><fig id="sa4fig1" position="float"><label>Author response image 1.</label><caption><title>Matrix rank computed for whole-brain parcel- and voxel-space time-series in individual subjects across the training run.</title><p>The results indicate that whole-brain parcel-space input features are full rank (rank = 148) for all participants (i.e. - MEG activity is orthogonal between all parcels). The matrix rank of voxel-space input features (rank = 267 ± 17 SD), on the other hand, approached the number of useable MEG sensor channels (n = 272). Although not full rank, the voxel-space rank exceeded the parcel-space rank for all participants. Thus, some voxel-space features provide additional orthogonal information to representations at the parcel-space scale. An expression of this is shown in the correlation distribution between parcel and constituent voxel time-series in Figure 2—figure Supplement 2.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102475-sa4-fig1-v1.tif"/></fig><p>Figure 2—figure Supplement 2 in the revised manuscript now shows that the degree of dependence between the two spatial scales varies over the regional voxel-space. That is, some voxels within a given parcel correlate strongly with the time-series of the parcel they belong to, while others do not. This finding is consistent with a documented increase in correlational structure of neural activity across spatial scales that does not reflect perfect dependency or orthogonality [9]. Notably, the regional voxel-spaces included in the hybridspace decoder are significantly less correlated with the averaged parcel-space time-series than excluded voxels. We now point readers to this new figure in the results.</p><p>Taken together, these results indicate that the multi-scale information in the hybrid feature set is complimentary rather than orthogonal. This is consistent with the idea that hybridspace features better represent multi-scale temporospatial dynamics reported to be a fundamental characteristic of how the brain stores and adapts memories, and generates behavior across species [9].</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public review):</bold></p><p>Summary:</p><p>The current paper consists of two parts. The first part is the rigorous feature optimization of the MEG signal to decode individual finger identity performed in a sequence (4-1-3-2-4; 1~4 corresponds to little~index fingers of the left hand). By optimizing various parameters for the MEG signal, in terms of (i) reconstructed source activity in voxel- and parcel-level resolution and their combination, (ii) frequency bands, and (iii) time window relative to press onset for each finger movement, as well as the choice of decoders, the resultant &quot;hybrid decoder&quot; achieved extremely high decoding accuracy (~95%). This part seems driven almost by pure engineering interest in gaining as high decoding accuracy as possible.</p><p>In the second part of the paper, armed with the successful 'hybrid decoder,' the authors asked more scientific questions about how neural representation of individual finger movement that is embedded in a sequence, changes during a very early period of skill learning and whether and how such representational change can predict skill learning. They assessed the difference in MEG feature patterns between the first and the last press 4 in sequence 41324 at each training trial and found that the pattern differentiation progressively increased over the course of early learning trials. Additionally, they found that this pattern differentiation specifically occurred during the rest period rather than during the practice trial. With a significant correlation between the trial-by-trial profile of this pattern differentiation and that for accumulation of offline learning, the authors argue that such &quot;contextualization&quot; of finger movement in a sequence (e.g., what-where association) underlies the early improvement of sequential skill. This is an important and timely topic for the field of motor learning and beyond.</p><p>Strengths:</p><p>Each part has its own strength. For the first part, the use of temporally rich neural information (MEG signal) has a significant advantage over previous studies testing sequential representations using fMRI. This allowed the authors to examine the earliest period (= the first few minutes of training) of skill learning with finer temporal resolution. Through the optimization of MEG feature extraction, the current study achieved extremely high decoding accuracy (approx. 94%) compared to previous works. For the second part, the finding of the early &quot;contextualization&quot; of the finger movement in a sequence and its correlation to early (offline) skill improvement is interesting and important. The comparison between &quot;online&quot; and &quot;offline&quot; pattern distance is a neat idea.</p><p>Weaknesses:</p><p>Despite the strengths raised, the specific goal for each part of the current paper, i.e., achieving high decoding accuracy and answering the scientific question of early skill learning, seems not to harmonize with each other very well. In short, the current approach, which is solely optimized for achieving high decoding accuracy, does not provide enough support and interpretability for the paper's interesting scientific claim. This reminds me of the accuracy-explainability tradeoff in machine learning studies (e.g., Linardatos et al., 2020). More details follow.</p><p>There are a number of different neural processes occurring before and after a key press, such as planning of upcoming movement and ahead around premotor/parietal cortices, motor command generation in primary motor cortex, sensory feedback related processes in sensory cortices, and performance monitoring/evaluation around the prefrontal area. Some of these may show learning-dependent change and others may not.</p></disp-quote><p>In this paper, the focus as stated in the Introduction was to evaluate “the millisecond-level differentiation of discrete action representations during learning”, a proposal that first required the development of more accurate computational tools. Our first step, reported here, was to develop that tool. With that in hand, we then proceeded to test if neural representations differentiated during early skill learning. Our results showed they did. Addressing the question the Reviewer asks is part of exciting future work, now possible based on the results presented in this paper. We acknowledge this issue in the revised Discussion:</p><p>Discussion (Lines 428-434):</p><p>“In this study, classifiers were trained on MEG activity recorded during or immediately after each keypress, emphasizing neural representations related to action execution, memory consolidation and recall over those related to planning. An important direction for future research is determining whether separate decoders can be developed to distinguish the representations or networks separately supporting these processes. Ongoing work in our lab is addressing this question. The present accuracy results across varied decoding window durations and alignment with each keypress action support the feasibility of this approach (Figure 3—figure supplement 5).”</p><disp-quote content-type="editor-comment"><p>Given the use of whole-brain MEG features with a wide time window (up to ~200 ms after each key press) under the situation of 3~4 Hz (i.e., 250~330 ms press interval) typing speed, these different processes in different brain regions could have contributed to the expression of the &quot;contextualization,&quot; making it difficult to interpret what really contributed to the &quot;contextualization&quot; and whether it is learning related. Critically, the majority of data used for decoder training has the chance of such potential overlap of signal, as the typing speed almost reached a plateau already at the end of the 11th trial and stayed until the 36th trial. Thus, the decoder could have relied on such overlapping features related to the future presses. If that is the case, a gradual increase in &quot;contextualization&quot; (pattern separation) during earlier trials makes sense, simply because the temporal overlap of the MEG feature was insufficient for the earlier trials due to slower typing speed. Several direct ways to address the above concern, at the cost of decoding accuracy to some degree, would be either using the shorter temporal window for the MEG feature or training the model with the early learning period data only (trials 1 through 11) to see if the main results are unaffected would be some example.</p></disp-quote><p>We now include additional analyses carried out with decoding time windows ranging from 50 to 250ms in duration, which have been added to the revised manuscript as follows:</p><p>Results (lines 258-261):</p><p>“The improved decoding accuracy is supported by greater differentiation in neural representations of the index finger keypresses performed at positions 1 and 5 of the sequence (Figure 4A), and by the trial-by-trial increase in 2-class decoding accuracy over early learning (Figure 4C) across different decoder window durations (Figure 4 – figure supplement 2).”</p><p>Results (lines 310-312):</p><p>“Offline contextualization strongly correlated with cumulative micro-offline gains (r = 0.903, R<sup>2</sup> = 0.816, p &lt; 0.001; Figure 5 – figure supplement 1A, inset) across decoder window durations ranging from 50 to 250ms (Figure 5 – figure supplement 1B, C).“</p><p>Discussion (lines 382-385):</p><p>“This was further supported by the progressive differentiation of neural representations of the index finger keypress (Figure 4A) and by the robust trial-by trial increase in 2-class decoding accuracy across time windows ranging between 50 and 250ms (Figure 4C; Figure 4 – figure supplement 2).”</p><p>Discussion (lines 408-9):</p><p>“Offline contextualization consistently correlated with early learning gains across a range of decoding windows (50–250ms; Figure 5 – figure supplement 1).”</p><p>Several new control analyses are also provided addressing the question of overlapping keypresses:</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public review):</bold></p><p>Summary:</p><p>One goal of this paper is to introduce a new approach for highly accurate decoding of finger movements from human magnetoencephalography data via dimension reduction of a &quot;multi-scale, hybrid&quot; feature space. Following this decoding approach, the authors aim to show that early skill learning involves &quot;contextualization&quot; of the neural coding of individual movements, relative to their position in a sequence of consecutive movements.</p><p>Furthermore, they aim to show that this &quot;contextualization&quot; develops primarily during short rest periods interspersed with skill training and correlates with a performance metric which the authors interpret as an indicator of offline learning.</p><p>Strengths:</p><p>A strength of the paper is the innovative decoding approach, which achieves impressive decoding accuracies via dimension reduction of a &quot;multi-scale, hybrid space&quot;. This hybridspace approach follows the neurobiologically plausible idea of concurrent distribution of neural coding across local circuits as well as large-scale networks. A further strength of the study is the large number of tested dimension reduction techniques and classifiers.</p><p>Weaknesses:</p><p>A clear weakness of the paper lies in the authors' conclusions regarding &quot;contextualization&quot;. Several potential confounds, which partly arise from the experimental design (mainly the use of a single sequence) and which are described below, question the neurobiological implications proposed by the authors and provide a simpler explanation of the results. Furthermore, the paper follows the assumption that short breaks result in offline skill learning, while recent evidence, described below, casts doubt on this assumption.</p></disp-quote><p>Please, see below for detailed response to each of these points.</p><disp-quote content-type="editor-comment"><p>Specifically: The authors interpret the ordinal position information captured by their decoding approach as a reflection of neural coding dedicated to the local context of a movement (Figure 4). One way to dissociate ordinal position information from information about the moving effectors is to train a classifier on one sequence and test the classifier on other sequences that require the same movements, but in different positions (Kornysheva et al., Neuron 2019). In the present study, however, participants trained to repeat a single sequence (4-1-3-2-4).</p></disp-quote><p>A crucial difference between our present study and the elegant study from Kornysheva et al. (2019) in Neuron highlighted by the Reviewer is that while ours is a learning study, the Kornysheva et al. study is not. Kornysheva et al. included an initial separate behavioral training session (i.e. – performed outside of the MEG) during which participants learned associations between fractal image patterns and different keypress sequences. Then in a separate, later MEG session—after the stimulus-response associations had been already learned in the first session—participants were tasked with recalling the learned sequences in response to a presented visual cue (i.e. – the paired fractal pattern).</p><p>Our rationale for not including multiple sequences in the same Day 1 training session of our study design was that it would lead to prominent interference effects, as widely reported in the literature [10-12]. Thus, while we had to take the issue of interference into consideration for our design, the Kornysheva et al. study did not. While Kornysheva et al. aimed to “dissociate ordinal position information from information about the moving effectors”, we tested various untrained sequences on Day 2 allowing us to determine that the contextualization result was specific to the trained sequence. By using this approach, we avoided interference effects on the learning of the primary skill caused by simultaneous acquisition of a second skill.</p><p>The revised manuscript states our findings related to the Day 2 Control data in the following locations:</p><p>Results (lines 117-122):</p><p>“On the following day, participants were retested on performance of the same sequence (4-1-3-2-4) over 9 trials (<italic>Day 2 Retest</italic>), as well as on the single-trial performance of 9 different untrained control sequences (<italic>Day 2 Controls</italic>: 2-1-3-4-2, 4-2-4-3-1, 3-4-2-3-1, 1-4-3-4-2, 3-2-4-3-1, 1-4-2-3-1, 3-2-4-2-1, 3-2-1-4-2, and 4-23-1-4). As expected, an upward shift in performance of the trained sequence (0.68 ± SD 0.56 keypresses/s; t = 7.21, <italic>p</italic> &lt; 0.001) was observed during Day 2 Retest, indicative of an overnight skill consolidation effect (Figure 1 – figure supplement 1A).”</p><p>Results (lines 212-219):</p><p>“Utilizing the highest performing decoders that included LDA-based manifold extraction, we assessed the robustness of hybrid-space decoding over multiple sessions by applying it to data collected on the following day during the Day 2 Retest (9-trial retest of the trained sequence) and Day 2 Control (single-trial performance of 9 different untrained sequences) blocks. The decoding accuracy for Day 2 MEG data remained high (87.11% ± SD 8.54% for the trained sequence during Retest, and 79.44% ± SD 5.54% for the untrained Control sequences; Figure 3 – figure supplement 4). Thus, index finger classifiers constructed using the hybrid decoding approach robustly generalized from Day 1 to Day 2 across trained and untrained keypress sequences.”</p><p>Results (lines 269-273):</p><p>“On Day 2, incorporating contextual information into the hybrid-space decoder enhanced classification accuracy for the trained sequence only (improving from 87.11% for 4-class to 90.22% for 5-class), while performing at or below-chance levels for the Control sequences (≤ 30.22% ± SD 0.44%). Thus, the accuracy improvements resulting from inclusion of contextual information in the decoding framework was specific for the trained skill sequence.”</p><disp-quote content-type="editor-comment"><p>As a result, ordinal position information is potentially confounded by the fixed finger transitions around each of the two critical positions (first and fifth press). Across consecutive correct sequences, the first keypress in a given sequence was always preceded by a movement of the index finger (=last movement of the preceding sequence), and followed by a little finger movement. The last keypress, on the other hand, was always preceded by a ring finger movement, and followed by an index finger movement (=first movement of the next sequence). Figure 4 - supplement 2 shows that finger identity can be decoded with high accuracy (&gt;70%) across a large time window around the time of the keypress, up to at least +/-100 ms (and likely beyond, given that decoding accuracy is still high at the boundaries of the window depicted in that figure). This time window approaches the keypress transition times in this study. Given that distinct finger transitions characterized the first and fifth keypress, the classifier could thus rely on persistent (or &quot;lingering&quot;) information from the preceding finger movement, and/or &quot;preparatory&quot; information about the subsequent finger movement, in order to dissociate the first and fifth keypress.</p><p>Currently, the manuscript provides little evidence that the context information captured by the decoding approach is more than a by-product of temporally extended, and therefore overlapping, but independent neural representations of consecutive keypresses that are executed in close temporal proximity - rather than a neural representation dedicated to context.</p><p>During the review process, the authors pointed out that a &quot;mixing&quot; of temporally overlapping information from consecutive keypresses, as described above, should result in systematic misclassifications and therefore be detectable in the confusion matrices in Figures 3C and 4B, which indeed do not provide any evidence that consecutive keypresses are systematically confused. However, such absence of evidence (of systematic misclassification) should be interpreted with caution, and, of course, provides no evidence of absence. The authors also pointed out that such &quot;mixing&quot; would hamper the discriminability of the two ordinal positions of the index finger, given that &quot;ordinal position 5&quot; is systematically followed by &quot;ordinal position 1&quot;. This is a valid point which, however, cannot rule out that &quot;contextualization&quot; nevertheless reflects the described &quot;mixing&quot;.</p></disp-quote><p>The revised manuscript contains several control analyses which rule out this potential confound.</p><p>Results (lines 318-328):</p><p>“Within-subject correlations were consistent with these group-level findings. The average correlation between offline contextualization and micro-offline gains within individuals was significantly greater than zero (Figure 5 – figure supplement 4, left; t = 3.87, p = 0.00035, df = 25, Cohen's d = 0.76) and stronger than correlations between online contextualization and either micro-online (Figure 5 – figure supplement 4, middle; t = 3.28, p = 0.0015, df = 25, Cohen's d = 1.2) or micro-offline gains (Figure 5 – figure supplement 4, right; t = 3.7021, p = 5.3013e-04, df = 25, Cohen's d = 0.69). These findings were not explained by behavioral changes of typing rhythm (t = -0.03, <italic>p</italic> = 0.976; Figure 5 – figure supplement 5), adjacent keypress transition times (R<sup>2</sup> = 0.00507, F[1,3202] = 16.3; Figure 5 – figure supplement 6), or overall typing speed (between-subject; R<sup>2</sup> = 0.028, <italic>p</italic> = 0.41; Figure 5 – figure supplement 7).”</p><p>Results (lines 385-390):</p><p>“Further, the 5-class classifier—which directly incorporated information about the sequence location context of each keypress into the decoding pipeline—improved decoding accuracy relative to the 4-class classifier (Figure 4C). Importantly, testing on Day 2 revealed specificity of this representational differentiation for the trained skill but not for the same keypresses performed during various unpracticed control sequences (Figure 5C).”</p><p>Discussion (lines 408-423):</p><p>“Offline contextualization consistently correlated with early learning gains across a range of decoding windows (50–250ms; Figure 5 – figure supplement 1). This result remained unchanged when measuring offline contextualization between the last and second sequence of consecutive trials, inconsistent with a possible confounding effect of pre-planning [30] (Figure 5 – figure supplement 2A). On the other hand, online contextualization did not predict learning (Figure 5 – figure supplement 3). Consistent with these results the average within-subject correlation between offline contextualization and micro-offline gains was significantly stronger than within subject correlations between online contextualization and either micro-online or micro-offline gains (Figure 5 – figure supplement 4).</p><p>Offline contextualization was not driven by trial-by-trial behavioral differences, including typing rhythm (Figure 5 – figure supplement 5) and adjacent keypress transition times (Figure 5 – figure supplement 6) nor by between-subject differences in overall typing speed (Figure 5 – figure supplement 7)—ruling out a reliance on differences in the temporal overlap of keypresses. Importantly, offline contextualization documented on Day 1 stabilized once a performance plateau was reached (trials 11-36), and was retained on Day 2, documenting overnight consolidation of the differentiated neural representations.”</p><disp-quote content-type="editor-comment"><p>During the review process, the authors responded to my concern that training of a single sequence introduces the potential confound of &quot;mixing&quot; described above, which could have been avoided by training on several sequences, as in Kornysheva et al. (Neuron 2019), by arguing that Day 2 in their study did include control sequences. However, the authors' findings regarding these control sequences are fundamentally different from the findings in Kornysheva et al. (2019), and do not provide any indication of effector-independent ordinal information in the described contextualization - but, actually, the contrary. In Kornysheva et al. (Neuron 2019), ordinal, or positional, information refers purely to the rank of a movement in a sequence. In line with the idea of competitive queuing, Kornysheva et al. (2019) have shown that humans prepare for a motor sequence via a simultaneous representation of several of the upcoming movements, weighted by their rank in the sequence. Importantly, they could show that this gradient carries information that is largely devoid of information about the order of specific effectors involved in a sequence, or their timing, in line with competitive queuing. They showed this by training a classifier to discriminate between the five consecutive movements that constituted one specific sequence of finger movements (five classes: 1st, 2nd, 3rd, 4th, 5th movement in the sequence) and then testing whether that classifier could identify the rank (1st, 2nd, 3rd, etc) of movements in another sequence, in which the fingers moved in a different order, and with different timings. Importantly, this approach demonstrated that the graded representations observed during preparation were largely maintained after this cross decoding, indicating that the sequence was represented via ordinal position information that was largely devoid of information about the specific effectors or timings involved in sequence execution. This result differs completely from the findings in the current manuscript. Dash et al. report a drop in detected ordinal position information (degree of contextualization in figure 5C) when testing for contextualization in their novel, untrained sequences on Day 2, indicating that context and ordinal information as defined in Dash et al. is not at all devoid of information about the specific effectors involved in a sequence. In this regard, a main concern in my public review, as well as the second reviewer's public review, is that Dash et al. cannot tell apart, by design, whether there is truly contextualization in the neural representation of a sequence (which they claim), or whether their results regarding &quot;contextualization&quot; are explained by what they call &quot;mixing&quot; in their author response, i.e., an overlap of representations of consecutive movements, as suggested as an alternative explanation by Reviewer 2 and myself.</p></disp-quote><p>Again, as stated in response to a related comment by the Reviewer above, it is not surprising that our results differ from the study by Kornysheva et al. (2019) . A crucial difference between the studies that the Reviewer fails to recognize is that while ours is a learning study, the Kornysheva et al. study is not. Our rationale for not including multiple sequences in the same Day 1 training session of our study design was that it would lead to prominent interference effects, as widely reported in the literature [10-12]. Thus, while we had to take the issue of interference into consideration for our design, the Kornysheva et al. study did not, since it was not concerned with learning dynamics. The strengths of the elegant Kornysheva study highlighted by the Reviewer—that the pre-planned sequence queuing gradient of sequence actions was independent of the effectors or timings used—is precisely due to the fact that participants were selecting between sequence options that had been previously—and equivalently—learned. The decoders in the Kornynsheva study were trained to classify effector- and timing-independent sequence position information— by design—so it is not surprising that this is the information they reflect.</p><p>The questions asked in our study were different: (1) Do the neural representations of the same sequence action executed in different skill (ordinal sequence) locations differentiate (contextualize) during early learning? and (2) Is the observed contextualization specific to the learned sequence? Thus, while Kornysheva et al. aimed to “dissociate ordinal position information from information about the moving effectors”, we tested various untrained sequences on Day 2 allowing us to determine that the contextualization result was specific to the trained sequence. By using this approach, we avoided interference effects on the learning of the primary skill caused by simultaneous acquisition of a second skill.</p><disp-quote content-type="editor-comment"><p>Such temporal overlap of consecutive, independent finger representations may also account for the dynamics of &quot;ordinal coding&quot;/&quot;contextualization&quot;, i.e., the increase in 2class decoding accuracy, across Day 1 (Figure 4C). As learning progresses, both tapping speed and the consistency of keypress transition times increase (Figure 1), i.e., consecutive keypresses are closer in time, and more consistently so. As a result, information related to a given keypress is increasingly overlapping in time with information related to the preceding and subsequent keypresses. The authors seem to argue that their regression analysis in Figure 5 - figure supplement 3 speaks against any influence of tapping speed on &quot;ordinal coding&quot; (even though that argument is not made explicitly in the manuscript). However, Figure 5 - figure supplement 3 shows inter-individual differences in a between-subject analysis (across trials, as in panel A, or separately for each trial, as in panel B), and, therefore, says little about the within-subject dynamics of &quot;ordinal coding&quot; across the experiment. A regression of trial-by-trial &quot;ordinal coding&quot; on trial-by-trial tapping speed (either within-subject, or at a group-level, after averaging across subjects) could address this issue. Given the highly similar dynamics of &quot;ordinal coding&quot; on the one hand (Figure 4C), and tapping speed on the other hand (Figure 1B), I would expect a strong relationship between the two in the suggested within-subject (or group-level) regression.</p></disp-quote><p>The aim of the between-subject regression analysis presented in the Results (see below) and in Figure 5—figure supplement 7 (previously Figure 5—figure supplement 3) of the revised manuscript, was to rule out a general effect of tapping speed on the magnitude of contextualization observed. If temporal overlap of neural representations was driving their differentiation, then participants typing at higher speeds should also show greater contextualization scores. We made the decision to use a between-subject analysis to address this issue since within-subject skill speed variance was rather small over most of the training session.</p><p>The Reviewer’s request that we additionally carry-out a “regression of trial-by-trial &quot;ordinal coding&quot; on trial-by-trial tapping speed (either within-subject, or at a group-level, after averaging across subjects)” is essentially the same request of Reviewer 2 above. That request was to perform a modified simple linear regression analysis where the predictor is the sum the 4-4 and 4-1 transition times, since these transitions are where any temporal overlaps of neural representations would occur. A new Figure 5 – figure supplement 6 in the revised manuscript includes a scatter plot showing the sum of adjacent index finger keypress transition times (i.e. – the 4-4 transition at the conclusion of one sequence iteration and the 4-1 transition at the beginning of the next sequence iteration) versus online contextualization distances measured during practice trials. Both the keypress transition times and online contextualization scores were z-score normalized within individual subjects, and then concatenated into a single data superset. As is clear in the figure data, results of the regression analysis showed a very weak linear relationship between the two (R<sup>2</sup> = 0.00507, F[1,3202] = 16.3). Thus, contextualization score magnitudes do not reflect the amount of overlap between adjacent keypresses when assessed either within- or between-subject.</p><p>The revised manuscript now states:</p><p>Results (lines 318-328):</p><p>“Within-subject correlations were consistent with these group-level findings. The average correlation between offline contextualization and micro-offline gains within individuals was significantly greater than zero (Figure 5 – figure supplement 4, left; t = 3.87, p = 0.00035, df = 25, Cohen's d = 0.76) and stronger than correlations between online contextualization and either micro-online (Figure 5 – figure supplement 4, middle; t = 3.28, p = 0.0015, df = 25, Cohen's d = 1.2) or micro-offline gains (Figure 5 – figure supplement 4, right; t = 3.7021, p = 5.3013e-04, df = 25, Cohen's d = 0.69). These findings were not explained by behavioral changes of typing rhythm (t = -0.03, <italic>p</italic> = 0.976; Figure 5 – figure supplement 5), adjacent keypress transition times (R<sup>2</sup> = 0.00507, F[1,3202] = 16.3; Figure 5 – figure supplement 6), or overall typing speed (between-subject; R<sup>2</sup> = 0.028, <italic>p</italic> = 0.41; Figure 5 – figure supplement 7).”</p><disp-quote content-type="editor-comment"><p>Furthermore, learning should increase the number of (consecutively) correct sequences, and, thus, the consistency of finger transitions. Therefore, the increase in 2-class decoding accuracy may simply reflect an increasing overlap in time of increasingly consistent information from consecutive keypresses, which allows the classifier to dissociate the first and fifth keypress more reliably as learning progresses, simply based on the characteristic finger transitions associated with each. In other words, given that the physical context of a given keypress changes as learning progresses - keypresses move closer together in time and are more consistently correct - it seems problematic to conclude that the mental representation of that context changes. To draw that conclusion, the physical context should remain stable (or any changes to the physical context should be controlled for).</p></disp-quote><p>The revised manuscript now addresses specifically the question of mixing of temporally overlapping information:</p><p>Results (Lines 310-328)</p><p>“Offline contextualization strongly correlated with cumulative micro-offline gains (r = 0.903, R<sup>2</sup> = 0.816, p &lt; 0.001; Figure 5 – figure supplement 1A, inset) across decoder window durations ranging from 50 to 250ms (Figure 5 – figure supplement 1B, C). The offline contextualization between the final sequence of each trial and the second sequence of the subsequent trial (excluding the first sequence) yielded comparable results. This indicates that pre-planning at the start of each practice trial did not directly influence the offline contextualization measure [30] (Figure 5 – figure supplement 2A, <italic>1st vs. 2nd Sequence approaches</italic>). Conversely, online contextualization (using either measurement approach) did not explain early online learning gains (i.e. – Figure 5 – figure supplement 3). Within-subject correlations were consistent with these group-level findings. The average correlation between offline contextualization and micro-offline gains within individuals was significantly greater than zero (Figure 5 – figure supplement 4, left; t = 3.87, p = 0.00035, df = 25, Cohen's d = 0.76) and stronger than correlations between online contextualization and either micro-online (Figure 5 – figure supplement 4, middle; t = 3.28, p = 0.0015, df = 25, Cohen's d = 1.2) or micro-offline gains (Figure 5 – figure supplement 4, right; t = 3.7021, p = 5.3013e-04, df = 25, Cohen's d = 0.69). These findings were not explained by behavioral changes of typing rhythm (t = -0.03, <italic>p</italic> = 0.976; Figure 5 – figure supplement 5), adjacent keypress transition times (R<sup>2</sup> = 0.00507, F[1,3202] = 16.3; Figure 5 – figure supplement 6), or overall typing speed (between-subject; R<sup>2</sup> = 0.028, <italic>p</italic> = 0.41; Figure 5 – figure supplement 7). “</p><p>Discussion (Lines 417-423)</p><p>“Offline contextualization was not driven by trial-by-trial behavioral differences, including typing rhythm (Figure 5 – figure supplement 5) and adjacent keypress transition times (Figure 5 – figure supplement 6) nor by between-subject differences in overall typing speed (Figure 5 – figure supplement 7)—ruling out a reliance on differences in the temporal overlap of keypresses. Importantly, offline contextualization documented on Day 1 stabilized once a performance plateau was reached (trials 11-36), and was retained on Day 2, documenting overnight consolidation of the differentiated neural representations.”</p><disp-quote content-type="editor-comment"><p>A similar difference in physical context may explain why neural representation distances (&quot;differentiation&quot;) differ between rest and practice (Figure 5). The authors define &quot;offline differentiation&quot; by comparing the hybrid space features of the last index finger movement of a trial (ordinal position 5) and the first index finger movement of the next trial (ordinal position 1). However, the latter is not only the first movement in the sequence but also the very first movement in that trial (at least in trials that started with a correct sequence), i.e., not preceded by any recent movement. In contrast, the last index finger of the last correct sequence in the preceding trial includes the characteristic finger transition from the fourth to the fifth movement. Thus, there is more overlapping information arising from the consistent, neighbouring keypresses for the last index finger movement, compared to the first index finger movement of the next trial. A strong difference (larger neural representation distance) between these two movements is, therefore, not surprising, given the task design, and this difference is also expected to increase with learning, given the increase in tapping speed, and the consequent stronger overlap in representations for consecutive keypresses. Furthermore, initiating a new sequence involves pre-planning, while ongoing practice relies on online planning (Ariani et al., eNeuro 2021), i.e., two mental operations that are dissociable at the level of neural representation (Ariani et al., bioRxiv 2023).</p></disp-quote><p>The revised manuscript now addresses specifically the question of pre-planning:</p><p>Results (lines 310-318):</p><p>“Offline contextualization strongly correlated with cumulative micro-offline gains (r = 0.903, R<sup>2</sup> = 0.816, p &lt; 0.001; Figure 5 – figure supplement 1A, inset) across decoder window durations ranging from 50 to 250ms (Figure 5 – figure supplement 1B, C). The offline contextualization between the final sequence of each trial and the second sequence of the subsequent trial (excluding the first sequence) yielded comparable results. This indicates that pre-planning at the start of each practice trial did not directly influence the offline contextualization measure [30] (Figure 5 – figure supplement 2A, <italic>1st vs. 2nd Sequence approaches</italic>). Conversely, online contextualization (using either measurement approach) did not explain early online learning gains (i.e. – Figure 5 – figure supplement 3).”</p><p>Discussion (lines 408-416):</p><p>“Offline contextualization consistently correlated with early learning gains across a range of decoding windows (50–250ms; Figure 5 – figure supplement 1). This result remained unchanged when measuring offline contextualization between the last and second sequence of consecutive trials, inconsistent with a possible confounding effect of pre-planning [30] (Figure 5 – figure supplement 2A). On the other hand, online contextualization did not predict learning (Figure 5 – figure supplement 3). Consistent with these results the average within-subject correlation between offline contextualization and micro-offline gains was significantly stronger than within-subject correlations between online contextualization and either micro-online or micro-offline gains (Figure 5 – figure supplement 4).”</p><disp-quote content-type="editor-comment"><p>A further complication in interpreting the results stems from the visual feedback that participants received during the task. Each keypress generated an asterisk shown above the string on the screen. It is not clear why the authors introduced this complicating visual feedback in their task, besides consistency with their previous studies. The resulting systematic link between the pattern of visual stimulation (the number of asterisks on the screen) and the ordinal position of a keypress makes the interpretation of &quot;contextual information&quot; that differentiates between ordinal positions difficult. During the review process, the authors reported a confusion matrix from a classification of asterisks position based on eye tracking data recorded during the task and concluded that the classifier performed at chance level and gaze was, thus, apparently not biased by the visual stimulation. However, the confusion matrix showed a huge bias that was difficult to interpret (a very strong tendency to predict one of the five asterisk positions, despite chance-level performance). Without including additional information for this analysis (or simply the gaze position as a function of the number of astersisk on the screen) in the manuscript, this important control analysis cannot be properly assessed, and is not available to the public.</p></disp-quote><p>We now include the gaze position data requested by the Reviewer alongside the confusion matrix results in Figure 4 – figure supplement 3.</p><p>Results (lines 207-211):</p><p>“An alternate decoder trained on ICA components labeled as movement or physiological artefacts (e.g. – head movement, ECG, eye movements and blinks; Figure 3 – figure supplement 3A, D) and removed from the original input feature set during the pre-processing stage approached chance-level performance (Figure 4 – figure supplement 3), indicating that the 4-class hybrid decoder results were not driven by task-related artefacts.” Results (lines 261-268):</p><p>“As expected, the 5-class hybrid-space decoder performance approached chance levels when tested with randomly shuffled keypress labels (18.41%± SD 7.4% for Day 1 data; Figure 4 – figure supplement 3C). Task-related eye movements did not explain these results since an alternate 5-class hybrid decoder constructed from three eye movement features (gaze position at the KeyDown event, gaze position 200ms later, and peak eye movement velocity within this window; Figure 4 – figure supplement 3A) performed at chance levels (cross-validated test accuracy = 0.2181; Figure 4 – figure supplement 3B, C). “</p><p>Discussion (Lines 362-368):</p><p>“Task-related movements—which also express in lower frequency ranges—did not explain these results given the near chance-level performance of alternative decoders trained on (a) artefact-related ICA components removed during MEG preprocessing (Figure 3 – figure supplement 3A-C) and on (b) task-related eye movement features (Figure 4 – figure supplement 3B, C). This explanation is also inconsistent with the minimal average head motion of 1.159 mm (± 1.077 SD) across the MEG recording (Figure 3 – figure supplement 3D).”</p><p>The rationale for the task design including the asterisks is presented below:</p><p>Methods (Lines 500-514)</p><p>“The five-item sequence was displayed on the computer screen for the duration of each practice round and participants were directed to fix their gaze on the sequence. Small asterisks were displayed above a sequence item after each successive keypress, signaling the participants' present position within the sequence. Inclusion of this feedback minimizes working memory loads during task performance [73]. Following the completion of a full sequence iteration, the asterisk returned to the first sequence item. The asterisk did not provide error feedback as it appeared for both correct and incorrect keypresses. At the end of each practice round, the displayed number sequence was replaced by a string of five &quot;X&quot; symbols displayed on the computer screen, which remained for the duration of the rest break. Participants were instructed to focus their gaze on the screen during this time. The behavior in this explicit, motor learning task consists of generative action sequences rather than sequences of stimulus-induced responses as in the serial reaction time task (SRTT). A similar real-world example would be manually inputting a long password into a secure online application in which one intrinsically generates the sequence from memory and receives similar feedback about the password sequence position (also provided as asterisks), which is typically ignored by the user.”</p><disp-quote content-type="editor-comment"><p>The authors report a significant correlation between &quot;offline differentiation&quot; and cumulative micro-offline gains. However, this does not address the question whether there is a trial-by-trial relation between the degree of &quot;contextualization&quot; and the amount of micro-offline gains - i.e., the question whether performance changes (micro-offline gains) are less pronounced across rest periods for which the change in &quot;contextualization&quot; is relatively low. The single-subject correlation between contextualization changes &quot;during&quot; rest and micro-offline gains (Figure 5 - figure supplement 4) addresses this question, however, the critical statistical test (are correlation coefficients significantly different from zero) is not included. Given the displayed distribution, it seems unlikely that correlation coefficients are significantly above zero.</p></disp-quote><p>As recommend by the Reviewer, we now include one-way right-tailed t-test results which provide further support to the previously reported finding. The mean of within-subject correlations between offline contextualization and cumulative micro-offline gains was significantly greater than zero (t = 3.87, p = 0.00035, df = 25, Cohen's d = 0.76; see Figure 5 – figure supplement 4, left), while correlations for online contextualization versus cumulative micro-online (t = -1.14, p = 0.8669, df = 25, Cohen's d = -0.22) or micro-offline gains t = -0.097, p = 0.5384, df = 25, Cohen's d = -0.019 were not. We have incorporated the significant one-way t-test for offline contextualization and cumulative micro-offline gains in the Results section of the revised manuscript (lines 313-318) and the Figure 5 – figure supplement 4 legend.</p><disp-quote content-type="editor-comment"><p>The authors follow the assumption that micro-offline gains reflect offline learning.</p><p>However, there is no compelling evidence in the literature, and no evidence in the present manuscript, that micro-offline gains (during any training phase) reflect offline learning. Instead, emerging evidence in the literature indicates that they do not (Das et al., bioRxiv 2024), and instead reflect transient performance benefits when participants train with breaks, compared to participants who train without breaks, however, these benefits vanish within seconds after training if both groups of participants perform under comparable conditions (Das et al., bioRxiv 2024). During the review process, the authors argued that differences in the design between Das et al. (2024) on the one hand (Experiments 1 and 2), and the study by Bönstrup et al. (2019) on the other hand, may have prevented Das et al. (2024) from finding the assumed (lasting) learning benefit by micro-offline consolidation. However, the Supplementary Material of Das et al. (2024) includes an experiment (Experiment S1) whose design closely follows the early learning phase of Bönstrup et al. (2019), and which, nevertheless, demonstrates that there is no lasting benefit of taking breaks for the acquired skill level, despite the presence of micro-offline gains.</p></disp-quote><p>We thank the Reviewer for alerting us to this new data added to the revised supplementary materials of Das et al. (2024) posted to bioRxiv. However, despite the Reviewer’s claim to the contrary, a careful comparison between the Das et al and Bönstrup et al studies reveal more substantive differences than similarities and does not “closely follows a large proportion of the early learning phase of Bönstrup et al. (2019)” as stated.</p><p>In the Das et al. Experiment S1, sixty-two participants were randomly assigned to “with breaks” or “no breaks” skill training groups. The “with breaks” group alternated 10 seconds of skill sequence practice with 10 seconds of rest over seven trials (2 min and 2 sec total training duration). This amounts to 66.7% of the early learning period defined by Bönstrup et al. (2019) (i.e. - eleven 10-second-long practice periods interleaved with ten 10-second-long rest breaks; 3 min 30 sec total training duration).</p><p>Also, please note that while no performance feedback nor reward was given in the Bönstrup et al. (2019) study, participants in the Das et al. study received explicit performance-based monetary rewards, a potentially crucial driver of differentiated behavior between the two studies:</p><p>“Participants were incentivized with bonus money based on the total number of correct sequences completed throughout the experiment.”</p><p>The “no breaks” group in the Das et al. study practiced the skill sequence for 70 continuous seconds. Both groups (despite one being labeled “no breaks”) follow training with a long 3-minute break (also note that since the “with breaks” group ends with 10 seconds of rest their break is actually longer), before finishing with a skill “<italic>test</italic>” over a continuous 50-second-long block. During the 70 seconds of training, the “with breaks” group shows more learning than the “no breaks” group. Interestingly, following the long 3minute break the “with breaks” group display a performance drop (relative to their performance at the end of training) that is stable over the full 50-second test, while the “no breaks” group shows an immediate performance improvement following the long break that continues to increase over the 50-second test.</p><p>Separately, there are important issues regarding the Das et al. study that should be considered through the lens of recent findings not referred to in the preprint. A major element of their experimental design is that both groups—“with breaks” and “no breaks”— actually receive quite a long 3-minute break just before the skill test. This long break is more than 2.5x the cumulative interleaved rest experienced by the “with breaks” group. Thus, although the design is intended to contrast the presence or absence of rest “breaks”, that difference between groups is no longer maintained at the point of the skill test.</p><p>The Das et al. results are most consistent with an alternative interpretation of the data— that the “no breaks” group experiences offline learning during their long 3-minute break. This is supported by the recent work of Griffin et al. (2025) where micro-array recordings from primary and premotor cortex were obtained from macaque monkeys while they performed blocks of ten continuous reaching sequences up to 81.4 seconds in duration (see source data for Extended Data Figure 1h) with 90 seconds of interleaved rest. Griffin et al. observed offline improvement in skill immediately following the rest break that was causally related to neural reactivations (i.e. – neural replay) that occurred <italic>during</italic> the rest break. Importantly, the highest density of reactivations was present in the very first 90second break between Blocks 1 and 2 (see Fig. 2f in Griffin et al., 2025). This supports the interpretation that both the “with breaks” and “no breaks” group express offline learning gains, with these gains being delayed in the “no breaks” group due to the practice schedule.</p><p>On the other hand, if offline learning can occur during this longer break, then why would the “with breaks” group show no benefit? Again, it could be that most of the offline gains for this group were front-loaded during the seven shorter 10-second rest breaks. Another possible, though not mutually exclusive, explanation is that the observed drop in performance in the “with breaks” group is driven by contextual interference. Specifically, similar to Experiments 1 and 2 in Das et al. (2024), the skill test is conducted under very different conditions than those which the “with breaks” group practiced the skill under (short bursts of practiced alternating with equally short breaks). On the other hand, the “no breaks” group is tested (50 seconds of continuous practice) under quite similar conditions to their training schedule (70 seconds of continuous practice). Thus, it is possible that this dissimilarity between training and test could lead to reduced performance in the “with breaks” group.</p><p>We made the following manuscript revisions related to these important issues:</p><p>Introduction (Lines 26-56)</p><p>“Practicing a new motor skill elicits rapid performance improvements (early learning) [1] that precede skill performance plateaus [5]. Skill gains during early learning accumulate over rest periods (micro-offline) interspersed with practice [1, 6-10], and are up to four times larger than offline performance improvements reported following overnight sleep [1]. During this initial interval of prominent learning, retroactive interference immediately following each practice interval reduces learning rates relative to interference after passage of time, consistent with stabilization of the motor memory [11]. Micro-offline gains observed during early learning are reproducible [7, 10-13] and are similar in magnitude even when practice periods are reduced by half to 5 seconds in length, thereby confirming that they are not merely a result of recovery from performance fatigue [11]. Additionally, they are unaffected by the random termination of practice periods, which eliminates the possibility of predictive motor slowing as a contributing factor [11]. Collectively, these behavioral findings point towards the interpretation that micro offline gains during early learning represent a form of memory consolidation [1].</p><p>This interpretation has been further supported by brain imaging and electrophysiological studies linking known memory-related networks and consolidation mechanisms to rapid offline performance improvements. In humans, the rate of hippocampo-neocortical neural replay predicts micro-offline gains [6]. Consistent with these findings, Chen et al. [12] and Sjøgård et al. [13] furnished direct evidence from intracranial human EEG studies, demonstrating a connection between the density of hippocampal sharp-wave ripples (80-120 Hz)—recognized markers of neural replay—and micro-offline gains during early learning. Further, Griffin et al. reported that neural replay of task-related ensembles in the motor cortex of macaques during brief rest periods— akin to those observed in humans [1, 6-8, 14]—are not merely correlated with, but are causal drivers of micro-offline learning [15]. Specifically, the same reach directions that were replayed the most during rest breaks showed the greatest reduction in path length (i.e. – more efficient movement path between two locations in the reach sequence) during subsequent trials, while stimulation applied during rest intervals preceding performance plateau reduced reactivation rates and virtually abolished micro-offline gains [15]. Thus, converging evidence in humans and non-human primates across indirect non-invasive and direct invasive recording techniques link hippocampal activity, neural replay dynamics and offline skill gains in early motor learning that precede performance plateau.”</p><p>Next, in the Methods, we articulate important constrains formulated by Pan and Rickard and Bonstrup et al for meaningful measurements:</p><p>Methods (Lines 493-499)</p><p>“The study design followed specific recommendations by Pan and Rickard (2015): (1) utilizing 10-second practice trials and (2) constraining analysis of micro-offline gains to early learning trials (where performance monotonically increases and 95% of overall performance gains occur) that precede the emergence of “scalloped” performance dynamics strongly linked to reactive inhibition effects ([29, 72]). This is precisely the portion of the learning curve Pan and Rickard referred to when they stated “…rapid learning during that period masks any reactive inhibition effect” [29].”</p><p>We finally discuss the implications of neglecting some or all of these recommendations:</p><p>Discussion (Lines 444-452):</p><p>“Finally, caution should be exercised when extrapolating findings during early skill learning, a period of steep performance improvements, to findings reported after insufficient practice [67], post-plateau performance periods [68], or non-learning situations (e.g. performance of non-repeating keypress sequences in [67]) when reactive inhibition or contextual interference effects are prominent. Ultimately, it will be important to develop new paradigms allowing one to independently estimate the different coincident or antagonistic features (e.g. - memory consolidation, planning, working memory and reactive inhibition) contributing to micro-online and micro-offline gains during and after early skill learning within a unifying framework.”</p><disp-quote content-type="editor-comment"><p>Along these lines, the authors' claim, based on Bönstrup et al. 2020, that &quot;retroactive interference immediately following practice periods reduces micro-offline learning&quot;, is not supported by that very reference. Citing Bönstrup et al. (2020), &quot;Regarding early learning dynamics (trials 1-5), we found no differences in microscale learning parameters (micro online/offline) or total early learning between both interference groups.&quot; That is, contrary to Dash et al.'s current claim, Bönstrup et al. (2020) did not find any retroactive interference effect on the specific behavioral readout (micro-offline gains) that the authors assume to reflect consolidation.</p></disp-quote><p>Please, note that the Bönstrup et al. 2020 paper abstract states:</p><p>“Third, retroactive interference immediately after each practice period reduced the learning rate relative to interference after passage of time (N = 373), indicating stabilization of the motor memory at a microscale of several seconds.”</p><p>which is further supported by this statement in the Results:</p><p>“The model comprised three parameters representing the initial performance, maximum performance and learning rate (see Eq. 1, “Methods”, “Data Analysis” section). We then statistically compared the model parameters between the interference groups (Fig. 2d). The late interference group showed a higher learning rate compared with the early interference group (late: 0.26 ± 0.23, early: 2.15 ± 0.20, P=0.04). The effect size of the group difference was small to medium (Cohen’s d 0.15)[29]. Similar differences with a stronger rise in the learning curve of a late interference groups vs. an early interference group were found in a smaller sample collected in the lab environment (Supplementary Fig. 3).”</p><p>We have modified the statement in the revised manuscript to specify that the difference observed was between learning rates: Introduction (Lines 30-32)</p><p>“During this initial interval of prominent learning, retroactive interference immediately following each practice interval reduces learning rates relative to interference after passage of time, consistent with stabilization of the motor memory [11].”</p><disp-quote content-type="editor-comment"><p>The authors conclude that performance improves, and representation manifolds differentiate, &quot;during&quot; rest periods (see, e.g., abstract). However, micro-offline gains (as well as offline contextualization) are computed from data obtained during practice, not rest, and may, thus, just as well reflect a change that occurs &quot;online&quot;, e.g., at the very onset of practice (like pre-planning) or throughout practice (like fatigue, or reactive inhibition).</p></disp-quote><p>The Reviewer raises again the issue of a potential confound of “pre-planning” on our contextualization measures as in the comment above:</p><p>“Furthermore, initiating a new sequence involves pre-planning, while ongoing practice relies on online planning (Ariani et al., eNeuro 2021), i.e., two mental operations that are dissociable at the level of neural representation (Ariani et al., bioRxiv 2023).”</p><p>The cited studies by Ariani et al. indicate that effects of pre-planning are likely to impact the first 3 keypresses of the initial sequence iteration in each trial. As stated in the response to this comment above, we conducted a control analysis of contextualization that ignores the first sequence iteration in each trial to partial out any potential preplanning effect. This control analyses yielded comparable results, indicating that preplanning is not a major driver of our reported contextualization effects. We now report this in the revised manuscript:</p><p>We also state in the Figure 1 legend (Lines 99-103) in the revised manuscript that preplanning has no effect on the behavioral measures of micro-offline and micro-online gains in our dataset:</p><p>The Reviewer also raises the issue of possible effects stemming from “fatigue” and “reactive inhibition” which inhibit performance and are indeed relevant to skill learning studies. We designed our task to specifically mitigate these effects. We now more clearly articulate this rationale in the description of the task design as well as the measurement constraints essential for minimizing their impact.</p><p>We also discuss the implications of fatigue and reactive inhibition effects in experimental designs that neglect to follow these recommendations formulated by Pan and Rickard in the Discussion section and propose how this issue can be better addressed in future investigations.</p><p>To summarize, the results of our study indicate that: (a) offline contextualization effects are not explained by pre-planning of the first action sequence iteration in each practice trial; and (b) the task design implemented in this study purposefully minimize any possible effects of reactive inhibition or fatigue. Circling back to the Reviewer’s proposal that “contextualization…may just as well reflect a change that occurs &quot;online&quot;”, we show in this paper direct empirical evidence that contextualization develops to a greater extent across rest periods rather than across practice trials, contrary to the Reviewer’s proposal.</p><disp-quote content-type="editor-comment"><p>That is, the definition of micro-offline gains (as well as offline contextualization) conflates online and &quot;offline&quot; processes. This becomes strikingly clear in the recent Nature paper by Griffin et al. (2025), who computed micro-offline gains as the difference in average performance across the first five sequences in a practice period (a block, in their terminology) and the last five sequences in the previous practice period. Averaging across sequences in this way minimises the chance to detect online performance changes and inflates changes in performance &quot;offline&quot;. The problem that &quot;online&quot; gains (or contextualization) is actually computed from data entirely generated online, and therefore subject to processes that occur online, is inherent in the very definition of micro-online gains, whether, or not, they computed from averaged performance.</p></disp-quote><p>We would like to make it clear that the issue raised by the Reviewer with respect to averaging across sequences done in the Griffin et al. (2025) study does not impact our study in any way. The primary skill measure used in all analyses reported in our paper is not temporally averaged. We estimated instantaneous correct sequence speed over the entire trial. Once the first sequence iteration within a trial is completed, the speed estimate is then updated at the resolution of individual keypresses. All micro-online and -offline behavioral changes are measured as the difference in instantaneous speed at the beginning and end of individual practice trials.</p><p>Methods (lines 528-530):</p><p>“The instantaneous correct sequence speed was calculated as the inverse of the average KTT across a single correct sequence iteration and was updated for each correct keypress.”</p><p>The instantaneous speed measure used in our analyses, in fact, maximizes the likelihood of detecting changes in online performance, as the Reviewer indicates. Despite this optimally sensitive measurement of online changes, our findings remained robust, consistently converging on the same outcome across our original analyses and the multiple controls recommended by the reviewers. Notably, online contextualization changes are significantly weaker than offline contextualization in all comparisons with different measurement approaches.</p><p>Results (lines 302-309)</p><p>“The Euclidian distance between neural representations of Index<sub>OP1</sub> (i.e. - index finger keypress at ordinal position 1 of the sequence) and Index<sub>OP5</sub> (i.e. - index finger keypress at ordinal position 5 of the sequence) increased progressively during early learning (Figure 5A)—predominantly during rest intervals (offline contextualization) rather than during practice (online) (t = 4.84, p &lt; 0.001, df = 25, Cohen's d = 1.2; Figure 5B; Figure 5 – figure supplement 1A). An alternative online contextualization determination equalling the time interval between online and offline comparisons (<italic>Trial-based;</italic> 10 seconds between Index<sub>OP1</sub> and Index<sub>OP5</sub> observations in both cases) rendered a similar result (Figure 5 – figure supplement 2B).</p><p>Results (lines 316-318)</p><p>“Conversely, online contextualization (using either measurement approach) did not explain early online learning gains (i.e. – Figure 5 – figure supplement 3).”</p><p>Results (lines 318-328)</p><p>“Within-subject correlations were consistent with these group-level findings. The average correlation between offline contextualization and micro-offline gains within individuals was significantly greater than zero (Figure 5 – figure supplement 4, left; t = 3.87, p = 0.00035, df = 25, Cohen's d = 0.76) and stronger than correlations between online contextualization and either micro-online (Figure 5 – figure supplement 4, middle; t = 3.28, p = 0.0015, df = 25, Cohen's d = 1.2) or microoffline gains (Figure 5 – figure supplement 4, right; t = 3.7021, p = 5.3013e-04, df = 25, Cohen's d = 0.69). These findings were not explained by behavioral changes of typing rhythm (t = -0.03, <italic>p</italic> = 0.976; Figure 5 – figure supplement 5), adjacent keypress transition times (R<sup>2</sup> = 0.00507, F[1,3202] = 16.3; Figure 5 – figure supplement 6), or overall typing speed (between-subject; R<sup>2</sup> = 0.028, <italic>p</italic> = 0.41; Figure 5 – figure supplement 7).”</p><p>We disagree with the Reviewer’s statement that “the definition of micro-offline gains (as well as offline contextualization) conflates online and &quot;offline&quot; processes”. From a strictly behavioral point of view, it is obviously true that one can only measure skill (rather than the absence of it during rest) to determine how it changes over time. While skill changes surrounding rest are used to infer offline learning processes, recovery of skill decay following intense practice is used to infer “unmeasurable” recovery from fatigue or reactive inhibition. In other words, the alternative processes proposed by the Reviewer also rely on the same inferential reasoning.</p><p>Importantly, inferences can be validated through the identification of mechanisms. Our experiment constrained the study to evaluation of changes in neural representations of the same action in different contexts, while minimized the impact of mechanisms related to fatigue/reactive inhibition [13, 14]. In this way, we observed that behavioral gains and neural contextualization occurs to a greater extent over rest breaks rather than during practice trials and that offline contextualization changes strongly correlate with the offline behavioral gains, while online contextualization does not. This result was supported by the results of all control analyses recommended by the Reviewers. Specifically:</p><p>Methods (Lines 493-499)</p><p>“The study design followed specific recommendations by Pan and Rickard (2015): (1) utilizing 10-second practice trials and (2) constraining analysis of micro-offline gains to early learning trials (where performance monotonically increases and 95% of overall performance gains occur) that precede the emergence of “scalloped” performance dynamics strongly linked to reactive inhibition effects ([29, 72]). This is precisely the portion of the learning curve Pan and Rickard referred to when they stated “…rapid learning during that period masks any reactive inhibition effect” [29]<italic>.”</italic></p><p>And Discussion (Lines 444-448):</p><p>“Finally, caution should be exercised when extrapolating findings during early skill learning, a period of steep performance improvements, to findings reported after insufficient practice [67], post-plateau performance periods [68], or non-learning situations (e.g. performance of non-repeating keypress sequences in [67]) when reactive inhibition or contextual interference effects are prominent.”</p><p>Next, we show that offline contextualization is greater than online contextualization and predicts offline behavioral gains across all measurement approaches, including all controls suggested by the Reviewer’s comments and recommendations.</p><p>Results (lines 302-318):</p><p>“The Euclidian distance between neural representations of Index<sub>OP1</sub> (i.e. - index finger keypress at ordinal position 1 of the sequence) and Index<sub>OP5</sub> (i.e. - index finger keypress at ordinal position 5 of the sequence) increased progressively during early learning (Figure 5A)—predominantly during rest intervals (<italic>offline contextualization</italic>) rather than during practice (<italic>online</italic>) (t = 4.84, p &lt; 0.001, df = 25, Cohen's d = 1.2; Figure 5B; Figure 5 – figure supplement 1A). An alternative online contextualization determination equalling the time interval between online and offline comparisons (<italic>Trial-based;</italic> 10 seconds between Index<sub>OP1</sub> and Index<sub>OP5</sub> observations in both cases) rendered a similar result (Figure 5 – figure supplement 2B).</p><p>Offline contextualization strongly correlated with cumulative micro-offline gains (r = 0.903, R<sup>2</sup> = 0.816, p &lt; 0.001; Figure 5 – figure supplement 1A, inset) across decoder window durations ranging from 50 to 250ms (Figure 5 – figure supplement 1B, C). The offline contextualization between the final sequence of each trial and the second sequence of the subsequent trial (excluding the first sequence) yielded comparable results. This indicates that pre-planning at the start of each practice trial did not directly influence the offline contextualization measure [30] (Figure 5 – figure supplement 2A, <italic>1st vs. 2nd Sequence approaches</italic>). Conversely, online contextualization (using either measurement approach) did not explain early online learning gains (i.e. – Figure 5 – figure supplement 3).”</p><p>Results (lines 318-324)</p><p>“Within-subject correlations were consistent with these group-level findings. The average correlation between offline contextualization and micro-offline gains within individuals was significantly greater than zero (Figure 5 – figure supplement 4, left; t = 3.87, p = 0.00035, df = 25, Cohen's d = 0.76) and stronger than correlations between online contextualization and either micro-online (Figure 5 – figure supplement 4, middle; t = 3.28, p = 0.0015, df = 25, Cohen's d = 1.2) or microoffline gains (Figure 5 – figure supplement 4, right; t = 3.7021, p = 5.3013e-04, df = 25, Cohen's d = 0.69).”</p><p>Discussion (lines 408-416):</p><p>“Offline contextualization consistently correlated with early learning gains across a range of decoding windows (50–250ms; Figure 5 – figure supplement 1). This result remained unchanged when measuring offline contextualization between the last and second sequence of consecutive trials, inconsistent with a possible confounding effect of pre-planning [30] (Figure 5 – figure supplement 2A). On the other hand, online contextualization did not predict learning (Figure 5 – figure supplement 3). Consistent with these results the average within-subject correlation between offline contextualization and micro-offline gains was significantly stronger than within subject correlations between online contextualization and either micro-online or micro-offline gains (Figure 5 – figure supplement 4).”</p><p>We then show that offline contextualization is not explained by pre-planning of the first action sequence:</p><p>Results (lines 310-316):</p><p>“Offline contextualization strongly correlated with cumulative micro-offline gains (r = 0.903, R<sup>2</sup> = 0.816, p &lt; 0.001; Figure 5 – figure supplement 1A, inset) across decoder window durations ranging from 50 to 250ms (Figure 5 – figure supplement 1B, C). The offline contextualization between the final sequence of each trial and the second sequence of the subsequent trial (excluding the first sequence) yielded comparable results. This indicates that pre-planning at the start of each practice trial did not directly influence the offline contextualization measure [30] (Figure 5 – figure supplement 2A, 1st vs. 2nd Sequence approaches).”</p><p>Discussion (lines 409-412):</p><p>“This result remained unchanged when measuring offline contextualization between the last and second sequence of consecutive trials, inconsistent with a possible confounding effect of pre-planning [30] (Figure 5 – figure supplement 2A).”</p><p>In summary, none of the presented evidence in this paper—including results of the multiple control analyses carried out in response to the Reviewers’ recommendations— supports the Reviewer’s position.</p><p>Please note that the micro-offline learning &quot;inference&quot; has extensive mechanistic support across species and neural recording techniques (see Introduction, lines 26-56). In contrast, the reactive inhibition &quot;inference,&quot; which is the Reviewer's alternative interpretation, has no such support yet [15].</p><p>Introduction (Lines 26-56)</p><p>“Practicing a new motor skill elicits rapid performance improvements (early learning) [1] that precede skill performance plateaus [5]. Skill gains during early learning accumulate over rest periods (micro-offline) interspersed with practice [1, 6-10], and are up to four times larger than offline performance improvements reported following overnight sleep [1]. During this initial interval of prominent learning, retroactive interference immediately following each practice interval reduces learning rates relative to interference after passage of time, consistent with stabilization of the motor memory [11]. Micro-offline gains observed during early learning are reproducible [7, 10-13] and are similar in magnitude even when practice periods are reduced by half to 5 seconds in length, thereby confirming that they are not merely a result of recovery from performance fatigue [11]. Additionally, they are unaffected by the random termination of practice periods, which eliminates the possibility of predictive motor slowing as a contributing factor [11]. Collectively, these behavioral findings point towards the interpretation that microoffline gains during early learning represent a form of memory consolidation [1].</p><p>This interpretation has been further supported by brain imaging and electrophysiological studies linking known memory-related networks and consolidation mechanisms to rapid offline performance improvements. In humans, the rate of hippocampo-neocortical neural replay predicts micro-offline gains [6].</p><p>Consistent with these findings, Chen et al. [12] and Sjøgård et al. [13] furnished direct evidence from intracranial human EEG studies, demonstrating a connection between the density of hippocampal sharp-wave ripples (80-120 Hz)—recognized markers of neural replay—and micro-offline gains during early learning. Further, Griffin et al. reported that neural replay of task-related ensembles in the motor cortex of macaques during brief rest periods— akin to those observed in humans [1, 6-8, 14]—are not merely correlated with, but are causal drivers of micro-offline learning [15]. Specifically, the same reach directions that were replayed the most during rest breaks showed the greatest reduction in path length (i.e. – more efficient movement path between two locations in the reach sequence) during subsequent trials, while stimulation applied during rest intervals preceding performance plateau reduced reactivation rates and virtually abolished micro-offline gains [15]. Thus, converging evidence in humans and non-human primates across indirect non-invasive and direct invasive recording techniques link hippocampal activity, neural replay dynamics and offline skill gains in early motor learning that precede performance plateau.”</p><p>That said, absence of evidence, is not evidence of absence and for that reason we also state in the Discussion (lines 448-452):</p><disp-quote content-type="editor-comment"><p>A simple control analysis based on shuffled class labels could lend further support to the authors' complex decoding approach. As a control analysis that completely rules out any source of overfitting, the authors could test the decoder after shuffling class labels. Following such shuffling, decoding accuracies should drop to chance-level for all decoding approaches, including the optimized decoder. This would also provide an estimate of actual chance-level performance (which is informative over and beyond the theoretical chance level). During the review process, the authors reported this analysis to the reviewers. Given that readers may consider following the presented decoding approach in their own work, it would have been important to include that control analysis in the manuscript to convince readers of its validity.</p></disp-quote><p>As requested, the label-shuffling analysis was carried out for both 4- and 5-class decoders and is now reported in the revised manuscript.</p><p>Results (lines 204-207):</p><p>“Testing the keypress state (4-class) hybrid decoder performance on Day 1 after randomly shuffling keypress labels for held-out test data resulted in a performance drop approaching expected chance levels (22.12%± SD 9.1%; Figure 3 – figure supplement 3C).”</p><p>Results (lines 261-264):</p><p>“As expected, the 5-class hybrid-space decoder performance approached chance levels when tested with randomly shuffled keypress labels (18.41%± SD 7.4% for Day 1 data; Figure 4 – figure supplement 3C).”</p><p>Furthermore, the authors' approach to cortical parcellation raises questions regarding the information carried by varying dipole orientations within a parcel (which currently seems to be ignored?) and the implementation of the mean-flipping method (given that there are two dimensions - space and time - it is unclear what the authors refer to when they talk about the sign of the &quot;average source&quot;, line 477).</p><p>The revised manuscript now provides a more detailed explanation of the parcellation, and sign-flipping procedures implemented:</p><p>Methods (lines 604-611):</p><p>“Source-space parcellation was carried out by averaging all voxel time-series located within distinct anatomical regions defined in the Desikan-Killiany Atlas [31]. Since source time-series estimated with beamforming approaches are inherently sign-ambiguous, a custom Matlab-based implementation of the <italic>mne.extract_label_time_course</italic> with “<italic>mean_flip”</italic> sign-flipping procedure in MNEPython [78] was applied prior to averaging to prevent within-parcel signal cancellation. All voxel time-series within each parcel were extracted and the timeseries sign was flipped at locations where the orientation difference was greater than 90° from the parcel mode. A mean time-series was then computed across all voxels within the parcel after sign-flipping.”</p><disp-quote content-type="editor-comment"><p><bold>Recommendations for the authors:</bold></p><p><bold>Reviewer #1 (Recommendations for the authors):</bold></p><p>Comments on the revision:</p><p>The authors have made large efforts to address all concerns raised. A couple of suggestions remain:</p><p>- formally show if and how movement artefacts may contribute to the signal and analysis; it seems that the authors have data to allow for such an analysis</p></disp-quote><p>We have implemented the requested control analyses addressing this issue. They are reported in: Results (lines 207-211 and 261-268), Discussion (Lines 362-368):</p><disp-quote content-type="editor-comment"><p>- formally show that the signals from the intra- and inter parcel spaces are orthogonal.</p></disp-quote><p>Please note that, despite the Reviewer’s statement above, we never claim in the manuscript that the parcel-space and regional voxel-space features show “complete independence”.</p><p>Furthermore, the machine learning-based decoding methods used in the present study do not require input feature orthogonality, but instead non-redundancy [7], which is a requirement satisfied by our data (see below and the new Figure 2 – figure supplement 2 in the revised manuscript). Finally, our results already show that the hybrid space decoder outperformed all other methods even after input features were fully orthogonalized with LDA or PCA dimensionality reduction procedures prior to the classification step (Figure 3 – figure supplement 2).</p><p>We also highlight several additional results that are informative regarding this issue. For example, if spatially overlapping parcel- and voxel-space time-series only provided redundant information, inclusion of both as input features should increase model overfitting to the training dataset and decrease overall cross-validated test accuracy [8]. In the present study however, we see the opposite effect on decoder performance. First, Figure 3 – figure supplements 1 &amp; 2 clearly show that decoders constructed from hybrid-space features outperform the other input feature (sensor-, whole-brain parcel- and whole-brain voxel-) spaces in every case (e.g. – wideband, all narrowband frequency ranges, and even after the input space is fully orthogonalized through dimensionality reduction procedures prior to the decoding step). Furthermore, Figure 3 – figure supplement 6 shows that hybridspace decoder performance supers when parcel-time series that spatially overlap with the included regional voxel-spaces are removed from the input feature set. We state in the Discussion (lines 353-356)</p><p>“The observation of increased cross-validated test accuracy (as shown in Figure 3 – Figure Supplement 6) indicates that the spatially overlapping information in parcel- and voxel-space time-series in the hybrid decoder was complementary, rather than redundant [41].”</p><p>To gain insight into the complimentary information contributed by the two spatial scales to the hybrid-space decoder, we first independently computed the matrix rank for whole-brain parcel- and voxel-space input features for each participant (shown in Author response image 1). The results indicate that whole-brain parcel-space input features are full rank (rank = 148) for all participants (i.e. - MEG activity is orthogonal between all parcels). The matrix rank of voxelspace input features (rank = 267± 17 SD), exceeded the parcel-space rank for all participants and approached the number of useable MEG sensor channels (n = 272). Thus, voxel-space features provide both additional and complimentary information to representations at the parcel-space scale.</p><p>Figure 2—figure Supplement 2 in the revised manuscript now shows that the degree of dependence between the two spatial scales varies over the regional voxel-space. That is, some voxels within a given parcel correlate strongly with the time-series of the parcel they belong to, while others do not. This finding is consistent with a documented increase in correlational structure of neural activity across spatial scales that does not reflect perfect dependency or orthogonality [9]. Notably, the regional voxel-spaces included in the hybridspace decoder are significantly less correlated with the averaged parcel-space time-series than excluded voxels. We now point readers to this new figure in the results.</p><p>Taken together, these results indicate that the multi-scale information in the hybrid feature set is complimentary rather than orthogonal. This is consistent with the idea that hybridspace features better represent multi-scale temporospatial dynamics reported to be a fundamental characteristic of how the brain stores and adapts memories, and generates behavior across species [9].</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations for the authors):</bold></p><p>I appreciate the authors' efforts in addressing the concerns I raised. The responses generally made sense to me. However, I had some trouble finding several corrections/additions that the authors claim they made in the revised manuscript:</p><p>&quot;We addressed this question by conducting a new multivariate regression analysis to directly assess whether the neural representation distance score could be predicted by the 4-1, 2-4, and 4-4 keypress transition times observed for each complete correct sequence (both predictor and response variables were z-score normalized within-subject). The results of this analysis also affirmed that the possible alternative explanation that contextualization effects are simple reflections of increased mixing is not supported by the data (Adjusted R<sup>2</sup> = 0.00431; F = 5.62). We now include this new negative control analysis in the revised manuscript.&quot;</p></disp-quote><p>This approach is now reported in the manuscript in the Results (Lines 324-328 and Figure 5-Figure Supplement 6 legend).</p><p>&quot;We strongly agree with the Reviewer that the issue of generalizability is extremely important and have added a new paragraph to the Discussion in the revised manuscript highlighting the strengths and weaknesses of our study with respect to this issue.&quot;</p><p>Discussion (Lines 436-441)</p><p>“One limitation of this study is that contextualization was investigated for only one finger movement (index finger or digit 4) embedded within a relatively short 5-item skill sequence. Determining if representational contextualization is exhibited across multiple finger movements embedded within for example longer sequences (e.g. – two index finger and two little finger keypresses performed within a short piece of piano music) will be an important extension to the present results.”</p><p>&quot;We strongly agree with the Reviewer that any intended clinical application must carefully consider the specific input feature constraints dictated by the clinical cohort, and in turn impose appropriate and complimentary constraints on classifier parameters that may differ from the ones used in the present study. We now highlight this issue in the Discussion of the revised manuscript and relate our present findings to published clinical BCI work within this context.&quot;</p><p>Discussion (Lines 441-444)</p><p>“While a supervised manifold learning approach (LDA) was used here because it optimized hybrid-space decoder performance, unsupervised strategies (e.g. - PCA and MDS, which also substantially improved decoding accuracy in the present study; Figure 3 – figure supplement 2) are likely more suitable for real-time BCI applications.”</p><disp-quote content-type="editor-comment"><p>and</p><p>&quot;The Reviewer makes a good point. We have now implemented the suggested normalization procedure in the analysis provided in the revised manuscript.&quot;</p></disp-quote><p>Results (lines 275-282)</p><p>“We used a Euclidian distance measure to evaluate the differentiation of the neural representation manifold of the same action (i.e. - an index-finger keypress) executed within different local sequence contexts (i.e. - ordinal position 1 vs. ordinal position 5; Figure 5). To make these distance measures comparable across participants, a new set of classifiers was then trained with group-optimal parameters (i.e. – broadband hybrid-space MEG data with subsequent manifold extraction Figure 3 – figure supplements 2) and LDA classifiers (Figure 3 – figure supplements 7) trained on 200ms duration windows aligned to the KeyDown event (see Methods, Figure 3 – figure supplements 5). “</p><disp-quote content-type="editor-comment"><p>Where are they in the manuscript? Did I read the wrong version? It would be more helpful to specify with page/line numbers. Please also add the detailed procedure of the control/additional analyses in the Method.</p></disp-quote><p>As requested, we now refer to all manuscript revisions with specific line numbers. We have also included all detailed procedures related to any additional analyses requested by reviewers.</p><disp-quote content-type="editor-comment"><p>I also have a few other comments back to the authors' following responses:</p><p>&quot;Thus, increased overlap between the &quot;4&quot; and &quot;1&quot; keypresses (at the start of the sequence) and &quot;2&quot; and &quot;4&quot; keypresses (at the end of the sequence) could artefactually increase contextualization distances even if the underlying neural representations for the individual keypresses remain unchanged. One must also keep in mind that since participants repeat the sequence multiple times within the same trial, a majority of the index finger keypresses are performed adjacent to one another (i.e. - the &quot;4-4&quot; transition marking the end of one sequence and the beginning of the next). Thus, increased overlap between consecutive index finger keypresses as typing speed increased should increase their similarity and mask contextualization- related changes to the underlying neural representations.&quot; &quot;We also re-examined our previously reported classification results with respect to this issue.</p><p>We reasoned that if mixing effects reflecting the ordinal sequence structure is an important driver of the contextualization finding, these effects should be observable in the distribution of decoder misclassifications. For example, &quot;4&quot; keypresses would be more likely to be misclassified as &quot;1&quot; or &quot;2&quot; keypresses (or vice versa) than as &quot;3&quot; keypresses. The confusion matrices presented in Figures 3C and 4B and Figure 3-figure supplement 3A display a distribution of misclassifications that is inconsistent with an alternative mixing effect explanation of contextualization.&quot;</p><p>&quot;Based upon the increased overlap between adjacent index finger keypresses (i.e. - &quot;4-4&quot; transition), we also reasoned that the decoder tasked with separating individual index finger keypresses into two distinct classes based upon sequence position, should show decreased performance as typing speed increases. However, Figure 4C in our manuscript shows that this is not the case. The 2-class hybrid classifier actually displays improved classification performance over early practice trials despite greater temporal overlap. Again, this is inconsistent with the idea that the contextualization effect simply reflects increased mixing of individual keypress features.&quot;</p><p>As the time window for MEG feature is defined after the onset of each press, it is more likely that the feature overlap is the current and the future presses, rather than the current and the past presses (of course the three will overlap at very fast typing speed). Therefore, for sequence 41324, if we note the planning-related processes by a Roman numeral, the overlapping features would be '4i', '1iii', '3ii', '2iv', and '4iv'. Assuming execution-related process (e.g., 1) and planning-related process (e.g., i) are not necessarily similar, especially in finer temporal resolution, the patterns for '4i' and '4iv' are well separated in terms of process 'i' and 'iv,' and this advantage will be larger in faster typing speed. This also applies to the other presses. Thus, the author's arguments about the masking of contextualization and misclassification due to pattern overlap seem odd. The most direct and probably easiest way to resolve this would be to use a shorter time window for the MEG feature. Some decrease in decoding accuracy in this case is totally acceptable for the science purpose.</p></disp-quote><p>The revised manuscript now includes analyses carried out with decoding time windows ranging from 50 to 250ms in duration. These additional results are now reported in:</p><p>Results (lines 258-268):</p><p>“The improved decoding accuracy is supported by greater differentiation in neural representations of the index finger keypresses performed at positions 1 and 5 of the sequence (Figure 4A), and by the trial-by-trial increase in 2-class decoding accuracy over early learning (Figure 4C) across different decoder window durations (Figure 4 – figure supplement 2). As expected, the 5-class hybrid-space decoder performance approached chance levels when tested with randomly shuffled keypress labels (18.41%± SD 7.4% for Day 1 data; Figure 4 – figure supplement 3C). Task-related eye movements did not explain these results since an alternate 5-class hybrid decoder constructed from three eye movement features (gaze position at the KeyDown event, gaze position 200ms later, and peak eye movement velocity within this window; Figure 4 – figure supplement 3A) performed at chance levels (crossvalidated test accuracy = 0.2181; Figure 4 – figure supplement 3B, C).”</p><p>Results (lines 310-316):</p><p>“Offline contextualization strongly correlated with cumulative micro-offline gains (r = 0.903, R² = 0.816, p &lt; 0.001; Figure 5 – figure supplement 1A, inset) across decoder window durations ranging from 50 to 250ms (Figure 5 – figure supplement 1B, C). The offline contextualization between the final sequence of each trial and the second sequence of the subsequent trial (excluding the first sequence) yielded comparable results. This indicates that pre-planning at the start of each practice trial did not directly influence the offline contextualization measure [30] (Figure 5 – figure supplement 2A, 1st vs. 2nd Sequence approaches). “</p><p>Discussion (lines 380-385):</p><p>“The first hint of representational differentiation was the highest false-negative and lowest false-positive misclassification rates for index finger keypresses performed at different locations in the sequence compared with all other digits (Figure 3C). This was further supported by the progressive differentiation of neural representations of the index finger keypress (Figure 4A) and by the robust trial-by-trial increase in 2class decoding accuracy across time windows ranging between 50 and 250ms (Figure 4C; Figure 4 – figure supplement 2).”</p><p>Discussion (lines 408-9):</p><p>“Offline contextualization consistently correlated with early learning gains across a range of decoding windows (50–250ms; Figure 5 – figure supplement 1).”</p><disp-quote content-type="editor-comment"><p>&quot;We addressed this question by conducting a new multivariate regression analysis to directly assess whether the neural representation distance score could be predicted by the 4-1, 2-4 and 4-4 keypress transition times observed for each complete correct sequence&quot;</p><p>For regression analysis, I recommend to use total keypress time per a sequence (or sum of 4-1 and 4-4) instead of specific transition intervals, because there likely exist specific correlational structure across the transition intervals. Using correlated regressors may distort the result.</p></disp-quote><p>This approach is now reported in the manuscript:</p><p>Results (Lines 324-328) and Figure 5-Figure Supplement 6 legend.</p><disp-quote content-type="editor-comment"><p>&quot;We do agree with the Reviewer that the naturalistic, generative, self-paced task employed in the present study results in overlapping brain processes related to planning, execution, evaluation and memory of the action sequence. We also agree that there are several tradeoffs to consider in the construction of the classifiers depending on the study aim. Given our aim of optimizing keypress decoder accuracy in the present study, the set of tradeoffs resulted in representations reflecting more the latter three processes, and less so the planning component. Whether separate decoders can be constructed to tease apart the representations or networks supporting these overlapping processes is an important future direction of research in this area. For example, work presently underway in our lab constrains the selection of windowing parameters in a manner that allows individual classifiers to be temporally linked to specific planning, execution, evaluation or memoryrelated processes to discern which brain networks are involved and how they adaptively reorganize with learning. Results from the present study (Figure 4-figure supplement 2) showing hybrid-space decoder prediction accuracies exceeding 74% for temporal windows spanning as little as 25ms and located up to 100ms prior to the KeyDown event strongly support the feasibility of such an approach.&quot;</p><p>I recommend that the authors add this paragraph or a paragraph like this to the Discussion. This perspective is very important and still missing in the revised manuscript.</p></disp-quote><p>We now included in the manuscript the following sections addressing this point:</p><p>Discussion (lines 334-338)</p><p>“The main findings of this study during which subjects engaged in a naturalistic, self-paced task were that individual sequence action representations differentiate during early skill learning in a manner reflecting the local sequence context in which they were performed, and that the degree of representational differentiation— particularly prominent over rest intervals—correlated with skill gains. “</p><p>Discussion (lines 428-434)</p><p>“In this study, classifiers were trained on MEG activity recorded during or immediately after each keypress, emphasizing neural representations related to action execution, memory consolidation and recall over those related to planning. An important direction for future research is determining whether separate decoders can be developed to distinguish the representations or networks separately supporting these processes. Ongoing work in our lab is addressing this question. The present accuracy results across varied decoding window durations and alignment with each keypress action support the feasibility of this approach (Figure 3—figure supplement 5).”</p><disp-quote content-type="editor-comment"><p>&quot;The rapid initial skill gains that characterize early learning are followed by micro-scale fluctuations around skill plateau levels (i.e. following trial 11 in Figure 1B)&quot; Is this a mention of Figure 1 Supplement 1 A?</p></disp-quote><p>The sentence was replaced with the following: Results (lines 108-110)</p><p>“Participants reached 95% of maximal skill (i.e. - Early Learning) within the initial 11 practice trials (Figure 1B), with improvements developing over inter-practice rest periods (micro-offline gains) accounting for almost all total learning across participants (Figure 1B, inset) [1].”</p><disp-quote content-type="editor-comment"><p>The citation below seems to have been selected by mistake;</p><p>&quot;9. Chen, S. &amp; Epps, J. Using task-induced pupil diameter and blink rate to infer cognitive load. Hum Comput Interact 29, 390-413 (2014).&quot;</p></disp-quote><p>We thank the Reviewer for bringing this mistake to our attention. This citation has now been corrected.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Recommendations for the authors):</bold></p><p>The authors write in their response that &quot;We now provide additional details in the Methods of the revised manuscript pertaining to the parcellation procedure and how the sign ambiguity problem was addressed in our analysis.&quot; I could not find anything along these lines in the (redlined) version of the manuscript and therefore did not change the corresponding comment in the public review.</p></disp-quote><p>The revised manuscript now provides a more detailed explanation of the parcellation, and sign-flipping procedure implemented:</p><p>Methods (lines 604-611):</p><p>“Source-space parcellation was carried out by averaging all voxel time-series located within distinct anatomical regions defined in the Desikan-Killiany Atlas [31]. Since source time-series estimated with beamforming approaches are inherently sign-ambiguous, a custom Matlab-based implementation of the <italic>mne.extract_label_time_course</italic> with “<italic>mean_flip”</italic> sign-flipping procedure in MNEPython [78] was applied prior to averaging to prevent within-parcel signal cancellation. All voxel time-series within each parcel were extracted and the timeseries sign was flipped at locations where the orientation difference was greater than 90° from the parcel mode. A mean time-series was then computed across all voxels within the parcel after sign-flipping.”</p><disp-quote content-type="editor-comment"><p>The control analysis based on a multivariate regression that assessed whether the neural representation distance score could be predicted by the 4-1, 2-4 and 4-4 keypress transition times, as briefly mentioned in the authors' responses to Reviewer 2 and myself, was not included in the manuscript and could not be sufficiently evaluated.</p></disp-quote><p>This approach is now reported in the manuscript: Results (Lines 324-328) and Figure 5-Figure Supplement 6 legend.</p><disp-quote content-type="editor-comment"><p>The authors argue that differences in the design between Das et al. (2024) on the one hand (Experiments 1 and 2), and the study by Bönstrup et al. (2019) on the other hand, may have prevented Das et al. (2024) from finding the assumed learning benefit by micro-offline consolidation. However, the Supplementary Material of Das et al. (2024) includes an experiment (Experiment S1) whose design closely follows a large proportion of the early learning phase of Bönstrup et al. (2019), and which, nevertheless, demonstrates that there is no lasting benefit of taking breaks with respect to the acquired skill level, despite the presence of micro-offline gains.</p></disp-quote><p>We thank the Reviewer for alerting us to this new data added to the revised supplementary materials of Das et al. (2024) posted to bioRxiv. However, despite the Reviewer’s claim to the contrary, a careful comparison between the Das et al and Bönstrup et al studies reveal more substantive differences than similarities and does not “closely follows a large proportion of the early learning phase of Bönstrup et al. (2019)” as stated.</p><p>In the Das et al. Experiment S1, sixty-two participants were randomly assigned to “with breaks” or “no breaks” skill training groups. The “with breaks” group alternated 10 seconds of skill sequence practice with 10 seconds of rest over seven trials (2 min and 2 sec total training duration). This amounts to 66.7% of the early learning period defined by Bönstrup et al. (2019) (i.e. - eleven 10-second long practice periods interleaved with ten 10-second long rest breaks; 3 min 30 sec total training duration). Also, please note that while no performance feedback nor reward was given in the Bönstrup et al. (2019) study, participants in the Das et al. study received explicit performance-based monetary rewards, a potentially crucial driver of differentiated behavior between the two studies:</p><p>“Participants were incentivized with bonus money based on the total number of correct sequences completed throughout the experiment.”</p><p>The “no breaks” group in the Das et al. study practiced the skill sequence for 70 continuous seconds. Both groups (despite one being labeled “no breaks”) follow training with a long 3-minute break (also note that since the “with breaks” group ends with 10 seconds of rest their break is actually longer), before finishing with a skill “<italic>test</italic>” over a continuous 50-second-long block. During the 70 seconds of training, the “with breaks” group shows more learning than the “no breaks” group. Interestingly, following the long 3minute break the “with breaks” group display a performance drop (relative to their performance at the end of training) that is stable over the full 50-second test, while the “no breaks” group shows an immediate performance improvement following the long break that continues to increase over the 50-second test.</p><p>Separately, there are important issues regarding the Das et al study that should be considered through the lens of recent findings not referred to in the preprint. A major element of their experimental design is that both groups—“with breaks” and “no breaks”— actually receive quite a long 3-minute break just before the skill test. This long break is more than 2.5x the cumulative interleaved rest experienced by the “with breaks” group. Thus, although the design is intended to contrast the presence or absence of rest “breaks”, that difference between groups is no longer maintained at the point of the skill test.</p><p>The Das et al results are most consistent with an alternative interpretation of the data— that the “no breaks” group experiences offline learning during their long 3-minute break. This is supported by the recent work of Griffin et al. (2025) where micro-array recordings from primary and premotor cortex were obtained from macaque monkeys while they performed blocks of ten continuous reaching sequences up to 81.4 seconds in duration (see source data for Extended Data Figure 1h) with 90 seconds of interleaved rest. Griffin et al. observed offline improvement in skill immediately following the rest break that was causally related to neural reactivations (i.e. – neural replay) that occurred <italic>during</italic> the rest break. Importantly, the highest density of reactivations was present in the very first 90second break between Blocks 1 and 2 (see Fig. 2f in Griffin et al., 2025). This supports the interpretation that both the “with breaks” and “no breaks” group express offline learning gains, with these gains being delayed in the “no breaks” group due to the practice schedule.</p><p>On the other hand, if offline learning can occur during this longer break, then why would the “with breaks” group show no benefit? Again, it could be that most of the offline gains for this group were front-loaded during the seven shorter 10-second rest breaks. Another possible, though not mutually exclusive, explanation is that the observed drop in performance in the “with breaks” group is driven by contextual interference. Specifically, similar to Experiments 1 and 2 in Das et al. (2024), the skill test is conducted under very different conditions than those which the “with breaks” group practiced the skill under (short bursts of practiced alternating with equally short breaks). On the other hand, the “no breaks” group is tested (50 seconds of continuous practice) under quite similar conditions to their training schedule (70 seconds of continuous practice). Thus, it is possible that this dissimilarity between training and test could lead to reduced performance in the “with breaks” group.</p><p>We made the following manuscript revisions related to these important issues:</p><p>Introduction (Lines 26-56)</p><p>“Practicing a new motor skill elicits rapid performance improvements (early learning) [1] that precede skill performance plateaus [5]. Skill gains during early learning accumulate over rest periods (micro-offline) interspersed with practice [1, 6-10], and are up to four times larger than offline performance improvements reported following overnight sleep [1]. During this initial interval of prominent learning, retroactive interference immediately following each practice interval reduces learning rates relative to interference after passage of time, consistent with stabilization of the motor memory [11]. Micro-offline gains observed during early learning are reproducible [7, 10-13] and are similar in magnitude even when practice periods are reduced by half to 5 seconds in length, thereby confirming that they are not merely a result of recovery from performance fatigue [11]. Additionally, they are unaffected by the random termination of practice periods, which eliminates the possibility of predictive motor slowing as a contributing factor [11]. Collectively, these behavioral findings point towards the interpretation that microoffline gains during early learning represent a form of memory consolidation [1].</p><p>This interpretation has been further supported by brain imaging and electrophysiological studies linking known memory-related networks and consolidation mechanisms to rapid offline performance improvements. In humans, the rate of hippocampo-neocortical neural replay predicts micro-offline gains [6]. Consistent with these findings, Chen et al. [12] and Sjøgård et al. [13] furnished direct evidence from intracranial human EEG studies, demonstrating a connection between the density of hippocampal sharp-wave ripples (80-120 Hz)—recognized markers of neural replay—and micro-offline gains during early learning. Further, Griffin et al. reported that neural replay of task-related ensembles in the motor cortex of macaques during brief rest periods— akin to those observed in humans [1, 6-8, 14]—are not merely correlated with, but are causal drivers of micro-offline learning [15]. Specifically, the same reach directions that were replayed the most during rest breaks showed the greatest reduction in path length (i.e. – more efficient movement path between two locations in the reach sequence) during subsequent trials, while stimulation applied during rest intervals preceding performance plateau reduced reactivation rates and virtually abolished micro-offline gains [15]. Thus, converging evidence in humans and non-human primates across indirect non-invasive and direct invasive recording techniques link hippocampal activity, neural replay dynamics and offline skill gains in early motor learning that precede performance plateau.”</p><p>Next, in the Methods, we articulate important constraints formulated by Pan and Rickard (2015) and Bönstrup et al. (2019) for meaningful measurements:</p><p>Methods (Lines 493-499)</p><p>“The study design followed specific recommendations by Pan and Rickard (2015): (1) utilizing 10-second practice trials and (2) constraining analysis of micro-offline gains to early learning trials (where performance monotonically increases and 95% of overall performance gains occur) that precede the emergence of “scalloped” performance dynamics strongly linked to reactive inhibition effects ([29, 72]). This is precisely the portion of the learning curve Pan and Rickard referred to when they stated “…rapid learning during that period masks any reactive inhibition effect” [29].”</p><p>We finally discuss the implications of neglecting some or all of these recommendations:</p><p>Discussion (Lines 444-452):</p><p>“Finally, caution should be exercised when extrapolating findings during early skill learning, a period of steep performance improvements, to findings reported after insufficient practice [67], post-plateau performance periods [68], or non-learning situations (e.g. performance of non-repeating keypress sequences in [67]) when reactive inhibition or contextual interference effects are prominent. Ultimately, it will be important to develop new paradigms allowing one to independently estimate the different coincident or antagonistic features (e.g. - memory consolidation, planning, working memory and reactive inhibition) contributing to micro-online and micro-offline gains during and after early skill learning within a unifying framework.”</p><disp-quote content-type="editor-comment"><p>Personally, given that the idea of (micro-offline) consolidation seems to attract a lot of interest (and therefore cause a lot of future effort/cost public money) in the scientific community, I would find it extremely important to be cautious in interpreting results in this field. For me, this would include abstaining from the claim that processes occur &quot;during&quot; a rest period (see abstract, for example), given that micro-offline gains (as well as offline contextualization) are computed from data obtained during practice, not rest, and may, thus, just as well reflect a change that occurs &quot;online&quot;, e.g., at the very onset of practice (like pre-planning) or throughout practice (like fatigue, or reactive inhibition). In addition, I would suggest to discuss in more depth the actual evidence not only in favour, but also against, the assumption of micro-offline gains as a phenomenon of learning.</p></disp-quote><p>We agree with the reviewer that caution is warranted. Based upon these suggestions, we have now expanded the manuscript to very clearly define the experimental constraints under which different groups have successfully studied micro-offline learning and its mechanisms, the impact of fatigue/reactive inhibition on micro-offline performance changes unrelated to learning, as well as the interpretation problems that emerge when those recommendations are not followed.</p><p>We clearly articulate the crucial constrains recommended by Pan and Rickard (2015) and Bönstrup et al. (2019) for meaningful measurements and interpretation of offline gains in the revised manuscript.</p><p>Methods (Lines 493-499)</p><p>“The study design followed specific recommendations by Pan and Rickard (2015): (1) utilizing 10-second practice trials and (2) constraining analysis of micro-offline gains to early learning trials (where performance monotonically increases and 95% of overall performance gains occur) that precede the emergence of “scalloped” performance dynamics strongly linked to reactive inhibition effects ([29, 72]). This is precisely the portion of the learning curve Pan and Rickard referred to when they stated “…rapid learning during that period masks any reactive inhibition effect” [29].”</p><p>In the Introduction, we review the extensive evidence emerging from LFP and microelectrode recordings in humans and monkeys (including causality of neural replay with respect to micro-offline gains and early learning in the Griffin et al. Nature 2025 publication):</p><p>Introduction (Lines 26-56)</p><p>“Practicing a new motor skill elicits rapid performance improvements (early learning) [1] that precede skill performance plateaus [5]. Skill gains during early learning accumulate over rest periods (micro-offline) interspersed with practice [1, 6-10], and are up to four times larger than offline performance improvements reported following overnight sleep [1]. During this initial interval of prominent learning, retroactive interference immediately following each practice interval reduces learning rates relative to interference after passage of time, consistent with stabilization of the motor memory [11]. Micro-offline gains observed during early learning are reproducible [7, 10-13] and are similar in magnitude even when practice periods are reduced by half to 5 seconds in length, thereby confirming that they are not merely a result of recovery from performance fatigue [11]. Additionally, they are unaffected by the random termination of practice periods, which eliminates the possibility of predictive motor slowing as a contributing factor [11]. Collectively, these behavioral findings point towards the interpretation that microoffline gains during early learning represent a form of memory consolidation [1].</p><p>This interpretation has been further supported by brain imaging and electrophysiological studies linking known memory-related networks and consolidation mechanisms to rapid offline performance improvements. In humans, the rate of hippocampo-neocortical neural replay predicts micro-offline gains [6]. Consistent with these findings, Chen et al. [12] and Sjøgård et al. [13] furnished direct evidence from intracranial human EEG studies, demonstrating a connection between the density of hippocampal sharp-wave ripples (80-120 Hz)—recognized markers of neural replay—and micro-offline gains during early learning. Further, Griffin et al. reported that neural replay of task-related ensembles in the motor cortex of macaques during brief rest periods— akin to those observed in humans [1, 6-8, 14]—are not merely correlated with, but are causal drivers of micro-offline learning [15]. Specifically, the same reach directions that were replayed the most during rest breaks showed the greatest reduction in path length (i.e. – more efficient movement path between two locations in the reach sequence) during subsequent trials, while stimulation applied during rest intervals preceding performance plateau reduced reactivation rates and virtually abolished micro-offline gains [15]. Thus, converging evidence in humans and non-human primates across indirect non-invasive and direct invasive recording techniques link hippocampal activity, neural replay dynamics and offline skill gains in early motor learning that precede performance plateau.”</p><p>Following the reviewer’s advice, we have expanded our discussion in the revised manuscript of alternative hypotheses put forward in the literature and call for caution when extrapolating results across studies with fundamental differences in design (e.g. – different practice and rest durations, or presence/absence of extrinsic reward, etc).</p><p>Discussion (Lines 444-452):</p><p>“Finally, caution should be exercised when extrapolating findings during early skill learning, a period of steep performance improvements, to findings reported after insufficient practice [67], post-plateau performance periods [68], or non-learning situations (e.g. performance of non-repeating keypress sequences in [67]) when reactive inhibition or contextual interference effects are prominent. Ultimately, it will be important to develop new paradigms allowing one to independently estimate the different coincident or antagonistic features (e.g. - memory consolidation, planning, working memory and reactive inhibition) contributing to micro-online and micro-offline gains during and after early skill learning within a unifying framework.”</p><p>References</p><p>(1) Zimerman, M., et al., Disrupting the Ipsilateral Motor Cortex Interferes with Training of a Complex Motor Task in Older Adults. Cereb Cortex, 2012.</p><p>(2) Waters, S., T. Wiestler, and J. Diedrichsen, Cooperation Not Competition: Bihemispheric tDCS and fMRI Show Role for Ipsilateral Hemisphere in Motor Learning. J Neurosci, 2017. 37(31): p. 7500-7512.</p><p>(3) Sawamura, D., et al., Acquisition of chopstick-operation skills with the nondominant hand and concomitant changes in brain activity. Sci Rep, 2019. 9(1): p. 20397.</p><p>(4) Lee, S.H., S.H. Jin, and J. An, The dieerence in cortical activation pattern for complex motor skills: A functional near- infrared spectroscopy study. Sci Rep, 2019. 9(1): p. 14066.</p><p>(5) Grafton, S.T., E. Hazeltine, and R.B. Ivry, Motor sequence learning with the nondominant left hand. A PET functional imaging study. Exp Brain Res, 2002. 146(3): p. 369-78.</p><p>(6) Buch, E.R., et al., Consolidation of human skill linked to waking hippocamponeocortical replay. Cell Rep, 2021. 35(10): p. 109193.</p><p>(7) Wang, L. and S. Jiang, A feature selection method via analysis of relevance, redundancy, and interaction, in Expert Systems with Applications, Elsevier, Editor. 2021.</p><p>(8) Yu, L. and H. Liu, Eeicient feature selection via analysis of relevance and redundancy. Journal of Machine Learning Research, 2004. 5: p. 1205-1224.</p><p>(9) Munn, B.R., et al., Multiscale organization of neuronal activity unifies scaledependent theories of brain function. Cell, 2024.</p><p>(10) Borragan, G., et al., Sleep and memory consolidation: motor performance and proactive interference eeects in sequence learning. Brain Cogn, 2015. 95: p. 54-61.</p><p>(11) Landry, S., C. Anderson, and R. Conduit, The eeects of sleep, wake activity and timeon-task on oeline motor sequence learning. Neurobiol Learn Mem, 2016. 127: p. 5663.</p><p>(12) Gabitov, E., et al., Susceptibility of consolidated procedural memory to interference is independent of its active task-based retrieval. PLoS One, 2019. 14(1): p. e0210876.</p><p>(13) Pan, S.C. and T.C. Rickard, Sleep and motor learning: Is there room for consolidation? Psychol Bull, 2015. 141(4): p. 812-34.</p><p>(14) , M., et al., A Rapid Form of Oeline Consolidation in Skill Learning. Curr Biol, 2019. 29(8): p. 1346-1351 e4.</p><p>(15) Gupta, M.W. and T.C. Rickard, Comparison of online, oeline, and hybrid hypotheses of motor sequence learning using a quantitative model that incorporate reactive inhibition. Sci Rep, 2024. 14(1): p. 4661.</p></body></sub-article></article>