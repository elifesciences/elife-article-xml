<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">57502</article-id><article-id pub-id-type="doi">10.7554/eLife.57502</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Curvature-processing domains in primate V4</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-182641"><name><surname>Tang</surname><given-names>Rendong</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3622-3383</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-182642"><name><surname>Song</surname><given-names>Qianling</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-9177-7429</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-182643"><name><surname>Li</surname><given-names>Ying</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-182644"><name><surname>Zhang</surname><given-names>Rui</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-96936"><name><surname>Cai</surname><given-names>Xingya</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7829-3833</contrib-id><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-29950"><name><surname>Lu</surname><given-names>Haidong D</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1739-9508</contrib-id><email>haidong@bnu.edu.cn</email><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution>State Key Laboratory of Cognitive Neuroscience and Learning, IDG/MGovern Institute for Brain Research, Beijing Normal University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Krug</surname><given-names>Kristine</given-names></name><role>Reviewing Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Gold</surname><given-names>Joshua I</given-names></name><role>Senior Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>19</day><month>11</month><year>2020</year></pub-date><pub-date pub-type="collection"><year>2020</year></pub-date><volume>9</volume><elocation-id>e57502</elocation-id><history><date date-type="received" iso-8601-date="2020-04-02"><day>02</day><month>04</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2020-11-18"><day>18</day><month>11</month><year>2020</year></date></history><permissions><copyright-statement>© 2020, Tang et al</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Tang et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-57502-v2.pdf"/><related-article ext-link-type="doi" id="ra1" related-article-type="article-reference" xlink:href="10.7554/eLife.57261"/><abstract><p>Neurons in primate V4 exhibit various types of selectivity for contour shapes, including curves, angles, and simple shapes. How are these neurons organized in V4 remains unclear. Using intrinsic signal optical imaging and two-photon calcium imaging, we observed submillimeter functional domains in V4 that contained neurons preferring curved contours over rectilinear ones. These curvature domains had similar sizes and response amplitudes as orientation domains but tended to separate from these regions. Within the curvature domains, neurons that preferred circles or curve orientations clustered further into finer scale subdomains. Nevertheless, individual neurons also had a wide range of contour selectivity, and neighboring neurons exhibited a substantial diversity in shape tuning besides their common shape preferences. In strong contrast to V4, V1 and V2 did not have such contour-shape-related domains. These findings highlight the importance and complexity of curvature processing in visual object recognition and the key functional role of V4 in this process.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>functional map</kwd><kwd>functional column</kwd><kwd>contour</kwd><kwd>macaque</kwd><kwd>ISOI</kwd><kwd>2-photon imaging</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>31530029</award-id><principal-award-recipient><name><surname>Lu</surname><given-names>Haidong D</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>31625012</award-id><principal-award-recipient><name><surname>Lu</surname><given-names>Haidong D</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>31800870</award-id><principal-award-recipient><name><surname>Tang</surname><given-names>Rendong</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002858</institution-id><institution>China Postdoctoral Science Foundation</institution></institution-wrap></funding-source><award-id>2018M631373</award-id><principal-award-recipient><name><surname>Tang</surname><given-names>Rendong</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Curvature-preferring neurons in monkey V4 cluster into 0.5-mm patches, which highlights the importance of curvature detection in visual object recognition and the key functional role of V4 in this process.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Shape extraction is crucial for object recognition and is a major function of the primate visual cortex. This process has been reported to occur in the ventral visual pathway (V1-V2-V4-IT) in a hierarchical manner (<xref ref-type="bibr" rid="bib5">Connor et al., 2007</xref>). The mid-level area V4 plays an important role in this process (<xref ref-type="bibr" rid="bib36">Roe et al., 2012</xref>; <xref ref-type="bibr" rid="bib30">Pasupathy et al., 2020</xref>). Many V4 neurons selectively respond to curvatures (<xref ref-type="bibr" rid="bib31">Pasupathy and Connor, 1999</xref>) and complex shape features (<xref ref-type="bibr" rid="bib6">Desimone and Schein, 1987</xref>; <xref ref-type="bibr" rid="bib11">Gallant et al., 1993</xref>; <xref ref-type="bibr" rid="bib21">Kobatake and Tanaka, 1994</xref>). However, the distribution of these shape-selective neurons in V4 remains unclear.</p><p>In the V1-V2-V4-IT pathway, orientation maps have been reported in V1, V2, and V4. Functional maps for faces (<xref ref-type="bibr" rid="bib43">Wang et al., 1996</xref>; <xref ref-type="bibr" rid="bib41">Tsao et al., 2006</xref>) and various shape features (<xref ref-type="bibr" rid="bib10">Fujita et al., 1992</xref>; <xref ref-type="bibr" rid="bib42">Tsunoda et al., 2001</xref>; <xref ref-type="bibr" rid="bib37">Sato et al., 2009</xref>) have been reported in IT. This processing hierarchy appears to lack functional structures for shape features of intermediate complexity, including curvatures and angles. A previous fMRI study reported several patches of the ventral cortex that prefer curved features with one being located in V4 (<xref ref-type="bibr" rid="bib46">Yue et al., 2014</xref>). However, given the limited spatial resolution of fMRI signals, these patches were relatively large (at the cm-scale). It remains unclear whether there are submillimeter functional columns for curvatures that are similar to those for edge orientations.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Curvature domains imaged using intrinsic signal optical imaging (ISOI)</title><p>Through ISOI on anaesthetized macaques, we imaged cortical hemodynamic signals for various contour features. The stimulus set included simple contour shapes, including circles and triangles, as well as parts of these shapes, including curves, angles, and short straight lines. As shown in <xref ref-type="fig" rid="fig1">Figure 1C</xref>, the contours were presented on a full screen and drifted along one of four or eight directions. Each stimulus condition was presented for 3.5 s and repeated 25–50 times in a random sequence. The light reflectance was imaged through an optical chamber covering parts of V1, V2, and V4 (<xref ref-type="fig" rid="fig1">Figure 1A and B</xref>). The exposed V4 region corresponded to the visual field of 0°−10° eccentricity in a lower quadrant. We obtained support vector machine (SVM) maps that compared cortical images collected during two stimulus conditions (<xref ref-type="fig" rid="fig1">Figure 1D–L</xref>). In the circle vs. triangle map (<xref ref-type="fig" rid="fig1">Figure 1D</xref>), the black and white patches corresponded to regions that preferred circles and triangles, respectively. This V4 pattern significantly differed from the orientation (<xref ref-type="fig" rid="fig1">Figure 1E</xref>) and color patterns (<xref ref-type="fig" rid="fig1">Figure 1F</xref>) obtained with established methods (<xref ref-type="bibr" rid="bib40">Tanigawa et al., 2010</xref>; <xref ref-type="bibr" rid="bib22">Li et al., 2013</xref>). In contrast to V4, we did not observe circle vs. triangle patterns in V1 and V2, or in the cortex anterior to the superior temporal sulcus (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). We also examined single-condition maps (stimulus vs. blank); however, the responses were dominated by feature-non-specific activation and the shape-selective response patterns were not apparent (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Intrinsic signal optical imaging (ISOI) of curvature domains in area V4.</title><p>(<bold>A</bold>) A schematic representation of the macaque brain showing the imaging region (green circle) and sulci locations. lu, lunate sulcus; st, superior temporal sulcus; and io, inferior occipital sulcus. (<bold>B</bold>) In vivo image of the blood vessel pattern in the 16 mm diameter imaging region in Case 1, which included parts of V1, V2, and V4. The exposed V4 region was between the st and lu sulci. A, anterior; M, medial. (<bold>C</bold>) An illustration of the full-screen stimulus pattern used for ISOI imaging. Circle diameter: 2.5°. Drifting speed: 4°/s. (<bold>D–L</bold>) Functional maps (SVM maps) from Case 1. The icons shown at the top represent the stimulus conditions being compared. In the ISOI maps, dark and white regions were preferentially activated by the stimulus icons shown on the left and right, respectively. For the maps shown in G, H, J, and K, data from different stimulus orientations were pooled for lines, curves, and angles. Other maps were obtained with the exact stimuli as shown on the maps. (<bold>D</bold>) The circle vs. triangle map shows clear patches in V4 (dark regions preferred circles and white regions preferred triangles), which were absent in V1 and V2. The dotted line represents the border between V1 and V2. (<bold>E</bold>) The orientation preference map shows the 45° (dark) and 135° (white) orientation domains in V2 and V4. The lack of orientation domains in V1 could have been resulted from the low SF of the stimulus gratings (0.25 c/degrees). (<bold>F</bold>) The color preference map shows the color domains in V1, V2, and V4. (<bold>G</bold>) The circle vs. straight line map shows a preference pattern similar to that in the circle vs. triangle map (<bold>D</bold>). (<bold>H</bold>) The curve vs. straight line map shows patterns similar to those in D and G. The curve was a half-circle. (<bold>I</bold>) The curve-orientation map shows smaller and weaker patches preferring different curve orientations. (<bold>J</bold>) The triangle vs. straight line map shows weaker and larger patches than those in the circle vs. straight line map in G. The dark domains preferred triangles over lines and occupied the same regions as the white patches in D. (<bold>K</bold>) The angle vs. straight line map shows a very weak pattern similar to that in J. (<bold>L</bold>) There was no clear pattern in the angle-orientation map.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57502-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Comparison of single-condition maps and difference maps (Case 1).</title><p>(<bold>A</bold>) A single-condition SVM map obtained by comparing circle response and blank response from Case 1. (<bold>B</bold>) As in A, but for triangle response. (<bold>C</bold>) The difference map comparing circle and triangle responses (same as shown in <xref ref-type="fig" rid="fig1">Figure 1D</xref>). (<bold>D–O</bold>) As in A–C, single-condition maps (top two rows) and their corresponding difference maps (bottom row). The single-conditions maps contained stimulus-non-specific hemodynamic signals, which were diffuse and low contrast. Difference maps removed these common responses and revealed stimulus-specific responses. Maps A–I and J–O were obtained from the same chamber in two separate experiments.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57502-fig1-figsupp1-v2.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Additional functional maps of Case 1.</title><p>(<bold>A–D</bold>) All four curve-orientation maps of Case 1 comparing opposite curve orientations. B is the same map as shown in <xref ref-type="fig" rid="fig1">Figure 1I</xref>. (<bold>E</bold>) The vector-summation map for the curve-orientation preferences calculated based on the maps in A-D. (<bold>F</bold>) An enlarged view of the vector-summation map showed in E. (<bold>G–L</bold>) Functional maps of Case 1 obtained with the same method as those in <xref ref-type="fig" rid="fig1">Figure 1</xref>. (<bold>M and N</bold>) Circle vs. triangle maps obtained with binocular stimulation (M, same as in <xref ref-type="fig" rid="fig1">Figure 1D</xref>) or monocular left-eye stimulation (<bold>N</bold>). The red-framed regions in M are enlarged in O-R. The value at bottom of N is the correlation between V4 regions in the two maps. (<bold>O–R</bold>) Zoom-in views of 4 regions (locations are indicated in M) from 12 functional maps (columns) for detailed comparisons. The stimulus conditions are illustrated on the top of each column. Values at the bottom are correlation values between the whole V4 region in the corresponding map (not only the enlarged regions) and the V4 region in the circle vs. triangle map (<bold>M</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57502-fig1-figsupp2-v2.tif"/></fig></fig-group><p>Similar V4 patterns were observed in the circle vs. triangle (<xref ref-type="fig" rid="fig1">Figure 1D</xref>), circle vs. line (<xref ref-type="fig" rid="fig1">Figure 1G</xref>), and curve vs. line maps (<xref ref-type="fig" rid="fig1">Figure 1H</xref>). Although the strength of the dark patches in the latter two maps appeared weaker, they had similar general layouts and locations as the first one (also see <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2O–R</xref> for enlarged views). This similarity suggests that the key contour feature responsible for these dark patches was the curviness. Therefore, we have henceforth referred to these patches as ‘curvature domains’. These curvature domains contained smaller substructures. For example, a map comparing differently oriented curves showed smaller and weaker patches within the curvature domains (<xref ref-type="fig" rid="fig1">Figure 1I</xref>, <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>). Note that this curve orientation (also called direction) is different from the grating orientation (0–180°) and has a range of 0–360°.</p><p>Compared with the curvature domains, triangle-activated cortical regions appeared significantly weaker. In the triangle vs. line (<xref ref-type="fig" rid="fig1">Figure 1J</xref>) and angle vs. line maps (<xref ref-type="fig" rid="fig1">Figure 1K</xref>), the dark patches (angle-preferring) were apparently more diffused and weaker than those in the circle vs. line or curve vs. line maps (<xref ref-type="fig" rid="fig1">Figure 1G and H</xref>). This was also observed in the circle vs. triangle map (<xref ref-type="fig" rid="fig1">Figure 1D</xref>), which had fewer and weaker white patches (triangle-preferring) than dark patches (circle-preferring) (also see <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2G</xref>). Moreover, the orientation subdomains observed in the curve-orientation map (<xref ref-type="fig" rid="fig1">Figure 1I</xref>) were not present in the angle-orientation map (<xref ref-type="fig" rid="fig1">Figure 1L</xref>).</p><p>Imaging results of seven hemispheres (cases) of six macaque monkeys were consistent (<xref ref-type="fig" rid="fig2">Figure 2B</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1B</xref>). We observed curvature domains in the entire exposed V4 surface representing both foveal and peripheral visual fields, but peripheral V4 tend to prefer larger circles (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2A–D</xref>). Moreover, similar patterns can be repeatedly imaged from the same chamber over months (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>). Modification of the experimental conditions (e.g. monocular left- or right-eye viewing conditions or binocular conditions, see <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2M and N</xref>) and noncritical stimulus parameters (e.g. contour brightness, filled disks, and regular vs. random contour arrangements) did not alter the main pattern features (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2E–I</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Comparison of curvature and orientation maps.</title><p>(<bold>A–D</bold>) Maps from Cases 2–4 are shown in rows 1–3. (<bold>A</bold>) The blood vessel patterns of the imaging regions. (<bold>B</bold>) The circle vs. triangle maps obtained using the same stimuli as those for <xref ref-type="fig" rid="fig1">Figure 1D</xref>. (<bold>C</bold>) Orientation preference maps showing the 45° vs. 135° orientation patterns in V1, V2, and V4. The dotted lines represent the borders between V1 and V2. Case 4 did not have V2 exposed on the surface. (<bold>D</bold>) The spatial relationship between the curvature and orientation domains (0°, 45°, 90°, 135°) in each case. (<bold>E</bold>) The curvature and orientation domains had similar domain sizes. (<bold>F</bold>) The curvature and orientation domains had similar response amplitudes. (<bold>G</bold>) The size of the overlap regions between the curvature and orientation domains was smaller than that of the random prediction (p=0.030; paired t-test, n = 7), which indicates a tendency of separation of these two types of domains.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57502-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Three types of maps from all seven cases.</title><p>(<bold>A</bold>) Blood-vessel patterns of the seven chambers used in ISOI imaging, plotted in the same convention as that in <xref ref-type="fig" rid="fig1">Figure 1B</xref>. Cases 1–5 were from left hemispheres, and Cases 6 and 7 were from right hemispheres. A, anterior; M, medial; lu, lunate sulcus; st, superior temporal sulcus; and io, inferior occipital sulcus. (<bold>B</bold>) Circle <italic>vs.</italic> triangle maps. (<bold>C</bold>) Orientation preference maps. (<bold>D</bold>) Color preference maps. (<bold>E</bold>) The overlap of three types of domains. (<bold>F</bold>) Percentages of areas occupied by four types of domains in V4 (first four columns), which serve as a random distribution control for the proportion of overlapped region by another type of domain (five columns on the right). One or two asterisks indicates p&lt;0.05 or p&lt;0.01, respectively (paired t-test, n = 7). Error bars: s.e.m.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57502-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Circle vs. triangle maps obtained with different stimulus parameters.</title><p>(<bold>A–C</bold>) Circle vs. triangle maps obtained with three different circle sizes (A: 1.25°; B: 2.5°; C: 5°). The size of the triangle was kept at 2.5°. Three rows are maps from three different cases. Red frames in the maps are enlarged in D for detailed comparison. The lateral V4 represents the foveal visual field (lower visual eccentricity), and the medial V4 represents peripheral (higher visual eccentricity). When the circle size increased, stronger activation domains in V4 shifted from lateral to medial. (<bold>D</bold>) Zoom-in views of the regions indicated in A–C. Maps in the three columns correspond to the three columns in A–C. When circle size increased, the activation of the lateral domains (labeled 1) decreased (from the left column to the right column), while medial domains (labeled 3) increased their activity. Domain in the middle (labeled 2) were more activated by mid-sized circles. (<bold>E</bold>) Standard circle vs. triangle maps of Cases 2, 4, and 5. These maps are the same as those shown in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1B</xref> and were obtained with a regular stimulus protocol. (<bold>F–I</bold>) Circle vs. triangle maps obtained with different types of circle stimuli, while triangle stimuli were kept the same as in E, including: circles randomly positioned as contrast to orderly positioned ones (e.g. <xref ref-type="fig" rid="fig1">Figure 1C</xref>) (<bold>F</bold>); Black circles (<bold>G</bold>), Filled gray disks (<bold>H</bold>), and Filled dark disks (<bold>I</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57502-fig2-figsupp2-v2.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>Repeated imaging of the maps on different days.</title><p>(<bold>A–C</bold>) Circle vs. triangle maps obtained from four cases (four rows) on different days (three columns). The stimulus protocols were the same as the example shown in <xref ref-type="fig" rid="fig1">Figure 1D</xref>. Imaging dates are indicated on the top of each map.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57502-fig2-figsupp3-v2.tif"/></fig></fig-group><p>The curvature domains had an average diameter of 518 ± 25 μm (mean ± s.e.m), which was similar to that of the orientation domains (479 ± 16 μm, p=0.074, paired t-test, n = 7; <xref ref-type="fig" rid="fig2">Figure 2E</xref>). The curvature domains occupied 12.1 ± 1.7% of the V4 surface, smaller than the coverage of the orientation domains (22.3 ± 3.7%, p=0.025, paired t-test, n = 7). The intrinsic optical signal amplitude (percentage change), which was measured from the raw subtraction maps, was numerically, but not significantly, larger for the circle vs. triangle maps than the orientation maps (curvature domains: 0.036%, orientation domains: 0.029%, p=0.15, paired t-test, n = 7, <xref ref-type="fig" rid="fig2">Figure 2F</xref>).</p><p>Both the curvature and orientation domains represent shape features; therefore, it is logical to expect that they might overlap. However, we observed little overlap between the curvature and orientation domains (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). The overlap size was significantly smaller than that expected in a random distribution (p=0.03, paired t-test, n = 7, <xref ref-type="fig" rid="fig2">Figure 2G</xref>), which indicates an avoidance tendency between both domains. Moreover, the curvature domains did not overlap with the color domains (p=0.004, paired t-test, n = 7, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1F</xref>). Contrastingly, the triangle-preferring white patches in the circle vs. triangle maps tended to overlap with the orientation (p=0.003, paired t-test, n = 7; <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1F</xref>) but not the color domains (p=0.17, paired t-test, n = 7; <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1F</xref>).</p></sec><sec id="s2-2"><title>Two-photon calcium imaging of the responses to contour shapes</title><p>ISOI used a metabolism-based hemodynamic signal; therefore, the actual neuronal responses and neuron constitution within these domains were unclear. Moreover, ISOI could not provide information regarding the variations in different cortical layers. We then used two-photon calcium imaging to address these questions. Based on the ISOI functional maps, we injected AAV1/9-GCaMP6s virus into multiple locations in two chambers (Cases 3 and 4 in <xref ref-type="fig" rid="fig2">Figure 2A</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). The injections targeted either the centers of the curvature domains or regions outside these domains. We imaged the monkeys under similar anesthesia conditions 1.5 months after the injections. <xref ref-type="fig" rid="fig3">Figure 3C</xref> shows an image from Case 3 (red frame in <xref ref-type="fig" rid="fig3">Figure 3A and B</xref>, also see <xref ref-type="video" rid="fig3video1">Figure 3—video 1</xref>) at a 210 μm depth. The center of this image frame contained a curvature domain (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). Mapped with both manual and computer-controlled visual stimuli, the population receptive field (RF) of this region was ~4° in size and approximately 7° from the fovea (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Two-photon calcium imaging of neuronal shape responses.</title><p>(<bold>A</bold>) An image of the cortical region obtained from Case 3 in which AAV-GCaMP6s was injected for calcium imaging. The red and green frames indicate two regions examined using two-photon imaging. (<bold>B</bold>) Circle vs. triangle map of the region shown in A. (<bold>C</bold>) Neurons in the red-frame region shown in A and B that were imaged using a 16× objective at a 210 μm depth from the cortical surface. Two neurons marked in red are examined in detail in panel F. Scale bar applies to C–E. (<bold>D and E</bold>) Single-condition response maps (ΔF) for the circle (<bold>D</bold>), and triangle (<bold>E</bold>) stimuli. Each map was obtained after averaging 15 repeats and pooling of 4 orientations. (<bold>F</bold>) Responses (ΔF/F) of 3 neurons to 14 typical contour stimuli (showed at the bottom, red: curvature stimuli; green: rectilinear stimuli). The responses to circle and triangle were the best-orientation ones. Cells 1 and 2 were selected from the curvature domain shown in C. Although both neurons preferred circle stimuli, they exhibited different response levels to other stimuli types. Cell 3 was selected from a rectilinear region (marked in <xref ref-type="fig" rid="fig4">Figure 4F</xref>) and was strongly activated by the triangle stimulus and one of its line segment. The gray and blue lines represent individual trials and the average, respectively. The stimulus duration (2 s) is labeled at the bottom of the last row.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57502-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>All the 10 two-photon-imaged V4 regions in this study.</title><p>(<bold>A</bold>) The blood vessel map of Case 3, in which five V4 regions studied with the two-photon imaging are indicated (red squares). A, anterior; M, medial; lu, lunate sulcus; st, superior temporal sulcus; and io, inferior occipital sulcus. (<bold>B</bold>) The circle vs. triangle map of Case 3. The two-photon imaged regions (red squares) are further enlarged in C. (<bold>C</bold>) The zoom-in views of the five regions indicated in the circle vs. triangle map in B. Site one was the same as shown in <xref ref-type="fig" rid="fig4">Figure 4A</xref>. Site four was the same site as shown in <xref ref-type="fig" rid="fig4">Figure 4D</xref>. (<bold>D</bold>) Curvature (red) vs. rectilinear (green) preference maps of the five regions (five columns), plotted with the same convention as those in <xref ref-type="fig" rid="fig4">Figure 4B and C</xref>. The different maps in each column were from different imaging depths (indicated at the bottom right of each map). A consistency among different depths, as well as with the ISOI maps in C, can be observed. (<bold>E–H</bold>) Similar to A–D, the maps from Case 4 show the same trend. Site one was the same as shown in <xref ref-type="fig" rid="fig4">Figure 4G</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57502-fig3-figsupp1-v2.tif"/></fig><media id="fig3video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-57502-fig3-video1.mp4"><label>Figure 3—video 1.</label><caption><title>Fluorescent responses of V4 neurons to contour shapes.</title><p>Single-trial two-photon images from one experiment session were extracted from the raw data and displayed in a real-time speed. This imaging site is also shown in <xref ref-type="fig" rid="fig3">Figure 3C</xref>. For each stimulus condition, seven consecutive frames after the stimulus onset were extracted and displayed. This include three frames collected during the stimulus presentation and four frames collected during interstimulus interval. The top-down refreshing display mimics the scanning sequence of the Galvo mode imaging (1.3 Hz) used in the experiments. Each frame was clipped to the range of 0 and mean+7SD, where ‘mean’ is the average of pixel values in all the frames in this video and ‘SD’ is the average of standard deviations of all the frames. Images were aligned to correct motion noises. Frame size was resized from 512 × 512 pixels to 410 × 410 pixels to reduce file size. Stimuli elicited the fluorescent responses were illustrated on the bottom right. Each stimulus was ~1.6°, moved across a range of 4° in one of eight directions. The size of the population RF for this imaged region is approximately four degrees.</p></caption></media></fig-group><p>We tested 19 different curved and rectilinear contours, presented at different orientations, which resulted 73 unique stimuli (Figure 6A, also see Materials and methods). Each stimulus contained a single contour element similar to those used in the ISOI experiments (<xref ref-type="video" rid="fig3video1">Figure 3—video 1</xref>). The stimulus moved across the population RF along a direction randomly chosen. Consistent with the ISOI results (<xref ref-type="fig" rid="fig3">Figure 3B</xref>), we observed significant activation of the neurons by circle stimuli (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). The whole frame showed a scaled-down response to triangles (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). The results demonstrate that different stimuli types mainly affected the population response amplitudes rather than activating different cells within the curvature domain.</p><p>We determined the preferences of curved and rectilinear stimuli for each pixel in the two-photon image (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). This imaged region showed a preference for curved (red) over rectilinear (green) stimuli. Consistent preference patterns were observed for this two-photon map (<xref ref-type="fig" rid="fig4">Figure 4B</xref>) and the ISOI map from the same region (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). Similar preference patterns were observed at deeper layers for this (<xref ref-type="fig" rid="fig4">Figure 4B and C</xref>) and all five locations imaged at multiple depths (<xref ref-type="fig" rid="fig4">Figure 4D–I</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Therefore, the curvature domains form a columnar structure within at least the top V4 layers.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Consistency between ISOI and two-photon imaging results.</title><p>(<bold>A</bold>) An enlarged view of a curvature domain in an ISOI circle-triangle map in Case 3 (the red-framed region in <xref ref-type="fig" rid="fig3">Figure 3B</xref>). (<bold>B</bold>) A curvature (red) vs. rectilinear (green) preference map for the same image used in <xref ref-type="fig" rid="fig3">Figure 3C</xref>. Each pixel is color coded for its preferred responses to the curvature (red-framed icons in <xref ref-type="fig" rid="fig3">Figure 3F</xref>) or rectilinear stimuli (green-framed icons in <xref ref-type="fig" rid="fig3">Figure 3F</xref>). The brightness of the pixels is proportional to the fluorescence strength and shape preference (see Materials and methods). (<bold>C</bold>) Preference maps for the same location shown in B but obtained from a deeper layer (350 μm from the surface). Contour-type preferences are similar as shallower depths (<bold>B</bold>). (<bold>D–F</bold>) As in A-C, but for another location in Case 3 (green-framed regions in <xref ref-type="fig" rid="fig3">Figure 3A and B</xref>). This region contained a subregion preferring curved stimuli (top right) and a subregion preferring rectilinear stimuli (lower left). Two-photon preference maps show consistent contour-type preferences with the ISOI map, as well as consistency between different depths. Cell 3 with an arrow was also used in <xref ref-type="fig" rid="fig3">Figure 3F</xref>. (<bold>G–I</bold>) As in above two sites, a third example obtained from Case 4, which contained a small curvature domain. Consistency between ISOI imaging and two-photon imaging, as well as consistency between different depths of two-photon images are evident. (<bold>J</bold>) Comparison of the ISOI and two-photon responses. The Y-axis represents differences in the fluorescent responses (optimal orientation) to circles and triangles in all neurons. The X-axis represents differences in hemodynamic responses for corresponding neuron pixels in the ISOI circle vs. triangle maps. There was a significant correlation between the two types of responses (Pearson r = 0.42, p=9.45×10<sup>−83</sup>, n = 1923). (<bold>K</bold>) Similar to J, there was a significant correlation between the fluorescent responses (optimal orientation) to curves vs. lines and ISOI responses to circles vs. triangles (Pearson r = 0.43, p=9.35×10<sup>−88</sup>, n = 1923). (<bold>L</bold>) The RF sizes of all neurons measured (Y-axis) had a negative correlation with the circle-triangle preferential responses of the corresponding pixels in the ISOI imaging (X-axis, same as the X-axis values in J and K). The dotted vertical line represents the threshold chosen (2SD) in determining whether a pixel is inside the curvature domains (the right side of the line) or outside (the left side of the line). (<bold>M</bold>) The average RF size was smaller for neurons inside the curvature domains (1.95 ± 0.032°, n = 583) than those outside (2.37 ± 0.038°, n = 835, p=1.15×10<sup>−14</sup>, t-test). Error bar: s.e.m.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57502-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>RF sizes of the sampled V4 neurons.</title><p>(<bold>A</bold>) The RF plot for the imaged neurons in <xref ref-type="fig" rid="fig3">Figure 3C</xref>. The red asterisk indicates the fovea location estimated from a back-projected plot of the blind spot. The center locations of the RFs were calculated from the responses to the 5 × 5 grid RF mapping stimuli, and the RF sizes were calculated from the size-tuning fitting functions. (<bold>B</bold>) The RF size of two example sites which shows progressive change in the right image, but not in the left image. (<bold>C</bold>) The curvature (red) vs. rectilinear (green) preference maps corresponding to the site shown on the top. (<bold>D</bold>) The RF sizes of all neurons measured (Y-axis) had a negative correlation with the curve-line preferential responses (optimal orientation) measured in the two-photon imaging (X-axis). Different colors indicate different two-photon sites (n = 9, different depths of the same site were pooled). (<bold>E</bold>) The distribution of the correlation values between RF sizes and curve-line preferential responses for 9 two-photon sites, measured from panel D. The X axis represents the standard deviation of curve-line preferential responses among the neurons in each two-photon site. (<bold>F and G</bold>) As in D and E, but for neurons’ surround suppression, which was positively correlated with their curvature preference, and such correlation was also influenced by the homogeneity of neurons in the imaging site (<bold>G</bold>). Note: A total of 1493 neurons had significant RF size tuning. The RF sizes were calculated from the size-tuning fitting functions. In these neurons, 13 had RF sizes smaller than 0.5°, and 62 had RF sizes larger than 12°. These 75 neurons were not included in the above plot or the analysis in panels D–G. In addition, 18 neurons had RF sizes too large (6–12°) to fit in the above plots, but were included in the population analysis.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57502-fig4-figsupp1-v2.tif"/></fig></fig-group><p>We also performed PCA analysis on the response patterns of all the neurons. This data-driven analysis also revealed a major difference in curved and rectilinear responses, and its association with the neurons’ locations that either inside or outside the curvature domains (<xref ref-type="fig" rid="fig5">Figure 5</xref>).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>PCA results show different response patterns for neurons inside and outside the curvature domains.</title><p>(<bold>A</bold>) Percentages of the response variance accounted for by the top 10 principle components obtained from the PCA analysis on neurons’ response matrices (n = 1556). Stimulus orientations are sorted according to the responses before the PCA analysis. (<bold>B</bold>) PC1 shows a negative response relationship between cirlces and rectilinear lines, comfirming the ISOI findings. The color of each stimulus represents the sign and strength of the population response to that stimulus correlated to this principle component. PC1 explained 32.5% of the response variance. (<bold>C</bold>) As in B, for PC2, which shows positive contribution from many stimuli except for the circles, PC2 explained 23.7% of the variance. (<bold>D</bold>) All neurons (n = 1556) plotted according to their PC1 and PC2 coordinates. Although had a large overlap, curvature neurons (red) tended to separate from the rectilinear neurons (green). Neurons in gray were those located outside of these two types of domains. (<bold>E</bold>) An example two-photon site in which neurons were labeled according to their PC1 coordinates. Neurons with positive PC1 coordinates (red) were mostly found inside the curvature domain on the top right cornor (with white outline). Neurons with negative PC1 coordinates (yellow and green) were mostly located outside the curvature domain.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57502-fig5-v2.tif"/></fig><p>Although neurons inside the domains exhibited a common preference for curve stimuli, individual neurons showed diverse response properties. <xref ref-type="fig" rid="fig3">Figure 3F</xref> shows the responses of 3 example neurons to 14 typical stimuli. Two neurons were selected from the curvature domain showed in <xref ref-type="fig" rid="fig3">Figure 3C</xref> (red markers). Both neurons were strongly activated by circle stimuli; however, cell 2 was also activated by multiple other stimuli. Cell 3 were selected from a region highly activated by rectilinear stimuli (<xref ref-type="fig" rid="fig4">Figure 4F</xref> arrow) and it showed strong responses to the triangle as well as a 45°-orientated line that resembled an edge of the triangle. Thus, at cellular level, contour-tuning differences exist not only between cells belonging to different functional domains but also between cells within a functional domain. This is further explored in <xref ref-type="fig" rid="fig6">Figure 6</xref>.</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Microarchitectures inside the curvature domains.</title><p>(<bold>A</bold>) Response matrix of an example ‘curve-orientation-preferring neuron’, which showed strong preference for a half circle oriented at 90° and an oval contained a similar curve fragment. (<bold>B</bold>) Orientation tuning curve for curves (half circles). Green dots represent response values to the curves at eight different orientations. Blue line represents fitting curve for the responses. Red circle represents the neurons’ average response level (a single value) for the circle stimuli. Pale-blue and red lines represent ± s.e.m of the responses. (<bold>C, D</bold>) As in A and B, but for a ‘dual-preference neuron’. This neuron showed significant orientation tuning to curves, along with a maximal response for the circle. (<bold>E, F</bold>) As in A-D, but for a ‘circle-preferring neuron’. This neuron responded best to the circles, but did not exhibit curve-orientation tuning. There was no fitting curve for the neuron shown in F due to its weak responses. (<bold>G</bold>) Neurons tended to cluster according to their preferences for circles or curves. Three maps are from three different two-photon imaged locations, and neurons are color coded as shown in the icon: red: circle-preferring neurons; green: curve-orientation-preferring neurons; yellow: dual-preference neurons. Neurons in gray did not pass the circle or curve-orientation preference tests. The neurons in the dotted ovals are further examined in <xref ref-type="fig" rid="fig7">Figure 7</xref>. (<bold>H</bold>) Neurons showed curve-orientation tuning (including curve-orientation-preferring and dual-preference neurons) tended to cluster according to their preferred orientations. The color of the neurons represents their preferred orientation (0–360°). (<bold>I</bold>) The percentages of the three neuron types inside and outside the curvature domains. The color code is the same as that in G. (<bold>J</bold>) The average cell-to-cell distances for circle-preferring neurons (red) and neurons showing curve-orientation tuning with similar preferred orientations (differences &lt; 45°, green and yellow) were shorter than the overall average distance (dotted line) (p&lt;0.001, t-test). Error bar: s.e.m. (<bold>K</bold>) Population averaged fluorescent responses to different contours. For each contour, the response to the optimal orientation was used. The circle-preferring neurons (red) showed gradual increase of response with the length or completeness of the circle, while the curve-orientation-preferring neurons (green) did not. Error bar: s.e.m. (<bold>L</bold>) As in K, but used orientation-averaged responses.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57502-fig6-v2.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>PCA results for neurons inside curvature domains.</title><p>(<bold>A</bold>) Percentages of the response variance accounted for by the top 10 principle components obtained from the PCA analysis of neurons inside curvature domains (n = 722). (<bold>B</bold>) PC1 shows a negative response relationship between cirlces and most of the other stimuli that unlike circles. PC1 explained 32.1% of the response variance. (<bold>C</bold>) As in B, for PC2, which shows a positive contribution from circles and other closed shapes, PC2 explained 23.7% of the variance. (<bold>D</bold>) All neuron in curvature domains are plotted according to their PC1 and PC2 coordinates. Circle-preferring neurons (red) tended to separate from curve-orientation-preferring neruons (green). Dual-preference neurons (yellow) tend to co-located with circle neurons. Neurons in gray were those do not belong to the above three groups.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57502-fig6-figsupp1-v2.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 2.</label><caption><title>Spatial periodicity of curve-orientation subdomain.</title><p>The correlation coefficients of curve-orientation tuning of cell pairs inside the curvature domains, based on their responses to the eight half-circle curves, were calculated, and then grouped based on the distance of the cell pairs at a step of 20 μm. The relationship between the average correlation coefficients of curve-orientation tuning and the distances of the cell pairs were plotted, and shown a trough around 360 μm and a second peak around 720 μm. Red line and shadow represent mean ± s.e.m of the correlation coefficients.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57502-fig6-figsupp2-v2.tif"/></fig></fig-group><p>We identified 1923 neurons in 10 two-photon imaged locations (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>); among them, 788 neurons were in the curvature domains while 1135 neurons were outside of these domains. Despite certain variability due to alignment error, a comparison of the neurons’ calcium responses and their corresponding pixel responses in ISOI maps revealed a general consistency between the two measurements (<xref ref-type="fig" rid="fig4">Figure 4J and K</xref>). <xref ref-type="fig" rid="fig4">Figure 4J and K</xref> also shows that more neurons had a greater response to curved stimuli than to rectilinear ones (more neurons had a positive Y axis value in both figures). Overall, the neurons with a stronger response to curved stimuli tended to have smaller RFs (<xref ref-type="fig" rid="fig4">Figure 4L and M</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1B-E</xref>) and greater surround suppression (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1F and G</xref>), which is consistent with previous findings on the relationship between end-stopping properties and curvature selectivity (<xref ref-type="bibr" rid="bib18">Hubel and Wiesel, 1965</xref>; <xref ref-type="bibr" rid="bib7">Dobbins et al., 1987</xref>; <xref ref-type="bibr" rid="bib34">Ponce et al., 2017</xref>).</p></sec><sec id="s2-3"><title>Microarchitectures of the curvature domains</title><p>Curvature domains imaged with curves and circles in ISOI were generally similar (e.g. <xref ref-type="fig" rid="fig1">Figure 1G and H</xref>). However, individual neurons inside the curvature domain often showed different responses to these two stimuli. <xref ref-type="fig" rid="fig6">Figure 6A,C and E</xref> shows response matrices of three example neurons selected from the curvature domains. Each neuron showed a wide response spectrum to the 73 contour stimuli. To analyze different responses to curves and circles, we labeled neurons that exhibited significant orientation tuning to curves as ‘curve-orientation-preferring neurons’ (e.g. <xref ref-type="fig" rid="fig6">Figure 6A and B</xref>) and those with stronger responses to circles than to curves as ‘circle-preferring neurons’ (e.g. <xref ref-type="fig" rid="fig6">Figure 6E and F</xref>). Some neurons that met both criteria were labeled ‘dual-preference neurons’ (e.g. <xref ref-type="fig" rid="fig6">Figure 6C and D</xref>). Note that after dual-preference neurons were isolated into a separate group, the earlier two groups no longer contained dual-preference neurons. PCA analysis of response patterns for neurons inside curvature domain also showed differences between circle-preferring neurons and curve-orientation-preferring neurons (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). Among the 788 neurons imaged inside the curvature domains, circle-preferring comprised 25.6% (202), dual-preference comprised 14.4% (113), and curve-orientation-preferring neurons comprised 19.2% (151), with the rest not passing the statistical tests. The corresponding proportions of these three groups in the 1135 neurons outside the curvature domains were 7.3% (83), 1.8% (20), and 11.7% (133), respectively (<xref ref-type="fig" rid="fig6">Figure 6I</xref>). As expected, the summed proportion of these three types of neurons was larger inside the curvature domains (59.1%) than the outside (20.8%). The ratio of circle-preferring to curve-orientation-preferring neurons also appeared to be larger inside (1.35) than outside (0.62) the curvature domains.</p><p>When neurons were labeled according to their preferences, there was a tendency of spatial clustering according to their types (<xref ref-type="fig" rid="fig6">Figure 6G</xref>). Moreover, the curve-orientation-preferring neurons further clustered based on their preferred orientations (<xref ref-type="fig" rid="fig6">Figure 6H</xref>), which is consistent with the ISOI results (<xref ref-type="fig" rid="fig1">Figure 1I</xref>, <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2A–D</xref>). The average distances for within-group neuron pairs were shorter than the average distance between two randomly selected neurons (<xref ref-type="fig" rid="fig6">Figure 6J</xref>). Periodicity analysis shows the size of curve-orientation subdomain was around 360 μm (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>).</p><p>Circle-preferring neurons also showed some interesting features. <xref ref-type="fig" rid="fig6">Figure 6K</xref> plots average responses to different contours for circle-preferring neurons (red) and curve-orientation neurons (green). For each stimulus, neurons’ maximum orientation-responses were averaged. For circle-preferring neurons, their responses increased approximately linearly with the length of the circle fragment. This was not the case for curve-orientation neurons. Also, their responses to closed shapes seemed to be proportional to the general similarity between the shape and the circle. As a comparison, <xref ref-type="fig" rid="fig6">Figure 6L</xref> plotted their orientation-averaged responses. The two curves are similar to those in <xref ref-type="fig" rid="fig6">Figure 6K</xref>, except that the green curve becomes lower on the left side, reflecting the modulation of curve orientation on the responses of the curve-orientation-preferring neurons.</p></sec><sec id="s2-4"><title>Diversity of contour tuning for neurons in the curvature domains</title><p>So far, we have shown the common response properties for neurons within the curvature domains and their subdomains. To have a full picture of the neuronal constituents within these functional domains, we examined the diversity of neuronal tunings inside the curvature domains.</p><p>In <xref ref-type="fig" rid="fig7">Figure 7</xref>, we show single-neuron response matrices from three example two-photon sites, including a circle-preferring site (A), a curvature-orientation-preferring site (B) and a rectilinear-preferring site (C). The location of these sites can be found in <xref ref-type="fig" rid="fig6">Figure 6G</xref>. For each site, 10 example neurons are shown. For the circle-preferring neurons (A), they prefer circles much better than the half circles. Their responses patterns also exhibited certain diversity, including some neurons responded modestly to the 90°-angle stimuli (cell 8–10) while others did not. They could respond well (cells 1, 2, 3, 5, 7, 9) or modestly (cells 4, 6, 8, 10) to hexagons. For cells in curve-orientation-preferring site (<xref ref-type="fig" rid="fig7">Figure 7B</xref>), response diversity appeared even larger. Different neurons showed strong selectivity to the trefoil shapes (cells 1, 4), or particular 90° angles (cell 3). Different degrees of circle-preference were also apparent among these neighboring neurons.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Single-neuron responses in three types of cortical sites.</title><p>(<bold>A</bold>) Response matrices of 10 neighboring neurons in a circle-preferring two--photon site (also shown in <xref ref-type="fig" rid="fig6">Figure 6G</xref>). Each matrix is normalized to its maximal and minimal responses. (<bold>B</bold>) As in A, but for a curve-orientation-preferring site. (<bold>C</bold>) As in A and B, but for a rectilinear site.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57502-fig7-v2.tif"/></fig><p>The rectilinear site shown in <xref ref-type="fig" rid="fig7">Figure 7C</xref> was also located in an orientation domain that preferring the 45° orientation. Many cells responded well to the triangles and the 45°-oriented lines. Some cells also responded to the 45°-orientated ovals and flat curves, likely due to their general orientation appearance. However, neighboring neurons could respond strongly to one of these stimuli (e.g. cell 1 to oval, cells 2 and 3 to triangle, cell 4 to line) but much weaker to others. Some neurons (e.g. cell 9) exhibited a wider range of preferred shapes than their neighbors.</p><p>Thus, for neighboring neurons, although their general shape preferences were similar, which constitute the basis of the ISOI signals, their contour response patterns still vary from cell to cell, and some of the differences were substantial. The degrees of such diversity also seem to be related to the types of these sites in V4.</p><p>Shape-related responses of neurons in curvature domains, rectilinear domains, and those outside of these two were summarized in <xref ref-type="fig" rid="fig8">Figure 8</xref>. In the orientation-sorted average response matrices, curvature neurons showed much higher response amplitudes, and larger differences between curved and rectilinear responses, than the other two types of neurons. Nevertheless, these neurons also responded to rectilinear stimuli, for example the triangles, at about half of the response amplitude. Interestingly, neurons in rectilinear domains did not show prominent differences in their responses to rectilinear and curved stimuli. This is also consistent with the weak rectilinear domains in ISOI imaging (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). <xref ref-type="fig" rid="fig8">Figure 8D</xref> further illustrates the differences among three regions, in which the size and color of the shapes are proportional to the response magnitudes of the first rows in the response matrices in A–C.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>A summary of neurons’ response patterns in different V4 regions.</title><p>(<bold>A–C</bold>) Average response matrices (without normalization) from neurons in the curvature domains (<bold>A</bold>), rectilinear domains (<bold>B</bold>) and those outside of these two types of domains (<bold>C</bold>). Responses are orientation-sorted before averaging. (<bold>D</bold>) An illustration of the contour-preferences for neurons in the three regions, calculated based on the optimal-orientation responses in A–C (the top rows). The size and color of the shapes represent the strength of the corresponding responses. For clarity, not all stimulus icons were drawn.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57502-fig8-v2.tif"/></fig></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Using two complementary imaging methods, we found a novel functional structure in V4, but not in V1 or V2, for curved contour processing. The size of these domains (518 µm) was similar to that of the orientation domains in this area; moreover, they tended to occupy regions outside the orientation domains. Within these domains, neurons preferring different curve features (e.g. curve orientation) further clustered into smaller subdomains. Interestingly, subdomains were also found in color- (<xref ref-type="bibr" rid="bib23">Li et al., 2014</xref>; <xref ref-type="bibr" rid="bib14">Ghose and Ts'o, 2017</xref>; <xref ref-type="bibr" rid="bib26">Liu et al., 2020</xref>), orientation- (<xref ref-type="bibr" rid="bib13">Ghose and Ts'o, 1997</xref>; <xref ref-type="bibr" rid="bib40">Tanigawa et al., 2010</xref>), and direction- (<xref ref-type="bibr" rid="bib22">Li et al., 2013</xref>) specific regions in V4. These nested functional architectures are similar to that of category domains in IT, where large category domains (animate vs. inanimate) contain subcategory domains (e.g. for face and body parts) (<xref ref-type="bibr" rid="bib25">Liu et al., 2013</xref>; <xref ref-type="bibr" rid="bib15">Grill-Spector and Weiner, 2014</xref>). Curvature domains are probably vertical columns. However, two-photon imaging revealed considerable complexity underlying these functional organizations. First, individual neurons usually responded to a wide range of stimuli with different levels of response amplitudes. Thus, curvature domains are not ‘curvature-only’ domains. Second, neurons inside the curvature domains and those outside do not completely differ in their stimulus coverage, although their optimal stimuli are usually different. Third, for neighboring neurons within a functional domain, although they showed common shape preferences, many of them exhibited different individual preferences, some of which were substantial. Thus, the functional maps we observed are best understood as a certain orderness of the complexity of shape responses in V4 population.</p><p>Consistent with previous findings (<xref ref-type="bibr" rid="bib31">Pasupathy and Connor, 1999</xref>; <xref ref-type="bibr" rid="bib32">Pasupathy and Connor, 2001</xref>; <xref ref-type="bibr" rid="bib33">Pasupathy and Connor, 2002</xref>; <xref ref-type="bibr" rid="bib46">Yue et al., 2014</xref>), we confirmed that V4 plays a key functional role in the representation and processing of curvature information. A majority of V4 neurons have been reported to exhibit complex multi-dimensional response patterns to shape stimuli (<xref ref-type="bibr" rid="bib11">Gallant et al., 1993</xref>). Recent studies in V4 (<xref ref-type="bibr" rid="bib1">Bashivan et al., 2019</xref>) and IT (<xref ref-type="bibr" rid="bib35">Ponce et al., 2019</xref>) have shown that individual neurons in these areas can be best activated by non-natural synthetic patterns that are much more complex than those traditionally tested. Thus, classifying neurons into functionally separate groups based on their contour responses is often difficult. This is especially true when the testing stimulus set is limited (as in the present work). However, intrinsic functional structures in an area are suggestive of particular feature dimensions been emphasized in this area. We observed that V4 contains clear maps for curvature processing, which suggests that curvature is a unique feature dimension in this area, not only in single neurons but also as a populational feature. Further, both curved and rectilinear contours formed functional structures (curvature and orientation domains) with each functional structure containing nested subdomains for further detailed tuning (<xref ref-type="fig" rid="fig6">Figure 6G and H</xref>). This functional organization could underlie the parallel processing of curved and straight contours (<xref ref-type="bibr" rid="bib19">Ito, 2012</xref>) and the different underlying pooling mechanisms (<xref ref-type="bibr" rid="bib29">Nandy et al., 2013</xref>).</p><p>In human fMRI studies, V4 is more activated by circular stimulus than by curves (<xref ref-type="bibr" rid="bib8">Dumoulin and Hess, 2007</xref>) or parallel patterns (<xref ref-type="bibr" rid="bib44">Wilkinson et al., 2000</xref>). Using two-photon imaging, we observed many circle-preferring neurons (<xref ref-type="fig" rid="fig6">Figure 6I</xref>). However, these circle-preferring neurons also showed good responses to other non-circle stimuli (<xref ref-type="fig" rid="fig6">Figure 6E</xref>). Many curve-orientation-preferring neurons also responded best to circles (<xref ref-type="fig" rid="fig6">Figure 6C</xref>). This indicates that these circle-preferring neurons do not constitute a functionally distinct subdivision of V4.</p><p>Early single-cell recordings have suggested that V4 neurons may cluster based on their color or orientation preferences (e.g. <xref ref-type="bibr" rid="bib39">Tanaka et al., 1986</xref>). Subsequent optical imaging studies confirmed these functional structures (<xref ref-type="bibr" rid="bib13">Ghose and Ts'o, 1997</xref>; <xref ref-type="bibr" rid="bib40">Tanigawa et al., 2010</xref>; <xref ref-type="bibr" rid="bib23">Li et al., 2014</xref>). For shape-responsive neurons, clustering according to their selectivity to complex patterns has also been suggested (<xref ref-type="bibr" rid="bib39">Tanaka et al., 1986</xref>; <xref ref-type="bibr" rid="bib11">Gallant et al., 1993</xref>; <xref ref-type="bibr" rid="bib12">Gallant et al., 1996</xref>), but studies have also shown that neurons selective to complex shape features are mixed with those selective to simple features such as orientations (<xref ref-type="bibr" rid="bib21">Kobatake and Tanaka, 1994</xref>). Our results confirmed that, although neurons tended to cluster according to their common response preferences, substantial diversity in contour tuning still exist among these clustered neurons. This heterogeneity may make these functional organizations less detectable in electrophysiological studies, for example, compared to the orientation columns in V1.</p><p>In a recent two-photon calcium imaging study posted on bioRxiv, <xref ref-type="bibr" rid="bib20">Jiang et al., 2019</xref> imaged cellular responses in parafoveal V4 representations (~1° eccentricity from the fovea) to a large set of natural and artificial stimuli. Their findings suggested a separate coding for orientation, curve and angle. However, due to the spatial limitation of the two-photon technique, domain features and distributions are not available. With ISOI over a large imaging window (16–20 mm diameter), we observed the distribution of the curvature domains and their spatial relationships with other known functional maps (<xref ref-type="fig" rid="fig2">Figure 2D</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). We found that curvature domains existed in the entire exposed V4 surface (0–10° eccentricity from the fovea). Further, the ISOI maps of the curvature and orientation domains were comparable (<xref ref-type="fig" rid="fig2">Figure 2F</xref>), which suggests that they had a comparable degree of clustering.</p><p>In another study also submitted to eLife, <xref ref-type="bibr" rid="bib17">Hu et al., 2020</xref> investigated curvature organization in area V4 with ISOI. Despite a different stimulus protocol they used, they observed curvature domains similar to what we observed. The major ISOI findings are similar between these two studies. With the power of two-photon imaging, we not only confirmed these ISOI findings but also revealed neuronal properties underlying these domains, including cellular-level preferences and the tuning diversity of neurons within these functional domains. Thus, <xref ref-type="bibr" rid="bib17">Hu et al., 2020</xref> and this study both revealed the overall features of curvature domains in V4, while <xref ref-type="bibr" rid="bib20">Jiang et al., 2019</xref> and this study both revealed cellular-level features of the functional domains. Only this study directly linked functional domain properties with their underlining neural responses.</p><p>Curve-preferring neurons have been reported in V1, V2, and V4 (<xref ref-type="bibr" rid="bib16">Hegdé and Van Essen, 2007</xref>; <xref ref-type="bibr" rid="bib34">Ponce et al., 2017</xref>). However, we did not observe functional structures for curves in V1 and V2, which is consistent with a previous study (<xref ref-type="bibr" rid="bib46">Yue et al., 2014</xref>). Curvature domains emerge in V4 (<xref ref-type="bibr" rid="bib46">Yue et al., 2014</xref>; this study) and remain present in IT (<xref ref-type="bibr" rid="bib46">Yue et al., 2014</xref>; <xref ref-type="bibr" rid="bib38">Srihasam et al., 2014</xref>). Therefore, V4 contains both basic orientation (similar to V1 and V2) and curvature maps (similar to IT), which indicates its intermediate-stage role in the shape processing hierarchy. There is a progressive change in multiple feature dimensions along this hierarchy, for example receptive field size, response linearity, and degree of modulation by top-down controls. Functional architectures for shape processing form an independent dimension, which could contribute to a better understanding of the neural mechanisms for shape processing. Moreover, the consistency between functional architectures and shape processing levels highlights the importance of functional organization in the brain. This study provides another measurement type (domain-level activation) for studies on shape processing in addition to the cellular- and voxel-level measurements. Interesting topics, such as the functional importance of clustering, the plasticity of such clustering and its contribution to cognition, can be further explored.</p><p>We have shown that curvature neurons had smaller RFs than those of non-curvature neurons (<xref ref-type="fig" rid="fig4">Figure 4L and M</xref>). We further analyzed and showed that curvature neurons had stronger surround suppression (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1F and G</xref>). Thus, consistent with previous findings, curvature neurons did exhibit end-stopping properties. However, curvature neurons showed additional curve-specific preferences, including curve-orientation tuning, preference for curves over similarly-sized angle stimuli, etc. For circle-preferring neurons, they prefer circles (larger) than the half-circles (smaller). These additional features suggest that curvature neurons were not simple end-stopping neurons, although they exhibited end-stopping properties.</p><p>Curvature domains are also unlikely the suppression-domains (S-domains) in V4 revealed by comparing activations to small and large patches of gratings (<xref ref-type="bibr" rid="bib13">Ghose and Ts'o, 1997</xref>). In our study, curvature domains were revealed in difference maps, including: circles vs. triangles (<xref ref-type="fig" rid="fig1">Figure 1D</xref>), circles vs. bars (<xref ref-type="fig" rid="fig1">Figure 1G</xref>), curves vs. bars (<xref ref-type="fig" rid="fig1">Figure 1H</xref>), and curves vs. angles (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2L</xref>). The two stimuli in each pair had similar sizes, and thus had similar surround suppression effects. Their contrast pattern in the difference maps could not be due to differences in suppression. The stimuli on the two sides also had balanced orientations, plus their maps had little overlap with the orientation maps (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). The only consistent contrasts in these pairs of stimuli was the curvature feature. Thus, the curvature domains we found are unlikely related to suppression and orientation domains.</p><p>Our two-photon results have limitations in terms of the stimulus set, anesthetized preparation, and calcium signals. We only tested 19 simple contour shapes, mostly with four orientations. Considering the complexity of single-cell response patterns we observed, the best-driven stimuli we identified may not be the optimal ones for the neurons. Although a more in-depth analysis of the current data set can still improve our estimation of the optimal stimuli, new stimuli, or experimental approaches seem to be necessary. A recently reported deep-learning-network approach successfully found optimal stimuli for V4 neurons (<xref ref-type="bibr" rid="bib1">Bashivan et al., 2019</xref>). The optimal stimuli they found were usually complex patterns and unlike the contour shapes previously tested. However, these optimal stimulus patterns also contained specific curvature features similar to the optimal ones obtained with a parametric stimulus set like ours. Thus, it is likely that the best-driven contour features we obtained should also be represented in the actual optimal stimuli for the neurons we measured. Our ISOI tests also provided a practical way in designing and narrowing down the stimulus set for the subsequent targeted two-photon imaging.</p><p>The primary new finding of this study is the functional architecture for curvature processing in V4. The curvature domain likely shares similar formational rules and functional significances with other functional architectures previously discovered (<xref ref-type="bibr" rid="bib28">Mountcastle, 1997</xref>; <xref ref-type="bibr" rid="bib4">Chklovskii and Koulakov, 2004</xref>). The significance of this particular structure is based on several observations described in Results: First, the curvature domains were found in V4 but not in V1 or V2, although curvature neurons were also found in the latter two areas (<xref ref-type="bibr" rid="bib16">Hegdé and Van Essen, 2007</xref>; <xref ref-type="bibr" rid="bib34">Ponce et al., 2017</xref>). Second, the domain strength was higher for V4 curvature domains than those for angles. These two factors are consistent with the notion that V4 plays an important role in curvature processing. Third, features of these domains are helpful in understanding the underlying neural processes. For example, the relative separation of the curvature and rectilinear domains suggests a parallel processing of these two contour features. The existence of the circle and curve-orientation sub-domains within the curvature domains suggests that there are different processes for curvatures. Finally, the existence of curvature domains also provides an efficient way to study curvature neurons in V4, for example, by targeted recording, imaging, or tracer labeling.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th>Reagent type <break/>(species) or resource</th><th>Designation</th><th>Source or reference</th><th>Identifiers</th><th>Additional information</th></tr></thead><tbody><tr><td>Strain, strain background (Macaque, male)</td><td>Macaca mulatta</td><td>Suzhou Xishan Zhongke animal Company, Ltd <break/>Hubei Topgene Biotechnology Co.,Ltd</td><td/><td><ext-link ext-link-type="uri" xlink:href="http://xsdw.bioon.com.cn/">http://xsdw.bioon.com.cn/</ext-link> <ext-link ext-link-type="uri" xlink:href="http://topgenebio.com/">http://topgenebio.com/</ext-link></td></tr><tr><td>Strain, strain background (Macaque, male)</td><td>Macaca fascicularis</td><td>Beijing Inst. of Xieerxin Bology Resource</td><td/><td><ext-link ext-link-type="uri" xlink:href="http://www.xexbio.com/">http://www.xexbio.com/</ext-link></td></tr><tr><td>Recombinant DNA reagent</td><td>AAV1.Syn.GCaMP6S.WPRE.SV40</td><td>Addgene</td><td>v25497</td><td/></tr><tr><td>Recombinant DNA reagent</td><td>AAV9.Syn.GCaMP6S.WPRE.SV40</td><td>Addgene</td><td>CS1282</td><td/></tr><tr><td>Software, algorithm</td><td>MATALAB R2017b</td><td>MathWorks</td><td/><td><ext-link ext-link-type="uri" xlink:href="https://www.mathworks.com">https://www.mathworks.com</ext-link></td></tr><tr><td>Software, algorithm</td><td>Codes for ISOI data analysis</td><td>This paper</td><td/><td><ext-link ext-link-type="uri" xlink:href="https://osf.io/qydj5/">https://osf.io/qydj5/</ext-link></td></tr><tr><td>Software, algorithm</td><td>Codes for 2P data analysis</td><td>This paper</td><td/><td><ext-link ext-link-type="uri" xlink:href="https://osf.io/qydj5/">https://osf.io/qydj5/</ext-link></td></tr></tbody></table></table-wrap><p>A total of seven hemispheres (i.e. cases) from six adult male macaque monkeys (five <italic>Macaca mulatta</italic>, one <italic>Macaca fascicularis</italic>) were imaged. ISOI were performed on all seven cases, two-photon imaging were performed on two cases (Case 3 and Case 4). These monkeys also participated in other studies. All procedures were performed in accordance with the National Institutes of Health Guidelines and were approved by the Institutional Animal Care and Use Committee of the Beijing Normal University (protocol number: IACUC(BNU)-NKCNL2016-06).</p><sec id="s4-1"><title>Surgery procedures</title><p>Animals were sedated with ketamine (10 mg/kg) or Zoletil (tiletamine HCl and zolazepam HCl, 4 mg/kg) and transferred to the lab. They were artificially ventilated on a stereotaxic and anesthetized with isoflurane (1.5–2.5%) during surgery. A 22–24 mm (diameter) circular craniotomy and durotomy were performed (center location, 30–37 mm from midline, 15–24 mm from posterior bone ridge) to expose visual areas V1, V2, and V4 (illustrated in <xref ref-type="fig" rid="fig1">Figure 1A</xref>). ISOI was performed right after the surgery (see below). Then, one of two types of protocols was chosen: For cases only used for ISOI, we implanted an optical chamber and recovered the animal. For cases used for two-photon calcium imaging, we injected virus into the visual cortex, placed back the bone and sealed the craniotomy (described below). After 1.5 months, we reopen the craniotomy and implanted an optical chamber for the following weekly based two-photon imaging experiments. The same type of chronic chamber was used for ISOI and two-photon imaging (<xref ref-type="bibr" rid="bib24">Li et al., 2017</xref>). The inside diameter of the chamber was 13–16 mm, thickness of the glass is 0.18 mm. Case 2 was only imaged once and then used for other studies thus no chamber was implanted.</p></sec><sec id="s4-2"><title>Intrinsic signal optical imaging (ISOI)</title><p>ISOI were performed either right after the surgery (without a chamber), or on a weekly-base after a chamber was implanted. Imaging usually lasted for 8 hr. Right before the imaging, anesthesia was switched from isoflurane to a mixture of propofol (induction 2 mg/kg, maintenance 2 mg/kg/hr) and sufentanil (induction 0.15 μg/kg, maintenance: 0.15 μg/kg/hr) (in four cases), or to Zoletil (tiletamine HCl and zolazepam HCl, induction 4 mg/kg, maintenance 1.25 mg/kg/hr, in three cases). The monkeys were immobilized with vecuronium bromide (induction 0.25 mg/kg, maintenance 0.05 mg/kg/hr) to prevent eye movements. Anesthetic depth was assessed continuously via monitoring the electrocardiogram, end-tidal CO<sub>2</sub>, blood oximetry, and body temperature. Eyes were dilated (atropine sulfate, 0.5 mg/ml) and fit with contact lenses of appropriate curvatures to focus on a stimulus screen 57 cm from the eyes.</p><p>Images of reflectance change (intrinsic hemodynamic signals) corresponding to local cortical activity were acquired (Imager 3001, Optical Imaging Inc) with 632 nm illumination. Frame size was 540 × 654 pixels, representing either 15.5 × 19 mm or 18 × 22 mm of imaged area, depending on the lenses chosen. For each trial, imaging started 0.5 s before the stimulus onset and collected at 4 Hz frame rate. Each visual stimulus was presented for 3.5 s. The total imaging time for each trial was 4 s, during which 16 frames were imaged. Interstimulus intervals were at least 6 s. Stimulus conditions were displayed in a randomized order.</p></sec><sec id="s4-3"><title>Virus injection</title><p>Virus injection and two-photon imaging procedures were similar to those described in <xref ref-type="bibr" rid="bib24">Li et al., 2017</xref>. In two cases (Case 3 and Case 4), we injected 500 nL AAV9.Syn.GCaMP6S.WPRE.SV40 (CS1282, titer 3.34e13 GC/ml, Addgene), or AAV1.Syn.GCaMP6S.WPRE.SV40 (v25497, titer 2.5e13 GC/ml, Addgene) into 10–15 cortical locations at a depth of 500 μm. After virus injection, cortex was covered with a piece of artificial dura. And the remaining dura was covered and glued to the top of the artificial dura with medical adhesive (Beijing Compont medical devices Co. Ltd). The original bone was placed back, secured with titanium lugs and bone wax in the gap. The scalp was sutured. A second surgery was performed 1.5 months later, in which the old craniotomy was reopened and an optical chamber was implanted for the following ISOI and two-photon imaging.</p></sec><sec id="s4-4"><title>Two-photon imaging</title><p>Two-photon calcium imaging was performed on a weekly-base after the chamber implanting. Animal anesthesia and preparation were the same as those in the ISOI experiments. Two-photon microscope was a Brucker Ultima IV Extended Reach (Bruker Nano Inc). Laser was generated with a Chameleon Ultra II (Coherent Inc). The excitation wavelength of the laser was set at 980 nm. Scanning frame rate was 1.3 Hz in a galvo scanning mode. Under a 16X objective (0.8 N.A., Nikon), 515 × 512 pixel images were collected, representing a 830 × 830 μm cortical surface. Imaging was continuous and the beginning of each stimulus presentation was synchronized with the beginning of a frame scanning.</p><p>As the microscope was vertical, we rotated the stereotaxic and the animal for ~45° so that the chamber plane was perpendicular to the laser beam. We imaged 10 cortical locations in the two virus-injected chambers (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A and E</xref>). Images were normally collected at a depth between 210 and 350 μm from the cortical surface. In six locations, we imaged at two depths, a depth around 230 μm and a depth around 310 μm (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1D and H</xref>). During the imaging session, slow drifts of cortex in the imaging window was observed. The drift was normally less than 50 μm in the X-Y plane and less than 150 μm along the Z-axis in a course of 6–8 hr. We closely monitored the cell features during the imaging and adjusted position of the focal plane accordingly. Drifts in the X-Y plane were further corrected in offline data analysis (described below). In addition, population receptive field locations were re-plotted every 1–1.5 hr in order to check the stableness of the eye positions. In half of the experiments, some eye drift (1–2°) was detected during the imaging session. If drift was larger than 1°, we repeated the last stimulus run at the new receptive field position. If the drift was smaller than 1°, we adjusted the stimulus location for the following stimuli and continued the imaging. Replication of two-photon imaging of the same neuron population were tried but was not systematically tested. A general replication of the population-level responses was qualitatively observed.</p></sec><sec id="s4-5"><title>Visual stimuli for ISOI</title><p>Visual stimuli were generated using ViSaGe (Cambridge Research Systems Ltd.) and presented on a CRT monitor positioned 57 cm from the eyes. The stimulus screen was gamma corrected and worked at 100 Hz refreshing rate. We compared contour preference maps obtained with monocular and binocular conditions in Case 1 (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2M and N</xref>), as well as two monocular conditions in Case 4 and did not find obvious differences. Since ISOI signal is normally stronger in binocular condition, all but one case (Case 5) were imaged in binocular conditions. For orientation and color preference maps, full-screen drifting sinewave gratings were used. The mean luminance was 28.9 cd/m<sup>2</sup>. Gratings of two SF (0.25 and 1 c/deg, except for Case 6 in which only 0.25 c/deg were tested) and two (45° and 135°, for Cases 5 and 6) or four orientations (0°, 45°, 90°, and 135°, for other five cases) were tested. Gratings were drifting at 4°/s along a random direction perpendicular to its orientation and were presented in a random order. The initial phases of the gratings were also randomly selected.</p><p>For contour shape preference maps (e.g. <xref ref-type="fig" rid="fig1">Figure 1D–L</xref>), drifting contour patterns were used. Each contour element was ~2.5° and placed in a 3 × 3° grid (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). The white contour lines was 0.2° in width and had a luminance of 111.2 cd/m<sup>2</sup>. The dark background had a luminance of 20.6 cd/m<sup>2</sup>. For each trial, a contour pattern was presented and drifted at one out of four or eight directions for 3.5 s at a speed of 4°/s. Interstimulus intervals were 6 s, during which a gray screen (20.6 cd/m<sup>2</sup>) was presented. The initial phase (i.e. relative position) of the pattern was random. Each stimulus was repeated for 25–50 times. The essential stimuli (e.g. circle, triangle, gratings) was obtained in all seven cases (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>), new stimuli were added in later cases and are described in the Results whenever is necessary.</p></sec><sec id="s4-6"><title>Visual stimuli for two-photon imaging</title><p>Visual stimuli used for two-photon imaging were generated in a similar way as those in the ISOI imaging and presented on a 21-inch LCD monitor (Dell E1913Sf) positioned 57 cm from the eyes. The stimulus screen was gamma corrected and worked at 60 Hz refreshing rate. All stimuli were bright stimulus (80.8 cd/m<sup>2</sup>) on a gray (13.2 cd/m<sup>2</sup>) background and presented monocularly to the left eye.</p><p>Population RF location was first mapped manually with a 2–3° circular patch of square-wave gratings, during which cortical fluorescent response was monitored. Then the RF were systematically mapped at the potential region with a single 2–3° patch of stimulus presented on a grid of 5 × 5 locations. Each position was tested with a square-wave grating, a random dot patch, and a circle, each moved at one out of four directions (45°, 135°, 225°, 315°) at 4°/s speed. Each stimulus was presented for 1.5 s. Interstimulus interval was 0.5 s. Population RF center (normally 5–7 degrees eccentricity) was then analyzed online based on cortical responses to these stimuli.</p><p>To obtain detailed RF size information, we presented circular patches of square-wave gratings (SF = 1 c/degrees, TF = 4 c/s, duty cycle = 0.2) of six different sizes (0.5°, 1°, 2°, 4°, 8°, 12°) at the population RF center mapped before. Each stimulus was drifted along one of eight directions, and presented for 2 s with a 3 s interval. Each stimulus was repeated for seven times. From these stimuli, a size-tuning curve was calculated, which normally peaked at patch sizes of 2°–3.5°. Population RF size was then defined as twice of this size (i.e. 4°–7°).</p><p>To test the contour-shape preferences of the neurons, we presented single contour elements in the population RF. Single contour element was the same as those used in the ISOI experiments. The size of the contour was adjusted to 40% of the population RF. Each stimulus was presented for 2 s, during which it first appeared in the center of the population RF and drifted along one of eight directions (randomly selected). After it moved to the edge of a virtual window equal to the population RF diameter, it disappeared and reappeared in the opposite side of the window, and continue its motion along the same direction (illustrated in <xref ref-type="video" rid="fig3video1">Figure 3—video 1</xref>). The speed of the contour movement was adjusted to (half of the diameter of the population RF)/s. The interstimulus intervals were 3 s. Each stimulus was usually repeated for 10–15 times. As shown in <xref ref-type="fig" rid="fig6">Figures 6A</xref>, 19 different contour shapes were used, most of them was presented in four orientations, two stimuli were presented in two orientations (square, hexagon), and one stimulus (half circle) was presented in eight orientations. This made up 73 different stimulus conditions. We also included four identical circles instead of 1 to be comparable to other stimuli’s four orientations. The final stimulus matrix contained 76 stimuli.</p></sec><sec id="s4-7"><title>ISOI data analysis</title><p>ISOI data analysis was performed using MatLab 2017 (The MathWorks, Natick, MA). We first obtained ΔR/R response to each stimulus using following formula ΔR/R=(R<sub>8-16</sub> - R<sub>1-4</sub>)/R<sub>1-4</sub>, in whichR<sub>8-16</sub> is the average of frames 8–16, R<sub>1-4</sub> is the average of frames 1–4. The ΔR/R frames for each trial were then used for following analysis.</p><p>We used a pattern classifier (support vector machine, SVM) for calculating contrast maps between ΔR/R frames of two stimulus conditions. Compared with simple subtraction maps, SVM weight map achieved a higher signal-noise ratio by suppressing blood vessel noise and low-frequency noises (<xref ref-type="bibr" rid="bib45">Xiao et al., 2008</xref>; <xref ref-type="bibr" rid="bib3">Chen et al., 2016</xref>). The Matlab SVM program was provided by Chih-Jen Lin (LIBLINEAR: A Library for Large Linear Classification, 2008; available at <ext-link ext-link-type="uri" xlink:href="https://www.csie.ntu.edu.tw/~cjlin/liblinear/">https://www.csie.ntu.edu.tw/~cjlin/liblinear/</ext-link>).</p><p>For each SVM map (e.g. <xref ref-type="fig" rid="fig1">Figure 1D–L</xref>), it was first Gaussian low-pass filtered (size = 5 pixels, std = 1), then clipped at 0 ± 8 SD for display, in which SD was the standard deviation of the background pixels values (blood vessel pixels and outside-chamber pixels, determined based on the blood vessel maps like the example shown in <xref ref-type="fig" rid="fig1">Figure 1B</xref>). For display purposes, the original map size (540 × 654 pixels) was cropped to 540 × 540 pixels by trimming off some background regions on the two edges.</p><p>To separate domain region from non-domain regions (e.g. <xref ref-type="fig" rid="fig2">Figure 2D</xref>), we used 0 ± 2 SD as the threshold levels and discarded resulting regions containing less than 50 pixels. Curvature domains were identified as the dark regions in the circle vs. triangle maps. Domain coverage in <xref ref-type="fig" rid="fig2">Figure 2D</xref> and the neuron classification in <xref ref-type="fig" rid="fig5">Figures 5</xref>–<xref ref-type="fig" rid="fig8">8</xref> were all based on this method. Only in estimating domain sizes (<xref ref-type="fig" rid="fig2">Figure 2E</xref>), we used a watershed method in order to deal with the ‘connected domain’ problem (see below). Orientation domains were identified as both the dark and white regions in the orientation maps. Color domains were identified as both the dark and white regions in the color vs. luminance maps. To compare with two-photon results (e.g. <xref ref-type="fig" rid="fig4">Figure 4J and K</xref>), regions in the SVM map that aligned with the two-photon imaging area were extracted and resized (bicubic interpolation) to 512 × 512 pixels for further analysis.</p><p>To estimate domain sizes (e.g. <xref ref-type="fig" rid="fig2">Figure 2E</xref>), neighboring domains were often connected and we separated them using a watershed algorithm. First, the image values were reversed to make the negative domains positive. Then we located the strongest response pixel, and cut out a 31 × 31 (0.9 × 0.9 mm) pixel region around this pixel. For all pixels in this square that had a value lower than 0+2SD, they were set as 0+2SD. The response pattern was fitted with a two-dimentional Gaussian. An oval was obtained from the two-dimentional Gaussian with a threshold so that the oval had half of its pixels valued larger than 0+2SD (and the other half pixel all had values of 0+2SD). This oval was taken as the representation of this curvature domain. Before search for the next domain, the pixels in the oval region in the original map was set as 0+2SD. The searching stopped until no more pixels had value larger than 0+2SD. In addition, small domains had fewer than 75 pixels were not included in the size analysis. Individual domain size was described as the diameter of an equivalent disk. Domain sizes were then averaged according to map types and cases. To measure the map strength of a functional map (e.g. <xref ref-type="fig" rid="fig2">Figure 2F</xref>), we calculated the differences of average pixel values in white and dark domains in the subtraction map, using the domain masks described above. For example, the map strength of a 45° vs. 135° orientation map was calculated as the subtraction between the average pixel values of 135° domains and the average pixel values of 45° domains in the 45°−135° subtraction map.</p></sec><sec id="s4-8"><title>Two-photon data analysis</title><p>Two-photon data analysis was performed using MatLab 2017 (The MathWorks, Natick, MA). Image alignment and cell identification algorithms were modified from those used in <xref ref-type="bibr" rid="bib24">Li et al., 2017</xref>. To correct slow cortex drifts and biological movements (likely due to heart pulsation and artificial ventilation) within the X-Y plane (normally less than 20 pixels during the whole imaging session, typically five pixels), we first obtained a frame template by averaging 1000 frames from a chosen session, then all frames of that experiment, and frames from other days of the same cortical layer, were aligned to this template using a cross-correlation method.</p><p>Fluorescent images (e.g. <xref ref-type="fig" rid="fig3">Figure 3C</xref>) were obtained by averaging all collected two-photon images during the imaging session, including the baseline and response images. Response images (e.g. <xref ref-type="fig" rid="fig3">Figure 3D and E</xref>) were obtained by subtracting the baseline image (average of the two frames before the stimulus onset) from the response image (average of the second and third frames after the stimulus onset).</p><p>Cell bodies were first identified based on their responses to each visual stimulus. We first averaged all repeats for a stimulus, then obtained a subtraction image by subtracting the baseline image (average of 2 immediate pre-stimulus frames) from the response image (average of frames 2 and 3 after the stimulus onset). This subtraction image was then filtered using two separate Gaussian filters: G1 (size = 7 pixels, std = 1.5) and G2 (size = 15 pixels, std = 7). Then the subtraction map of G1-G2 was used for cell extraction. The cells extracted in this way had smooth edges and filled cell-body. For each cell, the cell body identified from its best-responsive stimulus was used as its cell body and was used to calculate its responses in all the other stimuli.</p><p>A cell was identified if more than 30 connected pixels had values larger than mean+2.75SD, in which SD is the standard deviation of the pixel values of the whole filtered subtraction image. After cell locations were determined, we calculated fluorescence responses for cells to each stimulus using following formula: ΔF/F0=(F-F0)/F0, in which F is the average pixel value covered by the cell in the response image, and F0 is average pixel values in the baseline image. A cell was included for the following analysis if any of its stimulus responses (ΔF/F0) was larger than 0.3 for the stimuli tested.</p></sec><sec id="s4-9"><title>Orientation tuning to curves</title><p>A cell was identified as a curve-orientation-preferred cell (e.g. <xref ref-type="fig" rid="fig6">Figure 6A–D</xref>) if its responses to eight curve orientations passed the Rayleigh test for circular uniformity (<xref ref-type="bibr" rid="bib9">Fisher, 1993</xref>) at a significant level of p&lt;0.05. Then we fitted the responses with a modified von Mises function (<xref ref-type="bibr" rid="bib27">Mardia, 1972</xref>):<disp-formula id="equ1"><mml:math id="m1"><mml:mi mathvariant="normal">F</mml:mi><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="normal">a</mml:mi><mml:mn>0</mml:mn><mml:mo>+</mml:mo><mml:mi mathvariant="normal">b</mml:mi><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mn>1</mml:mn><mml:mo>×</mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mo>⁡</mml:mo><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>-</mml:mo><mml:mi>θ</mml:mi><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mo>⁡</mml:mo><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>-</mml:mo><mml:mi>θ</mml:mi><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>180</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></disp-formula>where θ is the orientation of curve (0–360°); θp is the preferred orientation; a0 is the baseline offset; (b1, b2) and (c1, c2) determine the amplitude and shape of the tuning curve, respectively. Fitting parameters were obtained with a least-square nonlinear regression method (nlinfit in Matlab, Mathworks). Goodness of fit (R<sup>2</sup>) values were &gt;0.7 for all neurons which have significant orientation tuning to curve (n = 417). Cells’ preferred orientations were then calculated from the fitting curve (<xref ref-type="fig" rid="fig6">Figure 6B</xref>).</p></sec><sec id="s4-10"><title>Circle preference</title><p>A cell was determined as circle-preferred cell if it met following two criteria: 1. The cell’s response was significantly modulated by contour types (bar, 90°-angle, triangle, curve, each was represented by its optimal oriented stimulus, and circle, p&lt;0.05, one-way ANOVA) and its maximum response was to the circle. 2. The cell’s response to the circle was significantly larger than its response to the curve of its preferred orientation (p&lt;0.05, paired t-test).</p></sec><sec id="s4-11"><title>Shape preference</title><p>In calculation of the preferential responses to two contours (e.g. <xref ref-type="fig" rid="fig4">Figure 4J and K</xref>), we first normalized the cell’s ΔF/F0 responses to the whole stimulus set to 0–1, then the differences of the responses to the two types of stimuli were calculated.</p></sec><sec id="s4-12"><title>RF size and surround suppression</title><p>To measure cell RF sizes (e.g. <xref ref-type="fig" rid="fig4">Figure 4L and M</xref>), we first performed a two-way ANOVA analysis (with repetition) for the cell’s responses to square-wave gratings of 6 different sizes and eight different moving directions. If the size factor is significant (p&lt;0.05), then we fitted a ratio of Gaussian function (<xref ref-type="bibr" rid="bib2">Cavanaugh et al., 2002</xref>) to the direction-averaged size tuning curve:<disp-formula id="equ2"><mml:math id="m2"><mml:mi mathvariant="normal">R</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:math></disp-formula><disp-formula id="equ3"><mml:math id="m3"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:msqrt><mml:mi>π</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo>-</mml:mo><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>/</mml:mo><mml:mi>w</mml:mi><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mi>d</mml:mi><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></disp-formula><disp-formula id="equ4"><mml:math id="m4"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:msqrt><mml:mi>π</mml:mi></mml:msqrt></mml:mrow></mml:mfrac><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo>-</mml:mo><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>/</mml:mo><mml:mi>w</mml:mi><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mi>d</mml:mi><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></disp-formula>where x is the stimulus diameter, k<sub>c</sub> and k<sub>s</sub> are gains for the RF center and surround, L<sub>c</sub> and L<sub>s</sub> are the total squared responses of the center and surround, and wc and ws are the size of the center and surround (wc &lt;ws). Fitting parameters were obtained with a least-square nonlinear regression method (nlinfit in Matlab, Mathworks). The optimal stimulus size was determined as the diameter corresponding to the peak response in the fitted function. Goodness of fit (R<sup>2</sup>) values were &gt;0.7 for all neurons that had significant size tuning to square wave gratings (n = 1493), and 95% (1418/1493) of these neurons had a preferred stimulus size between 0.5° and 12°. If a cell’s responses were not modulated by stimulus size (i.e. size factor was not significant in the two-way ANOVA analysis), then this cell was not included in the RF size related analysis. Surround suppression index (e.g. <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1F</xref>) was calculated from the size tuning curve as (maximum response – minimum response)/maximum response, in which minimum response was the least response obtained for stimulus size larger than that of maximum response (maximum surround suppression).</p></sec><sec id="s4-13"><title>Pixel-based contour-preference map</title><p>Pixel-based contour-preference maps (e.g. <xref ref-type="fig" rid="fig4">Figure 4B</xref>) were a combination of a gray value (G) map and a red/green hue map. For each pixel, we first calculated a shape preference index: SPI = abs(ΔFcc-ΔFbat)/max(ΔFcc,ΔFbat), where ΔFcc is the maximum fluorescence increase to curves and circles (red framed ones in <xref ref-type="fig" rid="fig3">Figure 3F</xref>), ΔFbat is the maximum fluorescence increase to bar, angle and triangle (green framed ones in <xref ref-type="fig" rid="fig3">Figure 3F</xref>). Then we calculated the gray value as: G = 200xSPIxFp/Fp_f, where Fp is the maximum of the fluorescence values in the response images to all five types of stimuli, Fp_f is the average of all pixels’ Fp in the same frame. Hue for a pixel is red if its ΔFcc is larger than ΔFbat, and is green if not.</p></sec><sec id="s4-14"><title>PCA</title><p>PCA results were shown in <xref ref-type="fig" rid="fig5">Figure 5</xref> and <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>. For each neuron, its response matrix was normalized to 0–1. Its responses to different orientations were sorted, so that for each contour, 0° represented its highest response and 135° for the lowest (thus no longer correspond to the stimulus icons). Only neurons tested with the full stimulus set were analyzed (n = 1556). The responses of these neurons were arranged as a 2D matrix, and the mean response to each stimulus was subtracted before the PCA analysis was performed. In <xref ref-type="fig" rid="fig5">Figure 5E</xref>, the color of the neurons was determined based on their coordinates on PC1.</p></sec><sec id="s4-15"><title>Statistical analysis</title><p>All t-tests and paired t-test are two-tailed.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This work was supported by the National Natural Science Foundation of China (31530029 and 31625012 to HDL and 31800870 to RT) and the China Postdoctoral Science Foundation (2018M631373 to RT). We thank Dr. Shiming Tang for valuable technical support on two-photon imaging. Lab members Jie Lu, Yan Xiao, Chen Fang, Kun Yan, Jingting Xu, Heng Ma, Jiayu Wang, Pengcheng Li, Chen Liang, and Wenhao Zhao provided technical assistance.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Validation, Investigation, Methodology, Project administration</p></fn><fn fn-type="con" id="con3"><p>Data curation, Investigation</p></fn><fn fn-type="con" id="con4"><p>Data curation, Investigation</p></fn><fn fn-type="con" id="con5"><p>Data curation, Investigation</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Resources, Data curation, Supervision, Funding acquisition, Validation, Investigation, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All procedures were performed in accordance with the National Institutes of Health Guidelines and were approved by the Institutional Animal Care and Use Committee of the Beijing Normal University. Protocol number: IACUC(BNU)-NKCNL2016-06.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-57502-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Data and MATLAB code required to reproduce all figures are available at <ext-link ext-link-type="uri" xlink:href="https://osf.io/qydj5/">https://osf.io/qydj5/</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Tang</surname><given-names>R</given-names></name><name><surname>Song</surname><given-names>Q</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Zhang</surname><given-names>R</given-names></name><name><surname>Cai</surname><given-names>X</given-names></name><name><surname>Lu</surname><given-names>HD</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Source data and codes for V4 manuscript</data-title><source>Open Science Framework</source><pub-id assigning-authority="Open Science Framework" pub-id-type="doi">10.17605/OSF.IO/QYDJ5</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bashivan</surname> <given-names>P</given-names></name><name><surname>Kar</surname> <given-names>K</given-names></name><name><surname>DiCarlo</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neural population control via deep image synthesis</article-title><source>Science</source><volume>364</volume><elocation-id>eaav9436</elocation-id><pub-id pub-id-type="doi">10.1126/science.aav9436</pub-id><pub-id pub-id-type="pmid">31048462</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cavanaugh</surname> <given-names>JR</given-names></name><name><surname>Bair</surname> <given-names>W</given-names></name><name><surname>Movshon</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Nature and interaction of signals from the receptive field center and surround in macaque V1 neurons</article-title><source>Journal of Neurophysiology</source><volume>88</volume><fpage>2530</fpage><lpage>2546</lpage><pub-id pub-id-type="doi">10.1152/jn.00692.2001</pub-id><pub-id pub-id-type="pmid">12424292</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>M</given-names></name><name><surname>Li</surname> <given-names>P</given-names></name><name><surname>Zhu</surname> <given-names>S</given-names></name><name><surname>Han</surname> <given-names>C</given-names></name><name><surname>Xu</surname> <given-names>H</given-names></name><name><surname>Fang</surname> <given-names>Y</given-names></name><name><surname>Hu</surname> <given-names>J</given-names></name><name><surname>Roe</surname> <given-names>AW</given-names></name><name><surname>Lu</surname> <given-names>HD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>An orientation map for motion boundaries in macaque V2</article-title><source>Cerebral Cortex</source><volume>26</volume><fpage>279</fpage><lpage>287</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu235</pub-id><pub-id pub-id-type="pmid">25260703</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chklovskii</surname> <given-names>DB</given-names></name><name><surname>Koulakov</surname> <given-names>AA</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Maps in the brain: what can we learn from them?</article-title><source>Annual Review of Neuroscience</source><volume>27</volume><fpage>369</fpage><lpage>392</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.27.070203.144226</pub-id><pub-id pub-id-type="pmid">15217337</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Connor</surname> <given-names>CE</given-names></name><name><surname>Brincat</surname> <given-names>SL</given-names></name><name><surname>Pasupathy</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Transformation of shape information in the ventral pathway</article-title><source>Current Opinion in Neurobiology</source><volume>17</volume><fpage>140</fpage><lpage>147</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2007.03.002</pub-id><pub-id pub-id-type="pmid">17369035</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desimone</surname> <given-names>R</given-names></name><name><surname>Schein</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Visual properties of neurons in area V4 of the macaque: sensitivity to stimulus form</article-title><source>Journal of Neurophysiology</source><volume>57</volume><fpage>835</fpage><lpage>868</lpage><pub-id pub-id-type="doi">10.1152/jn.1987.57.3.835</pub-id><pub-id pub-id-type="pmid">3559704</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dobbins</surname> <given-names>A</given-names></name><name><surname>Zucker</surname> <given-names>SW</given-names></name><name><surname>Cynader</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Endstopped neurons in the visual cortex as a substrate for calculating curvature</article-title><source>Nature</source><volume>329</volume><fpage>438</fpage><lpage>441</lpage><pub-id pub-id-type="doi">10.1038/329438a0</pub-id><pub-id pub-id-type="pmid">3657960</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dumoulin</surname> <given-names>SO</given-names></name><name><surname>Hess</surname> <given-names>RF</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Cortical specialization for concentric shape processing</article-title><source>Vision Research</source><volume>47</volume><fpage>1608</fpage><lpage>1613</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2007.01.031</pub-id><pub-id pub-id-type="pmid">17449081</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fisher</surname> <given-names>NI</given-names></name></person-group><year iso-8601-date="1993">1993</year><source>Statistical Analysis of Circular Data</source><publisher-name>Cambridge University Press</publisher-name></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fujita</surname> <given-names>I</given-names></name><name><surname>Tanaka</surname> <given-names>K</given-names></name><name><surname>Ito</surname> <given-names>M</given-names></name><name><surname>Cheng</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Columns for visual features of objects in monkey inferotemporal cortex</article-title><source>Nature</source><volume>360</volume><fpage>343</fpage><lpage>346</lpage><pub-id pub-id-type="doi">10.1038/360343a0</pub-id><pub-id pub-id-type="pmid">1448150</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallant</surname> <given-names>JL</given-names></name><name><surname>Braun</surname> <given-names>J</given-names></name><name><surname>Van Essen</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Selectivity for polar, Hyperbolic, and cartesian gratings in macaque visual cortex</article-title><source>Science</source><volume>259</volume><fpage>100</fpage><lpage>103</lpage><pub-id pub-id-type="doi">10.1126/science.8418487</pub-id><pub-id pub-id-type="pmid">8418487</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallant</surname> <given-names>JL</given-names></name><name><surname>Connor</surname> <given-names>CE</given-names></name><name><surname>Rakshit</surname> <given-names>S</given-names></name><name><surname>Lewis</surname> <given-names>JW</given-names></name><name><surname>Van Essen</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Neural responses to Polar, Hyperbolic, and cartesian gratings in area V4 of the macaque monkey</article-title><source>Journal of Neurophysiology</source><volume>76</volume><fpage>2718</fpage><lpage>2739</lpage><pub-id pub-id-type="doi">10.1152/jn.1996.76.4.2718</pub-id><pub-id pub-id-type="pmid">8899641</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghose</surname> <given-names>GM</given-names></name><name><surname>Ts'o</surname> <given-names>DY</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Form processing modules in primate area V4</article-title><source>Journal of Neurophysiology</source><volume>77</volume><fpage>2191</fpage><lpage>2196</lpage><pub-id pub-id-type="doi">10.1152/jn.1997.77.4.2191</pub-id><pub-id pub-id-type="pmid">9114265</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ghose</surname> <given-names>GM</given-names></name><name><surname>Ts'o</surname> <given-names>DY</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Integration of color, orientation, and size functional domains in the ventral pathway</article-title><source>Neurophotonics</source><volume>4</volume><elocation-id>031216</elocation-id><pub-id pub-id-type="doi">10.1117/1.NPh.4.3.031216</pub-id><pub-id pub-id-type="pmid">28573155</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grill-Spector</surname> <given-names>K</given-names></name><name><surname>Weiner</surname> <given-names>KS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The functional architecture of the ventral temporal cortex and its role in categorization</article-title><source>Nature Reviews Neuroscience</source><volume>15</volume><fpage>536</fpage><lpage>548</lpage><pub-id pub-id-type="doi">10.1038/nrn3747</pub-id><pub-id pub-id-type="pmid">24962370</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hegdé</surname> <given-names>J</given-names></name><name><surname>Van Essen</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A comparative study of shape representation in macaque visual Areas v2 and v4</article-title><source>Cerebral Cortex</source><volume>17</volume><fpage>1100</fpage><lpage>1116</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhl020</pub-id><pub-id pub-id-type="pmid">16785255</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hu</surname> <given-names>JM</given-names></name><name><surname>Song</surname> <given-names>XM</given-names></name><name><surname>Wang</surname> <given-names>Q</given-names></name><name><surname>Roe</surname> <given-names>AW</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Curvature domains in V4 of macaque monkey</article-title><source>eLife</source><volume>9</volume><elocation-id>e57261</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.57261</pub-id><pub-id pub-id-type="pmid">33211004</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname> <given-names>DH</given-names></name><name><surname>Wiesel</surname> <given-names>TN</given-names></name></person-group><year iso-8601-date="1965">1965</year><article-title>Receptive fields and functional architecture in two nonstriate visual Areas (18 and 19) OF the cat</article-title><source>Journal of Neurophysiology</source><volume>28</volume><fpage>229</fpage><lpage>289</lpage><pub-id pub-id-type="doi">10.1152/jn.1965.28.2.229</pub-id><pub-id pub-id-type="pmid">14283058</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ito</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Cortical shape adaptation transforms a circle into a hexagon: a novel afterimage illusion</article-title><source>Psychological Science</source><volume>23</volume><fpage>126</fpage><lpage>132</lpage><pub-id pub-id-type="doi">10.1177/0956797611422236</pub-id><pub-id pub-id-type="pmid">22207643</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Jiang</surname> <given-names>R</given-names></name><name><surname>Li</surname> <given-names>M</given-names></name><name><surname>Tang</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Discrete neural clusters encode orientation curvature and corners in macaque V4</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/808907</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kobatake</surname> <given-names>E</given-names></name><name><surname>Tanaka</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Neuronal selectivities to complex object features in the ventral visual pathway of the macaque cerebral cortex</article-title><source>Journal of Neurophysiology</source><volume>71</volume><fpage>856</fpage><lpage>867</lpage><pub-id pub-id-type="doi">10.1152/jn.1994.71.3.856</pub-id><pub-id pub-id-type="pmid">8201425</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>P</given-names></name><name><surname>Zhu</surname> <given-names>S</given-names></name><name><surname>Chen</surname> <given-names>M</given-names></name><name><surname>Han</surname> <given-names>C</given-names></name><name><surname>Xu</surname> <given-names>H</given-names></name><name><surname>Hu</surname> <given-names>J</given-names></name><name><surname>Fang</surname> <given-names>Y</given-names></name><name><surname>Lu</surname> <given-names>HD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A motion direction preference map in monkey V4</article-title><source>Neuron</source><volume>78</volume><fpage>376</fpage><lpage>388</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.02.024</pub-id><pub-id pub-id-type="pmid">23622068</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>M</given-names></name><name><surname>Liu</surname> <given-names>F</given-names></name><name><surname>Juusola</surname> <given-names>M</given-names></name><name><surname>Tang</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Perceptual color map in macaque visual area V4</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>202</fpage><lpage>217</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4549-12.2014</pub-id><pub-id pub-id-type="pmid">24381282</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>M</given-names></name><name><surname>Liu</surname> <given-names>F</given-names></name><name><surname>Jiang</surname> <given-names>H</given-names></name><name><surname>Lee</surname> <given-names>TS</given-names></name><name><surname>Tang</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Long-Term Two-Photon imaging in awake macaque monkey</article-title><source>Neuron</source><volume>93</volume><fpage>1049</fpage><lpage>1057</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.01.027</pub-id><pub-id pub-id-type="pmid">28215557</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>N</given-names></name><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name><name><surname>Mur</surname> <given-names>M</given-names></name><name><surname>Hadj-Bouziane</surname> <given-names>F</given-names></name><name><surname>Luh</surname> <given-names>WM</given-names></name><name><surname>Tootell</surname> <given-names>RB</given-names></name><name><surname>Ungerleider</surname> <given-names>LG</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Intrinsic structure of visual exemplar and category representations in macaque brain</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>11346</fpage><lpage>11360</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4180-12.2013</pub-id><pub-id pub-id-type="pmid">23843508</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>Y</given-names></name><name><surname>Li</surname> <given-names>M</given-names></name><name><surname>Zhang</surname> <given-names>X</given-names></name><name><surname>Lu</surname> <given-names>Y</given-names></name><name><surname>Gong</surname> <given-names>H</given-names></name><name><surname>Yin</surname> <given-names>J</given-names></name><name><surname>Chen</surname> <given-names>Z</given-names></name><name><surname>Qian</surname> <given-names>L</given-names></name><name><surname>Yang</surname> <given-names>Y</given-names></name><name><surname>Andolina</surname> <given-names>IM</given-names></name><name><surname>Shipp</surname> <given-names>S</given-names></name><name><surname>Mcloughlin</surname> <given-names>N</given-names></name><name><surname>Tang</surname> <given-names>S</given-names></name><name><surname>Wang</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Hierarchical representation for chromatic processing across macaque V1, V2, and V4</article-title><source>Neuron</source><volume>108</volume><fpage>538</fpage><lpage>550</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.07.037</pub-id><pub-id pub-id-type="pmid">32853551</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mardia</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="1972">1972</year><source>Statistics of Directional Data</source><publisher-name>Academic Press</publisher-name></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mountcastle</surname> <given-names>VB</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The columnar organization of the neocortex</article-title><source>Brain</source><volume>120</volume><fpage>701</fpage><lpage>722</lpage><pub-id pub-id-type="doi">10.1093/brain/120.4.701</pub-id><pub-id pub-id-type="pmid">9153131</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nandy</surname> <given-names>AS</given-names></name><name><surname>Sharpee</surname> <given-names>TO</given-names></name><name><surname>Reynolds</surname> <given-names>JH</given-names></name><name><surname>Mitchell</surname> <given-names>JF</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The fine structure of shape tuning in area V4</article-title><source>Neuron</source><volume>78</volume><fpage>1102</fpage><lpage>1115</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.04.016</pub-id><pub-id pub-id-type="pmid">23791199</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pasupathy</surname> <given-names>A</given-names></name><name><surname>Popovkina</surname> <given-names>DV</given-names></name><name><surname>Kim</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Visual functions of primate area V4</article-title><source>Annual Review of Vision Science</source><volume>6</volume><fpage>363</fpage><lpage>385</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-030320-041306</pub-id><pub-id pub-id-type="pmid">32580663</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pasupathy</surname> <given-names>A</given-names></name><name><surname>Connor</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Responses to contour features in macaque area V4</article-title><source>Journal of Neurophysiology</source><volume>82</volume><fpage>2490</fpage><lpage>2502</lpage><pub-id pub-id-type="doi">10.1152/jn.1999.82.5.2490</pub-id><pub-id pub-id-type="pmid">10561421</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pasupathy</surname> <given-names>A</given-names></name><name><surname>Connor</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Shape representation in area V4: position-specific tuning for boundary conformation</article-title><source>Journal of Neurophysiology</source><volume>86</volume><fpage>2505</fpage><lpage>2519</lpage><pub-id pub-id-type="doi">10.1152/jn.2001.86.5.2505</pub-id><pub-id pub-id-type="pmid">11698538</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pasupathy</surname> <given-names>A</given-names></name><name><surname>Connor</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Population coding of shape in area V4</article-title><source>Nature Neuroscience</source><volume>5</volume><fpage>1332</fpage><lpage>1338</lpage><pub-id pub-id-type="doi">10.1038/972</pub-id><pub-id pub-id-type="pmid">12426571</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ponce</surname> <given-names>CR</given-names></name><name><surname>Hartmann</surname> <given-names>TS</given-names></name><name><surname>Livingstone</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>End-Stopping predicts curvature tuning along the ventral stream</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>648</fpage><lpage>659</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2507-16.2016</pub-id><pub-id pub-id-type="pmid">28100746</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ponce</surname> <given-names>CR</given-names></name><name><surname>Xiao</surname> <given-names>W</given-names></name><name><surname>Schade</surname> <given-names>PF</given-names></name><name><surname>Hartmann</surname> <given-names>TS</given-names></name><name><surname>Kreiman</surname> <given-names>G</given-names></name><name><surname>Livingstone</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Evolving images for visual neurons using a deep generative network reveals coding principles and neuronal preferences</article-title><source>Cell</source><volume>177</volume><fpage>999</fpage><lpage>1009</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2019.04.005</pub-id><pub-id pub-id-type="pmid">31051108</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roe</surname> <given-names>AW</given-names></name><name><surname>Chelazzi</surname> <given-names>L</given-names></name><name><surname>Connor</surname> <given-names>CE</given-names></name><name><surname>Conway</surname> <given-names>BR</given-names></name><name><surname>Fujita</surname> <given-names>I</given-names></name><name><surname>Gallant</surname> <given-names>JL</given-names></name><name><surname>Lu</surname> <given-names>H</given-names></name><name><surname>Vanduffel</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Toward a unified theory of visual area V4</article-title><source>Neuron</source><volume>74</volume><fpage>12</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.03.011</pub-id><pub-id pub-id-type="pmid">22500626</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sato</surname> <given-names>T</given-names></name><name><surname>Uchida</surname> <given-names>G</given-names></name><name><surname>Tanifuji</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Cortical columnar organization is reconsidered in inferior temporal cortex</article-title><source>Cerebral Cortex</source><volume>19</volume><fpage>1870</fpage><lpage>1888</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhn218</pub-id><pub-id pub-id-type="pmid">19068487</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srihasam</surname> <given-names>K</given-names></name><name><surname>Vincent</surname> <given-names>JL</given-names></name><name><surname>Livingstone</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Novel domain formation reveals proto-architecture in inferotemporal cortex</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1776</fpage><lpage>1783</lpage><pub-id pub-id-type="doi">10.1038/nn.3855</pub-id><pub-id pub-id-type="pmid">25362472</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanaka</surname> <given-names>M</given-names></name><name><surname>Weber</surname> <given-names>H</given-names></name><name><surname>Creutzfeldt</surname> <given-names>OD</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Visual properties and spatial distribution of neurones in the visual association area on the prelunate gyrus of the awake monkey</article-title><source>Experimental Brain Research</source><volume>65</volume><fpage>11</fpage><lpage>37</lpage><pub-id pub-id-type="doi">10.1007/BF00243827</pub-id><pub-id pub-id-type="pmid">3803497</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanigawa</surname> <given-names>H</given-names></name><name><surname>Lu</surname> <given-names>HD</given-names></name><name><surname>Roe</surname> <given-names>AW</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Functional organization for color and orientation in macaque V4</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1542</fpage><lpage>1548</lpage><pub-id pub-id-type="doi">10.1038/nn.2676</pub-id><pub-id pub-id-type="pmid">21076422</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsao</surname> <given-names>DY</given-names></name><name><surname>Freiwald</surname> <given-names>WA</given-names></name><name><surname>Tootell</surname> <given-names>RB</given-names></name><name><surname>Livingstone</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A cortical region consisting entirely of face-selective cells</article-title><source>Science</source><volume>311</volume><fpage>670</fpage><lpage>674</lpage><pub-id pub-id-type="doi">10.1126/science.1119983</pub-id><pub-id pub-id-type="pmid">16456083</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsunoda</surname> <given-names>K</given-names></name><name><surname>Yamane</surname> <given-names>Y</given-names></name><name><surname>Nishizaki</surname> <given-names>M</given-names></name><name><surname>Tanifuji</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Complex objects are represented in macaque inferotemporal cortex by the combination of feature columns</article-title><source>Nature Neuroscience</source><volume>4</volume><fpage>832</fpage><lpage>838</lpage><pub-id pub-id-type="doi">10.1038/90547</pub-id><pub-id pub-id-type="pmid">11477430</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>G</given-names></name><name><surname>Tanaka</surname> <given-names>K</given-names></name><name><surname>Tanifuji</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Optical imaging of functional organization in the monkey inferotemporal cortex</article-title><source>Science</source><volume>272</volume><fpage>1665</fpage><lpage>1668</lpage><pub-id pub-id-type="doi">10.1126/science.272.5268.1665</pub-id><pub-id pub-id-type="pmid">8658144</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilkinson</surname> <given-names>F</given-names></name><name><surname>James</surname> <given-names>TW</given-names></name><name><surname>Wilson</surname> <given-names>HR</given-names></name><name><surname>Gati</surname> <given-names>JS</given-names></name><name><surname>Menon</surname> <given-names>RS</given-names></name><name><surname>Goodale</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>An fMRI study of the selective activation of human extrastriate form vision Areas by radial and concentric gratings</article-title><source>Current Biology</source><volume>10</volume><fpage>1455</fpage><lpage>1458</lpage><pub-id pub-id-type="doi">10.1016/S0960-9822(00)00800-9</pub-id><pub-id pub-id-type="pmid">11102809</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiao</surname> <given-names>Y</given-names></name><name><surname>Rao</surname> <given-names>R</given-names></name><name><surname>Cecchi</surname> <given-names>G</given-names></name><name><surname>Kaplan</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Improved mapping of information distribution across the cortical surface with the support vector machine</article-title><source>Neural Networks</source><volume>21</volume><fpage>341</fpage><lpage>348</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2007.12.022</pub-id><pub-id pub-id-type="pmid">18249089</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yue</surname> <given-names>X</given-names></name><name><surname>Pourladian</surname> <given-names>IS</given-names></name><name><surname>Tootell</surname> <given-names>RB</given-names></name><name><surname>Ungerleider</surname> <given-names>LG</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Curvature-processing network in macaque visual cortex</article-title><source>PNAS</source><volume>111</volume><fpage>E3467</fpage><lpage>E3475</lpage><pub-id pub-id-type="doi">10.1073/pnas.1412616111</pub-id><pub-id pub-id-type="pmid">25092328</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.57502.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Krug</surname><given-names>Kristine</given-names></name><role>Reviewing Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Connor</surname><given-names>Ed</given-names> </name><role>Reviewer</role><aff><institution>Johns Hopkins University</institution><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Das</surname><given-names>Aniruddha</given-names> </name><role>Reviewer</role><aff><institution>Columbia University and Zuckerman Institute</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>Curvature is a fundamental element of complex visual shapes in the world around us. This study elegantly combines cutting edge methodologies to investigate – from single brains cells to functional domains – how V4, a mid-level area of the visual cortex of primates, shows specialisation for processing and representing curvature, not seen at earlier levels of visual processing. This functional architecture complements known domains for orientation tuning and colour in V4 and significantly furthers our understanding of how primate brains recognise and discriminate visual objects.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you very much for submitting your article &quot;Curvature-processing domains in primate V4&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Joshua Gold as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Ed Connor (Reviewer #1); Aniruddha Das (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>As the editors have judged that your manuscript is of interest, but as described below that additional data analyses are required before it is published, we would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). First, because many researchers have temporarily lost access to the labs, we will give authors as much time as they need to submit revised manuscripts. We are also offering, if you choose, to post the manuscript to bioRxiv (if it is not already there) along with this decision letter and a formal designation that the manuscript is &quot;in revision at <italic>eLife</italic>&quot;. Please let us know if you would like to pursue this option. (If your work is more suitable for medRxiv, you will need to post the preprint yourself, as the mechanisms for us to do so are still in development.)</p><p>Summary:</p><p>Lu and colleagues present potentially compelling new results on the architecture of curvature response strength and selectivity in macaque visual cortical area V4, in comparison to the lack thereof in earlier level visual areas V1 and V2. A particular strength is that the authors combine intrinsic-signal optical imaging (giving meso-scale resolution over a few mm of cortex) with 2-photon imaging (single cell resolution, over a few 100 microns; including 2-photon imaging at multiple cortical depths). The intrinsic signal data show distinct clustering of responsiveness to object fragments that constitute &quot;intermediate&quot; visual representations that are more complicated that the traditional single orientation columns in V1 or V2. However, the reviewers raised a number of critical issues relating to analysis, presentation and interpretation of this exciting data set and hope that these can be satisfactorily addressed in order for the study to deliver its full potential impact.</p><p>Essential revisions:</p><p>1) To include single activation condition maps for the intrinsic optical imaging and explore whether map activations could be explained by simpler, underlying response patterns.</p><p>The presented intrinsic optical imaging data comprise only difference maps, which could potentially obscure underlying results. For example, in Figure 1L, it could be that those 2 angles elicit very little localized responses, or that they elicit an identical pattern of activation, and from the difference map we don't know which is the case. It would be good to see some single condition activation maps.</p><p>That would also potentially help in investigating to what extent these responses can be explained by simple receptive field (RF) summation. For instance, there is a substantial literature in associating preferential responses to curves with end-stopped neurons: Hubel and Wiesel, in 1965 suggested that end-stopped, length tuned neurons could be useful for curvature detection and there was a nice explicit model of how that could happen by Dobbins et al. in 1987. But the manuscript makes little reference to any size tuning or surround suppression, and how that, in combination with classic orientation tuning, could create a cell that responds vigorously to curvature. This is even a greater concern given the well-established prevalence of size tuning, both electrophysiologically (1987) and with optical imaging (1997), in area V4. This has a huge impact on both novelty and interpretability; if you have a region of surround suppression (which we know exist) and it overlaps with an orientation region, this can look like a &quot;curvature&quot; region in that it will respond to a curve better than extended straight line or grating. But we would argue it's not a &quot;curvature&quot; region, since a short bar or grating without any curvature is actually the optimal stimulus. For example, can the response to triangles, on a pixel by pixel basis, be explained by simply adding or averaging the response the constituent orientations? Similarly, can the circle responses be explained by adding the responses to the half-circles?</p><p>2) To support the 2-photon results with convincing anatomical images.</p><p>One technical issue is the lack of any good underlying anatomical images to support the 2-photon data. This is concerning because all the images provided here show cells that are filled in, but living cells should appear as rings representing the cell membrane. Filled in cells are dead or compromised, and this would be a critical caveat for all the response results reported here. All of the cells in Figure 3C-F appear to be filled in. This could be because (i) these images do not have sufficient resolution to show rings, (ii) the authors did some kind of smoothing of these images (smoothing is mentioned in Materials and methods), or (iii) the cells are filled with calcium, reflecting a dead or compromised state. This concern is further exacerbated by the strange cell shapes in Figures 4G and H and 5A, D, and G. The authors should show the underlying anatomical images for those panels and explain how they defined the odd shapes shown in them. In addition to showing anatomical images, the authors should quantify how many cells are filled or ring-like in their images, and clarify whether the cells for which they report tuning include filled cells (and how many).</p><p>3) The reviewers would like to see more systematic and consistent analysis and representation across Figures 4. and 5 that allows the reader to better understand the fundamental, underlying tuning properties of neurons.</p><p>A technical concern is that Figure 4 and Figure 5 appear to present the same phenomena, but with different analyses for different images. Figure 4G labels neurons according to whether they exhibited stronger responses to circles or arcs. Figure 5 distinguishes neurons by how closely they are correlated with the average response pattern for the local curvature domain. But the examples in Figures 5B,C,E,F,H,I make it clear that the differences between correlated and not correlated again have to do with relative responses to circles vs. arcs. All of these images in Figures 4 and 5 need to be analyzed in the same ways, with an emphasis on the more explanatory analyses related to tuning, rather than unexplained correlation.</p><p>In relations to the tuning properties underlying the impressive 2-photon data, the question arises to what extent can RF summation (for example, RF summation models that include non-linearities that have been applied to V4) explain responses across the stimulus array?</p><p>See also point 4 below, in relation to this issue of the underlying tuning properties of neurons.</p><p>4) To reanalyze both datasets (intrinsic optical imaging and 2-Photon) in light of what is well-known about V4 tuning for fragments, not whole shapes, for curvature acuteness (which means responses to triangles reflect high curvature acuteness tuning) and object-relative position of contour fragments (which explains the differences between &quot;circle&quot; neurons and &quot;curve&quot; neurons, as well as the difference between triangle responses and angle responses, most of which we do not get to see). This should radically change the interpretation of Figures 1 and 2, and change the analysis emphasis of regions in the 2-photon section of the paper.</p><p>The major technical and interpretational concern is that differences between response patterns throughout the paper are presented as though the neurons were tuned for circles in some cases, arcs in others, triangles in others, etc. This ignores well-established tuning dimensions in V4 that explain response patterns like these at a more basic level. Pasupathy and Connor, 1999; 2001and 2002) and Carlson et al. (2011, Current Biology) clearly demonstrated that:</p><p>i) V4 neurons respond to contour fragments, not complete shapes,</p><p>ii) V4 neurons are strongly tuned for the object-relative position of those contour fragments,</p><p>iii) V4 neurons are tuned for curvature acuteness, with a bias toward sharp curvatures,</p><p>iv) V4 neurons are differentially tuned for convexity and concavity.</p><p>By ignoring this literature, the authors might misinterpret many of their results:</p><p>a) In Figures 1 and 2, responses to triangles are treated as representative of non-curvature regions. But, per point (iii) above, the points of those triangles will drive strong responses from the most acute curvature tuning regions. Thus, the curvature/triangle contrasts are more likely to represent organization for broad curvature vs. acute curvature (angles are geometrically just the limiting case of acute curvature) than a difference between curvature and straight lines. The same is true for line segments, whose terminations drive weaker but similar responses, and which show only weak differences from triangles and angles. The only valid contrast for finding curvature domains is curves vs. gratings, which reveals very different regions than triangles in Figure 1. This reliance on circle vs. triangle contrast has ramifications throughout the paper, because it is used to define curvature domains and thus bias the 2-photon studies away from regions of acute curvature tuning.</p><p>b) A similar problem appears in Figure 3, where the only response shown for the &quot;rectilinear&quot; region is a highly selective response for a triangle. Per point (ii) above, triangles provide a whole object context in which V4 neurons can exhibit their strong tuning for object-relative position of contour fragments, including high-curvature angles. This is why neuron 3 does not respond to any other rectilinear stimulus. If triangle responses like this are the basis for the green regions in Figure 3, then those regions are acute curvature regions, not non-curvature regions, and again the authors will be excluding high-curvature regions from their analyses in Figures 4 and 5.</p><p>c) Per above, Figures 4 and 5 are restricted to clusters of broader curvature tuning, strongly biasing the analyses. This is undoubtedly one reason that many example neurons respond strongly to circles. The other major problem with these figures is that they are presented as evidence that many neurons in V4 are strongly selective for circles as whole stimuli, while others are strongly selective for arcs over circles. In fact, the references cited above make clear that neurons in V4 are invariably tuned for shape fragments (i), not whole shapes, and they are strongly tuned for fragment position within shapes (ii). This is why many neurons respond most strongly to circles, because they are tuned for an arc-shaped fragment, but respond much more strongly when that fragment is in the preferred object-relative position. This is frequently true for circles, because there is also a strong correlation between curvature orientation tuning and object position tuning, since convex curves pointing up usually occur at the top of an object; curves pointing to the right occur at the right, etc. In many other cases, however, the preferred object-relative position is off angle, and when that is true the responses to circles will be low, and the responses to isolated arcs will be higher. (Responses to an entire shape with the arc at the preferred position would be higher still.) Thus, differential tuning for object-relative position explains most of the differences highlighted in Figures 4 and 5.</p><p>5) To support the 2-photon data, which surveys properties in a large number of cells, a comprehensive, more clearly structured data summary is required.</p><p>Apart from the issue raised above, the summary statements of the 2-Photon data are not particularly satisfying: the categories of orientation and curve-orientation are not very enlightening about underlying principles. Perhaps PCA analysis could be used to see the patterns of selectivity that are prevalent across the sample (perhaps after selecting the best orientation or collapsing across orientation). Another possibility would be, after rotating to a common best orientation, to superimpose all the stimuli with an opacity relating the firing rate. In the end this seems like a lost opportunity to follow up the influential Hegde and Van Essen, 2000, studies whose stimulus set parallels the one used here.</p><p>6) Incorporating any new results from the analyses above, the underlying major concepts need to be more consistently defined and applied across the paper.</p><p>Related to the technical issues raised above (points 3-5), the terminology in the manuscript is sometimes confusing. The authors propose that there is “microarchitecture” of selectivity for circles vs. curves. But then they appear to contradict themselves. For example (final paragraph of subsection “Microarchitectures of the curvature domains”) the authors talks of neurons having “preferred curve” stimuli; and in the same section, (Figure 4K) the authors state that these same neurons respond more strongly to circles than to their preferred curves. What does it mean to be selective for a “preferred curve” if the response to the “preferred” stimulus is consistently weaker than to a different stimulus?</p><p>7) Please clarify the definition of curvature domains and examine their periodicity</p><p>Another technical issue is the poor description of how curvature domains were defined and drawn. The &quot;watershed&quot; technique should be described in detail, and the domains should be drawn on the sections, especially the sections in Figure 5, where the domain boundaries determine the average response pattern.</p><p>Given the limited spatial sampling with 2-photon imaging, distance correlations metrics with the intrinsic optical imaging reflectance data (using the above requested single condition activity maps) would be nice to examine the periodicity of horizontal organization patterns. Given the stimulus array is that used in the 2-photon data, the absolute value of correlations is going to be different, but the key issue here is the spacing and size of &quot;columns&quot; and whether that depends on the type of stimulus you're looking at.</p><p>What bandpass filtering is used for intrinsic optical images (since that can &quot;create&quot; domains out of noise)? Can Fourier analysis be used to describe the size and spacing of domains?</p><p>8) There are also a number of places where the primary narrative of the paper seems to contradict itself. For example: starting with the Abstract, the authors make the important observation that “curvature” domains have “little overlap” with “orientation domains”. They repeat this point, e.g. in the Results; and again, in the legend of Figure 3H,: with clearly distinct “curvature” and “rectilinear” zones. On the other hand, the authors also make a point of saying that individual neurons have mixed responses – with individual neurons in “curvature” domains responding well to rectilinear contours (e.g. Figure 3P). The authors further amplify the issue of response diversity in Figure 5, with nearest-neighbor neurons showing strikingly different response. The authors should rewrite the Abstract and the relevant sections of the results to have a more consistent description of the degree of overlap and response diversity that they observe.</p><p>9) While these results are very interesting, they are of course restricted to a limited set (73?) of human-selected and human-curated stimuli. Nowhere does the analysis address the question as to whether these are close to the optimal stimuli for this region of cortex, even in the (unnatural) anesthetized state. The authors should have a more expanded discussion of these limitations, and how to extend the analysis further to get a sense of the “optimal” stimuli for this stage of cortical processing.</p><p>Furthermore, the stimulus set used parallels that used by Hedge and Van Essen, 2000, in V4, and subsequently in V1 and V2 as well. Given that we know that selectivity’s exist that cannot simply be explained by orientation filters, the paper could do a better job of emphasizing what is new and, in particular, the significance of finding functional organization. If, for example, the authors feel that the presence of functional organization for a particular parameter is especially important in understanding the computations that occur within in an area, or in the broader picture, the role that area plays in visual processing, they should state so, and why they believe this.</p><p>These issues should be discussed and laid out appropriately.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you very much for resubmitting your article &quot;Curvature-processing domains in primate V4&quot; for consideration by <italic>eLife</italic>. Your revised article has been reviewed by two peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Joshua Gold as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Aniruddha Das (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>We would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). Specifically, we are asking editors to accept without delay manuscripts, like yours, that they judge can stand as <italic>eLife</italic> papers without additional data, even if they feel that they would make the manuscript stronger. Thus the revisions requested below only address clarity and presentation.</p><p>Summary:</p><p>Lu and colleagues present compelling new results on the architecture of curvature response strength and selectivity in macaque visual cortical area V4, in comparison to the lack thereof in earlier level visual areas V1 and V2. A particular strength is that the authors combine intrinsic-signal optical imaging (giving meso-scale resolution over a few mm of cortex) with 2-photon imaging (single cell resolution, over a few 100 microns; including 2-photon imaging at multiple cortical depths). The intrinsic signal data show distinct clustering of responsiveness to object fragments that constitute &quot;intermediate&quot; visual representations that are more complicated that the traditional single orientation columns in V1 or V2.</p><p>Revisions:</p><p>The authors have done an exemplary job in the revision, by addressing concerns raised and adding further analyses (clustering of single-cell-level response; PCA; more extended comparisons across classes of similar stimuli such as triangles / short oriented lines, as vs. circles / arcs; scaled to different sizes; filled / unfilled). Overall, these new analyses along with their original combination of intrinsic optical imaging and 2-photon imaging, showing the close spatial match between clusters identified separately by the two techniques make a compelling case for the specialised architecture the authors propose in the Discussion. There remain a small number of issues that would need to be addressed.</p><p>1) One disappointment is that some of the authors' responses didn't actually make into the manuscript or are &quot;buried&quot; in multi-panel supplementary figures. Specifically, the significance of relationship between surround suppression and curvature, and the PCA analysis (which proved interesting) are not particularly clear in the actual text of the manuscript. Also in light of some of the new analyses, the authors should probably cite some relevant literature about the existence of &quot;sub-domain&quot; specificity with domain-specific regions.</p><p>2) The direct correspondence between intrinsic and 2-photon imaging is certainly positive (correlation coefficients &gt; 0), but remarkably poor (and less than one), especially given that, for many experiments, intrinsic maps are seen as veridical and generally have good correspondence with targeted electrophysiology recordings. We noticed in the response letter that all intrinsic maps were Gaussian blurred, if one does the same procedure to the 2-photon data, does the correlation improve? And, if not, what explains this result: perhaps, significant noise in one type of measurement, or more interestingly, a true lack of correspondence between haemodynamics and cellular level responses. If the later, that's a big deal given: it potentially suggests that all haemodynamic maps should be taken with &quot;a grain of salt&quot; with regards to reflecting neuronal response property organization. And of course, if this is true, and intrinsic imaging is that noisy, it potentially calls into question many of the intrinsic signal difference maps and results even within this manuscript. This needs to be explicitly addressed.</p><p>3) More discussion in the actual manuscript about surround suppression, and specifically the points that appear in the authors' response, would be good. This is especially important, because surround suppression has long been associated with V4 responses, and there have been claims that it is functionally organized. The authors' remarks in the response about the only things the difference maps having is common is curvature is probably the best that can be made with the current data set. But, on the other hand, given the strong differences in surround suppression and receptive field size shown in the supplementary figures, that previous reports of surround suppression and its organization in V4 might simply reflect curvature regions that were studied with inappropriate sub-optimal stimuli.</p><p>4) This is a really large data set of cellular responses, and the PCA analyses are really important, but again, it would be better for this to appear in the actual manuscript.</p><p>One reason in particular is the paper's discussion of &quot;microorganization&quot; or sub-domains within a curvature region. We found these discussions a little anecdotal, and we were wishing that a spatial autocorrelation analysis could be done with pairs of neurons as function of distance to reveal how big a &quot;sub-domain&quot; was, and in particular, how it compared with orientation columns, which of course are sub-domains within the rectiiinear domains. For example, what one could do with regard to PCA weights: PCA1 spatial autocorrelation. In a similar vein, there have been several reports of color-specific sub-domains with color-preference domains, and, especially given the classic association of V4 with color sensitivity, that literature seems relevant here in a discussion of how universal domain/sub-domain organization may be and its variation between different cortical areas.</p><p>5) Scaling of the intrinsic signal optical images. The authors' methods suggest that the SD used for the gray scale is calculated separately for each (SVM) map. Is that correct? If so, there is no way to compare the strengths of activation by different stimuli. It likely also explains why the single-condition maps (e.g. Figure 1—figure supplement 1, panels A,B,D,E,G,H) appear not only relatively featureless but also occupying a grayscale range similar to the backgrounds of the difference images. In absolute terms, the single-condition responses presumably are ~ an order of magnitude higher amplitude if they are dominated by stimulus-nonspecific haemodynamic responses? Showing the single-condition and difference images on the same absolute scale would be uninformative. But it would be useful to show all the difference images on a common scale that is not tied to the SD per image, to get a sense of the efficacies of different stimulus pairwise differences. This could be done as an additional set of panels in supplementary figures.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.57502.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) To include single activation condition maps for the intrinsic optical imaging and explore whether map activations could be explained by simpler, underlying response patterns.</p><p>The presented intrinsic optical imaging data comprise only difference maps, which could potentially obscure underlying results. For example, in Figure 1L, it could be that those 2 angles elicit very little localized responses, or that they elicit an identical pattern of activation, and from the difference map we don't know which is the case. It would be good to see some single condition activation maps.</p></disp-quote><p>We agree with the reviewer that difference maps show the differences between two conditions, not the true response patterns. In the revised manuscript, we have included single-condition maps (new Figure 1—figure supplement 1) for comparison.</p><p>As we can see, although some activation patterns can be observed from these single-condition maps, the overall contrast of these patterns was low, and the differences between these maps were small. There were almost no differences for stimuli presented at different orientations (new Figure 1—figure supplement 1 D and E, or G and H). However, calculated from these similar single-condition response patterns, the difference maps are not similar: strong patterns can be observed in some maps (C, L), and weak (F) or no (I) patterns in others. Thus, single-condition maps here are not reliable for revealing the differences of activation patterns for different stimuli. This might be due to the diffused feature-non-specific hemodynamic responses in V4, blood vessel noise, and the reliance on blank activation. In addition, single-condition maps were more vulnerable to experimental factors like the anesthesia level, the general activation level of the preparation etc., which may vary from case to case. Thus, we choose to rely on difference maps in this study.</p><disp-quote content-type="editor-comment"><p>That would also potentially help in investigating to what extent these responses can be explained by simple receptive field (RF) summation. For instance, there is a substantial literature in associating preferential responses to curves with end-stopped neurons: Hubel and Wiesel, in 1965 suggested that end-stopped, length tuned neurons could be useful for curvature detection and there was a nice explicit model of how that could happen by Dobbins et al. in 1987. But the manuscript makes little reference to any size tuning or surround suppression, and how that, in combination with classic orientation tuning, could create a cell that responds vigorously to curvature. This is even a greater concern given the well-established prevalence of size tuning, both electrophysiologically (1987) and with optical imaging (1997), in area V4. This has a huge impact on both novelty and interpretability; if you have a region of surround suppression (which we know exist) and it overlaps with an orientation region, this can look like a &quot;curvature&quot; region in that it will respond to a curve better than extended straight line or grating. But we would argue it's not a &quot;curvature&quot; region, since a short bar or grating without any curvature is actually the optimal stimulus. For example, can the response to triangles, on a pixel by pixel basis, be explained by simply adding or averaging the response the constituent orientations? Similarly, can the circle responses be explained by adding the responses to the half-circles?</p></disp-quote><p>The reviewer’s question is two-fold: First, at single-cell level, whether end-stopping properties can account for the neuron’s curvature responses we observed. We have shown that curvature neurons had smaller RFs than those of non-curvature neurons (Figure 3—figure supplement 1D and E). In this revision, we further analyzed and showed that curvature neurons had stronger surround suppression (Figure 3—figure supplement 1H and I). Thus, consistent with previous findings, curvature neurons did exhibit end-stopping properties. However, curvature neurons showed additional curve-specific preferences, including curve-orientation tuning, preference for curves over similarly-sized angle stimuli, etc. For circle-preferring neurons, they prefer circles (larger) than the half-circles (smaller). These additional features suggest that curvature neurons were not simple end-stopping neurons, although they exhibited end-stopping properties.</p><p>The same question was asked at the functional domain level, i.e., whether the curvature domains could be the overlap regions of orientation domains and surround-suppression regions in V4. In this study, curvature domains were revealed in difference maps, including: circles vs. triangles (Figure 1D), circles vs. bars (Figure 1G), curves vs. bars (Figure 1H), and curves vs. angles (Figure 1—figure supplement 2L). The two stimuli in each pair had similar sizes, and thus had similar surround suppression effects. Their contrast pattern in the difference maps could not be due to differences in suppression. The stimuli on the two sides also had balanced orientations, plus their maps had little overlap with the orientation maps (Figure 2D). The only consistent contrasts in these pairs of stimuli was the curvature feature. Thus, the curvature domains we found are unlikely the overlap regions of suppression and orientation domains.</p><disp-quote content-type="editor-comment"><p>2) To support the 2-photon results with convincing anatomical images.</p><p>One technical issue is the lack of any good underlying anatomical images to support the 2-photon data. This is concerning because all the images provided here show cells that are filled in, but living cells should appear as rings representing the cell membrane. Filled in cells are dead or compromised, and this would be a critical caveat for all the response results reported here. All of the cells in Figure 3C-F appear to be filled in. This could be because (i) these images do not have sufficient resolution to show rings, (ii) the authors did some kind of smoothing of these images (smoothing is mentioned in Materials and methods), or (iii) the cells are filled with calcium, reflecting a dead or compromised state. This concern is further exacerbated by the strange cell shapes in Figures 4G and H and 5A, D, and G. The authors should show the underlying anatomical images for those panels and explain how they defined the odd shapes shown in them. In addition to showing anatomical images, the authors should quantify how many cells are filled or ring-like in their images, and clarify whether the cells for which they report tuning include filled cells (and how many).</p></disp-quote><p>Neurons in Figure 3C looked like filled was mainly due to the small size of the figure and the narrow clip range. In <xref ref-type="fig" rid="respfig1">Author response image 1</xref> we enlarged Figure 3C in panel A and also provided a larger clip-range version of the same image (panel B). It can be seen that most cell bodies appear ring-like.</p><fig id="respfig1"><label>Author response image 1.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57502-resp-fig1-v2.tif"/></fig><p>GCaMP is expressed in the plasma and usually does not go into the nucleus (Tian et al., 2009; Chen et al., 2013). Thus, in ideal condition (the imaging focal plane cuts through the cell nucleus), the cells appear as rings. For neurons located slightly off the imaging focal plane, and their nucleus are not cut by the focal plane, the cells will also appear as smaller filled patches. In addition, Figure 3C was an average of all the frames over an experimental session, the preparation usually had some drift along the Z axis, the ring-like appearance will also be blurred due to this reason.</p><p>Fluorescent response images (e.g. Figure 3 D-E) were based on incremental fluorescence changes at the stimulus onset. Neurons in these images usually had responses at the center and appeared less ring-like. This fact, plus the smoothing procedure in cell identification (described in Materials and methods), made the final cell images filled shapes (e.g. Figure 5 G and H).</p><p>There were indeed some neurons having a high baseline fluorescence but weak visual responses. Since our cell identification was based on neurons’ onset responses, these neurons would not pass the significance test for further analysis.</p><p>Based on fluorescent responses, many identified neurons did not have a circular shape. This was mainly due to the shape of their fluorescence responses and/or the responses from attached fibers imaged in the same focal plane.</p><disp-quote content-type="editor-comment"><p>3) The reviewers would like to see more systematic and consistent analysis and representation across Figures 4. and 5 that allows the reader to better understand the fundamental, underlying tuning properties of neurons.</p><p>A technical concern is that Figure 4 and Figure 5 appear to present the same phenomena, but with different analyses for different images. Figure 4G labels neurons according to whether they exhibited stronger responses to circles or arcs. Figure 5 distinguishes neurons by how closely they are correlated with the average response pattern for the local curvature domain. But the examples in Figures 5B,C,E,F,H,I make it clear that the differences between correlated and not correlated again have to do with relative responses to circles vs. arcs. All of these images in Figures 4 and 5 need to be analyzed in the same ways, with an emphasis on the more explanatory analyses related to tuning, rather than unexplained correlation.</p></disp-quote><p>We agree that the analysis in the original Figure 4 and 5 had some overlap on the same phenomena (i.e. different neurons responded differently to circles and arcs). In the revision, we replaced the original Figure 5 with a new figure (Figure 6) showing response matrices of neighboring neurons in 3 small regions (a circle subdomain, a curve-orientation subdomain, and a rectilinear region). These raw response patterns contain richest information, from which both commonality and diversity of the responses for the neighboring neurons can be observed.</p><disp-quote content-type="editor-comment"><p>In relations to the tuning properties underlying the impressive 2-photon data, the question arises to what extent can RF summation (for example, RF summation models that include non-linearities that have been applied to V4) explain responses across the stimulus array?</p></disp-quote><p>Due to the scope of this study, we have not evaluated the RF summation model in explaining the responses we observed. We agree, however, that this is an important question and needs to be explored. Based on our limited stimulus set, we observed complex response patterns for different neurons. Even for the neighboring neurons, they exhibited significant differences (Figure 6). Such a complexity seems difficult to be fully explained by a RF summation model. A recently study used a neural network approach and synthesized stimulus patterns that can maximally drove V4 neurons (Bashivan et al., 2019). These “optimal” stimulus patterns revealed complex RF structures of V4 neurons and suggest that additional complexity needs to be included in V4 RF modeling.</p><disp-quote content-type="editor-comment"><p>See also point 4 below, in relation to this issue of the underlying tuning properties of neurons.</p><p>4) To reanalyze both datasets (intrinsic optical imaging and 2-Photon) in light of what is well-known about V4 tuning for fragments, not whole shapes, for curvature acuteness (which means responses to triangles reflect high curvature acuteness tuning) and object-relative position of contour fragments (which explains the differences between &quot;circle&quot; neurons and &quot;curve&quot; neurons, as well as the difference between triangle responses and angle responses, most of which we do not get to see). This should radically change the interpretation of Figures 1 and 2, and change the analysis emphasis of regions in the 2-photon section of the paper.</p><p>The major technical and interpretational concern is that differences between response patterns throughout the paper are presented as though the neurons were tuned for circles in some cases, arcs in others, triangles in others, etc. This ignores well-established tuning dimensions in V4 that explain response patterns like these at a more basic level. Pasupathy and Connor, 1999; 2001 and 2002 and Carlson et al. (2011, Current Biology) clearly demonstrated that:</p><p>i) V4 neurons respond to contour fragments, not complete shapes,</p><p>ii) V4 neurons are strongly tuned for the object-relative position of those contour fragments,</p><p>iii) V4 neurons are tuned for curvature acuteness, with a bias toward sharp curvatures,</p><p>iv) V4 neurons are differentially tuned for convexity and concavity.</p><p>By ignoring this literature, the authors might misinterpret many of their results:</p><p>a) In Figures 1 and 2, responses to triangles are treated as representative of non-curvature regions. But, per point (iii) above, the points of those triangles will drive strong responses from the most acute curvature tuning regions. Thus, the curvature/triangle contrasts are more likely to represent organization for broad curvature vs. acute curvature (angles are geometrically just the limiting case of acute curvature) than a difference between curvature and straight lines. The same is true for line segments, whose terminations drive weaker but similar responses, and which show only weak differences from triangles and angles. The only valid contrast for finding curvature domains is curves vs. gratings, which reveals very different regions than triangles in Figure 1. This reliance on circle vs. triangle contrast has ramifications throughout the paper, because it is used to define curvature domains and thus bias the 2-photon studies away from regions of acute curvature tuning.</p></disp-quote><p>It is potentially possible that triangles we used in Figure 1 and 2 might represent acute curvatures and not for “rectilinear contour” representations. However, we found this was not the case after we examined many comparison maps. The responses to triangles were similar to those to short lines. For example, the triangle vs. straight line map was weak (Figure 1J), and the circle vs. triangle map and circle vs. straight line map were similar (Figure 1D, G). These indicate that responses elicited by triangles were mostly due to their line component, not the sharp angle component.</p><p>Following the reviewer’s suggestion, we compared “circle vs. gratings”, and “circle vs. triangle” maps (A and B in <xref ref-type="fig" rid="respfig2">Author response image 2</xref>). In these two maps, the curvature domains were found at the similar locations. Thus, the V4 responses to the triangles were primarily driven by their straight-line components, not by their sharp angles. The weak contrast in “triangle vs. gratings” map (<xref ref-type="fig" rid="respfig2">Author response image 2C</xref>) also indicates the similarity of these two types of responses.</p><fig id="respfig2"><label>Author response image 2.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57502-resp-fig2-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>b) A similar problem appears in Figure 3, where the only response shown for the &quot;rectilinear&quot; region is a highly selective response for a triangle. Per point (ii) above, triangles provide a whole object context in which V4 neurons can exhibit their strong tuning for object-relative position of contour fragments, including high-curvature angles. This is why neuron 3 does not respond to any other rectilinear stimulus. If triangle responses like this are the basis for the green regions in Figure 3, then those regions are acute curvature regions, not non-curvature regions, and again the authors will be excluding high-curvature regions from their analyses in Figures 4 and 5.</p></disp-quote><p>We thank the reviewer for pointing this out. We re-examined cell 3 in the original Figure 3P and found that, in addition to its response to triangle, this cell did respond to line segments oriented in 45 degrees. The original figure did not include this stimulus due to the space limitation. Now we have expanded the figure and included this and other relevant stimuli (new Figure 3F). Thus, the triangle responses of this neuron were likely driven by the 45-degree line segment in the triangle, instead of its high-curvature angles. More examples neurons from the rectilinear regions were provided in a new figure (Figure 6C) in which similar responses patterns were observed.</p><p>Population-wise, neurons that responded better to bars than to curves were more likely located in the “rectilinear” regions in ISOI imaging (old Figure 3R, new Figure 4K).</p><p>Thus, consistent with the findings in ISOI results (see answers to reviewer’s question “a” above), the 2-photon results also indicate that, although triangle stimuli were used to map the rectilinear regions, neurons in these regions were mainly driven by the line segments of the rectilinear stimuli, not their sharp angles.</p><disp-quote content-type="editor-comment"><p>c) Per above, Figures 4 and 5 are restricted to clusters of broader curvature tuning, strongly biasing the analyses. This is undoubtedly one reason that many example neurons respond strongly to circles. The other major problem with these figures is that they are presented as evidence that many neurons in V4 are strongly selective for circles as whole stimuli, while others are strongly selective for arcs over circles. In fact, the references cited above make clear that neurons in V4 are invariably tuned for shape fragments (i), not whole shapes, and they are strongly tuned for fragment position within shapes (ii). This is why many neurons respond most strongly to circles, because they are tuned for an arc-shaped fragment, but respond much more strongly when that fragment is in the preferred object-relative position. This is frequently true for circles, because there is also a strong correlation between curvature orientation tuning and object position tuning, since convex curves pointing up usually occur at the top of an object; curves pointing to the right occur at the right, etc. In many other cases, however, the preferred object-relative position is off angle, and when that is true the responses to circles will be low, and the responses to isolated arcs will be higher. (Responses to an entire shape with the arc at the preferred position would be higher still.) Thus, differential tuning for object-relative position explains most of the differences highlighted in Figures 4 and 5.</p></disp-quote><p>The reviewer’s main concern here is that we separated curvature neurons into two sub-groups (circle-preferring and curve-orientation-preferring neurons), and why the circle responses were not explained in terms of position-related curvature responses.</p><p>We separated circle-preferring neurons from curve-orientation neurons based on two observations: First, these two sets of neurons formed separated spatial clusters on V4 surface (Figure 5 G and H) and differed in their curve orientation tunings. Second, as we can observe from the response matrices in the new Figure 6, that neurons in the circle subdomains (Figure 6A) responded best to circles, but very weakly to any of the half circles (the third, fourth columns from the right). Note that we used 8 orientations here instead of 4 in other shapes, thus likely covered all possible orientations. These neurons also appeared to have a gradual increase of responses to the completeness of the circle (from the right-most column to the middle). In addition, they all had modest responses to closed contour shapes (the four columns left to the circle). These closed shapes do not share any similar curve fragment, but have the closeness as a common feature. In particular, these neurons responded better to the offset-paired half circles (the second column on the right of the circle) than to the single half circles. Population results shown in Figure 5 K and L also confirm the above observation. These features were not easily explained by the selectivity to a curve fragment with a certain object-relative position.</p><p>Considering that these small patches of neurons were located in domains identified with ISOI and only occupied a small fraction of V4 surface, it is possible that these neurons were not well represented in the previous single-unit recordings.</p><disp-quote content-type="editor-comment"><p>5) To support the 2-photon data, which surveys properties in a large number of cells, a comprehensive, more clearly structured data summary is required.</p><p>Apart from the issue raised above, the summary statements of the 2-Photon data are not particularly satisfying: the categories of orientation and curve-orientation are not very enlightening about underlying principles. Perhaps PCA analysis could be used to see the patterns of selectivity that are prevalent across the sample (perhaps after selecting the best orientation or collapsing across orientation). Another possibility would be, after rotating to a common best orientation, to superimpose all the stimuli with an opacity relating the firing rate. In the end this seems like a lost opportunity to follow up the influential Hegde and Van Essen, 2000, studies whose stimulus set parallels the one used here.</p></disp-quote><p>We thank the reviewer for this suggestion. We did PCA analysis on all the neurons’ responses (n=1556). The results were shown as new Figure 4—figure supplement 1. This data-driven analysis also reveals different response patterns for neurons inside and outside the curvature domains, which further confirmed our ISOI findings. We also performed PCA analysis on neurons inside curvature domains and found that circle neurons and curve-orientation neurons could also be separated by their PC coordinates (Figure 5—figure supplement 1).</p><disp-quote content-type="editor-comment"><p>6) Incorporating any new results from the analyses above, the underlying major concepts need to be more consistently defined and applied across the paper.</p><p>Related to the technical issues raised above (points 3-5), the terminology in the manuscript is sometimes confusing. The authors propose that there is “microarchitecture” of selectivity for circles vs. curves. But then they appear to contradict themselves. For example (final paragraph of subsection “Microarchitectures of the curvature domains”) the authors talks of neurons having “preferred curve” stimuli; and in the same section, (Figure 4K) the authors state that these same neurons respond more strongly to circles than to their preferred curves. What does it mean to be selective for a “preferred curve” if the response to the “preferred” stimulus is consistently weaker than to a different stimulus?</p></disp-quote><p>We agree that the original categorization was not clear. In the revision, we have separated the “dual-preference neurons” from the “curve-orientation-preference neurons” so that these neurons do not have overlaps. We revised the figure (new Figure 5 G, I, J) and the relevant text accordingly.</p><disp-quote content-type="editor-comment"><p>7) Please clarify the definition of curvature domains and examine their periodicity</p><p>Another technical issue is the poor description of how curvature domains were defined and drawn. The &quot;watershed&quot; technique should be described in detail, and the domains should be drawn on the sections, especially the sections in Figure 5, where the domain boundaries determine the average response pattern.</p></disp-quote><p>In most part of this manuscript, curvature domains were obtained with a threshold (gray level lower than 0-2SD) on the circle vs. triangle map (e.g. Figure 1D). Domain coverage in Figure 2D and the neuron classification in Figure 4 and 5 (original figures) were all based on this method.</p><p>Only in estimating domain sizes (Figure 2E), we used watershed method in order to deal with the “connected domain” problem, in which two or more domains were connected and multiple peaks existed. With watershed method, each time we found the strongest domain, fill this domain with the threshold values and moved on to find the next strongest domain. This process was repeated until all domains were identified. We have added the details of watershed method in the Materials and methods section.</p><disp-quote content-type="editor-comment"><p>Given the limited spatial sampling with 2-photon imaging, distance correlations metrics with the intrinsic optical imaging reflectance data (using the above requested single condition activity maps) would be nice to examine the periodicity of horizontal organization patterns. Given the stimulus array is that used in the 2-photon data, the absolute value of correlations is going to be different, but the key issue here is the spacing and size of &quot;columns&quot; and whether that depends on the type of stimulus you're looking at.</p><p>What bandpass filtering is used for intrinsic optical images (since that can &quot;create&quot; domains out of noise)? Can Fourier analysis be used to describe the size and spacing of domains?</p></disp-quote><p>We thank the reviewer’s suggestion. We have analyzed domain spacing and size with a domain-averaging method. In circle-triangle maps (e.g. Figure 1D), we located the peaks of each curvature domains and averaged all these domains with their peaks aligned. We did the same analysis on orientation domains based on the orientation maps (e.g. Figure 1E). The map in <xref ref-type="fig" rid="respfig3">Author response image 3</xref> shows the average maps for curvature domains (n=142) and orientation domains (n=218). We also plotted the normalized gray-level profiles of these two maps in panel C for comparison. The sizes of these two domains were very similar, which is consistent with the domain size results we obtained with a fitting method (Figure 2E). The length of the blue arrow is 0.518 mm, which is the measured curvature-domain size using a fitting method in the paper. It is approximately equal to the half-height width of the profile curves. Some details also can be observed from these profiles. For example, for orientation domain, there was a suppressive white ring around the black domain (diameter 1.17 mm), indicating there were opposite domains right next to these orientation domains (domains preferring orthogonal orientations). However, such feature was absent in the averaged curvature domain, suggesting that its opposite domains (rectilinear domains) were either not prominent or not adjacent.</p><fig id="respfig3"><label>Author response image 3.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-57502-resp-fig3-v2.tif"/></fig><p>Above results were obtained from difference maps. As we showed in <xref ref-type="fig" rid="respfig1">Author response image 1</xref>, the signal-noise ratio in single-condition maps were too low to be analyzed with this method. We also tried Fourier analysis but the results were not as clear as those described above.</p><p>For the bandpass filter question the reviewer asked, we only used a small low-pass Gaussian filter (diameter: 5 pixels, SD: 1 pixel) to smooth the original ISOI maps. No high-pass filter was used. This procedure is unlikely to create domains out of noises.</p><disp-quote content-type="editor-comment"><p>8) There are also a number of places where the primary narrative of the paper seems to contradict itself. For example: starting with the Abstract, the authors make the important observation that “curvature” domains have “little overlap” with “orientation domains”. They repeat this point, e.g. in the Results; and again, in the legend of Figure 3H,: with clearly distinct “curvature” and “rectilinear” zones. On the other hand, the authors also make a point of saying that individual neurons have mixed responses – with individual neurons in “curvature” domains responding well to rectilinear contours (e.g. Figure 3P). The authors further amplify the issue of response diversity in Figure 5, with nearest-neighbor neurons showing strikingly different response. The authors should rewrite the Abstract and the relevant sections of the results to have a more consistent description of the degree of overlap and response diversity that they observe.</p></disp-quote><p>We took the reviewer’s advice and revised the narrative in Abstract and Results to make the meaning more consistent. We have also included new analysis (Figure 5 K and L, Figure 7) and examples of individual neuron’s response patterns (Figure 6) to better describe the seemly contradicting features.</p><disp-quote content-type="editor-comment"><p>9) While these results are very interesting, they are of course restricted to a limited set (73?) of human-selected and human-curated stimuli. Nowhere does the analysis address the question as to whether these are close to the optimal stimuli for this region of cortex, even in the (unnatural) anesthetized state. The authors should have a more expanded discussion of these limitations, and how to extend the analysis further to get a sense of the “optimal” stimuli for this stage of cortical processing.</p></disp-quote><p>We agree that the stimulus set we used is simple and limited, and could not address the “optimal stimulus” problem. In the revised Discussion (the second last paragraph), we described these limitations and our thoughts on how to improve estimation of “optimal stimuli”.</p><disp-quote content-type="editor-comment"><p>Furthermore, the stimulus set used parallels that used by Hedge and Van Essen, 2000, in V4, and subsequently in V1 and V2 as well. Given that we know that selectivity’s exist that cannot simply be explained by orientation filters, the paper could do a better job of emphasizing what is new and, in particular, the significance of finding functional organization. If, for example, the authors feel that the presence of functional organization for a particular parameter is especially important in understanding the computations that occur within in an area, or in the broader picture, the role that area plays in visual processing, they should state so, and why they believe this.</p></disp-quote><p>These issues should be discussed and laid out appropriately.</p><p>We thank the reviewer’s suggestions. In the revised Discussion (the last paragraph), we discussed more on the significance of the finding of functional organization and our reasons.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Revisions:</p><p>The authors have done an exemplary job in the revision, by addressing concerns raised and adding further analyses (clustering of single-cell-level response; PCA; more extended comparisons across classes of similar stimuli such as triangles / short oriented lines, as vs. circles / arcs; scaled to different sizes; filled / unfilled). Overall, these new analyses along with their original combination of intrinsic optical imaging and 2-photon imaging, showing the close spatial match between clusters identified separately by the two techniques make a compelling case for the specialised architecture the authors propose in the Discussion. There remain a small number of issues that would need to be addressed.</p><p>1) One disappointment is that some of the authors' responses didn't actually make into the manuscript or are &quot;buried&quot; in multi-panel supplementary figures. Specifically, the significance of relationship between surround suppression and curvature, and the PCA analysis (which proved interesting) are not particularly clear in the actual text of the manuscript. Also in light of some of the new analyses, the authors should probably cite some relevant literature about the existence of &quot;sub-domain&quot; specificity with domain-specific regions.</p></disp-quote><p>We added surround suppression and PCA results into the main text (new Figure 4L and M, new Figure 5). We also discussed relevant findings about “sub-domains” in different domain-specific regions and cite the relevant papers (first paragraph in Discussion).</p><disp-quote content-type="editor-comment"><p>2) The direct correspondence between intrinsic and 2-photon imaging is certainly positive (correlation coefficients &gt; 0), but remarkably poor (and less than one), especially given that, for many experiments, intrinsic maps are seen as veridical and generally have good correspondence with targeted electrophysiology recordings. We noticed in the response letter that all intrinsic maps were Gaussian blurred, if one does the same procedure to the 2-photon data, does the correlation improve? And, if not, what explains this result: perhaps, significant noise in one type of measurement, or more interestingly, a true lack of correspondence between haemodynamics and cellular level responses. If the later, that's a big deal given: it potentially suggests that all haemodynamic maps should be taken with &quot;a grain of salt&quot; with regards to reflecting neuronal response property organization. And of course, if this is true, and intrinsic imaging is that noisy, it potentially calls into question many of the intrinsic signal difference maps and results even within this manuscript. This needs to be explicitly addressed.</p></disp-quote><p>The correlation between ISOI and 2-photon results shows a general consistency, e.g. the overall similarity between two types of maps (maps in Figure 4A-I). The relatively low correlation values (r=0.42, 0.43) in Figure 4J and K may due to the nature of the signals in these two imaging methods. Specifically, 2-photon signals contained substantial diversity in neighboring neurons’ responses to the same contours (new Figure 7), while such diversity was not reflected in the hemodynamic signals. Due to optical blurring and the nature of the hemodynamical signal, ISOI maps were much blurred than 2-photon maps. The 5x5-Gaussian-bluring was to reduce the grainy noise before the alignment. In Figure 4J and K, a cell’s 2-photon response was averaged from all pixels that the cell body covered (&gt; 30 pixels), thus, a further 5x5 filtering would not make much differences.</p><p>Thus, we think both technical factors (nature of the signals) and intrinsic diversity (cell-cell diversity) contribute to the relatively poor correlations between the two types of maps.</p><disp-quote content-type="editor-comment"><p>3) More discussion in the actual manuscript about surround suppression, and specifically the points that appear in the authors' response, would be good. This is especially important, because surround suppression has long been associated with V4 responses, and there have been claims that it is functionally organized. The authors' remarks in the response about the only things the difference maps having is common is curvature is probably the best that can be made with the current data set. But, on the other hand, given the strong differences in surround suppression and receptive field size shown in the supplementary figures, that previous reports of surround suppression and its organization in V4 might simply reflect curvature regions that were studied with inappropriate sub-optimal stimuli.</p></disp-quote><p>In the revised manuscript, we added surround suppression results into the main text and discussed how these results relevant to the previous findings (the eighth paragraph in Discussion).</p><p>Many studies have shown strong surround suppression in area V4. One of them also revealed a functional structure (S regions) associated with this feature (Ghose and Ts’o 1997). Although curvature domains have common properties as those S regions (stronger surround suppression), these two types of domains are unlikely the same. First, stimuli produce S regions did not contain any curviness, while curvature domains were only obtained with curvatures. Second, surround suppression is a more fundamental property than curvature preference. Although curvature neurons showed surround suppression, not all surround-suppressive neurons are curvature neurons. In area V4, surround suppression likely also involves, for example, texture, color, motion etc, in addition to contour shapes. Thus, we believe V4 surround suppression domains are independent domains that deserves further exploring.</p><disp-quote content-type="editor-comment"><p>4) This is a really large data set of cellular responses, and the PCA analyses are really important, but again, it would be better for this to appear in the actual manuscript.</p><p>One reason in particular is the paper's discussion of &quot;microorganization&quot; or sub-domains within a curvature region. We found these discussions a little anecdotal, and we were wishing that a spatial autocorrelation analysis could be done with pairs of neurons as function of distance to reveal how big a &quot;sub-domain&quot; was, and in particular, how it compared with orientation columns, which of course are sub-domains within the rectiiinear domains. For example, what one could do with regard to PCA weights: PCA1 spatial autocorrelation. In a similar vein, there have been several reports of color-specific sub-domains with color-preference domains, and, especially given the classic association of V4 with color sensitivity, that literature seems relevant here in a discussion of how universal domain/sub-domain organization may be and its variation between different cortical areas.</p></disp-quote><p>We took the reviewers’ advice and analyzed the spatial periodicity of the sub-domains inside curvature domains. Specifically, we calculated the correlation of curve-orientation tuning of cell pairs inside the curvature domains, based on their responses to the 8 half-circle curves. Figure 6—figure supplement 2 plots how such correlation values vary with the cell-pair distance. It shows a trough around 360 μm and a second peak around 720 μm. Thus, the subdomain size is around 360 μm and the periodicity is around 720 μm. We had added this finding into the Results and discussed in Discussion. We did not use PCA results for such analysis since the curve-orientation was sorted before the PCA analysis.</p><disp-quote content-type="editor-comment"><p>5) Scaling of the intrinsic signal optical images. The authors' methods suggest that the SD used for the gray scale is calculated separately for each (SVM) map. Is that correct? If so, there is no way to compare the strengths of activation by different stimuli. It likely also explains why the single-condition maps (e.g. Figure 1—figure supplement 1, panels A,B,D,E,G,H) appear not only relatively featureless but also occupying a grayscale range similar to the backgrounds of the difference images. In absolute terms, the single-condition responses presumably are ~ an order of magnitude higher amplitude if they are dominated by stimulus-nonspecific haemodynamic responses? Showing the single-condition and difference images on the same absolute scale would be uninformative. But it would be useful to show all the difference images on a common scale that is not tied to the SD per image, to get a sense of the efficacies of different stimulus pairwise differences. This could be done as an additional set of panels in supplementary figures.</p></disp-quote><p>Different scaling methods (individual or common) were normally used for revealing different aspects of the map signals. Individual scaling is better at revealing spatial features, while common scaling can be used for signal strength comparisons.</p><p>In our manuscript, we used SVM maps, which was obtained through a non-linear process. The value of individual SVM pixel was proportional to its contribution to classification. Thus, it is not a simple representation of signal strength. Considering this, we used individual clipping to emphasize the spatial features of the domains. For analysis where comparing signal strengths were needed (e.g. Figure 2F), we used raw dR/R values instead of the SVM pixel values. We also tried a uniform clipping for Figure 1, the general appearance was similar to the individually clipped one in the manuscript.</p></body></sub-article></article>