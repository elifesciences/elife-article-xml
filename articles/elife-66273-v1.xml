<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">66273</article-id><article-id pub-id-type="doi">10.7554/eLife.66273</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Evolving interpretable plasticity for spiking networks</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" equal-contrib="yes" id="author-220986"><name><surname>Jordan</surname><given-names>Jakob</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3438-5001</contrib-id><email>jakob.jordan@unibe.ch</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-195305"><name><surname>Schmidt</surname><given-names>Maximilian</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1040-2567</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-224156"><name><surname>Senn</surname><given-names>Walter</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-3622-0497</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund7"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-224157"><name><surname>Petrovici</surname><given-names>Mihai A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2632-0427</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Department of Physiology, University of Bern</institution><addr-line><named-content content-type="city">Bern</named-content></addr-line><country>Switzerland</country></aff><aff id="aff2"><label>2</label><institution>Ascent Robotics</institution><addr-line><named-content content-type="city">Tokyo</named-content></addr-line><country>Japan</country></aff><aff id="aff3"><label>3</label><institution>RIKEN Center for Brain Science</institution><addr-line><named-content content-type="city">Tokyo</named-content></addr-line><country>Japan</country></aff><aff id="aff4"><label>4</label><institution>Kirchhoff-Institute for Physics, Heidelberg University</institution><addr-line><named-content content-type="city">Heidelberg</named-content></addr-line><country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>van Rossum</surname><given-names>Mark CW</given-names></name><role>Reviewing Editor</role><aff><institution>University of Nottingham</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution>Brown University</institution><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>28</day><month>10</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e66273</elocation-id><history><date date-type="received" iso-8601-date="2021-01-05"><day>05</day><month>01</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2021-08-19"><day>19</day><month>08</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Jordan et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Jordan et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-66273-v1.pdf"/><abstract><p>Continuous adaptation allows survival in an ever-changing world. Adjustments in the synaptic coupling strength between neurons are essential for this capability, setting us apart from simpler, hard-wired organisms. How these changes can be mathematically described at the phenomenological level, as so-called ‘plasticity rules’, is essential both for understanding biological information processing and for developing cognitively performant artificial systems. We suggest an automated approach for discovering biophysically plausible plasticity rules based on the definition of task families, associated performance measures and biophysical constraints. By evolving compact symbolic expressions, we ensure the discovered plasticity rules are amenable to intuitive understanding, fundamental for successful communication and human-guided generalization. We successfully apply our approach to typical learning scenarios and discover previously unknown mechanisms for learning efficiently from rewards, recover efficient gradient-descent methods for learning from target signals, and uncover various functionally equivalent STDP-like rules with tuned homeostatic mechanisms.</p></abstract><abstract abstract-type="executive-summary"><title>eLife digest</title><p>Our brains are incredibly adaptive. Every day we form memories, acquire new knowledge or refine existing skills. This stands in contrast to our current computers, which typically can only perform pre-programmed actions. Our own ability to adapt is the result of a process called synaptic plasticity, in which the strength of the connections between neurons can change. To better understand brain function and build adaptive machines, researchers in neuroscience and artificial intelligence (AI) are modeling the underlying mechanisms.</p><p>So far, most work towards this goal was guided by human intuition – that is, by the strategies scientists think are most likely to succeed. Despite the tremendous progress, this approach has two drawbacks. First, human time is limited and expensive. And second, researchers have a natural – and reasonable – tendency to incrementally improve upon existing models, rather than starting from scratch.</p><p>Jordan, Schmidt et al. have now developed a new approach based on ‘evolutionary algorithms’. These computer programs search for solutions to problems by mimicking the process of biological evolution, such as the concept of survival of the fittest. The approach exploits the increasing availability of cheap but powerful computers. Compared to its predecessors (or indeed human brains), it also uses search strategies that are less biased by previous models.</p><p>The evolutionary algorithms were presented with three typical learning scenarios. In the first, the computer had to spot a repeating pattern in a continuous stream of input without receiving feedback on how well it was doing. In the second scenario, the computer received virtual rewards whenever it behaved in the desired manner – an example of reinforcement learning. Finally, in the third ‘supervised learning’ scenario, the computer was told exactly how much its behavior deviated from the desired behavior. For each of these scenarios, the evolutionary algorithms were able to discover mechanisms of synaptic plasticity to solve the new task successfully.</p><p>Using evolutionary algorithms to study how computers ‘learn’ will provide new insights into how brains function in health and disease. It could also pave the way for developing intelligent machines that can better adapt to the needs of their users.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>metalearning</kwd><kwd>learning to learn</kwd><kwd>synaptic plasticity</kwd><kwd>spiking neuronal networks</kwd><kwd>genetic programming</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000780</institution-id><institution>European Commission</institution></institution-wrap></funding-source><award-id>604102</award-id><principal-award-recipient><name><surname>Jordan</surname><given-names>Jakob</given-names></name><name><surname>Senn</surname><given-names>Walter</given-names></name><name><surname>Petrovici</surname><given-names>Mihai A</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000780</institution-id><institution>European Commission</institution></institution-wrap></funding-source><award-id>720270</award-id><principal-award-recipient><name><surname>Jordan</surname><given-names>Jakob</given-names></name><name><surname>Senn</surname><given-names>Walter</given-names></name><name><surname>Petrovici</surname><given-names>Mihai A</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000780</institution-id><institution>European Commission</institution></institution-wrap></funding-source><award-id>785907</award-id><principal-award-recipient><name><surname>Jordan</surname><given-names>Jakob</given-names></name><name><surname>Senn</surname><given-names>Walter</given-names></name><name><surname>Petrovici</surname><given-names>Mihai A</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001661</institution-id><institution>Universität Heidelberg</institution></institution-wrap></funding-source><award-id>Manfred Stärk Foundation</award-id><principal-award-recipient><name><surname>Petrovici</surname><given-names>Mihai A</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010548</institution-id><institution>National Centre for Supercomputing Applications</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Jordan</surname><given-names>Jakob</given-names></name><name><surname>Schmidt</surname><given-names>Maximilian</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000780</institution-id><institution>European Commission</institution></institution-wrap></funding-source><award-id>800858</award-id><principal-award-recipient><name><surname>Jordan</surname><given-names>Jakob</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000780</institution-id><institution>European Commission</institution></institution-wrap></funding-source><award-id>945539</award-id><principal-award-recipient><name><surname>Jordan</surname><given-names>Jakob</given-names></name><name><surname>Senn</surname><given-names>Walter</given-names></name><name><surname>Petrovici</surname><given-names>Mihai A</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Artificial evolution discovers biophysically plausible plasticity rules for spiking networks that perform competitively with and even outperform labor-intensive human-designed models in various learning scenarios, while providing new views on experimental data.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>How do we learn? Whether we are memorizing the way to the lecture hall at a conference or mastering a new sport, somehow our central nervous system is able to retain the relevant information over extended periods of time, sometimes with ease, other times only after intense practice. This acquisition of new memories and skills manifests at various levels of the system, with changes of the interaction strength between neurons being a key ingredient. Uncovering the mechanisms behind this synaptic plasticity is a key challenge in understanding brain function. Most studies approach this monumental task by searching for phenomenological models described by symbolic expressions that map local biophysical quantities to changes of the connection strength between cells (<xref ref-type="fig" rid="fig1">Figure 1A,B</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Artificial evolution of synaptic plasticity rules in spiking neuronal networks.</title><p>(<bold>A</bold>) Sketch of cortical microcircuits consisting of pyramidal cells (orange) and inhibitory interneurons (blue). Stimulation elicits action potentials in pre- and postsynaptic cells, which, in turn, influence synaptic plasticity. (<bold>B</bold>) Synaptic plasticity leads to a weight change (<inline-formula><mml:math id="inf1"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:math></inline-formula>) between the two cells, here measured by the change in the amplitude of post-synaptic potentials. The change in synaptic weight can be expressed by a function <inline-formula><mml:math id="inf2"><mml:mi>f</mml:mi></mml:math></inline-formula> that in addition to spike timings (<inline-formula><mml:math id="inf3"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mtext>pre</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mtext>post</mml:mtext></mml:msub></mml:mrow></mml:math></inline-formula>) can take into account additional local quantities, such as the concentration of neuromodulators (ρ, green dots in A) or postsynaptic membrane potentials. (<bold>C</bold>) For a specific experimental setup, an evolutionary algorithm searches for individuals representing functions <inline-formula><mml:math id="inf4"><mml:mi>f</mml:mi></mml:math></inline-formula> that maximize the corresponding fitness function <inline-formula><mml:math id="inf5"><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi></mml:math></inline-formula>. An offspring is generated by modifying the genome of a parent individual. Several runs of the evolutionary algorithm can discover phenomenologically different solutions (<inline-formula><mml:math id="inf6"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>) with comparable fitness. (<bold>D</bold>) An offspring is generated from a single parent via mutation. Mutations of the genome can, for example, exchange mathematical operators, resulting in a different function <inline-formula><mml:math id="inf7"><mml:mi>f</mml:mi></mml:math></inline-formula>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66273-fig1-v1.tif"/></fig><p>Approaches to deciphering synaptic plasticity can be broadly categorized into bottom-up and top-down. Bottom-up approaches typically rely on experimental data (e.g., <xref ref-type="bibr" rid="bib2">Artola et al., 1990</xref>; <xref ref-type="bibr" rid="bib22">Dudek and Bear, 1993</xref>; <xref ref-type="bibr" rid="bib8">Bi and Poo, 1998</xref>; <xref ref-type="bibr" rid="bib61">Ngezahayo et al., 2000</xref>) to derive dynamic equations for synaptic parameters that lead to functional emergent macroscopic behavior if appropriately embedded in networks (e.g., <xref ref-type="bibr" rid="bib32">Gütig et al., 2003</xref>; <xref ref-type="bibr" rid="bib34">Izhikevich, 2007</xref>; <xref ref-type="bibr" rid="bib13">Clopath et al., 2010</xref>). Top-down approaches proceed in the opposite direction: from a high-level description of network function, for example, in terms of an objective function (e.g., <xref ref-type="bibr" rid="bib80">Toyoizumi et al., 2005</xref>; <xref ref-type="bibr" rid="bib20">Deneve, 2008</xref>; <xref ref-type="bibr" rid="bib40">Kappel et al., 2015</xref>; <xref ref-type="bibr" rid="bib45">Kutschireiter et al., 2017</xref>; <xref ref-type="bibr" rid="bib73">Sacramento et al., 2018</xref>; <xref ref-type="bibr" rid="bib30">Göltz et al., 2019</xref>), dynamic equations for synaptic changes are derived and biophysically plausible implementations suggested. Evidently, this demarcation is not strict, as most approaches seek some balance between experimental evidence, functional considerations and model complexity. However, the relative weighting of each of these aspects is usually not made explicit in the communication of scientific results, making it difficult to track by other researchers. Furthermore, the selection of specific tasks to illustrate the effect of a suggested learning rule is usually made only after the rule was derived based on other considerations. Hence, this typically does not consider competing alternative solutions, as an exhaustive comparison would require significant additional investment of human resources. A related problem is that researchers, in a reasonable effort to use resources efficiently, tend to focus on promising parts of the search space around known solutions, leaving large parts of the search space unexplored (<xref ref-type="bibr" rid="bib69">Radi and Poli, 2003</xref>). Automated procedures, in contrast, can perform a significantly less biased search.</p><p>We suggest an automated approach to discover learning rules in spiking neuronal networks that explicitly addresses these issues. Automated procedures interpret the search for biological plasticity mechanisms as an optimization problem (<xref ref-type="bibr" rid="bib4">Bengio et al., 1992</xref>), an idea typically referred to as meta-learning or learning-to-learn. These approaches make the emphasis of particular aspects that guide this search explicit and place the researcher at the very end of the process, supporting much larger search spaces and the generation of a diverse set of hypotheses. Furthermore, they have the potential to discover domain-specific solutions that are more efficient than general-purpose algorithms. Early experiments focusing on learning in artificial neural networks (ANNs) made use of gradient descent or genetic algorithms to optimize parameterized learning rules (<xref ref-type="bibr" rid="bib3">Bengio et al., 1990</xref>; <xref ref-type="bibr" rid="bib4">Bengio et al., 1992</xref>; <xref ref-type="bibr" rid="bib5">Bengio et al., 1993</xref>) or genetic programming to evolve less constrained learning rules (<xref ref-type="bibr" rid="bib6">Bengio et al., 1994</xref>; <xref ref-type="bibr" rid="bib69">Radi and Poli, 2003</xref>), rediscovering mechanisms resembling the backpropagation of errors (<xref ref-type="bibr" rid="bib46">Linnainmaa, 1970</xref>; <xref ref-type="bibr" rid="bib33">Ivakhnenko, 1971</xref>; <xref ref-type="bibr" rid="bib72">Rumelhart et al., 1985</xref>). Recent experiments demonstrate how optimization methods can design optimization algorithms for recurrent ANNs (<xref ref-type="bibr" rid="bib1">Andrychowicz et al., 2016</xref>), evolve machine learning algorithms from scratch (<xref ref-type="bibr" rid="bib70">Real et al., 2020</xref>), and optimize parametrized learning rules in neuronal networks to achieve a desired function (<xref ref-type="bibr" rid="bib14">Confavreux et al., 2020</xref>).</p><p>We extend these meta-learning ideas to discover free-form, yet interpretable plasticity rules for spiking neuronal networks. The discrete nature of spike-based neuronal interactions endows these networks with rich dynamical and functional properties (e.g., <xref ref-type="bibr" rid="bib21">Dold et al., 2019</xref>; <xref ref-type="bibr" rid="bib37">Jordan et al., 2019</xref>; <xref ref-type="bibr" rid="bib42">Keup et al., 2020</xref>). In addition, with the advent of non-von Neumann computing systems based on spiking neuronal networks with online learning capabilities (<xref ref-type="bibr" rid="bib58">Moradi et al., 2017</xref>; <xref ref-type="bibr" rid="bib16">Davies et al., 2018</xref>; <xref ref-type="bibr" rid="bib9">Billaudelle et al., 2019</xref>), efficient learning algorithms for spiking systems become increasingly relevant for non-conventional computing. Here, we employ genetic programming (<xref ref-type="fig" rid="fig1">Figure 1C,D</xref>; <xref ref-type="bibr" rid="bib44">Koza, 2010</xref>) as a search algorithm for two main reasons. First, genetic programming can operate on analytically tractable mathematical expressions describing synaptic weight changes that are interpretable. Second, an evolutionary search does not need to compute gradients in the search space, thereby circumventing the need to estimate a gradient in non-differentiable systems.</p><p>We successfully apply our approach, which we refer to as ‘evolving-to-learn’ (E2L), to three different learning paradigms for spiking neuronal networks: reward-driven, error-driven, and correlation-driven learning. For the reward-driven task, our approach discovers new plasticity rules with efficient reward baselines that perform competively and even outperform previously suggested methods. The analytic form of the resulting expressions suggests experimental approaches that would allow us to distinguish between them. In the error-driven learning scenario, the evolutionary search discovers a variety of solutions which, with appropriate analysis of the corresponding expressions, can be shown to effectively implement stochastic gradient descent. Finally, in the correlation-driven task, our method generates a variety of STDP kernels and associated homeostatic mechanisms that lead to similar network-level behavior. This sheds new light onto the observed variability of synaptic plasticity and thus suggests a reevaluation of the reported variety in experimentally measured STDP curves with respect to their possible functional equivalence.</p><p>Our results demonstrate the significant potential of automated procedures in the search for plasticity rules in spiking neuronal networks, analogous to the transition from hand-designed to learned features that lies at the heart of modern machine learning.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Setting up an evolutionary search for plasticity rules</title><p>We introduce the following recipe to search for biophysically plausible plasticity rules in spiking neuronal networks. First, we determine a task family of interest and an associated experimental setup which includes specification of the network architecture, for example, neuron types and connectivity, as well as stimulation protocols or training data sets. Crucially, this step involves defining a fitness function to guide the evolutionary search towards promising regions of the search space. It assigns high fitness to those individuals, that is, learning rules, that solve the task well and low fitness to others. The fitness function may additionally contain constraints implied by experimental data or arising from computational considerations. We determine each individual’s fitness on various examples from the given task family, for example, different input spike train realizations, to discover plasticity rules that generalize well (<xref ref-type="bibr" rid="bib12">Chalmers, 1991</xref>; <xref ref-type="bibr" rid="bib76">Soltoggio et al., 2018</xref>). Finally, we specify the neuronal variables available to the plasticity rule, such as low-pass-filtered traces of pre- and postsynaptic spiking activity or neuromodulator concentrations. This choice is guided by biophysical considerations, for example, which quantities are locally available at a synapse, as well as by the task family, for example, whether reward or error signals are provided by the environment. We write the plasticity rule in the general form <inline-formula><mml:math id="inf8"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>η</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, where η is a fixed learning rate, and employ an evolutionary search to discover functions <inline-formula><mml:math id="inf9"><mml:mi>f</mml:mi></mml:math></inline-formula> that lead to high fitness.</p><p>We propose to use genetic programming (GP) as an evolutionary algorithm to discover plasticity rules in spiking neuronal networks. GP applies mutations and selection pressure to an initially random population of computer programs to artificially evolve algorithms with desired behaviors (e.g., <xref ref-type="bibr" rid="bib43">Koza, 1992</xref>). Here, we consider the evolution of mathematical expressions. We employ a specific form of GP, Cartesian genetic programming (CGP; e.g., <xref ref-type="bibr" rid="bib57">Miller and Thomson, 2000</xref>; <xref ref-type="bibr" rid="bib54">Miller, 2011</xref>), that uses an indexed graph representation of programs. The genotype of an individual is a two-dimensional Cartesian graph (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, top). Over the course of an evolutionary run, this graph has a fixed number of input, output, and internal nodes. The operation of each internal node is fully described by a single function gene and a fixed number of input genes. A function table maps function genes to mathematical operations (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, bottom), while input genes determine from where this node receives data. A given genotype is decoded into a corresponding computational graph (the phenotype, <xref ref-type="fig" rid="fig2">Figure 2B</xref>) which defines a function <inline-formula><mml:math id="inf10"><mml:mi>f</mml:mi></mml:math></inline-formula>. During the evolutionary run, mutations of the genotype alter connectivity and node operations, which can modify the encoded function (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). The indirect encoding of the computational graph via the genotype supports variable-length phenotypes, since some internal nodes may not be used to compute the output (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). The size of the genotype, in contrast, is fixed, thereby restricting the maximal size of the computational graph and ensuring compact, interpretable mathematical expressions. Furthermore, the separation into genotype and phenotype allows the buildup of ‘silent mutations’, that is, mutations in the genotype that do not alter the phenotype. These silent mutations can lead to more efficient search as they can accumulate and in combination lead to an increase in fitness once affecting the phenotype (<xref ref-type="bibr" rid="bib57">Miller and Thomson, 2000</xref>). A <inline-formula><mml:math id="inf11"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:math></inline-formula> evolution strategy (<xref ref-type="bibr" rid="bib7">Beyer and Schwefel, 2002</xref>) drives evolution by creating the next generation of individuals from the current one via tournament selection, mutation and selection of the fittest individuals (see section Evolutionary algorithm). Prior to starting the search, we choose the mathematical operations that can appear in the plasticity rule and other (hyper)parameters of the Cartesian graph and evolutionary algorithm. For simplicity, we consider a restricted set of mathematical operations and additionally make use of nodes with constant output. After the search has completed, for example, by reaching a target fitness value or a maximal number of generations, we analyze the discovered set of solutions.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Representation and mutation of mathematical expressions in Cartesian genetic programming.</title><p>(<bold>A</bold>) The genotype of an individual is a two-dimensional Cartesian graph (top). In this example, the graph contains three input nodes (<inline-formula><mml:math id="inf12"><mml:mrow><mml:mn>0</mml:mn><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>), six internal nodes (<inline-formula><mml:math id="inf13"><mml:mrow><mml:mn>3</mml:mn><mml:mo>-</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:math></inline-formula>) and a single output node (9). In each node, the genes of a specific genotype are shown, encoding the operator used to compute the node’s output and its inputs. Each operator gene maps to a specific mathematical function (bottom). Special values (<inline-formula><mml:math id="inf14"><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) represent input and output nodes. For example, node four uses the operator 1, the multiplication operation '*', and receives input from nodes 0 and 2. This node’s output is hence given by <inline-formula><mml:math id="inf15"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>*</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>. The number of input genes per node is determined by the operator with the maximal arity (here two). Fixed genes that cannot be mutated are highlighted in red. ∅ denotes non-coding genes. (<bold>B</bold>) The computational graph (phenotype) generated by the genotype in A. Input nodes (<inline-formula><mml:math id="inf16"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>) represent the arguments of the function <inline-formula><mml:math id="inf17"><mml:mi>f</mml:mi></mml:math></inline-formula>. Each output node selects one of the other nodes as a return value of the computational graph, thus defining a function from input <inline-formula><mml:math id="inf18"><mml:mi mathvariant="bold-italic">𝒙</mml:mi></mml:math></inline-formula> to output <inline-formula><mml:math id="inf19"><mml:mrow><mml:mi mathvariant="bold-italic">𝒚</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">𝒇</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold-italic">𝒙</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Here, the output node selects node four as a return value. Some nodes defined in the genotype are not used by a particular realization of the computational graph (in light gray, e.g., node 6). Mutations that affect such nodes have no effect on the phenotype and are therefore considered ‘silent’. (<bold>C</bold>) Mutations in the genome either lead to a change in graph connectivity (top, green arrow) or alter the operators used by an internal node (bottom, green node). Here, both mutations affect the phenotype and are hence not silent.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66273-fig2-v1.tif"/></fig><p>In the following, we describe the results of three experiments following the recipe outlined above.</p></sec><sec id="s2-2"><title>Evolving an efficient reward-driven plasticity rule</title><p>We consider a simple reinforcement learning task for spiking neurons. The experiment can be succinctly described as follows: <inline-formula><mml:math id="inf20"><mml:mi>N</mml:mi></mml:math></inline-formula> inputs project to a single readout modeled by a leaky integrator neuron with exponential postsynaptic currents and stochastic spike generation (for details see section Reward-driven learning task). We generate a finite number <inline-formula><mml:math id="inf21"><mml:mi>M</mml:mi></mml:math></inline-formula> of frozen-Poisson-noise patterns of duration <inline-formula><mml:math id="inf22"><mml:mi>T</mml:mi></mml:math></inline-formula> and assign each of these randomly to one of two classes. The output neuron should learn to classify each of these spatio-temporal input patterns into the corresponding class using a spike/no-spike code (<xref ref-type="fig" rid="fig3">Figure 3A,B</xref>).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Cartesian genetic programming evolves various efficient reward-driven learning rules.</title><p>(<bold>A</bold>) Network sketch. Multiple input neurons with Poisson activity project to a single output unit. Pre- and postsynaptic activity generate an eligibility trace in each synapse. Comparison between the output activity and the target activity generates a reward signal. <inline-formula><mml:math id="inf23"><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:math></inline-formula>, and <inline-formula><mml:math id="inf24"><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup></mml:math></inline-formula>, <inline-formula><mml:math id="inf25"><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:math></inline-formula> represent the expected reward, the expected positive and the expected negative reward, respectively. Depending on the hyperparameter settings either the former or the latter two are provided to the plasticity rule. (<bold>B</bold>) Raster plot of the activity of input neurons (small black dots) and output neuron (large golden dots). Gray (white) background indicate patterns for which the output should be active (inactive). Top indicates correct classifications (+) and incorrect classifications (-). We show 10 trials at the beginning (left) and the end of training (right) using the evolved plasticity rule: <inline-formula><mml:math id="inf26"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>η</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>. (<bold>C</bold>) Fitness of best individual per generation as a function of the generation index for multiple example runs of the evolutionary algorithm with different initial conditions but identical hyperparameters. Labels show the expression <inline-formula><mml:math id="inf27"><mml:mi>f</mml:mi></mml:math></inline-formula> at the end of the respective run for three runs resulting in well-performing plasticity rules. Gray lines represent runs with functionally identical solutions or low final fitness. (<bold>D</bold>) Fitness of a selected subset of evolved learning rules on the 10 experiments used during the evolutionary search (blue) and additional 80 fitness evaluations, each on 10 new experiments consisting of sets of frozen noise patterns and associated class labels not used during the evolutionary search (orange). Horizontal boxes represent mean, error bars indicate one standard deviation over fitness values. Gray line indicates mean fitness of LR0 for visual reference. Black stars indicate significance (<inline-formula><mml:math id="inf28"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>16</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>) with respect to LR0 according to Welch’s T-tests (<xref ref-type="bibr" rid="bib86">Welch, 1947</xref>). See main text for the full expressions for all learning rules.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66273-fig3-v1.tif"/></fig><p>The fitness <inline-formula><mml:math id="inf29"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of an individual encoding the function <inline-formula><mml:math id="inf30"><mml:mi>f</mml:mi></mml:math></inline-formula> is measured by the mean reward per trial averaged over a certain number of experiments <inline-formula><mml:math id="inf31"><mml:msub><mml:mi>n</mml:mi><mml:mtext>exp</mml:mtext></mml:msub></mml:math></inline-formula>, each consisting of <inline-formula><mml:math id="inf32"><mml:mi>n</mml:mi></mml:math></inline-formula> classification trials<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mrow><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>:=</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>n</mml:mi><mml:mtext>exp</mml:mtext></mml:msub></mml:mfrac></mml:mstyle><mml:mo>⁢</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>exp</mml:mtext></mml:msub></mml:munderover></mml:mstyle><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo rspace="5.3pt" stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf33"><mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>:=</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:msubsup><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the mean reward per trial obtained in experiment <inline-formula><mml:math id="inf34"><mml:mi>k</mml:mi></mml:math></inline-formula>. The reward <inline-formula><mml:math id="inf35"><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the reward obtained in the <inline-formula><mml:math id="inf36"><mml:mi>i</mml:mi></mml:math></inline-formula> th trial of experiment <inline-formula><mml:math id="inf37"><mml:mi>k</mml:mi></mml:math></inline-formula>. It is one if the classification is correct and -1 otherwise. In the following, we drop the subscripts from <inline-formula><mml:math id="inf38"><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> where its meaning is clear from context. Each experiment contains different realizations of frozen-noise input spike trains with associated class labels.</p><p>Previous work on reward-driven learning (<xref ref-type="bibr" rid="bib90">Williams, 1992</xref>) has demonstrated that in policy-gradient-based approaches (e.g., <xref ref-type="bibr" rid="bib77">Sutton and Barto, 2018</xref>), subtracting a so called ‘reward baseline’ from the received reward can improve the convergence properties by adjusting the magnitude of weight updates. However, choosing a good reward baseline is notoriously difficult (<xref ref-type="bibr" rid="bib89">Williams, 1988</xref>; <xref ref-type="bibr" rid="bib18">Dayan, 1991</xref>; <xref ref-type="bibr" rid="bib85">Weaver and Tao, 2001</xref>). For example, in a model for reinforcement learning in spiking neurons, <xref ref-type="bibr" rid="bib84">Vasilaki et al., 2009</xref> suggest the expected positive reward as a suitable baseline. Here, we consider plasticity rules which, besides immediate rewards, have access to expected rewards. These expectations are obtained as moving averages over a number of consecutive trials (here: 100 trials, i.e., 50 s) during one experiment and can either be estimated jointly (<inline-formula><mml:math id="inf39"><mml:mrow><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) or separately for positive (<inline-formula><mml:math id="inf40"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) and negative (<inline-formula><mml:math id="inf41"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>) rewards, with <inline-formula><mml:math id="inf42"><mml:mrow><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> (for details, see section Reward-driven learning task). In the former case, the plasticity rule takes the general form<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>η</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo rspace="5.3pt">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>while for seperately estimated positive and negative rewards it takes the form<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>η</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup><mml:mo rspace="5.3pt">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>In both cases, η is a fixed learning rate and <inline-formula><mml:math id="inf43"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is an eligibility trace that contains contributions from the spiking activity of pre- and post-synaptic neurons which is updated over the course of a single trial (for details see section Reward-driven learning task). The eligibility trace arises as a natural consequence of policy-gradient methods aiming to maximize the expected reward (<xref ref-type="bibr" rid="bib90">Williams, 1992</xref>) and is a common ingredient of reward-modulated plasticity rules for spiking neurons (<xref ref-type="bibr" rid="bib84">Vasilaki et al., 2009</xref>; <xref ref-type="bibr" rid="bib25">Frémaux and Gerstner, 2015</xref>). It is a low-pass filter of the product of two terms: the first is positive if the neuron was more active than expected by synaptic input; this can happen because the neuronal output is stochastic, to promote exploration. The second is a low-pass filter of presynaptic activity. A simple plasticity rule derived from maximizing the expected rewards would, for example, change weights according to the product of the received reward and the eligibility trace: <inline-formula><mml:math id="inf44"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>. If by chance a neuron is more active than expected, and the agent receives a reward, all weights of active afferents are increased, making it more likely for the neuron to fire in the future given identical input. Reward and eligibility trace values at the end of each trial (<inline-formula><mml:math id="inf45"><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:math></inline-formula>) are used to determine synaptic weight changes. In the following, we drop the time argument of <inline-formula><mml:math id="inf46"><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:math></inline-formula> for simplicity. Using CGP with three (<inline-formula><mml:math id="inf47"><mml:mi>R</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf48"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>), or four inputs (<inline-formula><mml:math id="inf49"><mml:mi>R</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf50"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>,</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>), respectively, we search for plasticity rules that maximize the fitness <inline-formula><mml:math id="inf51"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>).</p><p>None of the evolutionary runs with access to the expected reward (<inline-formula><mml:math id="inf52"><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:math></inline-formula>) make use of it as a reward baseline (see Appendix section Full evolution data for different CGP hyperparameter choices for full data). Some of them discover high-performing rules identical to that suggested by <xref ref-type="bibr" rid="bib81">Urbanczik and Senn, 2009</xref>: <inline-formula><mml:math id="inf53"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>η</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> (LR0, <inline-formula><mml:math id="inf54"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi><mml:mo>=</mml:mo><mml:mn>216.2</mml:mn></mml:mrow></mml:math></inline-formula>, <xref ref-type="fig" rid="fig3">Figure 3C,D</xref>). This rule uses a fixed base line, the maximal reward (<inline-formula><mml:math id="inf55"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mtext>max</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>), rather than the expected reward. Some runs discover a more sophisticated variant of this rule with a term that decreases the effective learning rate for negative rewards as the agent improves, that is, when the expected reward increases: <inline-formula><mml:math id="inf56"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>η</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> (LR1, <inline-formula><mml:math id="inf57"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi><mml:mo>=</mml:mo><mml:mn>234.2</mml:mn></mml:mrow></mml:math></inline-formula>, <xref ref-type="fig" rid="fig3">Figure 3C,D</xref>; see also Appendix section Causal and homeostatic terms over trials). Using this effective learning-rate, this rule achieve higher fitness than the vanilla formulation at the expense of requiring the agent to keep track of the expected reward.</p><p>Using the expected reward as a baseline, for example, <inline-formula><mml:math id="inf58"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>η</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, is unlikely to yield high-performing solutions: an agent may get stuck in weight configurations in which it continuously receives negative rewards, yet, as it is expecting negative rewards, does not significantly change its weights. This intuition is supported by our observation that none of the high-performing plasticity rules discovered by our evolutionary search make use of such a baseline, in contrast to previous studies (e.g., <xref ref-type="bibr" rid="bib25">Frémaux and Gerstner, 2015</xref>). Subtracting the maximal reward, in contrast, can be interpreted as an optimistic baseline (cf. <xref ref-type="bibr" rid="bib77">Sutton and Barto, 2018</xref>, Ch2.5), which biases learning to move away from weight configurations that result in negative rewards, while maintaining weight configurations that lead to positive rewards. However, a detrimental effect of such an optimistic baseline is that learning is sparse, as it only occurs upon receiving negative rewards, an assumption at odds with behavioral evidence.</p><p>In contrast, evolutionary runs with access to separate estimates of the negative and positive rewards discover plasticity rules with efficient baselines, resulting in increased fitness (see Appendix section Full evolution data for different CGP hyperparameter choices for the full data). In the following, we discuss four such high-performing plasticity rules with at least 10% higher fitness than LR0 (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). We first consider the rule (LR2, <inline-formula><mml:math id="inf59"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi><mml:mo>=</mml:mo><mml:mn>242.0</mml:mn></mml:mrow></mml:math></inline-formula>, <xref ref-type="fig" rid="fig3">Figure 3D</xref>)<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>η</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>η</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mtext>abs</mml:mtext></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mpadded width="+2.8pt"><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:mpadded></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where we introduced the expected absolute reward <inline-formula><mml:math id="inf60"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mtext>abs</mml:mtext></mml:msub><mml:mo>:=</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, with <inline-formula><mml:math id="inf61"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mtext>abs</mml:mtext></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Note the difference to the expected reward <inline-formula><mml:math id="inf62"><mml:mrow><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. Since the absolute magnitude of positive and negative rewards is identical in the considered task, <inline-formula><mml:math id="inf63"><mml:msub><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mtext>abs</mml:mtext></mml:msub></mml:math></inline-formula> increases in each trial, starting at zero and slowly converging to one with a time constant of 50 s. Instead of keeping track of the expected reward, the agent can thus simply optimistically increase its baseline with each trial. Behind this lies the, equally optimistic, expectation that the agent improves its performance over trials. Starting out as <inline-formula><mml:math id="inf64"><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:mrow></mml:math></inline-formula> and converging to <inline-formula><mml:math id="inf65"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:mrow></mml:math></inline-formula> this rule combines efficient learning from both positive and negative rewards initially, with improved convergence towards successful weight configuration during late learning by a reward-dependent modulation of the effective learning rate (see also Appendix section Causal and homeostatic terms over trials). Note that such a strategy may lead to issues with un- or re-learning. This may be overcome by the agent resetting the expected absolute reward <inline-formula><mml:math id="inf66"><mml:msub><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mtext>abs</mml:mtext></mml:msub></mml:math></inline-formula> upon encountering a new task, similar to a ‘novelty’ signal.</p><p>Furthermore, our algorithm discovers a variation of this rule (LR3, <inline-formula><mml:math id="inf67"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi><mml:mo>=</mml:mo><mml:mn>256.0</mml:mn></mml:mrow></mml:math></inline-formula>, <xref ref-type="fig" rid="fig3">Figure 3D</xref>), which replaces η with <inline-formula><mml:math id="inf68"><mml:mrow><mml:mi>η</mml:mi><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to decrease the magnitude of weight changes in regions of the weight space associated with high performance. This can improve convergence properties.</p><p>We next consider the rule (LR4, <inline-formula><mml:math id="inf69"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi><mml:mo>=</mml:mo><mml:mn>247.2</mml:mn></mml:mrow></mml:math></inline-formula>, <xref ref-type="fig" rid="fig3">Figure 3D</xref>):<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>η</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo rspace="4.2pt">[</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo rspace="5.3pt">]</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>This rule has the familiar form of LR0 and LR1, with an additional homeostatic term. Due to the prefactors <inline-formula><mml:math id="inf70"><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, this rule only changes weights on trials with negative reward. Initially, the expected reward <inline-formula><mml:math id="inf71"><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup></mml:math></inline-formula> is close to zero and the homeostatic term results in potentiation of all synapses, causing more and more neurons to spike. In particular, if initial weights are chosen poorly, this can make learning more robust. As the agent improves and the expected positive rewards increases, the homeostatic term becomes negative (see also Appendix section Causal and homeostatic terms over trials). In this regime, it can be interpreted as pruning all weights until only those are left that do not lead to negative rewards. This term can hence be interpreted as an adapting action baseline (<xref ref-type="bibr" rid="bib77">Sutton and Barto, 2018</xref>).</p><p>Finally, we consider the rule (LR5, <inline-formula><mml:math id="inf72"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi><mml:mo>=</mml:mo><mml:mn>254.8</mml:mn></mml:mrow></mml:math></inline-formula>, <xref ref-type="fig" rid="fig3">Figure 3D</xref>):<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>η</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mrow><mml:mn> 2</mml:mn><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup><mml:mo>-</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup><mml:mo>-</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow></mml:mrow><mml:mo rspace="5.3pt">}</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>To analyze this seemingly complex rule, we consider the expression for trials with positive and trials with negative reward separately:<disp-formula id="equ7"><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mspace width="thickmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>η</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mspace width="thinmathspace"/><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>abs</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mtext>abs</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mspace width="thickmathspace"/><mml:mo>,</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mspace width="thickmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>η</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mspace width="thinmathspace"/><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mspace width="thickmathspace"/><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Both expressions contain a ‘causal’ term depending on pre- and postsynaptic activity via the eligibility trace, as well as, and a ‘homeostatic’ term. Aside from the constant scaling factor, the causal term of <inline-formula><mml:math id="inf73"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mi>j</mml:mi><mml:mo>+</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> is identical to LR2 (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref>), that is, it only causes weight changes early during learning, and converges to zero for later times. Similarly, the causal term of <inline-formula><mml:math id="inf74"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mi>j</mml:mi><mml:mo>-</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> is initially identical to that of LR2 (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref>), decreasing weights for connections contributing to wrong decisions. However it increases in magnitude as the agent improves and the expected reward increases. The homeostatic term of <inline-formula><mml:math id="inf75"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mi>j</mml:mi><mml:mo>+</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> is potentiating, similarly to LR4 (<xref ref-type="disp-formula" rid="equ5">Equation 5</xref>): it encourages spiking by increasing all synaptic weights during early learning and decreases over time. The homeostatic term for negative rewards is also potentiating, but does not vanish for long times unless the agent is performing perfectly (<inline-formula><mml:math id="inf76"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>). Over time, this plasticity rule hence reacts less and less to positive rewards, while increasing weight changes for negative rewards. The reward-modulated potentiating homeostatic mechanisms can prevent synaptic weights from vanishing and thus encourage exploration for challenging scenarios in which the agent mainly receives negative rewards.</p><p>In conclusion, by making use of the separately estimated expected negative and positive rewards in precise combinations with the eligibility trace and the instantaneous reward, our evolving-to-learn approach discovered a variety of reward-based plasticity rules, many of them outperforming previously known solutions (e.g., <xref ref-type="bibr" rid="bib81">Urbanczik and Senn, 2009</xref>). The evolution of closed-form expressions allowed us to analyze the computational principles that allow these newly discovered rules to achieve high fitness. This analysis suggests new mechanisms for efficient learning, for example from ‘novelty’ and via reward-modulated homeostatic mechanisms. Each of these new hypotheses for reward-driven plasticity rules makes specific predictions about behavioral and neuronal signatures that potentially allow us to distinguish between them. For example LR2, LR3, and LR5 suggest that agents initially learn both from positive and negative rewards, while later they mainly learn from negative rewards. In particular the initial learning from positive rewards distinguishes these hypotheses from LR0, LR1, and LR4, and previous work (<xref ref-type="bibr" rid="bib81">Urbanczik and Senn, 2009</xref>). As LR2 does not make use of the, separately estimated, expected rewards, it is potentially employed in settings in which such estimates are difficult to obtain. Furthermore, LR4 and LR5 suggest that precisely regulated homeostatic mechanisms play a crucial role besides weight changes due to pre- and post-synaptic activity traces. During early learning, both rules implement potentiating homeostatic mechanisms triggered by negative rewards, likely to explore many possible weight configurations which may support successful behavior. During late learning, LR4 suggests that homeostatic changes become depressing, thus pruning unnecessary or even harmful connections. In contrast, they remain positive for LR5, potentially avoiding catastrophic dissociation between inputs and outputs for challenging tasks. Besides experimental data from the behavioral and neuronal level, different artificial reward-learning scenarios could further further select for strengths or against weaknesses of the discovered rules. Furthermore, additional considerations, for example achieving small variance in weight updates (<xref ref-type="bibr" rid="bib88">Williams, 1986</xref>; <xref ref-type="bibr" rid="bib18">Dayan, 1991</xref>), may lead to particular rules being favored over others. We thus believe that our new insights into reinforcement learning are merely a forerunner of future experimental and theoretical work enabled by our approach.</p></sec><sec id="s2-3"><title>Evolving an efficient error-driven plasticity rule</title><p>We next consider a supervised learning task in which a neuron receives information about how far its output is from the desired behavior, instead of just a scalar reward signal as in the previous task. The widespread success of this approach in machine learning highlights the efficacy of learning from errors compared to correlation- or reward-driven learning (<xref ref-type="bibr" rid="bib31">Goodfellow et al., 2016</xref>). It has therefore often been hypothesized that evolution has installed similar capabilities in biological nervous systems (see, e.g. <xref ref-type="bibr" rid="bib47">Marblestone et al., 2016</xref>; <xref ref-type="bibr" rid="bib87">Whittington and Bogacz, 2019</xref>).</p><p><xref ref-type="bibr" rid="bib82">Urbanczik and Senn, 2014</xref> introduced an efficient, flexible, and biophysically plausible implementation of error-driven learning via multi-compartment neurons. For simplicity, we consider an equivalent formulation of this learning principle in terms of two point neurons modeled as leaky integrator neurons with exponential postsynaptic currents and stochastic spike generation. One neuron mimics the somatic compartment and provides a teaching signal to the other neuron acting as the dendritic compartment. Here, the difference between the teacher and student membrane potentials drives learning:<disp-formula id="equ8"><label>(7)</label><mml:math id="m8"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>η</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo rspace="5.3pt" stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf77"><mml:mi>v</mml:mi></mml:math></inline-formula> is the teacher potential, <inline-formula><mml:math id="inf78"><mml:mi>u</mml:mi></mml:math></inline-formula> the student membrane potential, and η a fixed learning rate. <inline-formula><mml:math id="inf79"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>κ</mml:mi><mml:mo>*</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> represents the the presynaptic spike train <italic>s</italic><sub><italic>j</italic></sub> filtered by the synaptic kernel κ. <xref ref-type="disp-formula" rid="equ8">Equation 7</xref> can be interpreted as stochastic gradient descent on an appropriate cost function (<xref ref-type="bibr" rid="bib82">Urbanczik and Senn, 2014</xref>) and can be extended to support credit assignment in hierarchical neuronal networks (<xref ref-type="bibr" rid="bib73">Sacramento et al., 2018</xref>). For simplicity, we assume the student has direct access to the teacher’s membrane potential, but in principle one could also employ proxies such as firing rates as suggested in <xref ref-type="bibr" rid="bib67">Pfister et al., 2010</xref>; <xref ref-type="bibr" rid="bib82">Urbanczik and Senn, 2014</xref>.</p><p>We consider a one-dimensional regression task in which we feed random Poisson spike trains into the two neurons (<xref ref-type="fig" rid="fig4">Figure 4A</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Cartesian genetic programming evolves efficient error-driven learning rules.</title><p>(<bold>A</bold>) Network sketch. Multiple input neurons with Poisson activity project to two neurons. One of the neurons (the teacher) generates a target for the other (the student). The membrane potentials of teacher and student as well as the filtered pre-synaptic spike trains are provided to the plasticity rule that determines the weight update. (<bold>B</bold>) Root mean squared error between the teacher and student membrane potential over the course of learning using the evolved plasticity rule: <inline-formula><mml:math id="inf80"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>η</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. (<bold>C</bold>) Synaptic weights over the course of learning corresponding to panel B. Horizontal dashed lines represent target weights, that is, the fixed synaptic weights onto the teacher. (<bold>D</bold>) Fitness of the best individual per generation as a function of the generation index for multiple runs of the evolutionary algorithm with different initial conditions. Labels represent the rule at the end of the respective run. Colored markers represent fitness of each plasticity rule averaged over 15 validation tasks not used during the evolutionary search; error bars indicate one standard deviation.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66273-fig4-v1.tif"/></fig><p>The teacher maintains fixed input weights while the student’s weights should be adapted over the course of learning such that its membrane potential follows the teacher’s (<xref ref-type="fig" rid="fig4">Figure 4B,C</xref>). The fitness <inline-formula><mml:math id="inf81"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of an individual encoding the function <inline-formula><mml:math id="inf82"><mml:mi>f</mml:mi></mml:math></inline-formula> is measured by the root mean-squared error between the teacher and student membrane potential over the simulation duration <inline-formula><mml:math id="inf83"><mml:mi>T</mml:mi></mml:math></inline-formula>, excluding the initial 10%, averaged over <inline-formula><mml:math id="inf84"><mml:msub><mml:mi>n</mml:mi><mml:mtext>exp</mml:mtext></mml:msub></mml:math></inline-formula> experiments:<disp-formula id="equ9"><label>(8)</label><mml:math id="m9"><mml:mrow><mml:mrow><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>:=</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>n</mml:mi><mml:mtext>exp</mml:mtext></mml:msub></mml:mfrac></mml:mstyle><mml:mo>⁢</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>exp</mml:mtext></mml:msub></mml:munderover></mml:mstyle><mml:mpadded width="+2.8pt"><mml:msqrt><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo largeop="true" symmetric="true">∫</mml:mo><mml:mrow><mml:mn>0.1</mml:mn><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:msubsup></mml:mstyle><mml:mrow><mml:mtext>d</mml:mtext><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:msqrt></mml:mpadded></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Each experiment consists of different input spike trains and different teacher weights. The general form of the plasticity rule for this error-driven learning task is given by:<disp-formula id="equ10"><label>(9)</label><mml:math id="m10"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>η</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo rspace="5.3pt" stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Using CGP with three inputs (<inline-formula><mml:math id="inf85"><mml:mrow><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>), we search for plasticity rules that maximize the fitness <inline-formula><mml:math id="inf86"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>Starting from low fitness, about half of the evolutionary runs evolve efficient plasticity rules (<xref ref-type="fig" rid="fig4">Figure 4D</xref>) closely matching the performance of the stochastic gradient descent rule of <xref ref-type="bibr" rid="bib82">Urbanczik and Senn, 2014</xref>. While two runs evolve exactly <xref ref-type="disp-formula" rid="equ8">Equation 7</xref>, other solutions with comparable fitness are discovered, such as<disp-formula id="equ11"><label>(10)</label><mml:math id="m11"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mi/></mml:mrow><mml:mrow><mml:mi>η</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>-</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mpadded width="+2.8pt"><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>v</mml:mi></mml:mfrac></mml:mstyle></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>, and</mml:mtext></mml:mrow></mml:math></disp-formula><disp-formula id="equ12"><label>(11)</label><mml:math id="m12"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mi/></mml:mrow><mml:mrow><mml:mrow><mml:mi>η</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mpadded width="+2.8pt"><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>-</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:msup><mml:mi>v</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mfrac></mml:mstyle></mml:mpadded></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>At first sight, these rules may appear more complex, but for the considered parameter regime under the assumptions <inline-formula><mml:math id="inf87"><mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mo>≈</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>;</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>≫</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, we can write them as (see Appendix section Error-driven learning – simplification of the discovered rules):<disp-formula id="equ13"><label>(12)</label><mml:math id="m13"><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>η</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>-</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mpadded width="+2.8pt"><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mpadded></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>with a multiplicative constant <inline-formula><mml:math id="inf88"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒪</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and a negligible additive constant <italic>c</italic><sub>2</sub>. Elementary manipulations of the expressions found by CGP thus demonstrate the similarity of these superficially different rules to <xref ref-type="disp-formula" rid="equ8">Equation 7</xref>. Consequently, they can be interpreted as approximations of gradient descent. The constants generally fall into two categories: fine-tuning of the learning rate for the set of task samples encountered during evolution (<italic>c</italic><sub>1</sub>), which could be responsible for the slight increase in performance, and factors that have negligible influence and would most likely be pruned over longer evolutionary timescales (<italic>c</italic><sub>2</sub>). This pruning could be accelerated, for example, by imposing a penalty on the model complexity in the fitness function, thus preferentially selecting simpler solutions.</p><p>In conclusion, the evolutionary search rediscovers variations of a human-designed efficient gradient-descent-based learning rule for the considered error-driven learning task. Due to the compact, interpretable representation of the plasticity rules we are able to analyze the set of high-performing solutions and thereby identify phenomenologically identical rules despite their superficial differences.</p></sec><sec id="s2-4"><title>Evolving an efficient correlation-driven plasticity rule</title><p>We now consider a task in which neurons do not receive any feedback from the environment about their performance but instead only have access to correlations between pre- and postsynaptic activity. Specifically, we consider a scenario in which an output neuron should discover a repeating frozen-noise pattern interrupted by random background spikes using a combination of spike-timing-dependent plasticity and homeostatic mechanisms. Our experimental setup is briefly described as follows: <inline-formula><mml:math id="inf89"><mml:mi>N</mml:mi></mml:math></inline-formula> inputs project to a single output neuron (<xref ref-type="fig" rid="fig5">Figure 5A</xref>).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Cartesian genetic programming evolves diverse correlation-driven learning rules.</title><p>(<bold>A</bold>) Network sketch. Multiple inputs project to a single output neuron. The current synaptic weight <italic>w</italic><sub><italic>j</italic></sub> and the eligibility trace <inline-formula><mml:math id="inf90"><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>c</mml:mtext></mml:msubsup></mml:math></inline-formula> are provided to the plasticity rule that determines the weight update. (<bold>B</bold>) Membrane potential <inline-formula><mml:math id="inf91"><mml:mi>u</mml:mi></mml:math></inline-formula> of the output neuron over the course of learning using <xref ref-type="disp-formula" rid="equ18">Equation 17</xref>. Gray boxes indicate presentation of the frozen-noise pattern. (<bold>C</bold>) Fitness (<xref ref-type="disp-formula" rid="equ14">Equation 13</xref>) of the best individual per generation as a function of the generation index for multiple runs of the evolutionary algorithm with different initial conditions. Blue and red curves correspond to the two representative plasticity rules selected for detailed analysis. Blue and red markers represent fitness of the two representative rules and the orange marker the fitness of the homeostatic STDP rule (<xref ref-type="disp-formula" rid="equ18">Equation 17</xref>; <xref ref-type="bibr" rid="bib48">Masquelier, 2018</xref>), respectively, on 20 validation tasks not used during the evolutionary search. Error bars indicate one standard deviation over tasks. (<bold>D, E</bold>): Learning rules evolved by two runs of CGP (D: LR1, <xref ref-type="disp-formula" rid="equ20">Equation 19</xref>; E: LR2, <xref ref-type="disp-formula" rid="equ21">Equation 20</xref>). (<bold>F</bold>): Homeostatic STDP rule <xref ref-type="disp-formula" rid="equ18">Equation 17</xref> suggested by <xref ref-type="bibr" rid="bib48">Masquelier, 2018</xref>. Top panels: STDP kernels <inline-formula><mml:math id="inf92"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> as a function of spike timing differences <inline-formula><mml:math id="inf93"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> for three different weights <italic>w</italic><sub><italic>j</italic></sub>. Bottom panels: homeostatic mechanisms for those weights. The colors are specific to the respective learning rules (blue for LR1, red for LR2), with different shades representing the different weights <italic>w</italic><sub><italic>j</italic></sub>. The learning rate is <inline-formula><mml:math id="inf94"><mml:mrow><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:math></inline-formula>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66273-fig5-v1.tif"/></fig><p>The activity of all inputs is determined by a Poisson process with a fixed rate. A frozen-noise activity pattern of duration <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mtext>pattern</mml:mtext></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is generated once and replayed every <inline-formula><mml:math id="inf96"><mml:mrow><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>T</mml:mi><mml:mtext>inter</mml:mtext></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>ms</mml:mi></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig5">Figure 5B</xref>) while inputs are randomly spiking in between.</p><p>We define the fitness <inline-formula><mml:math id="inf97"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of an individual encoding the function <inline-formula><mml:math id="inf98"><mml:mi>f</mml:mi></mml:math></inline-formula> by the minimal average signal-to-noise ratio (<inline-formula><mml:math id="inf99"><mml:mi>SNR</mml:mi></mml:math></inline-formula>) across <inline-formula><mml:math id="inf100"><mml:msub><mml:mi>n</mml:mi><mml:mtext>exp</mml:mtext></mml:msub></mml:math></inline-formula> experiments:<disp-formula id="equ14"><label>(13)</label><mml:math id="m14"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>:=</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mi>min</mml:mi><mml:mi>k</mml:mi></mml:munder><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>SNR</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mpadded><mml:mo>,</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mtext>exp</mml:mtext></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo rspace="5.3pt">}</mml:mo></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The signal-to-noise ratio <inline-formula><mml:math id="inf101"><mml:msub><mml:mi>SNR</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula>, following <xref ref-type="bibr" rid="bib48">Masquelier, 2018</xref>, is defined as the difference between the maximal free membrane potential during pattern presentation averaged over multiple presentations (<inline-formula><mml:math id="inf102"><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mtext>max</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:math></inline-formula>) and the mean of the free membrane potential in between pattern presentations (<inline-formula><mml:math id="inf103"><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mtext>inter</mml:mtext></mml:mrow></mml:msub><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:math></inline-formula>) divided by its variance (<inline-formula><mml:math id="inf104"><mml:mrow><mml:mi>Var</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>inter</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>):<disp-formula id="equ15"><label>(14)</label><mml:math id="m15"><mml:msub><mml:mi>SNR</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>:=</mml:mo><mml:mrow><mml:mpadded width="+2.8pt"><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>max</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">⟩</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">⟨</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>inter</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">⟩</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>Std</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>inter</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mpadded><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The free membrane potential is obtained in a separate simulation with frozen weights by disabling the spiking mechanism for the output neuron. This removes measurement noise in the signal-to-noise ratio arising from spiking and subsequent membrane-potential reset. Each experiment consists of different realizations of a frozen-noise pattern and background spiking.</p><p>We evolve learning rules of the following general form, which includes a dependence on the current synaptic weight in line with previously suggested STDP rules (<xref ref-type="bibr" rid="bib32">Gütig et al., 2003</xref>):<disp-formula id="equ16"><label>(15)</label><mml:math id="m16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>STDP</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">p</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>c</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>c</mml:mtext></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn><mml:mspace width="thickmathspace"/><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf105"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>c</mml:mtext></mml:msubsup><mml:mo>:=</mml:mo><mml:msup><mml:mi mathvariant="normal">e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> represents an eligibility trace that depends on the relative timing of post- and presynaptic spiking (<inline-formula><mml:math id="inf106"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>post</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>pre</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>) and is represented locally in each synapse (e.g., <xref ref-type="bibr" rid="bib60">Morrison et al., 2008</xref>). η represents a fixed learning rate. The synaptic weight is bound such that <inline-formula><mml:math id="inf107"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We additionally consider weight-dependent homeostatic mechanisms triggered by pre- and postsynaptic spikes, respectively. These are implemented by additional functions of the general form:<disp-formula id="equ17"><label>(16)</label><mml:math id="m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" displaystyle="false" rowspacing=".2em"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">k</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">k</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Weight changes are determined jointly by <xref ref-type="disp-formula" rid="equ16">Equation 15</xref> and <xref ref-type="disp-formula" rid="equ17">Equation 16</xref> as <inline-formula><mml:math id="inf108"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>w</mml:mi><mml:mi>j</mml:mi><mml:mtext>STDP</mml:mtext></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>w</mml:mi><mml:mi>hom</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Using CGP, we search for functions <inline-formula><mml:math id="inf109"><mml:msub><mml:mi>f</mml:mi><mml:mtext>dep</mml:mtext></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf110"><mml:msub><mml:mi>f</mml:mi><mml:mtext>fac</mml:mtext></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf111"><mml:msubsup><mml:mi>f</mml:mi><mml:mtext>pre</mml:mtext><mml:mtext>hom</mml:mtext></mml:msubsup></mml:math></inline-formula>, and <inline-formula><mml:math id="inf112"><mml:msubsup><mml:mi>f</mml:mi><mml:mtext>post</mml:mtext><mml:mtext>hom</mml:mtext></mml:msubsup></mml:math></inline-formula> that maximize the fitness <inline-formula><mml:math id="inf113"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">ℱ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mtext>dep</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mtext>fac</mml:mtext></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ14">Equation 13</xref>).</p><p>As a baseline we consider a rule described by <xref ref-type="bibr" rid="bib48">Masquelier, 2018</xref> (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). It is a simple additive spike-timing-dependent plasticity (STDP) rule that replaces the depression branch of traditional STDP variants with a postsynaptically triggered constant homeostatic term <inline-formula><mml:math id="inf114"><mml:mrow><mml:msup><mml:mi>w</mml:mi><mml:mi>hom</mml:mi></mml:msup><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib41">Kempter et al., 1999</xref>). The synaptic weight of the projection from input <inline-formula><mml:math id="inf115"><mml:mi>j</mml:mi></mml:math></inline-formula> changes according to (<xref ref-type="fig" rid="fig5">Figure 5G</xref>):<disp-formula id="equ18"><label>(17)</label><mml:math id="m18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>STDP</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn><mml:mspace width="thickmathspace"/><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>c</mml:mtext></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn><mml:mspace width="thickmathspace"/><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mspace width="thickmathspace"/><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>with homeostatic mechanisms:<disp-formula id="equ19"><label>(18)</label><mml:math id="m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" displaystyle="false" rowspacing=".2em"><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">k</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>w</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msup></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">k</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mspace width="thickmathspace"/><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>To illustrate the result of synaptic plasticity following <xref ref-type="disp-formula" rid="equ18">Equation 17</xref> and <xref ref-type="disp-formula" rid="equ19">Equation 18</xref>, we consider the evolution of the membrane potential of an output neuron over the course of learning (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). While the target neuron spikes randomly at the beginning of learning, its membrane potential finally stays subthreshold in between pattern presentations and crosses the threshold reliably upon pattern presentation.</p><p>After 2000 generations, half of the runs of the evolutionary algorithm discover high-fitness solutions (<xref ref-type="fig" rid="fig5">Figure 5D</xref>). These plasticity rules lead to synaptic weight configurations which cause the neuron to reliably detect the frozen-noise pattern. From these well-performing learning rules, we pick two representative examples (<xref ref-type="fig" rid="fig5">Figure 5D,E</xref>) to analyze in detail. Learning rule 1 (LR1, <xref ref-type="fig" rid="fig5">Figure 5D</xref>) is defined by the following equations:<disp-formula id="equ20"><label>(19)</label><mml:math id="m20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>STDP</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">c</mml:mi></mml:mrow></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mspace width="1em"/><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>c</mml:mtext></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mspace width="1em"/><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow><mml:mspace width="thickmathspace"/><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mspace width="1em"/><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo>.</mml:mo><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">k</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo>.</mml:mo><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">k</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mspace width="thickmathspace"/><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Learning rule 2 (LR2, <xref ref-type="fig" rid="fig5">Figure 5E</xref>) is defined by the following equations:<disp-formula id="equ21"><label>(20)</label><mml:math id="m21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>STDP</mml:mtext></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>c</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mspace width="1em"/><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>E</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mtext>c</mml:mtext></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mtd><mml:mtd><mml:mspace width="1em"/><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow><mml:mspace width="thickmathspace"/><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mspace width="1em"/><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo>.</mml:mo><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">k</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo>.</mml:mo><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">k</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mspace width="thickmathspace"/><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The form of these discovered learning rules and associated homeostatic mechanisms suggests that they use distinct strategies to detect the repeated spatio-temporal pattern. LR1 causes potentiation for small time differences, regardless of whether they are causal or anticausal (note that <inline-formula><mml:math id="inf116"><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> since <inline-formula><mml:math id="inf117"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>). In the Hebbian spirit, this learning rule favors correlation between presynaptic and postsynaptic firing. Additionally, it potentiates synaptic weights upon presynaptic spikes, and depresses them for each postsynaptic spike. In contrast, LR2 implements a similar strategy as the learning rule of <xref ref-type="bibr" rid="bib48">Masquelier, 2018</xref>: it potentiates synapses only for small, positive (causal) time differences. Additionally, however, it pronouncedly punishes anticausal interactions. Similarly to LR1, its homeostatic component potentiates synaptic weights upon presynaptic spikes, and depresses them for each postsynaptic spike.</p><p>Note how both rules reproduce important components of experimentally established STDP traces (e.g., <xref ref-type="bibr" rid="bib11">Caporale and Dan, 2008</xref>). Despite their differences both in the form of the STDP kernel as well as the associated homeostatic mechanisms, both rules lead to high fitness, that is, comparable system-level behavior.</p><p>Unlike the classical perception of homeostatic mechanisms as merely maintaining an ideal working point of neurons (<xref ref-type="bibr" rid="bib17">Davis and Bezprozvanny, 2001</xref>), in both discovered plasticity rules these components support the computational goal of detecting the repeated pattern. By potentiating large weights more strongly than small weights, the pre-synaptically triggered homeostatic mechanisms support the divergence of synaptic weights into strong weights, related to the repeated pattern, and weak ones, providing background input. This observation suggests that homeostatic mechanisms and STDP work hand in hand to achieve desired functional outcomes, similar to homeostatic terms in stabilized Hebbian rules (<xref ref-type="bibr" rid="bib63">Oja, 1982</xref>; <xref ref-type="bibr" rid="bib56">Miller and MacKay, 1994</xref>). Experimental approaches hence need to take both factors into account and variations in observed STDP curves should be reconsidered from a point of functional equivalence when paired with data on homeostatic changes.</p><p>In conclusion, for the correlation-driven task, the evolutionary search discovered a wide variety of plasticity rules with associated homeostatic mechanisms supporting successful task learning, thus enabling new perspectives for learning in biological substrates.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Uncovering the mechanisms of learning via synaptic plasticity is a critical step toward understanding brain (dys)function and building truly intelligent, adaptive machines. We introduce a novel approach to discover biophysically plausible plasticity rules in spiking neuronal networks. Our meta-learning framework uses genetic programming to search for plasticity rules by optimizing a fitness function specific to the respective task family. Our evolving-to-learn approach discovers high-performing solutions for various learning paradigms, reward-driven, error-driven, and correlation-driven learning, yielding new insights into biological learning principles. Moreover, our results from the reward-driven and correlation-driven task families demonstrate that homeostatic terms and their precise interation with plasticity play an important role in shaping network function, highlighting the importance of considering both mechanisms jointly.</p><p>The experiments considered here were mainly chosen due to their simplicity and prior knowledge about corresponding plasticity rules that provided us with a high-performance reference for comparison. Additionally, in each experiment, we restricted ourselves to a constrained set of possible inputs to the plasticity rule. Here, we chose quantities which have been previously shown to be linked to synaptic plasticity in various learning paradigms, such as reward, low-pass filtered spike trains, and correlations between pre- and postsynaptic activities. This prior knowledge avoids requiring the evolutionary algorithm to rediscover these quantities but limits the search space, thus potentially excluding other efficient solutions.</p><p>A key point of E2L is the compact representation of the plasticity rules. We restrict the complexity of the expressions by three considerations. First, we assume that effective descriptions of weight changes can be found that are not unique to each individual synapse. This is a common assumption in computational neuroscience and based on the observation that nature must have found a parsimonious encoding of brain structure, as not every connection in the brain can be specified in the DNA of the organism (<xref ref-type="bibr" rid="bib91">Zador, 2019</xref>); rather, genes encode general principles by which the neuronal networks and subnetworks are organized and reorganized (<xref ref-type="bibr" rid="bib71">Risi and Stanley, 2010</xref>). Our approach aims at discovering such general principles for synaptic plasticity. Second, physical considerations restrict the information available to the plasticity rule to local quantities, such as pre- and post-synaptic activity traces or specific signals delivered via neuromodulators (e.g., <xref ref-type="bibr" rid="bib15">Cox and Witten, 2019</xref>; <xref ref-type="bibr" rid="bib52">Miconi et al., 2020</xref>). Third, we limit the maximal size of the expressions to keep the resulting learning rules interpretable and avoid overfitting.</p><p>We explicitly want to avoid constructing an opaque system that has high task performance but does not allow us to understand how the network structure is shaped over the course of learning. Since we obtain analytically tractable expressions for the plasticity rule, we can analyze them with conventional methods, in contrast to approaches representing plasticity rules with ANNs (e.g., <xref ref-type="bibr" rid="bib71">Risi and Stanley, 2010</xref>; <xref ref-type="bibr" rid="bib64">Orchard and Wang, 2016</xref>; <xref ref-type="bibr" rid="bib10">Bohnstingl et al., 2019</xref>), for which it is challenging to fully understand their macroscopic computation. This analysis generates intuitive understanding, facilitating communication and human-guided generalization from a set of solutions to different network architectures or task domains. In the search for plasticity rules suitable for physical implementations in biological systems, these insights are crucial as the identified plasticity mechanisms can serve as building blocks for learning rules that generalize to the actual challenges faced by biological agents. Rather than merely applying the discovered rules to different learning problems, researchers may use the analytic expressions and prior knowledge to distill general learning principles – such as the computational role of homeostasis emerging from the present work – and combine them in new ways to extrapolate beyond the task families considered in the evolutionary search. Therefore, our evolving-to-learn approach is a new addition to the toolset of the computational neuroscientist in which human intuition is paired with efficient search algorithms. Moreover, simple expressions highlight the key interactions between the local variables giving rise to plasticity, thus providing hints about the underlying biophysical processes and potentially suggesting new experimental approaches.</p><p>From a different perspective, while the learning rules found in the experiments described above were all evolved from random expressions, one can also view the presented framework as a hypothesis-testing machine. Starting from a known plasticity rule, our framework would allow researchers to address questions like: assuming the learning rule would additionally have access to variable <inline-formula><mml:math id="inf118"><mml:mi>x</mml:mi></mml:math></inline-formula>, could this be incorporated into the weight updates such that learning would improve? The automated procedure makes answering such questions much more efficient than a human-guided manual search. Additionally, the framework is suitable to find robust biophysically plausible approximations for complex learning rules containing quantities that might be non-local, difficult to compute, and/or hard to implement in physical substrates. In particular, multi-objective optimization is suitable to evolve a known, complex rule into simpler versions while maintaining high task performance. Similarly, one could search for modifications of general rules that are purposefully tuned to quickly learn within a specific task family, outperforming more general solutions. In each of these cases, prior knowledge about effective learning algorithms provides a starting point from which the evolutionary search can discover powerful extensions.</p><p>The automated search can discover plasticity rules for a given problem that exploit implicit assumptions in the task. It therefore highlights underconstrained searches, be this due to scarcity of biological data, the simplicity of chosen tasks or the omission of critical features in the task design. For instance, without asserting equal average spike rates of background and pattern neurons in the correlation-driven task, one could discover plasticity rules that exploit the rate difference rather than the spatio-temporal structure of the input.</p><p>Evolved Plastic Artificial Neural Networks (EPANNs; e.g., <xref ref-type="bibr" rid="bib76">Soltoggio et al., 2018</xref>) and in particular adaptive HyperNEAT (<xref ref-type="bibr" rid="bib71">Risi and Stanley, 2010</xref>), represent an alternative approach to designing plastic neural networks. In contrast to our method, however, these approaches include the network architecture itself into the evolutionary search, alongside synaptic plasticity rules. While this can lead to high-performance solutions due to a synergy between network architecture and plasticity, this interplay has an important drawback, as in general it is difficult to tease apart the contribution of plasticity from that of network structure to high task performance (cf. <xref ref-type="bibr" rid="bib27">Gaier and Ha, 2019</xref>). In addition, the distributed, implicit representation of plasticity rules in HyperNEAT can be difficult to interpret, which hinders a deeper understanding of the learning mechanisms. In machine-learning-oriented applications, this lack of credit assignment is less of an issue. For research into plasticity rules employed by biological systems, however, it presents a significant obstacle.</p><p>Future work needs to address a general issue of any optimization method: how can we systematically counter overfitting to reveal general solutions? A simple approach would increase the number of sample tasks during a single fitness evaluation. However, computational costs increase linearly in the number of samples. Another technique penalizes the complexity of the resulting expressions, for example, proportional to the size of the computational graph. Besides avoiding overfitting, such a penalty would automatically remove ‘null terms’ in the plasticity rules, that is, trivial subexpressions which have no influence on the expressions’ output. Since it is a priori unclear how this complexity penalty should be weighted against the original fitness measures, one should consider multi-objective optimization algorithms (e.g., <xref ref-type="bibr" rid="bib19">Deb, 2001</xref>).</p><p>Another issue to be addressed in future work is the choice of the learning rate. Currently, this value is not part of the optimization process and all tasks assume a fixed learning rate. The analysis of the reward- and error-driven learning rules revealed that the evolutionary algorithm tried to optimize the learning rate using the variables it had access to, partly generating complex terms that that amount to a variable scaling of the learning rate. The algorithm may benefit from the inclusion of additional constants which it could, for example, use for an unmitigated, permanent scaling of the learning rate. However, the dimensionality of the search space scales exponentially in the number of operators and constants, and the feasibility of such an approach needs to be carefully evaluated. One possibility to mitigate this combinatorial explosion is to combine the evolutionary search with gradient-based optimization methods that can fine-tune constants in the expressions (<xref ref-type="bibr" rid="bib79">Topchy and Punch, 2001</xref>; <xref ref-type="bibr" rid="bib35">Izzo et al., 2017</xref>).</p><p>Additionally, future work may involve less preprocessed data as inputs while considering more diverse mathematical operators. In the correlation-driven task, one could for example provide the raw times of pre- and postsynaptic spiking to the graph instead of the exponential of their difference, leaving more freedom for the evolutionary search to discover creative solutions. We expect particularly interesting applications of our framework to involve more complex tasks that are challenging for contemporary algorithms, such as life-long learning, which needs to tackle the issue of catastrophic forgetting (<xref ref-type="bibr" rid="bib26">French, 1999</xref>) or learning in recurrent spiking neuronal networks. In order to yield insights into information processing in the nervous system, the design of the network architecture should be guided by known anatomical features, while the considered task families should fall within the realm of ecologically relevant problems.</p><p>The evolutionary search for plasticity rules requires a large number of simulations, as each candidate solution needs to be evaluated on a sufficiently large number of samples from the task family to encourage generalization (e.g., <xref ref-type="bibr" rid="bib12">Chalmers, 1991</xref>; <xref ref-type="bibr" rid="bib4">Bengio et al., 1992</xref>). Due to silent mutations in CGP, that is, modifications of the genotype that do not alter the phenotype, we use caching methods to significantly reduce computational cost as only new solutions need to be evaluated. However, even employing such methods, the number of required simulations remains large, in the order of <inline-formula><mml:math id="inf119"><mml:mrow><mml:msup><mml:mn>10</mml:mn><mml:mn>3</mml:mn></mml:msup><mml:mo>-</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mn>4</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> per evolutionary run. For the experiments considered here, the computational costs are rather low, requiring <inline-formula><mml:math id="inf120"><mml:mrow><mml:mn>24</mml:mn><mml:mo>-</mml:mo><mml:mn>48</mml:mn></mml:mrow></mml:math></inline-formula> node hours for a few parallel runs of the evolutionary algorithms, easily within reach of a modern workstation. The total time increases linearly with the duration of a single simulation. When considering more complex tasks which would require larger networks and hence longer simulations, one possibility to limit computational costs would be to evolve scalable plasticity rules in simplified versions of the tasks and architectures. Such rules, quickly evolved, may then be applied to individual instances of the original complex tasks, mimicking the idea of ‘evolutionary hurdles’ that avoid wasting computational power on low-quality solutions (<xref ref-type="bibr" rid="bib75">So et al., 2019</xref>; <xref ref-type="bibr" rid="bib70">Real et al., 2020</xref>). A proof of concept for such an approach is the delta rule: originally in used in small-scale tasks, it has demonstrated incredible scaling potential in the context of error backpropagation. Similar observations indeed hold for evolved optimizers (<xref ref-type="bibr" rid="bib50">Metz et al., 2020</xref>).</p><p>Neuromorphic systems – dedicated hardware specifically designed to emulate neuronal networks – provide an attractive way to speed up the evolutionary search. To serve as suitable substrates for the approach presented here, these systems should be able to emulate spiking neuronal networks in an accelerated fashion with respect to real time and provide on-chip plasticity with a flexible specification of plasticity mechanisms (e.g., <xref ref-type="bibr" rid="bib16">Davies et al., 2018</xref>; <xref ref-type="bibr" rid="bib9">Billaudelle et al., 2019</xref>; <xref ref-type="bibr" rid="bib49">Mayr et al., 2019</xref>).</p><p>We view the presented methods as a machinery for generating, testing, and extending hypotheses on learning in spiking neuronal networks driven by problem instances and prior knowledge and constrained by experimental evidence. We believe this approach holds significant promise to accelerate progress toward deep insights into information processing in physical systems, both biological and biologically inspired, with immanent potential for the development of powerful artificial learning machines.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Evolutionary algorithm</title><p>We use a <inline-formula><mml:math id="inf121"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:math></inline-formula> evolution strategy (<xref ref-type="bibr" rid="bib7">Beyer and Schwefel, 2002</xref>) to evolve a population of individuals towards high fitness. In each generation, λ new offsprings are created from μ parents via tournament selection (e.g., <xref ref-type="bibr" rid="bib55">Miller and Goldberg, 1995</xref>) and subsequent mutation. From these <inline-formula><mml:math id="inf122"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:math></inline-formula>, individuals the best μ individuals are selected as parents for the next generation (Alg. 4.1). In this work, we use a tournament size of one and a fixed mutation probability <inline-formula><mml:math id="inf123"><mml:msub><mml:mi>p</mml:mi><mml:mtext>mutate</mml:mtext></mml:msub></mml:math></inline-formula> for each gene in an offspring individual. Since in CGP crossover of individuals can lead to significant disruption of the search process due to major changes in the computational graphs (<xref ref-type="bibr" rid="bib53">Miller, 1999</xref>), we avoid it here. In other words, new offspring are only modified by mutations. We use neutral search (<xref ref-type="bibr" rid="bib57">Miller and Thomson, 2000</xref>), in which an offspring is preferred over a parent with equal fitness, to allow the accumulation of silent mutations that can jointly lead to an increase in fitness. As it is computationally infeasible to exhaustively evaluate an individual on all possible tasks from a task family, we evaluate individuals only on a limited number of sample tasks and aggregate the results into a scalar fitness, either by choosing the minimal result or averaging. We manually select the number of sample tasks to balance computational costs and sampling noise for each task. In each generation, we use the same initial conditions to allow a meaningful comparison of results across generations. If an expression is encountered that cannot be meaningfully evaluated, such as division by zero, the corresponding individual is assigned a fitness of <inline-formula><mml:math id="inf124"><mml:mrow><mml:mo>-</mml:mo><mml:mi mathvariant="normal">∞</mml:mi></mml:mrow></mml:math></inline-formula>.</p><table-wrap id="inlinetable1" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th valign="bottom">Algorithm 1: Variant of <inline-formula><mml:math id="inf125"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:math></inline-formula> evolution strategies used in this study. Note the absence of a crossover step.</th></tr></thead><tbody><tr><td valign="bottom"><bold>Data:</bold> Initial random parent Population <inline-formula><mml:math id="inf126"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of size μ <break/><inline-formula><mml:math id="inf127"><mml:mrow><mml:mi>t</mml:mi><mml:mo>←</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> <break/><bold>while</bold> <inline-formula><mml:math id="inf128"><mml:mrow><mml:mi>t</mml:mi><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>generations</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> <bold>do</bold> <break/>             Create new offspring population <inline-formula><mml:math id="inf129"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mtext>CreateOffspringPopulation</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> <break/>             Combine parent + offspring populations <inline-formula><mml:math id="inf130"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>∪</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> <break/>             Evaluate fitness of each individual in <inline-formula><mml:math id="inf131"><mml:msub><mml:mi>R</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:math></inline-formula> <break/>             Pick <inline-formula><mml:math id="inf132"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>⊂</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> best individuals as new parents <break/>             <inline-formula><mml:math id="inf133"><mml:mrow><mml:mi>t</mml:mi><mml:mo>←</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> <break/><bold>end</bold> <break/><bold>Function</bold> CreateOffspringPopulation (<inline-formula><mml:math id="inf134"><mml:mi>P</mml:mi></mml:math></inline-formula>) <break/><bold>begin</bold> <break/>             Offspring population <inline-formula><mml:math id="inf135"><mml:mrow><mml:mi>Q</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> <break/><bold>             while</bold> <inline-formula><mml:math id="inf136"><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mi>Q</mml:mi><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:math></inline-formula> <bold>do</bold> <break/>                   Choose random subset of <inline-formula><mml:math id="inf137"><mml:mi>P</mml:mi></mml:math></inline-formula> of size <inline-formula><mml:math id="inf138"><mml:msub><mml:mi>N</mml:mi><mml:mi>tournament</mml:mi></mml:msub></mml:math></inline-formula> <break/>                   Choose best individual in the subset and append to <inline-formula><mml:math id="inf139"><mml:mi>Q</mml:mi></mml:math></inline-formula> <break/><bold>             end</bold> <break/><bold>             for</bold> <inline-formula><mml:math id="inf140"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:math></inline-formula> <bold>do</bold> <break/>                   Mutate each gene of <inline-formula><mml:math id="inf141"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> with mutation probability <inline-formula><mml:math id="inf142"><mml:msub><mml:mi>p</mml:mi><mml:mtext>mutation</mml:mtext></mml:msub></mml:math></inline-formula> <break/><bold>             end</bold> <break/><bold>             Return</bold> <inline-formula><mml:math id="inf143"><mml:mi>Q</mml:mi></mml:math></inline-formula> <break/><bold>end</bold></td></tr></tbody></table></table-wrap></sec><sec id="s4-2"><title>HAL-CGP</title><p>HAL-CGP (<xref ref-type="bibr" rid="bib74">Schmidt and Jordan, 2020</xref>, <ext-link ext-link-type="uri" xlink:href="https://github.com/Happy-Algorithms-League/hal-cgp">https://github.com/Happy-Algorithms-League/hal-cgp</ext-link>, <xref ref-type="bibr" rid="bib39">Jordan, 2021b</xref>) is an extensible pure Python library implementing Cartesian genetic programming to represent, mutate and evaluate populations of individuals encoding symbolic expressions targeting applications with computationally expensive fitness evaluations. It supports the translation from a CGP genotype, a two-dimensional Cartesian graph, into the corresponding phenotype, a computational graph implementing a particular mathematical expression. These computational graphs can be exported as pure Python functions, NumPy-compatible functions (<xref ref-type="bibr" rid="bib83">van der Walt et al., 2011</xref>), SymPy expressions (<xref ref-type="bibr" rid="bib51">Meurer et al., 2017</xref>) or PyTorch modules (<xref ref-type="bibr" rid="bib65">Paszke et al., 2019</xref>). Users define the structure of the two-dimensional graph from which the computational graph is generated. This includes the number of inputs, columns, rows, and outputs, as well as the computational primitives, that is, mathematical operators and constants, that compose the mathematical expressions. Due to the modular design of the library, users can easily implement new operators to be used as primitives. It supports advanced algorithmic features, such as shuffling the genotype of an individual without modifying its phenotype to introduce additional drift over plateus in the search space and hence lead to better exploration (<xref ref-type="bibr" rid="bib29">Goldman and Punch, 2014</xref>). The library implements a <inline-formula><mml:math id="inf144"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>+</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:math></inline-formula> evolution strategy to evolve individuals (see section Evolutionary algorithm). Users need to specify hyperparameters for the evolutionary algorithm, such as the size of parent and offspring populations and the maximal number of generations. To avoid reevaluating phenotypes that have been previously evaluated, the library provides a mechanism for caching results on disk. Exploiting the wide availability of multi-core architectures, the library can parallelize the evaluation of all individuals in a single generation via separate processes.</p></sec><sec id="s4-3"><title>NEST simulator</title><p>Spiking neuronal network simulations are based on the 2.16.0 release of the NEST simulator (<xref ref-type="bibr" rid="bib28">Gewaltig and Diesmann, 2007</xref>, <ext-link ext-link-type="uri" xlink:href="https://github.com/nest/nest-simulator">https://github.com/nest/nest-simulator</ext-link>; <xref ref-type="bibr" rid="bib24">Eppler, 2021</xref> commit 3c6f0f3). NEST is an open-source simulator for spiking neuronal networks with a focus on large networks with simple neuron models. The computationally intensive propagation of network dynamics is implemented in C++ while the network model can be specified using a Python API (PyNEST; <xref ref-type="bibr" rid="bib23">Eppler et al., 2008</xref>; <xref ref-type="bibr" rid="bib92">Zaytsev and Morrison, 2014</xref>). NEST profits from modern multi-core and multi-node systems by combining local parallelization with OpenMP threads and inter-node communication via the Message Passing Interface (MPI) (<xref ref-type="bibr" rid="bib36">Jordan et al., 2018</xref>). The standard distribution offers a variety of established neuron and plastic synapse models, including variants of spike-timing-dependent plasticity, reward-modulated plasticity and structural plasticity. New models can be implemented via a domain-specific language (<xref ref-type="bibr" rid="bib68">Plotnikov et al., 2016</xref>) or custom C++ code. For the purpose of this study, we implemented a reward-driven (<xref ref-type="bibr" rid="bib81">Urbanczik and Senn, 2009</xref>) and an error-driven learning rule (<xref ref-type="disp-formula" rid="equ8">Equation 7</xref>; <xref ref-type="bibr" rid="bib82">Urbanczik and Senn, 2014</xref>), as well as a homeostatic STDP rule (<xref ref-type="disp-formula" rid="equ18">Equation 17</xref>; <xref ref-type="bibr" rid="bib48">Masquelier, 2018</xref>) via custom C++ code. Due to the specific implementation of spike delivery in NEST, we introduce a constant in the STDP rule that is added at each potentiation call instead of using a separate depression term. To support arbitrary mathematical expressions in the error-driven (<xref ref-type="disp-formula" rid="equ10">Equation 9</xref>) and correlation-driven synapse models (<xref ref-type="disp-formula" rid="equ16">Equation 15</xref>), we additionally implemented variants in which the weight update can be specified via SymPy compatible strings (<xref ref-type="bibr" rid="bib51">Meurer et al., 2017</xref>) that are parsed by SymEngine (<ext-link ext-link-type="uri" xlink:href="https://github.com/symengine/symengine">https://github.com/symengine/symengine</ext-link>; <xref ref-type="bibr" rid="bib78">SymEngine Contributors, 2021</xref>) a C++ library for symbolic computation. All custom synapse models and necessary kernel patches are available as NEST modules in the repository accompanying this study (<ext-link ext-link-type="uri" xlink:href="https://github.com/Happy-Algorithms-League/e2l-cgp-snn">https://github.com/Happy-Algorithms-League/e2l-cgp-snn</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:390ee2664ea9a00fac9f6be0950a9f6312403292;origin=https://github.com/Happy-Algorithms-League/e2l-cgp-snn;visit=swh:1:snp:10c1f7017ac4ad4d702a505cf1d845502f61b954;anchor=swh:1:rev:2f370ba6ec46a46cf959afcc6c1c1051394cd02a">swh:1:rev:2f370ba6ec46a46cf959afcc6c1c1051394cd02a</ext-link>), <xref ref-type="bibr" rid="bib38">Jordan, 2021a</xref>).</p></sec><sec id="s4-4"><title>Computing systems</title><p>Experiments were performed on JUWELS (Jülich Wizard for European Leadership Science), an HPC system at the Jülich Research Centre, Jülich, Germany, with 12 Petaflop peak performance. The system contains 2271 general-purpose compute nodes, each equipped with two Intel Xeon Platinum 8168 processors (2×24 cores) and 12×8 GB main memory. Compute nodes are connected via an EDR-Infiniband fat-tree network and run CentOS 7. Additional experiments were performed on the multicore partition of Piz Daint, an HPC system at the Swiss National Supercomputing Centre, Lugano, Switzerland with 1.731 Petaflops peak performance. The system contains 1813 general-purpose compute nodes, each equipped with two Intel Xeon E5-2695 v4 processors (2×18 cores) and 64 GB main memory. Compute nodes are connected via Cray Aries routing and communications ASIC with Dragonfly network topology and run Cray Linux Environment (CLE). Each experiment employed a single compute node.</p></sec><sec id="s4-5"><title>Reward-driven learning task</title><p>We consider a reinforcement learning task for spiking neurons inspired by <xref ref-type="bibr" rid="bib81">Urbanczik and Senn, 2009</xref>. Spiking activity of the output neuron is generated by an inhomogeneous Poisson process with instantaneous rate <inline-formula><mml:math id="inf145"><mml:mi>ϕ</mml:mi></mml:math></inline-formula> determined by its membrane potential <inline-formula><mml:math id="inf146"><mml:mi>u</mml:mi></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib66">Pfister et al., 2006</xref>; <xref ref-type="bibr" rid="bib81">Urbanczik and Senn, 2009</xref>):<disp-formula id="equ22"><label>(21)</label><mml:math id="m22"><mml:mrow><mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>:=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>ρ</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mpadded width="+2.8pt"><mml:msup><mml:mi>e</mml:mi><mml:mfrac><mml:mrow><mml:mi>u</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mtext>th</mml:mtext></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:mfrac></mml:msup></mml:mpadded></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Here, ρ is the firing rate at threshold, <inline-formula><mml:math id="inf147"><mml:msub><mml:mi>u</mml:mi><mml:mtext>th</mml:mtext></mml:msub></mml:math></inline-formula> the threshold potential, and <inline-formula><mml:math id="inf148"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:math></inline-formula> a parameter governing the noise amplitude. In contrast to <xref ref-type="bibr" rid="bib81">Urbanczik and Senn, 2009</xref>, we consider an instantaneous reset of the membrane potential after a spike instead of an hyperpolarization kernel. The output neuron receives spike trains from sources randomly drawn from an input population of size <inline-formula><mml:math id="inf149"><mml:mi>N</mml:mi></mml:math></inline-formula> with randomly initialized weights (<inline-formula><mml:math id="inf150"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mtext>initial</mml:mtext></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>w</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>). Before each pattern presentation, the output neurons membrane potential and synaptic currents are reset.</p><p>The eligibility trace in every synapse is updated in continuous time according to the following differential equation (<xref ref-type="bibr" rid="bib81">Urbanczik and Senn, 2009</xref>; <xref ref-type="bibr" rid="bib25">Frémaux and Gerstner, 2015</xref>):<disp-formula id="equ23"><label>(22)</label><mml:math id="m23"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mtext>M</mml:mtext></mml:msub><mml:mo>⁢</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>E</mml:mi><mml:mo>˙</mml:mo></mml:mover><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:munder><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>∈</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:munder></mml:mstyle><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo rspace="5.3pt" stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf151"><mml:msub><mml:mi>τ</mml:mi><mml:mtext>M</mml:mtext></mml:msub></mml:math></inline-formula> governs the time scale of the eligibility trace and has a similar role as the decay parameter γ in policy-gradient methods (<xref ref-type="bibr" rid="bib77">Sutton and Barto, 2018</xref>), <inline-formula><mml:math id="inf152"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:math></inline-formula> is a parameter of the postsynaptic cell governing its noise amplitude, <inline-formula><mml:math id="inf153"><mml:mi>y</mml:mi></mml:math></inline-formula> represents the postsynaptic spike train, and <inline-formula><mml:math id="inf154"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>κ</mml:mi><mml:mo>*</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> the presynaptic spike train <italic>s</italic><sub><italic>j</italic></sub> filtered by the synaptic kernel κ. The learning rate η was manually tuned to obtain high performance with the one suggested by <xref ref-type="bibr" rid="bib81">Urbanczik and Senn, 2009</xref>. Expected positive and negative rewards in trial <inline-formula><mml:math id="inf155"><mml:mi>i</mml:mi></mml:math></inline-formula> are separately calculated as moving averages over previous trials (<xref ref-type="bibr" rid="bib84">Vasilaki et al., 2009</xref>):<disp-formula id="equ24"><label>(23)</label><mml:math id="m24"><mml:mrow><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>i</mml:mi><mml:mrow><mml:mo>+</mml:mo><mml:mo>⁣</mml:mo><mml:mrow><mml:mi/><mml:mo>/</mml:mo><mml:mo>-</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mstyle displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>m</mml:mi><mml:mtext>r</mml:mtext></mml:msub></mml:mfrac></mml:mstyle></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mo>⁣</mml:mo><mml:mrow><mml:mi/><mml:mo>/</mml:mo><mml:mo>-</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mstyle displaystyle="true"><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>m</mml:mi><mml:mtext>r</mml:mtext></mml:msub></mml:mfrac></mml:mstyle><mml:mo>⁢</mml:mo><mml:mpadded width="+2.8pt"><mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mtext>+/-</mml:mtext></mml:msub></mml:mpadded></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf156"><mml:msub><mml:mi>m</mml:mi><mml:mtext>r</mml:mtext></mml:msub></mml:math></inline-formula> determines the number of relevant previous trials and <inline-formula><mml:math id="inf157"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msub><mml:mo>:=</mml:mo><mml:mrow><mml:mtext>max</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo>-</mml:mo></mml:msub><mml:mo>:=</mml:mo><mml:mrow><mml:mtext>min</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Note that <inline-formula><mml:math id="inf158"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf159"><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, since <inline-formula><mml:math id="inf160"><mml:mrow><mml:mi>R</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We obtain the average reward as a sum of these separate estimates <inline-formula><mml:math id="inf161"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow></mml:mrow><mml:mo>;</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, while the expected absolute reward is determined by their difference <inline-formula><mml:math id="inf162"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mtext>abs</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow></mml:mrow><mml:mo>;</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mtext>abs</mml:mtext></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="s4-6"><title>Error-driven learning task</title><p>We consider an error-driven learning task for spiking neurons inspired by <xref ref-type="bibr" rid="bib82">Urbanczik and Senn, 2014</xref>. <inline-formula><mml:math id="inf163"><mml:mi>N</mml:mi></mml:math></inline-formula> Poisson inputs with constant rates (<inline-formula><mml:math id="inf164"><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒰</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mtext>min</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mtext>max</mml:mtext></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>N</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>) project to a teacher neuron and, with the same connectivity pattern, to a student neuron. As in section Reward-driven learning task, spiking activity of the output neuron is generated by an inhomogeneous Poisson process. In contrast to section Reward-driven learning task, the membrane potential is not reset after spike emission. Fixed synaptic weights from the inputs to the teacher are uniformly sampled from the interval <inline-formula><mml:math id="inf165"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mtext>min</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mtext>max</mml:mtext></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>, while weights to the student are all initialized to a fixed value <italic>w</italic><sub>0</sub>. In each trial we randomly shift all teacher weights by a global value <inline-formula><mml:math id="inf166"><mml:msub><mml:mi>w</mml:mi><mml:mtext>shift</mml:mtext></mml:msub></mml:math></inline-formula> to avoid a bias in the error signal that may arise if the teacher membrane potential is initially always larger or always smaller than the student membrane potential. Target potentials are read out from the teacher every <inline-formula><mml:math id="inf167"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> and provided instantaneously to the student. The learning rate η was chosen via grid search on a single example task for high performance with <xref ref-type="disp-formula" rid="equ8">Equation 7</xref>. Similar to <xref ref-type="bibr" rid="bib82">Urbanczik and Senn, 2014</xref>, we low-pass filter weight updates with an exponential kernel with time constant <inline-formula><mml:math id="inf168"><mml:msub><mml:mi>τ</mml:mi><mml:mtext>I</mml:mtext></mml:msub></mml:math></inline-formula> before applying them.</p></sec><sec id="s4-7"><title>Correlation-driven learning task</title><p>We consider a correlation-driven learning task for spiking neurons similar to <xref ref-type="bibr" rid="bib48">Masquelier, 2018</xref>: a spiking neuron, modeled as a leaky integrate-and-fire neuron with delta-shaped post-synaptic currents, receives stochastic spike trains from <inline-formula><mml:math id="inf169"><mml:mi>N</mml:mi></mml:math></inline-formula> inputs via plastic synapses.</p><p>To construct the input spike trains, we first create a frozen-noise pattern by drawing random spikes <inline-formula><mml:math id="inf170"><mml:mrow><mml:mrow><mml:msubsup><mml:mi class="ltx_font_mathcaligraphic">𝒮</mml:mi><mml:mi>i</mml:mi><mml:mi>pattern</mml:mi></mml:msubsup><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>pattern</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> from a Poisson process with rate ν. Neurons that fire at least once in this pattern are in the following called ‘pattern neurons’, the remaining are called ‘background neurons’. We alternate this frozen-noise pattern with random spike trains of length <inline-formula><mml:math id="inf171"><mml:msub><mml:mi>T</mml:mi><mml:mi>inter</mml:mi></mml:msub></mml:math></inline-formula> generated by a Poisson process with rate ν (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). To balance the average rates of pattern neurons and background neurons, we reduce the spike rate of pattern neurons in between patterns by a factor α. Background neurons have an average rate of <inline-formula><mml:math id="inf172"><mml:mrow><mml:msub><mml:mi>ν</mml:mi><mml:mi>inter</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>ν</mml:mi><mml:mo>⁢</mml:mo><mml:mfrac><mml:msub><mml:mi>T</mml:mi><mml:mi>inter</mml:mi></mml:msub><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>inter</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>pattern</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></inline-formula>. We assume that pattern neurons spike only once during the pattern. Thus, they have an average rate of rate of <inline-formula><mml:math id="inf173"><mml:mrow><mml:mi>ν</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ν</mml:mi><mml:mi>inter</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>inter</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mi>pattern</mml:mi></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>ν</mml:mi><mml:mi>inter</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>ν</mml:mi><mml:mi>pattern</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. Plugging in the previous expression for <inline-formula><mml:math id="inf174"><mml:msub><mml:mi>ν</mml:mi><mml:mtext>inter</mml:mtext></mml:msub></mml:math></inline-formula> and solving for α yields <inline-formula><mml:math id="inf175"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mfrac><mml:msub><mml:mi>ν</mml:mi><mml:mi>pattern</mml:mi></mml:msub><mml:msub><mml:mi>ν</mml:mi><mml:mi>inter</mml:mi></mml:msub></mml:mfrac></mml:mrow></mml:mrow></mml:math></inline-formula>. We choose the same learning rate as <xref ref-type="bibr" rid="bib48">Masquelier, 2018</xref>. Due to the particular implementation of STDP-like rules in NEST (<xref ref-type="bibr" rid="bib59">Morrison et al., 2007</xref>), we do not need to evolve multiple functions describing correlation-induced and homeostatic changes separately, but can evolve only one function for each branch of the STDP window. Terms in these functions which do not vanish for <inline-formula><mml:math id="inf176"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>c</mml:mtext></mml:msubsup><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> are effectively implementing pre-synaptically triggered (in the acausal branch) and post-synaptically triggered (in the causal branch) homeostatic mechanisms.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We gratefully acknowledge funding from the European Union, under grant agreements 604102, 720270, 785907, 945539 (HBP) and the Manfred Stärk Foundation. We further express our gratitude towards the Gauss Centre for Supercomputing e.V. (<ext-link ext-link-type="uri" xlink:href="https://www.gauss-centre.eu">https://www.gauss-centre.eu</ext-link>) for co-funding this project by providing computing time through the John von Neumann Institute for Computing (NIC) on the GCS Supercomputer JUWELS at Jülich Supercomputing Centre (JSC). We acknowledge the use of Fenix Infrastructure resources, which are partially funded from the European Union’s Horizon 2020 research and innovation programme through the ICEI project under the grant agreement No. 800858. We thank all participants from the HBP SP9 Fürberg meetings for stimulating interactions and Tomoki Fukai for initial discussions and support. We also thank Henrik Mettler and Akos Kungl for helpful comments on the manuscript. All network simulations carried out with NEST (<ext-link ext-link-type="uri" xlink:href="https://www.nest-simulator.org">https://www.nest-simulator.org</ext-link>).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Resources, Funding acquisition, Project administration, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Formal analysis, Funding acquisition, Investigation, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-66273-transrepform-v1.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All data and scripts required to reproduce the manuscript figures, as well as source code, simulation and analysis scripts are publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/Happy-Algorithms-League/e2l-cgp-snn">https://github.com/Happy-Algorithms-League/e2l-cgp-snn</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:rev:2f370ba6ec46a46cf959afcc6c1c1051394cd02a">https://archive.softwareheritage.org/swh:1:rev:2f370ba6ec46a46cf959afcc6c1c1051394cd02a</ext-link>).</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Andrychowicz</surname> <given-names>M</given-names></name><name><surname>Denil</surname> <given-names>M</given-names></name><name><surname>Gomez</surname> <given-names>S</given-names></name><name><surname>Hoffman</surname> <given-names>MW</given-names></name><name><surname>Pfau</surname> <given-names>D</given-names></name><name><surname>Schaul</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Learning to learn by gradient descent by gradient descent</article-title><conf-name>30th Conference on Neural Information Processing Systems</conf-name><fpage>3981</fpage><lpage>3989</lpage><ext-link ext-link-type="uri" xlink:href="https://papers.nips.cc/paper/2016/file/fb87582825f9d28a8d42c5e5e5e8b23d-Paper.pdf">https://papers.nips.cc/paper/2016/file/fb87582825f9d28a8d42c5e5e5e8b23d-Paper.pdf</ext-link></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Artola</surname> <given-names>A</given-names></name><name><surname>Bröcher</surname> <given-names>S</given-names></name><name><surname>Singer</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Different voltage-dependent thresholds for inducing long-term depression and long-term potentiation in slices of rat visual cortex</article-title><source>Nature</source><volume>347</volume><fpage>69</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1038/347069a0</pub-id><pub-id pub-id-type="pmid">1975639</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bengio</surname> <given-names>Y</given-names></name><name><surname>Bengio</surname> <given-names>S</given-names></name><name><surname>Cloutier</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Learning a synaptic learning rule</article-title><conf-name>IJCNN-91-Seattle International Joint Conference on Neural Networks</conf-name><pub-id pub-id-type="doi">10.1109/IJCNN.1991.155621</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bengio</surname> <given-names>S</given-names></name><name><surname>Bengio</surname> <given-names>Y</given-names></name><name><surname>Cloutier</surname> <given-names>J</given-names></name><name><surname>Gecsei</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>On the optimization of a synaptic learning rule</article-title><conf-name>Preprints Conf. Optimality in Artificial and Biological Neural Networks</conf-name></element-citation></ref><ref id="bib5"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bengio</surname> <given-names>S</given-names></name><name><surname>Bengio</surname> <given-names>Y</given-names></name><name><surname>Cloutier</surname> <given-names>J</given-names></name><name><surname>Gecsei</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1993">1993</year><chapter-title>Generalization of a Parametric Learning Rule</chapter-title><person-group person-group-type="editor"><name><surname>Gielen</surname> <given-names>S</given-names></name><name><surname>Kappen</surname> <given-names>B</given-names></name></person-group><source>ICANN ’93</source><publisher-name>Springer</publisher-name><fpage>502</fpage><pub-id pub-id-type="doi">10.1007/978-1-4471-2063-6_131</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bengio</surname> <given-names>S</given-names></name><name><surname>Bengio</surname> <given-names>Y</given-names></name><name><surname>Cloutier</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Use of genetic programming for the search of a new learning rule for neural networks</article-title><conf-name>IEEE World Congress on Computational Intelligence</conf-name><fpage>324</fpage><lpage>327</lpage><pub-id pub-id-type="doi">10.1109/ICEC.1994.349932</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beyer</surname> <given-names>H-G</given-names></name><name><surname>Schwefel</surname> <given-names>H-P</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Evolution strategies–a comprehensive introduction</article-title><source>Natural Computing</source><volume>1</volume><fpage>3</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1023/A:1015059928466</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bi</surname> <given-names>GQ</given-names></name><name><surname>Poo</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Synaptic modifications in cultured hippocampal neurons: dependence on spike timing, synaptic strength, and postsynaptic cell type</article-title><source>Journal of Neuroscience</source><volume>18</volume><fpage>10464</fpage><lpage>10472</lpage><pub-id pub-id-type="pmid">9852584</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Billaudelle</surname> <given-names>S</given-names></name><name><surname>Stradmann</surname> <given-names>Y</given-names></name><name><surname>Schreiber</surname> <given-names>K</given-names></name><name><surname>Cramer</surname> <given-names>B</given-names></name><name><surname>Baumbach</surname> <given-names>A</given-names></name><name><surname>Dold</surname> <given-names>D</given-names></name><name><surname>Göltz</surname> <given-names>J</given-names></name><name><surname>Kungl</surname> <given-names>AF</given-names></name><name><surname>Wunderlich</surname> <given-names>TC</given-names></name><name><surname>Hartel</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Versatile emulation of spiking neural networks on an accelerated neuromorphic substrate</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1912.12980">https://arxiv.org/abs/1912.12980</ext-link></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bohnstingl</surname> <given-names>T</given-names></name><name><surname>Scherr</surname> <given-names>F</given-names></name><name><surname>Pehle</surname> <given-names>C</given-names></name><name><surname>Meier</surname> <given-names>K</given-names></name><name><surname>Maass</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neuromorphic hardware learns to learn</article-title><source>Frontiers in Neuroscience</source><volume>13</volume><elocation-id>483</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2019.00483</pub-id><pub-id pub-id-type="pmid">31178681</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caporale</surname> <given-names>N</given-names></name><name><surname>Dan</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Spike timing-dependent plasticity: a hebbian learning rule</article-title><source>Annual Review of Neuroscience</source><volume>31</volume><fpage>25</fpage><lpage>46</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.31.060407.125639</pub-id><pub-id pub-id-type="pmid">18275283</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chalmers</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="1991">1991</year><chapter-title>The evolution of learning: An experiment in genetic connectionism</chapter-title><person-group person-group-type="editor"><name><surname>Chalmers</surname> <given-names>DJ</given-names></name></person-group><source>Connectionist Models</source><publisher-loc>Amsterdam, Netherlands</publisher-loc><publisher-name>Elsevier</publisher-name><fpage>81</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1016/B978-1-4832-1448-1.50014-7</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clopath</surname> <given-names>C</given-names></name><name><surname>Büsing</surname> <given-names>L</given-names></name><name><surname>Vasilaki</surname> <given-names>E</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Connectivity reflects coding: a model of voltage-based STDP with homeostasis</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>344</fpage><lpage>352</lpage><pub-id pub-id-type="doi">10.1038/nn.2479</pub-id><pub-id pub-id-type="pmid">20098420</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Confavreux</surname> <given-names>B</given-names></name><name><surname>Zenke</surname> <given-names>F</given-names></name><name><surname>Agnes</surname> <given-names>E</given-names></name><name><surname>Lillicrap</surname> <given-names>T</given-names></name><name><surname>Vogels</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A meta-learning approach to (re) discover plasticity rules that carve a desired function into a neural network</article-title><conf-name>34th Conference on Neural Information Processing Systems</conf-name><ext-link ext-link-type="uri" xlink:href="https://proceedings.neurips.cc/paper/2020/file/bdbd5ebfde4934142c8a88e7a3796cd5-Paper.pdf">https://proceedings.neurips.cc/paper/2020/file/bdbd5ebfde4934142c8a88e7a3796cd5-Paper.pdf</ext-link></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname> <given-names>J</given-names></name><name><surname>Witten</surname> <given-names>IB</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Striatal circuits for reward learning and decision-making</article-title><source>Nature Reviews Neuroscience</source><volume>20</volume><fpage>482</fpage><lpage>494</lpage><pub-id pub-id-type="doi">10.1038/s41583-019-0189-2</pub-id><pub-id pub-id-type="pmid">31171839</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davies</surname> <given-names>M</given-names></name><name><surname>Srinivasa</surname> <given-names>N</given-names></name><name><surname>Lin</surname> <given-names>T-H</given-names></name><name><surname>Chinya</surname> <given-names>G</given-names></name><name><surname>Cao</surname> <given-names>Y</given-names></name><name><surname>Choday</surname> <given-names>SH</given-names></name><name><surname>Dimou</surname> <given-names>G</given-names></name><name><surname>Joshi</surname> <given-names>P</given-names></name><name><surname>Imam</surname> <given-names>N</given-names></name><name><surname>Jain</surname> <given-names>S</given-names></name><name><surname>Liao</surname> <given-names>Y</given-names></name><name><surname>Lin</surname> <given-names>C-K</given-names></name><name><surname>Lines</surname> <given-names>A</given-names></name><name><surname>Liu</surname> <given-names>R</given-names></name><name><surname>Mathaikutty</surname> <given-names>D</given-names></name><name><surname>McCoy</surname> <given-names>S</given-names></name><name><surname>Paul</surname> <given-names>A</given-names></name><name><surname>Tse</surname> <given-names>J</given-names></name><name><surname>Venkataramanan</surname> <given-names>G</given-names></name><name><surname>Weng</surname> <given-names>Y-H</given-names></name><name><surname>Wild</surname> <given-names>A</given-names></name><name><surname>Yang</surname> <given-names>Y</given-names></name><name><surname>Wang</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Loihi: a neuromorphic manycore processor with On-Chip learning</article-title><source>IEEE Micro</source><volume>38</volume><fpage>82</fpage><lpage>99</lpage><pub-id pub-id-type="doi">10.1109/MM.2018.112130359</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname> <given-names>GW</given-names></name><name><surname>Bezprozvanny</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Maintaining the stability of neural function: a homeostatic hypothesis</article-title><source>Annual Review of Physiology</source><volume>63</volume><fpage>847</fpage><lpage>869</lpage><pub-id pub-id-type="doi">10.1146/annurev.physiol.63.1.847</pub-id><pub-id pub-id-type="pmid">11181978</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dayan</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1991">1991</year><chapter-title>Connectionist Models</chapter-title><person-group person-group-type="editor"><name><surname>Touretzky</surname> <given-names>D</given-names></name><name><surname>Elman</surname> <given-names>J</given-names></name><name><surname>Sejnowski</surname> <given-names>T</given-names></name><name><surname>Hinton</surname> <given-names>G</given-names></name></person-group><source>Oxford Companion to Consciousness</source><publisher-loc>New York</publisher-loc><publisher-name>Oxford University Press</publisher-name><fpage>45</fpage><lpage>51</lpage></element-citation></ref><ref id="bib19"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Deb</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2001">2001</year><source>Multi-Objective Optimization Using Evolutionary Algorithms</source><publisher-loc>New Jersey, United States</publisher-loc><publisher-name>John Wiley &amp; Sons</publisher-name></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deneve</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Bayesian spiking neurons I: inference</article-title><source>Neural Computation</source><volume>20</volume><fpage>91</fpage><lpage>117</lpage><pub-id pub-id-type="doi">10.1162/neco.2008.20.1.91</pub-id><pub-id pub-id-type="pmid">18045002</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dold</surname> <given-names>D</given-names></name><name><surname>Bytschok</surname> <given-names>I</given-names></name><name><surname>Kungl</surname> <given-names>AF</given-names></name><name><surname>Baumbach</surname> <given-names>A</given-names></name><name><surname>Breitwieser</surname> <given-names>O</given-names></name><name><surname>Senn</surname> <given-names>W</given-names></name><name><surname>Schemmel</surname> <given-names>J</given-names></name><name><surname>Meier</surname> <given-names>K</given-names></name><name><surname>Petrovici</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Stochasticity from function - Why the bayesian brain may need no noise</article-title><source>Neural Networks</source><volume>119</volume><fpage>200</fpage><lpage>213</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2019.08.002</pub-id><pub-id pub-id-type="pmid">31450073</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dudek</surname> <given-names>SM</given-names></name><name><surname>Bear</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Bidirectional long-term modification of synaptic effectiveness in the adult and immature Hippocampus</article-title><source>The Journal of Neuroscience</source><volume>13</volume><fpage>2910</fpage><lpage>2918</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.13-07-02910.1993</pub-id><pub-id pub-id-type="pmid">8331379</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eppler</surname> <given-names>JM</given-names></name><name><surname>Helias</surname> <given-names>M</given-names></name><name><surname>Muller</surname> <given-names>E</given-names></name><name><surname>Diesmann</surname> <given-names>M</given-names></name><name><surname>Gewaltig</surname> <given-names>MO</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>PyNEST: a convenient interface to the NEST simulator</article-title><source>Frontiers in Neuroinformatics</source><volume>2</volume><elocation-id>12</elocation-id><pub-id pub-id-type="doi">10.3389/neuro.11.012.2008</pub-id><pub-id pub-id-type="pmid">19198667</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Eppler</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>The Neural Simulation Tool - NEST</data-title><source>Zenodo</source><version designator="3c6f0f3">3c6f0f3</version><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.1400175">https://doi.org/10.5281/zenodo.1400175</ext-link></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frémaux</surname> <given-names>N</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuromodulated Spike-Timing-Dependent plasticity, and theory of Three-Factor learning rules</article-title><source>Frontiers in Neural Circuits</source><volume>9</volume><elocation-id>85</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2015.00085</pub-id><pub-id pub-id-type="pmid">26834568</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>French</surname> <given-names>RM</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Catastrophic forgetting in connectionist networks</article-title><source>Trends in Cognitive Sciences</source><volume>3</volume><fpage>128</fpage><lpage>135</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(99)01294-2</pub-id><pub-id pub-id-type="pmid">10322466</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Gaier</surname> <given-names>A</given-names></name><name><surname>Ha</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Weight agnostic neural networks</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1906.04358">https://arxiv.org/abs/1906.04358</ext-link></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gewaltig</surname> <given-names>M-O</given-names></name><name><surname>Diesmann</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>NEST (NEural simulation tool)</article-title><source>Scholarpedia</source><volume>2</volume><elocation-id>1430</elocation-id><pub-id pub-id-type="doi">10.4249/scholarpedia.1430</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldman</surname> <given-names>BW</given-names></name><name><surname>Punch</surname> <given-names>WF</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Analysis of cartesian genetic programming’s Evolutionary Mechanisms</article-title><source>IEEE Transactions on Evolutionary Computation</source><volume>19</volume><fpage>359</fpage><lpage>373</lpage><pub-id pub-id-type="doi">10.1109/TEVC.2014.2324539</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Göltz</surname> <given-names>J</given-names></name><name><surname>Baumbach</surname> <given-names>A</given-names></name><name><surname>Billaudelle</surname> <given-names>S</given-names></name><name><surname>Breitwieser</surname> <given-names>O</given-names></name><name><surname>Dold</surname> <given-names>D</given-names></name><name><surname>Kriener</surname> <given-names>L</given-names></name><name><surname>Kungl</surname> <given-names>AF</given-names></name><name><surname>Senn</surname> <given-names>W</given-names></name><name><surname>Schemmel</surname> <given-names>J</given-names></name><name><surname>Meier</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Fast and deep neuromorphic learning with time-to-first-spike coding</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1912.11443">https://arxiv.org/abs/1912.11443</ext-link></element-citation></ref><ref id="bib31"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Goodfellow</surname> <given-names>I</given-names></name><name><surname>Bengio</surname> <given-names>Y</given-names></name><name><surname>Courville</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><source>Deep Learning</source><publisher-loc>Massachusetts, United States</publisher-loc><publisher-name>MIT press</publisher-name></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gütig</surname> <given-names>R</given-names></name><name><surname>Aharonov</surname> <given-names>R</given-names></name><name><surname>Rotter</surname> <given-names>S</given-names></name><name><surname>Sompolinsky</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Learning input correlations through nonlinear temporally asymmetric hebbian plasticity</article-title><source>The Journal of Neuroscience</source><volume>23</volume><fpage>3697</fpage><lpage>3714</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.23-09-03697.2003</pub-id><pub-id pub-id-type="pmid">12736341</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ivakhnenko</surname> <given-names>AG</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>Polynomial theory of complex systems</article-title><conf-name>IEEE Transactions on Systems, Man, and Cybernetics</conf-name><fpage>364</fpage><lpage>378</lpage><pub-id pub-id-type="doi">10.1109/TSMC.1971.4308320</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Izhikevich</surname> <given-names>EM</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Solving the distal reward problem through linkage of STDP and dopamine signaling</article-title><source>Cerebral Cortex</source><volume>17</volume><fpage>2443</fpage><lpage>2452</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhl152</pub-id><pub-id pub-id-type="pmid">17220510</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Izzo</surname> <given-names>D</given-names></name><name><surname>Biscani</surname> <given-names>F</given-names></name><name><surname>Mereta</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Differentiable genetic programming</article-title><conf-name>European Conference on Genetic Programming</conf-name><fpage>35</fpage><lpage>51</lpage></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jordan</surname> <given-names>J</given-names></name><name><surname>Ippen</surname> <given-names>T</given-names></name><name><surname>Helias</surname> <given-names>M</given-names></name><name><surname>Kitayama</surname> <given-names>I</given-names></name><name><surname>Sato</surname> <given-names>M</given-names></name><name><surname>Igarashi</surname> <given-names>J</given-names></name><name><surname>Diesmann</surname> <given-names>M</given-names></name><name><surname>Kunkel</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Extremely scalable spiking neuronal network simulation code: from laptops to exascale computers</article-title><source>Frontiers in Neuroinformatics</source><volume>2</volume><elocation-id>2</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2018.00002</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jordan</surname> <given-names>J</given-names></name><name><surname>Petrovici</surname> <given-names>MA</given-names></name><name><surname>Breitwieser</surname> <given-names>O</given-names></name><name><surname>Schemmel</surname> <given-names>J</given-names></name><name><surname>Meier</surname> <given-names>K</given-names></name><name><surname>Diesmann</surname> <given-names>M</given-names></name><name><surname>Tetzlaff</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Deterministic networks for probabilistic computing</article-title><source>Scientific Reports</source><volume>9</volume><fpage>1</fpage><lpage>17</lpage><pub-id pub-id-type="doi">10.1038/s41598-019-54137-7</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Jordan</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021a</year><data-title>e2l-cgp-snn</data-title><source>Software Heritage</source><version designator="swh:1:rev:2f370ba6ec46a46cf959afcc6c1c1051394cd02a">swh:1:rev:2f370ba6ec46a46cf959afcc6c1c1051394cd02a</version><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:390ee2664ea9a00fac9f6be0950a9f6312403292;origin=https://github.com/Happy-Algorithms-League/e2l-cgp-snn;visit=swh:1:snp:10c1f7017ac4ad4d702a505cf1d845502f61b954;anchor=swh:1:rev:2f370ba6ec46a46cf959afcc6c1c1051394cd02a">https://archive.softwareheritage.org/swh:1:dir:390ee2664ea9a00fac9f6be0950a9f6312403292;origin=https://github.com/Happy-Algorithms-League/e2l-cgp-snn;visit=swh:1:snp:10c1f7017ac4ad4d702a505cf1d845502f61b954;anchor=swh:1:rev:2f370ba6ec46a46cf959afcc6c1c1051394cd02a</ext-link></element-citation></ref><ref id="bib39"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Jordan</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021b</year><data-title>HAL-CGP</data-title><source>GitHub</source><version designator="3.0">3.0</version><ext-link ext-link-type="uri" xlink:href="https://github.com/Happy-Algorithms-League/hal-cgp">https://github.com/Happy-Algorithms-League/hal-cgp</ext-link></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kappel</surname> <given-names>D</given-names></name><name><surname>Habenschuss</surname> <given-names>S</given-names></name><name><surname>Legenstein</surname> <given-names>R</given-names></name><name><surname>Maass</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Network plasticity as bayesian inference</article-title><source>PLOS Computational Biology</source><volume>11</volume><elocation-id>e1004485</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004485</pub-id><pub-id pub-id-type="pmid">26545099</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kempter</surname> <given-names>R</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name><name><surname>van Hemmen</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Hebbian learning and spiking neurons</article-title><source>Physical Review E</source><volume>59</volume><fpage>4498</fpage><lpage>4514</lpage><pub-id pub-id-type="doi">10.1103/PhysRevE.59.4498</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Keup</surname> <given-names>C</given-names></name><name><surname>Kühn</surname> <given-names>T</given-names></name><name><surname>Dahmen</surname> <given-names>D</given-names></name><name><surname>Helias</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Transient chaotic dimensionality expansion by recurrent networks</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2002.11006">https://arxiv.org/abs/2002.11006</ext-link></element-citation></ref><ref id="bib43"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Koza</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="1992">1992</year><source>Genetic Programming: On the Programming of Computers by Means of Natural Selection</source><publisher-loc>Cambridge, United States</publisher-loc><publisher-name>MIT press</publisher-name></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koza</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Human-competitive results produced by genetic programming</article-title><source>Genetic Programming and Evolvable Machines</source><volume>11</volume><fpage>251</fpage><lpage>284</lpage><pub-id pub-id-type="doi">10.1007/s10710-010-9112-3</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kutschireiter</surname> <given-names>A</given-names></name><name><surname>Surace</surname> <given-names>SC</given-names></name><name><surname>Sprekeler</surname> <given-names>H</given-names></name><name><surname>Pfister</surname> <given-names>JP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Nonlinear bayesian filtering and learning: a neuronal dynamics for perception</article-title><source>Scientific Reports</source><volume>7</volume><elocation-id>8722</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-017-06519-y</pub-id><pub-id pub-id-type="pmid">28821729</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Linnainmaa</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1970">1970</year><source>The Representation of the Cumulative Rounding Error of an Algorithm as a Taylor Expansion of the Local Rounding Errors</source><publisher-loc>Helsinki, Finland</publisher-loc><publisher-name>University of Helsinki</publisher-name></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marblestone</surname> <given-names>AH</given-names></name><name><surname>Wayne</surname> <given-names>G</given-names></name><name><surname>Kording</surname> <given-names>KP</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Toward an integration of deep learning and neuroscience</article-title><source>Frontiers in Computational Neuroscience</source><volume>10</volume><elocation-id>94</elocation-id><pub-id pub-id-type="doi">10.3389/fncom.2016.00094</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Masquelier</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>STDP allows Close-to-Optimal spatiotemporal spike pattern detection by single coincidence detector neurons</article-title><source>Neuroscience</source><volume>389</volume><fpage>133</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2017.06.032</pub-id><pub-id pub-id-type="pmid">28668487</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Mayr</surname> <given-names>C</given-names></name><name><surname>Hoeppner</surname> <given-names>S</given-names></name><name><surname>Furber</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Spinnaker 2: a 10 million core processor system for brain simulation and machine learning</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1911.02385">https://arxiv.org/abs/1911.02385</ext-link></element-citation></ref><ref id="bib50"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Metz</surname> <given-names>L</given-names></name><name><surname>Maheswaranathan</surname> <given-names>N</given-names></name><name><surname>Freeman</surname> <given-names>CD</given-names></name><name><surname>Poole</surname> <given-names>B</given-names></name><name><surname>Sohl-Dickstein</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Tasks, stability, architecture, and compute: training more effective learned optimizers, and using them to train themselves</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2009.11243">https://arxiv.org/abs/2009.11243</ext-link></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meurer</surname> <given-names>A</given-names></name><name><surname>Smith</surname> <given-names>CP</given-names></name><name><surname>Paprocki</surname> <given-names>M</given-names></name><name><surname>Čertík</surname> <given-names>O</given-names></name><name><surname>Kirpichev</surname> <given-names>SB</given-names></name><name><surname>Rocklin</surname> <given-names>M</given-names></name><name><surname>Kumar</surname> <given-names>AMiT</given-names></name><name><surname>Ivanov</surname> <given-names>S</given-names></name><name><surname>Moore</surname> <given-names>JK</given-names></name><name><surname>Singh</surname> <given-names>S</given-names></name><name><surname>Rathnayake</surname> <given-names>T</given-names></name><name><surname>Vig</surname> <given-names>S</given-names></name><name><surname>Granger</surname> <given-names>BE</given-names></name><name><surname>Muller</surname> <given-names>RP</given-names></name><name><surname>Bonazzi</surname> <given-names>F</given-names></name><name><surname>Gupta</surname> <given-names>H</given-names></name><name><surname>Vats</surname> <given-names>S</given-names></name><name><surname>Johansson</surname> <given-names>F</given-names></name><name><surname>Pedregosa</surname> <given-names>F</given-names></name><name><surname>Curry</surname> <given-names>MJ</given-names></name><name><surname>Terrel</surname> <given-names>AR</given-names></name><name><surname>Roučka</surname> <given-names>S</given-names></name><name><surname>Saboo</surname> <given-names>A</given-names></name><name><surname>Fernando</surname> <given-names>I</given-names></name><name><surname>Kulal</surname> <given-names>S</given-names></name><name><surname>Cimrman</surname> <given-names>R</given-names></name><name><surname>Scopatz</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>SymPy: symbolic computing in Python</article-title><source>PeerJ Computer Science</source><volume>3</volume><elocation-id>e103</elocation-id><pub-id pub-id-type="doi">10.7717/peerj-cs.103</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Miconi</surname> <given-names>T</given-names></name><name><surname>Rawal</surname> <given-names>A</given-names></name><name><surname>Clune</surname> <given-names>J</given-names></name><name><surname>Stanley</surname> <given-names>KO</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Backpropamine: training self-modifying neural networks with differentiable neuromodulated plasticity</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2002.10585">https://arxiv.org/abs/2002.10585</ext-link></element-citation></ref><ref id="bib53"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Miller</surname> <given-names>JF</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>An empirical study of the efficiency of learning boolean functions using a cartesian genetic programming approach</article-title><conf-name>Proceedings of the 1st Annual Conference on Genetic and Evolutionary Computation-</conf-name><fpage>1135</fpage><lpage>1142</lpage><pub-id pub-id-type="doi">10.5555/2934046.2934074</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Miller</surname> <given-names>JF</given-names></name></person-group><year iso-8601-date="2011">2011</year><source>Cartesian Genetic Programming</source><publisher-loc>Berlin, Heidelberg</publisher-loc><publisher-name>Springer</publisher-name><pub-id pub-id-type="doi">10.1007/978-3-642-17310-3_2</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname> <given-names>BL</given-names></name><name><surname>Goldberg</surname> <given-names>DE</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Genetic algorithms, tournament selection, and the effects of noise</article-title><source>Complex Systems</source><volume>9</volume><fpage>193</fpage><lpage>212</lpage></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname> <given-names>KD</given-names></name><name><surname>MacKay</surname> <given-names>DJC</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>The role of constraints in hebbian learning</article-title><source>Neural Computation</source><volume>6</volume><fpage>100</fpage><lpage>126</lpage><pub-id pub-id-type="doi">10.1162/neco.1994.6.1.100</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Miller</surname> <given-names>J</given-names></name><name><surname>Thomson</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Cartesian genetic programming</article-title><conf-name>European Conference on Genetic Programming</conf-name><fpage>121</fpage><lpage>132</lpage></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moradi</surname> <given-names>S</given-names></name><name><surname>Qiao</surname> <given-names>N</given-names></name><name><surname>Stefanini</surname> <given-names>F</given-names></name><name><surname>Indiveri</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A scalable multicore architecture with heterogeneous memory structures for dynamic neuromorphic asynchronous processors (DYNAPs)</article-title><source>IEEE Transactions on Biomedical Circuits and Systems</source><volume>12</volume><fpage>106</fpage><lpage>122</lpage><pub-id pub-id-type="doi">10.1109/TBCAS.2017.2759700</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morrison</surname> <given-names>A</given-names></name><name><surname>Aertsen</surname> <given-names>A</given-names></name><name><surname>Diesmann</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Spike-timing-dependent plasticity in balanced random networks</article-title><source>Neural Computation</source><volume>19</volume><fpage>1437</fpage><lpage>1467</lpage><pub-id pub-id-type="doi">10.1162/neco.2007.19.6.1437</pub-id><pub-id pub-id-type="pmid">17444756</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morrison</surname> <given-names>A</given-names></name><name><surname>Diesmann</surname> <given-names>M</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Phenomenological models of synaptic plasticity based on spike timing</article-title><source>Biological Cybernetics</source><volume>98</volume><fpage>459</fpage><lpage>478</lpage><pub-id pub-id-type="doi">10.1007/s00422-008-0233-1</pub-id><pub-id pub-id-type="pmid">18491160</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ngezahayo</surname> <given-names>A</given-names></name><name><surname>Schachner</surname> <given-names>M</given-names></name><name><surname>Artola</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Synaptic activity modulates the induction of bidirectional synaptic changes in adult mouse Hippocampus</article-title><source>The Journal of Neuroscience</source><volume>20</volume><fpage>2451</fpage><lpage>2458</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.20-07-02451.2000</pub-id><pub-id pub-id-type="pmid">10729325</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nordlie</surname> <given-names>E</given-names></name><name><surname>Gewaltig</surname> <given-names>MO</given-names></name><name><surname>Plesser</surname> <given-names>HE</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Towards reproducible descriptions of neuronal network models</article-title><source>PLOS Computational Biology</source><volume>5</volume><elocation-id>e1000456</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000456</pub-id><pub-id pub-id-type="pmid">19662159</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oja</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>A simplified neuron model as a principal component analyzer</article-title><source>Journal of Mathematical Biology</source><volume>15</volume><fpage>267</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1007/BF00275687</pub-id><pub-id pub-id-type="pmid">7153672</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Orchard</surname> <given-names>J</given-names></name><name><surname>Wang</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The evolution of a generalized neural learning rule</article-title><conf-name>Neural Networks (IJCNN), 2016 International Joint Conference</conf-name><fpage>4688</fpage><lpage>4694</lpage></element-citation></ref><ref id="bib65"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Paszke</surname> <given-names>A</given-names></name><name><surname>Gross</surname> <given-names>S</given-names></name><name><surname>Massa</surname> <given-names>F</given-names></name><name><surname>Lerer</surname> <given-names>A</given-names></name><name><surname>Bradbury</surname> <given-names>J</given-names></name><name><surname>Chanan</surname> <given-names>G</given-names></name><name><surname>Killeen</surname> <given-names>T</given-names></name><name><surname>Lin</surname> <given-names>Z</given-names></name><name><surname>Gimelshein</surname> <given-names>N</given-names></name><name><surname>Antiga</surname> <given-names>L</given-names></name><name><surname>Desmaison</surname> <given-names>A</given-names></name><name><surname>Kopf</surname> <given-names>A</given-names></name><name><surname>Yang</surname> <given-names>E</given-names></name><name><surname>DeVito</surname> <given-names>Z</given-names></name><name><surname>Raison</surname> <given-names>M</given-names></name><name><surname>Tejani</surname> <given-names>A</given-names></name><name><surname>Chilamkurthy</surname> <given-names>S</given-names></name><name><surname>Steiner</surname> <given-names>B</given-names></name><name><surname>Fang</surname> <given-names>L</given-names></name><name><surname>Bai</surname> <given-names>J</given-names></name><name><surname>Chintala</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>PyTorch: an imperative style, high-performance deep learning library</article-title><conf-name>33rd Conference on Neural Information Processing Systems. .</conf-name><fpage>8024</fpage><lpage>8035</lpage><ext-link ext-link-type="uri" xlink:href="https://papers.neurips.cc/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf">https://papers.neurips.cc/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf</ext-link></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfister</surname> <given-names>JP</given-names></name><name><surname>Toyoizumi</surname> <given-names>T</given-names></name><name><surname>Barber</surname> <given-names>D</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Optimal spike-timing-dependent plasticity for precise action potential firing in supervised learning</article-title><source>Neural Computation</source><volume>18</volume><fpage>1318</fpage><lpage>1348</lpage><pub-id pub-id-type="doi">10.1162/neco.2006.18.6.1318</pub-id><pub-id pub-id-type="pmid">16764506</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfister</surname> <given-names>JP</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Lengyel</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Synapses with short-term plasticity are optimal estimators of presynaptic membrane potentials</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1271</fpage><lpage>1275</lpage><pub-id pub-id-type="doi">10.1038/nn.2640</pub-id><pub-id pub-id-type="pmid">20852625</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Plotnikov</surname> <given-names>D</given-names></name><name><surname>Rumpe</surname> <given-names>B</given-names></name><name><surname>Blundell</surname> <given-names>I</given-names></name><name><surname>Ippen</surname> <given-names>T</given-names></name><name><surname>Eppler</surname> <given-names>JM</given-names></name><name><surname>Morrison</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>NESTML: a modeling language for spiking neurons</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1606.02882">https://arxiv.org/abs/1606.02882</ext-link></element-citation></ref><ref id="bib69"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Radi</surname> <given-names>A</given-names></name><name><surname>Poli</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2003">2003</year><chapter-title>Discovering efficient learning rules for feedforward neural networks using genetic programming</chapter-title><person-group person-group-type="editor"><name><surname>Abraham</surname> <given-names>A</given-names></name><name><surname>Jain</surname> <given-names>LC</given-names></name><name><surname>Kacprzyk</surname> <given-names>J</given-names></name></person-group><source>Recent Advances in Intelligent Paradigms and Applications</source><publisher-name>Springer</publisher-name><fpage>133</fpage><lpage>159</lpage><pub-id pub-id-type="doi">10.1007/978-3-7908-1770-6_7</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Real</surname> <given-names>E</given-names></name><name><surname>Liang</surname> <given-names>C</given-names></name><name><surname>So</surname> <given-names>D</given-names></name><name><surname>Le</surname> <given-names>Q</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>AutoML-Zero: evolving machine learning algorithms from scratch</article-title><conf-name>International Conference on Machine Learning</conf-name><fpage>8007</fpage><lpage>8019</lpage></element-citation></ref><ref id="bib71"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Risi</surname> <given-names>S</given-names></name><name><surname>Stanley</surname> <given-names>KO</given-names></name></person-group><year iso-8601-date="2010">2010</year><chapter-title>Indirectly encoding neural plasticity as a pattern of local rules</chapter-title><person-group person-group-type="editor"><name><surname>Doncieux</surname> <given-names>S</given-names></name><name><surname>Girard</surname> <given-names>B</given-names></name><name><surname>Guillot</surname> <given-names>A</given-names></name><name><surname>Hallam</surname> <given-names>J</given-names></name><name><surname>Meyer</surname> <given-names>JA</given-names></name><name><surname>Mouret</surname> <given-names>JB</given-names></name></person-group><source>From Animals to Animats 11</source><publisher-loc>New York, United States</publisher-loc><publisher-name>Springer</publisher-name><fpage>533</fpage><lpage>543</lpage><pub-id pub-id-type="doi">10.1007/978-3-642-15193-4_50</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rumelhart</surname> <given-names>DE</given-names></name><name><surname>Hinton</surname> <given-names>GE</given-names></name><name><surname>Williams</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="1985">1985</year><source>Learning Internal Representations by Error Propagation</source><publisher-name>MIT Press</publisher-name><pub-id pub-id-type="doi">10.5555/104279.104293</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Sacramento</surname> <given-names>J</given-names></name><name><surname>Costa</surname> <given-names>RP</given-names></name><name><surname>Bengio</surname> <given-names>Y</given-names></name><name><surname>Senn</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Dendritic cortical microcircuits approximate the backpropagation algorithm</article-title><conf-name>NIPS'18: Proceedings of the 32nd International Conference on Neural Information Processing Systems</conf-name><fpage>8721</fpage><lpage>8732</lpage><pub-id pub-id-type="doi">10.5555/3327546.3327550</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Schmidt</surname> <given-names>M</given-names></name><name><surname>Jordan</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>HAL-CGP</data-title><source>Cartesian Genetic Programming in Pure Python</source><version designator="fbb5435">fbb5435</version><ext-link ext-link-type="uri" xlink:href="https://github.com/Happy-Algorithms-League/hal-cgp">https://github.com/Happy-Algorithms-League/hal-cgp</ext-link></element-citation></ref><ref id="bib75"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>So</surname> <given-names>DR</given-names></name><name><surname>Liang</surname> <given-names>C</given-names></name><name><surname>Le</surname> <given-names>Q</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The evolved transformer</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1901.11117">https://arxiv.org/abs/1901.11117</ext-link></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Soltoggio</surname> <given-names>A</given-names></name><name><surname>Stanley</surname> <given-names>KO</given-names></name><name><surname>Risi</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Born to learn: the inspiration, progress, and future of evolved plastic artificial neural networks</article-title><source>Neural Networks</source><volume>108</volume><fpage>48</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2018.07.013</pub-id><pub-id pub-id-type="pmid">30142505</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sutton</surname> <given-names>RS</given-names></name><name><surname>Barto</surname> <given-names>AG</given-names></name></person-group><year iso-8601-date="2018">2018</year><source>Reinforcement Learning: An Introduction</source><publisher-loc>Cambridge, United Kingdom</publisher-loc><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib78"><element-citation publication-type="software"><person-group person-group-type="author"><collab>SymEngine Contributors</collab></person-group><year iso-8601-date="2021">2021</year><data-title>SymEngine</data-title><source>GitHub</source><version designator="0.7.0">0.7.0</version><ext-link ext-link-type="uri" xlink:href="https://github.com/symengine/symengine/releases/tag/v0.7.0">https://github.com/symengine/symengine/releases/tag/v0.7.0</ext-link></element-citation></ref><ref id="bib79"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Topchy</surname> <given-names>A</given-names></name><name><surname>Punch</surname> <given-names>WF</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Faster genetic programming based on local gradient search of numeric leaf values</article-title><conf-name>Proceedings of the 3rd Annual Conference on Genetic and Evolutionary Computation</conf-name><fpage>155</fpage><lpage>162</lpage><pub-id pub-id-type="doi">10.5555/2955239.2955258</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Toyoizumi</surname> <given-names>T</given-names></name><name><surname>Pfister</surname> <given-names>JP</given-names></name><name><surname>Aihara</surname> <given-names>K</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Generalized Bienenstock-Cooper-Munro rule for spiking neurons that maximizes information transmission</article-title><source>PNAS</source><volume>102</volume><fpage>5239</fpage><lpage>5244</lpage><pub-id pub-id-type="doi">10.1073/pnas.0500495102</pub-id><pub-id pub-id-type="pmid">15795376</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Urbanczik</surname> <given-names>R</given-names></name><name><surname>Senn</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Reinforcement learning in populations of spiking neurons</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>250</fpage><lpage>252</lpage><pub-id pub-id-type="doi">10.1038/nn.2264</pub-id><pub-id pub-id-type="pmid">19219040</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Urbanczik</surname> <given-names>R</given-names></name><name><surname>Senn</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Learning by the dendritic prediction of somatic spiking</article-title><source>Neuron</source><volume>81</volume><fpage>521</fpage><lpage>528</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.11.030</pub-id><pub-id pub-id-type="pmid">24507189</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Walt</surname> <given-names>S</given-names></name><name><surname>Colbert</surname> <given-names>SC</given-names></name><name><surname>Varoquaux</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The NumPy array: a structure for efficient numerical computation</article-title><source>Computing in Science &amp; Engineering</source><volume>13</volume><fpage>22</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1109/MCSE.2011.37</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vasilaki</surname> <given-names>E</given-names></name><name><surname>Frémaux</surname> <given-names>N</given-names></name><name><surname>Urbanczik</surname> <given-names>R</given-names></name><name><surname>Senn</surname> <given-names>W</given-names></name><name><surname>Gerstner</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Spike-based reinforcement learning in continuous state and action space: when policy gradient methods fail</article-title><source>PLOS Computational Biology</source><volume>5</volume><elocation-id>e1000586</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000586</pub-id><pub-id pub-id-type="pmid">19997492</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Weaver</surname> <given-names>L</given-names></name><name><surname>Tao</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The optimal reward baseline for gradient-based reinforcement learning</article-title><conf-name>Proceedings of the Seventeenth Conference on Uncertainty in Artificial Intelligence</conf-name><fpage>535</fpage><lpage>538</lpage><pub-id pub-id-type="doi">10.5555/2074022.2074088</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Welch</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="1947">1947</year><article-title>The generalization ofstudent’s’ problem when several different population variances are involved</article-title><source>Biometrika</source><volume>34</volume><fpage>28</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.1093/biomet/34.1-2.28</pub-id><pub-id pub-id-type="pmid">20287819</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whittington</surname> <given-names>JCR</given-names></name><name><surname>Bogacz</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Theories of error Back-Propagation in the brain</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>235</fpage><lpage>250</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.12.005</pub-id><pub-id pub-id-type="pmid">30704969</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Williams</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1986">1986</year><source>Reinforcement Learning in Connectionist Networks: A Mathematical Analysis</source><publisher-loc>San Diego</publisher-loc><publisher-name>University of California</publisher-name></element-citation></ref><ref id="bib89"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Williams</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1988">1988</year><source>Toward a Theory of Reinforcement-Learning Connectionist Systems</source><publisher-loc>Boston</publisher-loc><publisher-name>Northeastern University</publisher-name></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Simple statistical gradient-following algorithms for connectionist reinforcement learning</article-title><source>Machine Learning</source><volume>8</volume><fpage>229</fpage><lpage>256</lpage><pub-id pub-id-type="doi">10.1007/BF00992696</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zador</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A critique of pure learning and what artificial neural networks can learn from animal brains</article-title><source>Nature Communications</source><volume>10</volume><fpage>1</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1038/s41467-019-11786-6</pub-id><pub-id pub-id-type="pmid">31434893</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zaytsev</surname> <given-names>YV</given-names></name><name><surname>Morrison</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>CyNEST: a maintainable Cython-based interface for the NEST simulator</article-title><source>Frontiers in Neuroinformatics</source><volume>8</volume><elocation-id>23</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2014.00023</pub-id><pub-id pub-id-type="pmid">24672470</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><boxed-text><sec id="s8" sec-type="appendix"><title>A reward-driven learning</title><sec id="s8-1"><title>Full evolution data for different CGP hyperparameter choices</title><p>The following tables summarize all evolved plasticity rules for the four different hyperparameter sets used for the reward-driven learning experiments.</p><table-wrap id="inlinetable2" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th colspan="2">CGP hyperparameter set 0</th></tr><tr><th>Population</th><th><inline-formula><mml:math id="inf177"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mtext>mutation</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.035</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></th></tr></thead><tbody><tr><td>Genome</td><td><inline-formula><mml:math id="inf178"><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>inputs</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>outputs</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>rows</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>columns</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>24</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mtext>max</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>24</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>Primitives</td><td>Add, Sub, Mul, Div, Const(1.0), Const(0.5)</td></tr><tr><td>EA</td><td><inline-formula><mml:math id="inf179"><mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>breeding</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>tournament</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mtext>reorder</mml:mtext><mml:mo>=</mml:mo><mml:mtext>true</mml:mtext></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>Other</td><td><inline-formula><mml:math id="inf180"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>1000</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>500.0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table></table-wrap><table-wrap id="inlinetable3" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th colspan="3">Discovered plasticity rules for hyperparameter set 0</th></tr><tr><th>Label</th><th>Fitness <inline-formula><mml:math id="inf181"><mml:mi class="ltx_font_mathcaligraphic" mathvariant="normal">F</mml:mi></mml:math></inline-formula></th><th>Expression <inline-formula><mml:math id="inf182"><mml:mi>f</mml:mi></mml:math></inline-formula></th></tr></thead><tbody><tr><td>LR0</td><td>216.2</td><td><inline-formula><mml:math id="inf183"><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>/</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR1</td><td>73.0</td><td><inline-formula><mml:math id="inf184"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mmultiscripts><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext><mml:none/><mml:mn>2</mml:mn></mml:mmultiscripts></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR2</td><td>216.2</td><td><inline-formula><mml:math id="inf185"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mn>1.0</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR3</td><td>221.6</td><td><inline-formula><mml:math id="inf186"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mn>1.0</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mn>1.0</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR4</td><td>234.2</td><td><inline-formula><mml:math id="inf187"><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR5</td><td>216.2</td><td><inline-formula><mml:math id="inf188"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR6</td><td>69.2</td><td><inline-formula><mml:math id="inf189"><mml:mrow><mml:mrow><mml:mrow><mml:mn>4.0</mml:mn><mml:mo>⁢</mml:mo><mml:mmultiscripts><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext><mml:none/><mml:mn>2</mml:mn></mml:mmultiscripts></mml:mrow><mml:mo>/</mml:mo><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mn>2.0</mml:mn><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR7</td><td>234.2</td><td><inline-formula><mml:math id="inf190"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula></td></tr></tbody></table></table-wrap><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Fitness of best individual per generation as a function of the generation index for multiple runs of the evolutionary algorithm with different initial conditions for hyperparameter set 0.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66273-app1-fig1-v1.tif"/></fig><table-wrap id="inlinetable4" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th colspan="2">CGP hyperparameter set 1</th></tr><tr><th>Population</th><th><inline-formula><mml:math id="inf191"><mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mtext>mutation</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0.035</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula></th></tr></thead><tbody><tr><td>Genome</td><td><inline-formula><mml:math id="inf192"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>inputs</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mn mathvariant="bold">4</mml:mn></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>outputs</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext> rows</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>columns</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn mathvariant="bold">12</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn mathvariant="bold">12</mml:mn></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td>Primitives</td><td>Add, Sub, Mul, Div, Const(1.0), Const(0.5)</td></tr><tr><td>EA</td><td><inline-formula><mml:math id="inf193"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>breeding</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>tournament</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mtext>reorder</mml:mtext><mml:mo>=</mml:mo><mml:mtext>true</mml:mtext></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td>Other</td><td><inline-formula><mml:math id="inf194"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>1000</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>500.0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table><table-wrap-foot><fn><p><inline-formula><mml:math id="inf195"><mml:msup><mml:mi/><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> Bold highlights values changed with respect to hyperparameter set 0.</p></fn></table-wrap-foot></table-wrap><table-wrap id="inlinetable5" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th colspan="3">Discovered plasticity rules for hyperparameter set 1</th></tr><tr><th>Label</th><th>Fitness <inline-formula><mml:math id="inf196"><mml:mi class="ltx_font_mathcaligraphic" mathvariant="normal">F</mml:mi></mml:math></inline-formula></th><th>Expression <inline-formula><mml:math id="inf197"><mml:mi>f</mml:mi></mml:math></inline-formula></th></tr></thead><tbody><tr><td>LR0</td><td>238.6</td><td><inline-formula><mml:math id="inf198"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR1</td><td>233.4</td><td><inline-formula><mml:math id="inf199"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR2</td><td>217.2</td><td><inline-formula><mml:math id="inf200"><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mn>1.0</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR3</td><td>227.6</td><td><inline-formula><mml:math id="inf201"><mml:mrow><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo>-</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>/</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR4</td><td>247.2</td><td><inline-formula><mml:math id="inf202"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mn>1.0</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR5</td><td>198.2</td><td><inline-formula><mml:math id="inf203"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR6</td><td>216.2</td><td><inline-formula><mml:math id="inf204"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR7</td><td>225.8</td><td><inline-formula><mml:math id="inf205"><mml:mrow><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr></tbody></table></table-wrap><fig id="app1fig2" position="float"><label>Appendix 1—figure 2.</label><caption><title>Fitness of best individual per generation as a function of the generation index for multiple runs of the evolutionary algorithm with different initial conditions for hyperparameter set 1.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66273-app1-fig2-v1.tif"/></fig><table-wrap id="inlinetable6" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th colspan="2">CGP hyperparameter set 2</th></tr><tr><th>Population</th><th><inline-formula><mml:math id="inf206"><mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mtext>mutation</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0.035</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula></th></tr></thead><tbody><tr><td>Genome</td><td><inline-formula><mml:math id="inf207"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>inputs</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>outputs</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>rows</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>columns</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mn mathvariant="bold">24</mml:mn></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn mathvariant="bold">24</mml:mn></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td>Primitives</td><td>Add, Sub, Mul, Div, Const(1.0), Const(0.5)</td></tr><tr><td>EA</td><td><inline-formula><mml:math id="inf208"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>breeding</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>tournament</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mtext>reorder</mml:mtext><mml:mo>=</mml:mo><mml:mrow><mml:mtext mathvariant="bold">false</mml:mtext></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td>Other</td><td><inline-formula><mml:math id="inf209"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>1000</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>500.0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table><table-wrap-foot><fn><p><inline-formula><mml:math id="inf210"><mml:msup><mml:mi/><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> Bold highlights values changed with respect to hyperparameter set 1.</p></fn></table-wrap-foot></table-wrap><table-wrap id="inlinetable7" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th colspan="3">Discovered plasticity rules for hyperparameter set 2</th></tr><tr><th>Label</th><th>Fitness <inline-formula><mml:math id="inf211"><mml:mi class="ltx_font_mathcaligraphic" mathvariant="normal">F</mml:mi></mml:math></inline-formula></th><th>Expression <inline-formula><mml:math id="inf212"><mml:mi>f</mml:mi></mml:math></inline-formula></th></tr></thead><tbody><tr><td>LR0</td><td>127.2</td><td><inline-formula><mml:math id="inf213"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup></mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR1</td><td>192.0</td><td><inline-formula><mml:math id="inf214"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR2</td><td>216.2</td><td><inline-formula><mml:math id="inf215"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR3</td><td>170.6</td><td><inline-formula><mml:math id="inf216"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR4</td><td>237.6</td><td><inline-formula><mml:math id="inf217"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR5</td><td>233.4</td><td><inline-formula><mml:math id="inf218"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR6</td><td>120.8</td><td><inline-formula><mml:math id="inf219"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR7</td><td>254.8</td><td><inline-formula><mml:math id="inf220"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr></tbody></table></table-wrap><fig id="app1fig3" position="float"><label>Appendix 1—figure 3.</label><caption><title>Fitness of best individual per generation as a function of the generation index for multiple runs of the evolutionary algorithm with different initial conditions for hyperparameter set 2.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66273-app1-fig3-v1.tif"/></fig><table-wrap id="inlinetable8" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th colspan="2">CGP hyperparameter set 3</th></tr><tr><th>Population</th><th><inline-formula><mml:math id="inf221"><mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mtext>mutation</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0.035</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula></th></tr></thead><tbody><tr><td>Genome</td><td><inline-formula><mml:math id="inf222"><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>inputs</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>outputs</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>rows</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>columns</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>24</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mtext>max</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>24</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>Primitives</td><td>Add, Sub, Mul, Div, Const(1.0), Const(0.5)</td></tr><tr><td>EA</td><td><inline-formula><mml:math id="inf223"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>breeding</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>tournament</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mtext>reorder</mml:mtext><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mtext mathvariant="bold">true</mml:mtext></mml:mrow><mml:mrow><mml:mo mathvariant="bold">∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td>Other</td><td><inline-formula><mml:math id="inf224"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>1000</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>500.0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table><table-wrap-foot><fn><p><inline-formula><mml:math id="inf225"><mml:msup><mml:mi/><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> Bold highlights values changed with respect to hyperparameter set 2.</p></fn></table-wrap-foot></table-wrap><table-wrap id="inlinetable9" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th colspan="3">Discovered plasticity rules for hyperparameter set 3</th></tr><tr><th>Label</th><th>Fitness <inline-formula><mml:math id="inf226"><mml:mi class="ltx_font_mathcaligraphic" mathvariant="normal">F</mml:mi></mml:math></inline-formula></th><th>Expression <inline-formula><mml:math id="inf227"><mml:mi>f</mml:mi></mml:math></inline-formula></th></tr></thead><tbody><tr><td>LR0</td><td>236.0</td><td><inline-formula><mml:math id="inf228"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>3</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR1</td><td>242.0</td><td><inline-formula><mml:math id="inf229"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR2</td><td>242.0</td><td><inline-formula><mml:math id="inf230"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR3</td><td>227.6</td><td><inline-formula><mml:math id="inf231"><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR4</td><td>256.0</td><td><inline-formula><mml:math id="inf232"><mml:mrow><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup><mml:mo>+</mml:mo><mml:mn>1.0</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR5</td><td>71.0</td><td><inline-formula><mml:math id="inf233"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>+</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR6</td><td>216.2</td><td><inline-formula><mml:math id="inf234"><mml:mrow><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>-</mml:mo><mml:mn>1.0</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td>LR7</td><td>227.8</td><td><inline-formula><mml:math id="inf235"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>E</mml:mi><mml:mi>j</mml:mi><mml:mtext>r</mml:mtext></mml:msubsup><mml:mo>-</mml:mo><mml:mpadded width="+1.7pt"><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mpadded><mml:mmultiscripts><mml:mo stretchy="false">)</mml:mo><mml:mprescripts/><mml:none/><mml:mn>2</mml:mn></mml:mmultiscripts></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:mpadded width="+1.7pt"><mml:msup><mml:mover accent="true"><mml:mi>R</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>-</mml:mo></mml:msup></mml:mpadded><mml:mmultiscripts><mml:mo>-</mml:mo><mml:mprescripts/><mml:none/><mml:mn>2</mml:mn></mml:mmultiscripts><mml:mn>1.0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr></tbody></table></table-wrap><fig id="app1fig4" position="float"><label>Appendix 1—figure 4.</label><caption><title>Fitness of best individual per generation as a function of the generation index for multiple runs of the evolutionary algorithm with different initial conditions for hyperparameter set 3.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66273-app1-fig4-v1.tif"/></fig></sec><sec id="s8-2"><title>Causal and homeostatic terms over trials</title><p><xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5</xref> illustrates the behavior of the causal and homeostatic terms of the six plasticity rules discovered in the reward-driven learning experiments.</p><fig id="app1fig5" position="float"><label>Appendix 1—figure 5.</label><caption><title>Causal and homeostatic terms of LR-LR6 over trials.</title><p><inline-formula><mml:math id="inf236"><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>c</mml:mi><mml:mo>-</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> represent causal terms (prefactors of eligibility trace), <inline-formula><mml:math id="inf237"><mml:mrow><mml:msup><mml:mi>h</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mi>h</mml:mi><mml:mo>-</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> represent homeostatic terms, for positive and negative rewards, respectively.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66273-app1-fig5-v1.tif"/></fig></sec><sec id="s8-3"><title>Cumulative reward over trials</title><p><xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref> illustrates the cumulative reward over trials for the six platicity rules discovered in the reward-driven learning experiments.</p><fig id="app1fig6" position="float"><label>Appendix 1—figure 6.</label><caption><title>Cumulative reward of LR-LR5 over trials.</title><p>Solid line represent mean, shaded regions indicate plus/minus one standard deviation over 80 experiments. Cumulative reward of LR0 shown in all panels for comparison. Gray line indicates maximal performance (maximal reward received in each trial).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66273-app1-fig6-v1.tif"/></fig></sec></sec><sec id="s9" sec-type="appendix"><title>Error-driven learning – simplification of the discovered rules</title><p>As in the main manuscript <inline-formula><mml:math id="inf238"><mml:mi>v</mml:mi></mml:math></inline-formula> is the teacher potential, <inline-formula><mml:math id="inf239"><mml:mi>u</mml:mi></mml:math></inline-formula> the student membrane potential, and η a fixed learning rate. <inline-formula><mml:math id="inf240"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>κ</mml:mi><mml:mo>*</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> represents the the presynaptic spike train <italic>s</italic><sub><italic>j</italic></sub> filtered by the synaptic kernel κ.</p><p>We first consider <xref ref-type="disp-formula" rid="equ11">Equation 10</xref>:<disp-formula id="equ25"><mml:math id="m25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>u</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>v</mml:mi></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>δ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>v</mml:mi></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:munder><mml:mrow><mml:munder><mml:mfrac><mml:mi>δ</mml:mi><mml:mi>v</mml:mi></mml:mfrac><mml:mo>⏟</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mo>≪</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munder><mml:mo>−</mml:mo><mml:munder><mml:mrow><mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mi>v</mml:mi></mml:mfrac><mml:mo>⏟</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mo>≈</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:munder></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>≈</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where we introduced <inline-formula><mml:math id="inf241"><mml:mrow><mml:mi>δ</mml:mi><mml:mo>:=</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mo>-</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. From the third to the fourth line, we assumed that the mismatch between student and teacher potential is much smaller than their absolute magnitude and that their absolute magnitude is much larger than one. For our parameter choices and initial conditions, this is a reasonable assumption.</p><p>We next consider <xref ref-type="disp-formula" rid="equ12">Equation 11</xref>:<disp-formula id="equ26"><mml:math id="m26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>+</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mfrac><mml:mrow><mml:mi>v</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msup><mml:mi>v</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>δ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mi>v</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mi>v</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mi>δ</mml:mi><mml:mi>v</mml:mi></mml:mfrac><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>v</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mi>η</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>−</mml:mo><mml:munder><mml:mrow><mml:munder><mml:mfrac><mml:mi>δ</mml:mi><mml:mi>v</mml:mi></mml:mfrac><mml:mo>⏟</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mo>≪</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munder></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:munder><mml:mrow><mml:munder><mml:mfrac><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>v</mml:mi></mml:mfrac><mml:mo>⏟</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mo>≪</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munder><mml:mo>+</mml:mo><mml:munder><mml:mrow><mml:munder><mml:mfrac><mml:mi>δ</mml:mi><mml:mi>v</mml:mi></mml:mfrac><mml:mo>⏟</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mo>≪</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munder><mml:munder><mml:mrow><mml:munder><mml:mfrac><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>v</mml:mi></mml:mfrac><mml:mo>⏟</mml:mo></mml:munder></mml:mrow><mml:mrow><mml:mo>≪</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munder></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>≈</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:mi>v</mml:mi><mml:mo>−</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>As previously, from the third to fourth line, we assumed that the mismatch between student and teacher potential is much smaller than their absolute magnitude and that their absolute magnitude is much larger than one. This implies <inline-formula><mml:math id="inf242"><mml:mrow><mml:mfrac><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mi>v</mml:mi></mml:mfrac><mml:mo>≪</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> as <inline-formula><mml:math id="inf243"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>≈</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒪</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> for small input rates.</p><p>The additional terms in both <xref ref-type="disp-formula" rid="equ11">Equation 10</xref> and <xref ref-type="disp-formula" rid="equ12">Equation 11</xref> hence reduce to a simple scaling of the learning rate and thus perform similarly to the purple rule in <xref ref-type="fig" rid="fig4">Figure 4</xref>.</p></sec><sec id="s10" sec-type="appendix"><title>Correlation-driven learning – detailed experimental results</title><p><xref ref-type="fig" rid="app1fig7">Appendix 1—figure 7</xref> illustrates membrane potential dynamics for the output neuron using the two plasticity rules discovered in the correlation-driven learning experiments.</p><fig id="app1fig7" position="float"><label>Appendix 1—figure 7.</label><caption><title>Evolution of membrane potential for two evolved learning rules.</title><p>Membrane potential <inline-formula><mml:math id="inf244"><mml:mi>u</mml:mi></mml:math></inline-formula> of the output neuron over the course of learning using the two evolved learning rules LR1 (top row, <xref ref-type="disp-formula" rid="equ20">Equation 19</xref>) and LR2 (bottom row, <xref ref-type="disp-formula" rid="equ21">Equation 20</xref>) (compare <xref ref-type="fig" rid="fig5">Figure 5B</xref>). Gray boxes indicate presentation of the frozen-noise pattern.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66273-app1-fig7-v1.tif"/></fig></sec><sec id="s11" sec-type="appendix"><title>Simulation details</title><p><xref ref-type="table" rid="app1table1">Appendix 1—table 1</xref>, <xref ref-type="table" rid="app1table2">Appendix 1—table 2</xref>, and <xref ref-type="table" rid="app1table3">Appendix 1—table 3</xref> summarize the network models used in the experiments (according to <xref ref-type="bibr" rid="bib62">Nordlie et al., 2009</xref>).</p><table-wrap id="app1table1" position="float"><label>Appendix 1—table 1.</label><caption><title>Description of the network model used in the reward-driven learning task (4.5).</title></caption><table frame="hsides" rules="groups"><tbody><tr><td colspan="2"><bold>A model summary</bold></td><td/></tr><tr><td colspan="2">Populations</td><td>2</td></tr><tr><td colspan="2">Topology</td><td>—</td></tr><tr><td colspan="2">Connectivity</td><td>Feedforward with fixed connection probability</td></tr><tr><td colspan="2">Neuron model</td><td>Leaky integrate-and-fire (LIF) with exponential post-synaptic currents</td></tr><tr><td colspan="2">Plasticity</td><td>Reward-driven</td></tr><tr><td colspan="2">Measurements</td><td>Spikes</td></tr><tr><td colspan="3"><bold>B populations</bold></td></tr><tr><td>Name</td><td>Elements</td><td>Size</td></tr><tr><td>Input</td><td>Spike generators with pre-defined spike trains (see 4.5)</td><td><inline-formula><mml:math id="inf245"><mml:mi>N</mml:mi></mml:math></inline-formula></td></tr><tr><td>Output</td><td>LIF neuron</td><td>1</td></tr><tr><td colspan="3"><bold>C connectivity</bold></td></tr><tr><td>Source</td><td>Target</td><td>Pattern</td></tr><tr><td>Input</td><td>Output</td><td>Fixed pairwise connection probability <inline-formula><mml:math id="inf246"><mml:mi>p</mml:mi></mml:math></inline-formula>; synaptic delay <inline-formula><mml:math id="inf247"><mml:mi>d</mml:mi></mml:math></inline-formula>; random initial weights from <inline-formula><mml:math id="inf248"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="3"><bold>D neuron model</bold></td></tr><tr><td colspan="2">Type</td><td>LIF neuron with exponential post-synaptic currents</td></tr><tr><td colspan="2">Subthreshold dynamics</td><td><inline-formula><mml:math id="inf249"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mi mathvariant="normal">L</mml:mi></mml:msub></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:msub></mml:mfrac></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:msub></mml:mfrac></mml:mrow></mml:mrow></mml:math></inline-formula> if not refractory</td></tr><tr><td colspan="2"/><td><inline-formula><mml:math id="inf250"><mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> else <inline-formula><mml:math id="inf251"><mml:mrow><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>w</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf252"><mml:mi>k</mml:mi></mml:math></inline-formula>: neuron index, <inline-formula><mml:math id="inf253"><mml:mi>i</mml:mi></mml:math></inline-formula>: spike index</td></tr><tr><td colspan="2">Spiking</td><td>Stochastic spike generation via inhomogeneous Poisson process with intensity <inline-formula><mml:math id="inf254"><mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>ρ</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mtext>th</mml:mtext></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>; reset of <inline-formula><mml:math id="inf255"><mml:mi>u</mml:mi></mml:math></inline-formula> to <inline-formula><mml:math id="inf256"><mml:msub><mml:mi>u</mml:mi><mml:mtext>r</mml:mtext></mml:msub></mml:math></inline-formula> after spike emission and refractory period of <inline-formula><mml:math id="inf257"><mml:msub><mml:mi>τ</mml:mi><mml:mtext>r</mml:mtext></mml:msub></mml:math></inline-formula></td></tr><tr><td colspan="3"><bold>E synapse model</bold></td></tr><tr><td colspan="2">Plasticity</td><td>Reward-driven with episodic update (<xref ref-type="disp-formula" rid="equ2">Equation 2</xref>, <xref ref-type="disp-formula" rid="equ3">Equation 3</xref>)</td></tr><tr><td colspan="2">Other</td><td>Each synapse stores an eligibility trace (<xref ref-type="disp-formula" rid="equ23">Equation 22</xref>)</td></tr><tr><td colspan="3"><bold>F simulation parameters</bold></td></tr><tr><td colspan="2">Populations</td><td><inline-formula><mml:math id="inf258"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Connectivity</td><td><inline-formula><mml:math id="inf259"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>w</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:msup><mml:mn>10</mml:mn><mml:mn>3</mml:mn></mml:msup></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>pA</mml:mtext></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Neuron model</td><td><inline-formula><mml:math id="inf260"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn><mml:mspace width="thinmathspace"/><mml:mtext>Hz</mml:mtext><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn><mml:mspace width="thinmathspace"/><mml:mtext>mV</mml:mtext><mml:mo>,</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mtext>L</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>70</mml:mn><mml:mspace width="thinmathspace"/><mml:mtext>mV</mml:mtext><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>70</mml:mn><mml:mspace width="thinmathspace"/><mml:mtext>mV</mml:mtext><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mtext>th</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>55</mml:mn><mml:mspace width="thinmathspace"/></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>mV</mml:mtext><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext>m</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mtext>m</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>250</mml:mn><mml:mspace width="thinmathspace"/><mml:mtext>pF</mml:mtext><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext>s</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td colspan="2">Synapse model</td><td><inline-formula><mml:math id="inf261"><mml:mrow><mml:mrow><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mtext>M</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>500</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>ms</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>1</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>ms</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Input</td><td><inline-formula><mml:math id="inf262"><mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>30</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>6</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>Hz</mml:mtext></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>500</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>ms</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>training</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>500</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>exp</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Other</td><td><inline-formula><mml:math id="inf263"><mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>0.01</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>ms</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mtext>r</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="3"><bold>G CGP parameters</bold></td></tr><tr><td colspan="2">Population</td><td><inline-formula><mml:math id="inf264"><mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mtext>mutation</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0.035</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Genome</td><td><inline-formula><mml:math id="inf265"><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>inputs</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>outputs</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>rows</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>columns</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>12</mml:mn><mml:mo>,</mml:mo><mml:mn>24</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mtext>max</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>12</mml:mn><mml:mo>,</mml:mo><mml:mn>24</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Primitives</td><td>Add, Sub, Mul, Div, Const(1.0), Const(0.5)</td></tr><tr><td colspan="2">EA</td><td><inline-formula><mml:math id="inf266"><mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>breeding</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>tournament</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mtext>reorder</mml:mtext><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mtext>true</mml:mtext><mml:mo>,</mml:mo><mml:mtext>false</mml:mtext><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Other</td><td><inline-formula><mml:math id="inf267"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>1000</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>500</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table></table-wrap><table-wrap id="app1table2" position="float"><label>Appendix 1—table 2.</label><caption><title>Description of the network model used in the error-driven learning task (4.6).</title></caption><table frame="hsides" rules="groups"><tbody><tr><td colspan="2"><bold>A model summary</bold></td><td/></tr><tr><td colspan="2">Populations</td><td>3</td></tr><tr><td colspan="2">Topology</td><td>—</td></tr><tr><td colspan="2">Connectivity</td><td>Feedforward with all-to-all connections</td></tr><tr><td colspan="2">Neuron model</td><td>Leaky integrate-and-fire (LIF) with exponential post-synaptic currents</td></tr><tr><td colspan="2">Plasticity</td><td>Error-driven</td></tr><tr><td colspan="2">Measurements</td><td>Spikes, membrane potentials</td></tr><tr><td colspan="3"><bold>B populations</bold></td></tr><tr><td>Name</td><td>Elements</td><td>Size</td></tr><tr><td>Input</td><td>Spike generators with pre-defined spike trains (see 4.6)</td><td><inline-formula><mml:math id="inf268"><mml:mi>N</mml:mi></mml:math></inline-formula></td></tr><tr><td>Teacher</td><td>LIF neuron</td><td>1</td></tr><tr><td>Student</td><td>LIF neuron</td><td>1</td></tr><tr><td colspan="3"><bold>C connectivity</bold></td></tr><tr><td>Source</td><td>Target</td><td>Pattern</td></tr><tr><td>Input</td><td>Teacher</td><td>All-to-all; synaptic delay <inline-formula><mml:math id="inf269"><mml:mi>d</mml:mi></mml:math></inline-formula>; random weights <inline-formula><mml:math id="inf270"><mml:mrow><mml:mi>w</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒰</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mtext>min</mml:mtext></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mtext>max</mml:mtext></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>; weights randomly shifted by <inline-formula><mml:math id="inf271"><mml:msub><mml:mi>w</mml:mi><mml:mtext>shift</mml:mtext></mml:msub></mml:math></inline-formula> on each trial</td></tr><tr><td>Input</td><td>Student</td><td>All-to-all; synaptic delay <inline-formula><mml:math id="inf272"><mml:mi>d</mml:mi></mml:math></inline-formula>; fixed initial weights <italic>w</italic><sub>0</sub></td></tr><tr><td colspan="3"><bold>D neuron model</bold></td></tr><tr><td colspan="2">Type</td><td>LIF neuron with exponential post-synaptic currents</td></tr><tr><td colspan="2">Subthreshold dynamics</td><td><inline-formula><mml:math id="inf273"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mi mathvariant="normal">L</mml:mi></mml:msub></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:msub></mml:mfrac></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:msub></mml:mfrac></mml:mrow></mml:mrow></mml:math></inline-formula><inline-formula><mml:math id="inf274"><mml:mrow><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>J</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula><inline-formula><mml:math id="inf275"><mml:mi>k</mml:mi></mml:math></inline-formula>: neuron index, <inline-formula><mml:math id="inf276"><mml:mi>i</mml:mi></mml:math></inline-formula>: spike index</td></tr><tr><td colspan="2">Spiking</td><td>Stochastic spike generation via inhomogeneous Poisson process with intensity <inline-formula><mml:math id="inf277"><mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>ρ</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mtext>th</mml:mtext></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>; no reset after spike emission</td></tr><tr><td colspan="3"><bold>E synapse model</bold></td></tr><tr><td colspan="2">Plasticity</td><td>Error-driven with continuous update (<xref ref-type="disp-formula" rid="equ8">Equation 7</xref>, <xref ref-type="disp-formula" rid="equ10">Equation 9</xref>)</td></tr><tr><td colspan="3"><bold>F simulation parameters</bold></td></tr><tr><td colspan="2">Populations</td><td><inline-formula><mml:math id="inf278"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Connectivity</td><td><inline-formula><mml:math id="inf279"><mml:mrow><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mtext>min</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mtext>max</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>20</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mtext>shift</mml:mtext></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>15</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mn>15</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Neuron model</td><td><inline-formula><mml:math id="inf280"><mml:mrow><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>0.2</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>Hz</mml:mtext></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>1.0</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>mV</mml:mtext></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mtext>L</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>70</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>mV</mml:mtext></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mtext>th</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>55</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>mV</mml:mtext></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mtext>m</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>10</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>ms</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mtext>m</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>250</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>pF</mml:mtext></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mtext>s</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>2</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>ms</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Synapse model</td><td><inline-formula><mml:math id="inf281"><mml:mrow><mml:mrow><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>1.7</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>1</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>ms</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mtext>I</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>100.0</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>ms</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Input</td><td><inline-formula><mml:math id="inf282"><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mtext>min</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>150</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>Hz</mml:mtext></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mtext>max</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>850</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>Hz</mml:mtext></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>000</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>ms</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>exp</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>15</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Other</td><td><inline-formula><mml:math id="inf283"><mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>0.01</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>ms</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mi>δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>5</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>ms</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="3"><bold>G CGP parameters</bold></td></tr><tr><td colspan="2">Population</td><td><inline-formula><mml:math id="inf284"><mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mtext>mutation</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0.045</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Genome</td><td><inline-formula><mml:math id="inf285"><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>inputs</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>outputs</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>rows</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>columns</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>12</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mtext>max</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>12</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Primitives</td><td>Add, Sub, Mul, Div, Const(1.0)</td></tr><tr><td colspan="2">EA</td><td><inline-formula><mml:math id="inf286"><mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>breeding</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>tournament</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Other</td><td><inline-formula><mml:math id="inf287"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>1000</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table></table-wrap><table-wrap id="app1table3" position="float"><label>Appendix 1—table 3.</label><caption><title>: Description of the network model used in the correlation-driven learning task (4.7).</title></caption><table frame="hsides" rules="groups"><tbody><tr><td colspan="2"><bold>A model summary</bold></td><td/></tr><tr><td colspan="2">Populations</td><td>2</td></tr><tr><td colspan="2">Topology</td><td>—</td></tr><tr><td colspan="2">Connectivity</td><td>Feedforward with fixed connection probability</td></tr><tr><td colspan="2">Neuron model</td><td>Leaky integrate-and-fire (LIF) with exponential post-synaptic currents</td></tr><tr><td colspan="2">Plasticity</td><td>Reward-driven</td></tr><tr><td colspan="2">Measurements</td><td>Spikes</td></tr><tr><td colspan="3"><bold>B populations</bold></td></tr><tr><td>Name</td><td>Elements</td><td>Size</td></tr><tr><td>Input</td><td>Spike generators with pre-defined spike trains (see 4.5)</td><td><inline-formula><mml:math id="inf288"><mml:mi>N</mml:mi></mml:math></inline-formula></td></tr><tr><td>Output</td><td>LIF neuron</td><td>1</td></tr><tr><td colspan="3"><bold>C connectivity</bold></td></tr><tr><td>Source</td><td>Target</td><td>Pattern</td></tr><tr><td>Input</td><td>Output</td><td>Fixed pairwise connection probability <inline-formula><mml:math id="inf289"><mml:mi>p</mml:mi></mml:math></inline-formula>; synaptic delay <inline-formula><mml:math id="inf290"><mml:mi>d</mml:mi></mml:math></inline-formula>; random initial weights from <inline-formula><mml:math id="inf291"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">𝒩</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>w</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="3"><bold>D neuron model</bold></td></tr><tr><td colspan="2">Type</td><td>LIF neuron with exponential post-synaptic currents</td></tr><tr><td colspan="2">Subthreshold dynamics</td><td><inline-formula><mml:math id="inf292"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mi mathvariant="normal">L</mml:mi></mml:msub></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:msub></mml:mfrac></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:msub></mml:mfrac></mml:mrow></mml:mrow></mml:math></inline-formula> if not refractory</td></tr><tr><td colspan="2"><inline-formula><mml:math id="inf293"><mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> else <inline-formula><mml:math id="inf294"><mml:mrow><mml:mrow><mml:msub><mml:mi>I</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mo largeop="true" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mpadded width="+1.7pt"><mml:msub><mml:mi>w</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mpadded><mml:mo>⁢</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf295"><mml:mi>k</mml:mi></mml:math></inline-formula>: neuron index, <inline-formula><mml:math id="inf296"><mml:mi>i</mml:mi></mml:math></inline-formula>: spike index</td><td/></tr><tr><td colspan="2">Spiking</td><td>Stochastic spike generation via inhomogeneous Poisson process with intensity <inline-formula><mml:math id="inf297"><mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>u</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>ρ</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mtext>th</mml:mtext></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>; reset of <inline-formula><mml:math id="inf298"><mml:mi>u</mml:mi></mml:math></inline-formula> to <inline-formula><mml:math id="inf299"><mml:msub><mml:mi>u</mml:mi><mml:mtext>r</mml:mtext></mml:msub></mml:math></inline-formula> after spike emission and refractory period of <inline-formula><mml:math id="inf300"><mml:msub><mml:mi>τ</mml:mi><mml:mtext>r</mml:mtext></mml:msub></mml:math></inline-formula></td></tr><tr><td colspan="3"><bold>E synapse model</bold></td></tr><tr><td colspan="2">Plasticity</td><td>Reward-driven with episodic update (<xref ref-type="disp-formula" rid="equ2">Equation 2</xref>, <xref ref-type="disp-formula" rid="equ3">Equation 3</xref>)</td></tr><tr><td colspan="2">Other</td><td>Each synapse stores an eligibility trace (<xref ref-type="disp-formula" rid="equ23">Equation 22</xref>)</td></tr><tr><td colspan="3"><bold>F simulation parameters</bold></td></tr><tr><td colspan="2">Populations</td><td><inline-formula><mml:math id="inf301"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Connectivity</td><td><inline-formula><mml:math id="inf302"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.8</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>w</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:msup><mml:mn>10</mml:mn><mml:mn>3</mml:mn></mml:msup></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>pA</mml:mtext></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Neuron model</td><td><inline-formula><mml:math id="inf303"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn><mml:mspace width="thinmathspace"/><mml:mtext>Hz</mml:mtext><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>u</mml:mi><mml:mo>=</mml:mo><mml:mn>0.2</mml:mn><mml:mspace width="thinmathspace"/><mml:mtext>mV</mml:mtext><mml:mo>,</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mtext>L</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>70</mml:mn><mml:mspace width="thinmathspace"/><mml:mtext>mV</mml:mtext><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>70</mml:mn><mml:mspace width="thinmathspace"/><mml:mtext>mV</mml:mtext><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mtext>th</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>55</mml:mn><mml:mspace width="thinmathspace"/><mml:mtext>mV</mml:mtext><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext>m</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mtext>m</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>250</mml:mn><mml:mspace width="thinmathspace"/><mml:mtext>pF</mml:mtext><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext>r</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext>s</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td colspan="2">Synapse model</td><td><inline-formula><mml:math id="inf304"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext>M</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>500</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td colspan="2">Input</td><td><inline-formula><mml:math id="inf305"><mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>30</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>6</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mtext>Hz</mml:mtext></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>500</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>ms</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>training</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>500</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>exp</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Other</td><td><inline-formula><mml:math id="inf306"><mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:mn>0.01</mml:mn></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>ms</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mtext>r</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="3"><bold>G CGP parameters</bold></td></tr><tr><td colspan="2">Population</td><td><inline-formula><mml:math id="inf307"><mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:mn>8</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mtext>mutation</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Genome</td><td><inline-formula><mml:math id="inf308"><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>inputs</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>outputs</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>rows</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>columns</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mtext>max</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Primitives</td><td>Add, Sub, Mul, Div, Pow, Const(1.0)</td></tr><tr><td colspan="2">EA</td><td><inline-formula><mml:math id="inf309"><mml:mrow><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>8</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>breeding</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>8</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mtext>tournament</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula></td></tr><tr><td colspan="2">Other</td><td><inline-formula><mml:math id="inf310"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>2000</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>10.0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr></tbody></table></table-wrap></sec></boxed-text></app></app-group></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.66273.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>van Rossum</surname><given-names>Mark CW</given-names></name><role>Reviewing Editor</role><aff><institution>University of Nottingham</institution><country>United Kingdom</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Sprekeler</surname><given-names>Henning</given-names> </name><role>Reviewer</role><aff><institution>Technische Universität Berlin</institution><country>Germany</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>A precise quantitative description of synaptic plasticity is currently unknown, so that most formulate learning rules somewhat ad hoc. This computational neuroscience paper uses genetic algorithms (GAs) to find synaptic plasticity rules that perform best on a variety of simulated plasticity tasks with spiking neurons. In principle GAs are potentially powerful, but by being non-differentiable they are limited by computational requirements and can only find simple equations and rely on pre-processing such pre-defined eligibility traces. Future research might be able to generalize this technique.</p><p><bold>Decision letter after peer review:</bold></p><p>[Editors’ note: the authors submitted for reconsideration following the decision after peer review. What follows is the decision letter after the first round of review.]</p><p>Thank you for submitting your work entitled &quot;Evolving to learn, discovering interpretable plasticity rules for spiking networks&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by a Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Henning Sprekeler (Reviewer #2).</p><p>Our decision has been reached after consultation between the reviewers. Based on these discussions and the individual reviews below, we regret to inform you that your work will not be considered further for publication in <italic>eLife</italic>. Our excuses for the long time we needed to reach our decision.</p><p>While the reviewers both saw the potential benefits of the method, the current application only reproduces already known plasticity rules (sometimes not without extra tweaking).</p><p>The reviewers agreed that the manuscript does not sufficiently support the applicability of the suggested method to less hand-crafted situations. The scalability of the method is potentially a concern. To be eligible for further consideration in <italic>eLife</italic>, this would have to be shown, either by applying the method to a situation with more and less hand-crafted inputs to the learning rule and/or by identifying novel, efficient and task ensemble-specific rules. Such a revision would likely require more time than <italic>eLife</italic> aims for.</p><p><italic>Reviewer #1:</italic></p><p>This paper uses genetic algorithms to find synaptic plasticity rules.</p><p>Overall, I found the results interesting, but as genetic algorithms have been well-established and the amount of new results are limited, I see this more as a tutorial and an effort to bring other researchers to use GAs.</p><p>However, the limitations of the method were not clear:</p><p>I would like to see a discussion of the computation time, and the scaling with model complexity and other limitations of the technique.</p><p>I found it also hard to judge whether this study presents an advance of other methods, such using multiple traces to fit learning rules (Gerstner c.s.).</p><p>The inputs to the GAs are quite engineered traces and it was unclear how important this was.</p><p>The reworking of the STDP rules in the last Results section was not so clear to me.</p><p>First the concept of instability needs to be explained better.</p><p>Do these reworked rules perform identically? If so, is there a equivalence class of STDP rules that perform identically on this task?</p><p>Furthermore, can stability not be included in the fitness function (either as direct constraint on \Δ w (t-&gt;\pm \infty), or by widening the task repertoire)?</p><p>It is not so elegant to have a supposedly general technique, and then hand-tune the solutions….</p><p>In conclusion, I'm not convinced the study presents enough of a conceptual or methodological advance.</p><p><italic>Reviewer #2:</italic></p><p>The article &quot;Evolving to learn, discovering interpretable learning rules for spiking networks&quot; by Jordan et al. proposes an evolutionary algorithm to meta-learn plasticity rules for spiking neurons. The algorithm learns to combine user-determined inputs into a mathematical formula for updating synaptic weights, by gradually mutating and selecting a set of candidates based on their performance. The algorithm is applied to (families of) reward-based, error-based, and correlation-based tasks, all three performed by a single neuron. In each case, the algorithm recovers previously proposed learning rules (or variants thereof) that are known to optimize some performance measure.</p><p>The article is clearly written, timely, and presents an exciting approach to meta-learning that holds the promise of not only generating task-specific learning rules, but of providing them in an interpretable form. Its key weakness is its limitation to a rediscovery of existing general purpose rules, in a setup where the quantities that enter the rules seem somewhat pre-engineered. As such, the paper is a proof-of-concept presentation of a very exciting method on simplistic examples. Whether the approach will actually be applicable to a situation with more inputs, for more complex settings (e.g., multi-layer networks) and whether it will ultimately discover task ensemble-specific learning rules is yet to be seen.</p><p>1. Pre-engineering of inputs: It's nice that the authors test their method on three different learning tasks. However, the inputs that enter these learning rules (e.g., the eligibility traces) are chosen by hand and reflect substantial domain knowledge. To show that the method could be applied by a more agnostic user, it would be nice to see that, e.g., different rules could be learned from the same set of inputs. Would it be possible to learn the shape of the eligibility traces? Does the number of successful evolutionary runs decline quickly with the number of inputs the rules are allowed to use?</p><p>2. Computational effort: Meta-learning is somewhat notorious in its demand for computing resources, and the authors acknowledge a high-performance computing center. How computationally expensive is the method? How does the computational expense scale with the number of inputs to the learning rules?</p><p>3. Discovery of unknown/non-general purpose rules: The paper would be strengthened substantially by an example of a discovered rule that is better than known general purpose rules. I fully appreciate that a search for such a situation may amount to finding a needle in a haystack and I suspect the authors have tried. I nevertheless dare to make a suggestion for a candidate: In Vasilaki et al. (2009), the authors used reward-based spiking learning rules to learn a navigation task and argue that policy-gradient methods fail. What works much better in the end is a biased rule that effectively amounts to something simple like pre x post x reward. Such a rule is clearly biased and could make catastrophic errors in other situations. However, I've suspected for a while (and I think I discussed this with Walter Senn at some point) that such a rule could actually be very powerful in a setting where rewards and state and action representations are very sparse. I wouldn't suggest to the authors to try their method on a navigation task, but policy gradient rules in spiking neurons are notoriously slow in much simpler settings. It feels like it should be possible to beat them. Maybe there is a simple single neuron task with sparse inputs, sparse target outputs and sparse rewards?</p><p>4. How sensitive is the method to hyperparameters? The authors use mutation probability 0.045 in first tasks, but 0.05 in last.</p><p>[Editors’ note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for submitting your article &quot;Evolving interpretable plasticity for spiking networks&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by a Reviewing Editor and Michael Frank as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Henning Sprekeler (Reviewer #2).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Summary:</p><p>This computational neuroscience paper uses genetic algorithms (GAs) to find synaptic plasticity rules that perform best on a variety of simulated plasticity tasks with spiking neurons. While GAs are potential powerful, being non-differentiable the study is limited by computationally requirements and can only find very simple equations and use fairly advanced preprocessing such pre-defined eligibility traces.</p><p>Essential revisions:</p><p>1) The authors have added a number of additions to the manuscript that present clear improvement. However, I have doubts about one of the main additions: the inclusion of different baselines for the RL task. From my understanding, rewards are either 1 or -1. Doesn't that mean that [R]+ = (R+1)/2 and [R]- = (R-1)/2? If that's true, all three baselines are all linearly dependent. My suspicion is that this leads to substantial amounts of &quot;neutral evolution&quot; of terms that basically sum up to zero (or converge to zero exponentially). I juggled around a bit with the various rules and found quite a few of those &quot;null&quot; terms.</p><p>I suspect that the point discussed in the section on error-driven learning rules (l. 270) also applies to the RL rules, and that the differences between the rules mostly amount to learning rate (schedules) and &quot;null terms&quot;. This may also explain why the gains in performance are not overwhelming. However, because the difference between the evolved rules is not analyzed in depth, this doesn't become clear in the manuscript. I'd suggest to support the discussion of the learning rules by figures. Maybe plot the different &quot;causal&quot; and &quot;homeostatic&quot; terms over time, and potentially something like a running average covariance with (R-1) E?</p><p>2) Proper statistical analysis of the findings.</p><p>In particular in Figure 3 significance estimates against the null-hypothesis need to be presented.</p><p>For that section, I would also like to see if the found learning rules differ in their convergence speed on new data.</p><p>3) Include data on the convergence speed of the learning. I still would like to see compute time used for a typical run, which is suspiciously absent from the paper.</p><p><italic>Reviewer #1:</italic></p><p>This paper uses genetic algorithms (GAs) to find synaptic plasticity rules on a variety of plasticity problems with spiking neurons. GAs have as an advantage that a free exploration of possible models potentially coming up with original, superior solutions. On the other hand, being non-differentiable they are severely limited by computationally requirements and can only find very simple equations and use fairly advanced pre-processing such pre-defined eligibility traces.</p><p>The paper reads on occasion more like an advertisement than a scientific paper.</p><p>For the unsupervised rules, was the LTP made explicitly dependent on (w-1)? Or was this found automatically?</p><p>The divergencies described in the previous version of the manuscript seemed to have disappeared like snow in the sun.</p><p><italic>Reviewer #2:</italic></p><p>– The discussion about the need to jointly consider learning rule and homeostatic mechanisms is nice, but of limited novelty. I'd suggest to cite at least Mackay and Miller (1994) here.</p><p>– Figure 3: Panel 3 doesn't show any rules with new baselines. Is this old data?</p><p>– I failed to find the time window on which the baselines are computed (m=?) This is quite important for your discussion about time varying learning rates.</p><p>– Section references are broken. Recompile?</p><p>– Double words: l. 82, 377</p><p>– l. 364: I learned the hard way to stay away from &quot;first demonstration&quot; claims in papers …</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.66273.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p>[Editors’ note: the authors resubmitted a revised version of the paper for consideration. What follows is the authors’ response to the first round of review.]</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>This paper uses genetic algorithms to find synaptic plasticity rules.</p><p>Overall, I found the results interesting, but as genetic algorithms have been well-established and the amount of new results are limited, I see this more as a tutorial and an effort to bring other researchers to use GAs.</p></disp-quote><p>We thank the reviewer for their comments, however, our manuscript is not a tutorial on genetic algorithms. Besides demonstrating for the first time the power of genetic programming in the search for plasticity rules in spiking neuronal networks, it provides new results with implications for both learning algorithm design as well as neuroscientific experiments. We hope that our new results on reinforcement learning and a significant revision of the correlation-driven learning section makes our contributions more evident and improves their accessibility. In the revised version of the manuscript we have addressed all concerns voiced by the reviewer. Please also consider our point-by-point reply below.</p><disp-quote content-type="editor-comment"><p>However, the limitations of the method were not clear:</p><p>I would like to see a discussion of the computation time, and the scaling with model complexity and other limitations of the technique.</p></disp-quote><p>We agree with the reviewer that the discussion of these topics was rather limited. The Discussion section of the revised manuscript now contains a description of the computational requirements of our methods.</p><disp-quote content-type="editor-comment"><p>I found it also hard to judge whether this study presents an advance of other methods, such using multiple traces to fit learning rules (Gerstner c.s.).</p></disp-quote><p>As we argue in the revised manuscript, our approach presents an advance over previous methods on several fronts. In contrast to traditional approaches relying on mathematical derivations requiring a significant number of assumption besides human intuition and manual work, the automated search requires fewer assumptions, is less biased and mainly consumes machine time. In contrast to previous automated searches for optimization algorithms or plasticity rules relying on representation by artificial neural networks [e.g., 1, 2] we obtain symbolic expressions which allow us to understand the encoded computational principles. In contrast to previous automated searches relying on fixed symbolic expressions with optimized coefficients [e.g., 3, 4] we consider a significantly larger search space by allowing our evolutionary algorithm to manipulate the form of the expressions. But most importantly, the revised manuscript presents new insights into biological information processing, which, we argue, would be difficult to obtain with other methods.</p><disp-quote content-type="editor-comment"><p>The inputs to the GAs are quite engineered traces and it was unclear how important this was.</p></disp-quote><p>The inputs to the plasticity rules are quantities that have been previously been shown to be linked to plasticity, such as reward, low-pass filtered spike trains, and correlations between pre- and postsynaptic activities. The eligibility trace has been successfully used in previous work on reinforcement learning with spiking neuronal networks and is a natural consequence of policy-gradient approaches. We agree with the reviewer that these inputs do reflect domain knowledge and that a possible direction of future research may explore which expressions would arise when one would, for example, provide the individual components of the eligibility trace. However, we are convinced that our algorithm would then be able to recover the current form of the eligibility trace from its components if this form is indeed a prerequisite for high performance.</p><p>Moreover, we would like to point out that making use of domain knowledge is potentially desirable and explicitly supported by our approach. We can leverage prior knowledge about the relevance of certain kinds of plasticity-related quantities instead of letting the algorithm “reinvent” them. If the user provides useful variables, the automated search is able to leverage information contained in these to suggest powerful rules. If a certain quantity has been consistently demonstrated to be related to synaptic plasticity in the literature, it seems reasonable to provide it as an input to the plasticity rule if the goal is to achieve high task performance, not the discovery of new “features”, e.g., variants of eligibility traces.</p><p>We have expanded the discussion of these points in the revised version of the manuscript.</p><disp-quote content-type="editor-comment"><p>The reworking of the STDP rules in the last Results section was not so clear to me.</p><p>First the concept of instability needs to be explained better.</p><p>Do these reworked rules perform identically? If so, is there a equivalence class of STDP rules that perform identically on this task?</p></disp-quote><p>We agree with the reviewer that the presentation of these results was suboptimal. The discovered plasticity rules indeed are functionally equivalent, i.e., despite their difference in mechanism, they lead to similar network-level behavior. The constants in the discovered plasticity rules can indeed be interpreted as pre- and post-synaptically triggered homeostatic mechanisms, suggesting that plasticity and homeostatic principles should always be considered jointly. The revised manuscript contains a more accessible presentation of these results.</p><disp-quote content-type="editor-comment"><p>Furthermore, can stability not be included in the fitness function (either as direct constraint on \Δ w (t-&gt;\pm \infty), or by widening the task repertoire)?</p></disp-quote><p>Including such direct constraints in the fitness function would be possible. However, this would require an additional hyperparameter for each constraint which governs how strongly this constraint influences the fitness of an individual. Similar to regularizers in traditional optimization problems, these hyperparameters would require careful tuning which is rather unnatural in our task-focused framework.</p><p>Equivalently, a similar effect could be achieved by widening the task repertoire to include specific tasks that effectively implement such constraints. This would, of course, be possible, but would have the same drawback, namely the tuning and weighing of these additional tasks. Another option would be to include multiple natural, but still different tasks, which could implicitly optimize for stability by effectively imposing a higher number of constraints than a single task. This scenario might also require some tuning of the balance between the tasks, but would certainly be more natural and should therefore be explored in future work.</p><disp-quote content-type="editor-comment"><p>It is not so elegant to have a supposedly general technique, and then hand-tune the solutions….</p></disp-quote><p>We thank the reviewer for raising this concern, but we would like to point out that the analysis and potentially even modification of the discovered solutions is an essential part of the workflow enabled by our approach. One main advantage of our method is the availability of compact humanreadable symbolic expressions, in contrast to the plethora of methods relying on artificial neural networks to represent plasticity rules or optimization algorithms. This allows us to analyze the discovered rules with traditional methods to gain an understanding of the computational principles underlying them. We view our approach as a hypothesis-generating machine that suggests possible plasticity rules. By themselves, these could provide new, computationally interesting solutions to learning problems. However, the benefit of our approach does not stop here. Equipped with the knowledge and expertise gained over many decades, researchers in our community can use these automatically generated expressions as starting points for further refinement, recombination and extrapolation. While all plasticity rules in our manuscript were generated by the evolutionary algorithm without hand-tuning, future work may involve manipulating the suggested expressions to incorporate additional expert knowledge not available to the automated search. We have expanded the discussion of these points in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>In conclusion, I'm not convinced the study presents enough of a conceptual or methodological advance.</p></disp-quote><p>We thank the reviewer for their detailed critique of the manuscript and hope that our answers, alongside a substantially revised manuscript including new results, help to better substantiate the relevance of our approach. We hope that the revised manuscript, including new, previously unknown learning rules for reinforcement learning with spiking neurons, make the relevance of our work more accessible.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>The article &quot;Evolving to learn, discovering interpretable learning rules for spiking networks&quot; by Jordan et al. proposes an evolutionary algorithm to meta-learn plasticity rules for spiking neurons. The algorithm learns to combine user-determined inputs into a mathematical formula for updating synaptic weights, by gradually mutating and selecting a set of candidates based on their performance. The algorithm is applied to (families of) reward-based, error-based, and correlation-based tasks, all three performed by a single neuron. In each case, the algorithm recovers previously proposed learning rules (or variants thereof) that are known to optimize some performance measure.</p><p>The article is clearly written, timely, and presents an exciting approach to meta-learning that holds the promise of not only generating task-specific learning rules, but of providing them in an interpretable form. Its key weakness is its limitation to a rediscovery of existing general purpose rules, in a setup where the quantities that enter the rules seem somewhat pre-engineered. As such, the paper is a proof-of-concept presentation of a very exciting method on simplistic examples. Whether the approach will actually be applicable to a situation with more inputs, for more complex settings (e.g., multi-layer networks) and whether it will ultimately discover task ensemble-specific learning rules is yet to be seen.</p></disp-quote><p>We thank the reviewer for appreciating the novelty of our approach, their valuable comments, and constructive critique. The revised manuscript contains novel results that go beyond merely rediscovering previously know plasticity rules. Below we have addressed the issues raised by the reviewer in a point-to-point reply.</p><disp-quote content-type="editor-comment"><p>1. Pre-engineering of inputs: It's nice that the authors test their method on three different learning tasks. However, the inputs that enter these learning rules (e.g., the eligibility traces) are chosen by hand and reflect substantial domain knowledge. To show that the method could be applied by a more agnostic user, it would be nice to see that, e.g., different rules could be learned from the same set of inputs. Would it be possible to learn the shape of the eligibility traces? Does the number of successful evolutionary runs decline quickly with the number of inputs the rules are allowed to use?</p></disp-quote><p>The inputs to the plasticity rules are quantities that have been previously been shown to be linked to plasticity, such as reward, low-pass filtered spike trains, and correlations between pre- and postsynaptic activities. The eligibility trace has been successfully used in previous work on reinforcement learning with spiking neuronal networks and is a natural consequence of policy-gradient approaches. We agree with the reviewer that these inputs do reflect domain knowledge and that a possible direction of future research may explore which expressions would arise when one would, for example, provide the individual components of the eligibility trace. However, we are convinced that our algorithm would then be able to recover the current form of the eligibility trace from its components if this form is indeed a prerequisite for high performance.</p><p>Moreover, we would like to point out that making use of domain knowledge is potentially desirable and explicitly supported by our approach. We can leverage prior knowledge about the relevance of certain kinds of plasticity-related quantities instead of letting the algorithm “reinvent” them. If the user provides useful variables, the automated search is able to leverage information contained in these to suggest powerful rules. If a certain quantity has been consistently demonstrated to be related to synaptic plasticity in the literature, it seems reasonable to provide it as an input to the plasticity rule if the goal is to achieve high task performance, not the discovery of new “features”, e.g., variants of eligibility traces.</p><p>The scaling of the evolutionary search with the number of inputs to the expressions heavily depends on a number of factors: the complexity of the “optimal solution”, the types of inputs, e.g., whether they are independent or correlated quantities, the operators available to the search and so on. Naturally, we expect the required runtime to increase with the complexity of the considered problem. We report that so far, we have not encountered insurmountable issues. However, we believe a detailed investigation of how CGP scales along various hyperparameter axes is outside the scope of the current work.</p><p>We have expanded the discussion of these points in the revised version of the manuscript and also refer to our answer to the reviewer’s next question.</p><disp-quote content-type="editor-comment"><p>2. Computational effort: Meta-learning is somewhat notorious in its demand for computing resources, and the authors acknowledge a high-performance computing center. How computationally expensive is the method? How does the computational expense scale with the number of inputs to the learning rules?</p></disp-quote><p>The reviewer is correctly pointing out the high demand of computational resources for meta learning. For the experiments considered in the present manuscript, the computational costs are rather low, requiring 24 − 48 node hours for a few parallel runs of the evolutionary algorithms, easily within reach of a modern workstation. However, more complex tasks requiring larger networks and/or longer runs will increase the computational resources and thus require longer waiting times, more parallelism, or faster simulation platforms. In particular, we point to neuromorphic systems as likely candidates for this task. Another option is to evolve rules relying on small networks and simplified task, and only run few instances at full scale for example by considering so called “hurdles” in which a fitness evaluation is stopped early unless the fitness value is not high enough after initial simulations [e.g., 5]. Furthermore, previous work has successfully demonstrated the application of CGP to directly evolve agents for complex tasks, such as playing Atari games, providing some confidence in the method’s scalability [6]. We have expanded the discussion of these points in the revised version of the manuscript.</p><disp-quote content-type="editor-comment"><p>3. Discovery of unknown/non-general purpose rules: The paper would be strengthened substantially by an example of a discovered rule that is better than known general purpose rules. I fully appreciate that a search for such a situation may amount to finding a needle in a haystack and I suspect the authors have tried. I nevertheless dare to make a suggestion for a candidate: In Vasilaki et al. (2009), the authors used reward-based spiking learning rules to learn a navigation task and argue that policy-gradient methods fail. What works much better in the end is a biased rule that effectively amounts to something simple like pre x post x reward. Such a rule is clearly biased and could make catastrophic errors in other situations. However, I've suspected for a while (and I think I discussed this with Walter Senn at some point) that such a rule could actually be very powerful in a setting where rewards and state and action representations are very sparse. I wouldn't suggest to the authors to try their method on a navigation task, but policy gradient rules in spiking neurons are notoriously slow in much simpler settings. It feels like it should be possible to beat them. Maybe there is a simple single neuron task with sparse inputs, sparse target outputs and sparse rewards?</p></disp-quote><p>We agree with the reviewer that discovering new learning principles using the presented approach is what makes it exciting. First, we would like to point out that the initial submission contained such new findings: various forms of STDP kernels lead to similar network-level behavior. However, the presentation of the corresponding results was certainly improvable and we have accordingly completely revised the corresponding section. Second, we thank the reviewer for suggesting to re-examine Vasilaki et al. (2009) [7]. As discussed there and in many previous works [e.g., 8, 9, 10] the choice of a suitable reward baseline is notoriously difficult in policy-gradient learning. We therefore expanded our reinforcement-learning task with a number of new inputs representing different quantities suggested as reward baselines, such as the expected rewards and the expected positive and negative reward, respectively. Exploiting the unbiased search of our evolutionary approach, we were curious to see which learning rules would be discovered. Indeed, the evolutionary search found a variety of interesting plasticity rules for learning from rewards making use of the these new quantities. Our results for the task family considered here can be briefly summarized as follows:</p><p>References</p><p>– average rewards not distinguishing between positive and negative rewards do not provide a good baseline;</p><p>– a quantity loosely related to the “novelty” of a task provides a surprisingly effective adaptive baseline that does not require agents to keep track of expected rewards;</p><p>– homeostatic mechanisms and their interplay with activity-regulated plasticity support high performance.</p><p>Not only do these discoveries provide insight into computational aspects of reinforcement learning, they also allow specific experimental predictions on the behavioral and neuronal level. To reflect these new results we have completely rewritten the corresponding section in the manuscript. We hope that the revised manuscript makes a more convincing point of the new insights that can be gained via our approach</p><disp-quote content-type="editor-comment"><p>4. How sensitive is the method to hyperparameters? The authors use mutation probability 0.045 in first tasks, but 0.05 in last.</p></disp-quote><p>The method is not specifically sensitive to hyperparameters, and we have not explicitly tuned these. Where possible we have chosen parameters extracted from previous work on CGP [e.g., 11]. However, compared to previous work our genome size was chosen rather small to keep the complexity of the resulting expression low. Complexity penalties introduced in the fitness evaluation could be introduced to make such choices obsolete in the future.</p><p>[Editors’ note: what follows is the authors’ response to the second round of review.]</p><disp-quote content-type="editor-comment"><p>Summary:</p><p>This computational neuroscience paper uses genetic algorithms (GAs) to find synaptic plasticity rules that perform best on a variety of simulated plasticity tasks with spiking neurons. While GAs are potential powerful, being non-differentiable the study is limited by computationally requirements and can only find very simple equations and use fairly advanced preprocessing such pre-defined eligibilty traces.</p></disp-quote><p>We thank the editorial team for preparing this summary. However, we disagree with several points expressed in the summary:</p><p>• Non-differential optimization algorithms are not fundamentally limited; the recent years have seen several successful large-scale applications of non-differentiable optimization algorithms [1]. We therefore consider that, while historically factual, many concerns about fundamental limitations of GAs are outdated. Along with an increasing number of researchers, we thus believe that the eld of algorithmic optimization has a lot to gain from the application of Gas in appropriate domains, e.g., non-differentiable search spaces, multidimensional optimization, etc.</p><p>• We emphasize throughout the manuscript that it is our explicit goal to discover simple equations: in order to be interpretable, understandable and generalizable by humans; learning rules should not be arbitrarily complex.</p><p>• Using \advanced preprocessed quantities&quot; is not a shortcoming of our approach, but an opportunity to leverage prior knowledge, such as eligibility traces which are commonly encountered in reinforcement learning algorithms; if such prior knowledge is intentionally ignored, one is free to supply different (\simpler&quot;) signals to the plasticity rule. We would like to point out that this is indeed done in the error-driven learning task.</p><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) The authors have added a number of additions to the manuscript that present clear improvement. However, I have doubts about one of the main additions: the inclusion of different baselines for the RL task. From my understanding, rewards are either 1 or -1. Doesn't that mean that [R]+ = (R+1)/2 and [R]- = (R-1)/2? If that's true, all three baselines are all linearly dependent. My suspicion is that this leads to substantial amounts of &quot;neutral evolution&quot; of terms that basically sum up to zero (or converge to zero exponentially). I juggled around a bit with the various rules and found quite a few of those &quot;null&quot; terms.</p><p>I suspect that the point discussed in the section on error-driven learning rules (l. 270) also applies to the RL rules, and that the differences between the rules mostly amount to learning rate (schedules) and &quot;null terms&quot;. This may also explain why the gains in performance are not overwhelming. However, because the difference between the evolved rules is not analyzed in depth, this doesn't become clear in the manuscript. I'd suggest to support the discussion of the learning rules by figures. Maybe plot the different &quot;causal&quot; and &quot;homeostatic&quot; terms over time, and potentially something like a running average covariance with (R-1) E?</p></disp-quote><p>Yes, this is the correct definition of positive and negative rewards, these quantities are indeed linearly dependent. In many cases, the new terms do represent an effective scaling of the learning rate, which depends on previously received reward and/or punishment as discussed in the main manuscript (e.g., l176ff, l192ff, l202ff, l215ff). Furthermore, these additional quantities are reflected in terms which can be interpreted as homeostatic mechanisms (e.g., l205ff, l218ff). Results on datasets not seen during evolution (Fig3D, new appendix Fig10) demonstrate that these terms, rather than being “null”, do have an effect on learning performance. We have now included figures in the appendix which visualize the time development of these additional causal and homeostatic terms over time, complementary to the mathematical analysis provided in the main manuscript.</p><disp-quote content-type="editor-comment"><p>2) Proper statistical analysis of the findings.</p><p>In particular in Figure 3 significance estimates against the null-hypothesis need to be presented.</p><p>For that section, I would also like to see if the found learning rules differ in their convergence speed on new data.</p></disp-quote><p>We have performed Welch’s T-tests for all learning rules against LR0 using an even larger number of experiments that previously (now 80, previously 30). <italic>p</italic>-values for all discovered learning rules are smaller than floating point precision (<italic>p &lt;</italic> 10<sup>−16</sup>). We have included this information in the main manuscript.</p><p>Our defined fitness function implicitly measures convergence speed: the fitness is proportional to the cumulative reward obtained over a fixed number of trials. Naturally, learning rules which converge slower will thus have a lower fitness value. We have now included additional figures in the appendix (Fig11) which compare the convergence speed of the different learning rules on new data.</p><disp-quote content-type="editor-comment"><p>3) Include data on the convergence speed of the learning. I still would like to see compute time used for a typical run, which is suspiciously absent from the paper.</p></disp-quote><p>Regarding convergence speed, please see our answer to the previous question.</p><p>The compute time required is explicitly addressed in the discussion (l467ff), quite contrary to being “suspiciously absent”. We believe the required time (24-48h runtime on a single workstation) is within reasonable reach for most labs.</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>This paper uses genetic algorithms (GAs) to find synaptic plasticity rules on a variety of plasticity problems with spiking neurons. GAs have as an advantage that a free exploration of possible models potentially coming up with original, superior solutions. On the other hand, being non-differentiable they are severely limited by computationally requirements and can only find very simple equations and use fairly advanced preprocessing such pre-defined eligibilty traces.</p><p>The paper reads on occasion more like an advertisement than a scientific paper.</p></disp-quote><p>While we agree with the reviewer’s assessment concerning the advantages of GAs, we find it necessary to add some nuance to the asserted drawbacks:</p><p>– GAs are not “severely limited by computational requirements” (see answer Summary above).</p><p>– Finding simple rules is not a drawback but an explicit goal of our approach (see answer to Summary above).</p><p>Furthermore, we believe to have offered scientifically rigorous arguments for all of our claims, based on sound theory and extensive simulations. Should the positive conclusions that we draw from such evidence be subsumed as “advertisement”, then we might disagree on semantics, but wholeheartedly stand by our claims.</p><disp-quote content-type="editor-comment"><p>For the unsupervised rules, was the LTP made explicitly dependent on (w-1)? Or was this found automatically?</p><p>The divergencies described in the previous version of the manuscript seemed to have disappeared like snow in the sun.</p></disp-quote><p>No, we did not adjust the LTP part manually, these terms were found autonomously by the GA.</p><p>The divergences discussed in the previous version of the manuscript have not “disappeared like snow in the sun”. On the contrary: the snow remains completely unchanged, but we do shed additional light on its makeup. More specifically, we reanalyzed the learning rules and in particular their implementation in NEST and discovered a more appropriate interpretation of constant terms (terms not decaying to zero for long intervals between pre- and postsynaptic spiking) namely as pre- and post-synaptically triggered homeostatic mechanism. This is discussed at length in our previous reply letter as well as in our previous manuscript revision.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>– The discussion about the need to jointly consider learning rule and homeostatic mechanisms is nice, but of limited novelty. I'd suggest to cite at least Mackay and Miller (1994) here.</p></disp-quote><p>We thank the reviewer for their critical evaluation and constructive criticism. We have included the reference in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>– Figure 3: Panel 3 doesn't show any rules with new baselines. Is this old data?</p></disp-quote><p>Figure 3C shows data from multiple runs of the GA without access to the new baselines, in that sense it’s similar to the ”old data”.</p><disp-quote content-type="editor-comment"><p>– I failed to find the time window on which the baselines are computed (m=?) This is quite important for your discussion about time varying learning rates.</p></disp-quote><p>The time window is unfortunately only reported in the parameter tables in the appendix (<italic>m</italic><sub>r</sub> = 100trials (50s)). In the revised version we mention this number in the main text.</p><disp-quote content-type="editor-comment"><p>– Section references are broken. Recompile?</p></disp-quote><p>We have replaced all broken references, thanks.</p><disp-quote content-type="editor-comment"><p>– Double words: l. 82, 377</p></disp-quote><p>We have fixed the double words, thanks.</p><disp-quote content-type="editor-comment"><p>– l. 364: I learned the hard way to stay away from &quot;first demonstration&quot; claims in papers …</p></disp-quote><p>We have removed the “first demonstration” sentence; we agree this is challenging to assess appropriately.</p><p>Reference</p><p>1. Such, F. P., Madhavan, V., Conti, E., Lehman, J., Stanley, K. O., &amp; Clune, J. (2017). Deep neuroevolution: Genetic algorithms are a competitive alternative for training deep neural networks for reinforcement learning. arXiv:1712.06567.; Stanley, K. O., Clune, J., Lehman, J., &amp; Miikkulainen, R. (2019). Designing neural networks through neuroevolution. Nature Machine Intelligence, 1(1), 24-35.; Real, E., Aggarwal, A., Huang, Y., &amp; Le, Q. V. (2019, July). Regularized evolution for image classi_er architecture search. In Proceedings of the AAAI conference on arti_cial intelligence (Vol. 33, No. 01, pp. 4780-4789).; Real, E., Liang, C., So, D., &amp; Le, Q. (2020). AutoML-zero: evolving machine learning algorithms from scratch. In International Conference on Machine Learning (pp. 8007-8019). PMLR.</p></body></sub-article></article>