<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">60628</article-id><article-id pub-id-type="doi">10.7554/eLife.60628</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Amplitude modulations of cortical sensory responses in pulsatile evidence accumulation</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-109421"><name><surname>Koay</surname><given-names>Sue Ann</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9648-2475</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-78881"><name><surname>Thiberge</surname><given-names>Stephan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6583-6613</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-3699"><name><surname>Brody</surname><given-names>Carlos D</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4201-561X</contrib-id><email>brody@princeton.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-9453"><name><surname>Tank</surname><given-names>David W</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9423-4267</contrib-id><email>dwtank@princeton.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Princeton Neuroscience Institute, Princeton University</institution><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>Bezos Center for Neural Circuit Dynamics, Princeton University</institution><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution>Howard Hughes Medical Institute, Princeton University</institution><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Salinas</surname><given-names>Emilio</given-names></name><role>Reviewing Editor</role><aff><institution>Wake Forest School of Medicine</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution>Brown University</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>02</day><month>12</month><year>2020</year></pub-date><pub-date pub-type="collection"><year>2020</year></pub-date><volume>9</volume><elocation-id>e60628</elocation-id><history><date date-type="received" iso-8601-date="2020-07-01"><day>01</day><month>07</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2020-11-30"><day>30</day><month>11</month><year>2020</year></date></history><permissions><copyright-statement>© 2020, Koay et al</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Koay et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-60628-v2.pdf"/><abstract><p>How does the brain internally represent a sequence of sensory information that jointly drives a decision-making behavior? Studies of perceptual decision-making have often assumed that sensory cortices provide noisy but otherwise veridical sensory inputs to downstream processes that accumulate and drive decisions. However, sensory processing in even the earliest sensory cortices can be systematically modified by various external and internal contexts. We recorded from neuronal populations across posterior cortex as mice performed a navigational decision-making task based on accumulating randomly timed pulses of visual evidence. Even in V1, only a small fraction of active neurons had sensory-like responses time-locked to each pulse. Here, we focus on how these ‘cue-locked’ neurons exhibited a variety of amplitude modulations from sensory to cognitive, notably by choice and accumulated evidence. These task-related modulations affected a large fraction of cue-locked neurons across posterior cortex, suggesting that future models of behavior should account for such influences.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>evidence accumulation</kwd><kwd>decision making</kwd><kwd>visual cortex</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>5U01NS090541</award-id><principal-award-recipient><name><surname>Koay</surname><given-names>Sue Ann</given-names></name><name><surname>Thiberge</surname><given-names>Stephan</given-names></name><name><surname>Brody</surname><given-names>Carlos D</given-names></name><name><surname>Tank</surname><given-names>David W</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>1U19NS104648</award-id><principal-award-recipient><name><surname>Koay</surname><given-names>Sue Ann</given-names></name><name><surname>Thiberge</surname><given-names>Stephan</given-names></name><name><surname>Brody</surname><given-names>Carlos D</given-names></name><name><surname>Tank</surname><given-names>David W</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>Simons Collaboration on the Global Brain-328057</award-id><principal-award-recipient><name><surname>Brody</surname><given-names>Carlos D</given-names></name><name><surname>Tank</surname><given-names>David W</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>From as early as primary visual cortex and across posterior cortical areas, neural responses to visual pulses during an evidence-accumulation task exhibit a multitude of task-related amplitude modulations/gain changes.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>As sensory information about the world is often noisy and/or ambiguous, an evidence accumulation process for increasing signal-to-noise ratio is thought to be fundamental to perceptual decision-making. Neural circuits that perform this are incompletely known, but canonically hypothesized to involve multiple stages starting from the detection of momentary sensory signals, which are then accumulated through time and later categorized into an appropriate behavioral action (<xref ref-type="bibr" rid="bib39">Gold and Shadlen, 2007</xref>; <xref ref-type="bibr" rid="bib12">Brody and Hanks, 2016</xref>; <xref ref-type="bibr" rid="bib15">Caballero et al., 2018</xref>). In this picture, the sensory detection stage has a predominantly feedforward role, that is, providing input to but not otherwise involved in accumulation and decision formation. However, another large body of literature has demonstrated that sensory processing in even the earliest sensory cortices can be modified by various external and internal contexts, including motor feedback, temporal statistics, learned associations, and attentional control (<xref ref-type="bibr" rid="bib90">Roelfsema and de Lange, 2016</xref>; <xref ref-type="bibr" rid="bib37">Gilbert and Sigman, 2007</xref>; <xref ref-type="bibr" rid="bib57">Kimura, 2012</xref>; <xref ref-type="bibr" rid="bib36">Gavornik and Bear, 2014</xref>; <xref ref-type="bibr" rid="bib38">Glickfeld and Olsen, 2017</xref>; <xref ref-type="bibr" rid="bib74">Niell and Stryker, 2010</xref>; <xref ref-type="bibr" rid="bib94">Saleem et al., 2013</xref>; <xref ref-type="bibr" rid="bib100">Shuler and Bear, 2006</xref>; <xref ref-type="bibr" rid="bib32">Fiser et al., 2016</xref>; <xref ref-type="bibr" rid="bib44">Haefner et al., 2016</xref>; <xref ref-type="bibr" rid="bib62">Lee and Mumford, 2003</xref>; <xref ref-type="bibr" rid="bib117">Zhang et al., 2014</xref>; <xref ref-type="bibr" rid="bib95">Saleem et al., 2018</xref>; <xref ref-type="bibr" rid="bib67">Makino and Komiyama, 2015</xref>; <xref ref-type="bibr" rid="bib55">Keller et al., 2012</xref>; <xref ref-type="bibr" rid="bib83">Poort et al., 2015</xref>; <xref ref-type="bibr" rid="bib64">Li et al., 2004</xref>; <xref ref-type="bibr" rid="bib104">Stănişor et al., 2013</xref>; <xref ref-type="bibr" rid="bib78">Petreanu et al., 2012</xref>; <xref ref-type="bibr" rid="bib91">Romo et al., 2002</xref>; <xref ref-type="bibr" rid="bib66">Luna et al., 2005</xref>; <xref ref-type="bibr" rid="bib75">Nienborg et al., 2012</xref>; <xref ref-type="bibr" rid="bib114">Yang et al., 2016</xref>; <xref ref-type="bibr" rid="bib11">Britten et al., 1996</xref>; <xref ref-type="bibr" rid="bib33">Froudarakis et al., 2019</xref>; <xref ref-type="bibr" rid="bib56">Keller and Mrsic-Flogel, 2018</xref>). For example, feedback-based gain control of sensory responses has been suggested as an important mechanism for enhancing behaviorally relevant signals, while suppressing irrelevant signals (<xref ref-type="bibr" rid="bib68">Manita et al., 2015</xref>; <xref ref-type="bibr" rid="bib49">Hillyard et al., 1998</xref>; <xref ref-type="bibr" rid="bib46">Harris and Thiele, 2011</xref>; <xref ref-type="bibr" rid="bib4">Azim and Seki, 2019</xref>; <xref ref-type="bibr" rid="bib30">Douglas and Martin, 2007</xref>; <xref ref-type="bibr" rid="bib1">Ahissar and Kleinfeld, 2003</xref>).</p><p>The above two ideas—evidence accumulation and context-specific modulations—make two different but both compelling points about how sensory signals should be processed to support behavior. The two ideas are not mutually incompatible, and insight into the brain’s specific implementation may be gained from a systematic investigation of sensory representations in the brain. To observe how each sensory increment influences neural dynamics, we utilized a behavioral paradigm with precisely initiated timings of sensory inputs that should drive an evidence accumulation process (<xref ref-type="bibr" rid="bib13">Brunton et al., 2013</xref>). Specifically, we recorded from posterior cortical areas during a navigational decision-making task (<xref ref-type="bibr" rid="bib79">Pinto et al., 2018</xref>; <xref ref-type="bibr" rid="bib9">BRAIN CoGS Collaboration, 2017</xref>) where as mice ran down the central corridor of a virtual T-maze, pulses of visual evidence (‘cues’) randomly appeared along both left and right sides of the corridor. To obtain rewards, mice should accumulate the numerosities of cues, then turn down the maze arm corresponding to the side with more cues. The well-separated and randomized timing of cues allowed us to clearly identify putative sensory responses that were time-locked to each pulse, whereas the seconds-long periods over which cues were delivered allowed us to observe the timecourse of neural responses throughout a gradually unfolding decision.</p><p>Across posterior cortices, the bulk of neural activity was sequentially active vs. time in the trial, in a manner that did not depend directly on the sensory cues, as we describe in detail in another article (<xref ref-type="bibr" rid="bib58">Koay et al., 2019</xref>). Even in the primary (V1) and secondary visual areas, only 5–15% of neurons active during the task had responses that were time-locked to sensory cues (‘cue-locked cells’). Still, it is known that remarkably small signals on the order of a few cortical neurons can influence behavior (<xref ref-type="bibr" rid="bib28">Doron and Brecht, 2015</xref>; <xref ref-type="bibr" rid="bib14">Buchan and Rowland, 2018</xref>; <xref ref-type="bibr" rid="bib107">Tanke et al., 2018</xref>; <xref ref-type="bibr" rid="bib63">Lerman et al., 2019</xref>; <xref ref-type="bibr" rid="bib16">Carrillo-Reid et al., 2019</xref>; <xref ref-type="bibr" rid="bib69">Marshel et al., 2019</xref>). Here, we focused on the cue-locked cells, as candidates for momentary sensory inputs that may drive an accumulation and decision-making process. The responses of these cells to cues were well-described by a single impulse response function per neuron, but with amplitudes that varied across the many cue presentations. The cue-response amplitudes of most cells varied systematically across time in the trial, as well as across trials depending on behavioral context, thus suggesting gain modulation effects potentially related to decision-making dynamics. Across posterior cortices and including as early as in V1, these variations in cue-response amplitudes contained information about multiple visual, motor, cognitive, and memory-related contextual variables. Notably, in all areas about 50% of cue-locked cells had response amplitudes that depended on the choice reported by the animal at the end of the trial, or depended on the value of the gradually accumulating evidence. Top-down feedback, potentially from non-sensory regions in which the choice is formed, has been proposed to explain choice-related effects in sensory responses (<xref ref-type="bibr" rid="bib11">Britten et al., 1996</xref>; <xref ref-type="bibr" rid="bib92">Romo et al., 2003</xref>; <xref ref-type="bibr" rid="bib76">Nienborg and Cumming, 2009</xref>; <xref ref-type="bibr" rid="bib114">Yang et al., 2016</xref>; <xref ref-type="bibr" rid="bib8">Bondy et al., 2018</xref>; <xref ref-type="bibr" rid="bib112">Wimmer et al., 2015</xref>; <xref ref-type="bibr" rid="bib44">Haefner et al., 2016</xref>). The dependence on accumulating evidence that we observed supports the hypothesis that this feedback may originate from an accumulator that itself eventually drives choice.</p><p>In sum, the amplitude modulations of cue-locked responses in this report can be thought of as due to multiplicative effects (or equivalently, changes in gain) on the brain’s internal representation of individual sensory pulses. These multiplicative effects were moreover not entirely random from one cue to the next, but rather depended on task-specific factors including those that the brain presumably keeps track of using internal neural dynamics, such as the accumulated evidence. We thus suggest that psychophysical studies of pulsatile-evidence accumulation may benefit from considering that even at the earliest, sensory input stage, neural variability can have a component that is correlated across responses to multiple cues in a trial, as opposed to the independent noise often assumed under lack of knowledge otherwise. Our findings in this article point to candidate neural bases for temporally correlated noise that has been deduced from behavioral data to limit perceptual accuracy, for example in odor discrimination tasks for rats where the subject was free to continue acquiring sensory samples (<xref ref-type="bibr" rid="bib116">Zariwala et al., 2013</xref>).</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We used cellular-resolution two-photon imaging to record from six posterior cortical regions of 11 mice trained in the Accumulating-Towers task (<xref ref-type="fig" rid="fig1">Figure 1a–c</xref>). These mice were from transgenic lines that express the calcium-sensitive fluorescent indicator GCaMP6f in cortical excitatory neurons (Materials and methods), and prior to behavioral training underwent surgical implantation of an optical cranial window centered over either the right or left parietal cortex. The mice then participated in previously detailed behavioral shaping (<xref ref-type="bibr" rid="bib79">Pinto et al., 2018</xref>) and neural imaging procedures as summarized below.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Two-photon calcium imaging of posterior cortical areas during a navigation-based evidence accumulation task.</title><p>(<bold>a</bold>) Layout of the virtual T-maze in an example left-rewarded trial. (<bold>b</bold>) Example snapshot of the cue region corridor from a mouse’s point of view when facing straight down the maze. Two cues on the right and left sides can be seen, closer and further from the mouse in that order. (<bold>c</bold>) Illustration of the virtual viewing angle θ. The visual angle <inline-formula><mml:math id="inf1"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> of a given cue is measured relative to θ and to the center of the cue. The <italic>y</italic> spatial coordinate points straight down the stem of the maze, and the <inline-formula><mml:math id="inf2"><mml:mi>x</mml:mi></mml:math></inline-formula> coordinate is transverse. <inline-formula><mml:math id="inf3"><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:math></inline-formula> is the velocity of the mouse in the virtual world. (<bold>d</bold>) Sigmoid curve fits to behavioral data for how frequently mice turned right for a given difference in total right vs. total left cue counts at the end of the trial, <inline-formula><mml:math id="inf4"><mml:mrow><mml:mi>Δ</mml:mi><mml:mo>≡</mml:mo><mml:mo>#</mml:mo><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:mo>#</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></inline-formula>. Dots: Percent of trials (out of those with a given <inline-formula><mml:math id="inf5"><mml:mi>Δ</mml:mi></mml:math></inline-formula>) in which mice turned right, pooling data from all mice. Error bars: 95% binomial C.I. (<bold>e</bold>) Logistic regression weights for predicting the mice’s choice given spatially-binned evidence <inline-formula><mml:math id="inf6"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>Δ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="inf7"><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> indexes three equally sized spatial bins of the cue region. Error bars: 95% C.I. across bootstrap experiments. (<bold>f</bold>) Average visual field sign map (<inline-formula><mml:math id="inf8"><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> mice) and visual area boundaries, with all recorded areas labeled. The visual field sign is −1 (dark blue) where the cortical layout is a mirror image and +1 (dark red) where it follows a non-inverted layout of the physical world.</p><p><supplementary-material id="fig1sdata1"><label>Figure 1—source data 1.</label><caption><title>Data points, summary statistics, and kernel bandwidths.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-60628-fig1-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60628-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Session-specific behavioral parameters, by mouse.</title><p>(<bold>a</bold>) Distribution (kernel density estimate) of session-average running speeds, for individual mice (columns). For each mouse, running speeds are sampled at the onset times of all the cues encountered in a given session, and then averaged across cue onsets for that session as a single entry in the distribution. (<bold>b</bold>) Distribution of session-specific standard deviation of running speeds, for individual mice (columns). Running speeds are computed as in (<bold>a</bold>), and then the standard deviation (instead of the mean) taken per session as a single entry in the mouse-specific distribution. (<bold>c</bold>) Session-average duration for which individual cues were visible to a given mouse (columns). The maximum duration is 200 ms after which cues were made to disappear, but shorter effective durations are possible if the mouse runs very quickly past the cue, causing it to move past the visual range of the VR display. Bars: 68% C.I. Lines: 95% C.I. (<bold>d</bold>) Session-specific standard deviation of cue visibility durations as in (<bold>c</bold>). Bars: 68% C.I. Lines: 95% C.I.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60628-fig1-figsupp1-v2.tif"/></fig></fig-group><p>Mice were trained in a head-fixed virtual reality system (<xref ref-type="bibr" rid="bib27">Dombeck et al., 2010</xref>) to navigate in a T-maze. As they ran down the stem of the maze, a series of transient, randomly located tower-shaped cues (<xref ref-type="fig" rid="fig1">Figure 1b,c</xref>) appeared along the right and left walls of the cue region corridor (length <inline-formula><mml:math id="inf9"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:mn>200</mml:mn></mml:mrow></mml:math></inline-formula> cm, average running speed in cue region <inline-formula><mml:math id="inf10"><mml:mrow><mml:mo>≈</mml:mo><mml:mn>60</mml:mn><mml:mi>c</mml:mi><mml:mi>m</mml:mi><mml:mo>/</mml:mo><mml:mi>s</mml:mi></mml:mrow></mml:math></inline-formula>; see Materials and methods), followed by a delay region where no cues appeared. The locations of cues were drawn randomly per trial, with Poisson-distributed mean counts of 7.7 on the majority and 2.3 on the minority side, and mice were rewarded for turning down the arm corresponding to the side with more cues. In agreement with previous work (<xref ref-type="bibr" rid="bib79">Pinto et al., 2018</xref>), all mice in this study exhibited characteristic psychometric curves (<xref ref-type="fig" rid="fig1">Figure 1d</xref>) and utilized multiple pieces of evidence to make decisions, with a small primacy effect (<xref ref-type="fig" rid="fig1">Figure 1e</xref>).</p><p>As the timing and visual location of the tower-shaped cues are important information about the behavior that we wished to relate to the neural activity, we programmed the virtual reality software to make a given cue visible to the mouse exactly when it reached a distance of 10 cm before the cue’s location along the T-maze stem (i.e. in the <italic>y</italic> coordinate, see <xref ref-type="fig" rid="fig1">Figure 1c</xref>). We refer to this instant at which a cue becomes visible as the ‘onset time’ for that cue, and used it to define the behavioral timings of visual pulses in all neural data analyses. Cues were made to vanish from view after 200 ms, although 1/11 mice ran so quickly that cues occasionally fell outside of the display range of the virtual reality system before that period (cue duration was ~190 ms for that mouse, see Materials and methods and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> for details on timing precision). Lastly, as mice controlled the virtual viewing angle θ, cues could appear at a variety of visual angles <inline-formula><mml:math id="inf11"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig1">Figure 1c</xref>). We accounted for this in all relevant data analyses, as well as conducted control experiments in which θ was restricted to be exactly zero from the beginning of the trial up to midway in the delay period (referred to as θ-controlled experiments; see Materials and methods).</p><p>For each mouse, we first identified the locations of the visual areas (<xref ref-type="fig" rid="fig1">Figure 1f</xref>; Materials and methods) using one-photon widefield imaging and a retinotopic visual stimulation protocol (<xref ref-type="bibr" rid="bib119">Zhuang et al., 2017</xref>). Then, while the mice performed the task, we used two-photon imaging to record from <inline-formula><mml:math id="inf12"><mml:mrow><mml:mn>500</mml:mn><mml:mi>μ</mml:mi><mml:mi>m</mml:mi><mml:mo>×</mml:mo><mml:mn>500</mml:mn><mml:mi>μ</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula> fields of view in either layers 2/3 or 5 from one of six areas (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>, <xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>): the primary visual cortex (V1), secondary visual areas (V2 including anteromedial area [AM], posteromedial area [PM], medial-to-AM area [MMA], medial-to-PM area [MMP] [<xref ref-type="bibr" rid="bib119">Zhuang et al., 2017</xref>]), and retrosplenial cortex (RSC). These fields of view were selected only to have good imaging quality (high apparent density of cells as unobscured as possible by brain vasculature), that is, prior to the start of the behavioral session and without any criteria based on neural responses. After correction for rigid brain motion, regions of interest representing putative single neurons were extracted using a semi-customized (Materials and methods) demixing and deconvolution procedure (<xref ref-type="bibr" rid="bib81">Pnevmatikakis et al., 2016</xref>). The fluorescence-to-baseline ratio <inline-formula><mml:math id="inf13"><mml:mrow><mml:mi>Δ</mml:mi><mml:mi>F</mml:mi><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> was used as an estimator of neural activity, and only cells with <inline-formula><mml:math id="inf14"><mml:mrow><mml:mo>≥</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula> transients per trial were selected for analysis. In total, we analyzed 10,113 cells from 143 imaging sessions, focusing on 891 neurons identified as time-locked to the visual cues as explained in the next sections.</p><sec id="s2-1"><title>Pulses of evidence evoke transient, time-locked responses in all recorded areas</title><p>We found neurons in all areas/layers that had activities clearly time-locked to the pulsatile cues (examples in <xref ref-type="fig" rid="fig2">Figure 2a–b</xref>). In trials with sparse occurrences of preferred-side cues, the activities of these cells tended to return to baseline following a fairly stereotyped impulse response. Individually, they thus represented only momentary information about the visual cues, although as a population they can form a more persistent stimulus memory (<xref ref-type="bibr" rid="bib40">Goldman, 2009</xref>; <xref ref-type="bibr" rid="bib98">Scott et al., 2017</xref>; <xref ref-type="bibr" rid="bib71">Miri et al., 2011</xref>). Interestingly, the amplitudes of these cells’ responses seemed to vary in a structured way, both across time in a trial, as well as across trials where the mouse eventually makes the choice to turn right vs. left (columns of <xref ref-type="fig" rid="fig2">Figure 2a–b</xref>). We therefore wished to quantify whether or not these putatively sensory amplitude changes also encoded other task-related information.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Pulses of evidence evoke transient, time-locked responses that are well described by an impulse response model.</title><p>(<bold>a</bold>) Trial-by-trial activity (rows) vs. time of an example right-cue-locked cell recorded in area AM, aligned in time to the end of the cue period (dashed line). Onset times of left (right) cues in each trial are shown as red (blue) dots. (<bold>b</bold>) Same as (<bold>a</bold>), but for an atypical right-cue-locked cell (in area AM) that has some left-cue-locked responses. (<bold>c</bold>) Depiction of the impulse response model for the activity level <inline-formula><mml:math id="inf15"><mml:mrow><mml:mi>Δ</mml:mi><mml:mi>F</mml:mi><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> of a neuron vs. time (x-axis). Star indicates the convolution operator. (<bold>d</bold>) Prediction of the impulse response model for the cell in (<bold>a</bold>) in one example trial. This cell had no significant secondary (left-cue) responses. (<bold>e</bold>) Same as (<bold>d</bold>) but for the cell in (<bold>b</bold>). The model prediction is the sum of primary (right-cue) and secondary (left-cue) responses. (<bold>f</bold>) Trial-average impulse response model prediction (purple) vs. the residual of the fit (<inline-formula><mml:math id="inf16"><mml:mrow><mml:mi>Δ</mml:mi><mml:mi>F</mml:mi><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> data minus model prediction, black), in 10 equally sized spatial bins of the cue region. For a given cell, the average model prediction (or average residual) is computed in each spatial bin, then the absolute value of this quantity is averaged across trials, separately per spatial bin. Line: Mean across cells. Dashed line: 95% C.I. across cells. Band: 68% C.I. across cells. For comparability across cells, <inline-formula><mml:math id="inf17"><mml:mrow><mml:mi>Δ</mml:mi><mml:mi>F</mml:mi><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> was expressed in units such that the mean model prediction of each cell is 1. The model prediction rises gradually from baseline at the beginning of the cue period due to nonzero lags in response onsets. (<bold>g</bold>) Distribution (kernel density estimate) of cue-locking significance for cells in various areas/layers. Significance is defined per cell, as the number of standard deviations beyond the median AIC<sub>C</sub> score of models constructed using shuffled data (Materials and methods). Error bars: S.E.M. of cells. Stars: significant differences in means (Wilcoxon rank-sum test). (<bold>h</bold>) Percent of significantly cue-locked cells in various areas/layers. Chance: <inline-formula><mml:math id="inf18"><mml:mrow><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mi>%</mml:mi></mml:mrow></mml:math></inline-formula>. Error bars: 95% binomial C.I. across sessions. (<bold>i</bold>) Distribution (kernel density estimate) of the half-maximum onset time of the primary response, for cells in various areas. Data were pooled across layers (inter-layer differences not significant). Error bars: S.E.M. across cells. Stars: significant differences in means (Wilcoxon rank-sum test). (<bold>j</bold>) As in (<bold>i</bold>) but for the full-width-at-half-max. Statistical tests use data pooled across layers. Means were significantly different across layers for areas AM and PM (Wilcoxon rank-sum test).</p><p><supplementary-material id="fig2sdata1"><label>Figure 2—source data 1.</label><caption><title>Data points including individual entries for histograms, summary statistics and kernel bandwidths.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-60628-fig2-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60628-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Additional statistics for cue-locked responses.</title><p>(<bold>a</bold>) Slope (<inline-formula><mml:math id="inf19"><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>) from a linear regression model <inline-formula><mml:math id="inf20"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mi>y</mml:mi></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf21"><mml:mi>ρ</mml:mi></mml:math></inline-formula> is the residual magnitude (absolute value of data minus impulse response model prediction) shown in <xref ref-type="fig" rid="fig2">Figure 2f</xref>, and <inline-formula><mml:math id="inf22"><mml:mi>y</mml:mi></mml:math></inline-formula> is the spatial bin of the cue region in which the residual was computed (as explained for <xref ref-type="fig" rid="fig2">Figure 2f</xref>). Each point corresponds to a single significantly cue-locked cell. Residuals were normalized per cell by the average impulse model prediction (across trials and place in the cue region) for that cell; this normalization factor is also shown as the x-coordinate in the plot. Units were defined for the spatial bins such that 0 (1) corresponds to the start (end) of the cue region. A slope of ±1 can therefore be interpreted as a change in residuals from the start to the end of the cue region by an amount comparable to the mean signal predicted by the impulse response model. (<bold>b</bold>) Distribution of cue-locking significance for cells with a significant primary response (above five standard deviations compared to cues-shuffled fits). (<bold>c</bold>) Proportion of cells in various areas/layers that respond only to contralateral cues (green), only ipsilateral cues (dark blue), or to cues on both sides (light blue). (<bold>d–g</bold>) As in <xref ref-type="fig" rid="fig2">Figure 2g–j</xref>, but comparing data from two strains of mice. Data were pooled across layers.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60628-fig2-figsupp1-v2.tif"/></fig></fig-group><p>For a given cell, we estimated the amplitude of its response to each cue <inline-formula><mml:math id="inf23"><mml:mi>i</mml:mi></mml:math></inline-formula> by modeling the cell’s activity as a time series of non-negative amplitudes <inline-formula><mml:math id="inf24"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> convolved with an impulse response function (<xref ref-type="fig" rid="fig2">Figure 2c</xref>). The latter was defined by lag, rise-time and fall-time parameters that were fit to each cell, but were the same for all cue-responses of that cell (deconvolving calcium dynamics; see Materials and methods). For a subset of neurons, this impulse response model resulted in excellent fits when the model included only primary responses to either right- or left-side cues (e.g. <xref ref-type="fig" rid="fig2">Figure 2d</xref>). In much rarer instances, adding a secondary response to the opposite-side cues resulted in a significantly better fit (e.g. <xref ref-type="fig" rid="fig2">Figure 2e</xref>; discounting for number of parameters by using AIC<sub>C</sub>[<xref ref-type="bibr" rid="bib50">Hurvich and Tsai, 1989</xref>] as a measure of goodness of fit). We defined cells to be cue-locked if the primary-response model yielded a much better fit to the data than a permutation test (data with cue timings shuffled within the cue region, see Materials and methods). For these cells, the trial-averaged activity predicted by the impulse response model (<xref ref-type="fig" rid="fig2">Figure 2f</xref>, magenta) was substantially larger than the magnitude of residuals of the fits (<xref ref-type="fig" rid="fig2">Figure 2f</xref>, ‘data - model’ prediction in black). For example, if cells had systematic rises or falls in baseline activity levels vs. time/place that could not be explained as transient responses to cues, then the residual would grow/diminish vs. <italic>y</italic> location in the cue region. <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1a</xref> shows that systematic trends (i.e. slopes) for the residual vs. <italic>y</italic> was small for most cells (68% C.I. of slopes across cells were within <inline-formula><mml:math id="inf25"><mml:mrow><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mo>−</mml:mo><mml:mn>0.098</mml:mn><mml:mo>,</mml:mo><mml:mn>0.062</mml:mn></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where a slope of ±1 corresponds to a change in residuals from the start to the end of the cue region being equal to the average signal predicted by the impulse response model). There were thus no large, unaccounted-for components in the activity of these identified cue-locked cells, in particular no components with long timescales.</p><p>Significantly cue-locked cells comprised a small fraction of the overall neural activity, but were nevertheless present in all areas/layers and exhibited some progression of response properties across posterior cortical areas in a roughly lateral-to-medial order (V1, V2, RSC). Cells with the most precisely time-locked responses to cues were found in the visual areas as opposed to RSC (high-significance tail of distributions in <xref ref-type="fig" rid="fig2">Figure 2g</xref>; low significance means that the model fit comparably well to data where cue timings were shuffled within the cue region). Reflecting this, about 5–15% of cells in visual areas were significantly cue-locked, compared to ~5% in RSC (<xref ref-type="fig" rid="fig2">Figure 2h</xref>). Of these significant cells, only ∼3% had secondary responses that were moreover much less significantly time-locked (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1b</xref>); most cells responded to only contralateral cues (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1c</xref>). The onset of the half-maximum response was ∼200 ms after each pulse (<xref ref-type="fig" rid="fig2">Figure 2i</xref>), and the response full-width-at-half-max (FWHM) was ∼100 ms but increased from V1 to secondary visual areas to RSC (<xref ref-type="fig" rid="fig2">Figure 2j</xref>). The impulse response model thus identified cells that follow what one might expect of purely visual-sensory responses on a cue-by-cue basis, but up to amplitude changes that we next discuss.</p></sec><sec id="s2-2"><title>Cue-locked response amplitudes contain information about visual, motor, cognitive, and memory-related contextual task variables</title><p>Studies of perceptual decision-making have shown that the animal’s upcoming choice affects the activity of stimulus-selective neurons in a variety of areas (<xref ref-type="bibr" rid="bib11">Britten et al., 1996</xref>; <xref ref-type="bibr" rid="bib76">Nienborg and Cumming, 2009</xref>). We analogously looked for such effects (and more) while accounting for the highly dynamical nature of our task. As neurons responded predominantly to only one laterality of cues, all our subsequent analyses focus on the primary-response amplitudes of cue-locked cells. Importantly, the impulse response model deconvolves responses to individual cues, so the response amplitude <inline-formula><mml:math id="inf26"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> can be conceptualized as a multiplicative gain factor that the cell’s response was subject to at the instant at which the <inline-formula><mml:math id="inf27"><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> cue appeared.</p><p>We used a neural-population decoding analysis to quantify how much information the cue-locked response amplitudes contained about various contextual variables. First, for the <inline-formula><mml:math id="inf28"><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> cue in the trial, we defined the neural state as the vector of amplitudes <inline-formula><mml:math id="inf29"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> of cells that responded to contralateral cues only. Then using the neural states corresponding to cues that occurred in the first third of the cue period, we trained a support vector machine (SVM) to linearly decode a given task variable from these neural states (cross-validated and corrected for multiple comparisons; see Materials and methods). This procedure was repeated for the other two spatial bins (second third and final third) of the cue period, to observe changes in neural information that may reflect place-/time-related changes in task conditions (illustrated in <xref ref-type="fig" rid="fig3">Figure 3a</xref>). <xref ref-type="fig" rid="fig3">Figure 3b</xref> shows that across posterior cortex, four task variables were accurately decodable from the cue-response amplitudes: the view angle <inline-formula><mml:math id="inf30"><mml:mi>θ</mml:mi></mml:math></inline-formula>, running speed, the running tally of evidence (<inline-formula><mml:math id="inf31"><mml:mrow><mml:mi>Δ</mml:mi><mml:mo>≡</mml:mo><mml:mo>#</mml:mo><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:mo>#</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></inline-formula>), and the eventual choice to turn right or left. The reward outcome from the previous trial could also be decoded, albeit less accurately, while in contrast decoding of the past-trial choice was near chance levels.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Multiple visual, motor, cognitive, and memory-related variables can be decoded from the amplitudes of cue-locked cell responses.</title><p>(<bold>a</bold>) Example time-traces of two statistically correlated task variables, the view angle <inline-formula><mml:math id="inf32"><mml:mi>θ</mml:mi></mml:math></inline-formula> (black) and the eventual navigational choice (magenta). (<bold>b</bold>) Cross-validated performance for decoding six task variables (individual plots) from the amplitudes of cue-locked neuronal responses, separately evaluated using responses to cues in three spatial bins of the cue region (Materials and methods). The performance measure is Pearson’s correlation between the actual task variable value and the prediction using cue-locked cell amplitudes. Lines: mean performance across recording sessions for various areas (colors). Bands: S.E.M. across sessions, for each area. (<bold>c</bold>) Example time-traces of the two uncorrelated modes obtained from a polar decomposition of the correlated task variables in (<bold>a</bold>). This decomposition (Materials and methods) solves for these uncorrelated modes such that they were linear combinations of the original time-traces that were closest, in the least-squares sense, to the original traces, while constrained to be themselves uncorrelated with each other. Correlation coefficients between individual uncorrelated modes and their corresponding original variables were &gt; 0.85 for all modes (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). (<bold>d</bold>) As in (<bold>a</bold>), but for decoding the uncorrelated task-variable modes illustrated in (<bold>c</bold>). (<bold>e</bold>) Proportion of imaging sessions that had significant decoding performance for the six task variables in (<bold>b</bold>) (dark gray points) and uncorrelated modes in (<bold>d</bold>) (blue points), compared to shuffled data and corrected for multiple comparisons. Data were restricted to 140/143 sessions with at least one cue-locked cell. Error bars: 95% binomial C.I. across sessions. (<bold>f</bold>) Linear regression (Support Vector Machine) weights for how much the decoding performance for uncorrelated task-variable modes in (<bold>d</bold>) depended on cortical area/layer and number of recorded cue-locked cells. The decoder accuracy was evaluated at the middle of the cue region for each dataset. The area and layer regressors are indicator variables, e.g. a recording from layer 5 of V1 would have regressor values (V1 = 1, AM = 0, PM = 0, MMA = 0, MMP = 0, RSC = 0, layer = 1). Weights that are not statistically different from zero are indicated with open circles. The negative weight for layer dependence of past-reward decoding means that layer five had significantly lower decoding performance than layers 2/3. Error bars: 95% C.I. computed via bootstrapping sessions.</p><p><supplementary-material id="fig3sdata1"><label>Figure 3—source data 1.</label><caption><title>Data points and summary statistics.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-60628-fig3-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60628-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Pearson’s correlation between uncorrelated behavioral modes (θ**, speed**, etc.) and the corresponding most similar task variable (θ, speed, etc.).</title><p>These uncorrelated modes were computed via polar decomposition as explained in the Materials and methods. Bands: standard deviation across imaging sessions.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60628-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Qualitatively similar performances for decoding task variables from cue-locked response amplitudes in control experiments with view-angle restricted to zero in the cue region.</title><p>(<bold>a–f</bold>) As in <xref ref-type="fig" rid="fig3">Figure 3</xref>, but using data from the θ-controlled experiments.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60628-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Evidence (and other task variables) can still be decoded from cue-locked response amplitudes, excluding cells that exhibit stimulus-specific adaptation (SSA).</title><p>(<bold>a–f</bold>) As in <xref ref-type="fig" rid="fig3">Figure 3</xref>, but with cells that favored the SSA model excluded from the data.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60628-fig3-figsupp3-v2.tif"/></fig></fig-group><p>As the six variables were statistically correlated by nature of the task (e.g. the mouse controls θ to execute the navigational choice, <xref ref-type="fig" rid="fig3">Figure 3a</xref>), indirect neural information about one variable could be exploited to increase the performance of decoding another correlated variable (<xref ref-type="bibr" rid="bib59">Krumin et al., 2018</xref>; <xref ref-type="bibr" rid="bib58">Koay et al., 2019</xref>). To account for this, we repeated the decoding analyses for a modified set of variables that had statistical correlations removed. As explained in the Materials and methods and illustrated in <xref ref-type="fig" rid="fig3">Figure 3c</xref>, we solved for uncorrelated modes being linear combinations of the original time-traces that were closest, in the least-squares sense, to the original traces, while constrained to be themselves uncorrelated with each other. As inter-variable correlations were low throughout the cue region, these uncorrelated modes were very similar to the original task variables. Each uncorrelated mode was identified with its closest original variable and labeled as such, and correlation coefficients between individual uncorrelated modes and their corresponding original variables were &gt; 0.85 for all modes (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Performances for decoding the uncorrelated modes were a little lower than the original task variables (<xref ref-type="fig" rid="fig3">Figure 3d</xref>), as expected since contributions from indirect neural information could no longer be present. Nevertheless, the modes that resembled view angle, speed, evidence, choice, and past-trial reward could all be consistently decoded across imaging sessions for all examined areas (<xref ref-type="fig" rid="fig3">Figure 3e</xref>). There was also comparably high performance of decoding evidence and choice in the θ-controlled experiments (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>), which explicitly shows that neural information about these variables do not originate solely from changes in visual perspective. In a comparable task where choice was highly correlated with view angle (θ) and <italic>y</italic> spatial location in the maze, it has previously been reported that θ and <italic>y</italic> explains most of neural responses in parietal posterior cortex, with small gains from including choice as a third factor (<xref ref-type="bibr" rid="bib59">Krumin et al., 2018</xref>). Interestingly however, our findings indicate that in a task where choice was <italic>distinguishable</italic> from other behavioral factors (here, at least within the cue region), there was significant neural information in all examined posterior cortical areas about this internally generated variable, choice.</p><p>As a population, the amplitudes of cue-locked cells thus reflected a rich set of present- and past-trial contextual information, with some apparent anatomical differences seen in <xref ref-type="fig" rid="fig3">Figure 3b,d</xref>. However, instead of the neural representation being different across different cortical regions, an alternative explanation could be that the accuracy of decoding task variable information depended on experimental factors such as the number of recorded neurons (which differed systematically across cortical areas/layers). To address this, we constructed a linear regression model to predict the decoding accuracy for various datasets as a weighted sum of a set of factors: the cortical area, layer, and number of recorded cells. The cortical area and layer regressors are indicator variables (0 or 1) that specify whether a given dataset was a recording from a particular area and layers 2/3 vs. 5. Likely due to the small numbers of recorded cue-locked cells per session (~0–10), the decoding performance for all variables depended most strongly on the number of cells (<xref ref-type="fig" rid="fig3">Figure 3f</xref>). <xref ref-type="fig" rid="fig3">Figure 3f</xref> also shows that RSC had significantly lower view angle and speed decoding performance than other regions, which we can think of as increased invariance of cue-locked response amplitudes to low-level visual parameters of the stimuli. Layer 5 was also distinguishable from layer 2/3 data in having reduced performance for decoding speed and past-trial reward.</p></sec><sec id="s2-3"><title>Decision-related changes in cue-locked response amplitudes are compatible with a feedback origin</title><p>Interestingly, the response amplitudes of some individual cue-locked cells appeared to systematically depend on time (e.g. <xref ref-type="fig" rid="fig2">Figure 2a–b</xref>), as did the population-level decoding performance for variables such as choice (<xref ref-type="fig" rid="fig3">Figure 3b,d</xref>). To understand if these neural dynamics may reflect a gradually unfolding decision-making process, we turned to modeling how amplitudes of cue-locked cell responses may depend on choice and place/time, while accounting for other time-varying behavioral factors.</p><p>As a null hypothesis based on previous literature, we hypothesized that cue-response amplitudes can depend on a receptive field specified by the visual angle of the cue (<inline-formula><mml:math id="inf33"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, <xref ref-type="fig" rid="fig1">Figure 1c</xref>), as well as running speed (<xref ref-type="bibr" rid="bib74">Niell and Stryker, 2010</xref>; <xref ref-type="bibr" rid="bib94">Saleem et al., 2013</xref>). Given limited data statistics, we compared this null hypothesis to three other conceptually distinct models (Materials and methods), each of which aims to parsimoniously explain cue-response amplitudes using small sets of behavioral factors. These models predict the observed cue-response amplitudes to be random samples from a Gamma distribution, where the mean of the Gamma distribution is a function of various behavioral factors at the time at which a given cue appeared. The mean functions for all models have the form <inline-formula><mml:math id="inf34"><mml:mrow><mml:mi>ρ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo> </mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>v</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo> </mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>⋯</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf35"><mml:mrow><mml:mi>ρ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is an angular receptive field function, <inline-formula><mml:math id="inf36"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>v</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a running speed (<inline-formula><mml:math id="inf37"><mml:mi>v</mml:mi></mml:math></inline-formula>) dependence function, and <inline-formula><mml:math id="inf38"><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>⋯</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is specific to each of the three models, as follows. First, the ‘SSA’ model parameterizes stimulus-specific adaptation (<xref ref-type="bibr" rid="bib109">Ulanovsky et al., 2003</xref>; <xref ref-type="bibr" rid="bib102">Sobotka and Ringo, 1994</xref>) or enhancement (<xref ref-type="bibr" rid="bib110">Vinken et al., 2017</xref>; <xref ref-type="bibr" rid="bib53">Kaneko et al., 2017</xref>) with exponential time-recovery in between cues. Second, the ‘choice’ model allows for a flexible change in amplitudes vs. place/time in the cue region, with a potentially different trend for right- vs. left-choice trials. Third, the ‘cue-counts’ model allows the amplitudes to depend on the running tally of <inline-formula><mml:math id="inf39"><mml:mrow><mml:mo>#</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf40"><mml:mrow><mml:mo>#</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></inline-formula>, or <inline-formula><mml:math id="inf41"><mml:mrow><mml:mi>Δ</mml:mi><mml:mo>=</mml:mo><mml:mo>#</mml:mo><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:mo>#</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></inline-formula>. This selection of models allows us to ask if cue-locked responses are sufficiently explained by previously known effects, or if after accounting for such there are still effects related to the accumulation process, such as choice or cue-count dependence.</p><p>We constructed the amplitude model prediction as the AIC<sub>C</sub>-likelihood-weighted average of the above models, which accounts for when two or more are comparably good (<xref ref-type="bibr" rid="bib111">Volinsky et al., 1999</xref>). As illustrative examples, <xref ref-type="fig" rid="fig4">Figure 4a</xref> shows how the amplitudes of two simultaneously recorded cue-locked cells in area AM depended on behavioral factors and compared to model predictions. There are clear differences in predictions for right- vs. left-choice trials that can also be seen in the raw amplitude data (restricted to a range of <inline-formula><mml:math id="inf42"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> such that angular receptive field effects are small, 2nd and 3rd columns of <xref ref-type="fig" rid="fig4">Figure 4a</xref>). Although both cells responded preferentially to right-side cues, they had oppositely signed choice modulation effects, defined as the difference between amplitude model predictions on contralateral- vs. ipsilateral-choice trials (Materials and methods). <xref ref-type="fig" rid="fig4">Figure 4b</xref> shows two more example choice-modulated cells that had near-constant angular receptive fields. We note that except for the parameters of SSA, all findings in this section were qualitatively similar in θ-controlled experiments where there can be no angular receptive field effects (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Cue-locked response amplitudes depend on view angle, speed, and cue frequency, but a large fraction exhibit choice-related modulations that increase during the course of the trial.</title><p>(<bold>a</bold>) Response amplitudes of two example right-cue-locked cells (one cell per row) vs. (columns) the visual angle at which the cue appeared (<inline-formula><mml:math id="inf43"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>), running speed (<inline-formula><mml:math id="inf44"><mml:mi>v</mml:mi></mml:math></inline-formula>), and <inline-formula><mml:math id="inf45"><mml:mi>y</mml:mi></mml:math></inline-formula> location of the cue in the cue region. Points: amplitude data in blue (red) according to the upcoming right (left) choice. Lines: AIC<sub>C</sub>-weighted model mean functions for right- vs. left-choice trials (lines); the model predicts the data to be random samples from a Gamma distribution with this behavior-dependent mean function. The data in the right two columns were restricted to a subset where angular receptive field effects are small, corresponding to the indicated area in the leftmost plots. (<bold>b</bold>) Same as (<bold>a</bold>) but for two (left-cue-locked) cells with broader angular receptive fields. (<bold>c</bold>) Percentages of cells that significantly favor various amplitude modulation models (likelihood ratio &lt;0.05, defaulting to null model if none are significant), in the indicated cortical areas and layers. For layer 2/3 data, V1 has a significantly higher fraction of cells preferring the null model than other areas (p = 0.02, two-tailed Wilcoxon rank-sum test). For layer 5 data, V1 has a significantly lower choice-model preferring fraction than the other areas (p = 0.003). (<bold>d</bold>) Distribution (kernel density estimate) of adaptation/enhancement factors for cells that favor the SSA model. A factor of 1 corresponds to no adaptation, while for other values the subsequent response is scaled by this amount with exponential recovery toward 1. Error bars: S.E.M. Stars: significant differences in means (Wilcoxon rank-sum test). (<bold>e</bold>) Comparison of the behaviorally deduced weighting of cues (green, same as <xref ref-type="fig" rid="fig1">Figure 1e</xref>) to the neural choice modulation strength vs. location in the cue region (for contralateral-cue-locked cells only, but ipsilateral-cue-locked cells in <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2g</xref> have similar trends). The choice modulation strength is defined using the amplitude-modulation model predictions, and is the difference between predicted amplitudes on preferred-choice minus anti-preferred-choice trials, where preferred choice means that the neuron will have higher amplitudes on trials of that choice compared to trials of the opposite (anti-preferred) choice. For comparability across cells, the choice modulation strength is normalized to the average amplitude for each cell (Materials and methods). Lines: mean across cue-locked cells, computed separately for positively vs. negatively choice-modulated cells (data from all brain regions). Bands: S.E.M.</p><p><supplementary-material id="fig4sdata1"><label>Figure 4—source data 1.</label><caption><title>Data points and summary statistics.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-60628-fig4-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60628-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Qualitatively similar cue-locked amplitude modulations in control experiments with view angle restricted to be zero in the cue region.</title><p>(<bold>a–b,e–f</bold>) As in <xref ref-type="fig" rid="fig4">Figure 4</xref>, except using data from the control experiments. (<bold>c–d,g</bold>) As in <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2a–b,d</xref>, except using data from the θ-controlled experiments.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60628-fig4-figsupp1-v2.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Additional statistics for amplitude modulations of cue-locked cells.</title><p>(<bold>a</bold>) Distribution of AIC<sub>C</sub> likelihood ratios for various amplitude-modulation models vs. the null hypothesis where cell responses only depend on an angular receptive field and speed. Colored areas corresponds to cells for which the indicated model is the best model for that cell (likelihood ratio n &lt; 0.05). Data were pooled across all sessions. Note the logarithmic x-axis scale. (<bold>b</bold>) As in (<bold>a</bold>), distribution of AIC<sub>C</sub> likelihood ratios for cue-counts model vs. the SSA model. Colored areas corresponds to cells for which the cue-counts model was the best model for that cell (likelihood ratio &lt;0.05). (<bold>c</bold>) Distribution (kernel density estimate) of predicted speed-induced changes in amplitudes for a change in speed of 10 cm/s. Data were pooled across layers. Error bars: S.E.M. across cells. Stars: significant differences in means (Wilcoxon rank-sum test). (<bold>d</bold>) Distribution of adaptation/enhancement timescales for cells that favor the SSA model, defined as the time taken for the amplitude to recover to baseline by a factor of <inline-formula><mml:math id="inf46"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:math></inline-formula>. Error bars: S.E.M. across cells. Stars: significant differences in means (Wilcoxon rank-sum test). (<bold>e</bold>) Distribution of choice modulation effect sizes for cue-locked cells in various areas/layers, defined as the maximum difference in predicted responses on contralateral- vs. ipsilateral-choice trials, divided by the mean response. Cells with numerically near-zero modulations (<inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>δ</mml:mi><mml:mrow><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mrow><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>) were excluded. Error bars: S.E.M. across cells. (<bold>f</bold>) Proportions out of all significantly cue-counts-modulated cells for which the best model is that which depends on the difference (left columns) in or single-side counts (middle and right columns) of cues, and shown separately for contralateral- and ipsilateral-cue-locked cells. Error bars: 95% C.I. across cells. (<bold>g</bold>) As in <xref ref-type="fig" rid="fig4">Figure 4e</xref>, but for ipsilateral-cue-locked cells. (<bold>h</bold>) As in <xref ref-type="fig" rid="fig4">Figure 4c</xref>, but for mice of two different strains. Data were pooled across layers.</p><p><supplementary-material id="fig4s2sdata1"><label>Figure 4—figure supplement 2—source data 1.</label><caption><title>Summary statistics.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-60628-fig4-figsupp2-data1-v2.zip"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60628-fig4-figsupp2-v2.tif"/></fig></fig-group><p>To summarize the prevalence and composition of amplitude-modulation effects, we selected the best model per cell using AIC<sub>C</sub>, defaulting in ambiguous cases (relative likelihood &lt;0.05) to the null hypothesis. <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2a</xref> shows that there were large fractions of cells with very high AIC<sub>C</sub> likelihoods for all three alternative models compared to the null hypothesis. Cells that favored the cue-counts model could also be clearly distinguished from those that favored the SSA model (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2b</xref>); in fact, exclusion of cells that exhibited SSA had little effect on how well evidence and other variables could be decoded from the neural population (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>). In all areas and layers, &gt;85% of cue-locked cells exhibited some form of amplitude modulations beyond angular receptive field and running speed effects (<xref ref-type="fig" rid="fig4">Figure 4c</xref>). Overall, <inline-formula><mml:math id="inf48"><mml:mrow><mml:msubsup><mml:mrow><mml:mn>27</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msubsup><mml:mi>%</mml:mi></mml:mrow></mml:math></inline-formula> of cells were best explained by SSA while <inline-formula><mml:math id="inf49"><mml:mrow><mml:msubsup><mml:mrow><mml:mn>67</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msubsup><mml:mi>%</mml:mi></mml:mrow></mml:math></inline-formula> favored either choice or cue-counts models. The notable inter-area difference is for layer 5 data, which had a qualitatively smaller proportion of choice-model preferring cells in V1 compared to other areas (p = 0.003, Wilcoxon rank-sum test). Most cells thus exhibited some form of amplitude modulations beyond visuomotor effects, with little difference in composition across areas and layers.</p><p>Although SSA, choice, and cue-counts dependencies all predict changes in cue-response amplitudes vs. time in the trial, there were qualitative differences that distinguished SSA from choice and cue-count modulations, as we next discuss. Cells in the two largest categories, SSA and choice, had qualitatively different population statistics for how their cue-response amplitudes depended on place/time in the trial. Most cells (<inline-formula><mml:math id="inf50"><mml:mrow><mml:msubsup><mml:mrow><mml:mn>92</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mrow><mml:mo>+</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msubsup><mml:mi>%</mml:mi></mml:mrow></mml:math></inline-formula>) that favored the SSA model corresponded to a phenotype with decreased responses to subsequent cues. Adaptation effects were weakest in V1 and stronger other areas (<xref ref-type="fig" rid="fig4">Figure 4d</xref>, but see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1f–g</xref> for θ-controlled experiments), although the ∼0.8 s recovery timescale had no significant inter-area differences (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2d</xref>). In contrast, cue-locked cells with both choice laterality preferences were intermixed in all areas and layers (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2e</xref>). Also unlike the <italic>decrease</italic> in response amplitudes vs. time for cells that favored the SSA model, both subpopulations of positively and negatively choice-modulated cells exhibited gradually <italic>increasing</italic> effect sizes vs. place/time in the trial (<xref ref-type="fig" rid="fig4">Figure 4e</xref> for contralateral cue-locked cells, <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2g</xref> for ipsilateral cue-locked cells). Cells that favored the cue-counts modulated category also had qualitatively different population statistics compared to cells that exhibited SSA. Comparable proportions of cue-counts modulated cells were best explained by dependence on counts on either the contralateral side, ipsilateral side, or the difference of the two sides (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2f</xref>). For (say) right-cue-locked cells, <inline-formula><mml:math id="inf51"><mml:mrow><mml:mo>#</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf52"><mml:mi>Δ</mml:mi></mml:math></inline-formula> dependencies are not directly explainable by SSA because the modulation is by left-side cues that the cells do not otherwise respond to. The remaining time-independent <inline-formula><mml:math id="inf53"><mml:mrow><mml:mo>#</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:math></inline-formula> modulation also cannot be explained by SSA, unless SSA has an infinitely long timescale. Such infinite-timescale SSA would require some additional prescription for ‘resetting’ the adaptation factor, for example at the start of each trial, because otherwise amplitudes would continue to decrease/increase throughout the ~1 hr long session (which we do not observe).</p><p>Although relationships between sensory responses and choice can arise in a purely feedforward circuit structure, because sensory neurons play a causal role in producing the behavioral choice (<xref ref-type="bibr" rid="bib99">Shadlen et al., 1996</xref>), others have noted that this should result in similar timecourses of neural and behavioral fluctuations (<xref ref-type="bibr" rid="bib76">Nienborg and Cumming, 2009</xref>). Instead, we observed contrasting timecourses: as each trial evolved, there was a slow increase in time in choice modulations of cue-locked responses (<xref ref-type="fig" rid="fig4">Figure 4e</xref>; <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2g</xref>), which was opposite to the behaviorally-assessed decrease in time in how sensory evidence fluctuations influenced the mice’s choice (green line in <xref ref-type="fig" rid="fig4">Figure 4e</xref>, which was replicated from <xref ref-type="fig" rid="fig1">Figure 1e</xref>). Additionally, a feedforward structure predicts that positive fluctuations in right- (left)-preferring cue-locked neurons should produce rightwards (leftwards) fluctuations in choice. Instead, we observed that about half of the cue-locked cells were modulated by choice in a manner opposite to their cue-side preference (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2e</xref>). Both of these observations argue against a purely feedforward structure, and thus support the existence of feedback influences on sensory responses (<xref ref-type="bibr" rid="bib112">Wimmer et al., 2015</xref>; <xref ref-type="bibr" rid="bib76">Nienborg and Cumming, 2009</xref>; <xref ref-type="bibr" rid="bib44">Haefner et al., 2016</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Psychophysics-motivated evidence accumulation models <xref ref-type="bibr" rid="bib88">Ratcliff and McKoon, 2008</xref>; <xref ref-type="bibr" rid="bib106">Stone, 1960</xref>; <xref ref-type="bibr" rid="bib7">Bogacz et al., 2006</xref> have long guided research into how such algorithms may map onto neural activity and areas in the brain. A complementary, bottom-up approach starts from data-driven observations and formulates hypotheses based on the structure of the observations (<xref ref-type="bibr" rid="bib99">Shadlen et al., 1996</xref>; <xref ref-type="bibr" rid="bib112">Wimmer et al., 2015</xref>). In this direction, we exploited the mouse model system to systematically record from layers 2/3 and 5 of six posterior cortical areas during a task involving temporal accumulation of pulsatile visual evidence. A separate optogenetic perturbation study showed that all of these areas contributed to mice’s performance of the Accumulating-Towers task (<xref ref-type="bibr" rid="bib80">Pinto et al., 2019</xref>). We reasoned that to understand how cortical areas contribute to evidence accumulation, a necessary first step is to understand the neural representation of sensory inputs to the process. In this work, we therefore focused on cue-locked cells that had sensory-like responses that is, time-locked to individual pulses of evidence, which comprised ~5–15% of active neurons in visual areas and ~5% in the RSC. These cells are candidates for sensory inputs that may feed into an accumulation process that drives behavior, but could also reflect more complex neural dynamics such as from top-down feedback throughout the seconds-long decision formation process. We characterized properties of cue-locked responses across the posterior cortex, which revealed that although we selected cells that had highly stereotypical time-courses of impulse responses to individual cues, the amplitudes of these responses varied across cue presentations in intriguingly task-specific ways.</p><p>One long-standing postulated function of the visual cortical hierarchy is to generate invariant visual representations (<xref ref-type="bibr" rid="bib25">DiCarlo et al., 2012</xref>), for example for the visual cues regardless of viewing perspective or placement in the T-maze. On the other hand, predictive processing theories propose that visual processing intricately incorporates multiple external and internal contextual information, in a continuous loop of hypothesis formation and checking (<xref ref-type="bibr" rid="bib86">Rao and Ballard, 1999</xref>; <xref ref-type="bibr" rid="bib5">Bastos et al., 2012</xref>; <xref ref-type="bibr" rid="bib56">Keller and Mrsic-Flogel, 2018</xref>). Compatible with the latter hypotheses, we observed that across posterior cortices, cue-locked cells had amplitude modulations that reflected not only visual perspective and running speed (<xref ref-type="bibr" rid="bib74">Niell and Stryker, 2010</xref>; <xref ref-type="bibr" rid="bib94">Saleem et al., 2013</xref>), but also the accumulated evidence, choice, and reward history (neural population decoding in <xref ref-type="fig" rid="fig3">Figure 3</xref>). Inter-area differences were mostly in degree (<xref ref-type="bibr" rid="bib70">Minderer et al., 2019</xref>), with V1 having significantly lower performance for decoding view angle and choice, whereas RSC had lower decoding performance for speed but higher decoding performance for evidence (<xref ref-type="fig" rid="fig3">Figure 3f</xref>). We also observed an anatomical progression from V1 to secondary visual areas to RSC in terms of increasing timescales of cue-locked responses (<xref ref-type="fig" rid="fig2">Figure 2i–j</xref>) and increasing strengths of stimulus-specific adaptation (<xref ref-type="fig" rid="fig4">Figure 4d</xref>). Our results are compatible with other experimental findings of increasing timescales along a cortical hierarchy (<xref ref-type="bibr" rid="bib72">Murray et al., 2014</xref>; <xref ref-type="bibr" rid="bib93">Runyan et al., 2017</xref>; <xref ref-type="bibr" rid="bib29">Dotson et al., 2018</xref>; <xref ref-type="bibr" rid="bib97">Schmolesky et al., 1998</xref>), and theoretical proposals that all cortical circuits contribute to accumulation with intrinsic timescales that follow a progression across brain areas (<xref ref-type="bibr" rid="bib47">Hasson et al., 2015</xref>; <xref ref-type="bibr" rid="bib18">Chaudhuri et al., 2015</xref>; <xref ref-type="bibr" rid="bib20">Christophel et al., 2017</xref>; <xref ref-type="bibr" rid="bib103">Sreenivasan et al., 2014</xref>).</p><p>The amplitude modulations of cue-locked cells can be interpreted as multiplicative gain changes on otherwise sensory responses, and could be clearly distinguished from additive effects due to our experimental design with pulsatile stimuli and high signal-to-noise calcium imaging (<xref ref-type="fig" rid="fig2">Figure 2</xref>). While a number of other studies have quantified the presence of multiplicative noise correlations in cortical responses (<xref ref-type="bibr" rid="bib41">Goris et al., 2014</xref>; <xref ref-type="bibr" rid="bib2">Arandia-Romero et al., 2016</xref>; <xref ref-type="bibr" rid="bib65">Lin et al., 2015</xref>), we showed that for most cells the amplitude variations were not random, but instead depended systematically on visuomotor and cognitive variables (<xref ref-type="fig" rid="fig4">Figure 4c</xref>). Relationships between sensory responses and choice can arise in a purely feedforward circuit structure (<xref ref-type="bibr" rid="bib99">Shadlen et al., 1996</xref>), where the causal role of sensory neurons in producing the behavioral choice predicts that choice-related neural and behavioral fluctuations should have similar timecourses (<xref ref-type="bibr" rid="bib76">Nienborg and Cumming, 2009</xref>). Incompatible with a solely feedforward circuit hypothesis, we instead observed that choice modulations of cue-locked responses <italic>increased</italic> in time (<xref ref-type="fig" rid="fig4">Figure 4e</xref>), whereas the behavioral influence of sensory evidence fluctuations on the mice’s choice <italic>decreased</italic> in time (<xref ref-type="fig" rid="fig1">Figure 1e</xref>). Both the choice- and count-modulation observations discussed here were suggestive of signals originating from an accumulator.</p><p>Our findings extend previous reports of relationships between sensory responses and perceptual decisions, termed ‘choice probability (<xref ref-type="bibr" rid="bib11">Britten et al., 1996</xref>)’ (CP), and may constitute a form of conjunctive coding of cue and contextual information that preserves both the specificity and precise timing of responses to cues. An interesting question arises as to whether such multiplexing of cue and contextual information can cause potential interference between the different multiplexed information. For example, many evidence accumulation studies have reported positive correlations between CP and the stimulus selectivity of cells (<xref ref-type="bibr" rid="bib11">Britten et al., 1996</xref>; <xref ref-type="bibr" rid="bib17">Celebrini and Newsome, 1994</xref>; <xref ref-type="bibr" rid="bib22">Cohen and Newsome, 2009</xref>; <xref ref-type="bibr" rid="bib26">Dodd et al., 2001</xref>; <xref ref-type="bibr" rid="bib61">Law and Gold, 2009</xref>; <xref ref-type="bibr" rid="bib84">Price and Born, 2010</xref>; <xref ref-type="bibr" rid="bib60">Kumano et al., 2016</xref>; <xref ref-type="bibr" rid="bib96">Sasaki and Uka, 2009</xref>; <xref ref-type="bibr" rid="bib43">Gu et al., 2014</xref>; <xref ref-type="bibr" rid="bib77">Nienborg and Cumming, 2014</xref>) (for a differing view, see <xref ref-type="bibr" rid="bib115">Zaidel et al., 2017</xref> for analyses that better separate effects of stimulus vs. choice responses, and <xref ref-type="bibr" rid="bib118">Zhao et al., 2020</xref> for a recent re-analysis at the neural-population level). Translated to our task, positively correlated CP vs. stimulus preferences means that neurons that responded selectively to <italic>right</italic> cues tended to have increased firing rates when the animal will make a choice to the <italic>right</italic>. In this kind of coding scheme, increased activity in right-cue-locked cells could be due to either more right-side cues being presented or an internally generated right-choice signal, and there is no obvious way to distinguish between these two possibilities from just the activities of these cells. Our data deviates from the abovementioned CP studies in that highly contralateral-cue-selective neurons could be divided into two near-equally sized subpopulations with positive choice modulation (analogous to CP &gt;0.5) and negative choice modulation (CP &lt;0.5) respectively (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2e</xref>). As two simultaneously recorded cells that respond to the <italic>same</italic> visual cue can be <italic>oppositely</italic> modulated (<xref ref-type="fig" rid="fig4">Figure 4a</xref>), these phenomena are not expected from canonical accounts of spatial- or feature/object-based attention in visual processing (<xref ref-type="bibr" rid="bib21">Cohen and Maunsell, 2014</xref>; <xref ref-type="bibr" rid="bib108">Treue, 2014</xref>), but rather more compatible with mixed choice- and sensory-selectivity reported in other perceptual decision-making experiments (<xref ref-type="bibr" rid="bib87">Raposo et al., 2014</xref>).</p><p>We can conceptualize how our CP-related findings differ from previous literature by considering how choice modifies the neural-population-level representations of the visual cues, as illustrated in <xref ref-type="fig" rid="fig5">Figure 5</xref> for two hypothetical neurons that both respond to right-side cues. We refer to the joint activity levels of these two hypothetical neurons as the neural (population) state. <xref ref-type="fig" rid="fig5">Figure 5a</xref> illustrates that when there is no cue both neurons have near-zero activity levels (gray dots), whereas when a right-side cue is present both neurons have high activity levels with some variations due to noise (purple dots). Conversely, the presence or absence of a right-side cue can be better decoded from the neural-population activity than from individual noisy neurons, by summing their activities or equivalently projecting the two-dimensional neural state onto a cue-decoding direction <inline-formula><mml:math id="inf54"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> as depicted in <xref ref-type="fig" rid="fig5">Figure 5a</xref>. If in addition these two neurons both have CP &gt;0.5 (positive choice modulation), this means that the neural responses in the presence of a right-side cue can further be separated into two distinguishable distributions depending on whether the subject will eventually make a right or left behavioral choice (<xref ref-type="fig" rid="fig5">Figure 5b</xref>, blue or red dots for the two choices, respectively). The CP &gt;0.5 case corresponds to both neurons having slightly higher (lower) activity levels on right (left) choice trials, which means that we can decode the subject’s behavioral choice by projecting the neural state onto a choice-decoding direction <inline-formula><mml:math id="inf55"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> that is more or less aligned with the cue-decoding direction <inline-formula><mml:math id="inf56"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (arrows in <xref ref-type="fig" rid="fig5">Figure 5b</xref>). However as noted above, collinearity of <inline-formula><mml:math id="inf57"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="inf58"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> means that based on neural activities alone, there can be many cases where we cannot unambiguously decide whether the subject saw more right-side cues or will make a right behavioral choice (overlap between blue and red points in <xref ref-type="fig" rid="fig5">Figure 5b</xref>). This is distinct from the case—as observed in our data—where the two neurons have opposite choice modulations, for example neuron 1 has CP &lt;0.5 (negative choice modulation) whereas neuron 2 has CP &gt;0.5. As depicted in <xref ref-type="fig" rid="fig5">Figure 5c</xref>, neuron 1 now has lower activity on right-choice than left-choice trials, whereas neuron 2 has higher activity on right-choice than left-choice trials, leading to a choice-decoding direction <inline-formula><mml:math id="inf59"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> that is orthogonal to <inline-formula><mml:math id="inf60"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Intuitively, if comparable proportions of sensory units are positively vs. negatively modulated by choice, the opposite signs of these modulations can cancel out when sensory unit activities are summed (projected onto <inline-formula><mml:math id="inf61"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>), leading to a readout of sensory information that is less confounded by internally generated choice signals. Our results are compatible with findings from areas MSTd and VIP of nonhuman primates that use alternative analyses (to CP) that more rigorously separates stimulus vs. choice effects on neural activity as they are behaviorally interrelated (<xref ref-type="bibr" rid="bib115">Zaidel et al., 2017</xref>), as well as a recent re-analysis of area MT data in nonhuman primates performing an evidence-accumulation task (<xref ref-type="bibr" rid="bib118">Zhao et al., 2020</xref>). Similar arguments have been made for how motor preparatory activity and feedback do not interfere with motor output (<xref ref-type="bibr" rid="bib54">Kaufman et al., 2014</xref>; <xref ref-type="bibr" rid="bib105">Stavisky et al., 2017</xref>), and how attentional-state signals can be distinguished from visual stimulus information (<xref ref-type="bibr" rid="bib101">Snyder et al., 2018</xref>). The use of both positive and negative modulations for coding non-sensory information, such as choice here, may hint at a general coding principle that allows non-destructive multiplexing of information in the same neuronal population.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Conceptualization of how choice-related modulations can modify sensory representations at the neural-population level.</title><p>(<bold>a</bold>) Illustrated distribution of the joint activity levels (‘neural state’) of two cue-locked cells, at time-points when there is no visual cue (dark gray), vs. time-points when a cue of the preferred laterality for these cells (purple) is present. Each time-point in this simulation corresponds to different samples of noise in the two neural responses, which results in variations in the neural state (multiple dots each corresponding to a different neural state). <inline-formula><mml:math id="inf62"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is a direction that best separates neural states for the ‘no cue’ vs. ‘cue visible’ conditions. (<bold>b</bold>) Illustrated distribution of neural states as in (<bold>a</bold>), but for time-points when a cue is present, colored differently depending on whether the mouse will eventually make a right-turn (blue) or left-turn choice. <inline-formula><mml:math id="inf63"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is a direction that best separates neural states for right- vs. left-choice conditions, which was chosen here to be parallel to <inline-formula><mml:math id="inf64"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (defined as in (<bold>a</bold>)). (<bold>c</bold>) Same as (<bold>b</bold>), but for a scenario where <inline-formula><mml:math id="inf65"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> was chosen to be orthogonal to <inline-formula><mml:math id="inf66"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>d</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-60628-fig5-v2.tif"/></fig><p>All in all, our neurophysiological observations in a mouse pulsatile evidence-accumulation task bears some similarity to but also notable differences with respect to an extensive body of related work on evidence accumulation tasks in nonhuman primates (NHP). We hypothesize that although a sensory evidence accumulation process may underlie the decision-making behaviors in all of these tasks, there are qualitative differences in both the nature of the tasks as well as our methods of investigation that may shed light on the differences in reported neurophysiological findings. From a methodological standpoint, the use of randomized pulsatile stimuli gives us the power to exploit the unpredictable (but known to the experimenter) timing of sensory pulses to separate stimulus responses from responses to other aspects of the behavior. One downside to this random design, together with the navigational nature of the task that the mouse controls, is that no two trials are literally identical. We thus trade off the richness of the behavior and the ability to directly identify sensory responses, with an inability to directly measure effects that require exactly repeated trials, such as noise correlations. The scope of our study should therefore be understood as being on signal responses across the posterior cortex, and we do not attempt here to report features such as noise correlations that are contingent on having a fully correct model of signal responses in order to interpret the residual as ‘noise’.</p><p>Starting from our most basic neurophysiological observation, the small fractions of cue-locked neural activity in even the visual cortices is not unexpected, because the visual inputs of the task were not tuned to elicit maximal responses from the recorded neurons. In fact, the virtual spatial environment that the mice experienced corresponds to a high rate of visual information beyond just the tower-like cues, all of which are highly salient visual inputs for performing the navigation aspect of the task and may therefore be expected to influence much of the activity in visual cortices. Our observation that choice-related variability in cue-locked cell responses were not lateralized according to brain hemisphere <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2e</xref>, is similar to the non-lateralized choice information in the activities of other (non-cue-locked) neurons that we report in an upcoming article (<xref ref-type="bibr" rid="bib58">Koay et al., 2019</xref>). These findings of cells with intermixed choice preferences within the same brain hemisphere is compatible with several other rodent neurophysiological findings in evidence-accumulation tasks (<xref ref-type="bibr" rid="bib31">Erlich et al., 2011</xref>; <xref ref-type="bibr" rid="bib45">Hanks et al., 2015</xref>; <xref ref-type="bibr" rid="bib98">Scott et al., 2017</xref>), but not, to the best of our knowledge, the NHP choice probability literature discussed above unless via alternative/extended analyses such as in <xref ref-type="bibr" rid="bib115">Zaidel et al., 2017</xref>; <xref ref-type="bibr" rid="bib118">Zhao et al., 2020</xref>. Other than analysis methodology and interspecies differences in brain architecture as a plausible cause for different neural representations of choice, we wonder if these differences could arise from choice and stimulus preferences being related in a more abstract way in our task (and other rodent behavioral paradigms) than in the NHP studies. In the Accumulating-Towers task, although the mouse should choose to turn to the side of the T-maze corresponding to the side with more cues, a navigational goal location is qualitatively different in modality from the retinotopic location of the tower-shaped cues. In contrast, in classic NHP evidence-accumulation tasks (<xref ref-type="bibr" rid="bib39">Gold and Shadlen, 2007</xref>) the subject should saccade in the same direction as they perceive random dot motion stimulus to be along, that is perform a directly visual-direction-based action to indicate their choice. Our overall hypothesis is that if there is additional task-relevant information that have potentially abstract relationships to the visual cues to be accumulated, the brain may need to employ more complex neural representational schemes—including in as early as V1—in order to keep track of not only the momentary sensory information in visual cortices, but also various environmental and memory-based contexts in which they occur.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Experiment subjects</title><p>All procedures were approved by the Institutional Animal Care and Use Committee at Princeton University (protocol 1910) and were performed in accordance with the Guide for the Care and Use of Laboratory Animals (<xref ref-type="bibr" rid="bib73">National Research Council, Division on Earth and Life Studies, Institute for Laboratory Animal Research, and Committee for the Update of the Guide for the Care and Use of Laboratory Animals, 2011</xref>). We used 11 mice for the main experiments (+4 mice for control experiments), aged 2–16 months of both genders, and from three transgenic strains (see <xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>) that express the calcium-sensitive fluorescent indicator GCamp6f (<xref ref-type="bibr" rid="bib19">Chen et al., 2013</xref>) in excitatory neurons of the neocortex:</p><list list-type="bullet"><list-item><p>Six (+2 control) mice (6 male, 2 female): Thy1-GCaMP6f (<xref ref-type="bibr" rid="bib23">Dana et al., 2014</xref>) [C57BL/6J-Tg(Thy1-GCaMP6f)GP5.3Dkim/J, Jackson Laboratories, stock # 028280]. Abbreviated as ‘Thy1 GP5.3’ mice.</p></list-item><list-item><p>Five (+1 control) mice (three male, three female): Triple transgenic crosses expressing GCaMP6f under the CaMKIIα promoter, from the following two lines: Ai93-D; CaMKIIα-tTA [IgS5<sup>tm93.1(tetO−GCaMP6f)Hze</sup> Tg(Camk2atTA) 1Mmay/J (<xref ref-type="bibr" rid="bib42">Gorski et al., 2002</xref>), Jackson Laboratories, stock #024108] (<xref ref-type="bibr" rid="bib68">Manita et al., 2015</xref>); Emx1-IRES-Cre [B6.129S2-Emx1<sup>tm1(cre)Krj</sup>/J, Jackson Laboratories, stock #005628]. Abbreviated as ‘Ai93-Emx1’ mice.</p></list-item><list-item><p>One mouse (control experiments; female): quadruple transgenic crossexpressing GCaMP6f in the cytoplasm and the mCherry protein in the nucleus. both Cre-dependent, from the three lines: Ai93-D; CaMKIIα-tTA, Emx1-IRES-Cre, and Rosa26 LSL H2B mCherry [B6;129S-Gt(ROSA)26Sor<sup>tm1.1Ksvo</sup>/J, Jackson Laboratories, stock #023139].</p></list-item></list><p>Mice were randomly assigned such that there were about the same numbers of either gender and various transgenic lines in each group (main vs. control experiments). As the Ai93-Emx1 strain had higher expression levels of the fluorescent indicator, they produced significantly higher signal-to-noise (SNR) recordings than the Thy1 GP5.3 strain, and contributed more to the layer 5 datasets (see <xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>). Strain differences in the results were small and not of a qualitative nature (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1d–g</xref>, <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2h</xref>).</p></sec><sec id="s4-2"><title>Surgery</title><p>Young adult mice (2–3 months of age) underwent aseptic stereotaxic surgery to implant an optical cranial window and a custom lightweight titanium headplate under isoflurane anesthesia (2.5% for induction, 1–1.5% for maintenance). Mice received one pre-operative dose of meloxicam subcutaneously for analgesia (1 mg/kg) and another one 24 hr later, as well as peri-operative intraperitoneal injection of sterile saline (0.5cc, body-temperature) and dexamethasone (2–5 mg/kg). Body temperature was maintained throughout the procedure using a homeothermic control system (Harvard Apparatus). After asepsis, the skull was exposed and the periosteum removed using sterile cotton swabs. A 5 mm diameter craniotomy approximately centered over the parietal bone was made using a pneumatic drill. The cranial window implant consisted of a 5 mm diameter round #1 thickness glass coverslip bonded to a steel ring (0.5 mm thickness, 5 mm diameter) using a UV-curing optical adhesive. The steel ring was glued to the skull with cyanoacrylate adhesive. Lastly, a titanium headplate was attached to the cranium using dental cement (Metabond, Parkell).</p></sec><sec id="s4-3"><title>Behavioral task</title><p>After at least three days of post-operative recovery, mice were started on water restriction and the Accumulating-Towers training protocol (<xref ref-type="bibr" rid="bib79">Pinto et al., 2018</xref>), summarized here. Mice received 1–2 mL of water per day, or more in case of clinical signs of dehydration or body mass falling below 80% of the pre-operative value. Behavioral training started with mice being head-fixed on an 8-inch Styrofoam ball suspended by compressed air, and ball movements were measured with optical flow sensors. The VR environment was projected at 85 Hz onto a custom-built Styrofoam toroidal screen and the virtual environment was generated by a computer running the Matlab (Mathworks) based software ViRMEn (<xref ref-type="bibr" rid="bib3">Aronov and Tank, 2014</xref>), plus custom code.</p><p>For historical reasons, 3 out of 11 mice were trained on mazes that were longer (30 cm pre-cue region + 250 cm cue region + 100–150 cm delay region) than the rest of the cohort (30 cm pre-cue region + 200 cm cue region + 100 cm delay region). In VR, as the mouse navigated down the stem of the maze, tall, high-contrast visual cues appeared along either wall of the cue region when the mouse arrived within 10 cm of a predetermined cue location; cues were then made to disappear after 200 ms (see following section for details on timing precision). Cue locations were drawn randomly per trial according to a spatial Poisson process with 12 cm refractory period between consecutive cues on the same wall side. The mean number of majority:minority cues was 8.5:2.5 for the 250 cm cue region maze and 7.7:2.3 for the 200 cm cue region maze. Mice were rewarded with <inline-formula><mml:math id="inf67"><mml:mrow><mml:mo>≥</mml:mo><mml:mn>4</mml:mn><mml:mi>μ</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:math></inline-formula> of a sweet liquid reward (10% diluted condensed milk, or 15% sucrose) for turning down the arm on the side with the majority number of cues. Correct trials were followed by a 3s-long inter-trial-interval (ITI), whereas error trials were followed by a loud sound and an additional 9 s time-out period. To discourage a tendency of mice to systematically turn to one side, we used a de-biasing algorithm that adjusts the probabilities of sampling right- vs. left-rewarded trials (<xref ref-type="bibr" rid="bib79">Pinto et al., 2018</xref>). Per session, we computed the percent of correct choices using a sliding window of 100 trials and included the dataset for analysis if the maximum performance was <inline-formula><mml:math id="inf68"><mml:mrow><mml:mo>≥</mml:mo><mml:mn>65</mml:mn><mml:mi>%</mml:mi></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="s4-4"><title>Functional identification of visual areas</title><p>We adapted methods (<xref ref-type="bibr" rid="bib35">Garrett et al., 2014</xref>; <xref ref-type="bibr" rid="bib52">Kalatsky and Stryker, 2003</xref>; <xref ref-type="bibr" rid="bib119">Zhuang et al., 2017</xref>) to functionally delineate the primary and secondary visual areas using widefield imaging of calcium activity paired with presentation of retinotopic stimuli to awake and passively running mice. We used custom-built, tandem-lens widefield macroscopes consisting of a back-to-back objective system (<xref ref-type="bibr" rid="bib89">Ratzlaff and Grinvald, 1991</xref>) connected through a filter box holding a dichroic mirror and emission filter. One-photon excitation was provided using a blue (470 nm) LED (Luxeon star) and the returning green fluorescence was bandpass-filtered at 525 nm (Semrock) before reaching a sCMOS camera (Qimaging, or Hamamatsu). The LED delivered about 2–2.5 mW/cm<sup>2</sup> of power at the focal plane, while the camera was configured for 20–30 Hz frame rate and about 5–10 µm spatial resolution. Visual stimuli were displayed on either a 32’ AMVA LED monitor (BenQ BL3200PT), or the same custom Styrofoam toroidal screen as for the VR rigs. The screens were placed to span most of the visual hemifield on the side contralateral to the mouse’s optical window implant. The space between the headplate and the objective was covered using a custom made cone of opaque material.</p><p>The software used to generate the retinotopic stimuli and coordinate the stimulus with the widefield imaging acquisition was a customized version of the ISI package (<xref ref-type="bibr" rid="bib51">Juavinett et al., 2017</xref>) and utilized the Psychophysics Toolbox (<xref ref-type="bibr" rid="bib10">Brainard, 1997</xref>). Mice were presented with a 20° wide bar with a full-contrast checkerboard texture (25° squares) that inverted in polarity at 12 Hz, and drifted slowly (9°/s) across the extent of the screen in either of four cardinal directions (<xref ref-type="bibr" rid="bib119">Zhuang et al., 2017</xref>). Each sweep direction was repeated 15 times, totaling four consecutive blocks with a pause in between. Retinotopic maps were computed similarly to previous work (<xref ref-type="bibr" rid="bib52">Kalatsky and Stryker, 2003</xref>) with some customization that improved the robustness of the algorithms for preparations with low signal-to-noise ratios (SNR). Boundaries between the primary and secondary visual areas were detected using a gradient-inversion-based algorithm (<xref ref-type="bibr" rid="bib35">Garrett et al., 2014</xref>), again with some changes to improve stability for a diverse range of SNR.</p></sec><sec id="s4-5"><title>Two-photon imaging during VR-based behavior</title><p>The virtual reality plus two-photon scanning microscopy rig used in these experiments follow a previous design (<xref ref-type="bibr" rid="bib27">Dombeck et al., 2010</xref>). The microscope was designed to minimally obscure the ∼270° horizontal and ∼80° vertical span of the toroidal VR screen, and also to isolate the collection of fluorescence photons from the brain from the VR visual display. Two-photon illumination was provided by a Ti:Sapphire laser (Chameleon Vision II, Coherent) operating at 920 nm wavelength, and fluorescence signals were acquired using a 40 × 0.8 NA objective (Nikon) and GaAsP PMTs (Hamamatsu) after passing through a bandpass filter (542/50, Semrock). The amount of laser power at the objective used ranged from ~40–150 mW. The region between the base of the objective lens and the headplate was shielded from external sources of light using a black rubber tube. Horizontal scans of the laser were performed using a resonant galvanometer (Thorlabs), resulting in a frame acquisition rate of 30 Hz and configured for a field of view (FOV) of approximately <inline-formula><mml:math id="inf69"><mml:mrow><mml:mn>500</mml:mn><mml:mo>×</mml:mo><mml:mn>500</mml:mn><mml:mi>μ</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula> in size. Microscope control and image acquisition were performed using the ScanImage software (<xref ref-type="bibr" rid="bib82">Pologruto et al., 2003</xref>). Data related to the VR-based behavior were recorded using custom Matlab-based software embedded in the ViRMEn engine loop, and synchronized with the fluorescence imaging frames using the I2C digital serial bus communication capabilities of ScanImage. A single FOV at a fixed cortical depth and location relative to the functional visual area maps was continuously imaged throughout the 1–1.5 hr behavioral session. The vasculature pattern at the surface of the brain was used to locate a two-photon imaging FOV of interest.</p></sec><sec id="s4-6"><title>Identification of putative neurons</title><p>All imaging data were downsampled in time by a factor of 2 to facilitate analysis (i.e. 15 Hz effective frame rate), and first corrected for rigid brain motion by using the Open Source Computer Vision (OpenCV) software library function cv::matchTemplate. Fluorescence timecourses corresponding to individual neurons were then extracted using a deconvolution and demixing procedure that utilizes the Constrained Non-negative Matrix Factorization algorithm (CNMF [<xref ref-type="bibr" rid="bib81">Pnevmatikakis et al., 2016</xref>]). A custom, Matlab Image Processing Toolbox (Mathworks) based algorithm was used to construct initial hypotheses for the neuron shapes in a data-driven way. In brief, the 3D fluorescence movie was binarized to mark significantly active pixels, then connected components of this binary movie were found. Each of these components arose from a hypothetical neuron, but a neuron could have contributed to multiple components. A shape-based matching procedure was used to remove duplicates before using these as input to CNMF. The ‘finalized’ components from CNMF were then selected post-hoc to identify those that resembled neural somata, using a multivariate classifier with a manual vetting step.</p></sec><sec id="s4-7"><title>General statistics</title><p>We summarize the distribution of a given quantity vs. areas and layers using quantile-based statistics, which are less sensitive to non-Gaussian tails. The standard deviation is computed as half the difference between the 84% and 16% quantiles of the data points. The standard error (S.E.M.) is computed as the standard deviation divided by <inline-formula><mml:math id="inf70"><mml:mrow><mml:msqrt><mml:mi>n</mml:mi></mml:msqrt></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="inf71"><mml:mi>n</mml:mi></mml:math></inline-formula> is the number of data points. For uncertainties on fractions/proportions, we compute a binomial confidence interval using a formulation with the equal-tailed Jeffreys prior interval (<xref ref-type="bibr" rid="bib24">DasGupta et al., 2001</xref>). The significance of differences in means of distributions were assessed using a two-sided Wilcoxon rank sum test. The p-value threshold for evaluating significance is 0.05 for all tests, unless otherwise stated.</p></sec><sec id="s4-8"><title>Behavioral metrics</title><p>These analyses were described in a previous study (<xref ref-type="bibr" rid="bib79">Pinto et al., 2018</xref>) and outlined here. The fraction of trials where a given mouse turned right was computed in 11 bins of evidence levels <inline-formula><mml:math id="inf72"><mml:mrow><mml:mi>Δ</mml:mi><mml:mo>≡</mml:mo><mml:mo>#</mml:mo><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:mo>#</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></inline-formula> at the end of each trial, and fit to a 4-parameter sigmoid function <inline-formula><mml:math id="inf73"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>R</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>Δ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>Δ</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>Δ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:msup></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> to obtain psychometric curves. A logistic regression model was used to assess the dependence of the mice’s choices on the spatial location of cues, that is, with factors being the evidence <inline-formula><mml:math id="inf74"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>Δ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> computed using cues in equally sized thirds of the cue region (indexed by <inline-formula><mml:math id="inf75"><mml:mi>i</mml:mi></mml:math></inline-formula>). Statistical uncertainties on the regression weights were determined by repeating this fit using 1000 bootstrapped pseudo-experiments.</p></sec><sec id="s4-9"><title>Precision of behavioral cue timings</title><p>The cue onset is defined as the instant at which a given cue is made visible in the virtual reality display, that is, when the mouse approaches 10 cm of the predetermined cue location in <italic>y</italic>, the coordinate down the stem of the maze. Given a typical mouse running speed of about 70 cm/s (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1a–b</xref>) and the virtual reality display refresh rate of 85 Hz, there can be a lag of up to one frame (12 ms) or equivalently about 0.8 cm distance in the cue onset from the intended 10 cm approach definition. Regardless, the actual frame at which the cue appears was recorded in the behavioral logs and was used in all analyses.</p><p>The cues were made to vanish after 200 ms, but it is possible for a mouse to run so quickly that a given cue falls outside of the 270° virtual reality display range in less than 200 ms. Only 1/11 mice exhibited running speeds (~90 cm/s) that occasionally ran into this regime. <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1c–d</xref> shows that for 10/11 mice the actual duration of visibility of cues was essentially 200 ms (standard deviation &lt;10 ms), while for the one fast mouse the cue duration was ~190 ms (standard deviation &lt;30 ms).</p><p>We do not expect cue-responsive neurons in the visual cortices to continue responding strongly to a given cue for the entire 200 ms for which it is visible, because of the expected retinotopy of visual cortical responses and previous reports of 15°−20° receptive field radii. For a neuron with a 20° receptive field that has one edge at the cue onset location (10 cm ahead and 4 cm lateral of the mouse), the cue would fall outside of a 40° diameter receptive field within 130 ms (110 ms) if the mouse ran straight past it at 60 cm/s (70 cm/s). In sum, we expect the variability in how long a cue remains in neural receptive fields to be on the order of 10 s of milliseconds (or less for neurons with more lateralized receptive fields).</p></sec><sec id="s4-10"><title>Impulse response model for cue-locked cells</title><p>This analysis excluded some rare trials where the mouse backtracks through the T-maze, by using only trials where the <italic>y</italic> displacement between two consecutive behavioral iterations was &gt; −0.2 cm (including all time-points up to the entry to the T-maze arm), and if the duration of the trial up to and not including the ITI was no more than 50% different from the median trial duration in that session.</p><p>We modeled the activity of each cell as a time series of non-negative amplitudes <inline-formula><mml:math id="inf76"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> in response to the <inline-formula><mml:math id="inf77"><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> cue, convolved with a parametric impulse response function <inline-formula><mml:math id="inf78"><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:mfrac><mml:mrow><mml:mtext>Δ</mml:mtext><mml:mi>F</mml:mi></mml:mrow><mml:mi>F</mml:mi></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mstyle displaystyle="true" mathsize="140%"><mml:mo movablelimits="false">∑</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:munderover><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext>lag</mml:mtext></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>δ</mml:mi><mml:msub><mml:mi>τ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>;</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mo>↑</mml:mo></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mo>↓</mml:mo></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo> </mml:mo><mml:mtext>i.i.d. noise</mml:mtext></mml:mrow></mml:math></disp-formula><disp-formula id="equ2"><label>(1)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">↑</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">↓</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:msqrt><mml:mn>2</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>π</mml:mi><mml:mtext> </mml:mtext></mml:msqrt><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">↑</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">↓</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">↑</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>t</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mo stretchy="false">↓</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>t</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:msup><mml:mtext>Ca</mml:mtext><mml:mrow><mml:mn>2</mml:mn><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf79"><mml:mrow><mml:mo>{</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula> are the appearance times of cues throughout the behavioral session. The free parameters of this model are the lag (<inline-formula><mml:math id="inf80"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>), rise (<inline-formula><mml:math id="inf81"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mo>↑</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula>) and fall (<inline-formula><mml:math id="inf82"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mo>↓</mml:mo></mml:msub></mml:mrow></mml:math></inline-formula>) times of the impulse response function, the amplitudes <inline-formula><mml:math id="inf83"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, and small (L2-regularized) time jitters <inline-formula><mml:math id="inf84"><mml:mrow><mml:mi>δ</mml:mi><mml:msub><mml:mi>τ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> that decorrelates variability in response timings from amplitude changes. <inline-formula><mml:math id="inf85"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:msup><mml:mi>a</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a calcium indicator response function using parameters from literature (<xref ref-type="bibr" rid="bib19">Chen et al., 2013</xref>), which deconvolves calcium and indicator dynamics from our reports of timescales. This function is parameterized as a difference of exponentials, <inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>C</mml:mi><mml:msup><mml:mi>a</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>+</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mo stretchy="false">↑</mml:mo></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>t</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mi>τ</mml:mi><mml:mrow><mml:mo stretchy="false">↓</mml:mo></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:msup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf87"><mml:mrow><mml:msubsup><mml:mi>τ</mml:mi><mml:mo>↑</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msubsup><mml:mo>≡</mml:mo><mml:mn>35</mml:mn><mml:mi>m</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf88"><mml:mrow><mml:msubsup><mml:mi>τ</mml:mi><mml:mo>↓</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msubsup><mml:mo>≡</mml:mo><mml:mn>300</mml:mn><mml:mi>m</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf89"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is a normalization constant such that the peak of this function is 1. The per-cue time jitter parameters <inline-formula><mml:math id="inf90"><mml:mrow><mml:mi>δ</mml:mi><mml:msub><mml:mi>τ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> additionally allows this model to flexibly account for some experimental uncertainty in the assumed cue onset times (see previous section). The distribution of jitter parameters that we obtained from fitting this model (as explained below) had a standard deviation of about 50 ms across neurons, which is within the expected range of behavioral timing variations. We also note that neural response timescales cannot be resolved to better than the Nyquist rate of the imaging data, <inline-formula><mml:math id="inf91"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>15</mml:mn><mml:mi>H</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo>≈</mml:mo><mml:mn>33</mml:mn><mml:mi>m</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:math></inline-formula>.</p><p>We maximized the model likelihood to obtain point estimates of all the parameters, using a custom coordinate-descent-like algorithm (<xref ref-type="bibr" rid="bib113">Wright, 2015</xref>). The significance of a given cell’s time-locking to cues was defined as the number of standard deviations that the impulse response model AIC<sub>C</sub> score (bias-corrected Aikaike Information Criterion [<xref ref-type="bibr" rid="bib50">Hurvich and Tsai, 1989</xref>]) lies above the median AIC<sub>C</sub> of null hypothesis models where the timings <inline-formula><mml:math id="inf92"><mml:mrow><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of cues were randomly shuffled within the cue region. Given the <inline-formula><mml:math id="inf93"><mml:mrow><mml:mi>Δ</mml:mi><mml:mi>F</mml:mi><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> time-series <inline-formula><mml:math id="inf94"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for a given cell and the predicted activity time-trace <inline-formula><mml:math id="inf95"><mml:mrow><mml:mi>m</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> which we treat as vectors <inline-formula><mml:math id="inf96"><mml:mover accent="true"><mml:mi>F</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:math></inline-formula> and <inline-formula><mml:math id="inf97"><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>→</mml:mo></mml:mover></mml:math></inline-formula> respectively, the AIC<sub>C</sub> score is:<disp-formula id="equ3"><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtext>AICC</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:mover><mml:mi>m</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>:=</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>par</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>−</mml:mo><mml:mover><mml:mi>m</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>par</mml:mtext></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>par</mml:mtext></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mtext>par</mml:mtext></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf98"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>F</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the number of time-points that comprise the data and <inline-formula><mml:math id="inf99"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the number of free parameters in the model. Lastly, a small fraction of cells responded to both left- and right-side cues. We parsimoniously allowed for different impulse responses to these by first selecting a primary response (preferred-side cues) as that which yields the best single-side model AIC<sub>C</sub>, then adding a secondary response if and only if it would improve the model likelihood. This criterion is <inline-formula><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtext>AICC</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:msub><mml:mover><mml:mi>m</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mtext>AICC</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>F</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mo>,</mml:mo><mml:msub><mml:mover><mml:mi>m</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mover><mml:mi>m</mml:mi><mml:mo stretchy="false">→</mml:mo></mml:mover><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≥</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf101"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the model prediction with only primary responses and <inline-formula><mml:math id="inf102"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>m</mml:mi><mml:mo>→</mml:mo></mml:mover><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the model prediction with both primary and secondary responses. We defined cells to be cue-locked if the primary response significance exceeded three standard deviations of the abovementioned null hypotheses. Other than a factor of about two reduction in the number of identified cue-locked neurons, we found no qualitative difference in our conclusions for a much stricter significance threshold of 5 standard deviations.</p></sec><sec id="s4-11"><title>Decoding from cue-locked amplitudes</title><p>The decoding models were fit separately using responses to cues in three equally sized spatial bins of the cue region. We defined the neural state response as the vector of contralateral-cue-locked cell response amplitudes to a given cue, and used a Support Vector Machine classifier (SVM) to predict a task variable of interest from this neural state (using data across trials but restricted to responses to cues in a given third of the cue region, as mentioned). To assess the performance of these classifiers using threefold cross-validation, we trained the SVM using 2/3rds of the data and computed Pearson’s correlation coefficient between the predicted and actual task variable values in the held-out 1/3rd of the data. Significance was assessed by constructing 100 null hypothesis pseudo-experiments where the neural state for a given epoch bin was permuted across trials, that is preserving inter-neuron correlations but breaking any potential relationship between neural activity and behavior.</p><p>To correct for multiple comparisons when determining whether the decoding p-value for a particular dataset was significant, we used the Benjamini-Hochberg procedure (<xref ref-type="bibr" rid="bib6">Benjamini and Hochberg, 1995</xref>) as follows. For a given type of decoder, we sorted the <inline-formula><mml:math id="inf103"><mml:mi>p</mml:mi></mml:math></inline-formula>-values of all data points (spatial bins and imaging sessions) in ascending order, <inline-formula><mml:math id="inf104"><mml:mrow><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mn>...</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and found the first rank <inline-formula><mml:math id="inf105"><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> such that <inline-formula><mml:math id="inf106"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:msub><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>×</mml:mo><mml:mn>0.05</mml:mn><mml:mo>/</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:math></inline-formula>. The decoding performance was then considered to be significantly above chance for all <inline-formula><mml:math id="inf107"><mml:mrow><mml:mi>p</mml:mi><mml:mo>≤</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:msub><mml:mi>i</mml:mi><mml:mi>α</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="s4-12"><title>Uncorrelated modes of task variables</title><p>We wished to define a set of uncorrelated behavioral modes such that the original set of six task variables are each a linear combination of these modes, with the additional requirement that each mode should be as similar as possible to one of the task variables. In matrix notation, this means that we want to solve:<disp-formula id="equ4"><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munder><mml:mtext>argmin</mml:mtext><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow></mml:munder><mml:mtext> </mml:mtext><mml:msub><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold">X</mml:mi></mml:mrow></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mspace width="1em"/><mml:mtext>s.t.</mml:mtext><mml:mspace width="1em"/><mml:msup><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">Y</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where each column of <inline-formula><mml:math id="inf108"><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>X</mml:mi></mml:mstyle></mml:math></inline-formula> corresponds to values of a given task variable across trials, each column of <inline-formula><mml:math id="inf109"><mml:mrow><mml:mo> </mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>Y</mml:mi></mml:mstyle></mml:mrow></mml:math></inline-formula> are the uncorrelated behavioral modes, and <inline-formula><mml:math id="inf110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msub><mml:mo>≡</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> is the Frobenius norm of a matrix <inline-formula><mml:math id="inf111"><mml:mrow><mml:mo> </mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>A</mml:mi></mml:mstyle></mml:mrow></mml:math></inline-formula>. This can be computed using polar decomposition (<xref ref-type="bibr" rid="bib48">Higham, 1988</xref>): <inline-formula><mml:math id="inf112"><mml:mrow><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>X</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>Y</mml:mi><mml:mi>H</mml:mi></mml:mstyle></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf113"><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>Y</mml:mi></mml:mstyle></mml:math></inline-formula> is an orthogonal matrix and <inline-formula><mml:math id="inf114"><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>H</mml:mi></mml:mstyle></mml:math></inline-formula> a symmetric matrix. To obtain the polar decomposition, we used an algorithm based on the singular value decomposition <inline-formula><mml:math id="inf115"><mml:mrow><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>X</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>U</mml:mi><mml:mi>Σ</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>V</mml:mi></mml:mstyle><mml:mo>⊤</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>, which gives the solution <inline-formula><mml:math id="inf116"><mml:mrow><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>Y</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>U</mml:mi></mml:mstyle><mml:msup><mml:mstyle mathsize="normal" mathvariant="bold"><mml:mi>V</mml:mi></mml:mstyle><mml:mo>⊤</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>.</p></sec><sec id="s4-13"><title>Amplitude modulation models</title><p>These models used as input the following behavioral data: <inline-formula><mml:math id="inf117"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the onset time of the <inline-formula><mml:math id="inf118"><mml:mrow><mml:msup><mml:mi>i</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> cue, which is located at distance <inline-formula><mml:math id="inf119"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> along the cue region, and appears at a visual angle <inline-formula><mml:math id="inf120"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mtext>cue</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> relative to the mouse (<xref ref-type="fig" rid="fig1">Figure 1c</xref>). <inline-formula><mml:math id="inf121"><mml:mrow><mml:mi>Δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the cumulative cue counts (explained further below) up to and including cue <inline-formula><mml:math id="inf122"><mml:mi>i</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf123"><mml:mrow><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the upcoming choice of the mouse in that trial. <inline-formula><mml:math id="inf124"><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>≡</mml:mo><mml:mi>v</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the running speed of the mouse in the virtual world at the time that the <inline-formula><mml:math id="inf125"><mml:mi>i</mml:mi></mml:math></inline-formula><sup>th</sup> cue appeared, and for simple linear speed dependencies explained below, the standardized version <inline-formula><mml:math id="inf126"><mml:mrow><mml:mover accent="true"><mml:mi>v</mml:mi><mml:mo>˜</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≡</mml:mo><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>v</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mi>Q</mml:mi><mml:mrow><mml:mn>50</mml:mn><mml:mi>%</mml:mi></mml:mrow><mml:mi>v</mml:mi></mml:msubsup><mml:mrow><mml:mo>]</mml:mo> <mml:mo>/</mml:mo> <mml:mo>[</mml:mo></mml:mrow><mml:msubsup><mml:mi>Q</mml:mi><mml:mrow><mml:mn>90</mml:mn><mml:mi>%</mml:mi></mml:mrow><mml:mi>v</mml:mi></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>Q</mml:mi><mml:mrow><mml:mn>10</mml:mn><mml:mi>%</mml:mi></mml:mrow><mml:mi>v</mml:mi></mml:msubsup></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is used, where <inline-formula><mml:math id="inf127"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi><mml:mi>p</mml:mi><mml:mi>v</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> is the <inline-formula><mml:math id="inf128"><mml:mi>p</mml:mi></mml:math></inline-formula> probability content quantile of the speed distribution.</p><p>To account for the stochastic and nonnegative nature of pulsatile responses, the cue-locked cell response amplitudes <inline-formula><mml:math id="inf129"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> were modeled as random samples from a Gamma distribution, <inline-formula><mml:math id="inf130"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo> </mml:mo><mml:mo>|</mml:mo><mml:mo> </mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>∼</mml:mo></mml:mrow></mml:math></inline-formula><inline-formula><mml:math id="inf131"><mml:mrow><mml:mi>Γ</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>k</mml:mi></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The shape parameter <italic>k</italic> for the Gamma distribution is a free parameter, and furthermore indexed by choice for the choice model. The four models discussed in the text are defined by having different behavior-dependent mean functions <inline-formula><mml:math id="inf132"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> that have the following forms (detailed below):<disp-formula id="equ5"><label>(2)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>s</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>v</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>φ</mml:mi><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">A</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>y</mml:mi><mml:mi>c</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>φ</mml:mi><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi mathvariant="normal">Δ</mml:mi></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mtext>-</mml:mtext><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In all of the models, <inline-formula><mml:math id="inf133"><mml:mrow><mml:mi>ρ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is an angular receptive field function that has either a skew-Gaussian (<xref ref-type="bibr" rid="bib85">Priebe et al., 2006</xref>) or sigmoidal dependence on <inline-formula><mml:math id="inf134"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ6"><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ρ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>σ</mml:mi><mml:mo>+</mml:mo><mml:mi>ζ</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>ζ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd><mml:mtd><mml:mtext>skew-Gaussian</mml:mtext></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi>ρ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>ζ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>ν</mml:mi></mml:mrow></mml:msup></mml:mfrac></mml:mstyle></mml:mtd><mml:mtd><mml:mtext>sigmoid</mml:mtext></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p><inline-formula><mml:math id="inf135"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo>,</mml:mo><mml:mi>ζ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>ρ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf136"><mml:mi>ν</mml:mi></mml:math></inline-formula> are all free parameters, and either the skew-Gaussian or sigmoidal hypotheses are selected depending on which produces a better fit for the cell (using the AIC<sub>C</sub> score as explained below).</p><p>All the models also have a speed dependence that multiplies the angular receptive field function. For the null hypothesis, we allowed this to be highly flexible so as to potentially match the explanatory power of the other models (which have other behavioral dependencies). Specifically, the function <inline-formula><mml:math id="inf137"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>v</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>v</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is defined to be a cubic spline (piecewise 3rd-order polynomial [<xref ref-type="bibr" rid="bib34">Gan, 2004</xref>]) with control points at five equally-spaced quantiles of the running speed distribution, that is, at <inline-formula><mml:math id="inf138"><mml:mrow><mml:mi>v</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:msubsup><mml:mi>Q</mml:mi><mml:mn>0</mml:mn><mml:mi>v</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>Q</mml:mi><mml:mrow><mml:mn>25</mml:mn><mml:mi>%</mml:mi></mml:mrow><mml:mi>v</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>Q</mml:mi><mml:mrow><mml:mn>50</mml:mn><mml:mi>%</mml:mi></mml:mrow><mml:mi>v</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>Q</mml:mi><mml:mrow><mml:mn>75</mml:mn><mml:mi>%</mml:mi></mml:mrow><mml:mi>v</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>Q</mml:mi><mml:mrow><mml:mn>100</mml:mn><mml:mi>%</mml:mi></mml:mrow><mml:mi>v</mml:mi></mml:msubsup></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. A cubic spline model has as many free parameters as the number of control points. For the other models, we used a simple linear parameterization for speed dependence, <inline-formula><mml:math id="inf139"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>ψ</mml:mi><mml:mtext> </mml:mtext><mml:mrow><mml:mover><mml:mi>v</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> where <inline-formula><mml:math id="inf140"><mml:mi>ψ</mml:mi></mml:math></inline-formula> is a free parameter (for the choice model, there are two free parameters <inline-formula><mml:math id="inf141"><mml:mrow><mml:msub><mml:mi>ψ</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> where <italic>C</italic> indexes the choice).</p><p>The SSA, choice, and cue-counts models are further distinguished by how they depend on the <inline-formula><mml:math id="inf142"><mml:mi>h</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf143"><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>y</mml:mi><mml:mi>c</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf144"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>Δ</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> functions respectively. For the SSA model:<disp-formula id="equ7"><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>ξ</mml:mi><mml:mtext> </mml:mtext><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The response to the first cue in the session is defined to be <inline-formula><mml:math id="inf145"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. The <inline-formula><mml:math id="inf146"><mml:mi>h</mml:mi></mml:math></inline-formula> function can be understood as follows. Right after the cue at <inline-formula><mml:math id="inf147"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, the response is scaled by the free parameter <inline-formula><mml:math id="inf148"><mml:mi>ξ</mml:mi></mml:math></inline-formula>, that is, the new response level is <inline-formula><mml:math id="inf149"><mml:mrow><mml:mi>ξ</mml:mi><mml:mo> </mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="inf150"><mml:mrow><mml:mi>ξ</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> corresponds to facilitation and corresponds to depression. This facilitation/depression effect decays exponentially with time toward 1, that is, the amount by which the response <inline-formula><mml:math id="inf151"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. deviates from one is equal to the deviation (from 1) of the facilitated/depressed response <inline-formula><mml:math id="inf152"><mml:mrow><mml:mi>ξ</mml:mi><mml:mo> </mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mi>A</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, multiplied by the time-recovery factor <inline-formula><mml:math id="inf153"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>λ</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. Here <inline-formula><mml:math id="inf154"><mml:mi>λ</mml:mi></mml:math></inline-formula> is another free parameter that specifies the timescale of recovery.</p><p>The choice model has smooth dependencies on <inline-formula><mml:math id="inf155"><mml:mi>y</mml:mi></mml:math></inline-formula> location on the cue region parameterized by choice. This is given by two functions <inline-formula><mml:math id="inf156"><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>y</mml:mi><mml:mi>c</mml:mi></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="inf157"><mml:mi>C</mml:mi></mml:math></inline-formula> indexes either the right or left choice, and each of these functions is a cubic spline with control points at <inline-formula><mml:math id="inf158"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0.5</mml:mn><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mtext>cue</mml:mtext></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mtext>cue</mml:mtext></mml:mrow></mml:msub></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (recall that <inline-formula><mml:math id="inf159"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mtext>cue</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the total length of the cue region).</p><p>Lastly, the cue-counts model also has smooth dependencies on cue counts Δ, that is, the function <inline-formula><mml:math id="inf160"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>Δ</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>Δ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a cubic spline. As the responses of cells can depend on counts on either the right, left, or both sides (<xref ref-type="bibr" rid="bib98">Scott et al., 2017</xref>), we allowed Δ to be either the cumulative right or cumulative left cue counts (control points are at <inline-formula><mml:math id="inf161"><mml:mrow><mml:mi>Δ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>8</mml:mn></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>), or the cumulative difference <inline-formula><mml:math id="inf162"><mml:mrow><mml:mo>#</mml:mo><mml:mi>R</mml:mi><mml:mo>−</mml:mo><mml:mo>#</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:math></inline-formula> in cue counts (control points are at <inline-formula><mml:math id="inf163"><mml:mrow><mml:mi>Δ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>). The best definition of Δ was selected per cell according to which produced the best AIC<sub>C</sub> score.</p><p>Because neural activity can be very different in the rare cases where the mouse halts in the middle of the cue region, only data where the speed <italic>v</italic> is within 25% of its median value were included in the analysis of this model. Point estimates for the model parameters were obtained by minimizing the Gamma-distribution negative log-likelihood:<disp-formula id="equ8"><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Because the Gamma distribution is defined only in the positive domain, we had to make an assumption about how to treat data points where <inline-formula><mml:math id="inf164"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. We reasoned that we could substitute these with a noise-like distribution of amplitudes, which were obtained by fitting the impulse response model (<xref ref-type="disp-formula" rid="equ2">Equation 1</xref>) using the same cue timings but simulated noise-only data, which comprised of a <inline-formula><mml:math id="inf165"><mml:mrow><mml:mi>Δ</mml:mi><mml:mi>F</mml:mi><mml:mo>/</mml:mo><mml:mi>F</mml:mi></mml:mrow></mml:math></inline-formula> time-series drawn i.i.d. from a Gaussian distribution with zero mean and standard deviation being <inline-formula><mml:math id="inf166"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mi>F</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula>, the estimated fluorescence noise level for that cell. The relative AIC<sub>C</sub>-based likelihood used for model selection as described in the text, is <inline-formula><mml:math id="inf167"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mtext>AICC</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>model </mml:mtext><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mtext>AICC</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>model </mml:mtext><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></sec><sec id="s4-14"><title>Choice modulation strength</title><p>The location-dependent choice modulation strength for cue-locked amplitudes is defined as <inline-formula><mml:math id="inf168"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>δ</mml:mi><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mtext>choice</mml:mtext></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mtext>y</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mtext>A</mml:mtext><mml:mrow><mml:mtext>contra</mml:mtext></mml:mrow><mml:mrow><mml:mtext>choice</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mtext>y</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mtext>A</mml:mtext><mml:mrow><mml:mtext>ipsi</mml:mtext></mml:mrow><mml:mrow><mml:mtext>choice</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mtext>y</mml:mtext><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>⟨</mml:mo><mml:mi mathvariant="normal">A</mml:mi><mml:mo>⟩</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf169"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mtext>contra</mml:mtext></mml:mrow><mml:mrow><mml:mtext>choice</mml:mtext></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≡</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>;</mml:mo><mml:mtext> </mml:mtext><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> as in <xref ref-type="disp-formula" rid="equ5">Equation 2</xref>, and analogously for ipsilateral choices. This is computed by evaluating the amplitude model prediction vs. location in the cue region, but at fixed <inline-formula><mml:math id="inf170"><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mtext>cue</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> corresponding to zero view angle (<inline-formula><mml:math id="inf171"><mml:mrow><mml:mo>+</mml:mo><mml:mn>22</mml:mn><mml:mo>°</mml:mo></mml:mrow></mml:math></inline-formula> for right-side cues and <inline-formula><mml:math id="inf172"><mml:mrow><mml:mo>−</mml:mo><mml:mn>22</mml:mn><mml:mo>°</mml:mo></mml:mrow></mml:math></inline-formula> for left-side cues) and <inline-formula><mml:math id="inf173"><mml:mrow><mml:mi>Δ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. The normalization constant is:<disp-formula id="equ9"><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:mi mathvariant="normal">A</mml:mi></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mtext>cue</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mspace width="1em"/><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>C</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:munder><mml:mspace width="1em"/><mml:munderover><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mtext>cue</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mspace width="1em"/><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msubsup><mml:mi>A</mml:mi><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>F</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mtext> </mml:mtext><mml:mi>d</mml:mi><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></disp-formula></p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank BB Scott for brainstorming and feedback on the concept of this paper, as well as L Pinto, CM Constantinople, AG Bondy, M Aoi, and B Deverett for useful and interesting discussions. B Engelhard and L Pinto built rigs for the high-throughput training of mice, and S Stein helped in the training of mice in this study. B Engelhard and L Pinto contributed behavioral data from the mouse evidence accumulation task. We additionally thank all members of the BRAIN COGS team, Tank and Brody labs. This work was supported by the NIH grants 5U01NS090541 and 1U19NS104648, and the Simons Collaboration on the Global Brain (SCGB).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Investigation, Methodology, Writing - original draft</p></fn><fn fn-type="con" id="con2"><p>Resources, Supervision</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Supervision, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Supervision, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other" id="fn1"><p>Animal experimentation: All procedures were approved by the Institutional Animal Care and Use Committee at Princeton University (Protocol 1910) and were performed in accordance with the Guide for the Care and Use of Laboratory Animals (National Research Council et al. 2011). All surgeries were performed under isoflurane anesthesia, every effort was made to minimize suffering, and all experimental animals were group housed in enriched environments.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Number of imaging sessions and mice for various areas and layers, for the main experiment.</title></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-60628-supp1-v2.docx"/></supplementary-material><supplementary-material id="supp2"><label>Supplementary file 2.</label><caption><title>Overall performance and number of imaging sessions for the main experiment, per mouse (rows), in various areas and layers (columns).</title><p>Mice of the Thy1 GP5.3 strain have names starting with ‘gp’, and those from the Ai93-Emx1 strain have names starting with ‘ai’ (see Materials and methods).</p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-60628-supp2-v2.docx"/></supplementary-material><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-60628-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>A condensed set of imaging and behavioral data as well as secondary results from analyses and modeling have been deposited in Dryad with the DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/dryad.tb2rbnzxv">https://doi.org/10.5061/dryad.tb2rbnzxv</ext-link>. This dataset contains all of the information required to reproduce the figures in the manuscript. As the full, raw data generated in this study is extremely large, access to these raw data can be arranged upon reasonable request to the authors.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Koay</surname><given-names>SA</given-names></name><name><surname>Thiberge</surname><given-names>SY</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name><name><surname>Tank</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Amplitude modulations of cortical sensory responses in pulsatile evidence accumulation</data-title><source>Dryad Digital Repository</source><pub-id assigning-authority="Dryad" pub-id-type="doi">10.5061/dryad.tb2rbnzxv</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahissar</surname> <given-names>E</given-names></name><name><surname>Kleinfeld</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Closed-loop neuronal computations: focus on vibrissa somatosensation in rat</article-title><source>Cerebral Cortex</source><volume>13</volume><fpage>53</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1093/cercor/13.1.53</pub-id><pub-id pub-id-type="pmid">12466215</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arandia-Romero</surname> <given-names>I</given-names></name><name><surname>Tanabe</surname> <given-names>S</given-names></name><name><surname>Drugowitsch</surname> <given-names>J</given-names></name><name><surname>Kohn</surname> <given-names>A</given-names></name><name><surname>Moreno-Bote</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Multiplicative and additive modulation of neuronal tuning with population activity affects encoded information</article-title><source>Neuron</source><volume>89</volume><fpage>1305</fpage><lpage>1316</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.01.044</pub-id><pub-id pub-id-type="pmid">26924437</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aronov</surname> <given-names>D</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Engagement of neural circuits underlying 2D spatial navigation in a rodent virtual reality system</article-title><source>Neuron</source><volume>84</volume><fpage>442</fpage><lpage>456</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.08.042</pub-id><pub-id pub-id-type="pmid">25374363</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Azim</surname> <given-names>E</given-names></name><name><surname>Seki</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Gain control in the sensorimotor system</article-title><source>Current Opinion in Physiology</source><volume>8</volume><fpage>177</fpage><lpage>187</lpage><pub-id pub-id-type="doi">10.1016/j.cophys.2019.03.005</pub-id><pub-id pub-id-type="pmid">31403088</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bastos</surname> <given-names>AM</given-names></name><name><surname>Usrey</surname> <given-names>WM</given-names></name><name><surname>Adams</surname> <given-names>RA</given-names></name><name><surname>Mangun</surname> <given-names>GR</given-names></name><name><surname>Fries</surname> <given-names>P</given-names></name><name><surname>Friston</surname> <given-names>KJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Canonical microcircuits for predictive coding</article-title><source>Neuron</source><volume>76</volume><fpage>695</fpage><lpage>711</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.10.038</pub-id><pub-id pub-id-type="pmid">23177956</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benjamini</surname> <given-names>Y</given-names></name><name><surname>Hochberg</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Controlling the false discovery rate: a practical and powerful approach to multiple testing</article-title><source>Journal of the Royal Statistical Society: Series B</source><volume>57</volume><fpage>289</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1111/j.2517-6161.1995.tb02031.x</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogacz</surname> <given-names>R</given-names></name><name><surname>Brown</surname> <given-names>E</given-names></name><name><surname>Moehlis</surname> <given-names>J</given-names></name><name><surname>Holmes</surname> <given-names>P</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The physics of optimal decision making: a formal analysis of models of performance in two-alternative forced-choice tasks</article-title><source>Psychological Review</source><volume>113</volume><fpage>700</fpage><lpage>765</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.113.4.700</pub-id><pub-id pub-id-type="pmid">17014301</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bondy</surname> <given-names>AG</given-names></name><name><surname>Haefner</surname> <given-names>RM</given-names></name><name><surname>Cumming</surname> <given-names>BG</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Feedback determines the structure of correlated variability in primary visual cortex</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>598</fpage><lpage>606</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0089-1</pub-id><pub-id pub-id-type="pmid">29483663</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="web"><person-group person-group-type="author"><collab>BRAIN CoGS Collaboration</collab></person-group><year iso-8601-date="2017">2017</year><article-title>BRAIN circuits of coGnitive systems</article-title><ext-link ext-link-type="uri" xlink:href="https://www.braincogs.org/">https://www.braincogs.org/</ext-link><date-in-citation iso-8601-date="2021-01-01">January 1, 2021</date-in-citation></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname> <given-names>DH</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The psychophysics toolbox</article-title><source>Spatial Vision</source><volume>10</volume><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="doi">10.1163/156856897X00357</pub-id><pub-id pub-id-type="pmid">9176952</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Britten</surname> <given-names>KH</given-names></name><name><surname>Newsome</surname> <given-names>WT</given-names></name><name><surname>Shadlen</surname> <given-names>MN</given-names></name><name><surname>Celebrini</surname> <given-names>S</given-names></name><name><surname>Movshon</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>A relationship between behavioral choice and the visual responses of neurons in macaque MT</article-title><source>Visual Neuroscience</source><volume>13</volume><fpage>87</fpage><lpage>100</lpage><pub-id pub-id-type="doi">10.1017/S095252380000715X</pub-id><pub-id pub-id-type="pmid">8730992</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brody</surname> <given-names>CD</given-names></name><name><surname>Hanks</surname> <given-names>TD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural underpinnings of the evidence accumulator</article-title><source>Current Opinion in Neurobiology</source><volume>37</volume><fpage>149</fpage><lpage>157</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2016.01.003</pub-id><pub-id pub-id-type="pmid">26878969</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunton</surname> <given-names>BW</given-names></name><name><surname>Botvinick</surname> <given-names>MM</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Rats and humans can optimally accumulate evidence for decision-making</article-title><source>Science</source><volume>340</volume><fpage>95</fpage><lpage>98</lpage><pub-id pub-id-type="doi">10.1126/science.1233912</pub-id><pub-id pub-id-type="pmid">23559254</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buchan</surname> <given-names>MJ</given-names></name><name><surname>Rowland</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Stimulation of individual neurons is sufficient to influence Sensory-Guided Decision-Making</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>6609</fpage><lpage>6611</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1026-18.2018</pub-id><pub-id pub-id-type="pmid">30045967</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caballero</surname> <given-names>JA</given-names></name><name><surname>Humphries</surname> <given-names>MD</given-names></name><name><surname>Gurney</surname> <given-names>KN</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A probabilistic, distributed, recursive mechanism for decision-making in the brain</article-title><source>PLOS Computational Biology</source><volume>14</volume><elocation-id>e1006033</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006033</pub-id><pub-id pub-id-type="pmid">29614077</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carrillo-Reid</surname> <given-names>L</given-names></name><name><surname>Han</surname> <given-names>S</given-names></name><name><surname>Yang</surname> <given-names>W</given-names></name><name><surname>Akrouh</surname> <given-names>A</given-names></name><name><surname>Yuste</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Controlling visually guided behavior by holographic recalling of cortical ensembles</article-title><source>Cell</source><volume>178</volume><fpage>447</fpage><lpage>457</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2019.05.045</pub-id><pub-id pub-id-type="pmid">31257030</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Celebrini</surname> <given-names>S</given-names></name><name><surname>Newsome</surname> <given-names>WT</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Neuronal and psychophysical sensitivity to motion signals in Extrastriate area MST of the macaque monkey</article-title><source>The Journal of Neuroscience</source><volume>14</volume><fpage>4109</fpage><lpage>4124</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.14-07-04109.1994</pub-id><pub-id pub-id-type="pmid">8027765</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chaudhuri</surname> <given-names>R</given-names></name><name><surname>Knoblauch</surname> <given-names>K</given-names></name><name><surname>Gariel</surname> <given-names>MA</given-names></name><name><surname>Kennedy</surname> <given-names>H</given-names></name><name><surname>Wang</surname> <given-names>XJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A Large-Scale circuit mechanism for hierarchical dynamical processing in the primate cortex</article-title><source>Neuron</source><volume>88</volume><fpage>419</fpage><lpage>431</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.008</pub-id><pub-id pub-id-type="pmid">26439530</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>TW</given-names></name><name><surname>Wardill</surname> <given-names>TJ</given-names></name><name><surname>Sun</surname> <given-names>Y</given-names></name><name><surname>Pulver</surname> <given-names>SR</given-names></name><name><surname>Renninger</surname> <given-names>SL</given-names></name><name><surname>Baohan</surname> <given-names>A</given-names></name><name><surname>Schreiter</surname> <given-names>ER</given-names></name><name><surname>Kerr</surname> <given-names>RA</given-names></name><name><surname>Orger</surname> <given-names>MB</given-names></name><name><surname>Jayaraman</surname> <given-names>V</given-names></name><name><surname>Looger</surname> <given-names>LL</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name><name><surname>Kim</surname> <given-names>DS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Ultrasensitive fluorescent proteins for imaging neuronal activity</article-title><source>Nature</source><volume>499</volume><fpage>295</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1038/nature12354</pub-id><pub-id pub-id-type="pmid">23868258</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christophel</surname> <given-names>TB</given-names></name><name><surname>Klink</surname> <given-names>PC</given-names></name><name><surname>Spitzer</surname> <given-names>B</given-names></name><name><surname>Roelfsema</surname> <given-names>PR</given-names></name><name><surname>Haynes</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The distributed nature of working memory</article-title><source>Trends in Cognitive Sciences</source><volume>21</volume><fpage>111</fpage><lpage>124</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2016.12.007</pub-id><pub-id pub-id-type="pmid">28063661</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cohen</surname> <given-names>MR</given-names></name><name><surname>Maunsell</surname> <given-names>JHR</given-names></name></person-group><year iso-8601-date="2014">2014</year><source>Neuronal Mechanisms of Spatial Attention in Visual Cerebral Cortex</source><publisher-name>Oxford University Press</publisher-name><pub-id pub-id-type="doi">10.1093/oxfordhb/9780199675111.013.007</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname> <given-names>MR</given-names></name><name><surname>Newsome</surname> <given-names>WT</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Estimates of the contribution of single neurons to perception depend on timescale and noise correlation</article-title><source>Journal of Neuroscience</source><volume>29</volume><fpage>6635</fpage><lpage>6648</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5179-08.2009</pub-id><pub-id pub-id-type="pmid">19458234</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dana</surname> <given-names>H</given-names></name><name><surname>Chen</surname> <given-names>TW</given-names></name><name><surname>Hu</surname> <given-names>A</given-names></name><name><surname>Shields</surname> <given-names>BC</given-names></name><name><surname>Guo</surname> <given-names>C</given-names></name><name><surname>Looger</surname> <given-names>LL</given-names></name><name><surname>Kim</surname> <given-names>DS</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Thy1-GCaMP6 transgenic mice for neuronal population imaging in vivo</article-title><source>PLOS ONE</source><volume>9</volume><elocation-id>e108697</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0108697</pub-id><pub-id pub-id-type="pmid">25250714</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DasGupta</surname> <given-names>A</given-names></name><name><surname>Cai</surname> <given-names>TT</given-names></name><name><surname>Brown</surname> <given-names>LD</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Interval estimation for a binomial proportion</article-title><source>Statistical Science</source><volume>16</volume><fpage>101</fpage><lpage>133</lpage><pub-id pub-id-type="doi">10.1214/ss/1009213286</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DiCarlo</surname> <given-names>JJ</given-names></name><name><surname>Zoccolan</surname> <given-names>D</given-names></name><name><surname>Rust</surname> <given-names>NC</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>How does the brain solve visual object recognition?</article-title><source>Neuron</source><volume>73</volume><fpage>415</fpage><lpage>434</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.01.010</pub-id><pub-id pub-id-type="pmid">22325196</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dodd</surname> <given-names>JV</given-names></name><name><surname>Krug</surname> <given-names>K</given-names></name><name><surname>Cumming</surname> <given-names>BG</given-names></name><name><surname>Parker</surname> <given-names>AJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Perceptually bistable three-dimensional figures evoke high choice probabilities in cortical area MT</article-title><source>The Journal of Neuroscience</source><volume>21</volume><fpage>4809</fpage><lpage>4821</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.21-13-04809.2001</pub-id><pub-id pub-id-type="pmid">11425908</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dombeck</surname> <given-names>DA</given-names></name><name><surname>Harvey</surname> <given-names>CD</given-names></name><name><surname>Tian</surname> <given-names>L</given-names></name><name><surname>Looger</surname> <given-names>LL</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Functional imaging of hippocampal place cells at cellular resolution during virtual navigation</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1433</fpage><lpage>1440</lpage><pub-id pub-id-type="doi">10.1038/nn.2648</pub-id><pub-id pub-id-type="pmid">20890294</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doron</surname> <given-names>G</given-names></name><name><surname>Brecht</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>What single-cell stimulation has told us about neural coding</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>370</volume><elocation-id>20140204</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2014.0204</pub-id><pub-id pub-id-type="pmid">26240419</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dotson</surname> <given-names>NM</given-names></name><name><surname>Hoffman</surname> <given-names>SJ</given-names></name><name><surname>Goodell</surname> <given-names>B</given-names></name><name><surname>Gray</surname> <given-names>CM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Feature-Based visual Short-Term memory is widely distributed and hierarchically organized</article-title><source>Neuron</source><volume>99</volume><fpage>215</fpage><lpage>226</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.05.026</pub-id><pub-id pub-id-type="pmid">29909999</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Douglas</surname> <given-names>RJ</given-names></name><name><surname>Martin</surname> <given-names>KA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Recurrent neuronal circuits in the neocortex</article-title><source>Current Biology</source><volume>17</volume><fpage>R496</fpage><lpage>R500</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2007.04.024</pub-id><pub-id pub-id-type="pmid">17610826</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erlich</surname> <given-names>JC</given-names></name><name><surname>Bialek</surname> <given-names>M</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A cortical substrate for memory-guided orienting in the rat</article-title><source>Neuron</source><volume>72</volume><fpage>330</fpage><lpage>343</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.07.010</pub-id><pub-id pub-id-type="pmid">22017991</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiser</surname> <given-names>A</given-names></name><name><surname>Mahringer</surname> <given-names>D</given-names></name><name><surname>Oyibo</surname> <given-names>HK</given-names></name><name><surname>Petersen</surname> <given-names>AV</given-names></name><name><surname>Leinweber</surname> <given-names>M</given-names></name><name><surname>Keller</surname> <given-names>GB</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Experience-dependent spatial expectations in mouse visual cortex</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>1658</fpage><lpage>1664</lpage><pub-id pub-id-type="doi">10.1038/nn.4385</pub-id><pub-id pub-id-type="pmid">27618309</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Froudarakis</surname> <given-names>E</given-names></name><name><surname>Fahey</surname> <given-names>PG</given-names></name><name><surname>Reimer</surname> <given-names>J</given-names></name><name><surname>Smirnakis</surname> <given-names>SM</given-names></name><name><surname>Tehovnik</surname> <given-names>EJ</given-names></name><name><surname>Tolias</surname> <given-names>AS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The visual cortex in context</article-title><source>Annual Review of Vision Science</source><volume>5</volume><fpage>317</fpage><lpage>339</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-091517-034407</pub-id><pub-id pub-id-type="pmid">31525143</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gan</surname> <given-names>LK</given-names></name></person-group><year iso-8601-date="2004">2004</year><source>Interpolation: Cubic Spline Interpolation and Hermite Interpolation</source><publisher-name>Cubic Spline</publisher-name></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garrett</surname> <given-names>ME</given-names></name><name><surname>Nauhaus</surname> <given-names>I</given-names></name><name><surname>Marshel</surname> <given-names>JH</given-names></name><name><surname>Callaway</surname> <given-names>EM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Topography and areal organization of mouse visual cortex</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>12587</fpage><lpage>12600</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1124-14.2014</pub-id><pub-id pub-id-type="pmid">25209296</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gavornik</surname> <given-names>JP</given-names></name><name><surname>Bear</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Higher brain functions served by the lowly rodent primary visual cortex</article-title><source>Learning &amp; Memory</source><volume>21</volume><fpage>527</fpage><lpage>533</lpage><pub-id pub-id-type="doi">10.1101/lm.034355.114</pub-id><pub-id pub-id-type="pmid">25225298</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilbert</surname> <given-names>CD</given-names></name><name><surname>Sigman</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Brain states: top-down influences in sensory processing</article-title><source>Neuron</source><volume>54</volume><fpage>677</fpage><lpage>696</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.05.019</pub-id><pub-id pub-id-type="pmid">17553419</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glickfeld</surname> <given-names>LL</given-names></name><name><surname>Olsen</surname> <given-names>SR</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Higher-Order Areas of the mouse visual cortex</article-title><source>Annual Review of Vision Science</source><volume>3</volume><fpage>251</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-102016-061331</pub-id><pub-id pub-id-type="pmid">28746815</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname> <given-names>JI</given-names></name><name><surname>Shadlen</surname> <given-names>MN</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The neural basis of decision making</article-title><source>Annual Review of Neuroscience</source><volume>30</volume><fpage>535</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.29.051605.113038</pub-id><pub-id pub-id-type="pmid">17600525</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldman</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Memory without feedback in a neural network</article-title><source>Neuron</source><volume>61</volume><fpage>621</fpage><lpage>634</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.12.012</pub-id><pub-id pub-id-type="pmid">19249281</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goris</surname> <given-names>RL</given-names></name><name><surname>Movshon</surname> <given-names>JA</given-names></name><name><surname>Simoncelli</surname> <given-names>EP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Partitioning neuronal variability</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>858</fpage><lpage>865</lpage><pub-id pub-id-type="doi">10.1038/nn.3711</pub-id><pub-id pub-id-type="pmid">24777419</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorski</surname> <given-names>JA</given-names></name><name><surname>Talley</surname> <given-names>T</given-names></name><name><surname>Qiu</surname> <given-names>M</given-names></name><name><surname>Puelles</surname> <given-names>L</given-names></name><name><surname>Rubenstein</surname> <given-names>JL</given-names></name><name><surname>Jones</surname> <given-names>KR</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Cortical excitatory neurons and Glia, but not GABAergic neurons, are produced in the Emx1-expressing lineage</article-title><source>The Journal of Neuroscience</source><volume>22</volume><fpage>6309</fpage><lpage>6314</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.22-15-06309.2002</pub-id><pub-id pub-id-type="pmid">12151506</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gu</surname> <given-names>Y</given-names></name><name><surname>Angelaki</surname> <given-names>DE</given-names></name><name><surname>DeAngelis</surname> <given-names>GC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Contribution of correlated noise and selective decoding to choice probability measurements in extrastriate visual cortex</article-title><source>eLife</source><volume>3</volume><elocation-id>e02670</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.02670</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haefner</surname> <given-names>RM</given-names></name><name><surname>Berkes</surname> <given-names>P</given-names></name><name><surname>Fiser</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Perceptual Decision-Making as probabilistic inference by neural sampling</article-title><source>Neuron</source><volume>90</volume><fpage>649</fpage><lpage>660</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.03.020</pub-id><pub-id pub-id-type="pmid">27146267</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanks</surname> <given-names>TD</given-names></name><name><surname>Kopec</surname> <given-names>CD</given-names></name><name><surname>Brunton</surname> <given-names>BW</given-names></name><name><surname>Duan</surname> <given-names>CA</given-names></name><name><surname>Erlich</surname> <given-names>JC</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Distinct relationships of parietal and prefrontal cortices to evidence accumulation</article-title><source>Nature</source><volume>520</volume><fpage>220</fpage><lpage>223</lpage><pub-id pub-id-type="doi">10.1038/nature14066</pub-id><pub-id pub-id-type="pmid">25600270</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname> <given-names>KD</given-names></name><name><surname>Thiele</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cortical state and attention</article-title><source>Nature Reviews Neuroscience</source><volume>12</volume><fpage>509</fpage><lpage>523</lpage><pub-id pub-id-type="doi">10.1038/nrn3084</pub-id><pub-id pub-id-type="pmid">21829219</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname> <given-names>U</given-names></name><name><surname>Chen</surname> <given-names>J</given-names></name><name><surname>Honey</surname> <given-names>CJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Hierarchical process memory: memory as an integral component of information processing</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>304</fpage><lpage>313</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.04.006</pub-id><pub-id pub-id-type="pmid">25980649</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Higham</surname> <given-names>NJ</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Matrix nearness problems and applications</article-title><conf-name>Citeseer</conf-name></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hillyard</surname> <given-names>SA</given-names></name><name><surname>Vogel</surname> <given-names>EK</given-names></name><name><surname>Luck</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Sensory gain control (amplification) as a mechanism of selective attention: electrophysiological and neuroimaging evidence</article-title><source>Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences</source><volume>353</volume><fpage>1257</fpage><lpage>1270</lpage><pub-id pub-id-type="doi">10.1098/rstb.1998.0281</pub-id><pub-id pub-id-type="pmid">9770220</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hurvich</surname> <given-names>CM</given-names></name><name><surname>Tsai</surname> <given-names>C-L</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Regression and time series model selection in small samples</article-title><source>Biometrika</source><volume>76</volume><fpage>297</fpage><lpage>307</lpage><pub-id pub-id-type="doi">10.1093/biomet/76.2.297</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Juavinett</surname> <given-names>AL</given-names></name><name><surname>Nauhaus</surname> <given-names>I</given-names></name><name><surname>Garrett</surname> <given-names>ME</given-names></name><name><surname>Zhuang</surname> <given-names>J</given-names></name><name><surname>Callaway</surname> <given-names>EM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Automated identification of mouse visual Areas with intrinsic signal imaging</article-title><source>Nature Protocols</source><volume>12</volume><fpage>32</fpage><lpage>43</lpage><pub-id pub-id-type="doi">10.1038/nprot.2016.158</pub-id><pub-id pub-id-type="pmid">27906169</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalatsky</surname> <given-names>VA</given-names></name><name><surname>Stryker</surname> <given-names>MP</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>New paradigm for optical imaging: temporally encoded maps of intrinsic signal</article-title><source>Neuron</source><volume>38</volume><fpage>529</fpage><lpage>545</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(03)00286-1</pub-id><pub-id pub-id-type="pmid">12765606</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaneko</surname> <given-names>M</given-names></name><name><surname>Fu</surname> <given-names>Y</given-names></name><name><surname>Stryker</surname> <given-names>MP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Locomotion induces Stimulus-Specific response enhancement in adult visual cortex</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>3532</fpage><lpage>3543</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3760-16.2017</pub-id><pub-id pub-id-type="pmid">28258167</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Churchland</surname> <given-names>MM</given-names></name><name><surname>Ryu</surname> <given-names>SI</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Cortical activity in the null space: permitting preparation without movement</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>440</fpage><lpage>448</lpage><pub-id pub-id-type="doi">10.1038/nn.3643</pub-id><pub-id pub-id-type="pmid">24487233</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keller</surname> <given-names>GB</given-names></name><name><surname>Bonhoeffer</surname> <given-names>T</given-names></name><name><surname>Hübener</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Sensorimotor mismatch signals in primary visual cortex of the behaving mouse</article-title><source>Neuron</source><volume>74</volume><fpage>809</fpage><lpage>815</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.03.040</pub-id><pub-id pub-id-type="pmid">22681686</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keller</surname> <given-names>GB</given-names></name><name><surname>Mrsic-Flogel</surname> <given-names>TD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Predictive processing: a canonical cortical computation</article-title><source>Neuron</source><volume>100</volume><fpage>424</fpage><lpage>435</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.003</pub-id><pub-id pub-id-type="pmid">30359606</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kimura</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Visual mismatch negativity and unintentional temporal-context-based prediction in vision</article-title><source>International Journal of Psychophysiology</source><volume>83</volume><fpage>144</fpage><lpage>155</lpage><pub-id pub-id-type="doi">10.1016/j.ijpsycho.2011.11.010</pub-id><pub-id pub-id-type="pmid">22137965</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Koay</surname> <given-names>SA</given-names></name><name><surname>Thiberge</surname> <given-names>SY</given-names></name><name><surname>Brody</surname> <given-names>C</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Sequential and efficient neural-population coding of complex task information</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/801654</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krumin</surname> <given-names>M</given-names></name><name><surname>Lee</surname> <given-names>JJ</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Decision and navigation in mouse parietal cortex</article-title><source>eLife</source><volume>7</volume><elocation-id>e42583</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.42583</pub-id><pub-id pub-id-type="pmid">30468146</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumano</surname> <given-names>H</given-names></name><name><surname>Suda</surname> <given-names>Y</given-names></name><name><surname>Uka</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Context-Dependent accumulation of sensory evidence in the parietal cortex underlies flexible task switching</article-title><source>Journal of Neuroscience</source><volume>36</volume><fpage>12192</fpage><lpage>12202</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1693-16.2016</pub-id><pub-id pub-id-type="pmid">27903728</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Law</surname> <given-names>CT</given-names></name><name><surname>Gold</surname> <given-names>JI</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Reinforcement learning can account for associative and perceptual learning on a visual-decision task</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>655</fpage><lpage>663</lpage><pub-id pub-id-type="doi">10.1038/nn.2304</pub-id><pub-id pub-id-type="pmid">19377473</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>TS</given-names></name><name><surname>Mumford</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Hierarchical bayesian inference in the visual cortex</article-title><source>Journal of the Optical Society of America A</source><volume>20</volume><fpage>1434</fpage><lpage>1448</lpage><pub-id pub-id-type="doi">10.1364/JOSAA.20.001434</pub-id><pub-id pub-id-type="pmid">12868647</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lerman</surname> <given-names>GM</given-names></name><name><surname>Gill</surname> <given-names>JV</given-names></name><name><surname>Rinberg</surname> <given-names>D</given-names></name><name><surname>Shoham</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Precise optical probing of perceptual detection</article-title><conf-name>Biophotonics Congress: Optics in the Life Sciences Congress 2019 (BODA,BRAIN,NTM,OMA,OMP), BM3A.2. Optical Society of America</conf-name><pub-id pub-id-type="doi">10.1101/456764</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>W</given-names></name><name><surname>Piëch</surname> <given-names>V</given-names></name><name><surname>Gilbert</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Perceptual learning and top-down influences in primary visual cortex</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>651</fpage><lpage>657</lpage><pub-id pub-id-type="doi">10.1038/nn1255</pub-id><pub-id pub-id-type="pmid">15156149</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname> <given-names>IC</given-names></name><name><surname>Okun</surname> <given-names>M</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The nature of shared cortical variability</article-title><source>Neuron</source><volume>87</volume><fpage>644</fpage><lpage>656</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.06.035</pub-id><pub-id pub-id-type="pmid">26212710</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luna</surname> <given-names>R</given-names></name><name><surname>Hernández</surname> <given-names>A</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name><name><surname>Romo</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Neural codes for perceptual discrimination in primary somatosensory cortex</article-title><source>Nature Neuroscience</source><volume>8</volume><fpage>1210</fpage><lpage>1219</lpage><pub-id pub-id-type="doi">10.1038/nn1513</pub-id><pub-id pub-id-type="pmid">16056223</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Makino</surname> <given-names>H</given-names></name><name><surname>Komiyama</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Learning enhances the relative impact of top-down processing in the visual cortex</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1116</fpage><lpage>1122</lpage><pub-id pub-id-type="doi">10.1038/nn.4061</pub-id><pub-id pub-id-type="pmid">26167904</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manita</surname> <given-names>S</given-names></name><name><surname>Suzuki</surname> <given-names>T</given-names></name><name><surname>Homma</surname> <given-names>C</given-names></name><name><surname>Matsumoto</surname> <given-names>T</given-names></name><name><surname>Odagawa</surname> <given-names>M</given-names></name><name><surname>Yamada</surname> <given-names>K</given-names></name><name><surname>Ota</surname> <given-names>K</given-names></name><name><surname>Matsubara</surname> <given-names>C</given-names></name><name><surname>Inutsuka</surname> <given-names>A</given-names></name><name><surname>Sato</surname> <given-names>M</given-names></name><name><surname>Ohkura</surname> <given-names>M</given-names></name><name><surname>Yamanaka</surname> <given-names>A</given-names></name><name><surname>Yanagawa</surname> <given-names>Y</given-names></name><name><surname>Nakai</surname> <given-names>J</given-names></name><name><surname>Hayashi</surname> <given-names>Y</given-names></name><name><surname>Larkum</surname> <given-names>ME</given-names></name><name><surname>Murayama</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A Top-Down cortical circuit for accurate sensory perception</article-title><source>Neuron</source><volume>86</volume><fpage>1304</fpage><lpage>1316</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.05.006</pub-id><pub-id pub-id-type="pmid">26004915</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marshel</surname> <given-names>JH</given-names></name><name><surname>Kim</surname> <given-names>YS</given-names></name><name><surname>Machado</surname> <given-names>TA</given-names></name><name><surname>Quirin</surname> <given-names>S</given-names></name><name><surname>Benson</surname> <given-names>B</given-names></name><name><surname>Kadmon</surname> <given-names>J</given-names></name><name><surname>Raja</surname> <given-names>C</given-names></name><name><surname>Chibukhchyan</surname> <given-names>A</given-names></name><name><surname>Ramakrishnan</surname> <given-names>C</given-names></name><name><surname>Inoue</surname> <given-names>M</given-names></name><name><surname>Shane</surname> <given-names>JC</given-names></name><name><surname>McKnight</surname> <given-names>DJ</given-names></name><name><surname>Yoshizawa</surname> <given-names>S</given-names></name><name><surname>Kato</surname> <given-names>HE</given-names></name><name><surname>Ganguli</surname> <given-names>S</given-names></name><name><surname>Deisseroth</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Cortical layer-specific critical dynamics triggering perception</article-title><source>Science</source><volume>365</volume><elocation-id>eaaw5202</elocation-id><pub-id pub-id-type="doi">10.1126/science.aaw5202</pub-id><pub-id pub-id-type="pmid">31320556</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Minderer</surname> <given-names>M</given-names></name><name><surname>Brown</surname> <given-names>KD</given-names></name><name><surname>Harvey</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The spatial structure of neural encoding in mouse posterior cortex during navigation</article-title><source>Neuron</source><volume>102</volume><fpage>232</fpage><lpage>248</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.01.029</pub-id><pub-id pub-id-type="pmid">30772081</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miri</surname> <given-names>A</given-names></name><name><surname>Daie</surname> <given-names>K</given-names></name><name><surname>Arrenberg</surname> <given-names>AB</given-names></name><name><surname>Baier</surname> <given-names>H</given-names></name><name><surname>Aksay</surname> <given-names>E</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Spatial gradients and multidimensional dynamics in a neural integrator circuit</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1150</fpage><lpage>1159</lpage><pub-id pub-id-type="doi">10.1038/nn.2888</pub-id><pub-id pub-id-type="pmid">21857656</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname> <given-names>JD</given-names></name><name><surname>Bernacchia</surname> <given-names>A</given-names></name><name><surname>Freedman</surname> <given-names>DJ</given-names></name><name><surname>Romo</surname> <given-names>R</given-names></name><name><surname>Wallis</surname> <given-names>JD</given-names></name><name><surname>Cai</surname> <given-names>X</given-names></name><name><surname>Padoa-Schioppa</surname> <given-names>C</given-names></name><name><surname>Pasternak</surname> <given-names>T</given-names></name><name><surname>Seo</surname> <given-names>H</given-names></name><name><surname>Lee</surname> <given-names>D</given-names></name><name><surname>Wang</surname> <given-names>XJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A hierarchy of intrinsic timescales across primate cortex</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1661</fpage><lpage>1663</lpage><pub-id pub-id-type="doi">10.1038/nn.3862</pub-id><pub-id pub-id-type="pmid">25383900</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="book"><person-group person-group-type="author"><collab>National Research Council, Division on Earth and Life Studies, Institute for Laboratory Animal Research, and Committee for the Update of the Guide for the Care and Use of Laboratory Animals</collab></person-group><year iso-8601-date="2011">2011</year><source>Guide for the Care and Use of Laboratory Animals</source><publisher-name>National Academies Press</publisher-name></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niell</surname> <given-names>CM</given-names></name><name><surname>Stryker</surname> <given-names>MP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Modulation of visual responses by behavioral state in mouse visual cortex</article-title><source>Neuron</source><volume>65</volume><fpage>472</fpage><lpage>479</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.01.033</pub-id><pub-id pub-id-type="pmid">20188652</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nienborg</surname> <given-names>H</given-names></name><name><surname>Cohen</surname> <given-names>MR</given-names></name><name><surname>Cumming</surname> <given-names>BG</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Decision-related activity in sensory neurons: correlations among neurons and with behavior</article-title><source>Annual Review of Neuroscience</source><volume>35</volume><fpage>463</fpage><lpage>483</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-062111-150403</pub-id><pub-id pub-id-type="pmid">22483043</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nienborg</surname> <given-names>H</given-names></name><name><surname>Cumming</surname> <given-names>BG</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Decision-related activity in sensory neurons reflects more than a neuron's causal effect</article-title><source>Nature</source><volume>459</volume><fpage>89</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1038/nature07821</pub-id><pub-id pub-id-type="pmid">19270683</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nienborg</surname> <given-names>H</given-names></name><name><surname>Cumming</surname> <given-names>BG</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Decision-related activity in sensory neurons may depend on the columnar architecture of cerebral cortex</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>3579</fpage><lpage>3585</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2340-13.2014</pub-id><pub-id pub-id-type="pmid">24599457</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petreanu</surname> <given-names>L</given-names></name><name><surname>Gutnisky</surname> <given-names>DA</given-names></name><name><surname>Huber</surname> <given-names>D</given-names></name><name><surname>Xu</surname> <given-names>NL</given-names></name><name><surname>O'Connor</surname> <given-names>DH</given-names></name><name><surname>Tian</surname> <given-names>L</given-names></name><name><surname>Looger</surname> <given-names>L</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Activity in motor-sensory projections reveals distributed coding in somatosensation</article-title><source>Nature</source><volume>489</volume><fpage>299</fpage><lpage>303</lpage><pub-id pub-id-type="doi">10.1038/nature11321</pub-id><pub-id pub-id-type="pmid">22922646</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pinto</surname> <given-names>L</given-names></name><name><surname>Koay</surname> <given-names>SA</given-names></name><name><surname>Engelhard</surname> <given-names>B</given-names></name><name><surname>Yoon</surname> <given-names>AM</given-names></name><name><surname>Deverett</surname> <given-names>B</given-names></name><name><surname>Thiberge</surname> <given-names>SY</given-names></name><name><surname>Witten</surname> <given-names>IB</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>An Accumulation-of-Evidence task using visual pulses for mice navigating in virtual reality</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>12</volume><elocation-id>36</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2018.00036</pub-id><pub-id pub-id-type="pmid">29559900</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pinto</surname> <given-names>L</given-names></name><name><surname>Rajan</surname> <given-names>K</given-names></name><name><surname>DePasquale</surname> <given-names>B</given-names></name><name><surname>Thiberge</surname> <given-names>SY</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Task-Dependent changes in the Large-Scale dynamics and necessity of cortical regions</article-title><source>Neuron</source><volume>104</volume><fpage>810</fpage><lpage>824</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.08.025</pub-id><pub-id pub-id-type="pmid">31564591</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pnevmatikakis</surname> <given-names>EA</given-names></name><name><surname>Soudry</surname> <given-names>D</given-names></name><name><surname>Gao</surname> <given-names>Y</given-names></name><name><surname>Machado</surname> <given-names>TA</given-names></name><name><surname>Merel</surname> <given-names>J</given-names></name><name><surname>Pfau</surname> <given-names>D</given-names></name><name><surname>Reardon</surname> <given-names>T</given-names></name><name><surname>Mu</surname> <given-names>Y</given-names></name><name><surname>Lacefield</surname> <given-names>C</given-names></name><name><surname>Yang</surname> <given-names>W</given-names></name><name><surname>Ahrens</surname> <given-names>M</given-names></name><name><surname>Bruno</surname> <given-names>R</given-names></name><name><surname>Jessell</surname> <given-names>TM</given-names></name><name><surname>Peterka</surname> <given-names>DS</given-names></name><name><surname>Yuste</surname> <given-names>R</given-names></name><name><surname>Paninski</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Simultaneous denoising, Deconvolution, and demixing of calcium imaging data</article-title><source>Neuron</source><volume>89</volume><fpage>285</fpage><lpage>299</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.037</pub-id><pub-id pub-id-type="pmid">26774160</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pologruto</surname> <given-names>TA</given-names></name><name><surname>Sabatini</surname> <given-names>BL</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>ScanImage: flexible software for operating laser scanning microscopes</article-title><source>BioMedical Engineering OnLine</source><volume>2</volume><elocation-id>13</elocation-id><pub-id pub-id-type="doi">10.1186/1475-925X-2-13</pub-id><pub-id pub-id-type="pmid">12801419</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poort</surname> <given-names>J</given-names></name><name><surname>Khan</surname> <given-names>AG</given-names></name><name><surname>Pachitariu</surname> <given-names>M</given-names></name><name><surname>Nemri</surname> <given-names>A</given-names></name><name><surname>Orsolic</surname> <given-names>I</given-names></name><name><surname>Krupic</surname> <given-names>J</given-names></name><name><surname>Bauza</surname> <given-names>M</given-names></name><name><surname>Sahani</surname> <given-names>M</given-names></name><name><surname>Keller</surname> <given-names>GB</given-names></name><name><surname>Mrsic-Flogel</surname> <given-names>TD</given-names></name><name><surname>Hofer</surname> <given-names>SB</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Learning enhances sensory and multiple Non-sensory representations in primary visual cortex</article-title><source>Neuron</source><volume>86</volume><fpage>1478</fpage><lpage>1490</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.05.037</pub-id><pub-id pub-id-type="pmid">26051421</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Price</surname> <given-names>NS</given-names></name><name><surname>Born</surname> <given-names>RT</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Timescales of sensory- and decision-related activity in the middle temporal and medial superior temporal Areas</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>14036</fpage><lpage>14045</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2336-10.2010</pub-id><pub-id pub-id-type="pmid">20962225</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Priebe</surname> <given-names>NJ</given-names></name><name><surname>Lisberger</surname> <given-names>SG</given-names></name><name><surname>Movshon</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Tuning for spatiotemporal frequency and speed in directionally selective neurons of macaque striate cortex</article-title><source>Journal of Neuroscience</source><volume>26</volume><fpage>2941</fpage><lpage>2950</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3936-05.2006</pub-id><pub-id pub-id-type="pmid">16540571</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rao</surname> <given-names>RP</given-names></name><name><surname>Ballard</surname> <given-names>DH</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects</article-title><source>Nature Neuroscience</source><volume>2</volume><fpage>79</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1038/4580</pub-id><pub-id pub-id-type="pmid">10195184</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raposo</surname> <given-names>D</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A category-free neural population supports evolving demands during decision-making</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1784</fpage><lpage>1792</lpage><pub-id pub-id-type="doi">10.1038/nn.3865</pub-id><pub-id pub-id-type="pmid">25383902</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname> <given-names>R</given-names></name><name><surname>McKoon</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The diffusion decision model: theory and data for two-choice decision tasks</article-title><source>Neural Computation</source><volume>20</volume><fpage>873</fpage><lpage>922</lpage><pub-id pub-id-type="doi">10.1162/neco.2008.12-06-420</pub-id><pub-id pub-id-type="pmid">18085991</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratzlaff</surname> <given-names>EH</given-names></name><name><surname>Grinvald</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>A tandem-lens epifluorescence macroscope: hundred-fold brightness advantage for wide-field imaging</article-title><source>Journal of Neuroscience Methods</source><volume>36</volume><fpage>127</fpage><lpage>137</lpage><pub-id pub-id-type="doi">10.1016/0165-0270(91)90038-2</pub-id><pub-id pub-id-type="pmid">1905769</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roelfsema</surname> <given-names>PR</given-names></name><name><surname>de Lange</surname> <given-names>FP</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Early visual cortex as a multiscale cognitive blackboard</article-title><source>Annual Review of Vision Science</source><volume>2</volume><fpage>131</fpage><lpage>151</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-111815-114443</pub-id><pub-id pub-id-type="pmid">28532363</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Romo</surname> <given-names>R</given-names></name><name><surname>Hernández</surname> <given-names>A</given-names></name><name><surname>Zainos</surname> <given-names>A</given-names></name><name><surname>Lemus</surname> <given-names>L</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Neuronal correlates of decision-making in secondary somatosensory cortex</article-title><source>Nature Neuroscience</source><volume>5</volume><fpage>1217</fpage><lpage>1225</lpage><pub-id pub-id-type="doi">10.1038/nn950</pub-id><pub-id pub-id-type="pmid">12368806</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Romo</surname> <given-names>R</given-names></name><name><surname>Hernández</surname> <given-names>A</given-names></name><name><surname>Zainos</surname> <given-names>A</given-names></name><name><surname>Salinas</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Correlated neuronal discharges that increase coding efficiency during perceptual discrimination</article-title><source>Neuron</source><volume>38</volume><fpage>649</fpage><lpage>657</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(03)00287-3</pub-id><pub-id pub-id-type="pmid">12765615</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Runyan</surname> <given-names>CA</given-names></name><name><surname>Piasini</surname> <given-names>E</given-names></name><name><surname>Panzeri</surname> <given-names>S</given-names></name><name><surname>Harvey</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Distinct timescales of population coding across cortex</article-title><source>Nature</source><volume>548</volume><fpage>92</fpage><lpage>96</lpage><pub-id pub-id-type="doi">10.1038/nature23020</pub-id><pub-id pub-id-type="pmid">28723889</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saleem</surname> <given-names>AB</given-names></name><name><surname>Ayaz</surname> <given-names>A</given-names></name><name><surname>Jeffery</surname> <given-names>KJ</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Integration of visual motion and locomotion in mouse visual cortex</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1864</fpage><lpage>1869</lpage><pub-id pub-id-type="doi">10.1038/nn.3567</pub-id><pub-id pub-id-type="pmid">24185423</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saleem</surname> <given-names>AB</given-names></name><name><surname>Diamanti</surname> <given-names>EM</given-names></name><name><surname>Fournier</surname> <given-names>J</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Coherent encoding of subjective spatial position in visual cortex and Hippocampus</article-title><source>Nature</source><volume>562</volume><fpage>124</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0516-1</pub-id><pub-id pub-id-type="pmid">30202092</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sasaki</surname> <given-names>R</given-names></name><name><surname>Uka</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Dynamic readout of behaviorally relevant signals from area MT during task switching</article-title><source>Neuron</source><volume>62</volume><fpage>147</fpage><lpage>157</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.02.019</pub-id><pub-id pub-id-type="pmid">19376074</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmolesky</surname> <given-names>MT</given-names></name><name><surname>Wang</surname> <given-names>Y</given-names></name><name><surname>Hanes</surname> <given-names>DP</given-names></name><name><surname>Thompson</surname> <given-names>KG</given-names></name><name><surname>Leutgeb</surname> <given-names>S</given-names></name><name><surname>Schall</surname> <given-names>JD</given-names></name><name><surname>Leventhal</surname> <given-names>AG</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Signal timing across the macaque visual system</article-title><source>Journal of Neurophysiology</source><volume>79</volume><fpage>3272</fpage><lpage>3278</lpage><pub-id pub-id-type="doi">10.1152/jn.1998.79.6.3272</pub-id><pub-id pub-id-type="pmid">9636126</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname> <given-names>BB</given-names></name><name><surname>Constantinople</surname> <given-names>CM</given-names></name><name><surname>Akrami</surname> <given-names>A</given-names></name><name><surname>Hanks</surname> <given-names>TD</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Fronto-parietal cortical circuits encode accumulated evidence with a diversity of timescales</article-title><source>Neuron</source><volume>95</volume><fpage>385</fpage><lpage>398</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.013</pub-id><pub-id pub-id-type="pmid">28669543</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname> <given-names>MN</given-names></name><name><surname>Britten</surname> <given-names>KH</given-names></name><name><surname>Newsome</surname> <given-names>WT</given-names></name><name><surname>Movshon</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>A computational analysis of the relationship between neuronal and behavioral responses to visual motion</article-title><source>The Journal of Neuroscience</source><volume>16</volume><fpage>1486</fpage><lpage>1510</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.16-04-01486.1996</pub-id><pub-id pub-id-type="pmid">8778300</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shuler</surname> <given-names>MG</given-names></name><name><surname>Bear</surname> <given-names>MF</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Reward timing in the primary visual cortex</article-title><source>Science</source><volume>311</volume><fpage>1606</fpage><lpage>1609</lpage><pub-id pub-id-type="doi">10.1126/science.1123513</pub-id><pub-id pub-id-type="pmid">16543459</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Snyder</surname> <given-names>AC</given-names></name><name><surname>Yu</surname> <given-names>BM</given-names></name><name><surname>Smith</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Distinct population codes for attention in the absence and presence of visual stimulation</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>4382</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-06754-5</pub-id><pub-id pub-id-type="pmid">30348942</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sobotka</surname> <given-names>S</given-names></name><name><surname>Ringo</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Stimulus specific adaptation in excited but not in inhibited cells in inferotemporal cortex of Macaque</article-title><source>Brain Research</source><volume>646</volume><fpage>95</fpage><lpage>99</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(94)90061-2</pub-id><pub-id pub-id-type="pmid">8055344</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sreenivasan</surname> <given-names>KK</given-names></name><name><surname>Vytlacil</surname> <given-names>J</given-names></name><name><surname>D'Esposito</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Distributed and dynamic storage of working memory stimulus information in extrastriate cortex</article-title><source>Journal of Cognitive Neuroscience</source><volume>26</volume><fpage>1141</fpage><lpage>1153</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00556</pub-id><pub-id pub-id-type="pmid">24392897</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stănişor</surname> <given-names>L</given-names></name><name><surname>van der Togt</surname> <given-names>C</given-names></name><name><surname>Pennartz</surname> <given-names>CM</given-names></name><name><surname>Roelfsema</surname> <given-names>PR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A unified selection signal for attention and reward in primary visual cortex</article-title><source>PNAS</source><volume>110</volume><fpage>9136</fpage><lpage>9141</lpage><pub-id pub-id-type="doi">10.1073/pnas.1300117110</pub-id><pub-id pub-id-type="pmid">23676276</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stavisky</surname> <given-names>SD</given-names></name><name><surname>Kao</surname> <given-names>JC</given-names></name><name><surname>Ryu</surname> <given-names>SI</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Motor cortical visuomotor feedback activity is initially isolated from downstream targets in Output-Null neural state space dimensions</article-title><source>Neuron</source><volume>95</volume><fpage>195</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.05.023</pub-id><pub-id pub-id-type="pmid">28625485</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stone</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="1960">1960</year><article-title>Models for choice-reaction time</article-title><source>Psychometrika</source><volume>25</volume><fpage>251</fpage><lpage>260</lpage><pub-id pub-id-type="doi">10.1007/BF02289729</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanke</surname> <given-names>N</given-names></name><name><surname>Borst</surname> <given-names>JGG</given-names></name><name><surname>Houweling</surname> <given-names>AR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Single-Cell stimulation in barrel cortex influences psychophysical detection performance</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>2057</fpage><lpage>2068</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2155-17.2018</pub-id><pub-id pub-id-type="pmid">29358364</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Treue</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><source>Object- and Feature-Based Attention</source><publisher-name>Oxford Handbooks</publisher-name><pub-id pub-id-type="doi">10.1093/oxfordhb/9780199675111.013.008</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ulanovsky</surname> <given-names>N</given-names></name><name><surname>Las</surname> <given-names>L</given-names></name><name><surname>Nelken</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Processing of low-probability sounds by cortical neurons</article-title><source>Nature Neuroscience</source><volume>6</volume><fpage>391</fpage><lpage>398</lpage><pub-id pub-id-type="doi">10.1038/nn1032</pub-id><pub-id pub-id-type="pmid">12652303</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinken</surname> <given-names>K</given-names></name><name><surname>Vogels</surname> <given-names>R</given-names></name><name><surname>Op de Beeck</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Recent visual experience shapes visual processing in rats through Stimulus-Specific adaptation and response enhancement</article-title><source>Current Biology</source><volume>27</volume><fpage>914</fpage><lpage>919</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.02.024</pub-id><pub-id pub-id-type="pmid">28262485</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Volinsky</surname> <given-names>CT</given-names></name><name><surname>Raftery</surname> <given-names>AE</given-names></name><name><surname>Madigan</surname> <given-names>D</given-names></name><name><surname>Hoeting</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>David Draper and E. I. George, and a rejoinder by the authors</article-title><source>Statistical Science</source><volume>14</volume><fpage>382</fpage><lpage>417</lpage><pub-id pub-id-type="doi">10.1214/ss/1009212519</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wimmer</surname> <given-names>K</given-names></name><name><surname>Compte</surname> <given-names>A</given-names></name><name><surname>Roxin</surname> <given-names>A</given-names></name><name><surname>Peixoto</surname> <given-names>D</given-names></name><name><surname>Renart</surname> <given-names>A</given-names></name><name><surname>de la Rocha</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Sensory integration dynamics in a hierarchical network explains choice probabilities in cortical area MT</article-title><source>Nature Communications</source><volume>6</volume><elocation-id>6177</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms7177</pub-id><pub-id pub-id-type="pmid">25649611</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wright</surname> <given-names>SJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Coordinate descent algorithms</article-title><source>Mathematical Programming</source><volume>151</volume><fpage>3</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.1007/s10107-015-0892-3</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname> <given-names>H</given-names></name><name><surname>Kwon</surname> <given-names>SE</given-names></name><name><surname>Severson</surname> <given-names>KS</given-names></name><name><surname>O'Connor</surname> <given-names>DH</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Origins of choice-related activity in mouse somatosensory cortex</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>127</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1038/nn.4183</pub-id><pub-id pub-id-type="pmid">26642088</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zaidel</surname> <given-names>A</given-names></name><name><surname>DeAngelis</surname> <given-names>GC</given-names></name><name><surname>Angelaki</surname> <given-names>DE</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Decoupled choice-driven and stimulus-related activity in parietal neurons may be misrepresented by choice probabilities</article-title><source>Nature Communications</source><volume>8</volume><elocation-id>715</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-017-00766-3</pub-id><pub-id pub-id-type="pmid">28959018</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zariwala</surname> <given-names>HA</given-names></name><name><surname>Kepecs</surname> <given-names>A</given-names></name><name><surname>Uchida</surname> <given-names>N</given-names></name><name><surname>Hirokawa</surname> <given-names>J</given-names></name><name><surname>Mainen</surname> <given-names>ZF</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The limits of deliberation in a perceptual decision task</article-title><source>Neuron</source><volume>78</volume><fpage>339</fpage><lpage>351</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.02.010</pub-id><pub-id pub-id-type="pmid">23541901</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname> <given-names>S</given-names></name><name><surname>Xu</surname> <given-names>M</given-names></name><name><surname>Kamigaki</surname> <given-names>T</given-names></name><name><surname>Hoang Do</surname> <given-names>JP</given-names></name><name><surname>Chang</surname> <given-names>WC</given-names></name><name><surname>Jenvay</surname> <given-names>S</given-names></name><name><surname>Miyamichi</surname> <given-names>K</given-names></name><name><surname>Luo</surname> <given-names>L</given-names></name><name><surname>Dan</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Selective attention. Long-range and local circuits for top-down modulation of visual cortex processing</article-title><source>Science</source><volume>345</volume><fpage>660</fpage><lpage>665</lpage><pub-id pub-id-type="doi">10.1126/science.1254126</pub-id><pub-id pub-id-type="pmid">25104383</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname> <given-names>Y</given-names></name><name><surname>Yates</surname> <given-names>JL</given-names></name><name><surname>Levi</surname> <given-names>AJ</given-names></name><name><surname>Huk</surname> <given-names>AC</given-names></name><name><surname>Park</surname> <given-names>IM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Stimulus-choice (mis)alignment in primate area MT</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1007614</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007614</pub-id></element-citation></ref><ref id="bib119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhuang</surname> <given-names>J</given-names></name><name><surname>Ng</surname> <given-names>L</given-names></name><name><surname>Williams</surname> <given-names>D</given-names></name><name><surname>Valley</surname> <given-names>M</given-names></name><name><surname>Li</surname> <given-names>Y</given-names></name><name><surname>Garrett</surname> <given-names>M</given-names></name><name><surname>Waters</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>An extended retinotopic map of mouse cortex</article-title><source>eLife</source><volume>6</volume><elocation-id>e18372</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.18372</pub-id><pub-id pub-id-type="pmid">28059700</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.60628.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Salinas</surname><given-names>Emilio</given-names></name><role>Reviewing Editor</role><aff><institution>Wake Forest School of Medicine</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>This study investigates how sensory representations in visual cortex are modulated by ongoing task requirements as rats navigate a virtual environment and make a choice based on the total numbers of discrete stimuli, or 'pulses,' seen along the path. The main finding is that only a small fraction of active neurons had sensory-like responses time-locked to each pulse, and furthermore, for those that did, the amplitude of the response changed systematically as the impending choice advanced to completion. This shows that, even at a very basic level, the representation of sensory stimuli is strongly modulated and shaped by cognitive factors and behavioral relevance, and that a lot of the variability associated with sensory activity is not just random noise, as it often appears.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Amplitude modulations of sensory responses, and deviations from Weber's Law in pulsatile evidence accumulation&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Michael Frank as the Senior Editor. The reviewers have opted to remain anonymous.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>We would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). Specifically, when editors judge that a submitted work as a whole belongs in <italic>eLife</italic> but that some conclusions require additional new data or analyses, as they do with your paper, we are asking that the manuscript be revised to either limit claims to those supported by data in hand, or to explicitly state that the relevant conclusions require additional supporting data.</p><p>Our expectation is that the authors will eventually carry out the additional work and report on how it affects the relevant conclusions either in a preprint on bioRxiv or medRxiv, or if appropriate, as a Research Advance in <italic>eLife</italic>, either of which would be linked to the original paper.</p><p>Summary:</p><p>This manuscript carefully studies the properties of sensory responses in several visual areas during performance of a task in which head-fixed mice run along a virtual corridor and must turn toward the side that has more visual cues (small towers) along the wall. The results provide insight into the mechanisms whereby sensory evidence is accumulated and weighted to generate a choice, and on the sources of variability that limit the observed behavioral performance. All reviewers thought the work was generally interesting, carefully done, and novel.</p><p>However, the reviewers' impression was that the manuscript as it stands is very dense. In fact, it is largely two studies with different methods and approaches rolled into one. The first one (physiology) is still dense but less speculative and with interesting, solid results, and the revisions suggested by the reviewers should be relatively straightforward to address. In contrast, the modeling effort is no doubt connected to the physiology, but it really addresses a separate issue. The general feeling was that this material is probably better suited for a separate, subsequent article, for two reasons. First, because it will require substantial further work (see details below), and second, because it adds a fairly complex chapter to an already intricate analysis of the neurophysiological data.</p><p>So, going forward, we suggest that the authors revise the neurophys analyses along the lines suggested below (largely addressing clarity and completeness), leaving out the modeling study for a later report. If, however, the authors wish to maintain the current structure, they should address all the comments, and understand that we would reconsider the manuscript's suitability for publication after full re-review.</p><p>Revisions for this paper:</p><p>1) More should be done to highlight how very different the sensory representation is in this study compared with the great majority of earlier related work in the primate. This merits at least some discussion, and optimally, additional analyses of correlations in the data. See the comments from reviewer 3 for details.</p><p>2) Figure 4E was confusing. What is the point of showing the shades (which extend very far)? If the idea is to contrast the SSA and feedback models, then it would be better to plot their corresponding effects directly, on the same graph, or to show predictions versus actual data in each case, in two graphs. In any case, the data need to be shown in a different way, or the point made differently.</p><p>Similarly for Figure 3F. Could the authors explain how each point is calculated? I was specially confused about the meaning of the points <italic>for each area</italic> in the x-axis.</p><p>3) The prediction about the Fano Factor (FF) is problematic in a couple of ways. First, it seems to come out of the blue because Figure 5 is described before any discussion of the variability in the model is presented (except for the dice in the model schematic).</p><p>And second, the FF prediction itself is verified for a very small fraction of neurons even when an unusual pValue of 0.1 is used. Furthermore, the mathematical derivation relies on an Taylor series around <italic>N<sub>R</sub></italic> ~ 0? (In most of the paper, CLT is invoked on the assumption <italic>N<sub>R</sub></italic> is &quot;large&quot;). Due to the lack of transparency of this prediction and the mild support, the authors could consider dropping it, at least from the main manuscript.</p><p>4). The 1st prediction in Figure 5 seems very unspecific. In particular, it would seem like any &quot;open loop&quot; modulation of the cue-locked response which depended on time, or on location along the track, would induce a trend like the one assessed in Figure 5C-E. It is not clear this is a prediction specific to the multiplicative-feedback model the authors are advocating for.</p><p>5) The number of cells showing responses consistent with the model (Figure 5E) seems very small (~15% of 5-10% of cells with cue-locked responses). Could they really underlie the behavioral effects? The authors could perhaps comment on this.</p><p>6) It wasn't completely clear how the time of a particular cue onset was defined. In a real environment the cues would appear small (from afar) and get progressively bigger as the animal advances (at least if they are 3D objects, as depicted in Figure 1). What would be the cue onset in that case, and does the virtual environment work in the same way? This is probably not a serious issue, but it comes across as a bit at odds with the supposed &quot;pulsatile&quot; nature of the sensory stream, and would seem somewhat different from the auditory case with clicks.</p><p>A related question concerns multiple references to cue timing made in the Introduction, as if such timing were very precise. This seems strange given that all time points depend on the running speed of the mice, which is surely variable. So, how exactly is cue position converted to cue time, and why is there an assumption of very low variability? Some of this detail may be in previous reports, but it would be important to make at least a brief, explicit clarification early on.</p><p>Revisions expected in follow-up work:</p><p>For details, see comments 1-3 from reviewer 2 and comment 1 from reviewer 1, below.</p><p><italic>Reviewer #1:</italic></p><p>This study investigates the responses of neurons in the parietal cortex of mice (recorded via two-photon Ca imaging) performing a virtual navigation task, and then relates their activity to the animal's psychophysical performance. It is essentially two studies rolled into one. The analysis of neurophysiological activity in the first part shows that visually driven responses in the recorded &quot;cue cells&quot; are strongly modulated by the eventual choice and/or by the integrated quantity that defines that choice (the difference in left vs. right stimulus counts), as well as by other task variables, such as running speed. The model comparison study of the second part shows that, in the context of a sensory-motor circuit for performing the task, this type of feedback may account for subtle but robust psychophysical effects observed in the mice from this study and in rats from previous studies from the lab. Notably, the feedback explains intriguing deviations in choice accuracy from the Weber-Fechner law.</p><p>Both parts are interesting and carefully executed, although both are pretty dense; there are a ton of important technical details at each step. I wonder if this isn't too much for a single study. Had I not been reading it as a reviewer, I probably would have stopped after Figure 4 or just skimmed the rest. After that, the motivation, methods, and analyses shift markedly. I'm not pushing hard on this issue, but I think the authors should ponder it.</p><p>Other comments:</p><p>1) Figure 6 and the accompanying section of the manuscript investigate a variety of models with different architectures (feedback vs. purely feedforward) and noise sources. Here, if I understood correctly, the actual cue-driven responses are substituted with variables that are affected by different types of noise. It is this part that I found a bit disconnected from the rest, and somewhat confusing.</p><p>Here, there's a jump from the actual cells to model responses. I think this needs an earlier and more explicit introduction. It is clear what the objective of the modeling effort is; what's unclear are the elements that initially go into it. This is partly because the section jumps off with a discussion about accumulator noise, but the modeling involves many more assumptions (i.e., simplifications about the inputs to the accumulators).</p><p>What I wondered here was, what happened to all the variance that was carefully peeled away from the cue driven responses in the earlier part of the manuscript? Were the dependencies on running speed, viewing angle, contra versus ipsi sensitivity, etc still in play, or were the modeled cue-driven responses considering just the sensory noise from the impulse responses? I apologize if I missed this. I guess the broader question is how exactly the noise sources in the model relate to all the dependencies of the cue cells exposed in the earlier analyses.</p><p>Overall, my general impression is that this section requires more unpacking; perhaps it should become an independent report.</p><p><italic>Reviewer #2:</italic></p><p>In this manuscript, the authors present an in-depth analysis of the properties of sensory responses in several visual areas during performance of an evidence-accumulation task for head-fixed running mice (developed and studied by the authors previously), and of how these properties can illuminate aspects of the performance of mice and rats during pulsatile evidence accumulation, with a focus on the effect of &quot;overall stimulus strength&quot; on discriminability (Weber-Fechner scaling).</p><p>The manuscript is very dense and presents many findings, but the most salient ones are a description of how the variability in the large Ca++ transients evoked by the behaviourally-relevant visual stimuli (towers) are related to several low-level behavioural variables (speed, view) and also variables relevant for the task (future choice, running count of accumulated evidence), and a framework based on multiplicative-top down feedback that seeks to explain some aspects of this variability and ultimately the psychophysical performance in the accumulating-towers task. The first topic is framed in the context of the literature on choice-probability, and the second in the context of &quot;Weber-Fechner&quot; scaling, which in the current task would imply constant performance for given ratios of Left/Right counts as their total number is varied.</p><p>Overall, the demonstration of how trial to trial variability is informative about various relevant variables is important and convincing, and the model with multiplicative feedback is elegant, novel, naturally motivated by the neural data, and an interesting addition to a topic with a long-history.</p><p>1) Non-integrable variability. In addition to 'sensory noise' (independent variability in the magnitude of each pulse), it is critical in the model to include a source of variability whose impact does not decay through temporal averaging (to recover Weber-Fechner asymptotically for large N). This is achieved in the model by positing trial-to-trial variability (but not within-trial) in the dot product of the feedforward (w) and feedback (u) directions. But the way this is done seems to me problematic:</p><p>The authors model variability in w*u as LogNormal (subsection “Sources of noise in various accumulator architectures”). First, the justification for this choice is incorrect as far as I can tell. The authors write: &quot;We model <inline-formula><mml:math id="inf174"><mml:msub><mml:mover><mml:mi>m</mml:mi><mml:mo accent="true">̂</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub></mml:math></inline-formula> with a lognormal distribution, which is the limiting case of a product of many positive random variables&quot;. But neither is the dot product of w and u a product (it's a sum of many products), nor are the elements of this sum positive variables (the vector u has near zero mean and both positive and <italic>negative</italic> elements allowing different neurons to have opposite preferences on choice – see e.g., in the subsection “Cue-locked amplitude modulations motivate a multiplicative feedback-loop circuit model” where it is stated that <italic>u<sub>i</sub></italic>&lt;0 for some cells), nor would it have a LogNormal distribution even if the elements of the sum were indeed positive. Without further assumptions, the dot product w*u will have a normal distribution with mean and variance dependent on the (chosen) statistics of u and w.Two conditions seem to be necessary for u*w: it should have a mean positive but close to zero (if it's too large a(t) will explode), and it should have enough variability to make non-integrable noise have an impact in practice. For a normal distribution, this would imply that for approximately half of the trials, w*u would need to be negative, meaning a decaying accumulator and effectively no feedback. This does not seem like a sensible strategy that the brain would use.</p><p>The authors should clarify how this LogNormality is justified and whether it is a critical modelling choice (as an aside, although LogNormality in u*w allows non-negativity, low mean and large variability, the fact that it has very long tails sometimes leads to instability in the values of a(t)).</p><p>2) Related to this point, it would be helpful to have more clarity on exactly what is being assumed about the feedback vector u. The neural data suggests u has close to zero mean (across neurons). At the same time, it is posited that u varies across trials (&quot;accumulator feedback is noisy&quot;) is and that this variability is significant and important (previous comment). However, it would seem like neurons keep their choice preference across trials, meaning the trial to trial variability in each element of u has to be smaller than the mean. The authors only describe variability in u*w (LogNormal), but, in addition to the issues just mentioned about this choice, what implications does this have for the variability in u? The logic of the approach would greatly increase if the authors made assumptions about the statistics of u consistent with the neural data, and then derived the statistics of u*w.</p><p>3) Overall, it seems like there is an intrinsically hard problem to be solved here, which is not acknowledged: how to obtain large variability in the effective gain of a feedback loop while at the same time keeping the gain &quot;sufficiently restricted&quot;, i.e., neither too large and positive (runaway excitation) nor negative (counts are forgotten). While the authors avoid worrying about model parameters by fitting their values from data (with the caveats discussed above), their case would become much stronger if they studied the phenomenology of the model itself, exposing clearly the computational challenges faced and whether robust solutions to these problems exist.</p><p><italic>Reviewer #3:</italic></p><p>This manuscript describes measurements of neuronal activity in mice performing a discrimination task, and a new model that links these data to psychophysical performance. The key element of the new model is that sensory neurons are subject to gain modulations that evolve during each trial. They show that the model can produce pure sensory integration, Weber-Fechner performance, or intermediate states that nicely replicate the behavioral observations. This is an interesting and valuable contribution.</p><p>My only significant comment relates to the Discussion, which should do more to make sure the reader understands how very different the sensory representation is in this study compared with the great majority of earlier related work in the primate:</p><p>First, choice related signals are not systematically related to stimulus preferences (no Choice Probability). This is mentioned, but only very briefly.</p><p>Second, there appears to be no relationship between stimulus preference (visual field in this case) and noise correlation. Unfortunately, this emerges from the model fits, not an analysis of data. But is an important difference with profound implications for how the coding of information is organized. It really needs a discussion. It should also be supported by an analysis of correlations in the data. I know some people argue that 2 photon measures make this difficult, but if that's true then surely they can’t be used to support a model in which correlations are a key component.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.60628.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Revisions for this paper:</p></disp-quote><p>To our understanding, items 3-5 listed in this section of the decision letter are only relevant for the accumulator modeling work, and we have therefore moved them to the next section.</p><disp-quote content-type="editor-comment"><p>1) More should be done to highlight how very different the sensory representation is in this study compared with the great majority of earlier related work in the primate. This merits at least some discussion, and optimally, additional analyses of correlations in the data. See the comments from reviewer 3 for details.</p></disp-quote><p>We have replaced the last half of the Discussion, which used to be about the accumulator circuit models, with an extended discussion of how the neural responses to visual cues in our task relate to and differ from previous work on nonhuman primates (NHP) and rodents. Most of this discussion concerns points brought up by reviewer 3 (please see the specific reply to reviewer 3 below for details). In particular, we discuss how the subject’s eventual choice modifies sensory representations, which we illustrate in an added conceptual Figure 5. The last Discussion paragraph provides a more general comparison between our work vs. other rodent work and the NHP literature. With respect to reviewer 3’s request for analyses of correlations in the data, we have refrained from doing so because we do not think that we can make correct claims about noise correlations in our data. The reason is the nature of the behavior which could not have truly repeated trials. Please see the reply to reviewer 3 for details.</p><disp-quote content-type="editor-comment"><p>2) Figure 4E was confusing. What is the point of showing the shades (which extend very far)? If the idea is to contrast the SSA and feedback models, then it would be better to plot their corresponding effects directly, on the same graph, or to show predictions versus actual data in each case, in two graphs. In any case, the data need to be shown in a different way, or the point made differently.</p></disp-quote><p>We have replaced Figure 4E in the revised manuscript to provide a direct comparison of the neural vs. behavioral timecourses. We wanted the timecourse of neural choice modulations in Figure 4E to be compared to the timecourse of how cues influenced the behavioral performance data in Figure 1E. Perhaps because these panels were separated by many figures, it is not obvious what the reader should take away by the time they come to Figure 4E.</p><disp-quote content-type="editor-comment"><p>Similarly for Figure 3F. Could the authors explain how each point is calculated? I was specially confused about the meaning of the points for each area in the x-axis.</p></disp-quote><p>We have added a more detailed explanation of the computation of Figure 3F to both the text and the caption, as follows. The goal of Figure 3F is to address the visible differences across brain areas, in Figure 3B, D, in how well various task variables could be decoded from the amplitudes of a population of cue-locked cells. We wanted to know if these differences were indeed region-specific differences or whether they could be explained by differences in the number of recorded neurons (which differed systematically across cortical areas/layers). To do this we constructed a linear regression model to predict the decoding performance (evaluated in the middle of the cue region for each dataset) as a weighted sum of a set of factors being the x-axis coordinates in Figure 3F. The cortical area and layer regressors had values of either 0 or 1 depending on whether the dataset was for the stated area and layer, e.g. a recording from layer 5 of V1 would have regressor values (V1=1, AM=0, PM=0, MMA=0, MMP=0, RSC=0, layer=1). This explanation is now in the text as the last paragraph of the subsection “Cue-locked response amplitudes contain information about visual, motor, cognitive, and memory-related contextual task variables”.</p><disp-quote content-type="editor-comment"><p>6) It wasn't completely clear how the time of a particular cue onset was defined. In a real environment the cues would appear small (from afar) and get progressively bigger as the animal advances (at least if they are 3D objects, as depicted in Figure 1). What would be the cue onset in that case, and does the virtual environment work in the same way? This is probably not a serious issue, but it comes across as a bit at odds with the supposed &quot;pulsatile&quot; nature of the sensory stream, and would seem somewhat different from the auditory case with clicks.</p></disp-quote><p>We indeed neglected to provide this information while introducing the task, and have added this now as a third paragraph in the Results, as well as details on the following points in the Materials and methods. In summary, the “cue onset” is defined as the instant at which the cue is made visible in the virtual reality display, which is when the mouse approaches within 10cm of a predetermined cue location.</p><disp-quote content-type="editor-comment"><p>A related question concerns multiple references to cue timing made in the Introduction, as if such timing were very precise. This seems strange given that all time points depend on the running speed of the mice, which is surely variable. So, how exactly is cue position converted to cue time, and why is there an assumption of very low variability? Some of this detail may be in previous reports, but it would be important to make at least a brief, explicit clarification early on.</p></disp-quote><p>We have precise experimental control over the onset time of cues as we now explain in the Materials and methods (“Precision of behavioral cue timings”), and the cues were made to disappear from view in 200ms. However, there is some variability in how long any one cue will remain in the visual field of the mouse, which as the reviewer correctly noted, depends on how it runs down the maze. This variability is small except for one mouse that had a much higher running speed than other mice, and we have added Figure 1—figure supplement 1 to quantify these behavior-induced variations. Regardless, for the above reasons as well as complications due to neurons having limited receptive fields, we had included in the cue-locked response model small timing jitter parameters that allowed the model to flexibly account for some timing uncertainty in neural responses with regards to the assumed cue onset times. Insofar as we can think of, only the cue-locked response model depends on knowing the precise timings of cues, and the distribution of jitter parameters across the model fits for cue-locked neurons had a standard deviation of about 50ms, which is ballpark what we expected.</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>This manuscript describes measurements of neuronal activity in mice performing a discrimination task, and a new model that links these data to psychophysical performance. The key element of the new model is that sensory neurons are subject to gain modulations that evolve during each trial. They show that the model can produce pure sensory integration, Weber-Fechner performance, or intermediate states that nicely replicate the behavioral observations. This is an interesting and valuable contribution.</p><p>My only significant comment relates to the Discussion, which should do more to make sure the reader understands how very different the sensory representation is in this study compared with the great majority of earlier related work in the primate:</p></disp-quote><p>We have added a last paragraph to the Discussion regarding some overall points where we believe our findings could be surprising compared to the primate work: (a) the small fractions of cue-locked neural activity even in V1; (b) choice modulations that are not lateralized by brain hemisphere; (c) the prevalence of many types of cue-locked amplitude modulations.</p><disp-quote content-type="editor-comment"><p>First, choice related signals are not systematically related to stimulus preferences (no Choice Probability). This is mentioned, but only very briefly.</p></disp-quote><p>To the best of our knowledge of the primate literature, choice probability (CP) values that correspond to higher firing rates in trials where the subject will make a choice <italic>opposite</italic>​​ to the stimulus preference (CP &lt; 0.5) could also have been detected as significant, albeit we have not been able to find reports of this other than in the recent re-analysis of monkey data by Zhao et al., 2020). If we guess correctly that CP &lt; 0.5 is what the reviewer meant by “choice related signals [that] are not systematically related to stimulus preferences”, then we referred to such phenomena in the Discussion as cue-locked cells that have negative choice modulations as opposed to “no CP” (since these choice modulations were consistent across trials). In other words, rather than individual cue-locked cells having no CP, we observed that a substantial fraction of them had highly significant CP. Where our results differ from the primate work is in the statistics across the population of cue-locked cells, which had comparable fractions with positive (CP &gt; 0.5) and negative (CP &lt; 0.5) choice modulations, as opposed to the primate work where mostly CP &gt; 0.5 results have been reported. We have added a conceptual Figure 5 as well as expanded upon these differences between our and previous work in the second-to-last paragraph of the Discussion. However it is possible that we have misunderstood the reviewer’s comment, in which case we ask for some more clarification.</p><disp-quote content-type="editor-comment"><p>Second, there appears to be no relationship between stimulus preference (visual field in this case) and noise correlation. Unfortunately, this emerges from the model fits, not an analysis of data. But is an important difference with profound implications for how the coding of information is organized. It really needs a discussion. It should also be supported by an analysis of correlations in the data. I know some people argue that 2 photon measures make this difficult, but if that's true then surely they can’t be used to support a model in which correlations are a key component.</p></disp-quote><p>We hope that we have not erroneously claimed any results about noise correlations in the paper, and would like to know where this was implied so that we can be more careful about the wording. We had in the past wished to perform direct analyses of noise correlations, but then realized that this was extremely difficult because our behavioral task has no exactly repeated trials that we could use to remove the effect of signal correlations. In particular, we did have in the task design multiple trials per session with exactly the same spatial configuration of cues, but unfortunately since the mice could run down the T-maze in different ways in each trial, we fear that differences in running speed, view angle etc. could result in signal-induced variability across these trials. Insofar as we can think of, we could try to subtract signal variance using a computational model, but then of course any results we obtain for noise correlations would be contingent on how well the model captures signal effects at a timepoint-by-timepoint level. We therefore feel that the soundness of any claims that we could try to make on noise correlations would be under question.</p><disp-quote content-type="editor-comment"><p>Revisions expected in follow-up work:</p><p>For details, see comments 1-3 from reviewer 2 and comment 1 from reviewer 1.</p><p>3) The prediction about the Fano Factor (FF) is problematic in a couple of ways. First, it seems to come out of the blue because Figure 5 is described before any discussion of the variability in the model is presented (except for the dice in the model schematic).</p><p>And second, the FF prediction itself is verified for a very small fraction of neurons even when an unusual pValue of 0.1 is used. Furthermore, the mathematical derivation relies on an Taylor series around N<sub>R</sub> ~ 0? (In most of the paper, CLT is invoked on the assumption N<sub>R</sub> is &quot;large&quot;). Due to the lack of transparency of this prediction and the mild support, the authors could consider dropping it, at least from the main manuscript.</p></disp-quote><p>The FF measurement was indeed very difficult to perform because of insufficient statistics (that’s why we used a pValue threshold of 0.1 for testing effect sizes). This result is more of a consistency check in the sense that we didn’t observe a phenomenon that <italic>contradicted</italic>​ predictions of the theoretical model, but as noted neither do we have strong statistical support for predictions of the model. We will move the FF analysis to the supplement and word the text to indicate the difficulty of this measurement.</p><disp-quote content-type="editor-comment"><p>4) The first prediction in Figure 5 seems very unspecific. In particular, it would seem like any &quot;open loop&quot; modulation of the cue-locked response which depended on time, or on location along the track, would induce a trend like the one assessed in Figure 5C-E. It is not clear this is a prediction specific to the multiplicative-feedback model the authors are advocating for.</p></disp-quote><p>The reviewer is correct that it is always possible to write down models with ad hoc time- or location-dependent scaling of cue-locked responses (in fact, we included ad hoc location-dependent scaling in all models for the mouse data). However, what we wished to do with the feedback-loop model was to propose a neural circuit origin for the observed amplitude scaling trends, and also the specific prediction is that the cue-response amplitudes should depend on the accumulated number of cues, not time or location. We will explain more clearly in the text that this is one of the reasons why the Figure 5C-E trends were made using only neural responses to the last cue in a trial and only including trials where that occurred in the last third of the cue region, so that the spatial location of the cue along the track is kept as similar as possible. We should also add a supplementary figure where the time at which the last cue occurs (which is highly correlated with its location along the track given the stereotypical running patterns of mice) is similarly restricted.</p><disp-quote content-type="editor-comment"><p>5) The number of cells showing responses consistent with the model (Figure 5E) seems very small (~15% of 5-10% of cells with cue-locked responses). Could they really underlie the behavioral effects? The authors could perhaps comment on this.</p></disp-quote><p>We agree with the reviewer that these are important points to discuss in the upcoming paper. Regarding the small fraction of active cells with cue-locked responses, it is indeed intriguing that only a small fraction of neural activity even in V1 were cue-locked, but since each of our recordings only includes a very small piece of brain tissue, and 98% of recordings had at least 1 cue-locked cell (despite us having selected imaging locations agnostic to any neural analyses), the total amount of signal in the cortex can be large. Our finding of cue-locked cells in many posterior cortical regions as well as both layers 2/3 and 5 also implies that somehow the wiring of the brain allows for this small fraction of sensory-like information to be transmitted in a widespread manner (e.g. found in the retrosplenial cortex), and we might perhaps speculate that this need not have been the case for neural signals that are too weak to drive behavior.</p><p>On the small fraction of evidence-modulated cue-locked cells, we should discuss the statistical power of our analysis as well as neural circuit considerations brought up by reviewer 2’s main comments 2 and 3.</p><p>Our fitting of accumulator models to behavioral data favored the multiplicative feedback-loop (<italic>fdbk</italic>​​) model where the feedback-loop gain u*w has mean close to zero in the <italic>fdbk</italic>​​ model fits. This behavioral prediction is compatible with the amplitude-vs.-cue-counts slopes of cue-locked cells (dA/dN) having a distribution with more cells having slopes closer to zero (albeit this is not necessary to generate small u*w). Given limited, noisy data we can only have the statistical power to find as significant those slopes that have large magnitudes, which can be why we only found 18% of cells with significant slopes. We should also note that this analysis was performed separately using trials of a fixed choice, i.e. testing for a dependence on cue-counts beyond that which can be accounted for by choice. However, noisy cells that receive weak accumulator feedback can more easily pass statistical tests for being modulated by choice (assuming that the accumulator drives and is therefore correlated with choice), than having count modulation beyond that explainable by choice. In these ways, we believe that our neural observations are consistent with, albeit not a necessary implication of, the behavioral model fits.</p><p>We also note that small (dA/dN) does not necessarily correspond to a small neural signal. Because (dA/dN) is a change in cue-response amplitudes per accumulated cue, if we consider the net change after accumulating ~ 8 cues (the average number of majority-side cues in the behavioral task), the responses of count-modulated cue-locked cells can increase/decrease in amplitudes by about × 2 compared to their responses to the first cue. As further discussed in the reply to reviewer 2, a feedback-loop neural circuit with very large magnitudes of dA/dN can have runaway excitation or complete suppression of cue responses after accumulating many cues. It is therefore our thinking that small dA/dN are more physiologically reasonable, and at least according to our accumulator circuit modeling results, can have a behavioral effect.</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>[…] 1) Figure 6 and the accompanying section of the manuscript investigate a variety of models with different architectures (feedback vs. purely feedforward) and noise sources. Here, if I understood correctly, the actual cue-driven responses are substituted with variables that are affected by different types of noise. It is this part that I found a bit disconnected from the rest, and somewhat confusing.</p><p>Here, there's a jump from the actual cells to model responses. I think this needs an earlier and more explicit introduction. It is clear what the objective of the modeling effort is; what's unclear are the elements that initially go into it. This is partly because the section jumps off with a discussion about accumulator noise, but the modeling involves many more assumptions (i.e., simplifications about the inputs to the accumulators).</p><p>What I wondered here was, what happened to all the variance that was carefully peeled away from the cue driven responses in the earlier part of the manuscript? Were the dependencies on running speed, viewing angle, contra versus ipsi sensitivity, etc still in play, or were the modeled cue-driven responses considering just the sensory noise from the impulse responses? I apologize if I missed this. I guess the broader question is how exactly the noise sources in the model relate to all the dependencies of the cue cells exposed in the earlier analyses.</p><p>Overall, my general impression is that this section requires more unpacking; perhaps it should become an independent report.</p></disp-quote><p>We think that the suggested splitting off of the accumulator modeling work to a second paper is an excellent way to more cleanly separate the more complicated neurophysiological findings from the simplifications that we made in the accumulator modeling work for reasons of conceptual clarity. The modeling paper can therefore start out with an explicit list of assumptions made, as follows.</p><p>There were three major simplifications made in going from the experimentally observed cue-locked neural responses to the computational accumulator model. First, we assumed that the sensory units in the computational accumulator models only responded to one laterality of cues, because in the neural data there was only &lt;​ 5​ % of cells that responded to both lateralities, and even for these 5% of cells the responses still had a strong cue laterality preference. Second, while the cue-locked neurons had impulse responses of duration ~ 100ms to the pulsatile visual cues, in the computational model we simplified the sensory inputs to the accumulators to have instantaneous responses to the visual cues. The motivation for this was to make the model analytically solvable, which then allowed us to mathematically understand its phenomenology. Third, we did not separately model the other sources of cue-locked response variabilities mentioned by the reviewer, but this is because they act as behavioral sources of sensory and/or accumulator-level noise, and were thus conceptually lumped into the two (sensory and accumulator) noise sources in the models. For example, variability that is due to the mouse viewing different cues at different running speeds can be thought of as adding a different random number to a sensory unit’s response to each cue, i.e. exactly what we defined as the per-pulse sensory noise in the model. In general, sources of noise that are fast (changing from cue to cue) and have no systematic relationship to the running tally of cue counts or choice would all contribute some part of the models’ sensory noise variance. Other sources of noise that are slow (changing from trial to trial, e.g. variability that is correlated to the mouse’s eventual choice) would contribute to the models’ accumulator noise variance because they affect every cue response within the trial in the same way and therefore are accumulated in the same way as the cue responses.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>[…] 1) Non-integrable variability. In addition to 'sensory noise' (independent variability in the magnitude of each pulse), it is critical in the model to include a source of variability whose impact does not decay through temporal averaging (to recover Weber-Fechner asymptotically for large N). This is achieved in the model by positing trial-to-trial variability (but not within-trial) in the dot product of the feedforward (w) and feedback (u) directions. But the way this is done seems to me problematic:</p><p>The authors model variability in w*u as LogNormal (subsection “Sources of noise in various accumulator architectures”). First, the justification for this choice is incorrect as far as I can tell. The authors write: &quot;We model <inline-formula><mml:math id="inf175"><mml:mrow><mml:mspace width="0.222em"/><mml:msub><mml:mover><mml:mi>m</mml:mi><mml:mo accent="true">̂</mml:mo></mml:mover><mml:mi>R</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> with a lognormal distribution, which is the limiting case of a product of many positive random variables&quot;. But neither is the dot product of w and u a product (it's a sum of many products), nor are the elements of this sum positive variables (the vector u has near zero mean and both positive and negative elements allowing different neurons to have opposite preferences on choice – see e.g., in the subsection “Cue-locked amplitude modulations motivate a multiplicative feedback-loop circuit model” where it is stated that u<sub>i</sub>&lt;0 for some cells), nor would it have a LogNormal distribution even if the elements of the sum were indeed positive. Without further assumptions, the dot product w*u will have a normal distribution with mean and variance dependent on the (chosen) statistics of u and w.Two conditions seem to be necessary for u*w: it should have a mean positive but close to zero (if it's too large a(t) will explode), and it should have enough variability to make non-integrable noise have an impact in practice. For a normal distribution, this would imply that for approximately half of the trials, w*u would need to be negative, meaning a decaying accumulator and effectively no feedback. This does not seem like a sensible strategy that the brain would use.</p><p>The authors should clarify how this LogNormality is justified and whether it is a critical modelling choice (as an aside, although LogNormality in u*w allows non-negativity, low mean and large variability, the fact that it has very long tails sometimes leads to instability in the values of a(t)).</p></disp-quote><p>We agree with the reviewer that the description of the lognormal distribution for u*w is confusing. Specifically, we wrote “limiting case of a product of many positive random variables” only as a statement about the lognormal distribution, and did not think to explain why we made that modeling choice. Upon hindsight, this way of writing it was unintentionally misleading. The justification that we had in mind when designing the model was related to what the reviewer mentioned: if the distribution of u*w can have both negative and positive tails, either the variance of this distribution must be very small relative to its (positive) mean, or else there will be a substantial fraction of trials in which there is negative accumulator feedback modulating the sensory unit responses. However, as reasoned by the reviewer, our assumption of strictly positive u*w was not very natural and would seem to require some kind of careful rectification by neural circuits, for which we have no proposed mechanism.</p><p>To address this and the other related comments below, we have extended our work to include a more thorough exploration of noise distribution modeling options, specifically the choices of (1) the sensory response distribution, which we had previously assumed to be gaussian; and (2) the feedback/modulatory noise distribution. As a reminder, the feedforward accumulator models had an accumulator state equal to n*m, where <italic>n</italic> is a stochastic sensory response drawn from (1) and which depends on the true stimulus counts N, whereas m is a per-trial modulatory noise drawn from (2). The feedback accumulator state is instead proportional to [exp(n m) – 1]/m, with <italic>n</italic> as for the feedforward models and m = u*w now interpreted as a feedback-related source of noise. We sketch our results so far below.</p><p>Our previous choice of <italic>n</italic> drawn from a gaussian distribution with mean proportional to <italic>N</italic> means that under some conditions it is possible for the sensory response <italic>n</italic> to be negative, which we can interpret as a nonzero probability for cues of one laterality to be confused for cues of the opposite laterality. However, this is a modeling assumption that can be tested by alternatively drawing <italic>n</italic> from a Gamma distribution, and interestingly seems to produce a better fit for the rat data specifically for trials where there are only cues of one laterality.</p><p>For the feedback/modulatory noise distribution (2), we tried a spectrum of options ranging from the symmetric gaussian distribution to skewed distributions with progressively longer tails, including the lognormal but also other distributions that have both negative and positive tails. Our preliminary findings are that gaussian-distributed modulatory noise actually produces a significantly better behavioral prediction for the mouse data than our previous choice of the lognormal distribution, and gaussian-distributed u*w may be more compatible with our neural observations of comparable proportions of cue-locked cells with positive vs. negative count-modulations. Specifically to answer the reviewer’s question about which are critical aspects of the lognormal distribution that produced a good fit for the rat data, by comparing its behavioral prediction to a similar model where the distribution of u*w had a truncated positive tail as well as a (smaller) negative tail, we found that these models both predicted the behavior equivalently well. This points to that the strict positivity and extreme tails of the lognormal distribution were not necessary to explain behavior, but rather other features such as a mode close to zero and a positively skewed tail were important.</p><disp-quote content-type="editor-comment"><p>2) Related to this point, it would be helpful to have more clarity on exactly what is being assumed about the feedback vector u. The neural data suggests u has close to zero mean (across neurons). At the same time, it is posited that u varies across trials (&quot;accumulator feedback is noisy&quot;) is and that this variability is significant and important (previous comment). However, it would seem like neurons keep their choice preference across trials, meaning the trial to trial variability in each element of u has to be smaller than the mean. The authors only describe variability in u*w (LogNormal), but, in addition to the issues just mentioned about this choice, what implications does this have for the variability in u? The logic of the approach would greatly increase if the authors made assumptions about the statistics of u consistent with the neural data, and then derived the statistics of u*w.</p></disp-quote><p>We first admit that the result mentioned by the reviewer of cells having consistent choice preferences across trials, is unfortunately not sufficient to show that the postulated feedback strength u is fairly consistent across trials. This is because the choice- and count-modulation models that we constructed for cue-locked cell amplitudes <italic>assumed</italic>​ ​ across-trial consistency, e.g. cells that had differently signed choice modulations from one trial to the next would not have passed significance tests for being choice modulated. Insofar as we can think of, the only way for us to measure the distribution of the u across trials directly from the neural data, is to fit for a potentially different value of u per trial using the responses of a cue-locked cell to multiple cue presentations within a given trial. When we attempted this, say using a simple linear model <italic>a<sub>k</sub> </italic>= <italic>a</italic><sub>0</sub> + <italic>uk</italic> where <italic>a<sub>k</sub></italic> is a given cell’s response amplitude to the <italic>k<sup>th</sup></italic> cue in a trial, we roughly found three categories of cells with u having symmetric, positively skewed, and negatively skewed distributions, all categories with means close to zero but large variances relative to the mean. We unfortunately feel that these results have many interpretation caveats that make them difficult to claim, e.g. the many other modulatory factors that influence cue-locked activities, and independent cue-to-cue variability (intrinsic to the sensory response) that can increase the variance of the estimated u but seems very difficult to dissociate from this method of estimating u.</p><p>We therefore think that the best that we can do to answer this question is to try various modeling options for the u*w distribution as outlined in the answer to comment 1. The general idea is for the different distribution options to explore different properties such as strict positivity, long tails and so forth, using which we can determine which regimes of u*w distribution shapes produce good fits for the behavior, and then more speculatively discuss these fits with regards to neural circuit considerations as suggested by the reviewer in comment 3.</p><disp-quote content-type="editor-comment"><p>3) Overall, it seems like there is an intrinsically hard problem to be solved here, which is not acknowledged: how to obtain large variability in the effective gain of a feedback loop while at the same time keeping the gain &quot;sufficiently restricted&quot;, i.e., neither too large and positive (runaway excitation) nor negative (counts are forgotten). While the authors avoid worrying about model parameters by fitting their values from data (with the caveats discussed above), their case would become much stronger if they studied the phenomenology of the model itself, exposing clearly the computational challenges faced and whether robust solutions to these problems exist.</p></disp-quote><p>We will include in the second paper a study of the phenomenology of the model in terms of different sensory response and feedback/modulatory noise distributions, as mentioned in the reply to comment 1. Our preliminary findings are that there are many combinations of distribution shapes that can produce comparably good predictions of the behavior, which may perhaps hint at robustness in the sense that the behavioral prediction depends on gross properties and not details of various noise distributions, and that multiple hypothesized neural implementations can produce the same behavioral outcomes.</p></body></sub-article></article>