<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">94485</article-id><article-id pub-id-type="doi">10.7554/eLife.94485</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.94485.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Future movement plans interact in sequential arm movements</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Kashefi</surname><given-names>Mehrdad</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5981-5923</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Reschechtko</surname><given-names>Sasha</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1025-4533</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Ariani</surname><given-names>Giacomo</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9074-1272</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Shahbazi</surname><given-names>Mahdiyar</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Tan</surname><given-names>Alice</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Diedrichsen</surname><given-names>Jörn</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Pruszynski</surname><given-names>J Andrew</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0786-0081</contrib-id><email>andrew.pruszynski@uwo.ca</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02grkyz14</institution-id><institution>Western Institute for Neuroscience, Western University</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>Canada</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0264fdx42</institution-id><institution>School of Exercise and Nutritional Sciences, San Diego State University</institution></institution-wrap><addr-line><named-content content-type="city">San Diego</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02grkyz14</institution-id><institution>Department of Physiology and Pharmacology, Western University</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>Canada</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02grkyz14</institution-id><institution>Department of Computer Science, Western University</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>Canada</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02grkyz14</institution-id><institution>Department of Statistical and Actuarial Sciences, Western University</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>Canada</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Gallego</surname><given-names>Juan Alvaro</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/041kmwe10</institution-id><institution>Imperial College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>02</day><month>09</month><year>2024</year></pub-date><volume>13</volume><elocation-id>RP94485</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-12-11"><day>11</day><month>12</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-11-13"><day>13</day><month>11</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.05.24.542099"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-02-07"><day>07</day><month>02</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.94485.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-08-01"><day>01</day><month>08</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.94485.2"/></event></pub-history><permissions><copyright-statement>© 2024, Kashefi et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Kashefi et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-94485-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-94485-figures-v1.pdf"/><related-article related-article-type="commentary" ext-link-type="doi" xlink:href="10.7554/eLife.101739" id="ra1"/><abstract><p>Real-world actions often comprise a series of movements that cannot be entirely planned before initiation. When these actions are executed rapidly, the planning of multiple future movements needs to occur simultaneously with the ongoing action. How the brain solves this task remains unknown. Here, we address this question with a new sequential arm reaching paradigm that manipulates how many future reaches are available for planning while controlling execution of the ongoing reach. We show that participants plan at least two future reaches simultaneously with an ongoing reach. Further, the planning processes of the two future reaches are not independent of one another. Evidence that the planning processes interact is twofold. First, correcting for a visual perturbation of the ongoing reach target is slower when more future reaches are planned. Second, the curvature of the current reach is modified based on the next reach only when their planning processes temporally overlap. These interactions between future planning processes may enable smooth production of sequential actions by linking individual segments of a long sequence at the level of motor planning.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>sequential movement</kwd><kwd>eye movements</kwd><kwd>motor planning</kwd><kwd>sequential reaching</kwd><kwd>reaching</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000024</institution-id><institution>Canadian Institutes of Health Research</institution></institution-wrap></funding-source><award-id>PJT-175010</award-id><principal-award-recipient><name><surname>Diedrichsen</surname><given-names>Jörn</given-names></name><name><surname>Pruszynski</surname><given-names>J Andrew</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100010785</institution-id><institution>Canada First Research Excellence Fund</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Diedrichsen</surname><given-names>Jörn</given-names></name><name><surname>Pruszynski</surname><given-names>J Andrew</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001804</institution-id><institution>Canada Research Chairs</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Pruszynski</surname><given-names>J Andrew</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000196</institution-id><institution>Canada Foundation for Innovation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Pruszynski</surname><given-names>J Andrew</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>To ensure smooth sequential actions, reaches to at least two future targets are planned during the execution of the current reach and the planning processes of the future reaches interact.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Many everyday actions like speaking or preparing a cup of tea are composed of a long and often rapid sequences of movements (<xref ref-type="bibr" rid="bib19">Lashley, 1951</xref>). For successful performance of such tasks, the next movement needs to be proactively planned before the previous movement is concluded. Indeed, prior investigations in saccadic eye movements (<xref ref-type="bibr" rid="bib20">McPeek et al., 2000</xref>; <xref ref-type="bibr" rid="bib21">McPeek and Keller, 2002</xref>), reading (<xref ref-type="bibr" rid="bib26">Rayner, 1998</xref>), walking (<xref ref-type="bibr" rid="bib22">Patla and Vickers, 2003</xref>), typing (<xref ref-type="bibr" rid="bib31">Snyder and Logan, 2014</xref>), finger movements (<xref ref-type="bibr" rid="bib4">Ariani et al., 2021</xref>; <xref ref-type="bibr" rid="bib3">Ariani et al., 2020</xref>; <xref ref-type="bibr" rid="bib29">Shahbazi et al., 2024</xref>), path tracking (<xref ref-type="bibr" rid="bib5">Bashford et al., 2022</xref>), target harvesting (<xref ref-type="bibr" rid="bib9">Diamond et al., 2017</xref>), and reaching (<xref ref-type="bibr" rid="bib16">Howard et al., 2015</xref>; <xref ref-type="bibr" rid="bib28">Säfström et al., 2014</xref>; <xref ref-type="bibr" rid="bib32">Zimnik and Churchland, 2021</xref>) consistently show that sequence production is faster and more efficient when participants have access to information that allows them to plan the future movements. This improvement demonstrates the nervous system’s ability to plan future movements while executing the current movement – i.e., to do <italic>online planning</italic> (<xref ref-type="bibr" rid="bib4">Ariani et al., 2021</xref>; <xref ref-type="bibr" rid="bib3">Ariani et al., 2020</xref>; <xref ref-type="bibr" rid="bib2">Ariani and Diedrichsen, 2019</xref>).</p><p>Planning and execution-related processes of a single movement occur in overlapping brain areas and often even carried out by the same neurons (<xref ref-type="bibr" rid="bib8">Crammond and Kalaska, 2000</xref>; <xref ref-type="bibr" rid="bib11">Elsayed et al., 2016</xref>; <xref ref-type="bibr" rid="bib17">Kaufman et al., 2014</xref>), so an important question is how the nervous system avoids interference between the planning of a future movement and the control of the current one when producing rapid sequential movements. In a short sequence of two reaches, <xref ref-type="bibr" rid="bib32">Zimnik and Churchland, 2021</xref> proposed that in monkey primary motor cortex (M1) and dorsal premotor cortex (PMd), preparation of the next movement occurs in an orthogonal neural subspace to that which controls the ongoing movement, thereby allowing these two processes to run in parallel without interference.</p><p>For longer movement sequences, especially if they are to be rapidly executed, it may be necessary to prepare beyond the next reach. It remains unknown to what degree multiple future reaches are planned, and whether these planning processes interact with each other and with the ongoing action. Here, we address this question with a new continuous reaching task in which we control how many future movements can be planned and how much the kinematics of the individual segments of the sequence could affect each other.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We investigated how multiple future targets of a sequence are planned in a continuous reaching task. Participants were instructed to perform sequences of 14 reaches in a planar robotic exoskeleton. The targets were generated from a hexagonal grid of potential targets with radii of 1 cm spaced 4 cm apart over a 21×24 cm<sup>2</sup> total workspace (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Every trial started from the same ‘home’ target in the center of the workspace. Participants were instructed to capture a target before moving on the next target. They captured each target by staying within it for 75, 200, or 400 ms (dwell time, <xref ref-type="fig" rid="fig1">Figure 1B</xref>). Longer dwell times required a full stop in each target, while shorter dwell times allowed participants to link subsequent reaches into a co-articulated unit (<xref ref-type="fig" rid="fig1">Figure 1C</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Experimental paradigm.</title><p>(<bold>A</bold>) Participants performed reaches in an exoskeleton robot. Their hand was occluded, and hand position was indicated by a red dot. The full grid of possible targets not shown to participants. The targets and their order were shown with decreasing brightness (an H3 trial is shown). (<bold>B</bold>) Movement trajectory in three example trials (Horizon 2; Dwell 75, 200, 400). Trials always started from a fixed home target in center (gray target). The small circles on the traces show the time point in which the target was captured. (<bold>C</bold>) Speed profiles for the example trials shown in (<bold>B</bold>). (<bold>D</bold>) Timeline of the task for Horizon 1–3 conditions. Ticks show the time when the target was captured (colored number) and a new target was shown on the screen (colored small dot). The boxes above the line show the available time for planning each movement, the time from when the target first shown to the beginning of the execution of the movement. The boxes below the line show the execution of each movement, the time interval in which the hand was moving from one target to another.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94485-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Speed profile for two participants.</title><p>(<bold>A</bold>) From one participant, for each horizon, one trial is selected randomly. Black traces show the speed profile, red dots show the time point that hand entered a new target. (<bold>B</bold>) Same as (<bold>A</bold>) but for a different participant.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94485-fig1-figsupp1-v1.tif"/></fig></fig-group><p>Participants could see the position of their hand displayed as a circular cursor in the horizontal plane of the task. Participants were shown either one (Horizon 1), two (H2), three (H3), four (H4), or five (H5) future targets to control how much information about the future sequence was available. The order of future targets was indicated by their brightness. The Horizon 1 condition was equivalent to a serial reaction time task because the next target appeared only when the current one was captured. Therefore, the next movement could not be planned until the end of the current movement (<xref ref-type="fig" rid="fig1">Figure 1D</xref>, H1). In contrast, the Horizon 2 condition allowed for some planning of the next movement while executing the current one (<xref ref-type="fig" rid="fig1">Figure 1D</xref>, H2). Horizon 3–5 conditions allowed planning the next two, three, or four movements, respectively (<xref ref-type="fig" rid="fig1">Figure 1D</xref>, H3).</p><sec id="s2-1"><title>Planning future reaches speeds up sequence execution</title><p>To establish how many future movements participants planned, we first asked whether participants were faster when extra future targets were visible. To quantify speed, we measured the inter-reach interval (IRI), defined as the time required to move the hand from the boundary of one target to the boundary of the next target (<xref ref-type="fig" rid="fig2">Figure 2</xref>). IRI was significantly reduced from Horizon 1 to Horizon 2 for all dwell times. The average reduction of IRI was 206 ms (t<sub>(10)</sub> = 22.76, p=3.02e-10), 232 ms (t<sub>(10)</sub> = 27.41, p=4.83e-11), and 246 ms (t<sub>(10)</sub> = 24.84, p=1.27e-10) for the 75, 200, and 400 ms dwell times, respectively. We also observed a further small 16 ms improvement from H2 to H3 in the 75 ms dwell time condition (t<sub>(10)</sub> = 3.137, p=5.30e-3). These results suggest that, at least for a dwell time of 75 ms, participants plan two targets ahead of the current reach.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Inter-reach interval (IRI) for three dwell times and five horizons.</title><p>IRI was averaged across all trials, all session, for each participant. The error bars show a 95% confidence interval accross participants (n = 11), ** signifies p&lt;0.01, **** signifies p&lt;0.0001.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94485-fig2-v1.tif"/></fig></sec><sec id="s2-2"><title>Target jump confirms participants plan two future reaches</title><p>Because the reduction of IRI from H2 to H3 observed above was small, we performed a second experiment to test whether participants planned two movements into the future. That is, we occasionally displaced the target two reaches in the future (i.e. the +2 target) when the current (i.e. +0) target was captured. If information about the +2 target was not being used, we would expect to see no interruption in the sequence: both the movement toward the unperturbed +1 target, as well as to the jumped +2 target should not differ from unperturbed conditions (<xref ref-type="fig" rid="fig3">Figure 3B</xref>, solid line). We tested this prediction in the H3 condition with 75 ms dwell time.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Jump of the +2 target reveals existence of planning processes for the reach toward +2 target during the execution of +0 reach.</title><p>(<bold>A</bold>) Timeline of the jump experiment in Horizon 3, Dwell time 75 ms condition. The jump occurred at the capture of +0 target (vertical gray arrow). (<bold>B</bold>) Reach trajectory for an example no-jump trial (solid line) in which the pre-jump target (light purple) was not shown, and a +2 jump sample trial (dotted line) in which the pre-jump target moved to a new position (dark purple) at the time the +0 target was captured (vertical gray arrow). (<bold>C</bold>) The time for Execution +1 (E+1), Dwell +1, and Execution +2 (E+2), and the minimum distance of reach trajectory to the center of pre-jump target for no-jump and jump conditions. Each dot represents one participant (n = 10), *** shows p-value&lt;0.001.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94485-fig3-v1.tif"/></fig><p>Our results indicate that participants used the information about the +2 target. We observed a normal reach toward the unperturbed +1 target. The reach time to the +1 target was not reliably different between the jump and no-jump conditions (t<sub>(9)</sub> = 0.63, p=0.54; <xref ref-type="fig" rid="fig3">Figure 3C</xref>, Execution +1). This was also true for dwell time inside the +1 target (t<sub>(9)</sub> = 1.98, p=0.08; <xref ref-type="fig" rid="fig3">Figure 3C</xref>, Dwell +1). However, movement time from the +1 to the +2 target was significantly longer in the jump condition (t<sub>(9)</sub>=5.90, p=2.00e-4; <xref ref-type="fig" rid="fig3">Figure 3C</xref>, Execution +2).</p><p>One reason for this delay could be that visual displacement of the target was simply a distracting stimulus. However, this explanation is not consistent with our kinematic analysis which revealed participants reached toward the pre-jump +2 target, and then corrected their reach toward the new position of +2 target (<xref ref-type="fig" rid="fig3">Figure 3B</xref>, dotted line). We quantified this commitment to the pre-jump +2 target position by measuring the minimum distance between the reach trajectory and the center of the pre-jump +2 target (see Methods). The minimum distance was significantly lower in the jump condition (t<sub>(9)</sub>=5.78, p=3.00e-4).</p><p>Together with the speedup of the overall movement (<xref ref-type="fig" rid="fig2">Figure 2</xref>), these results show that the reach to the +2 target was at least partially planned before the target jump, simultaneous with the reach to the +0 target and planning of the reach to the +1 target (<xref ref-type="fig" rid="fig3">Figure 3A</xref>).</p></sec><sec id="s2-3"><title>Planning processes for multiple future movements are not independent</title><p>Our previously described results indicate that multiple future movements are planned at the same time. Consequently, we next asked whether these preparatory processes are independent of each other or if they interact.</p><p>We tested whether two future movement plans interact by jumping the position of the +1 target when the +0 target was captured. This was done under the 75 ms dwell time. We compared the speed of the correction in the H2 and H3 conditions (see <xref ref-type="fig" rid="fig4">Figure 4A</xref> and Methods). Although the two conditions had similar kinematics, participants could only plan the +1 target in the H2 condition, whereas they could plan both the +1 and +2 targets in the H3 condition (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). If the +1 and +2 targets are planned independently, the movement correction to a displacement of the +1 target should be the same in the H2 and H3 conditions. Alternatively, if the movements interact – if they are planned together or share limited resources – the correction should be slower in the H3 condition because some of the resources would be assigned to planning the +2 target.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Correction for jump of the +1 target is delayed when more future movements are planned.</title><p>(<bold>A</bold>) Timeline of the jump experiment in the H2 and H3 conditions. In both conditions, the jump of the +1 target (orange) occurred when the +0 target was captured (vertical gray arrow). (<bold>B</bold>) Example trials for a no-jump condition (solid line) and for jump conditions for H2 (dashed line) and H3 (dotted line). In the latter two conditions, the +1 target (orange dotted circle) jumped to a new position (curved gray arrow), when the +0 target was captured (vertical gray arrow). (<bold>C</bold>) Movement time, trajectory length, and minimum distance of the trajectory to the center of +2 target for the reach to the new position of the +1 target. Dots and triangles show mean values for each subject (n = 10) in H2 and H3 conditions respectively. ** and *** signify p-value&lt;0.01 and p-value&lt;0.001, respectively.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94485-fig4-v1.tif"/></fig><p>Consistent with an interaction between future plans, we found that the corrections for a +1 target jump were longer and slower in the H3 condition than in the H2 condition (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). In both conditions, participants failed to correct the movement before arriving at the pre-jump position of the +1 target (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). In the H3 condition, both the movement time (t<sub>(9)</sub> = 4.85, p=1.80e-3) and the trajectory length (t<sub>(9)</sub> = 6.19, p=3.00e-4) of the corrective movement were longer than that of the H2 condition. The longer correction trajectory was due to participants moving onward to the +2 target without having corrected for the displaced +1 target. We again used the minimum distance between the corrective reach trajectory and the +2 target to quantify this effect (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). The corrective reaches were closer to the center of the +2 target in H3 condition (t<sub>(9)</sub> = 4.28, p=4.00e-3).</p><p>In summary, it took more time to update the +1 movement plan when participants could simultaneously plan both the +1 and +2 target as compared to when they could only plan the +1 target. This effect indicates that planning a reach to the +2 target occupied some part of a shared computational resource such that less of the resource was available for updating the reach to the +1 target. These results indicate a clear interaction between the planning processes for future movements.</p></sec><sec id="s2-4"><title>Planning processes are not completely integrated in a single chunk</title><p>So far, we have established that people plan reaches to multiple future targets and that these planning processes interact with each other (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). An extreme version of such an interaction is that the two future reaches are planned as a single unit, as a ‘motor chunk’ (<xref ref-type="fig" rid="fig5">Figure 5B</xref>; <xref ref-type="bibr" rid="bib25">Ramkumar et al., 2016</xref>). Our data, however, are not consistent with the idea that future reaches are planned as a motor chunk.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Jump of the +2 target or +1 rejects chunked planning of the reaches to the +1 and +2 targets.</title><p>(<bold>A</bold>) Timeline of the task in the jump experiments. Ticks show the time when the target was captured (colored number) and a new target was shown on the screen (colored small dot). The boxes above the line show the available time for planning each movement, and the boxes below the line show the execution of each planned movement. (<bold>B</bold>) Same as (A), but for the chunked planning hypothesis, here one chunked planning controls both Execution +1 (E+1) and Execution +2 (E+2) reaches. (<bold>C</bold>) Reach trajectories for +2 target jump experiment. Reach trajectory for one example no-jump trial (solid line) in which the pre-jump target (light purple) was not shown, and a +2 jump sample trial (dotted line) in which the pre-jump target moved to a new position (dark purple) at the time the +0 target was captured (vertical gray arrow). (<bold>D</bold>) Example trials for a no-jump condition (solid line) and for jump conditions for H2 (dashed line) in which the +1 target (orange dotted circle) jumped to a new position (curved gray arrow) when the +0 target was captured (vertical gray arrow). (<bold>E</bold>) +0 Reach time measured from when the cursor entered the +0 target (green circle) to when it exits the +1 target (orange circle) for each participant (n = 10). *** signify p-value&lt;0.01 and p-value&lt;0.001.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94485-fig5-v1.tif"/></fig><p>First, an important indicator of chunking is that, after a chunk is executed, there is a short delay until the next chunk is planned. For instance, in the H2 condition, since two targets are shown on the screen at any given time, the participants could execute two fast reaches, followed by a long pause in which they prepared the next chunk of two reaches. However, except for H1 condition, where the participants had to pause and wait for the next target to appear, the speed profiles of other horizon conditions showed no evidence of such pauses (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>).</p><p>Second, chunked planning predicts that a disturbance in any segment of the chunk would affect the whole chunked segment. We tested this prediction in two types of jump experiments. In the H3 condition, where participants could potentially plan +1 and +2 reaches as one chunk, we occasionally either jumped the position of the +2 target (<xref ref-type="fig" rid="fig5">Figure 5C</xref>) or the +1 targets (<xref ref-type="fig" rid="fig5">Figure 5D</xref>) when the +0 target was captured. Chunked planning predicts that both jumps should cause a disturbance in the first reach of the chunk, but this did not occur. When we jumped the +2 target, the participants performed the reach to the +1 target in a manner identical to the no-jump condition (t<sub>(9)</sub> = 0.60, p=0.56). Additionally, when we jumped the +1 target they still went through the pre-jump +1 target but their movement was significantly shortened by deviating toward the new position of the +1 target (t<sub>(9)</sub> = 14.36, p=1.64e-7) (<xref ref-type="fig" rid="fig5">Figure 5E</xref>).</p><p>In summary, participants were able to correct the second segment of their movement without causing any disturbance in the first segment. This observation provides clear evidence against chucked planning of the future reaches.</p></sec><sec id="s2-5"><title>Interaction among planning processes leads to co-articulation of reach segments</title><p>The experiments above indicate that reach planning to the +1 and +2 targets interact with each other. Such interactions could allow the motor system to optimize the set of movements leading to systematic co-articulation of movement segments. In other words, when the visual information of the future target is available, each movement in the sequence could be planned in a way that accounts for the movement that comes after it.</p><p>Indeed, we observed systematic co-articulation of movements in the H3 condition (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). When the +2 target demanded an upcoming rightward turn, the +1 reach curved left, and vice versa (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). Although this deviation led to a longer overall trajectory, it reduced the required turning angle at the +1 target. To summarize the effect of future target on curvature, we fit a linear model that predicted the signed curvature value of the current reach based on two independent variables: the turning angle toward the +2 target, and the incoming angle of the previous reach (see <xref ref-type="fig" rid="fig6">Figure 6C</xref> and Methods). Note that this model has the advantage over simple averaging because it accounts for the trivial curvature changes caused by the previous movement. The model was fit for each dwell time and horizon separately. <xref ref-type="fig" rid="fig6">Figure 6C</xref> shows the average curvature for all possible +1 target angles, corrected for the influence of the last target. To summarize the co-articulation effect across all the angles, we fit a line between five values of angles and the curvature (<xref ref-type="fig" rid="fig6">Figure 6B</xref>, black line). The slope of the line summarizes the strength of the curvature effect (<xref ref-type="fig" rid="fig6">Figure 6D</xref>) for each dwell time and horizon condition.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Curvature of the reach to +1 target is modulated by position of +2 target.</title><p>(<bold>A</bold>) Timeline of planning and execution for a Horizon 3 trial. Amount of time overlap (T) between planning processes for reach to +1 and +2 target is represented by the black arrow. (<bold>B</bold>) Effect of +2 target angle on the curvature of +1 reach for Dwell time 75, all horizons, one participant. Positive value of curvature indicates downward curve and vice versa. The overall effect is captured by the slope of the line relating average curvature to the five angles (slope of black lines). (<bold>C</bold>) All the reaches are aligned to one start point and one direction. Then, the angle at the start of the movement to the +2 target can be −120, –60, 0, 60, 120 degrees (60 is shown with dotted line). A linear model is used to predict the signed curvature based on the position of last target (+0 angle) and the +2 target (+2 angle). (<bold>D</bold>) Each dot represents the average summary statistics of the curvature across participants. Individual participant values are shown with shadowed dotted lines in the background. (<bold>E</bold>) Average curvature effect across participants vs overlaps of planning time (T) for each condition. Shades of gray show different horizons and solid, dashed, and dotted lines represent different dwell time conditions. Error bars are SEM across participants (n = 11), and ** signifies p-value&lt;0.001.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94485-fig6-v1.tif"/></fig><p>In the H1 and H2 conditions, the slope was not reliably different from zero, indicating no systematic co-articulation. This observation is expected for H1 since the +2 target was not on the screen during the planning or execution of the investigated reach. Notably, we did not observe the curvature effect in the H2 condition in which the +2 target was on the screen only during the execution of the +1 reach. This suggests that co-articulation of segments cannot happen if planning of the next segment happens during the execution of the previous one. In the H3 condition, the slope was reliably smaller than zero for all the dwell time conditions, indicating systematic co-articulation once parallel planning was feasible. In the case of the 75 ms dwell time, the co-articulation kept growing from H3 to H4 (t<sub>(10)</sub> = 5.54, p=2.60e-03). We observed no reliable increase in co-articulation for Horizon&gt;3 for the 200 ms (t<sub>(10)</sub> = 0.19, p&gt;0.98) or 400 ms dwell times (t<sub>(10)</sub> = 0.38, p&gt;0.99).</p><p>Overall, we observed less co-articulation for longer dwell times. Dwell time can have a dual role here. On the one hand, longer dwell times mean the participants have more time to benefit from future targets because they see the targets longer, potentially leading to more co-articulation. On the other hand, longer dwell times mean the participants had to stay stationary in the target for longer, making the movements less mechanically integrated, and therefore decreasing the benefit of co-articulation. To distinguish between these potential contributions of dwell time, we plotted the curvature effect versus the time that participants could see both the +1 and +2 targets before starting the +1 movement (<xref ref-type="fig" rid="fig6">Figure 6E</xref>). Both horizon and dwell time led to more overlap in planning times. For all dwell time conditions, the curvature effect increased between H2 and H3 conditions, and then saturated after the H4 condition. However, with longer dwell times, the overall rise and saturation of the curvature effect was smaller (F<sub>(2,20)</sub> = 16.71, p=6.00e-04), suggesting less interaction between planning processes when the movements are biomechanically separated.</p><p>Together, these results show that the biomechanically advantageous co-articulation between segments of the sequence occur when the segments are planned together.</p></sec><sec id="s2-6"><title>Fixation location is modified by the availability of future targets</title><p>Given that participants used visual information from two targets ahead, we were curious whether the availability of future targets influences participants’ eye-movement strategy, or whether they acquired this information parafoveally.</p><p>We collected data from a separate group of 19 participants in the same task, only focusing on Dwell time 75 ms, and H1, H2, and H3 conditions. We found that in ~95% of all reaches in all trials, participants made only one saccade per reach, indicating they primarily focused on the immediate next target with information about subsequent targets likely being processed through parafoveal vision. We assessed the timing of the saccades by measuring the saccade time relative to hand position (<xref ref-type="fig" rid="fig7">Figure 7A and B</xref>). The saccade to the next target occurred after the current target disappeared, and right before the hand exited the disappeared target. The relative timing between the saccade and the hand exiting the target was consistent across different horizons (F<sub>(2,36)</sub> = 1.92, p=0.16).</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Saccade position is shifted toward the future target.</title><p>(<bold>A</bold>) One sample trial from a representative participant. The blue and black trace shows the hand and eye position, respectively. The blue dots are when hand first entered the target, yellow dots show when hand exited the target, the red × shows the fixation location. (<bold>B</bold>) Timing of capturing the current target (gray), saccade to the next target (red), hand out of the captured target (yellow), and hand in the next target (blue), averaged across participants, black lines show 95% confidence interval. (<bold>C</bold>) Saccade angles of a representative participants for each possible +2 target and three horizons. (<bold>D</bold>) Average saccade angle for all participants (n = 19) and each horizon. Error bars show 95% confidence interval.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94485-fig7-v1.tif"/></fig><p>Next, we characterized the fixation location. If the visual information of the next target is received through the parafoveal vision, then it would be beneficial to shift the fixation location toward the future target. As shown in one representative participant (<xref ref-type="fig" rid="fig7">Figure 7C</xref>), we found that saccade angle is shifted toward the position of the future target in the H2 and H3 conditions. At the group level, the saccade angle was significantly different for different horizons (F<sub>(8,128)</sub> = 12.60, p=3.12e-13). In Horizon 1, as expected, the average saccade angle for different targets was identical since the future target was not shown. For both Horizon 2 and Horizon 3, the angle of the saccade was systematically shifted toward the position of the upcoming target.</p><p>Together, these results suggest that information about future targets is received parafoveally, and the fixation location is systematically shifted to facilitate this process.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><sec id="s3-1"><title>Planning horizon in sequential reaching versus finger presses</title><p>In a previous finger sequence study, using a similar horizon manipulation to the one used here, we found that participants executed sequences faster when they had information about multiple future finger presses (<xref ref-type="bibr" rid="bib4">Ariani et al., 2021</xref>). This benefit increased up to horizon of three future finger presses (H3) and then plateaued. Consistent with these findings, we observed a large reduction in movement time when participants were provided with one future reach target (<xref ref-type="fig" rid="fig2">Figure 2</xref>, H1 to H2). However, except for the shortest (75 ms) dwell time, the availability of a second future target (H2 to H3) did not further reduce movement time (<xref ref-type="fig" rid="fig2">Figure 2</xref>). In these longer (200 and 400 ms) dwell times, we did not observe faster performance for more knowledge of future target positions, likely because the participants had sufficient time to complete planning during the dwell period. Another possible reason for the more pronounced effect of horizon on movement speed in finger presses may be attributed to the nature of the effectors. Specifically, in reaching movements, the arm cannot initiate the next reach before completing the previous one. In contrast, with finger movements, future finger flexions can commence in advance, potentially resulting in faster execution of the sequence (<xref ref-type="bibr" rid="bib23">Popp et al., 2022</xref>). It is also possible that this difference arises because the transformation of the visual cue to motor plans is faster for the direct spatial mapping used here than for the more abstract number-to-finger mapping used in our previous study (<xref ref-type="bibr" rid="bib10">Diedrichsen et al., 2001</xref>; <xref ref-type="bibr" rid="bib15">Goodman and Kelso, 1980</xref>). Even though the planning of multiple future movements, as measured by IRI, could only be seen in shortest dwell times, our experiments with target displacements provide clear evidence that participants had planned two movements ahead (<xref ref-type="fig" rid="fig3">Figure 3</xref>). Overall, these observations suggest that the availability of the second reach target can be more significant when faster execution of the task demands faster transformation of visual cue to muscle commands, or when the cue-to-action mapping is more demanding.</p></sec><sec id="s3-2"><title>Interactions among future movement plans</title><p>If participants plan multiple future movements at the same time, the next question is whether these preparatory processes run independently or if they interact with each other. We investigated these possibilities by jumping the target that participants were about to reach toward. The participants corrected the reach only after initially reaching toward the pre-jump position of the target (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). This behavior is similar to that shown in the work by <xref ref-type="bibr" rid="bib1">Ames et al., 2019</xref>, where target displacement during execution led to an initial commitment to the pre-jump position of the target followed by a smooth corrective reach toward the new target position. Neurally, the authors showed that resource distribution in M1 and PMd is accomplished by re-planning the corrective reach in a subspace orthogonal to the one controlling the ongoing movement (<xref ref-type="bibr" rid="bib1">Ames et al., 2019</xref>). Here, we asked whether the re-planning process depended on any other planned future movement (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Interestingly, the corrections were slower when more future targets were known to the participants (<xref ref-type="fig" rid="fig4">Figure 4B</xref>), indicating some interaction between the two future planned reaches. This interaction could come in multiple forms. One possibility is that the neural resources dedicated to re-planning have to be split between preparation of future targets, slowing the re-planning of the next movement (<xref ref-type="bibr" rid="bib18">Kornysheva et al., 2019</xref>). Alternatively, the two future movements may be prepared as a chunk (<xref ref-type="bibr" rid="bib25">Ramkumar et al., 2016</xref>), and changing the entire chunk may take longer time than changing a single movement. The latter possibility seems unlikely since the results from jumping the +1 or +2 target within the same horizon of future target can be corrected separately (<xref ref-type="fig" rid="fig5">Figure 5</xref>). Either way, by probing the planned state with target perturbations we clearly demonstrate an obligatory interaction between multiple future movement plans.</p><p>We also provide evidence that the interactions between future movement plans can optimize kinematics of single reaches for the next reach in the sequence. When the planning processes of two future reaches overlapped sufficiently, we found changes in the curvature of the current reach that anticipated the direction of the next reach target. The curvature was opposite to the direction of the next target, making this co-articulation advantageous from a biomechanical point of view (<xref ref-type="fig" rid="fig6">Figure 6D</xref>). The observed curvature interaction can again be either due to fully chunked planning of two elements, or alternatively, due to separate, yet interactive, planning of the two reaches. The former possibility seems less likely since the interaction was observed even when movement segments were fully separated by a long dwell time (<xref ref-type="fig" rid="fig6">Figure 6D</xref>, Dwell 400).</p></sec><sec id="s3-3"><title>Implications for the neural control of online planning</title><p>What implications do our results have for the neural processes underlying the online planning of multiple future actions? Previous neurophysiological investigations showed that individual neurons can be involved in both the planning and execution of phases of a movement (<xref ref-type="bibr" rid="bib6">Churchland and Shenoy, 2007</xref>; <xref ref-type="bibr" rid="bib8">Crammond and Kalaska, 2000</xref>; <xref ref-type="bibr" rid="bib11">Elsayed et al., 2016</xref>; <xref ref-type="bibr" rid="bib17">Kaufman et al., 2014</xref>; <xref ref-type="bibr" rid="bib24">Pruszynski et al., 2014</xref>). Nonetheless, when two movements are concatenated, the planning of the second movement can be proceeded in parallel with the control of the first movement. This lack of interference can be explained by the fact that planning and execution proceed in orthogonal neural subspaces (<xref ref-type="bibr" rid="bib32">Zimnik and Churchland, 2021</xref>).</p><p>The phenomena demonstrated in this study raise the question of how the planning processes for multiple future movements are realized in the brain. One hypothesis is that the two future movements are also planned in orthogonal neural subspaces without any interactions during the planning phase. Under this hypothesis, the co-articulation we report would arise from an interaction between the execution dynamics associated with the current movement and the planning dynamics of the second planned movement. An alternative hypothesis is that the preparation processes of the next two movements directly interact with each other, and possibly are even encoded in partly together (<xref ref-type="bibr" rid="bib12">Fusi et al., 2016</xref>; <xref ref-type="bibr" rid="bib27">Rigotti et al., 2013</xref>). Our results are suggestive of the latter scheme since we observed no co-articulation when the next target was only available during execution of the current reach (<xref ref-type="fig" rid="fig6">Figure 6D</xref>, H2). Nevertheless, careful electrophysiology experiments are necessary to investigate the exact mechanism by which planning processes interact. The current paradigm provides a useful framework to do so.</p></sec><sec id="s3-4"><title>Eye movement coordination during sequence production</title><p>In our sequence task, participants switched their gaze location only once per reach, suggesting that information about the location of the next target is perceived parafoveally (<xref ref-type="fig" rid="fig7">Figure 7A</xref>). This observation aligns with previous studies (<xref ref-type="bibr" rid="bib7">Clavagnier et al., 2007</xref>; <xref ref-type="bibr" rid="bib14">González-Alvarez et al., 2007</xref>; <xref ref-type="bibr" rid="bib30">Sivak and MacKenzie, 1990</xref>) that found participants keep their visual attention on the current sequence item and can perceive the location of spatial targets even when foveal vision is occluded. However, when comparing gaze locations for conditions Horizon&gt;1, we observed that participants systematically biased their gaze location based on the sequence context. The gaze position shifted toward the next target, potentially allowing for more accurate location estimation (<xref ref-type="fig" rid="fig7">Figure 7C and D</xref>). Notably, changes in gaze location were observed even in Horizon 2, despite no changes in the curvature of hand movements in this horizon (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). This suggests that information about the next target may first be available in the circuitry that controls eye movements and later in the cortical areas that control voluntary upper limb movements. Further control studies are required to investigate this hypothesis.</p></sec></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Participants</title><p>Eleven participants (4 female) with an average age of 23.3 years (4.4 SD years) completed five experimental visits for this study (~10 hr data collection per participant); this data was used for IRI (<xref ref-type="fig" rid="fig2">Figure 2</xref>) and curvature analysis (<xref ref-type="fig" rid="fig6">Figure 6</xref>). Ten of these participants returned for two experimental visits where they were tested on target jump experiments. They were all right-handed with average handedness of 78 (24 SD), measured by the Edinburgh Handedness Inventory. For eye position analysis, we recruited a different group of 20 right-handed participants (2 female) with average age of 21.2 years (2.0 SD years), one participant was excluded from the analysis due to low quality of data (see Eye-tracker analysis below).</p><p>All participants reported no prior history of musculoskeletal, neurological, or psychiatric disorders. All the participants provided informed consent in the first session, and they were remunerated CA$ 15 per hour in the seventh and last session of the study. All the procedures were approved by the Health Sciences Research Ethics Board at the University of Western Ontario (Project ID 115088).</p></sec><sec id="s4-2"><title>Apparatus</title><p>Participants performed all experimental trials in an exoskeleton robot (Kinarm, Kingston, ON, Canada). The participants were seated on a height-adjustable chair while their right arm rested comfortably on the robot arm, which supported the elbow and shoulder weight against gravitational force and allowed them to freely move their hand in the horizontal plane. Arm kinematics were recorded at 1000 Hz. All the reaching targets were presented by a horizontally placed monitor onto a mirror which occluded the vision of the participant’s arm (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Participants’ eye movement was recorded using an SR Research Eyelink 1000 at 1000 Hz. The eye tracker also recorded the participants’ head movement by recording the position a bullseye target attached to the participants’ front. The eye position was subtracted from the bullseye position to correct for small head movements during the task.</p></sec><sec id="s4-3"><title>General procedures</title><p>In each experimental trial, participants performed sequences of 14 reaches. The sequences were generated from a hexagonal grid of equidistant circular targets (see <xref ref-type="fig" rid="fig1">Figure 1A and B</xref>). The radii of the targets were 1 cm, and the center of neighboring targets was 4 cm apart. The participants’ arm was occluded – they only saw a circle with radius of 0.5 cm aligned with the tip of their index finger as their hand feedback. The sequences always started from a fixed home target in the center of the working space. We generated sequences according to two rules. First, the next target in the sequence should be a neighbor of the previous target. This ensured that all the reaches were 4 cm apart. Second that there were no loops smaller than five reaches. This ensured that, when multiple future targets were presented, they did not overlap. The participants were instructed to move their right hand in the home target to start a trial. Once the hand was in the home target, either one, two, three, four, or five future targets of the sequence appeared on the screen (depending on the horizon condition); brightness indicated the order of targets, with the brightest target being the immediate next target. The participants were instructed to stay in the home target for 300 ms, after which they received a go cue by the disappearance of the home target. The participants were instructed to always move their hand to the brightest target and stay in the target until it was ‘captured’. Once one target was captured, the captured target disappeared, the brightness of the targets was updated, making the next target the brightest, and a new target appeared at the end of the horizon. This process was repeated until all 14 targets were captured. If the participant failed to stay in the target for the dwell time or the initial wait time in the home target, the trial was interrupted with an error message and rejected. Interrupted trials were repeated later in the session.</p><p>Our experiments manipulated two parameters: how much time participants had to stay in each target to capture it (dwell time), and how many future targets were on the screen (horizon). The dwell times could be 75, 200, or 400 ms. In the horizon conditions (H1 to H5), 1–5 future targets were visible. In the case of H1, the task is reduced to a sequential reaction time task, and with longer horizons, participants could potentially plan multiple future movements ahead of time.</p><p>The entire experiment had seven sessions. The first five sessions were designed to get a time and curvature analysis in all dwell and horizon conditions. The last two session added the jump experiment.</p></sec><sec id="s4-4"><title>Time and curvature analysis</title><p>The first five sessions measured performance in 15 conditions (3 dwell times × 5 horizons). Each session consisted of three blocks of 120 trials for each dwell time, and the horizon was randomized across trials totaling 360 trials per session. The order of dwell time blocks was randomized across five sessions for each participant. Each session of data collection was 1 hr and 15 min on average. As the first step, for each trial, we broke down the full sequence of reaches to their constituting single reaches by segmenting the full sequence trajectory whenever a target was captured. This led to a set of 14 individual reaches starting from each target and ending in the next. For all the analysis we were interested in simultaneous planning and execution processes, therefore we excluded all targets that were visible in the beginning and could therefore be pre-planned. We also excluded one to five targets at the end of each sequence since there was no need to plan future targets anymore. The number of excluded reaches changed with the horizon. For instance, in the H1 condition, we excluded the first and the last reach in the sequence.</p><p>Given our hexagonal grid, for each reach, there could be a maximum of five potential next target positions. However, near the boundaries of the workspace, the number of potential next targets decreases so the participants could potentially predict the overall position of the upcoming target and plan for it ahead of time (<xref ref-type="bibr" rid="bib13">Glaser et al., 2018</xref>). To ensure that this possibility did not affect our results, we only considered reaches with five potential future choices. This excluded the reaches toward and parallel to the boundaries of the workspace.</p><p>For the analysis of movement time, we computed IRI, defined as the time the hand entered a one target until it entered the next one. We subsequently averaged IRI values across all the reaches of a trial, all trials, and all sessions of each participant. The IRI contains both the time that the hand passed through the target and the time that the hand was moving between the two targets.</p><p>For the curvature analysis, we assessed the effect of the position of the +2 target on the curvature of the reach toward the +1 target. We started by aligning all the reaches: First, we translated the position of the +0 target (where the hand is sitting), the –1 target, the +1 target, and the reach trajectory so that the position of the +0 target is set to the center of the 2D coordinate system (0,0) cm. This ensures that all the reaches start from the same position. Next, we rotated the targets and trajectory around the +0 target so the position of the +1 target rests at (4,0) cm coordinates. This ensures that all the reaches have the same directions. With these transformations, the angle of the line connecting the +1 target to the +2 target, relative to the horizon line, connecting the +0 target to the +1 target, can be either −120,–60, 0, 60, or 120 degrees. The same is true for the angle of the line connecting the –1 target to the +0 target.</p><p>Next, we quantified the curvature of +1 reach. We used all the translated and rotated reaches of all the participants. To make the length of the reaches equal, for each reach, we took 100 equally distant spatial samples along the horizontal line connecting the center of the start target to the center of the end target of the reach. Then, we performed a PCA on the matrix containing the y coordinate values of each reach. The size of this matrix was (# reaches × 100). The first and the second PCs were arc-shaped and S-shaped ‘eigen reaches’ each accounting for 72% and 17% of the total variance. We then projected each reach onto the first eigen reach and used the resultant scalar value as a measure of curvature. The absolute value of this scalar shows the amount of the curvature, and the sign indicates the direction of the curve. We used all the reaches of all the participants to calculate the PCs, and then for each participant and condition, the curvature value was calculated separately. This ensured that the comparison between the conditions and averaging across participants are meaningful.</p><p>Finally, we were interested in the effect of the +2 target angle on the curvature of the reach to the +1 target. However, the curvature of a reach in a sequence also depends on the previous reach, therefore, to account for this effect, we fitted a linear model that predicted the signed curvature value of each reach based on the position of the previous target (angle of –1 target), next target (angle of +2 target). The angles were one-hot coded, resulting in one regressor for each angle; therefore, the beta values represent the effect of each input angle onto the curvature effect. This process was performed for each of the dwell time and horizon conditions separately. Finally, as summary statistics for the effect of all the one-hot coded values the outgoing target (+2 target effect), we fitted a line to beta values for each of the five angles. We used the slope of this line as a summary of the overall effect. Zero slopes indicated no curvature effect, the value and sign of the slope show the strength and direction of the effect, with a negative slope showing curvature toward the opposite direction of the next target, and vice versa.</p></sec><sec id="s4-5"><title>Jump experiment</title><p>For the last two data collection sessions, we focused on the 75 ms dwell condition and two of the horizons (H2, H3). All other parameters including the grid of targets, length of the sequence, size of the targets, etc. were identical to the first five sessions. In these experiments, only one jump of a target could happen in each trial. The jump happened randomly between the 4th and 10th reach of the sequence. We interleaved many no-jump trials in these sessions to avoid anticipation or adaptations for the jumps. The order of these two last sessions was randomized across participants.</p><p>The +1 jump experiment consisted of 400 trials, 200 target jumps in H2 and H3, interleaved with 200 no-jump trials with randomized across horizons. In the case of a jump trial, we displaced the next target (+1 target) exactly when the current target (+0 target) was captured. Before the jump, a pre-jump +1 target was shown on the screen, and then, at the moment of the jump, that is when the 75 ms dwell time was satisfied and the current target (+0 target) was captured, we removed the pre-jump +1 target and a new +1 target appeared on the screen. Both the new and pre-jump +1 target were selected in a way that was compatible with the current position of the +2 or +3 targets on the screen, in other words, the jump was compatible with the rules of generating sequence in the task. This jump happened both in the context of Horizon 2, with two future targets, and in Horizon 3, with three future targets presented on the screen.</p><p>The +2 jump experiment was performed only in Horizon 3 (H3) condition. There was a total of 300 trials. Two-third of them were no jump; in the remaining one-third, exactly at the movement that the current target (+0 target) was captured, the second future target (+2 target) jumped to a new position, and the position of the next target (+1 target) remained unchanged. Before the jump, we showed a temporary +2 target (pre-jump +2 target) on the screen, and the jump happened with the disappearance of the pre-jump +2 target and the appearance of a new target as the new +2 target.</p></sec><sec id="s4-6"><title>Eye-tracker analysis</title><p>For pre-processing of eye-tracker data, we first removed trials if the eye position was not recorded for a consecutive 600 ms. This missing data could be due to blinks or the eye tracker momentarily losing the eye position. We removed one participant due to low number of good trials. Then for the remaining trials we first partitioned each trial to 14 segments based on the time point that participants’ hand entered a new target. Then, within each segment we applied a fixed threshold on the derivative of eye position to detect the time point when the saccade occurred. Next, we used the average eye position before and after saccade for analysis of the saccade position. In 95% of the trial only one saccade happened in each reach. The eye position before and after saccade was centered on a circle with radius of 2 cm around the start and end target, respectively. These pre-processing steps were performed blind to the trial type. To analyze the changes in saccade position based on horizon, like curvature analysis, for each participant we first translated and rotated all the reaches and eye positions so that the start target (+0 target) and end target (+1 target) of the reaches are at (0,0) and (4,0) coordinate, respectively. Then for each horizon, we averaged the post-saccade eye position for each possible +2 target position.</p></sec><sec id="s4-7"><title>Statistical analysis</title><p>We employed a within-subject design. All the analyses were performed in RStudio 22.07.1. For analysis of IRI and curvature effect, we used two-way repeated measures ANOVA. Factors were dwell time (three levels), horizon (five levels: H1 to H5), and (dwell time × horizon) interaction. For comparison between different levels of each significant factor, we adjusted p-values for multiple comparisons using Holm method. For the jump +1 target experiment, we used a repeated measures two-way ANOVA with jump (two levels) and horizon (two levels) as factors. Correction for multiple comparisons was similar to the IRI analysis. The details of statistical analysis including the degrees of freedom, the test statistic, and the p-value are provided in the text.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>Reviewing editor, eLife</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Data curation, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Data curation, Supervision, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con7"><p>Conceptualization, Resources, Supervision, Methodology, Writing – original draft, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All the participants provided informed consent in the first session, and they were remunerated CA$ 15 per hour in the seventh and last session of the study. All the procedures were approved by the Health Sciences Research Ethics Board at the University of Western Ontario (Project ID 115088).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-94485-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All the raw data generated as part of this study are publicly available. The data has been uploaded to Dryad: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/dryad.7pvmcvf30">https://doi.org/10.5061/dryad.7pvmcvf30</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Kashefi</surname><given-names>M</given-names></name><name><surname>Reschechtko</surname><given-names>S</given-names></name><name><surname>Ariani</surname><given-names>G</given-names></name><name><surname>Shahbazi</surname><given-names>M</given-names></name><name><surname>Tan</surname><given-names>A</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name><name><surname>Pruszynski</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Data from: Future movement plans interact in sequential arm movements</data-title><source>Dryad Digital Repository</source><pub-id pub-id-type="doi">10.5061/dryad.7pvmcvf30</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported by a CIHR Project Grant to JD and JAP (PJT-175010). JAP received a salary award from the Canada Research Chairs Program.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ames</surname><given-names>KC</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Simultaneous motor preparation and execution in a last-moment reach correction task</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>2718</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-10772-2</pub-id><pub-id pub-id-type="pmid">31221968</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ariani</surname><given-names>G</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Sequence learning is driven by improvements in motor planning</article-title><source>Journal of Neurophysiology</source><volume>121</volume><fpage>2088</fpage><lpage>2100</lpage><pub-id pub-id-type="doi">10.1152/jn.00041.2019</pub-id><pub-id pub-id-type="pmid">30969809</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ariani</surname><given-names>G</given-names></name><name><surname>Kwon</surname><given-names>YH</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title><italic>Repetita iuvant:</italic> repetition facilitates online planning of sequential movements</article-title><source>Journal of Neurophysiology</source><volume>123</volume><fpage>1727</fpage><lpage>1738</lpage><pub-id pub-id-type="doi">10.1152/jn.00054.2020</pub-id><pub-id pub-id-type="pmid">32208910</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ariani</surname><given-names>G</given-names></name><name><surname>Kordjazi</surname><given-names>N</given-names></name><name><surname>Pruszynski</surname><given-names>JA</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The planning horizon for movement sequences</article-title><source>eNeuro</source><volume>8</volume><elocation-id>ENEURO.0085-21.2021</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0085-21.2021</pub-id><pub-id pub-id-type="pmid">33753410</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bashford</surname><given-names>L</given-names></name><name><surname>Kobak</surname><given-names>D</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name><name><surname>Mehring</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Motor skill learning decreases movement variability and increases planning horizon</article-title><source>Journal of Neurophysiology</source><volume>127</volume><fpage>995</fpage><lpage>1006</lpage><pub-id pub-id-type="doi">10.1152/jn.00631.2020</pub-id><pub-id pub-id-type="pmid">35196180</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Temporal complexity and heterogeneity of single-neuron activity in premotor and motor cortex</article-title><source>Journal of Neurophysiology</source><volume>97</volume><fpage>4235</fpage><lpage>4257</lpage><pub-id pub-id-type="doi">10.1152/jn.00095.2007</pub-id><pub-id pub-id-type="pmid">17376854</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clavagnier</surname><given-names>S</given-names></name><name><surname>Prado</surname><given-names>J</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name><name><surname>Perenin</surname><given-names>MT</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>How humans reach: distinct cortical systems for central and peripheral vision</article-title><source>The Neuroscientist</source><volume>13</volume><fpage>22</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1177/1073858406295688</pub-id><pub-id pub-id-type="pmid">17229972</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crammond</surname><given-names>DJ</given-names></name><name><surname>Kalaska</surname><given-names>JF</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Prior information in motor and premotor cortex: activity during the delay period and effect on pre-movement activity</article-title><source>Journal of Neurophysiology</source><volume>84</volume><fpage>986</fpage><lpage>1005</lpage><pub-id pub-id-type="doi">10.1152/jn.2000.84.2.986</pub-id><pub-id pub-id-type="pmid">10938322</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diamond</surname><given-names>JS</given-names></name><name><surname>Wolpert</surname><given-names>DM</given-names></name><name><surname>Flanagan</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Rapid target foraging with reach or gaze: The hand looks further ahead than the eye</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005504</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005504</pub-id><pub-id pub-id-type="pmid">28683138</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diedrichsen</surname><given-names>J</given-names></name><name><surname>Hazeltine</surname><given-names>E</given-names></name><name><surname>Kennerley</surname><given-names>S</given-names></name><name><surname>Ivry</surname><given-names>RB</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Moving to directly cued locations abolishes spatial interference during bimanual actions</article-title><source>Psychological Science</source><volume>12</volume><fpage>493</fpage><lpage>498</lpage><pub-id pub-id-type="doi">10.1111/1467-9280.00391</pub-id><pub-id pub-id-type="pmid">11760137</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elsayed</surname><given-names>GF</given-names></name><name><surname>Lara</surname><given-names>AH</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Reorganization between preparatory and movement population responses in motor cortex</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>13239</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms13239</pub-id><pub-id pub-id-type="pmid">27807345</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fusi</surname><given-names>S</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Rigotti</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Why neurons mix: high dimensionality for higher cognition</article-title><source>Current Opinion in Neurobiology</source><volume>37</volume><fpage>66</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2016.01.010</pub-id><pub-id pub-id-type="pmid">26851755</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glaser</surname><given-names>JI</given-names></name><name><surname>Perich</surname><given-names>MG</given-names></name><name><surname>Ramkumar</surname><given-names>P</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name><name><surname>Kording</surname><given-names>KP</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Population coding of conditional probability distributions in dorsal premotor cortex</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>1788</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-04062-6</pub-id><pub-id pub-id-type="pmid">29725023</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>González-Alvarez</surname><given-names>C</given-names></name><name><surname>Subramanian</surname><given-names>A</given-names></name><name><surname>Pardhan</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Reaching and grasping with restricted peripheral vision</article-title><source>Ophthalmic &amp; Physiological Optics</source><volume>27</volume><fpage>265</fpage><lpage>274</lpage><pub-id pub-id-type="doi">10.1111/j.1475-1313.2007.00476.x</pub-id><pub-id pub-id-type="pmid">17470239</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodman</surname><given-names>D</given-names></name><name><surname>Kelso</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Are movements prepared in parts? Not under compatible (naturalized) conditions</article-title><source>Journal of Experimental Psychology</source><volume>109</volume><fpage>475</fpage><lpage>495</lpage><pub-id pub-id-type="doi">10.1037/0096-3445.109.4.475</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>IS</given-names></name><name><surname>Wolpert</surname><given-names>DM</given-names></name><name><surname>Franklin</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The value of the follow-through derives from motor learning depending on future actions</article-title><source>Current Biology</source><volume>25</volume><fpage>397</fpage><lpage>401</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2014.12.037</pub-id><pub-id pub-id-type="pmid">25578907</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Cortical activity in the null space: permitting preparation without movement</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>440</fpage><lpage>448</lpage><pub-id pub-id-type="doi">10.1038/nn.3643</pub-id><pub-id pub-id-type="pmid">24487233</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kornysheva</surname><given-names>K</given-names></name><name><surname>Bush</surname><given-names>D</given-names></name><name><surname>Meyer</surname><given-names>SS</given-names></name><name><surname>Sadnicka</surname><given-names>A</given-names></name><name><surname>Barnes</surname><given-names>G</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neural competitive queuing of ordinal structure underlies skilled sequential action</article-title><source>Neuron</source><volume>101</volume><fpage>1166</fpage><lpage>1180</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.01.018</pub-id><pub-id pub-id-type="pmid">30744987</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lashley</surname><given-names>KS</given-names></name></person-group><year iso-8601-date="1951">1951</year><source>The Problem of Serial Order in Behavior</source><publisher-name>Bobbs-Merrill</publisher-name></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McPeek</surname><given-names>RM</given-names></name><name><surname>Skavenski</surname><given-names>AA</given-names></name><name><surname>Nakayama</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Concurrent processing of saccades in visual search</article-title><source>Vision Research</source><volume>40</volume><fpage>2499</fpage><lpage>2516</lpage><pub-id pub-id-type="doi">10.1016/s0042-6989(00)00102-4</pub-id><pub-id pub-id-type="pmid">10915889</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McPeek</surname><given-names>RM</given-names></name><name><surname>Keller</surname><given-names>EL</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Superior colliculus activity related to concurrent processing of saccade goals in a visual search task</article-title><source>Journal of Neurophysiology</source><volume>87</volume><fpage>1805</fpage><lpage>1815</lpage><pub-id pub-id-type="doi">10.1152/jn.00501.2001</pub-id><pub-id pub-id-type="pmid">11929902</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patla</surname><given-names>AE</given-names></name><name><surname>Vickers</surname><given-names>JN</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>How far ahead do we look when required to step on specific locations in the travel path during locomotion?</article-title><source>Experimental Brain Research</source><volume>148</volume><fpage>133</fpage><lpage>138</lpage><pub-id pub-id-type="doi">10.1007/s00221-002-1246-y</pub-id><pub-id pub-id-type="pmid">12478404</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Popp</surname><given-names>NJ</given-names></name><name><surname>Hernandez-Castillo</surname><given-names>CR</given-names></name><name><surname>Gribble</surname><given-names>PL</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>The role of feedback in the production of skilled finger sequences</article-title><source>Journal of Neurophysiology</source><volume>127</volume><fpage>829</fpage><lpage>839</lpage><pub-id pub-id-type="doi">10.1152/jn.00319.2021</pub-id><pub-id pub-id-type="pmid">35235441</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pruszynski</surname><given-names>JA</given-names></name><name><surname>Omrani</surname><given-names>M</given-names></name><name><surname>Scott</surname><given-names>SH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Goal-dependent modulation of fast feedback responses in primary motor cortex</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>4608</fpage><lpage>4617</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4520-13.2014</pub-id><pub-id pub-id-type="pmid">24672006</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramkumar</surname><given-names>P</given-names></name><name><surname>Acuna</surname><given-names>DE</given-names></name><name><surname>Berniker</surname><given-names>M</given-names></name><name><surname>Grafton</surname><given-names>ST</given-names></name><name><surname>Turner</surname><given-names>RS</given-names></name><name><surname>Kording</surname><given-names>KP</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Chunking as the result of an efficiency computation trade-off</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>12176</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms12176</pub-id><pub-id pub-id-type="pmid">27397420</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rayner</surname><given-names>K</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Eye movements in reading and information processing: 20 years of research</article-title><source>Psychological Bulletin</source><volume>124</volume><fpage>372</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.1037/0033-2909.124.3.372</pub-id><pub-id pub-id-type="pmid">9849112</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigotti</surname><given-names>M</given-names></name><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Warden</surname><given-names>MR</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The importance of mixed selectivity in complex cognitive tasks</article-title><source>Nature</source><volume>497</volume><fpage>585</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1038/nature12160</pub-id><pub-id pub-id-type="pmid">23685452</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Säfström</surname><given-names>D</given-names></name><name><surname>Johansson</surname><given-names>RS</given-names></name><name><surname>Flanagan</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Gaze behavior when learning to link sequential action phases in a manual task</article-title><source>Journal of Vision</source><volume>14</volume><elocation-id>3</elocation-id><pub-id pub-id-type="doi">10.1167/14.4.3</pub-id><pub-id pub-id-type="pmid">24695992</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shahbazi</surname><given-names>M</given-names></name><name><surname>Ariani</surname><given-names>G</given-names></name><name><surname>Kashefi</surname><given-names>M</given-names></name><name><surname>Pruszynski</surname><given-names>JA</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Neural correlates of online action preparation</article-title><source>The Journal of Neuroscience</source><volume>44</volume><elocation-id>e1880232024</elocation-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1880-23.2024</pub-id><pub-id pub-id-type="pmid">38641408</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sivak</surname><given-names>B</given-names></name><name><surname>MacKenzie</surname><given-names>CL</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Integration of visual information and motor output in reaching and grasping: the contributions of peripheral and central vision</article-title><source>Neuropsychologia</source><volume>28</volume><fpage>1095</fpage><lpage>1116</lpage><pub-id pub-id-type="doi">10.1016/0028-3932(90)90143-c</pub-id><pub-id pub-id-type="pmid">2267060</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Snyder</surname><given-names>KM</given-names></name><name><surname>Logan</surname><given-names>GD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The problem of serial order in skilled typing</article-title><source>Journal of Experimental Psychology. Human Perception and Performance</source><volume>40</volume><fpage>1697</fpage><lpage>1717</lpage><pub-id pub-id-type="doi">10.1037/a0037199</pub-id><pub-id pub-id-type="pmid">24979360</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zimnik</surname><given-names>AJ</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Independent generation of sequence elements by motor cortex</article-title><source>Nature Neuroscience</source><volume>24</volume><fpage>412</fpage><lpage>424</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00798-5</pub-id><pub-id pub-id-type="pmid">33619403</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.94485.3.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Gallego</surname><given-names>Juan Alvaro</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Imperial College London</institution><country>United Kingdom</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Compelling</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>This study presents an <bold>important</bold> set of results illuminating how movement sequences are planned. Using several different behavioural manipulations and analysis methods, the authors present <bold>compelling</bold> evidence that multiple future movements are planned simultaneously with execution, and that these future movement plans influence each other. The work will be of great interest to those studying motor control.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.94485.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Mehrdad Kashefi et al. investigated the availability of planning future reaches while simultaneously controlling the execution of the current reach. Through a series of experiments employing a novel sequential arm reaching paradigm they developed, the authors made several findings: (1) participants demonstrate the capability to plan future reaches in advance, thereby accelerating the execution of the reaching sequence, (2) planning processes for future movements are not independent one another, however, it's not a single chunk neither, (3) Interaction among these planning processes optimizes the current movement for the movement that comes after for it.</p><p>The question of this paper is very interesting, and the conclusions of this paper are well supported by data.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.94485.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>In this work, Kashefi et al. investigate the planning of sequential reaching movements and how the additional information about future reaches affects planning and execution. This study, carried out with human subjects, extends a body of research in sequential movements to ask important questions: How many future reaches can you plan in advance? And how do those future plans interact with each other?</p><p>The authors designed several experiments to address these questions, finding that information about future targets makes reaches more efficient in both timing and path curvature. Further, with some clever target jump manipulations, the authors show that plans for a distant future reach can influence plans for a near future reach, suggesting that the planning for multiple future reaches is not independent. Lastly, the authors show that information about future targets is acquired parafoveally--that is, subjects tend to fixate mainly on the target they are about to reach to, acquiring future target information by paying attention to targets outside the fixation point.</p><p>The study opens up exciting questions about how this kind of multi-target planning is implemented in the brain. As the authors note in the manuscript, previous work in monkeys showed that preparatory neural activity for a future reaching movement can occur simultaneously with a current reaching movement, but that study was limited to the monkey only knowing about two future targets. It would be quite interesting to see how neural activity partitions preparatory activity for a third future target, given that this study shows that the third target's planning may interact with the second target's planning.</p><p>[Editors' note: The authors fully addressed the reviewers' comments on the original manuscript.]</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.94485.3.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Kashefi</surname><given-names>Mehrdad</given-names></name><role specific-use="author">Author</role><aff><institution>Western University</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Reschechtko</surname><given-names>Sasha</given-names></name><role specific-use="author">Author</role><aff><institution>San Diego State University</institution><addr-line><named-content content-type="city">San Diego</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Ariani</surname><given-names>Giacomo</given-names></name><role specific-use="author">Author</role><aff><institution>Western University</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Shahbazi</surname><given-names>Mahdiyar</given-names></name><role specific-use="author">Author</role><aff><institution>Western University</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Tan</surname><given-names>Alice</given-names></name><role specific-use="author">Author</role><aff><institution>Western University</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Diedrichsen</surname><given-names>Jörn</given-names></name><role specific-use="author">Author</role><aff><institution>Western University</institution><addr-line><named-content content-type="city">London, ON</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Pruszynski</surname><given-names>J Andrew</given-names></name><role specific-use="author">Author</role><aff><institution>Western University</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>Canada</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1:</bold></p><p>Mehrdad Kashefi et al. investigated the availability of planning future reaches while simultaneously controlling the execution of the current reach. Through a series of experiments employing a novel sequential arm reaching paradigm they developed, the authors made several findings: (1) participants demonstrate the capability to plan future reaches in advance, thereby accelerating the execution of the reaching sequence, (2) planning processes for future movements are not independent one another, however, it's not a single chunk neither, (3) Interaction among these planning processes optimizes the current movement for the movement that comes after for it.</p><p>The question of this paper is very interesting, and the conclusions of this paper are well supported by data. However, certain aspects require further clarification and expansion.</p></disp-quote><p>We thank reviewer one for their evaluation of the work.</p><disp-quote content-type="editor-comment"><p>(1) The question of this study is whether future reach plans are available during an ongoing reach. In the abstract, the authors summarized that &quot;participants plan at least two future reaches simultaneously with an ongoing reach and that the planning processes of the two future reaches are not independent of one another&quot; and showed the evidence in the next sentences. However the evidence is about the relationship about ongoing reach and future plans but not about in between future plans (Line 52-55). But the last sentence (Line 55-58) mentioned about interactions between future plans only. There are some discrepancies between sentences. Could you make the abstract clear by mentioning interference between (1) ongoing movement and future plans and (2) in between future plans?</p></disp-quote><p>We thank Reviewer for their comment. We have separated the longer sentence in the original abstract into two shorter ones. This should clarify that the two pieces of evidence pertain to the interaction of planning processes.</p><disp-quote content-type="editor-comment"><p>(2) I understood the ongoing reach and future reaches are not independent from the results of first experiment (Figure 2). A target for the current reach is shown at Horizon 1, on the other hand, in Horizon 2, a current and a future target are shown on the screen. Inter-reach-interval was significantly reduced from H1 to H2 (Figure 2). The authors insist that &quot;these results suggest that participants can plan two targets (I guess +1 and +2) ahead of the current reach (I guess +0)&quot;. But I think these results suggest that participants can plan a target (+1) ahead of the current reach (+0) because participants could see the current (+0) and a future target (+1) in H2. Could the authors please clarify this point?</p></disp-quote><p>We thank Reviewer for raising this point. Our conclusion that “participants can plan two targets ahead of the current reach” is supported by the reduction in Inter-Response Interval (IRI) observed when comparing H2 to H3 in the 75 ms Dwell time condition. Specifically, on average, participants were 16 ms faster when they could see two future targets on the screen (H3) than when they could see only one (H2). To clarify this in the paper, we have revised the wording in line 124 to explicitly state that the conclusion pertains to the 75 ms Dwell time condition. Additionally, we emphasize that the strongest evidence for planning two future targets comes from the experiment shown in Figure 3.</p><disp-quote content-type="editor-comment"><p>(3) Movement correction for jump of the +1 target takes longer time in H3 compared to H2 (Figure 4). Does this perturbation have any effect on reaching for +2 target? If the +1 jump doesn't affect reaching for +2 target, combined with the result that jump of the +2 target didn't affect the movement time of +1 target (Figure 3C), perturbation (target jump) only affects the movement directly perturbed. Is this implementation correct? If so, does these results support to decline future reaches are planned as motor chunk? I would like to know the author's thoughts about this.</p></disp-quote><p>In the experiment presented in Figure 4, once we jumped the +1 target, the reach to that target was changed and participants replaned a corrective movement to the new location of the +1 target. This usually was followed by a longer-than-usual pause at the new location of +1 target for resuming the sequence and finishing the trial. Consequently, in these jump trials, it was impossible to compare the +2 reach to no-jump trials, as the normal sequence of movement was disrupted, and the reach to the +2 target originated from a different starting location. Nevertheless, we addressed the possibility that the two future reaches were planned as a chunk by the analysis shown in figure 5: There we showed that a displacement of the +2 target did not influence the reach to the +1 target, indicating that the movement plans could be updated independently.</p><disp-quote content-type="editor-comment"><p>(4) Any discussion about Saccade position (Figure 7)?</p></disp-quote><p>We thank reviewer 1 for this important comment. The following discussion section is added for the gaze position results.</p><p>In our sequence task, participants switched their gaze location only once per reach, suggesting that information about the location of the next target is perceived parafoveally (Figure 7A). This observation aligns with previous studies (Clavagnier et al., 2007; González-Alvarez et al., 2007; Sivak and MacKenzie, 1990) that found participants keep their visual attention on the current sequence item and can perceive the location of spatial targets even when foveal vision is occluded. However, when comparing gaze locations for conditions Horizon &gt;1, we observed that participants systematically biased their gaze location based on the sequence context. The gaze position shifted toward the next target, potentially allowing for more accurate location estimation (Figures 7C-D). Notably, changes in gaze location were observed even in Horizon 2, despite no changes in the curvature of hand movements in this horizon (Figure 6B). This suggests that information about the next target may first be available in the circuitry that controls eye movements and later in the cortical areas that control voluntary upper limb movements. Further control studies are required to investigate this hypothesis.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2:</bold></p><p>Summary:</p><p>In this work, Kashefi et al. investigate the planning of sequential reaching movements and how the additional information about future reaches affects planning and execution. This study, carried out with human subjects, extends a body of research in sequential movements to ask important questions: How many future reaches can you plan in advance? And how do those future plans interact with each other?</p><p>The authors designed several experiments to address these questions, finding that information about future targets makes reaches more efficient in both timing and path curvature. Further, with some clever target jump manipulations, the authors show that plans for a distant future reach can influence plans for a near future reach, suggesting that the planning for multiple future reaches is not independent. Lastly, the authors show that information about future targets is acquired parafoveally--that is, subjects tend to fixate mainly on the target they are about to reach to, acquiring future target information by paying attention to targets outside the fixation point.</p><p>The study opens up exciting questions about how this kind of multi-target planning is implemented in the brain. As the authors note in the manuscript, previous work in monkeys showed that preparatory neural activity for a future reaching movement can occur simultaneously with a current reaching movement, but that study was limited to the monkey only knowing about two future targets. It would be quite interesting to see how neural activity partitions preparatory activity for a third future target, given that this study shows that the third target's planning may interact with the second target's planning.</p><p>Strengths:</p><p>A major strength of this study is that the experiments and analyses are designed to answer complementary questions, which together form a relatively complete picture of how subjects act on future target information. This complete description of a complex behavior will be a boon to future work in understanding the neural control of sequential, compound movements.</p></disp-quote><p>We thank the reviewer for their thorough reading of our work.</p><disp-quote content-type="editor-comment"><p>Weaknesses:</p><p>I found no real glaring weaknesses with the paper, though I do wish that there had been some more discussion of what happens to planning with longer dwell times in target. In the later parts of the manuscript, the authors mention that the co-articulation result (where reaches are curved to make future target acquisition more efficient) was less evident for longer dwell times, likely because for longer dwell times, the subject needs to fully stop in target before moving to the next one. This result made me wonder if the future plan interaction effect (tested with the target jumps) would have been affected by dwell time. As far as I can tell, the target jump portion only dealt with the shorter dwell times, but if the authors had longer dwell time data for these experiments, I would appreciate seeing the results and interpretations.</p></disp-quote><p>We thank the reviewer for raising this point. In our time (Figure 2) and curvature analysis (Figure 6), we collected data with five levels of the horizon and three levels of dwell time to explore the space of parameters and to see if there is any interaction between dwell time and the horizon of planning the future targets. Apriori, we expected that the full stop in each target imposed by the 400 ms dwell time would be long enough to remove any effect of future targets on how the current move is executed. In line with our initial hypothesis, the systematic curvature of reaches based on the future target was smaller in longer dwell times (Figure 6E). Nevertheless, we observed a significant curvature even in 400 ms dwell time. Based on this observation, we expect running the jump experiments (Figures 4 and 5) in longer dwell times will lead to the same pattern of results but with a smaller effect size since longer dwells break the interdependence of sequence elements (Kalidindi &amp; Crevecoeur, 2023). In the end, for the jump experiments, we limited our experimental conditions to the fastest dwell time (75 ms dwell) since we were conceptually interested in situations where movements in the sequence are maximally dependent on each other.</p><disp-quote content-type="editor-comment"><p>Beyond this , the authors also mentioned in the results and discussion the idea of &quot;neural resources&quot; being assigned to replan movements, but it's not clear to me what this might actually mean concretely. I wonder if the authors have a toy model in mind for what this kind of resource reassignment could mean. I realize it would likely be quite speculative, but I would greatly appreciate a description or some sort of intuition if possible.</p></disp-quote><p>Our use of the term &quot;neural resources&quot; is inspired by classic psychology literature on how cognitive resources such as attention and working memory are divided between multiple sequence components. Early studies on working memory suggest that human participants can retain and manipulate a fixed number of abstract items in working memory (Miller, 1956). However, more recent literature postulates that a specific number of items does not limit working memory, rather, it is limited by a finite attentional resource that is softly allocated to task items.</p><p>Here we borrowed the same notion of soft distribution of resources for the preparation of multiple sequence items. A large portion of our observation in this paper and also previous work on sequence production can be explained by a simple model that assumes one central planning resource that is “softly” divided between sequence elements when participants see future items of the sequence (Author Response Image 1). The first sequence element receives the majority of the resources and is planned the most. The rest of the sequence receives the remaining planning resources in an exponentially decaying manner for preparation of the movement during the execution of the ongoing movement. Once the ongoing movement is over, the resource is then transferred to the next sequence item and this process is repeated until the sequence is over. Assignment of planning resources to future items explains why participants are faster when seeing future items (Figure 2). But this comes with a cost – if the ongoing movement is perturbed, the replanning process is delayed since some of the resources are occupied by future planning (Figure 4). This naturally leads to the question of how this resource allocation is implemented in neural tissue. To address this, we are conducting the same sequence task with the horizon in non-human primates (NHPs), and the investigation of these neural implementation questions will be the focus of future studies.</p><fig id="sa3fig1" position="float"><label>Author response image 1.</label><caption><title>Basic diagram showing a soft distribution of a limited planning resource.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94485-sa3-fig1-v1.tif"/></fig><disp-quote content-type="editor-comment"><p><bold>Recommendations for the author:</bold></p><p><bold>Reviewer #1</bold></p></disp-quote><p>We thank reviewer one for these comments regarding the clarity and consistency of figures and terminology.</p><disp-quote content-type="editor-comment"><p>(1) Figure 3. Are &quot;+1 Move&quot; in Fig. 3B and &quot;+ 1 Movement&quot; in Fig. 3C as same as &quot;E + 1&quot; in Fig. 3A? Also does &quot;Dwell&quot; in Fig. 3B mean same as &quot;+1 Dwell&quot; in Fig. 3C? Consistent terminology would help readers to understand the figure.</p></disp-quote><p>“+1 Move” in Figure 3B is the same as +1 movement in Figure 3C. “Dwell” in Figure 3B is the same as +1 Dwell in Figure 3C. We changed the figure for more consistency.</p><disp-quote content-type="editor-comment"><p>(2) Figure 3. A type in the second last line in the legend, &quot;pre-jump target for no-jump and jump and condition&quot;. The second &quot;and&quot; isn't necessary.</p></disp-quote><p>The typo is corrected. Thank you.</p><disp-quote content-type="editor-comment"><p>(3) Figure 4C. Is &quot;Movement time&quot; equivalent with &quot;E + 1&quot;?</p></disp-quote><p>“Movement time” is equivalent to E+1 only in no-jump conditions. When the jump occurs,</p><p>Movement time contains all the</p><disp-quote content-type="editor-comment"><p>(4) Figure 6B. Is the gray circle in between the graph and target positions there by mistake?</p></disp-quote><p>We fixed this typo. Thank you.</p><disp-quote content-type="editor-comment"><p>(5) Figure 6E. It's hard to distinguish H2-H5 from the color differences.</p></disp-quote><p>We changed the H5 to full white with a black stroke to improve the contrast. Thank you.</p><disp-quote content-type="editor-comment"><p>(6) Figure 7A. Blue dots are almost invisible.</p></disp-quote><p>We added a black stroke to blue circles for more visibility. Thank you.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2</bold></p><p>I found this manuscript to be engaging and well written--many of the questions I had while reading were answered promptly in the next section. As such, my comments are mostly minor and primarily geared towards improving clarity in the manuscript.</p><p>(1) One major recurring confusion I had while reading the manuscript was how to think about H1, H2, and H3. It was clearly explained in the text, and the explanations of the results were generally clear once I read through it all, but I found it strangely confusing at times when trying to interpret the figures for myself (e.g., in H2, 2 targets are on screen, but the second target can only be planned during the reach toward the first target). This confusion may just be me reading the manuscript over two days, but I wonder if it could be made clearer with some semantic iconography associated with each horizon added to the later figures alongside the H labels. As one option, perhaps the planning timeline part of Fig 1D could be simplified and shrunk down to make an icon for each horizon that clearly shows when planning overlaps for each horizon.</p></disp-quote><p>(Please see the response to point #2 below)</p><disp-quote content-type="editor-comment"><p>(2) Regarding Fig 1D: I like this figure, but it's unclear to me how the exact preparation and execution times are determined. Is this more of a general schematic of overlaps, or is there specific information about timing in here?</p></disp-quote><p>We thank reviewer 2 for their important feedback. The role of Figure 1D was to summarize the timing of the experiments for different horizons. That is, to clarify the relative timing of the targets appearing on the screen (shown with a small circle above the horizontal line) and targets being captured by participants (the ticks and their associated number on the line). Execution is shown as the time interval that the hand is moving between the targets and planning is the potential planning time for participants from the target appearing on the screen until initiation of the reach to that target. We added the relevant parts of Figure 1D to the subplots for each subsequent experiment, to summarize the timing of other experiments and their analyses. For the experiments with target jump, a small vertical arrow shows the time of the target jump relative to other events.</p><p>However, this figure will be less useful, if the connection between the timing dots and ticks is not communicated. We agree that in the original manuscript, this important figure was only briefly explained in the caption of Figure 1. We expanded the explanation in the caption of Figure 1 and referenced the dots and ticks in the main text.</p><disp-quote content-type="editor-comment"><p>(3) Fig 6B - for some reason I got confused here: I thought the central target in this figure was the start target, and it took me embarrassingly long to figure out that the green target was the start target. This is likely because I'm used to seeing center-out behavioral figures. Incidentally, I wasn't confused by 7c (in fact, seeing 7c is what made me understand 6b), so maybe the solution is to clearly mark a directionality to the reach trajectories, or to point an arrow at the green target like in previous figures. Also, the bottom left gray target in the figure blends into the graph on the left--I didn't notice it until rereading. Because there's white space between that target and the green one, it might be good to introduce some white space to separate the graph from the targets more. The target arrangement makes more sense in panel C, but by the time I got there, I had already been a bit confused.</p></disp-quote><p>Thanks for raising this point. As shown in Figure 6C, we used the reach to the +1 target for the curvature analysis. The confusion about Figure 6B is probably due to continuing the reach trajectories after the +1 target. That also explains why Figure 7C seemed more straightforward. To solve this issue we modified Figure 6B such that the reaches are shown with full opacity right until the +1 target and then shown with more transparency. We believe this change focuses the reader's attention to the reach initiated from the +0 target to the +1 target.</p><p>As for the gray target in Figure 6B, we originally had the gray target as it is a potential start location for the reach to the +0 target, and for having similar visuals between the plots. The gray target is now removed from Figure 6B.</p><disp-quote content-type="editor-comment"><p>(4) Line 253 - I'm not sure I understand the advantage over simple averaging that the authors mention here--would be nice to get a bit more intuition.</p></disp-quote><p>Thanks for raising this point. We used a two-factor model in our analysis, with each factor representing the angle of the last and next target, respectively. Both factors had five levels: -120, -60, 0, 60, and 120 degrees relative to the +1 reach. In a balanced two-factor design, where each combination of factor levels has an equal number of trials, using a linear model and simple averaging would yield equivalent results. However, when the number of trials for the combinations of the two factors is unbalanced, simple averaging can lead to misleading differences in the levels of the second factor. Additionally, the linear model allows us to investigate potential interactions between the two factors, which is not possible with simple averaging.</p><disp-quote content-type="editor-comment"><p>(5) Fig 7a - I would have liked to see the traces labeled in figure (i.e. hand trajectory vs. eye trajectory)</p></disp-quote><p>Hand and eye trajectories are now labeled in the figure.</p><disp-quote content-type="editor-comment"><p>(6) Fig 7c - very minor, but the hexagon of targets is rotated 30 degrees from all previous hexagons shown (also, this hex grid target arrangement can't lead to the trajectory shown in 7a, so it can't be that this was a different experimental grid). I'm guessing this was a simple oversight.</p></disp-quote><p>We used the same grid in the eye-tracking experiment. The targets are to visually match the previous plots. Thank you for raising this point.</p><p>Reference</p><p>Clavagnier, S., Prado, J., Kennedy, H., &amp; Perenin, M.-T. (2007). How humans reach: distinct cortical systems for central and peripheral vision. <italic>The Neuroscientist: A Review Journal Bringing Neurobiology, Neurology and Psychiatry</italic>, <italic>13</italic>(1), 22–27.</p><p>González-Alvarez, C., Subramanian, A., &amp; Pardhan, S. (2007). Reaching and grasping with restricted peripheral vision. <italic>Ophthalmic &amp; Physiological Optics: The Journal of the British College of Ophthalmic Opticians</italic>, <italic>27</italic>(3), 265–274.</p><p>Kalidindi, H. T., &amp; Crevecoeur, F. (2023). Task dependent coarticulation of movement sequences (p.2023.12.15.571847). https://doi.org/10.1101/2023.12.15.571847</p><p>Miller, G. A. (1956). The magical number seven plus or minus two: some limits on our capacity for processing information. <italic>Psychological Review, 63</italic>(2), 81–97.</p><p>Sivak, B., &amp; MacKenzie, C. L. (1990). Integration of visual information and motor output in reaching and grasping: the contributions of peripheral and central vision. <italic>Neuropsychologia</italic>, <italic>28</italic>(10), 1095–1116.</p></body></sub-article></article>