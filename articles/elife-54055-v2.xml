<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">54055</article-id><article-id pub-id-type="doi">10.7554/eLife.54055</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Human Biology and Medicine</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Combining magnetoencephalography with magnetic resonance imaging enhances learning of surrogate-biomarkers</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-166606"><name><surname>Engemann</surname><given-names>Denis A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7223-1014</contrib-id><email>denis-alexander.engemann@inria.fr</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-168211"><name><surname>Kozynets</surname><given-names>Oleh</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-168217"><name><surname>Sabbagh</surname><given-names>David</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-168213"><name><surname>Lemaître</surname><given-names>Guillaume</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-42419"><name><surname>Varoquaux</surname><given-names>Gael</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-1076-5122</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-168215"><name><surname>Liem</surname><given-names>Franziskus</given-names></name><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-168216"><name><surname>Gramfort</surname><given-names>Alexandre</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Université Paris-Saclay, Inria, CEA</institution><addr-line><named-content content-type="city">Palaiseau</named-content></addr-line><country>France</country></aff><aff id="aff2"><label>2</label><institution>Department of Neurology, Max Planck Institute for Human Cognitive and Brain Sciences</institution><addr-line><named-content content-type="city">Leipzig</named-content></addr-line><country>Germany</country></aff><aff id="aff3"><label>3</label><institution>Inserm, UMRS-942, Paris Diderot University</institution><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff4"><label>4</label><institution>Department of Anaesthesiology and Critical Care, Lariboisière Hospital, Assistance Publique Hôpitaux de Paris</institution><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff5"><label>5</label><institution>University Research Priority Program Dynamics of Healthy Aging, University of Zürich</institution><addr-line><named-content content-type="city">Zürich</named-content></addr-line><country>Switzerland</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Shackman</surname><given-names>Alexander</given-names></name><role>Reviewing Editor</role><aff><institution>University of Maryland</institution><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>de Lange</surname><given-names>Floris P</given-names></name><role>Senior Editor</role><aff><institution>Radboud University</institution><country>Netherlands</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>19</day><month>05</month><year>2020</year></pub-date><pub-date pub-type="collection"><year>2020</year></pub-date><volume>9</volume><elocation-id>e54055</elocation-id><history><date date-type="received" iso-8601-date="2019-11-29"><day>29</day><month>11</month><year>2019</year></date><date date-type="accepted" iso-8601-date="2020-05-09"><day>09</day><month>05</month><year>2020</year></date></history><permissions><copyright-statement>© 2020, Engemann et al</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Engemann et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-54055-v2.pdf"/><abstract><p>Electrophysiological methods, that is M/EEG, provide unique views into brain health. Yet, when building predictive models from brain data, it is often unclear how electrophysiology should be combined with other neuroimaging methods. Information can be redundant, useful common representations of multimodal data may not be obvious and multimodal data collection can be medically contraindicated, which reduces applicability. Here, we propose a multimodal model to robustly combine MEG, MRI and fMRI for prediction. We focus on age prediction as a surrogate biomarker in 674 subjects from the Cam-CAN dataset. Strikingly, MEG, fMRI and MRI showed additive effects supporting distinct brain-behavior associations. Moreover, the contribution of MEG was best explained by cortical power spectra between 8 and 30 Hz. Finally, we demonstrate that the model preserves benefits of stacking when some data is missing. The proposed framework, hence, enables multimodal learning for a wide range of biomarkers from diverse types of brain signals.</p></abstract><abstract abstract-type="executive-summary"><title>eLife digest</title><p>How old are you? What about your body, and your brain? People are used to answering this question by counting the years since birth. However, biological age could also be measured by looking at the integrity of the DNA in cells or by measuring the levels of proteins in the blood. Whether one goes by chronological age or biological age, each is simply an indicator of general health – but people with the same chronological age may have different biological ages, and vice versa.</p><p>There are different imaging techniques that can be used to study the brain. A method called MRI reveals the brain’s structure and the different types of tissue present, like white and grey matter. Functional MRIs (fMRIs for short) measure activity across different brain regions, while electrophysiology records electrical signals sent between neurons. Distinct features measured by all three techniques – MRI, fMRI and electrophysiology – have been associated with aging. For example, differences between younger and older people have been observed in the proportion of grey to white matter, the communication between certain brain regions, and the intensity of neural activity.</p><p>MRIs, with their anatomical detail, remain the go-to for predicting the biological age of the brain. Patterns of neuronal activity captured by electrophysiology also provide information about how well the brain is working. However, it remains unclear how electrophysiology could be combined with other brain imaging methods, like MRI and fMRI. Can data from these three techniques be combined to better predict brain age?</p><p>Engemann et al. designed a computer algorithm stacking electrophysiology data on top of MRI and fMRI imaging to assess the benefit of this three-pronged approach compared to using MRI alone. Brain scans from healthy people between 17 and 90 years old were used to build the computer model. The experiments showed that combining all three methods predicted brain age better. The predictions also correlated with the cognitive fitness of individuals. People whose brains were predicted to be older than their years tended to complain about the quality of their sleep and scored worse on memory and speed-thinking tasks.</p><p>Crucially, Engemann et al. tested how the algorithm would hold up if some data were missing. This can happen in clinical practice where some tests are required but not others. Positively, prediction was maintained even with incomplete data, meaning this could be a useful clinical tool for characterizing the brain.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>biomarker</kwd><kwd>aging</kwd><kwd>magnetic resonance imaging</kwd><kwd>magnetoencephalogrphy</kwd><kwd>oscillations</kwd><kwd>machine learning</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010663</institution-id><institution>H2020 European Research Council</institution></institution-wrap></funding-source><award-id>SLAB ERC-StG-676943</award-id><principal-award-recipient><name><surname>Gramfort</surname><given-names>Alexandre</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution>Inria</institution></institution-wrap></funding-source><award-id>Médecine Numérique 2018</award-id><principal-award-recipient><name><surname>Engemann</surname><given-names>Denis A</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001677</institution-id><institution>Inserm</institution></institution-wrap></funding-source><award-id>Médecine Numérique 2018</award-id><principal-award-recipient><name><surname>Engemann</surname><given-names>Denis A</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Predicting age jointly from multimodal brain images and electrophysiology with machine learning enhances detecting health issues and facets of cognitive decline.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Non-invasive electrophysiology assumes a unique role in clinical neuroscience. Magneto- and electophencephalography (M/EEG) have an unparalleled capacity for capturing brain rhythms without penetrating the skull. EEG is operated in a wide array of peculiar situations, such as surgery (<xref ref-type="bibr" rid="bib7">Baker et al., 1975</xref>), flying an aircraft (<xref ref-type="bibr" rid="bib101">Skov and Simons, 1965</xref>) or sleeping (<xref ref-type="bibr" rid="bib3">Agnew et al., 1966</xref>). Unlike EEG, MEG captures a more selective set of brain sources with greater spectral and spatial definition (<xref ref-type="bibr" rid="bib4">Ahlfors et al., 2010</xref>; <xref ref-type="bibr" rid="bib51">Hari et al., 2000</xref>). Yet, neither of them is optimal for isolating anatomical detail. Clinical practice in neurology and psychiatry, therefore, relies on additional neuroimaging modalities with enhanced spatial resolution such as magnetic resonance imaging (MRI), functional MRI (fMRI), or positron emission tomography (PET). Recently, machine learning has received significant interest in clinical neuroscience for its potential to predict from such heterogeneous multimodal brain data (<xref ref-type="bibr" rid="bib123">Woo et al., 2017</xref>). Unfortunately, the effectiveness of machine learning in psychiatry and neurology is constrained by the lack of large high-quality datasets (<xref ref-type="bibr" rid="bib123">Woo et al., 2017</xref>; <xref ref-type="bibr" rid="bib118">Varoquaux, 2017</xref>; <xref ref-type="bibr" rid="bib16">Bzdok and Yeo, 2017</xref>; <xref ref-type="bibr" rid="bib27">Engemann et al., 2018</xref>) and comparably limited understanding about the data generating mechanisms (<xref ref-type="bibr" rid="bib61">Jonas and Kording, 2017</xref>). This, potentially, limits the advantage of complex learning strategies proven successful in purely somatic problems (<xref ref-type="bibr" rid="bib30">Esteva et al., 2017</xref>; <xref ref-type="bibr" rid="bib124">Yoo et al., 2019</xref>; <xref ref-type="bibr" rid="bib89">Ran et al., 2019</xref>).</p><p>In clinical neuroscience, prediction can therefore be pragmatically approached with classical machine learning algorithms (<xref ref-type="bibr" rid="bib22">Dadi et al., 2019</xref>), expert-based feature engineering and increasing emphasis on surrogate tasks. Such tasks attempt to learn on abundant high-quality data an outcome that is not primarily interesting, to then exploit its correlation with the actual outcome of interest in small datasets. This problem is also known as transfer learning (<xref ref-type="bibr" rid="bib84">Pan and Yang, 2009</xref>) which, in its simplest form, is implemented by reusing predictions from a surrogate-marker model as predictors in the small dataset. Over the past years, predicting the age of a person from its brain data has crystalized as a surrogate-learning paradigm in neurology and psychiatry (<xref ref-type="bibr" rid="bib25">Dosenbach et al., 2010</xref>). First results suggest that the prediction error of models trained to learn age from brain data of healthy populations provides clinically relevant information (<xref ref-type="bibr" rid="bib21">Cole et al., 2018</xref>; <xref ref-type="bibr" rid="bib93">Ronan et al., 2016</xref>; <xref ref-type="bibr" rid="bib20">Cole et al., 2015</xref>) related to neurodegenerative anomalies, physical and cognitive decline (<xref ref-type="bibr" rid="bib65">Kaufmann et al., 2019</xref>). For simplicity, this characteristic prediction error is often referred to as the brain age delta Δ (<xref ref-type="bibr" rid="bib104">Smith et al., 2019</xref>). Can learning of such a surrogate biomarker be enhanced by combining expert-features from M/EEG, fMRI and MRI?</p><p>Research on aging has suggested important neurological group-level differences between young and elderly people: Studies have found alterations in grey matter density and volume, cortical thickness and fMRI-based functional connectivity, potentially indexing brain atrophy (<xref ref-type="bibr" rid="bib63">Kalpouzos et al., 2012</xref>) and decline-related compensatory strategies. Peak frequency and power drop in the alpha band (8–12 Hz), assessed by EEG, has been linked to aging-related slowing of cognitive processes, such as the putative speed of attention (<xref ref-type="bibr" rid="bib91">Richard Clark et al., 2004</xref>; <xref ref-type="bibr" rid="bib6">Babiloni et al., 2006</xref>). Increased anteriorization of beta band power (15–30 Hz) has been associated with effortful compensatory mechanisms (<xref ref-type="bibr" rid="bib45">Gola et al., 2013</xref>) in response to intensified levels of neural noise, that is, decreased temporal autocorrelation of the EEG signal as revealed by flatter 1/f slopes (<xref ref-type="bibr" rid="bib120">Voytek et al., 2015</xref>). Importantly, age-related variability in fMRI and EEG seems to be independent to a substantial degree (<xref ref-type="bibr" rid="bib69">Kumral et al., 2020</xref>).</p><p>The challenge of predicting at the single-subject level from such heterogenous neuroimaging modalities governed by distinct data-generating mechanisms has been recently addressed with model-stacking techniques (<xref ref-type="bibr" rid="bib88">Rahim et al., 2015</xref>; <xref ref-type="bibr" rid="bib64">Karrer et al., 2019</xref>; <xref ref-type="bibr" rid="bib75">Liem et al., 2017</xref>). <xref ref-type="bibr" rid="bib88">Rahim et al., 2015</xref> enhanced classification in Alzheimer’s disease by combining fMRI and PET using a stacking approach (<xref ref-type="bibr" rid="bib122">Wolpert, 1992</xref>), such that the stacked models used input data from different modalities. <xref ref-type="bibr" rid="bib75">Liem et al., 2017</xref> have then applied this approach to age-prediction and found that combining anatomical MRI with fMRI significantly helped reduce errors while facilitating detection of cognitive impairment. This suggests that stacked prediction might also enable combining MRI with electrophysiology. Yet, this idea faces one important obstacle related to the clinical reality of data collection. It is often not practical to do multimodal assessments for all patients. Scanners may be overbooked, patients may not be in the condition to undergo MRI and acute demand in intensive care units may dominate priorities. Incomplete and missing data is, therefore, inevitable and has to be handled to unleash the full potential of multimodal predictive models. To tackle this challenge, we set out to build a stacking model for predicting age from electrophysiology and MRI such that any subject was included if some data was available for at least one modality. We, therefore, call it opportunistic stacking model.</p><p>At this point, there are very few multimodal databases providing access to electrophysiology alongside MRI and fMRI. The Leipzig Mind-Brain-Body (LEMON) dataset (<xref ref-type="bibr" rid="bib5">Babayan et al., 2019</xref>) includes high-quality research-EEG with MRI and fMRI for 154 young subjects and 75 elderly subjects. The dataset used in the present study is curated by the Cam-CAN (<xref ref-type="bibr" rid="bib97">Shafto et al., 2014</xref>; <xref ref-type="bibr" rid="bib109">Taylor et al., 2017</xref>) and was specifically designed for studying the neural correlates of aging continuously across the life-span. The Cam-CAN dataset is currently the largest public resource on multimodal imaging with high-resolution electrophysiology in the form of MEG alongside MRI data and rich neuropsychological data for more than 650 healthy subjects between 17 and 90 years. The choice of MEG over EEG may lead to a certain degree of friction with the aging-related literature in electrophysiology, the bulk of which is based on EEG-studies. Fortunately, MEG and EEG share the same classes of neural generators, rendering the aging-related EEG-literature highly relevant for MEG-based modeling. On the other hand, the distinct biophysics of MEG and EEG makes both modalities complementary methods. While EEG captures sources of any orientation, MEG preferentially captures tangential but not radial sources. Compared to EEG, MEG benefits from the magnetic transparency of the skull, which facilitates source localization by reducing the risk of errors due to an incorrect head conductivity model, but also by limiting the large-scale mixing of neural sources. This significantly increases the signal-to-noise ratio for MEG in higher frequencies, rendering it a formidable technique for studying cortical oscillatory activity (<xref ref-type="bibr" rid="bib73">Lehtelä et al., 1997</xref>; <xref ref-type="bibr" rid="bib44">Gobbelé et al., 1998</xref>). MEG is, therefore, an interesting modality in its own right for developing neuro-cognitive biomarkers while its close link with EEG may potentially open the door to translatable electrophysiology markers suitable for massive deployment with clinical EEG.</p><p>Our study focuses on the following questions: 1) Can MRI-based prediction of age be enhanced with MEG-based electrophysiology? 2) Do fMRI and MEG carry non-redundant clinically relevant information? 3) What are the most informative electrophysiological markers of aging? 4) Can potential advantages of multimodal learning be maintained in the presence of missing values?</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Opportunistic prediction-stacking approach</title><p>We begin by summarizing the proposed method. To build a model for predicting age from electrophysiology, fMRI and anatomical MRI, we employed prediction-stacking (<xref ref-type="bibr" rid="bib122">Wolpert, 1992</xref>). As in <xref ref-type="bibr" rid="bib75">Liem et al., 2017</xref>, the stacked models, here, referred to different input data instead of alternative models on the same data. We used ridge regression (<xref ref-type="bibr" rid="bib56">Hoerl and Kennard, 1970</xref>) to linearly predict age from high-dimensional inputs of each modality. Linear predictions were based on distinct features from anatomical MRI, fMRI and MEG that have been commonly associated with aging. For extracting features from MEG, in a first step, we drew inspiration from EEG-literature on aging and considered evoked response latencies, alpha band peak frequency, 1/f slope topographies assessed in sensor-space. Previous work on neural development and aging (<xref ref-type="bibr" rid="bib67">Khan et al., 2018</xref>; <xref ref-type="bibr" rid="bib45">Gola et al., 2013</xref>) and Alzheimer’s disease (<xref ref-type="bibr" rid="bib40">Gaubert et al., 2019</xref>) has pointed at the importance of spatial alterations in stationary power spectra which can be exploited using high-dimensional regression techniques (<xref ref-type="bibr" rid="bib38">Fruehwirt et al., 2017</xref>). In this work, we have adapted this reasoning to the more general problem of predicting age while exploiting the advanced source-modeling options supported by the Cam-CAN dataset based on MEG and the individual MRIs. Therefore, it was our principal effort to expose the geometry of stationary power spectra with minimal distortion by using source localization based on the individual head geometry (<xref ref-type="bibr" rid="bib94">Sabbagh et al., 2019</xref>) to then perform high-dimensional regression. As a result, we predicted from the spatial distribution of power and bivariate interactions between signals (connectivity) in nine frequency bands (<xref ref-type="table" rid="table1">Table 1</xref>).</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Frequency band definitions.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>Name</th><th>Low</th><th><inline-formula><mml:math id="inf1"><mml:mi>δ</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf2"><mml:mi>θ</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf3"><mml:mi>α</mml:mi></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf4"><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf5"><mml:msub><mml:mi>β</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf6"><mml:msub><mml:mi>γ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf7"><mml:msub><mml:mi>γ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula></th><th><inline-formula><mml:math id="inf8"><mml:msub><mml:mi>γ</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:math></inline-formula></th></tr></thead><tbody><tr><td>range (Hz)</td><td>0.1 - 1.5</td><td>1.5 - 4</td><td>4 - 8</td><td>8 - 15</td><td>15 - 26</td><td>26 - 35</td><td>35 - 50</td><td>50 - 74</td><td>76 - 100</td></tr></tbody></table></table-wrap><p>For MRI and fMRI, we followed the method established in <xref ref-type="bibr" rid="bib75">Liem et al., 2017</xref> and included cortical thickness, cortical surface area and subcortical volume as well as functional connectivity based on the fMRI time-series. For detailed description of the features, see <xref ref-type="table" rid="table2">Table 2</xref> and section <italic>Feature extraction</italic> in Materials and methods. To correct for the necessarily biased linear model, we then used a non-linear random forest regressor with age predictions from the linear model as lower-dimensional input features.</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Summary of extracted features.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>#</th><th>Modality</th><th>Family</th><th>Input</th><th>Feature</th><th>Variants</th><th>Spatial selection</th></tr></thead><tbody><tr><td>1</td><td>MEG</td><td>sensor mixed</td><td>ERF</td><td>latency</td><td>aud, vis, audvis</td><td>max channel</td></tr><tr><td>2</td><td>…</td><td>…</td><td>PSDα</td><td>peak</td><td/><td>max channel</td></tr><tr><td>3</td><td>…</td><td>…</td><td>PSD</td><td>1/f slope</td><td>low, <inline-formula><mml:math id="inf9"><mml:mi mathsize="80%">γ</mml:mi></mml:math></inline-formula></td><td>max channel in ROI</td></tr><tr><td>4</td><td>…</td><td>source activity</td><td>signal</td><td>power</td><td>low,<inline-formula><mml:math id="inf10"><mml:mi mathsize="80%">δ</mml:mi></mml:math></inline-formula>,<inline-formula><mml:math id="inf11"><mml:mi mathsize="80%">θ</mml:mi></mml:math></inline-formula>,<inline-formula><mml:math id="inf12"><mml:mi mathsize="80%">α</mml:mi></mml:math></inline-formula>,<inline-formula><mml:math id="inf13"><mml:msub><mml:mi mathsize="80%">β</mml:mi><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mn mathsize="80%">2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf14"><mml:msub><mml:mi mathsize="80%">γ</mml:mi><mml:mrow><mml:mn mathsize="80%">1</mml:mn><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mn mathsize="80%">2</mml:mn><mml:mo mathsize="80%" stretchy="false">,</mml:mo><mml:mn mathsize="80%">3</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula></td><td>MNE, 448 ROIs</td></tr><tr><td>5</td><td>…</td><td>…</td><td>envelope</td><td>…</td><td>…</td><td>…</td></tr><tr><td>6</td><td>…</td><td>source connectivity</td><td>signal</td><td>covariance</td><td>…</td><td>…</td></tr><tr><td>7</td><td>…</td><td>…</td><td>envelope</td><td>…</td><td>…</td><td>…</td></tr><tr><td>8</td><td>…</td><td>…</td><td>env.</td><td>corr.</td><td>…</td><td>…</td></tr><tr><td>9</td><td>…</td><td>…</td><td>env.</td><td>corr. ortho.</td><td>…</td><td>…</td></tr><tr><td>10</td><td>fMRI</td><td>connectivity</td><td>time-series</td><td>correlation</td><td>…</td><td>256 ROIs</td></tr><tr><td>11</td><td>MRI</td><td>anatomy</td><td>volume</td><td>cortical thickness</td><td/><td>5124 vertices</td></tr><tr><td>12</td><td>…</td><td>…</td><td>surface</td><td>cortical surface area</td><td/><td>5124 vertices</td></tr><tr><td>13</td><td>…</td><td>…</td><td>volume</td><td>subcortical volumes</td><td/><td>66 ROIs</td></tr></tbody></table><table-wrap-foot><fn><p>Note. ERF = event related field, PSD = power spectral density, MNE = Minimum Norm-Estimates, ROI = region of interest, corr. = correlation, ortho. = orthogonalized.</p></fn></table-wrap-foot></table-wrap><p>Thereby, we made sure to use consistent cross-validation splits for all layers and automatically selected central tuning-parameters of the linear model and the random forest with nested cross-validation. Our stacked models handle missing values by treating missing value as data, provided there is an opportunity to see at least one modality (<xref ref-type="bibr" rid="bib62">Josse et al., 2019</xref>). We, therefore, call it opportunistic stacking model. Concretely, the procedure duplicated all variables and inserted once a small value and once a very large value where data was initially missing for which we chose biologically implausible age values of −1000 and 1000, respectively. For an illustration of the proposed model architecture, see <xref ref-type="fig" rid="fig1">Figure 1</xref> section <italic>Stacked-Prediction Model for Opportunistic Learning</italic> in Materials and methods for a detailed description of the model.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Opportunistic stacking approach.</title><p>The proposed method allows to learn from any case for which at least one modality is available. The stacking model first generates, separately for each modality, linear predictions of age for held-out data. 10-fold cross-validation with 10 repeats is used. This step, based on ridge regression, helps reduce the dimensionality of the data by generating predictions based on linear combinations of the major directions of variance within each modality. The predicted age is then used as derived set of features in the following steps. First, missing values are handled by a coding-scheme that duplicates the second-level data and substitutes missing values with arbitrary small and large numbers. A random forest model is then trained to predict the actual age with the missing-value coded age-predictions from each ridge model as input features. This potentially helps improve prediction performance by combining additive information and introducing non-linear regression on a lower-dimensional representation.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-54055-fig1-v2.tif"/></fig></sec><sec id="s2-2"><title>fMRI and MEG non-redundantly enhance anatomy-based prediction</title><p>Currently, anatomical MRI is the canonical modality for brain age prediction. However, MRI does not access brain dynamics, whereas MEG and fMRI both capture neuronal activity, hence, convey additional information at smaller time-scales. How would they add to the prediction of brain age when combined with anatomical MRI? <xref ref-type="fig" rid="fig2">Figure 2A</xref> depicts a model comparison in which anatomical MRI served as baseline and which tracked changes in performance as fMRI and MEG were both added through stacking (black boxplot). Anatomical MRI scored an expected generalization error of about 6 years (<inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>0.6</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>2.5</mml:mn><mml:mo>,</mml:mo><mml:mn>97.5</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>4.9</mml:mn><mml:mo>,</mml:mo><mml:mn>7.16</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>), whereas expected chance-level prediction was about 15.5 years (<inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>1.17</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>2.5</mml:mn><mml:mo>,</mml:mo><mml:mn>97.5</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>13.26</mml:mn><mml:mo>,</mml:mo><mml:mn>17.8</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>) based on a dummy-model proposing as prediction the average age of the training-data. MRI performed better than chance-level prediction in every single cross-validation fold. The average improvement over chance-level prediction across folds was at least 9 years (<inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>1.33</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>2.5</mml:mn><mml:mo>,</mml:mo><mml:mn>97.5</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mo>−</mml:mo><mml:mn>12.073</mml:mn><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mn>7.347</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>). Relative to MRI, age-prediction performance was reduced by almost 1 year on average by adding either MEG (<inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mo>&lt;</mml:mo><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>91</mml:mn><mml:mi mathvariant="normal">%</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>0.79</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>0.57</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>2.5</mml:mn><mml:mo>,</mml:mo><mml:mn>97.5</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mo>−</mml:mo><mml:mn>1.794</mml:mn><mml:mo>,</mml:mo><mml:mn>0.306</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>) or fMRI (<inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mo>&lt;</mml:mo><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>94</mml:mn><mml:mi mathvariant="normal">%</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>0.96</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>0.59</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>2.5</mml:mn><mml:mo>,</mml:mo><mml:mn>97.5</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mo>−</mml:mo><mml:mn>1.99</mml:mn><mml:mo>,</mml:mo><mml:mn>0.15</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>). Finally, the performance gain was greater than 1 year on average (<inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mo>&lt;</mml:mo><mml:mi>M</mml:mi><mml:mi>R</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>99</mml:mn><mml:mi mathvariant="normal">%</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>1.32</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>0.672</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>2.5</mml:mn><mml:mo>,</mml:mo><mml:mn>97.5</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mo>−</mml:mo><mml:mn>2.43</mml:mn><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mn>0.16</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>) when adding both MEG and fMRI to the model, yielding an expected generalization error of about 4.7 years (<inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>0.55</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>2.5</mml:mn><mml:mo>,</mml:mo><mml:mn>97.5</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>3.77</mml:mn><mml:mo>,</mml:mo><mml:mn>5.74</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>). Note that dependable numerical p-values are hard to obtain for paired model comparisons based on cross-validation on the same dataset: Many datasets equivalent to the Cam-CAN would be required. Nevertheless, the uncertainty intervals extracted from the cross-validation distribution suggests that the observed differences in performance were systematic and can be expected to generalize as more data is analyzed. Moreover, the out-of-sample ranking between the different models was stable over cross-validation folds (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>) with the full model achieving the first rank 71/100 times and performing at least 80/100 better than the MRI + fMRI or the MRI + MEG model. This emphasizes that the relative importance of MEG and fMRI for enhancing MRI-based prediction of age can be expected to generalize to future data.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Combining MEG and fMRI with MRI enhances age-prediction.</title><p>(<bold>A</bold>) We performed age-prediction based on distinct input-modalities using anatomical MRI as baseline. Boxes and dots depict the distribution of fold-wise paired differences between stacking with anatomical MRI (blue), functional modalities, that is fMRI (yellow) and MEG (green) and complete stacking (black). Each dot shows the difference from the MRI testing-score at a given fold (10 folds × 10 repetitions). Boxplot whiskers indicate the area including 95% of the differences. fMRI and MEG show similar improvements over purely anatomical MRI around 0.8 years of error. Combining all modalities reduced the error by more than one year on average. (<bold>B</bold>) Relationship between prediction errors from fMRI and MEG. Left: unimodal models. Right: models including anatomical MRI. Here, each dot stands for one subject and depicts the error of the cross-validated prediction (10 folds) averaged across the 10 repetitions. The actual age of the subject is represented by the color and size of the dots. MEG and fMRI errors were only weakly associated. When anatomy was excluded, extreme errors occurred in different age groups. The findings suggest that fMRI and MEG conveyed non-redundant information. For additional details, please consider our supplementary findings.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-54055-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Rank statistics.</title><p>Rank statistics for multimodal stacking models. (<bold>A</bold>) depicts rankings over cross-validation testing splits for the six stacking models and the chance-level estimator. The ranking was overall stable with perfect separation from chance and top-rankings predominantly occupied by the multimodal stacking model. (<bold>B</bold>) Matrix of pairwise rank frequencies. The values indicate how many times the row-item ranked better than the column-item. For example, all models ranked 100/100 times better than chance (right-most column) and the full model ranked 82/100 times better than MRI + fMRI (row 1 from bottom, column 2 from left), 86/100 better than MRI + MEG (row 1 from bottom, column 3 from left), which in turn ranked 91/100 better than MRI (row 3 from bottom, column 4 from left).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-54055-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Partial dependence.</title><p>Two-dimensional partial-dependence analysis for 6 top-important stacking inputs. This analysis demonstrates, intuitively, how stacked predictions change as the input predictions from different modalities into the stacking layer change, two at a time. The x and y axes depict the empirical value range of the age inputs (CrtT = cortical thickness, SbcV = subcortical volume). The color and contours show the resulting output prediction of the stacking model. Additive patterns dominated, suggesting independent contributions of MEG and fMRI with little evidence for interaction effects. It is noteworthy that the range of output ages was somewhat wider when the age input from fMRI was manipulated, suggesting that the model trusted fMRI more than MEG.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-54055-fig2-figsupp2-v2.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>Relationship between predication performance and age.</title><p>Breakdown of prediction error across age by stacking model. It is a common characteristic of regression models for prediction of brain age to show systematically increased very old or young sub-populations (<xref ref-type="bibr" rid="bib104">Smith et al., 2019</xref>; <xref ref-type="bibr" rid="bib71">Le et al., 2018</xref>), hence, referred to as brain age bias. Could the enhanced performance of the full stacking model possibly go along with reduced brain age bias or is the improvement uniform across age groups? To investigate the mechanism of action of the stacking-method, we visualized the subject-wise prediction errors across age. The upper row shows unimodal models, the lower row multimodal ones. The average trend is depicted by a regression line obtained from locally estimated scatter plot smoothing (LOESS, degree 2). One can see that the overall shape of the error distributions are similar with increasing errors in young and old subjects. This tendency seemed more pronounced for the single-modality MEG models showing more extreme errors, especially in young and old sub-populations. Overall, the multimodal models (bottom-row) made visibly fewer errors beyond 15 years of MAE (y-axis), suggesting that, in this dataset, improvements of stacking were predominantly uniform across age. These impressions can be formalized with an ANOVA model of log-error by family and age group (7 approximately equally sized groups) suggesting a main-effect of age group (<inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>6</mml:mn><mml:mo>,</mml:mo><mml:mn>3174</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>8.362</mml:mn><mml:mo>,</mml:mo><mml:mn>5.13</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>09</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>), a main effect of family (<inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>F</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>3174</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>12.938</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1.75</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>12</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>) and an interaction effect (<inline-formula><mml:math id="inf37"><mml:mrow><mml:mrow><mml:mrow><mml:mi>F</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>30</mml:mn><mml:mo>,</mml:mo><mml:mn>3174</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1.740</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.008</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). However, such statistical inference has to be treated with caution as the cross-validated predictions made by the models are not necessarily statistically independent.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-54055-fig2-figsupp3-v2.tif"/></fig></fig-group><p>The improved prediction obtained by combining MEG and fMRI suggests that both modalities carry independent information. If MEG and MRI carried purely redundant information, the random forest algorithm would not have reached better out-of-sample performance. Indeed, comparing the cross-validated prediction errors of MEG-based and fMRI-based models (<xref ref-type="fig" rid="fig2">Figure 2B</xref>), errors were only weakly correlated (<inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.139</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.019</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1.31</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>). fMRI, sometimes, made extreme errors for cases better predicted by MEG in younger people, whereas MEG made errors in distinct cases from young and old age groups. When adding anatomical MRI to each model, the errors became somewhat more dependent leading to moderate correlation (<inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.45</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.20</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>2.2</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>16</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>). This additive component also became apparent when considering predictive simulations on how the model actually combined MEG, fMRI and MRI (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>) using two-dimensional partial dependence analysis (<xref ref-type="bibr" rid="bib64">Karrer et al., 2019</xref>; <xref ref-type="bibr" rid="bib52">Hastie et al., 2005</xref>, chapter 10.13.2). Moreover, exploration of the age-dependent improvements through stacking suggest that stacking predominantly reduced prediction errors uniformly (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>) instead of systematically mitigating brain age bias (<xref ref-type="bibr" rid="bib71">Le et al., 2018</xref>; <xref ref-type="bibr" rid="bib104">Smith et al., 2019</xref>).</p><p>These findings demonstrate that stacking allows to enhance brain-age prediction by extracting information from MEG, fMRI and MRI while mitigating modality-specific errors. This raises the question whether this additive information from multiple neuroimaging modalities also implies non-redundant associations with behavior and cognition.</p></sec><sec id="s2-3"><title>Brain age Δ learnt from MEG and fMRI indexes distinct cognitive functions</title><p>The brain ageΔ has been interpreted as indicator of health where positive Δ has been linked to reduced fitness or health-outcomes (<xref ref-type="bibr" rid="bib20">Cole et al., 2015</xref>; <xref ref-type="bibr" rid="bib21">Cole et al., 2018</xref>). Does improved performance through stacking strengthen effect-sizes? Can MEG and fMRI help detect complementary associations? <xref ref-type="fig" rid="fig3">Figure 3</xref> summarizes linear correlations between the brain ageΔ and the 38 neuropsychological scores after projecting out the effect of age, <xref ref-type="disp-formula" rid="equ8">Equations 6- 8</xref> (see <italic>Analysis of brain-behavior correlation</italic> in Materials and methods for a detailed overview). As effect sizes can be expected to be small in the curated and healthy population of the Cam-CAN dataset, we considered classical hypothesis testing for characterizing associations. Traditional significance testing (<xref ref-type="fig" rid="fig3">Figure 3A</xref>) suggests that the best stacking models supported discoveries for between 20% (7) and 25% (9) of the scores. Dominating associations concerned fluid intelligence, depression, sleep quality (PSQI), systolic and diastolic blood pressure (cardiac features 1,2), cognitive impairment (MMSE) and different types of memory performance (VSTM, PicturePriming, FamousFaces, EmotionalMemory). The model coefficients in <xref ref-type="fig" rid="fig3">Figure 3B</xref> depict the strength and direction of association. One can see that stacking models not only tended to suggest more discoveries as their performance improved but also led to stronger effect sizes. However, the trend is not strict as fMRI seemed to support unique discoveries that disappeared when including the other modalities. Similarly, some effect sizes were even slightly stronger in sub-models, for example for fluid intelligence in MRI and MEG. A priori, the full model enjoys priority over the sub-models as its expected generalization estimated with cross-validation was lower. This could imply that some of the discoveries suggested by fMRI may suffer from overfitting, but are finally corrected by the full model. Nevertheless, many of the remaining associations were found by multiple methods (e.g. fluid intelligence, sleep quality assessed by PSQI) whereas others were uniquely contributed by fMRI (e.g. depression). It is also noteworthy that the directions of the effects were consistent with the predominant interpretation of the brain age Δ as indicator of mental or physical fitness (note that high PSQI score indicate sleeping difficulties whereas lower MMSE scores indicate cognitive decline) and directly confirm previous findings (<xref ref-type="bibr" rid="bib75">Liem et al., 2017</xref>; <xref ref-type="bibr" rid="bib104">Smith et al., 2019</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Residual correlation between brain ageΔ and neuropsycholgical assessment.</title><p>(<bold>A</bold>) Manhattan plot for linear fits of 38 neuropsychology scores against brain ageΔ from different models (see scores for <xref ref-type="table" rid="table5">Table 5</xref>). Y-axis: <inline-formula><mml:math id="inf44"><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mn>10</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. X-axis: individual scores, grouped and colored by stacking model. Arbitrary jitter is added along the x-axis to avoid overplotting. For convenience, we labeled the top scores, arbitrarily thresholded by the uncorrected 5% significance level, indicated by pyramids. For orientation, traditional 5%, 1% and 0.1% significance levels are indicated by solid, dashed and dotted lines, respectively. (<bold>B</bold>) Corresponding standardized coefficients of each linear model (y-axis). Identical labeling as in (<bold>A</bold>). One can see that, stacking often improved effect sizes for many neuropsychological scores and that different input modalities show complementary associations. For additional details, please consider our supplementary findings.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-54055-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Results based on joint deconfounding.</title><p>Association between brain age Δ and neuropsychological assessments based on joint confounding for age through multiple regression.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-54055-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Results based on joint deconfounding with additional regressors of non-interest.</title><p>Association between brain age Δ and neuropsychological assessments based on joint confounding for age, gender, handedness and motion through multiple regression.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-54055-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Distribution of neuropsychological scores by age.</title><p>Neuropsychological scores across lifespan.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-54055-fig3-figsupp3-v2.tif"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 4.</label><caption><title>Distribution of neuropsychological scores by age after residualizing.</title><p>Neuropsychological scores across lifespan after residualizing for age with polynomial regression (third degree).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-54055-fig3-figsupp4-v2.tif"/></fig><fig id="fig3s5" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 5.</label><caption><title>Bootstrap estimates.</title><p>Residual correlation between brain ageΔ and neuropsycholgical assessment. The x-axis depicts the coefficients from univariate regression models. Uncertainty intervals are obtained from non-parametric bootstrap estimates with 2000 iterations.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-54055-fig3-figsupp5-v2.tif"/></fig></fig-group><p>Note that the results were highly similar when performing deconfounding jointly via multiple regression (<xref ref-type="disp-formula" rid="equ9">Equation 9</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>) instead of predicting age-residualized neuropsychological scores, and when including additional predictors of non-interest, that is gender, handedness and head motion (<xref ref-type="disp-formula" rid="equ10">Equation 10</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). More elaborate confounds-modeling even seemed to improve SNR as suggested by an increasing number of discoveries and growing effect sizes.</p><p>These findings suggest that brain age Δ learnt from fMRI or MEG carries non-redundant information on clinically relevant markers of cognitive health and that combining both fMRI and MEG with anatomy can help detect health-related issues in the first place. This raises the question of what aspect of the MEG signal contributes most.</p></sec><sec id="s2-4"><title>MEG-based age-prediction is explained by source power</title><p>Whether MEG or EEG-based assessment is practical in the clinical context depends on the predictive value of single features, the cost for obtaining predictive features and the potential benefit of improving prediction by combining multiple features. Here, we considered purely MEG-based age prediction to address the following questions: Can the stacking method be helpful to analyze the importance of MEG-specific features? Are certain frequency bands of dominating importance? Is information encoded in the regional power distribution or more related to neuronal interactions between brain regions? <xref ref-type="fig" rid="fig4">Figure 4A</xref> compares alternative MEG-based models stacking different combinations of MEG-features. We compared models against chance-level prediction as estimated with a mean-regressor outputting the average age of the training data as prediction. Again, chance-level was distributed around 15.5 years (<inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>1.17</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>2.5</mml:mn><mml:mo>,</mml:mo><mml:mn>97.5</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>13.26</mml:mn><mml:mo>,</mml:mo><mml:mn>17.80</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>). All models performed markedly better. The model based on diverse sensor space features from task and resting state recordings showed the lowest performance around 12 years MAE (<inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>1.04</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>2.5</mml:mn><mml:mo>,</mml:mo><mml:mn>97.5</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>9.80</mml:mn><mml:mo>,</mml:mo><mml:mn>13.52</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>), yet it was systematically better than chance (<inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mo>&lt;</mml:mo><mml:mi>C</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>98.00</mml:mn><mml:mi mathvariant="normal">%</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>1.64</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>2.5</mml:mn><mml:mo>,</mml:mo><mml:mn>97.5</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mo>−</mml:mo><mml:mn>7.11</mml:mn><mml:mo>,</mml:mo><mml:mo>−</mml:mo><mml:mn>0.44</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>). All models featuring source-level power spectra or connectivity (‘Source Activity, Source Connectivity’) performed visibly better, with expected errors between 8 and 6.5 years and no overlap with the distribution of chance-level scores. Models based on source-level power spectra (‘Source Activity’, <inline-formula><mml:math id="inf53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>7.40</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>0.82</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>2.5</mml:mn><mml:mo>,</mml:mo><mml:mn>97.5</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>6.01</mml:mn><mml:mo>,</mml:mo><mml:mn>9.18</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>) and connectivity (‘Source Connectivity’, <inline-formula><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>7.58</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>0.90</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>2.5</mml:mn><mml:mo>,</mml:mo><mml:mn>97.5</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>6.05</mml:mn><mml:mo>,</mml:mo><mml:mn>9.31</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>) performed similarly with a slight advantage for the ‘Source Activity’ model. The best results were obtained when combining power and connectivity features (‘Full’, <inline-formula><mml:math id="inf59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>6.75</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>0.83</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>2.5</mml:mn><mml:mo>,</mml:mo><mml:mn>97.5</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>5.36</mml:mn><mml:mo>,</mml:mo><mml:mn>8.20</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>). Adding sensor space features did not lead to any visible improvement of ‘Full’ over ‘Combine Source’ with virtually indistinguishable error distributions. The observed average model-ranking was highly consistent over cross-validation testing-splits (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>), suggesting that the relative importance of the different blocks of MEG features was systematic, hence, can be expected to generalize to future data. The observed ranking between MEG models suggests that regional changes in source-level power spectra contained most information while source-level connectivity added another portion of independent information which helped improve prediction by at least 0.5 years on average. A similar picture emerged when inspecting the contribution of the Layer-I linear models to the performance of the full model in terms of variable importance (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). Sensor space features were least influential, whereas top contributing features were all related to power and connectivity, which, upon permutation, increased the error by up to 1 year. The most informative input to the stacking model were ridge regression models based on either signal power or the Hilbert analytic signal power concatenated across frequency bands (P<sub>cat</sub>, E<sub>cat</sub>). Other noteworthy contributions were related to power envelope covariance (without source leakage correction) as well as source power in the beta (15–30 Hz) and alpha (8–15 Hz) band frequency range. The results suggest that regional changes in power across different frequency bands are best summarized with a single linear model but additional non-linear additive effects may exist in specific frequency bands. The observed importance rankings were highly consistent with importance rankings obtained from alternative methods for extraction of variable importance (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>), emphasizing the robustness of these rankings.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>MEG performance was predominantly driven by source power.</title><p>We used the stacking-method to investigate the impact of distinct blocks of features on the performance of the full MEG model. We considered five models based on non-exhaustive combinations of features from three families. ‘Sensor Mixed’ included layer-1 predictions from auditory and visual evoked latencies, resting-state alpha-band peaks and 1/f slopes in low frequencies and the beta band (sky blue). ‘Source Activity’ included layer-1 predictions from resting-state power spectra based on signals and envelopes simultaneously or separately for all frequencies (dark orange). ‘Source Connectivity’ considered layer-1 predictions from resting-state source-level connectivity (signals or envelopes) quantified by covariance and correlation (with or without orthogonalization), separately for each frequency (blue). For an overview on features, see <xref ref-type="table" rid="table2">Table 2</xref>. Best results were obtained for the ‘Full’ model, yet, with negligible improvements compared to ‘Combined Source’. (<bold>B</bold>) Importance of linear-inputs inside the layer-II random forest. X-axis: permutation importance estimating the average drop in performance when shuffling one feature at a time. Y-axis: corresponding performance of the layer-I linear model. Model-family is indicated by color, characteristic types of inputs or features by shape. Top-performing age-predictors are labeled for convenience (p=power, E = envelope, cat = concatenated across frequencies, greek letters indicate the frequency band). It can be seen that solo-models based on source activity (red) performed consistently better than solo-models based other families of features (blue) but were not necessarily more important. Certain layer-1-inputs from the connectivity family received top-rankings, that is alpha-band and low beta-band covariances of the power envelopes. The most important and best performing layer-1 models concatenated source-power across all nine frequency bands. See <xref ref-type="table" rid="table4">Table 4</xref> for full details on the top-10 layer-1 models. For additional details, please consider our supplementary findings.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-54055-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Rank statistics.</title><p>Rank statistics for MEG stacking models. (<bold>A</bold>) depicts rankings over cross-validation testing splits for the five stacking models and the chance-level estimator. The ranking was, overall, stable with perfect separation from chance for all but the ’Sensor Mixed’ models. Two blocks surfaced: models based on either source-level activity (power of signals) or source-level connectivity (covariance, correlation) and a second block with models that combined source-level activity with connectivity. In the first block, models competed for rankings higher than sensor space models but lower than combined models. At the same time, the ‘Combined Source’ and ‘Full’ higher order models predominantly competed for top-rankings. (<bold>B</bold>) Matrix of pairwise rank frequencies. The values indicate how many times the row-item ranked better than the column-item. For example, all models (except ‘Sensor Mixed’) ranked 100/100 times better than chance (right-most column). The ‘Full’ model ranked 87/100 times better than ‘Source Activity’ (row one from bottom, column three from left), 95/100 better than ‘Source Connectivity’ (row one from bottom, column four from left). Competition between models is expressed by quasi-alternation, for example, ‘Full’ was 59 times better than ‘Combined Source’, which, in turn, was better than 'Full' 41 times.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-54055-fig4-figsupp1-v2.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Ranking-stability across methods for variable importance.</title><p>Alternative metrics for estimation of variable importance. The permutation-based variable importance presented so far may suffer from two limitations: overfitting and insensitivity to conditional dependencies between variables. (<bold>A</bold>) Results obtained with out-of-sample permutations from the 100 cross-validation splits used for model evaluation. This analysis is less prone to overfitting than in-sample permutations but, by design, is not prepared to handle correlation between the inputs and does not capture interaction effects between variables. (<bold>B</bold>) Results from the mean decrease impurity (MDI) metric defined for the training data. MDI can capture interaction effects but increases the risk of false positives and false negatives. Compared with the main findings in <xref ref-type="fig" rid="fig4">Figure 4B</xref>, all three metrics strongly agreed on the subset of most important variables and yielded highly similar importance rankings. The association between these importance estimates was <inline-formula><mml:math id="inf62"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.95</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.90</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>2.2</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>16</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> for in-sample permutations and MDI, <inline-formula><mml:math id="inf63"><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mo>⁢</mml:mo><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.96</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>0.92</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> for in-sample permutations and out-of-sample permutations and <inline-formula><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.94</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.88</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>2.2</mml:mn><mml:mo>×</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>−</mml:mo><mml:mn>16</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> for MDI and out-of-sample permutations. These supplementary findings suggest that the detection of the most important factors contributing to model performance was robust across distinct variable importance metrics.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-54055-fig4-figsupp2-v2.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>Partial dependence.</title><p>Partial dependence between top age-inputs and the final stacked age-prediction. This analysis simulates how stacked predictions change as the age predicted from layer-1 linear models increases. Results revealed a staircase pattern suggesting dominant monotonic and non-linear relationship. Moreover, the analysis revealed that more important input models had wider ranges of age predictions and were, on average, less strongly corrected by shrinkage toward the mean age. This provides some insight into one potential mechanism by which the stacking model helps improve over the linear model, that is, by pulling implausible extreme predictions towards the mean prediction by age-group-dependent amounts.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-54055-fig4-figsupp3-v2.tif"/></fig><fig id="fig4s4" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 4.</label><caption><title>Performance of solo- versus stacking-models.</title><p>Distribution of prediction errors across 62 first-level linear models (green) and 9 second-level stacking models (black) based on random forests. One can see that stacking mitigates prediction error beyond the best performing linear model.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-54055-fig4-figsupp4-v2.tif"/></fig></fig-group><p>Moreover, partial dependence analysis (<xref ref-type="bibr" rid="bib64">Karrer et al., 2019</xref>; <xref ref-type="bibr" rid="bib52">Hastie et al., 2005</xref>, chapter 10.13.2) suggested that the Layer-II random forest extracted non-linear functions (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>). Finally, the best stacked models scored lower errors than the best linear models (<xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref>), suggesting that stacking achieved more than mere variable selection by extracting non-redundant information from the inputs.</p><p>These findings show that MEG-based prediction of age is predominantly enabled by power spectra that can be relatively easily accessed in terms of computation and data processing. Moreover, the stacking approach applied to MEG data helped improve beyond linear models by upgrading to non-linear regression.</p></sec><sec id="s2-5"><title>Advantages of multimodal stacking can be maintained in populations with incomplete data</title><p>One important obstacle for combining signals from multiple modalities in clinical settings is that not all modalities are available for all cases. So far, we have restricted the analysis to 536 cases for which all modalities were present. Can the advantage of multimodal stacking be preserved in the absence of complete data or will missing values mitigate prediction performance? To investigate this question, we trained our stacked model on all 674 cases for which we had the opportunity to extract at least one feature on any modality, hence, opportunistic stacking (see <xref ref-type="fig" rid="fig1">Figure 1</xref> and <xref ref-type="table" rid="table3">Table 3</xref> in section <italic>Sample</italic> in Materials and methods). We first compared the opportunistic model with the restricted model on the cases with complete data <xref ref-type="fig" rid="fig5">Figure 5A</xref>. Across stacking models, performance was virtually identical, even when extending the comparison to the cases available to the sub-model with fewer modalities, for example MRI and fMRI. We then scored the fully opportunistic model trained on all cases and all modalities and compared it to different non-opportunistic sub-models on restricted cases (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, squares). The fully opportunistic model always out-performed the sub-model. This raises the question of how the remaining cases would be predicted for which fewer modalities were available. <xref ref-type="fig" rid="fig5">Figure 5B</xref> shows the performance of the opportunistic split by subgroups defined by different combinations of input modalities available. As expected, performance degraded considerably on subgroups for which important features (as delineated by the previous results) were not available. See, for example, the subgroup for which only sensor-space MEG was available. This is unsurprising, as prediction has to be based on data and is necessarily compromised if the features important at train-time are not available at predict-time. One can, thus, say that the opportunistic model operates conservatively: The performance on the subgroups reflects the quality of the features available, hence, enables learning from the entire data.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Opportunistic learning performance.</title><p>(<bold>A</bold>) Comparisons between opportunistically trained model and models restricted to common available cases. Opportunistic versus restricted model with different combinations scored on all 536 <italic>common</italic> cases (circles). Same analysis extended to include <italic>extra common</italic> cases available for sub-models (squares). Fully opportunistic stacking model (all cases, all modalities) versus reduced non-opportunistic sub-models (fewer modalities) on the cases available to the given sub-model (diamonds). One can see that multimodal stacking is generally of advantage whenever multiple modalities are available and does not impact performance compared to restricted analysis on modality-complete data. (<bold>B</bold>) Performance for opportunistically trained model for subgroups defined by different combinations of available input modalities, ordered by average error. Points depict single-case prediction errors. Boxplot-whiskers show the 5% and 95% uncertainty intervals. When performance was degraded, important modalities were absent or the number of cases was small, for example, in MEG<sub>sens</sub> where only sensor space features were present.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-54055-fig5-v2.tif"/></fig><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Available cases by input modality.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>Modality</th><th>MEG sensor</th><th>MEG source</th><th>MRI</th><th>fMRI</th><th>Common cases</th></tr></thead><tbody><tr><td>cases</td><td>589</td><td>600</td><td>621</td><td>626</td><td>536</td></tr></tbody></table><table-wrap-foot><fn><p>Note. MEG sensor space cases reflect separate task-related and resting state recordings corresponding to family ‘sensor mixed’ in <xref ref-type="table" rid="table2">Table 2</xref>. MEG source space cases were exclusively based on the resting state recordings and mapped to family ‘source activity’ and ‘source connectivity’ in <xref ref-type="table" rid="table2">Table 2</xref>.</p></fn></table-wrap-foot></table-wrap><p>It is important to emphasize that if missing values depend on age, the opportunistic model inevitably captures this information, hence, bases its predictions on the non-random missing data. This may be desirable or undesirable, depending on the applied context. To diagnose this model-behavior, we propose to run the opportunistic random forest model with the observed missing values as input and observations from the input modalities set to zero. In the current setting, the model trained on missing data indicators performed at chance level (<inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mo>&lt;</mml:mo><mml:mi>C</mml:mi><mml:mi>h</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>30.00</mml:mn><mml:mi mathvariant="normal">%</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>0.65</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>1.68</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>2.5</mml:mn><mml:mo>,</mml:mo><mml:mn>97.5</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mo>−</mml:mo><mml:mn>2.96</mml:mn><mml:mo>,</mml:mo><mml:mn>3.60</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>), suggesting that the missing values were not informative of age.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We have demonstrated improved learning of surrogate biomarkers by combining electrophysiology as accessed through MEG, functional and anatomical MRI. Here, we have focused on the example of age-prediction by multimodal modeling on 674 subjects from the Cam-CAN dataset, the currently largest publicly available collection of MEG, fMRI and MRI data. Our results suggest that MEG and fMRI both substantially improved age-prediction when combined with anatomical MRI. We have then explored potential implications of the ensuing brain-age Δ as a surrogate-biomarker for cognitive and physical health. Our results suggest that MEG and fMRI convey non-redundant information on cognitive functioning and health, for example fluid intelligence, memory, sleep quality, cognitive decline and depression. Moreover, combining all modalities has led to lower prediction errors. Inspection of the MEG-based models suggested unique information on aging is conveyed by regional distribution of power in the <inline-formula><mml:math id="inf69"><mml:mi>α</mml:mi></mml:math></inline-formula> (8–12 Hz) and <inline-formula><mml:math id="inf70"><mml:mi>β</mml:mi></mml:math></inline-formula> (15–30 Hz) frequency bands, in line with the notion of spectral fingerprints (<xref ref-type="bibr" rid="bib66">Keitel and Gross, 2016</xref>). When applied in clinical settings, multimodal approaches should make it more likely to detect relevant brain-behavior associations. We have, therefore, addressed the issue of missing values, which is an important obstacle for multimodal learning approaches in clinical settings. Our stacking model, trained on the entire data with an opportunistic strategy, performed equivalently to the restricted model on common subsets of the data and helped exploiting multimodal information to the extent available. This suggests that the advantages of multimodal prediction can be maintained in practice.</p><sec id="s3-1"><title>fMRI and MEG reveal complementary information on cognitive aging</title><p>Our results have revealed complementary effects of anatomy and neurophysiology in age-prediction. When adding either MEG or fMRI to the anatomy-based stacking model, the prediction error markedly dropped (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). Both, MEG and fMRI helped gain almost 1 year of error compared to purely anatomy-based prediction. This finding suggests that both modalities access equivalent information. This is in line with the literature on correspondence of MEG with fMRI in resting state networks, highlighting the importance of spatially correlated slow fluctuations in brain oscillations (<xref ref-type="bibr" rid="bib55">Hipp and Siegel, 2015</xref>; <xref ref-type="bibr" rid="bib54">Hipp et al., 2012</xref>; <xref ref-type="bibr" rid="bib13">Brookes et al., 2011</xref>). On the other hand, recent findings suggest that age-related variability in fMRI and EEG is independent to a substantial degree (<xref ref-type="bibr" rid="bib69">Kumral et al., 2020</xref>; <xref ref-type="bibr" rid="bib82">Nentwich et al., 2020</xref>). Interestingly, the prediction errors of models with MEG and models with fMRI were rather weakly correlated (<xref ref-type="fig" rid="fig2">Figure 2B</xref>, left panel). In some subpopulations, they even seemed anti-correlated, such that predictions from MEG or fMRI, for the same cases, were either accurate or extremely inaccurate. This additional finding suggests that the improvements of MEG and fMRI over anatomical MRI are due to their access to complementary information that helps predicting distinct cases. Indeed, as we combined MEG and fMRI in one common stacking model alongside anatomy, performance improved on average by 1.3 years over the purely anatomical model, which is almost half a year more precise than the previous MEG-based and fMRI-based models.</p><p>These results strongly argue in favor of the presence of an additive component, in line with the common intuition that MEG and fMRI are complementary with regard to spatial and temporal resolution. In this context, our results on performance decomposition in MEG (<xref ref-type="fig" rid="fig4">Figure 4</xref>) deliver one potentially interesting hint. Source power, especially in the <inline-formula><mml:math id="inf71"><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>8</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:mn>15</mml:mn><mml:mo>⁢</mml:mo><mml:mi>H</mml:mi><mml:mo>⁢</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf72"><mml:mrow><mml:mi>β</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>15</mml:mn><mml:mo>-</mml:mo><mml:mrow><mml:mn>26</mml:mn><mml:mo>⁢</mml:mo><mml:mi>H</mml:mi><mml:mo>⁢</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> range were the single most contributing type of feature (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). However, connectivity features, in general, and power-envelope connectivity, in particular, contributed substantively (<xref ref-type="fig" rid="fig4">Figure 4B</xref>, <xref ref-type="table" rid="table4">Table 4</xref>). Interestingly, applying orthogonalization (<xref ref-type="bibr" rid="bib54">Hipp et al., 2012</xref>; <xref ref-type="bibr" rid="bib55">Hipp and Siegel, 2015</xref>) for removing source leakage did not notably improve performance (<xref ref-type="table" rid="table4">Table 4</xref>). Against the background of research on MEG-fMRI correspondence highlighting the importance of slow fluctuations of brain rhythms (<xref ref-type="bibr" rid="bib55">Hipp and Siegel, 2015</xref>; <xref ref-type="bibr" rid="bib13">Brookes et al., 2011</xref>), this finding suggests that what renders MEG non-redundant with regard to fMRI are regional differences in the balance of fast brain-rhythms, in particular in the <inline-formula><mml:math id="inf73"><mml:mrow><mml:mi>α</mml:mi><mml:mo>-</mml:mo><mml:mi>β</mml:mi></mml:mrow></mml:math></inline-formula> range.</p><table-wrap id="table4" position="float"><label>Table 4.</label><caption><title>Top-10 Layer-1 models from MEG ranked by variable importance.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>ID</th><th>Family</th><th>Input</th><th>Feature</th><th>Variant</th><th>Importance</th><th>MAE</th></tr></thead><tbody><tr><td>5</td><td>source activity</td><td>envelope</td><td>power</td><td>E<sub>cat</sub></td><td>0.97</td><td>7.65</td></tr><tr><td>4</td><td>source activity</td><td>signal</td><td>power</td><td>P<sub>cat</sub></td><td>0.96</td><td>7.62</td></tr><tr><td>7</td><td>source connectivity</td><td>envelope</td><td>covariance</td><td><inline-formula><mml:math id="inf74"><mml:mi>α</mml:mi></mml:math></inline-formula></td><td>0.37</td><td>10.99</td></tr><tr><td>7</td><td>source connectivity</td><td>envelope</td><td>covariance</td><td><inline-formula><mml:math id="inf75"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></td><td>0.36</td><td>11.37</td></tr><tr><td>4</td><td>source activity</td><td>signal</td><td>power</td><td><inline-formula><mml:math id="inf76"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></td><td>0.29</td><td>8.79</td></tr><tr><td>5</td><td>source activity</td><td>envelope</td><td>power</td><td><inline-formula><mml:math id="inf77"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></td><td>0.28</td><td>8.96</td></tr><tr><td>7</td><td>source connectivity</td><td>envelope</td><td>covariance</td><td><inline-formula><mml:math id="inf78"><mml:mi>θ</mml:mi></mml:math></inline-formula></td><td>0.24</td><td>11.95</td></tr><tr><td>8</td><td>source connectivity</td><td>envelope</td><td>correlation</td><td><inline-formula><mml:math id="inf79"><mml:mi>α</mml:mi></mml:math></inline-formula></td><td>0.21</td><td>10.99</td></tr><tr><td>8</td><td>source connectivity</td><td>envelope</td><td>correlation</td><td><inline-formula><mml:math id="inf80"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></td><td>0.19</td><td>11.38</td></tr><tr><td>6</td><td>source connectivity</td><td>signal</td><td>covariance</td><td><inline-formula><mml:math id="inf81"><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></td><td>0.19</td><td>12.13</td></tr></tbody></table><table-wrap-foot><fn><p>Note. ID = mapping to rows from features. MAE = prediction performance of solo-models as in <xref ref-type="fig" rid="fig4">Figure 4</xref>.</p></fn></table-wrap-foot></table-wrap><p>While this interpretation may be enticing, an important caveat arises from the fact that fMRI signals are due to neurovascular coupling, hence, highly sensitive to events caused by sources other than neuronal activity (<xref ref-type="bibr" rid="bib57">Hosford and Gourine, 2019</xref>). Recent findings based on the dataset analyzed in the present study have shown that the fMRI signal in elderly populations might predominantly reflect vascular effects rather than neuronal activity (<xref ref-type="bibr" rid="bib112">Tsvetanov et al., 2015</xref>). The observed complementarity of the fMRI and MEG in age prediction might, therefore, be conservatively explained by the age-related increase in the ratio of vascular to neuronal contributions to the fMRI signal, while MEG signals are directly induced by neuronal activity, regardless of aging. Nevertheless, in the context of brain-age prediction these mechanisms are less important than the sensitivity of the prediction, for instance, regarding behavioral outcomes.</p><p>In sum, our findings suggest that electrophysiology can make a difference in prediction problems in which fast brain rhythms are strongly statistically related to the biomedical outcome of interest.</p></sec><sec id="s3-2"><title>Brain age Δ as sensitive index of normative aging</title><p>In this study, we have conducted an exploratory analysis on what might be the cognitive and health-related implications of our prediction models. Our findings suggest that the brain age Δ shows substantive associations with about 20–25% of all neuropsychological measures included. The overall big-picture is congruent with the brain age literature (see discussion in <xref ref-type="bibr" rid="bib104">Smith et al., 2019</xref> for an overview) and supports the interpretation of the brain age Δ as index of decline of physical health, well-being and cognitive fitness. In this sample, larger values of the Δ were globally associated with elevated depression scores, higher blood pressure, lower sleep quality, lower fluid intelligence, lower scores in neurological assessment and lower memory performance. Most strikingly, we found that fMRI and MEG contributed additive, if not unique information (<xref ref-type="fig" rid="fig3">Figure 3</xref>). For example, the association with depression appeared first when predicting age from fMRI. Likewise, the association with fluid intelligence and sleep quality visibly intensified when including MEG.</p><p>This extends the previous discussion in suggesting that MEG and fMRI are not only complementary for prediction but also with regard to characterizing brain-behavior mappings. In this context, it is worwhile considering that predicting biomedical outcomes from multiple modalities may reduce susceptibility to ‘modality impurity’ as often observed in modeling of individual differences in cognitive abilities (<xref ref-type="bibr" rid="bib37">Friedman and Miyake, 2004</xref>; <xref ref-type="bibr" rid="bib80">Miyake et al., 2000</xref>). In the present study, it was remarkable that cardiac measures were exclusively related to fMRI-based models and vanished as MEG was included. This may not be entirely surprising as the fMRI signal is a combination of, both, vascular and neuronal components (<xref ref-type="bibr" rid="bib57">Hosford and Gourine, 2019</xref>) and aging affects both of them differently, which poses an important challenges to fMRI-based studies of aging (<xref ref-type="bibr" rid="bib41">Geerligs et al., 2017</xref>; <xref ref-type="bibr" rid="bib113">Tsvetanov et al., 2016</xref>). It is imaginable that the cardiac measures were not associated with brain age estimates from fMRI when combined with the modalities as vascular components may have enhanced the SNR of neuronal signals through deconfounding (for extensive discussion on this topic, see <xref ref-type="bibr" rid="bib114">Tsvetanov et al., 2019</xref>).</p><p>Which neuronal components might explain the enhanced brain-behavior links extracted from the multimodal models? It is enticing to speculate that the regional power of fast-paced <inline-formula><mml:math id="inf82"><mml:mi>α</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf83"><mml:mi>β</mml:mi></mml:math></inline-formula> band brain rhythms captures fast-paced components of cognitive processes such as attentional sampling or adaptive attention (<xref ref-type="bibr" rid="bib45">Gola et al., 2013</xref>; <xref ref-type="bibr" rid="bib91">Richard Clark et al., 2004</xref>), which, in turn might explain unique variance in certain cognitive facets, such as fluid intelligence (<xref ref-type="bibr" rid="bib83">Ouyang et al., 2020</xref>) or visual short-term memory (<xref ref-type="bibr" rid="bib107">Tallon-Baudry et al., 2001</xref>). On the other hand, functional connectivity between cortical areas and subcortical structures, in particular the hippocampus, may be key for depression and is well captured with fMRI (<xref ref-type="bibr" rid="bib105">Stockmeier et al., 2004</xref>; <xref ref-type="bibr" rid="bib98">Sheline et al., 2009</xref>; <xref ref-type="bibr" rid="bib92">Rocca et al., 2015</xref>). Unfortunately, modeling such mediation effects exceeds the scope of the current work, although it would be worth being tested in an independent study with a dedicated design.</p><p>Could one argue that the overall effect sizes were too low to be considered practically interesting? Indeed, the strength of linear association was below 0.5 in units of standard deviations of the normalized predictors and the target. On the other hand, it is important to consider that the Cam-CAN sample consists of healthy individuals only. It, thus, appears as rather striking that systematic and neuropsychologically plausible effects can be detected. Our findings, therefore, argue in favor of the brain age Δ being a sensitive marker of normative aging. The effects are expected to be far more pronounced when applying the method in clinical settings, that is, in patients suffering from mild cognitive impairment, depression, neurodevelopmental or neurodegenerative disorders. This suggests that brain age Δ might be used as a screening tool for a wide array of clinical settings for which the Cam-CAN dataset could serve as a normative sample.</p></sec><sec id="s3-3"><title>Translation to the clinical setting</title><p>One critical factor for application of our approach in the clinic is the problem of incomplete availability of medical imaging and physiological measurements. Here, we addressed this issue by applying an opportunistic learning approach which enables learning from the data available at hand. Our analysis of opportunistic learning applied to age prediction revealed viable practical alternatives to confining the analysis to cases for which all measurements are available. In fact, adding extra cases with incomplete measurements never harmed prediction of the cases with complete data and the full multimodal stacking always outperformed sub-models with fewer modalities (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). Moreover, the approach allowed maintaining and extending the performance to new cases with incomplete modalities (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). Importantly, performance on such subsets was explained by the performance of a reduced model with the remaining modalities. Put differently, opportunistic stacking performed as good as a model restricted to data with all modalities. In practice, the approach allows one to improve predictions case-wise by including electrophysiology next to MRI or MRI next to electrophysiology, whenever there is the opportunity to do so.</p><p>A second critical factor for translating our findings into the clinic is that, most of the time, it is not high-density MEG that is available but low-density EEG. In this context, our finding showed that the source power was the most important feature, which is of clear practical interest. This is because it suggests that a rather simple statistical object accounts for the bulk of the performance of MEG. Source power can be approximated by the sensor-level topography of power spectra which can be computed on any multichannel EEG device in a few steps and only yields as many variables per frequency band as there are channels. Moreover, from a statistical standpoint, computing the power spectrum amounts to estimating the marginal expectation of the signal variance, which can be thought of as main effect. On the other hand, connectivity is often operationalized as bivariate interaction, which gives rise to a more complex statistical object of higher dimensionality whose precise, reproducible estimation may require far more samples. Moreover, as is the case for power envelope connectivity estimation, additional processing steps each of which may add researcher degrees of freedom (<xref ref-type="bibr" rid="bib100">Simmons et al., 2011</xref>), such as the choice between Hilbert (<xref ref-type="bibr" rid="bib13">Brookes et al., 2011</xref>) versus Wavelet filtering (<xref ref-type="bibr" rid="bib54">Hipp et al., 2012</xref>), types of orthogonalization (<xref ref-type="bibr" rid="bib8">Baker et al., 2014</xref>), and potentially thresholding for topological analysis (<xref ref-type="bibr" rid="bib67">Khan et al., 2018</xref>). This nourishes the hope that our findings will generalize and similar performance can be unlocked on simpler EEG devices with fewer channels. While clinical EEG may not well resolve functional connectivity it may be good enough to resolve changes in the source geometry of the power spectrum (<xref ref-type="bibr" rid="bib95">Sabbagh et al., 2020</xref>). On the other hand, source localization may be critical in this context as linear field spread actually results in a non-linear transform when considering the power of a source (<xref ref-type="bibr" rid="bib94">Sabbagh et al., 2019</xref>). However, in practice, it may be hard to conduct high-fidelity source localization on the basis of low-density EEG and frequently absent information on the individual anatomy. It will, therefore, be critical to benchmark and improve learning from power topographies in clinical settings.</p><p>Finally, it is worthwhile to highlight that, here, we have focused on age in the more specific context of the brain age Δ as surrogate biomarker. However, the proposed approach is fully compatible with any target of interest and may be easily applied directly to clinical end points, for example drug dosage, survival or diagnosis. Moreover, the approach presented here can be easily adapted to work with classification problems, for instance, by substituting logistic regression for ridge regression and by using a random forest classifier in the stacking layer. We have provided all materials from our study in form of publicly available version-controlled code with the hope to help other teams of biomedical researchers to adapt our method to their prediction problem.</p></sec><sec id="s3-4"><title>Limitations</title><p>For the present study, we see four principal limitations: availability of data, interpretability, non-exhaustive feature-engineering and potential lack of generalizability due to the focus on MEG.</p><p>The Cam-CAN is a unique resource of multimodal neuroimaging data with sufficient data points to enable machine learning approaches. Yet, from the point of view of machine learning, the Cam-CAN dataset is a small dataset. This has at least two consequences. If the Cam-CAN included many more data points, for example beyond 10–100 k subjects, the proposed stacking model might possibly be of limited advantage compared to purely non-linear models, for example random forests, gradient boosting or deep learning methods (<xref ref-type="bibr" rid="bib16">Bzdok and Yeo, 2017</xref>). At the same time, the fact that the Cam-CAN has been unique so far, hinders generalization testing to equivalent multimodal datasets from other sites based on alternative scanning methodologies, protocols and devices (<xref ref-type="bibr" rid="bib27">Engemann et al., 2018</xref>). This also renders computation of numerical hypothesis tests (including p-values) more difficult in the context of predictive modeling: The majority of data points is needed for model-fitting and metrics derived from left-out cross-validation splits, for example, predictions of brain age, lack statistical independence. This breaks essential assumptions of inferential statistics to an arbitrary and unknown degree. Our inferences were, therefore, predominantly based on estimated effect-sizes, that is the expected generalization error and its uncertainty assessed through cross-validation.</p><p>Second, at this point, statistical modeling faces the dilemma of whether inference or prediction is the priority. Procedures optimizing prediction performance in high dimensions are not yet supported by the in-depth understanding required to guarantee formal statistical inferences, whereas models with well-established procedures for statistical inference lack predictive capability (<xref ref-type="bibr" rid="bib14">Bzdok et al., 2018</xref>; <xref ref-type="bibr" rid="bib15">Bzdok and Ioannidis, 2019</xref>). Forcing interpretation out of machine learning models, therefore, often leads to duplicated analysis pipelines and model specifications, which is undesirable in terms of methodological coherence (for example <xref ref-type="bibr" rid="bib58">Hoyos-Idrobo et al., 2019</xref>; <xref ref-type="bibr" rid="bib53">Haufe et al., 2014</xref>; <xref ref-type="bibr" rid="bib11">Biecek, 2018</xref>). In the present work, we refrained from conducting fine-grained inferential analysis beyond the model comparisons presented, in particular inspection of layer-1 weightmaps whose interpretation remains an ongoing research effort. We hope, nevertheless, that the insights from our work will stimulate studies investigating the link between MEG, fMRI and MRI across the life-span using an inference-oriented framework.</p><p>Third, the MEG-features used in the present study were non-exhaustive. Based on the wider MEG/EEG-literature beyond the neuroscience of aging, many other features could have been included. Instead, feature-engineering was based on our aging-specific literature review constrained by biophysical considerations. In particular, the distinction between sensor-space and source-space features was purely descriptive and not substantive. From an empirical perspective, mirroring all features in sensor-space and source-space could have yielded more specific inferences, for example regarding the role of source-power. On the other hand, biophysical prior knowledge implies that oscillatory peak frequencies and evoked response latencies are not modified by source localization, whereas source localization or data-driven approximations thereof are essential for predicting from M/EEG power spectra (<xref ref-type="bibr" rid="bib94">Sabbagh et al., 2019</xref>). It is also fair to admit that, in the present paper, our passion was preferentially attracted by source modeling of neural power spectra. However, one could imagine that with equal investment of resources, more information could have been extracted from the sensor-level features (see <xref ref-type="bibr" rid="bib42">Gemein et al., 2020</xref> for approaches to tackle the important methodological issue of unbalanced investment of development-time). Related, the current work has strongly benefited from expertise on modeling of MEG power spectra under the assumption of stationary as captured by global power spectra, covariance or connectivity. Recent findings suggest that non-stationary analyses focusing on transient electrophysiological events may uncover clinically relevant information on cognitive brain dynamics (<xref ref-type="bibr" rid="bib9">Barttfeld et al., 2015</xref>; <xref ref-type="bibr" rid="bib8">Baker et al., 2014</xref>; <xref ref-type="bibr" rid="bib119">Vidaurre et al., 2018</xref>; <xref ref-type="bibr" rid="bib116">Van Schependom et al., 2019</xref>). It is, therefore, important to highlight that our proposed framework is open and readily enables integration of additional low- or high-dimensional inputs related to richer sensor-level features or non-stationary dynamics, beyond MEG as input modality.</p><p>Finally, while MEG and EEG share the same types of neural generators, their specific biophysics render these methods complementary for studying neuronal activity. At this point, unfortunately, there is no public dataset equivalent of the Cam-CAN including EEG or, both, EEG and MEG. Such a data resource would have enabled studying the complementarity between MEG with EEG as well as generalization from stacking with MRI and MEG to stacking models with MRI and EEG.</p><p>We hope that our method will help other scientists to incorporate the multimodal features related to their domain expertise into their applied regression problems.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Sample</title><p>We included MEG (task and rest), fMRI (rest), anatomical MRI and neuropsychological data (cognitive tests, home-interview, questionnaires) from the CAM-Can dataset (<xref ref-type="bibr" rid="bib97">Shafto et al., 2014</xref>). Our sample comprised 674 (340 female) healthy individuals between 18 (female = 18) to 88 (female = 87) years with an average of 54.2 (female = 53.7) and a standard deviation of 18.7 (female = 18.8) years. We included data according to availability and did not apply an explicit criterion for exclusion. When automated processing resulted in errors, we considered the data as missing. This induced additional missing data for some cases. A summary of available cases by input modality is reported in <xref ref-type="table" rid="table3">Table 3</xref>. For technical details regarding the MEG, fMRI, and MRI data acquisition, please consider the Cam-CAN reference publications (<xref ref-type="bibr" rid="bib97">Shafto et al., 2014</xref>; <xref ref-type="bibr" rid="bib109">Taylor et al., 2017</xref>).</p></sec><sec id="s4-2"><title>Feature extraction</title><p>Feature extraction was guided by the perspective of predictive modeling. For the goal of enhancing prediction performance as opposed to statistical inference (<xref ref-type="bibr" rid="bib15">Bzdok and Ioannidis, 2019</xref>), we emphasized on differences between modalities, hence, chose modality-specific methods and optimizations at the risk of sacrificing direct comparability between features used for MEG, fMRI and MRI. The selection of features was guided by our literature review on the neuroscience of aging presented in the introduction.</p><p>For MEG, we analyzed sensor space features related to timing (<xref ref-type="bibr" rid="bib86">Price et al., 2017</xref>), peak frequency (<xref ref-type="bibr" rid="bib91">Richard Clark et al., 2004</xref>) and temporal autocorrelation (<xref ref-type="bibr" rid="bib120">Voytek et al., 2015</xref>). Source space features included the power of source-level signals (<xref ref-type="bibr" rid="bib94">Sabbagh et al., 2019</xref>) and envelopes and their bivariate interactions (<xref ref-type="bibr" rid="bib67">Khan et al., 2018</xref>) in nine frequency bands (see <xref ref-type="table" rid="table1">Table 1</xref>, adapted from the Human Connectome Project, <xref ref-type="bibr" rid="bib70">Larson-Prior et al., 2013</xref>). The inclusion of power envelopes was theoretically important as the slow fluctuations of source power and their bivariate interactions have been repeatedly linked to fMRI resting state networks (<xref ref-type="bibr" rid="bib55">Hipp and Siegel, 2015</xref>; <xref ref-type="bibr" rid="bib13">Brookes et al., 2011</xref>). On the other hand, we specifically focused on the unique capacity of MEG to access spatial information induced by fast-paced brain rhythms emerging from regional sources (<xref ref-type="bibr" rid="bib68">King and Dehaene, 2014</xref>; <xref ref-type="bibr" rid="bib106">Stokes et al., 2015</xref>).</p><p>For extracting features from MRI and fMRI, we adapted the approach established by <xref ref-type="bibr" rid="bib75">Liem et al., 2017</xref>. For fMRI, we computed bivariate functional connectivity estimates. For MRI, we focused on cortical thickness, cortical surface area and subcortical volumes. An overview on all features used is presented in <xref ref-type="table" rid="table2">Table 2</xref>. In the remainder of this section, we describe computation details.</p><sec id="s4-2-1"><title>MEG features</title><sec id="s4-2-1-1"><title>Peak evoked latency</title><p>Sensory processing may slow down in the course of aging (<xref ref-type="bibr" rid="bib86">Price et al., 2017</xref>). Here, we assessed the evoked response latency during auditory, visual and simultaneous audiovisual stimulation (index 1, <xref ref-type="table" rid="table2">Table 2</xref>). For each of the conditions, we first computed the evoked response. Then, we computed the root-mean-square across gradiometers and looked up the time of the maximum. In total, this yielded three latency values per subject.</p></sec><sec id="s4-2-1-2"><title><inline-formula><mml:math id="inf84"><mml:mi>α</mml:mi></mml:math></inline-formula>-band peak frequency</title><p>Research suggests that the alpha-band frequency may be lower in older people. Here, we computed the resting-state power spectrum using a Welch estimator (index 2, <xref ref-type="table" rid="table2">Table 2</xref>). Then, we estimated the peak frequency between 6 and 15 Hz on occipito-parietal magnetometers after removing the 1/f trend using a polynomial regression (degree = 15) by computing the maximum power across sensors and looking up the frequency bin. This yielded one peak value per subject.</p></sec><sec id="s4-2-1-3"><title>1/f slope</title><p>Long-range auto-correlation in neural time-series gives rise to the characteristic 1/f decay of power on a logarithmic scale. Increases of neural noise during aging are thought to lead to reduced autocorrelation, hence a more shallow slope (<xref ref-type="bibr" rid="bib120">Voytek et al., 2015</xref>). We computed the 1/f slope from the Welch power spectral estimates above on all magnetometers using linear regression (index 3, <xref ref-type="table" rid="table2">Table 2</xref>). The slope is given by the <inline-formula><mml:math id="inf85"><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> of the linear fit with the log-frequencies as predictor and the log-power as target. We obtained one estimate for each of the 102 magnetometers, resulting in a 1/f topography. No further reduction was applied.</p></sec><sec id="s4-2-1-4"><title>Power and connectivity of source-level signals</title><p>The cortical generators of the brain-rhythms dominating the power spectrum change across life-span. To predict from the spatial distribution of MEG power spectra, we relied on source-localization to mitigate distortions due to individual head geometry. We adopted the pipeline optimized for high-dimensional regression presented in <xref ref-type="bibr" rid="bib94">Sabbagh et al., 2019</xref> and modeled power spectra in the time-domain based on covariance estimates after bandpass-filtering. We considered nine frequency bands (see <xref ref-type="table" rid="table1">Table 1</xref>), computed bandpass-filtered minimum norm source-estimates and then summarized the source-time courses ROI-wise by the first principal components with alignment to the surface normals using the ‘pca_flip’ option provided by MNE-Python (<xref ref-type="bibr" rid="bib48">Gramfort et al., 2013</xref>). To mitigate the curse of dimensionality we used a subdivision of the Desikan-Killiany atlas (<xref ref-type="bibr" rid="bib24">Desikan et al., 2006</xref>) comprising 448 ROIs. This set of ROIs proposed by <xref ref-type="bibr" rid="bib67">Khan et al., 2018</xref> for predictive modeling of neurodevelopmental trajectories was specifically designed to generate approximately equal ROI-size to avoid averaging over inhomogeneous regions with distinct leadfield coverage or to avoid averaging over larger regions that may contain multiple sources cancelling each other. Subsequently, we computed the covariance matrix from the concatenated epochs and used the 448 diagonal entries as power estimates (index 4 <xref ref-type="table" rid="table2">Table 2</xref>). The off-diagonal entries served as connectivity estimates. Covariance matrices live in a non-Euclidean curved space. To avoid model violations at the subsequent linear-modeling stages, we used tangent space projection (<xref ref-type="bibr" rid="bib117">Varoquaux et al., 2010</xref>) to vectorize the lower triangle of the covariance matrix. This projection allows one to treat entries of the covariance or correlation matrix as regular Euclidean objects, hence avoid violations to the linear model used for regression (<xref ref-type="bibr" rid="bib94">Sabbagh et al., 2019</xref>). This yielded <inline-formula><mml:math id="inf86"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mn>448</mml:mn><mml:mo>×</mml:mo><mml:mn>448</mml:mn></mml:mrow><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>448</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>128</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> connectivity values per subject (index 6 <xref ref-type="table" rid="table2">Table 2</xref>).</p></sec><sec id="s4-2-1-5"><title>Power and connectivity of source-level envelopes</title><p>Brain-rhythms are not constant in time but fluctuate in intensity. These slow fluctuations are technically captured by power envelopes and may show characteristic patterns of spatial correlation. To estimate power envelopes, for each frequency band, we computed the analytic signal using the Hilbert transform. For computational efficiency, we calculated the complex-valued analytic signal in sensor space and then source-localized it using the linear minimum norm operator. To preserve linearity, we only extracted the power envelopes by taking the absolute value of the analytic signal after having performed averaging inside the ROIs. Once the envelope time-series was computed, we applied the same procedure as for source power (paragraph above) to estimate the source power of the envelopes (index 5, <xref ref-type="table" rid="table2">Table 2</xref>) and their connectivity. Power and covariance were computed from concatenated epochs, correlation and orthogonalized correlation were computed epoch-wise. Note that, for systematic reasons, we also included power estimates of the envelope time-series applying the same method as we used for the time-series. In the MEG literature, envelope correlation is a well-established research topic (<xref ref-type="bibr" rid="bib54">Hipp et al., 2012</xref>; <xref ref-type="bibr" rid="bib13">Brookes et al., 2011</xref>). Thus, in addtition to the covariance, we computed the commonly used normalized Pearson correlations and orthogonalized Pearson correlations which are designed to mitigate source leakage (index 7–9, <xref ref-type="table" rid="table2">Table 2</xref>). However, as a result of orthogonalization, the resulting matrix is not any longer positive definite and cannot be projected to the tangent space using Riemannian geometry. Therefore, we used Fisher’s Z- transform (<xref ref-type="bibr" rid="bib99">Silver and Dunlap, 1987</xref>) to convert the correlation matrix into a set of standard-normal variables. The transform is defined as the inverse hyperbolic tangent function of the correlation coefficient: <inline-formula><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mi>log</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. This yielded 448 power envelope power estimates and 100,128 connectivity values per estimator.</p></sec></sec><sec id="s4-2-2"><title>fMRI features</title><sec id="s4-2-2-1"><title>Functional connectivity</title><p>Large-scale neuronal interactions between distinct brain networks has been repeatedly shown to change during healthy aging. Over the past years, for fMRI-based predictive modeling using functional atlases from about 50 to 1000 ROIs have emerged as a fundamental element for mitigating heterogeneity and dimensionality reduction, especially in small- to medium-sized datasets such as the Cam-CAN with less than 1000 observations (<xref ref-type="bibr" rid="bib22">Dadi et al., 2019</xref>; <xref ref-type="bibr" rid="bib2">Abraham et al., 2017</xref>). To estimate macroscopic functional connectivity, we deviated from the 197-ROI BASC atlas <xref ref-type="bibr" rid="bib10">Bellec et al., 2010</xref> used in <xref ref-type="bibr" rid="bib75">Liem et al., 2017</xref>. Instead, we used an atlas with 256 sparse and partially overlapping ROIs obtained from Massive Online Dictionary Learning (MODL) (<xref ref-type="bibr" rid="bib79">Mensch et al., 2016</xref>). Initial piloting suggested that both methods gave approximately equivalent results on average with slightly reduced variance for the MODL atlas. Then, we computed bivariate amplitude interactions using Pearson correlations from the ROI-wise average time-series (index 10, <xref ref-type="table" rid="table2">Table 2</xref>). Again, we used tangent space projection (<xref ref-type="bibr" rid="bib117">Varoquaux et al., 2010</xref>) to vectorize the correlation matrices. This yielded 32,640 connectivity values from the lower triangle of each matrix. No further reduction was applied.</p></sec></sec><sec id="s4-2-3"><title>MRI features</title><p>The extraction of features from MRI followed the previously established strategy presented in <xref ref-type="bibr" rid="bib75">Liem et al., 2017</xref> which is based on cortical surface reconstruction using the FreeSurfer software. For scientific references to specific procedures, see the section <italic>MRI data processing</italic> and the FreeSurfer website <ext-link ext-link-type="uri" xlink:href="http://freesurfer.net/">http://freesurfer.net/</ext-link>.</p><sec id="s4-2-3-1"><title>Cortical thickness</title><p>Aging-related brain atrophy has been related to thinning of the cortical tissue (for example <xref ref-type="bibr" rid="bib110">Thambisetty et al., 2010</xref>). We extracted cortical thickness, defined as shortest distance between white and pial surfaces, from the Freesurfer (<xref ref-type="bibr" rid="bib35">Fischl, 2012</xref>) segmentation using a surface tessellation with 5124 vertices in fsaverage4 space obtained from the FreeSurfer command <monospace>mris_preproc</monospace> using default parameters (index 11, <xref ref-type="table" rid="table2">Table 2</xref>). No further reduction was computed.</p></sec><sec id="s4-2-3-2"><title>Cortical surface area</title><p>Aging is also reflected in shrinkage of the cortical surface itself (for example <xref ref-type="bibr" rid="bib74">Lemaitre et al., 2012</xref>). We extracted vertex-wise cortical surface area estimates, defined as average of the faces adjacent to a vertex along the white surface, from the Freesurfer segmentation using a surface tessellation with 5124 vertices in fsaverage4 space obtained from the FreeSufer command <monospace>mris_preproc</monospace> using default parameters (index 12, <xref ref-type="table" rid="table2">Table 2</xref>). No further reduction was computed.</p></sec><sec id="s4-2-3-3"><title>Subcortical volumes</title><p>The volume of subcortical structures has been linked to aging (for example <xref ref-type="bibr" rid="bib81">Murphy et al., 1992</xref>). Here, we used the FreeSurfer command <monospace>asegstats2table</monospace>, using default parameters, to obtain estimates of the subcortical volumes and global volume, yielding 66 values for each subject with no further reductions (index 13, <xref ref-type="table" rid="table2">Table 2</xref>).</p></sec></sec></sec><sec id="s4-3"><title>Stacked-prediction model for opportunistic learning</title><p>We used the stacking framework (<xref ref-type="bibr" rid="bib122">Wolpert, 1992</xref>) to build our predictive model. However, we made the important specification that input models were regularized linear models trained on input data from different modalities, whereas stacking of linear predictions was achieved by a non-linear regression model. Our model can be intuitively denoted as follows:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>Here, each <inline-formula><mml:math id="inf88"><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the vector of predictions <inline-formula><mml:math id="inf89"><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula> of the target vector <inline-formula><mml:math id="inf90"><mml:mi>y</mml:mi></mml:math></inline-formula> from the jth model fitted using input data <inline-formula><mml:math id="inf91"><mml:msub><mml:mi>X</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula>:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>X</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>ϵ</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></disp-formula></p><p>We used ridge regression as input model and a random forest regressor as a general function approximator <inline-formula><mml:math id="inf92"><mml:mi>f</mml:mi></mml:math></inline-formula> [Ch. 15.4.3](<xref ref-type="bibr" rid="bib52">Hastie et al., 2005</xref>). A visual illustration of the model is presented in <xref ref-type="fig" rid="fig1">Figure 1</xref>.</p><sec id="s4-3-1"><title>Layer-1: Ridge regression</title><p>Results from statistical decision theory suggests that, for linear models, the expected out-of-sample error increases only linearly with the number of variables included in a prediction problem (<xref ref-type="bibr" rid="bib52">Hastie et al., 2005</xref>, chapter 2), not exponentially. In practice, biased (or penalized) linear models with Gaussian priors on the coefficients, that is ridge regression (or logistic regression for classification) with <inline-formula><mml:math id="inf93"><mml:msub><mml:mi mathvariant="normal">ℓ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>-penalty (squared <inline-formula><mml:math id="inf94"><mml:msub><mml:mi mathvariant="normal">ℓ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> norm) are hard to outperform in neuroimaging settings (<xref ref-type="bibr" rid="bib22">Dadi et al., 2019</xref>). Ridge regression can be seen as extension of ordinary least squares (OLS) where the solution is biased such that the coefficients estimated from the data are conservatively pushed toward zero:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>β</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi>X</mml:mi><mml:mo>⊤</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mi>X</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mi>X</mml:mi><mml:mo>⊤</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The estimated coefficients approach zero as the penalty term <inline-formula><mml:math id="inf95"><mml:mi>λ</mml:mi></mml:math></inline-formula> grows, and the solution approaches the OLS fit as <inline-formula><mml:math id="inf96"><mml:mi>λ</mml:mi></mml:math></inline-formula> gets closer to zero. This shrinkage affects directions of variance with small singular values more strongly than the ones with large singular values (see eqs. 3.47-3.50 in <xref ref-type="bibr" rid="bib52">Hastie et al., 2005</xref>, ch. 3.4.1), hence, can be seen as smooth principal component analysis as directions of variance are shrunk but no dimension is ever fully discarded. This is the same as assuming that the coefficient vector comes from a Gaussian distribution centered around zero such that increasing shrinkage reduces the variance <inline-formula><mml:math id="inf97"><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> of that distribution [chapter 7.3] (<xref ref-type="bibr" rid="bib26">Efron and Hastie, 2016</xref>):<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>β</mml:mi><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>λ</mml:mi></mml:mfrac><mml:mi>I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In practice, the optimal strength for this Gaussian prior is often unknown. For predictive modeling, <inline-formula><mml:math id="inf98"><mml:mi>λ</mml:mi></mml:math></inline-formula> is commonly chosen in a data-driven fashion such that one improves the expected out-of-sample error, for example tuned using cross-validation. We tuned <inline-formula><mml:math id="inf99"><mml:mi>λ</mml:mi></mml:math></inline-formula> using generalized cross-validation (<xref ref-type="bibr" rid="bib46">Golub et al., 1979</xref>) and considered 100 candidate values on an evenly spaced logarithmic scale between 10<sup>-3</sup> and 10<sup>5</sup>. This can be regarded equivalent to assuming a flat but discrete hyper-prior (a prior distribution of the hyper-parameters assumed for the model parameters) on the distribution of candidate regularization-strengths. Note that this procedure is computationally efficient and, on our problem, returned entire regularization paths within seconds. While this approach is standard-practice in applied machine learning and particularly useful with massive and high-dimensional data, many other methods exist for data-driven choice of the prior which may be more appropriate in situations on smaller datasets and where parameter inference, not prediction, is the priority.</p></sec><sec id="s4-3-2"><title>Layer-2: Random forest regression</title><p>However, the performance of the ridge model in high dimensions comes at the price of increasing bias. The stacking model tries to alleviate this issue by reducing the dimensionality in creating a derived data set of linear predictions, which can then be forwarded to a more flexible local regression model. Here, we chose the random forest algorithm (<xref ref-type="bibr" rid="bib12">Breiman, 2001</xref>) which can be seen as a general function approximator and has been interpreted as an adaptive nearest neighbors algorithm (<xref ref-type="bibr" rid="bib52">Hastie et al., 2005</xref>, chapter 15.4.3). Random forests can learn a wide range of functions and are capable of automatically detecting non-linear interaction effects with little tuning of hyper-parameters. They are based on two principles: regression trees and bagging (bootstrapping and aggregating). Regression trees are non-parametric methods and recursively subdivide the input data by finding combinations of thresholds that relate value ranges of the input variables to the target. The principle is illustrated at the right bottom of <xref ref-type="fig" rid="fig1">Figure 1</xref>. For a fully grown tree, each sample falls into one leaf of the tree which is defined by its unique path through combinations of input-variable thresholds through the tree. However, regression trees tend to easily overfit. This is counteracted by randomly generating alternative trees from bootstrap replica of the dataset and randomly selecting subset of variables for each tree. Importantly, thresholds are by default optimized with regard to a so-called impurity criterion, for which we used mean squared error. Predictions are then averaged, which mitigates overfitting and also explains how continuous predictions can be obtained from thresholds.</p><p>In practice, it is common to use a generous number of trees as performance plateaus once a certain number is reached, which may lay between hundreds or thousands. Here, we used 1000 trees. Moreover, limiting the overall depth of the trees can increase bias and mitigate overfitting at the expense of model complexity. An intuitive way of conceptualizing this step is to think of the tree-depth in terms of orders interaction effects. A tree with three nodes enables learning three-way interactions. Here, we tuned the model to choose between depth-values of 4, 6, or 8 or the option of not constraining the depth. Finally, the total number of features sampled at each node determines the degree to which the individual trees are independent or correlated. Small number of variables de-correlate the trees but make it harder to find important variables as the number of input variables increases. On the other hand, using more variables at once leads to more exhaustive search of good thresholds, but may increase overfitting. As our stacking models had to deal with different number of input variables, we had to tune this parameter and let the model select between <inline-formula><mml:math id="inf100"><mml:msqrt><mml:mi>p</mml:mi></mml:msqrt></mml:math></inline-formula>, <inline-formula><mml:math id="inf101"><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and all <inline-formula><mml:math id="inf102"><mml:mi>p</mml:mi></mml:math></inline-formula> input variables. We implemented selection of tuning-parameters by grid search as (nested) 5-fold cross-validation with the same scoring as used for evaluation of the model performance, that is mean absolute error. The choice of the mean absolute error is a natural choice for the study of aging as error is directly expressed in the units of interest.</p></sec><sec id="s4-3-3"><title>Stacked cross-validation</title><p>We used a 10-fold cross-validation scheme. To mitigate bias due to the actual order of the data, we repeated the procedure 10 times while reshuffling the data at each repeat. We then generated age-predictions from each layer-1 model on the left-out folds, such that we had for each case one age-prediction per repeat. We then stored the indices for each fold to make sure the random forest was trained on left-out predictions for the ridge models. This ensured that the input-layer train-test splits where carried forward to layer-2 and that the stacking model was always evaluated on left-out folds in which the input ages are actual predictions and the targets have not been seen by the model. Here, we customized the stacking procedure to be able to unbox and analyze the input-age predictions and implement opportunistic handling of missing values.</p></sec><sec id="s4-3-4"><title>Variable importance</title><p>Random forest models and, in general, regression trees are often inspected by estimating the impact of each variable on the prediction performance. This is commonly achieved by computing the so-called variable importance. The idea is to track and sum across all trees the relative reduction of impurity each time a given variable is used to split, hence, the name mean decrease impurity (MDI). The decrease in impurity can be tracked by regular performance metrics. Here we used mean squared error, which is the default option for random forest regression in scikit-learn (<xref ref-type="bibr" rid="bib85">Pedregosa et al., 2011</xref>). It has been shown that in correlated trees, variable importance can be biased and lead to masking effects, that is, fail to detect important variables (<xref ref-type="bibr" rid="bib78">Louppe et al., 2013</xref>) or suggest noise-variables to be important. One potential remedy is to increase the randomness of the trees, for example by selecting randomly a single variable for splitting and using extremely randomized trees (<xref ref-type="bibr" rid="bib43">Geurts et al., 2006</xref>; <xref ref-type="bibr" rid="bib27">Engemann et al., 2018</xref>), as it can be mathematically guaranteed that in fully randomized trees only actually important variables are assigned importance (<xref ref-type="bibr" rid="bib78">Louppe et al., 2013</xref>). However, such measures may mitigate prediction performance or lead to duplicated model specifications (one model for predicting, one for analyzing variable importance). Here, we used the approach from the original random forest paper (<xref ref-type="bibr" rid="bib12">Breiman, 2001</xref>), which consists in permuting <inline-formula><mml:math id="inf103"><mml:mi>k</mml:mi></mml:math></inline-formula> times one variable at a time and measuring the drop in performance at the units of performance scoring, that is mean absolute error in years. We computed permutation importance with <inline-formula><mml:math id="inf104"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1000</mml:mn></mml:mrow></mml:math></inline-formula> after fitting the random forest to the cross-validated predictions from the layer-1 models.</p><p>In-sample permutation importance is computationally convenient but may potentially suffer from an irreducible risk of overfitting, even when taking precautions such as limiting the tree-depth. This risk can be avoided by computing the permutations on left-out data, that is by permuting the variables in the testing-set, which can be computationally expensive. However, permutation importance (whether computed on training- or testing -data) has the known disadvantage that it does not capture conditional dependencies or higher order interactions between variables. For example, a variable may not be so important in itself but its interaction with other variables makes it an important predictor. Such conditional dependencies between variables can be captured with MDI importance.</p><p>To diagnose potential overfitting and to assess the impact of conditional dependencies, we additionally reported out-of-sample permutation importance and MDI importance. We computed out-of-sample permutation importance for each of the 100 splits from our cross-validation procedure with a reduced number of permutations (<inline-formula><mml:math id="inf105"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula>) to avoid excessive computation times. MDI importance was based on the same model fit as the in-sample permutations.</p></sec><sec id="s4-3-5"><title>Opportunistic learning with missing values</title><p>An important option for our stacking model concerns handling missing values. Here, we implemented the double-coding approach (<xref ref-type="bibr" rid="bib62">Josse et al., 2019</xref>) which duplicates the features and once assigns the missing value a very small and once a very large number (see also illustration in <xref ref-type="fig" rid="fig1">Figure 1</xref>). As our stacked input data consisted of age predictions from the ridge models, we used biologically implausible values of −1000 and 1000. This amounts to turning missing values into features and let the stacking model potentially learn from the missing values, as the reason for the missing value may contain information on the target. For example, an elderly patient may not be in the best conditions for an MRI scan, but nevertheless qualifies for electrophysiological assessment.</p><p>To implement opportunistic stacking, we considered the full dataset with missing values and then kept track of missing data while training layer-1. This yielded the stacking-data consisting of the age-predictions and missing values. Stacking was then performed after applying the feature-coding of missing values. This procedure made sure that all training and test splits were defined with regard to the full cases and, hence, the stacking model could be applied to all cases after feature-coding of missing values.</p></sec><sec id="s4-3-6"><title>Statistical inference</title><p>Rejecting a null-hypothesis regarding differences between two cross-validated models is problematic in the absence of sufficiently large unseen data or independent datasets: cross-validated scores are not statistically independent. Fortunately, cross-validation yields useful empirical estimates of the performance (and its dispersion) that can be expected on unseen data (<xref ref-type="bibr" rid="bib52">Hastie et al., 2005</xref>, Ch. 7.10). Here, we relied on uncertainty estimates of paired differences based on the stacked cross-validation with 10 folds and 10 repeats. To provide a quantitative summary of the distributions of paired split-wise differences in performance, we extracted the mean, the standard deviation, the 2.5 and 97.5 percentiles (inner 95% of the distribution) as well as the number of splits in which a model was better than a given reference (<inline-formula><mml:math id="inf106"><mml:mrow><mml:mi>P</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi/><mml:mo>&lt;</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>f</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. We estimated chance-level prediction using a dummy regressor that predicts the average of the training-set target using the same cross-validation procedure and identical random seeds to ensure split-wise comparability between non-trivial models. While not readily supporting computation of p-values, dummy estimates are computationally efficient and yield distributions equivalent to those obtained from label-permutation procedures. For statistical analyses linking external measurements with model-derived quantities such as the cross-validated age prediction or the brain age Δ, we used classical parametric hypothesis-testing. It should be clear, however, that hypothesis-testing, here, provides a quantitative orientation that needs to be contextualized by empirical estimates of effect sizes and their uncertainty to support inference.</p></sec></sec><sec id="s4-4"><title>Analysis of brain-behavior correlation</title><p>To explore the cognitive implications of the brain age Δ, we computed correlations with the neurobehavioral score from the Cam-CAN dataset. <xref ref-type="table" rid="table5">Table 5</xref> lists the scores we considered. The measures fall into three broad classes: neuropsychology, physiology and questionnaires (‘Type’ columns in <xref ref-type="table" rid="table5">Table 5</xref>). Extraction of neuropsychological scores sometimes required additional computation, which followed the description in <xref ref-type="bibr" rid="bib97">Shafto et al., 2014</xref>, (see also ‘Variables’ column in scores). For some neuropsychological tasks, the Cam-CAN dataset provided multiple scores and sometimes the final score of interest as described in <xref ref-type="bibr" rid="bib97">Shafto et al., 2014</xref>, had yet to be computed. At times, this amounted to computing ratios, averages or differences between different scores. In other scores, it was not obvious how to aggregate multiple interrelated sub-scores, hence, we extracted the first principal component explaining between about 50% and 85% of variance, hence offering reasonable summaries. In total, we included 38 variables. All neuropsychology and physiology scores (up to #17 in <xref ref-type="table" rid="table5">Table 5</xref>) were the scores available in the ‘cc770-scored’ folder from release 001 of the Cam-CAN dataset. We selected the additional questionnaire scores (#18-23 in <xref ref-type="table" rid="table5">Table 5</xref>) on theoretical grounds to provide an assessment of clinically relevant individual differences in cognitive functioning. The brain age Δ was defined as the difference between predicted and actual age of the person<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">B</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>such that positive values quantify overestimation and negative value underestimation. A common problem in establishing brain-behavior correlations for brain age is spurious correlations due to shared age-related variance in the brain age Δ and the neurobehavioral score (<xref ref-type="bibr" rid="bib104">Smith et al., 2019</xref>). To mitigate confounding effects of age, we computed the age residuals as<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf107"><mml:mi>score</mml:mi></mml:math></inline-formula> is the observed neuropsychological score and <inline-formula><mml:math id="inf108"><mml:msub><mml:mi>score</mml:mi><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is its prediction from the following polynomial regression:<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The estimated linear association between the residualized score and the brain age <inline-formula><mml:math id="inf109"><mml:mi mathvariant="normal">Δ</mml:mi></mml:math></inline-formula> was given by <inline-formula><mml:math id="inf110"><mml:msub><mml:mi>β</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> in<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">B</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>To obtain comparable coefficients across scores, we standardized both the age and the scores. We also included intercept terms in all models which are omitted here for simplicity.</p><table-wrap id="table5" position="float"><label>Table 5.</label><caption><title>Summary of neurobehavioral scores.</title></caption><table frame="hsides" rules="groups"><thead><tr><th>#</th><th>Name</th><th>Type</th><th>Variables (38)</th></tr></thead><tbody><tr><td>1</td><td>Benton faces</td><td>neuropsychology</td><td>total score (1)</td></tr><tr><td>2</td><td>Emotional expression recognition</td><td>…</td><td>PC1 of RT (1), EV = 0.66</td></tr><tr><td>3</td><td>Emotional memory</td><td>…</td><td>PC1 by memory type (3), EV = 0.48,0.66,0.85</td></tr><tr><td>4</td><td>Emotion regulation</td><td>…</td><td>positive and negative reactivity, regulation (3)</td></tr><tr><td>5</td><td>Famous faces</td><td>…</td><td>mean familiar details ratio (1)</td></tr><tr><td>6</td><td>Fluid intelligence</td><td>…</td><td>total score (1)</td></tr><tr><td>7</td><td>Force matching</td><td>…</td><td>Finger- and slider-overcompensation (2)</td></tr><tr><td>7</td><td>Hotel task</td><td>…</td><td>time(1)</td></tr><tr><td>9</td><td>Motor learning</td><td>…</td><td>M and SD of trajectory error (2)</td></tr><tr><td>10</td><td>Picture priming</td><td>…</td><td>baseline RT, baseline ACC (4)</td></tr><tr><td>…</td><td>…</td><td>…</td><td>M prime RT contrast, M target RT contrast</td></tr><tr><td>11</td><td>Proverb comprehension</td><td>…</td><td>score (1)</td></tr><tr><td>12</td><td>RT choice</td><td>…</td><td>M RT (1)</td></tr><tr><td>13</td><td>RT simple</td><td>…</td><td>M RT (1)</td></tr><tr><td>14</td><td>Sentence comprehension</td><td>…</td><td>unacceptable error, M RT (2)</td></tr><tr><td>15</td><td>Tip-of-the-tounge task</td><td>…</td><td>ratio (1)</td></tr><tr><td>16</td><td>Visual short term memory</td><td>…</td><td>K (M,precision,doubt,MSE) (4)</td></tr><tr><td>17</td><td>Cardio markers</td><td>physiology</td><td>pulse, systolic and diastolic pressure 3)</td></tr><tr><td>18</td><td>PSQI</td><td>questionnaire</td><td>total score (1)</td></tr><tr><td>19</td><td>Hours slept</td><td>…</td><td>total score (1)</td></tr><tr><td>20</td><td>HADS (Depression)</td><td>…</td><td>total score (1)</td></tr><tr><td>21</td><td>HADS (Anxiety)</td><td>…</td><td>total score (1)</td></tr><tr><td>22</td><td>ACE-R</td><td>…</td><td>total score (1)</td></tr><tr><td>23</td><td>MMSE</td><td>…</td><td>total score (1)</td></tr></tbody></table><table-wrap-foot><fn><p>Note. M = mean, SD = standard deviation, RT = reaction time, PC = principal component, EV = explained variance ratio (between 0 and 1), ACC = accuracy, PSQI = Pittsburgh Sleep Quality Index HADS = Hospital Anxiety and epression Scale, ACE-R = Addenbrookes Cognitive Examination Revised, MMSE = Mini Mental State Examination. Numbers in parentheses indicate how many variables were extracted.</p></fn></table-wrap-foot></table-wrap><p>It has been recently demonstrated, that such a two-step procedure can lead to spurious associations (<xref ref-type="bibr" rid="bib77">Lindquist et al., 2019</xref>). We have, therefore, repeated the analysis with a joint deconfounding model where the polynomial terms for age are entered into the regression model alongside the brain age predictor.<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">B</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Finally, the results may be due to confounding variable of non-interest. To assess the importance of such confounders, we have extended the model (<xref ref-type="disp-formula" rid="equ9">Equation 9</xref>) to also include gender, handedness (binarized) and a log Frobenius norm of the variability of motion parameters (three translation, three rotation) over the 241 acquired images.<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">B</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:msub><mml:mi mathvariant="normal">d</mml:mi><mml:mrow><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>6</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>7</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Note that motion correction was already performed during preprocessing of MRI and fMRI. Likewise, MEG source localization took into account individual head geometry as well as potentially confounding environmental noise through whitening with the noise covariance obtained from empty room recordings. Following the work by <xref ref-type="bibr" rid="bib75">Liem et al., 2017</xref>, we included total grey matter and total intracranial volume as important features of interest among the MRI-features.</p></sec><sec id="s4-5"><title>MEG data processing</title><sec id="s4-5-1"><title>Data acquisition</title><p>MEG recorded at a single site using a 306 VectorView system (Elekta Neuromag, Helsinki). This system is equipped with 102 magnetometers and 204 orthogonal planar gradiometers is placed in a light magnetically shielded room. During acquisition, an online filter was applied between around 0.03 Hz and 1000 Hz. This resulted in a sampling-frequency of 1000 Hz. To support offline artifact correction, vertical and horizontal electrooculogram (VEOG, HEOG) as well as electrocardiogram (ECG) signal was concomitantly recorded. Four Head-Position Indicator (HPI) coils were used to measure the position of the head. All types of recordings, that is resting-state, passive stimulation and the active task lasted about 8 min. For additional details on MEG acquisition, please consider the reference publications of the Cam-CAN dataset (<xref ref-type="bibr" rid="bib109">Taylor et al., 2017</xref>; <xref ref-type="bibr" rid="bib97">Shafto et al., 2014</xref>). The following sections will describe the custom data processing conducted in our study.</p></sec><sec id="s4-5-2"><title>Artifact removal</title><sec id="s4-5-2-1"><title>Environmental artifacts</title><p>To mitigate contamination of the MEG signal with artifacts produced by environmental magnetic sources, we applied temporal signal-space-separation (tSSS) (<xref ref-type="bibr" rid="bib108">Taulu and Kajola, 2005</xref>). The method uses spherical harmonic decomposition to separate spatial patterns produced by sources inside the head from patterns produced by external sources. We used the default settings with eight components for the harmonic decomposition of the internal sources, and three for the external sources on a ten seconds sliding window. We used a correlation threshold of 98% to ignore segments in which inner and outer signal components are poorly distinguishable. We performed no movement compensation, since there were no continuous head monitoring data available at the time of our study. The origin of internal and external multipolar moment space was estimated based on the head-digitization. We computed tSSS using the MNE <monospace>maxwell_filter</monospace> function (<xref ref-type="bibr" rid="bib48">Gramfort et al., 2013</xref>) but relied on the SSS processing logfiles from Cam-CAN for defining bad channels.</p></sec><sec id="s4-5-2-2"><title>Physiological artifacts</title><p>To mitigate signal distortions caused by eye-movements and heart-beats we used signal space projection (SSP) (<xref ref-type="bibr" rid="bib115">Uusitalo and Ilmoniemi, 1997</xref>). This method learns principal components on contaminated data-segments and then projects the signal into the sub-space orthogonal to the artifact. To obtain clean estimates, we excluded bad data segments from the EOG/ECG channels using the ‘global’ option from autoreject (<xref ref-type="bibr" rid="bib60">Jas et al., 2017</xref>). We then averaged the artefact-evoked signal (see ‘average’ option in <monospace>mne.preprocessing.compute_proj_ecg</monospace>) to enhance subspace estimation and only considered one single projection vector to preserve as much signal as possible.</p></sec><sec id="s4-5-2-3"><title>Rejection of residual artifacts</title><p>To avoid contamination with artifacts that were not removed by SSS or SSP, we used the ‘global’ option from autoreject (<xref ref-type="bibr" rid="bib60">Jas et al., 2017</xref>). This yielded a data-driven selection of the amplitude range above which data segments were excluded from the analysis.</p></sec><sec id="s4-5-2-4"><title>Temporal filtering</title><p>To study band-limited brain dynamics, we applied bandpass-filtering using the frequency band definitions in <xref ref-type="table" rid="table1">Table 1</xref>. We used default filter settings from the MNE software (development version 0.19) with a windowed time-domain design (firwin) and Hamming taper. Filter length and transition band-width was set using the ‘auto’ option and depended on the data.</p></sec><sec id="s4-5-2-5"><title>Epoching</title><p>For the active and passive tasks, we considered time windows between −200 and 700 ms around stimulus-onset and decimated the signal by retaining every eighth time sample.</p><p>For resting-state, we considered sliding windows of 5 s duration with no overlap and no baseline correction. To reduce computation time, we retained the first 5 min of the recording and decimated the signal by retaining every fifth time sample. Given the sampling frequency of 1000 Hz, this left unaffected the bulk of the features, only reducing the spectral resolution in the high gamma band to 75–100 Hz (instead of 75–120 Hz in the definition proposed by the Human Connectome Project [<xref ref-type="bibr" rid="bib70">Larson-Prior et al., 2013</xref>]).</p></sec><sec id="s4-5-2-6"><title>Channel selection</title><p>It is important to highlight that after SSS, the magnetometer and gradiometer data are reprojected from a common lower dimensional SSS coordinate system that typically spans between 64 and 80 dimensions. After SSS, magnetometers and gradiometers are reconstructed from the same basis vectors, which makes them linear combinations of another (<xref ref-type="bibr" rid="bib108">Taulu and Kajola, 2005</xref>). As a result, both sensor types contain highly similar information and yield equivalent results in many situations (<xref ref-type="bibr" rid="bib39">Garcés et al., 2017</xref>). Consequently, after applying SSS, the MNE software manipulates a single sensor type for source localization and uses as degrees of freedom the number of underlying SSS dimensions instead of the number of channels. Note, however, that after SSS, magnetometers and gradiometers can still yield systematically different results in sensor-space analyses despite being linear combinations of another. This happens once a non-linear transform is applied on the sensor-space, for example power, which is explained by the fact that SSS is a linear transform and powers in sensors space breaks linearity. On the other hand, once source localization is correctly performed, which takes into account the SSS solution, differences between gradiometers and gradiometers become negligible for, both, linear transforms and non-linear transforms. We, nevertheless, used all 102 magnetometers and 204 gradiometers for source analysis to stick with a familiar configuration. Note that while short-cuts can be achieved by processing only one of the sensor types, they should be avoided when other methods than SSS are used for preprocessing. However, driven by initial visual exploration, for some aspects of feature engineering in sensor space, that is, extraction of alpha peaks or computation of 1/f power spectra, we used the 102 magnetometers. For extraction of evoked response latencies, we used the 204 gradiometers. Nevertheless, due to the characteristic of SSS to combine sensor types into one common representation, in all analyses, magnetic fields sampled from, both, magnetometers and gradiometers were exploited even if only one type of sensors was formally included.</p></sec><sec id="s4-5-2-7"><title>Covariance modeling</title><p>To control the risk of overfitting in covariance modeling (<xref ref-type="bibr" rid="bib29">Engemann and Gramfort, 2015</xref>), we used a penalized maximum-likelihood estimator implementing James-Stein shrinkage (<xref ref-type="bibr" rid="bib59">James and Stein, 1992</xref>) of the form<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>biased</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mfrac><mml:mrow><mml:mi>Trace</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover accent="true"><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mi>p</mml:mi></mml:mfrac><mml:mo>⁢</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf111"><mml:mi>α</mml:mi></mml:math></inline-formula> is the regularization strength, <inline-formula><mml:math id="inf112"><mml:mover accent="true"><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula> is the unbiased maximum-likelihood estimator, <inline-formula><mml:math id="inf113"><mml:mi>p</mml:mi></mml:math></inline-formula> is the number of features and <inline-formula><mml:math id="inf114"><mml:mi>I</mml:mi></mml:math></inline-formula> the identity matrix. This, intuitively, amounts to pushing the covariance toward the identity matrix. Here, we used the Oracle Approximation Shrinkage (OAS) (<xref ref-type="bibr" rid="bib18">Chen et al., 2010</xref>) to compute the shrinkage factor <inline-formula><mml:math id="inf115"><mml:mi>α</mml:mi></mml:math></inline-formula> mathematically.</p></sec><sec id="s4-5-2-8"><title>Source localization</title><p>To estimate cortical generators of the MEG signal, we employed the cortically constraint Minimum-Norm-Estimates (<xref ref-type="bibr" rid="bib50">Hämäläinen and Ilmoniemi, 1994</xref>) based on individual anatomy of the subjects. The resulting projection operator exclusively captures inputs from the anatomy of the subject and additional whitening based on the noise covariance. On the other hand, beamforming methods, consider the segments of MEG data to be source-localized through the data covariance. Methods from the MNE-family are therefore also referred to as non-adaptive spatial filters, whereas beamforming methods are referred to as adaptive spatial filters. The MNE-operator can be expressed as<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">E</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>G</mml:mi><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mi mathvariant="normal">⊤</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Here <inline-formula><mml:math id="inf116"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>G</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>×</mml:mo><mml:mi>Q</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> with <inline-formula><mml:math id="inf117"><mml:mi>P</mml:mi></mml:math></inline-formula> sensors and <inline-formula><mml:math id="inf118"><mml:mi>Q</mml:mi></mml:math></inline-formula> sources denotes the forward model quantifying the spread from sources to M/EEG observations and <inline-formula><mml:math id="inf119"><mml:mi>λ</mml:mi></mml:math></inline-formula> a regularization parameter that controls the <inline-formula><mml:math id="inf120"><mml:msub><mml:mi mathvariant="normal">ℓ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>-norm of the activity coefficients. This parameter implicitly controls the spatial complexity of the model with larger regularization strength leading to more spatially smeared solutions. The forward model is obtained by numerically solving Maxwell’s equations based on the estimated head geometry, which we obtained from the Freesurfer brain segmentation. Note that from a statistical perspective, the MNE-solution is a Ridge model (see <xref ref-type="disp-formula" rid="equ3 equ4">Equations 3-4</xref>) predicting the magnetic field at a given sensor from a linear combination of corresponding entries in the leadfields. The inferred source activity is given by multiplication of the MNE-operator with sensor-level magnetic fields.</p><p>We estimated the source amplitudes on a grid of 8196 candidate dipole locations equally spaced along the cortical mantle. We used spatial whitening to approximate the model assumption of Gaussian noise (<xref ref-type="bibr" rid="bib29">Engemann and Gramfort, 2015</xref>). The whitening operator was based on the empty room noise covariance and applied to the MEG signal and the forward model. We applied no noise normalization and used the default depth weighting (<xref ref-type="bibr" rid="bib76">Lin et al., 2006</xref>) as implemented in the MNE software (<xref ref-type="bibr" rid="bib49">Gramfort et al., 2014</xref>) with weighting factor of 0.8 (<xref ref-type="bibr" rid="bib76">Lin et al., 2006</xref>) and a loose-constraint of 0.2. The squared regularization parameter <inline-formula><mml:math id="inf121"><mml:msup><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:math></inline-formula> was expressed with regard to the signal-to-noise ratio and fixed at the default value of <inline-formula><mml:math id="inf122"><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>SNR</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mfrac></mml:math></inline-formula> with <inline-formula><mml:math id="inf123"><mml:mrow><mml:mi>SNR</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula> for all subjects. This conservative choice was also motivated by the computational burden for optimizing the regularization parameter. Optimizing this hyper-parameter would have required pre-computing hundreds of MNE solutions to then perform grid search over the derived source-level outputs. As the goal was prediction from the source localized signals, not inference on spatial effects, we have instead relied on the subsequent data-driven shrinkage through the level-1 ridge model (see <xref ref-type="disp-formula" rid="equ3 equ4">Equations 3-4</xref>). It may be worthwhile to systematically investigate the interplay between shrinkage at the MNE-level and the ridge-level for predictive modeling with MEG in future research.</p></sec></sec></sec><sec id="s4-6"><title>MRI data processing</title><sec id="s4-6-1"><title>Data acquisition</title><p>For additional details on data acquisition, please consider the reference publications of the CAM-Can (<xref ref-type="bibr" rid="bib109">Taylor et al., 2017</xref>; <xref ref-type="bibr" rid="bib97">Shafto et al., 2014</xref>). The following sections will describe the custom data processing conducted in our study.</p></sec><sec id="s4-6-2"><title>Structural MRI</title><p>For preprocessing of structural MRI data we used the FreeSurfer (version 6.0) software (<ext-link ext-link-type="uri" xlink:href="http://surfer.nmr.mgh.harvard.edu/">http://surfer.nmr.mgh.harvard.edu/</ext-link>)) (<xref ref-type="bibr" rid="bib35">Fischl, 2012</xref>). Reconstruction included the following steps (adapted from the methods citation recommended by the authors of FreeSurfer <ext-link ext-link-type="uri" xlink:href="http://freesurfer.net/fswiki/FreeSurferMethodsCitation">http://freesurfer.net/fswiki/FreeSurferMethodsCitation</ext-link>): motion correction and average of multiple volumetric T1-weighted images (<xref ref-type="bibr" rid="bib90">Reuter et al., 2010</xref>), removal of non-brain tissue (<xref ref-type="bibr" rid="bib96">Ségonne et al., 2004</xref>), automated Talairach transformation, segmentation of the subcortical white matter and deep gray matter volumetric structures (<xref ref-type="bibr" rid="bib33">Fischl et al., 2002</xref>; <xref ref-type="bibr" rid="bib34">Fischl et al., 2004</xref>) intensity normalization (<xref ref-type="bibr" rid="bib102">Sled et al., 1998</xref>), tessellation of the gray-matter/white matter boundary, automated topology correction (<xref ref-type="bibr" rid="bib32">Fischl et al., 2001</xref>; <xref ref-type="bibr" rid="bib96">Ségonne et al., 2004</xref>), and surface deformation following intensity gradients (<xref ref-type="bibr" rid="bib23">Dale et al., 1999</xref>; <xref ref-type="bibr" rid="bib36">Fischl and Dale, 2000</xref>). Once cortical models were computed, so-called deformable procedures were applied including surface inflation (<xref ref-type="bibr" rid="bib31">Fischl et al., 1999</xref>), registration to a spherical atlas (<xref ref-type="bibr" rid="bib31">Fischl et al., 1999</xref>) and cortical parcellation (<xref ref-type="bibr" rid="bib24">Desikan et al., 2006</xref>).</p></sec><sec id="s4-6-3"><title>fMRI</title><p>The available fMRI data were visually inspected. The volumes were excluded from the study provided they had severe imaging artifacts or head movements with amplitude larger than 2 mm. After the rejection of corrupted data, we obtained a subset of 626 subjects for further investigation. The fMRI volumes underwent slice timing correction and motion correction to the mean volume. Following that, co-registration between anatomical and function volumes was done for every subject. Finally, brain tissue segmentation was done for every volume and the output data were morphed to the MNI space.</p></sec></sec><sec id="s4-7"><title>Scientific computation and software</title><sec id="s4-7-1"><title>Computing environment</title><p>For preprocessing and feature-extraction of MEG, MRI and fMRI we used a high-performance Linux server (72 cores, 376 GB RAM) running Ubuntu Linux 18.04.1 LTS. For subsequent statistical modeling, we used a golden Apple MacBook 12’́ (early 2016) running MacOS Mojave (8 GB RAM). General purpose computation was carried out using the Python (3.7.3) language and the scientific Python stack including NumPy, SciPy, Pandas, and Matplotlib. For embarrassingly parallel processing, we used the joblib library.</p></sec><sec id="s4-7-2"><title>MEG processing</title><p>For MEG processing, we used the MNE-Python software (<ext-link ext-link-type="uri" xlink:href="https://mne.tools">https://mne.tools</ext-link>) (<xref ref-type="bibr" rid="bib49">Gramfort et al., 2014</xref>) (version 0.19). All custom analysis code was scripted in Python and is shared in a dedicated repository including a small library and scripts (see section Code Availability).</p></sec><sec id="s4-7-3"><title>MRI and fMRI processing</title><p>For anatomical reconstruction we used the shell-scripts provided by FreeSurfer (version 6.0) software (<xref ref-type="bibr" rid="bib33">Fischl et al., 2002</xref>). We used the pypreprocess package, which reimplements parts of the SPM12 software for the analysis of brain images (<xref ref-type="bibr" rid="bib111">The Wellcome Centre for Human Neuroimaging, 2018</xref>), complemented by the Python-Matlab interface from Nipype (<xref ref-type="bibr" rid="bib47">Gorgolewski et al., 2011</xref>). For feature extraction and processing related to predictive modeling with MRI and fMRI, we used the NiLearn package (<xref ref-type="bibr" rid="bib1">Abraham et al., 2014</xref>).</p></sec><sec id="s4-7-4"><title>Statistical modeling</title><p>For predictive modeling, we used the scikit-learn package (<xref ref-type="bibr" rid="bib85">Pedregosa et al., 2011</xref>) (version 0.21). We used the R (3.5.3) language and its graphical ecosystem (<xref ref-type="bibr" rid="bib87">R Development Core Team, 2019</xref>; <xref ref-type="bibr" rid="bib121">Wickham, 2016</xref>; <xref ref-type="bibr" rid="bib103">Slowikowski, 2019</xref>; <xref ref-type="bibr" rid="bib19">Clarke and Sherrill-Mix, 2017</xref>; <xref ref-type="bibr" rid="bib17">Canty and Ripley, 2017</xref>) for statistical visualization of data. For computation of ranking-statistics, we used the pmr R-package (<xref ref-type="bibr" rid="bib72">Lee and Yu, 2013</xref>).</p></sec></sec><sec id="s4-8"><title>Code availability</title><p>We share all code used for this publication on GitHub: <ext-link ext-link-type="uri" xlink:href="https://github.com/dengemann/meg-mri-surrogate-biomarkers-aging-2020">https://github.com/dengemann/meg-mri-surrogate-biomarkers-aging-2020</ext-link>. (<xref ref-type="bibr" rid="bib28">Engemann, 2020</xref>; <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/meg-mri-surrogate-biomarkers-aging-2020">https://github.com/elifesciences-publications/meg-mri-surrogate-biomarkers-aging-2020</ext-link>) Our stacked model architecture can be compactly expressed using the <monospace>StackingRegressor</monospace> class in scikit-learn (<xref ref-type="bibr" rid="bib85">Pedregosa et al., 2011</xref>) as of version 0.22.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>This work was partly supported by a 2018 ‘médecine numérique’ (for digital medicine) thesis grant issued by Inserm (French national institute of health and medical research) and Inria (French national research institute for the digital sciences). It was also partly supported by the European Research Council Starting Grant SLAB ERC-StG-676943.</p><p>We thank Sheraz Khan for help with the Freesurfer segmentation and data management of the Cam-CAN dataset. We thank Mehdi Rahim for advice with the model stacking framework and data management of the Cam-CAN dataset. We thank Donald Krieger and Timothy Bardouille for help with the MEG co-registration. We thank Danilo Bzdok for feedback on the first version of the preprint.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf2"><p>Reviewing editor, <italic>eLife</italic></p></fn><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Resources, Data curation, Software, Investigation, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Resources, Software, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Resources, Software, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Formal analysis, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con6"><p>Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con7"><p>Conceptualization, Software, Formal analysis, Supervision, Validation, Methodology, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: This study is conducted in compliance with the Helsinki Declaration. No experiments on living beings were performed for this study. The data that we used was acquired by the Cam-CAN consortium and has been approved by the local ethics committee, Cambridgeshire 2 Research Ethics Committee (reference: 10/H0308/50).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-54055-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>We used the publicly available Cam-CAN dataset (<ext-link ext-link-type="uri" xlink:href="https://camcan-archive.mrc-cbu.cam.ac.uk/dataaccess/">https://camcan-archive.mrc-cbu.cam.ac.uk/dataaccess/</ext-link>). All software and code necessary to obtain the derivative data is shared on GitHub: <ext-link ext-link-type="uri" xlink:href="https://github.com/dengemann/meg-mri-surrogate-biomarkers-aging-2020">https://github.com/dengemann/meg-mri-surrogate-biomarkers-aging-2020</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://github.com/elifesciences-publications/meg-mri-surrogate-biomarkers-aging-2020">https://github.com/elifesciences-publications/meg-mri-surrogate-biomarkers-aging-2020</ext-link>).</p><p>The following previously published dataset was used:</p><p><element-citation id="dataset1" publication-type="data" specific-use="references"><person-group person-group-type="author"><name><surname>Shafto</surname><given-names>MA</given-names></name><name><surname>Tyler</surname><given-names>LK</given-names></name><name><surname>Dixon</surname><given-names>M</given-names></name><name><surname>Taylor</surname><given-names>JR</given-names></name><name><surname>Rowe</surname><given-names>JB</given-names></name><name><surname>Cusack</surname><given-names>R</given-names></name><name><surname>Calder</surname><given-names>AJ</given-names></name><name><surname>Marslen-Wilson</surname><given-names>WD</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name><name><surname>Dalgleish</surname><given-names>T</given-names></name><name><surname>Henson</surname><given-names>RN</given-names></name><name><surname>Brayne</surname><given-names>C</given-names></name><name><surname>Matthews</surname><given-names>FE</given-names></name><collab>Cam-CAN</collab></person-group><year iso-8601-date="2014">2014</year><data-title>Cam-CAN</data-title><source>Cam-CAN Data Portal</source><pub-id assigning-authority="other" pub-id-type="archive" xlink:href="https://camcan-archive.mrc-cbu.cam.ac.uk/dataaccess/">Cam-CAN</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abraham</surname> <given-names>A</given-names></name><name><surname>Pedregosa</surname> <given-names>F</given-names></name><name><surname>Eickenberg</surname> <given-names>M</given-names></name><name><surname>Gervais</surname> <given-names>P</given-names></name><name><surname>Mueller</surname> <given-names>A</given-names></name><name><surname>Kossaifi</surname> <given-names>J</given-names></name><name><surname>Gramfort</surname> <given-names>A</given-names></name><name><surname>Thirion</surname> <given-names>B</given-names></name><name><surname>Varoquaux</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Machine learning for neuroimaging with scikit-learn</article-title><source>Frontiers in Neuroinformatics</source><volume>8</volume><elocation-id>14</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2014.00014</pub-id><pub-id pub-id-type="pmid">24600388</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abraham</surname> <given-names>A</given-names></name><name><surname>Milham</surname> <given-names>MP</given-names></name><name><surname>Di Martino</surname> <given-names>A</given-names></name><name><surname>Craddock</surname> <given-names>RC</given-names></name><name><surname>Samaras</surname> <given-names>D</given-names></name><name><surname>Thirion</surname> <given-names>B</given-names></name><name><surname>Varoquaux</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Deriving reproducible biomarkers from multi-site resting-state data: an Autism-based example</article-title><source>NeuroImage</source><volume>147</volume><fpage>736</fpage><lpage>745</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.10.045</pub-id><pub-id pub-id-type="pmid">27865923</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Agnew</surname> <given-names>HW</given-names></name><name><surname>Webb</surname> <given-names>WB</given-names></name><name><surname>Williams</surname> <given-names>RL</given-names></name></person-group><year iso-8601-date="1966">1966</year><article-title>The first night effect: an EEG study of sleep</article-title><source>Psychophysiology</source><volume>2</volume><fpage>263</fpage><lpage>266</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.1966.tb02650.x</pub-id><pub-id pub-id-type="pmid">5903579</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahlfors</surname> <given-names>SP</given-names></name><name><surname>Han</surname> <given-names>J</given-names></name><name><surname>Belliveau</surname> <given-names>JW</given-names></name><name><surname>Hämäläinen</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Sensitivity of MEG and EEG to source orientation</article-title><source>Brain Topography</source><volume>23</volume><fpage>227</fpage><lpage>232</lpage><pub-id pub-id-type="doi">10.1007/s10548-010-0154-x</pub-id><pub-id pub-id-type="pmid">20640882</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Babayan</surname> <given-names>A</given-names></name><name><surname>Erbey</surname> <given-names>M</given-names></name><name><surname>Kumral</surname> <given-names>D</given-names></name><name><surname>Reinelt</surname> <given-names>JD</given-names></name><name><surname>Reiter</surname> <given-names>AMF</given-names></name><name><surname>Röbbig</surname> <given-names>J</given-names></name><name><surname>Schaare</surname> <given-names>HL</given-names></name><name><surname>Uhlig</surname> <given-names>M</given-names></name><name><surname>Anwander</surname> <given-names>A</given-names></name><name><surname>Bazin</surname> <given-names>P-L</given-names></name><name><surname>Horstmann</surname> <given-names>A</given-names></name><name><surname>Lampe</surname> <given-names>L</given-names></name><name><surname>Nikulin</surname> <given-names>VV</given-names></name><name><surname>Okon-Singer</surname> <given-names>H</given-names></name><name><surname>Preusser</surname> <given-names>S</given-names></name><name><surname>Pampel</surname> <given-names>A</given-names></name><name><surname>Rohr</surname> <given-names>CS</given-names></name><name><surname>Sacher</surname> <given-names>J</given-names></name><name><surname>Thöne-Otto</surname> <given-names>A</given-names></name><name><surname>Trapp</surname> <given-names>S</given-names></name><name><surname>Nierhaus</surname> <given-names>T</given-names></name><name><surname>Altmann</surname> <given-names>D</given-names></name><name><surname>Arelin</surname> <given-names>K</given-names></name><name><surname>Blöchl</surname> <given-names>M</given-names></name><name><surname>Bongartz</surname> <given-names>E</given-names></name><name><surname>Breig</surname> <given-names>P</given-names></name><name><surname>Cesnaite</surname> <given-names>E</given-names></name><name><surname>Chen</surname> <given-names>S</given-names></name><name><surname>Cozatl</surname> <given-names>R</given-names></name><name><surname>Czerwonatis</surname> <given-names>S</given-names></name><name><surname>Dambrauskaite</surname> <given-names>G</given-names></name><name><surname>Dreyer</surname> <given-names>M</given-names></name><name><surname>Enders</surname> <given-names>J</given-names></name><name><surname>Engelhardt</surname> <given-names>M</given-names></name><name><surname>Fischer</surname> <given-names>MM</given-names></name><name><surname>Forschack</surname> <given-names>N</given-names></name><name><surname>Golchert</surname> <given-names>J</given-names></name><name><surname>Golz</surname> <given-names>L</given-names></name><name><surname>Guran</surname> <given-names>CA</given-names></name><name><surname>Hedrich</surname> <given-names>S</given-names></name><name><surname>Hentschel</surname> <given-names>N</given-names></name><name><surname>Hoffmann</surname> <given-names>DI</given-names></name><name><surname>Huntenburg</surname> <given-names>JM</given-names></name><name><surname>Jost</surname> <given-names>R</given-names></name><name><surname>Kosatschek</surname> <given-names>A</given-names></name><name><surname>Kunzendorf</surname> <given-names>S</given-names></name><name><surname>Lammers</surname> <given-names>H</given-names></name><name><surname>Lauckner</surname> <given-names>ME</given-names></name><name><surname>Mahjoory</surname> <given-names>K</given-names></name><name><surname>Kanaan</surname> <given-names>AS</given-names></name><name><surname>Mendes</surname> <given-names>N</given-names></name><name><surname>Menger</surname> <given-names>R</given-names></name><name><surname>Morino</surname> <given-names>E</given-names></name><name><surname>Näthe</surname> <given-names>K</given-names></name><name><surname>Neubauer</surname> <given-names>J</given-names></name><name><surname>Noyan</surname> <given-names>H</given-names></name><name><surname>Oligschläger</surname> <given-names>S</given-names></name><name><surname>Panczyszyn-Trzewik</surname> <given-names>P</given-names></name><name><surname>Poehlchen</surname> <given-names>D</given-names></name><name><surname>Putzke</surname> <given-names>N</given-names></name><name><surname>Roski</surname> <given-names>S</given-names></name><name><surname>Schaller</surname> <given-names>M-C</given-names></name><name><surname>Schieferbein</surname> <given-names>A</given-names></name><name><surname>Schlaak</surname> <given-names>B</given-names></name><name><surname>Schmidt</surname> <given-names>R</given-names></name><name><surname>Gorgolewski</surname> <given-names>KJ</given-names></name><name><surname>Schmidt</surname> <given-names>HM</given-names></name><name><surname>Schrimpf</surname> <given-names>A</given-names></name><name><surname>Stasch</surname> <given-names>S</given-names></name><name><surname>Voss</surname> <given-names>M</given-names></name><name><surname>Wiedemann</surname> <given-names>A</given-names></name><name><surname>Margulies</surname> <given-names>DS</given-names></name><name><surname>Gaebler</surname> <given-names>M</given-names></name><name><surname>Villringer</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A mind-brain-body dataset of MRI, EEG, cognition, emotion, and peripheral physiology in young and old adults</article-title><source>Scientific Data</source><volume>6</volume><elocation-id>180308</elocation-id><pub-id pub-id-type="doi">10.1038/sdata.2018.308</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Babiloni</surname> <given-names>C</given-names></name><name><surname>Binetti</surname> <given-names>G</given-names></name><name><surname>Cassarino</surname> <given-names>A</given-names></name><name><surname>Dal Forno</surname> <given-names>G</given-names></name><name><surname>Del Percio</surname> <given-names>C</given-names></name><name><surname>Ferreri</surname> <given-names>F</given-names></name><name><surname>Ferri</surname> <given-names>R</given-names></name><name><surname>Frisoni</surname> <given-names>G</given-names></name><name><surname>Galderisi</surname> <given-names>S</given-names></name><name><surname>Hirata</surname> <given-names>K</given-names></name><name><surname>Lanuzza</surname> <given-names>B</given-names></name><name><surname>Miniussi</surname> <given-names>C</given-names></name><name><surname>Mucci</surname> <given-names>A</given-names></name><name><surname>Nobili</surname> <given-names>F</given-names></name><name><surname>Rodriguez</surname> <given-names>G</given-names></name><name><surname>Luca Romani</surname> <given-names>G</given-names></name><name><surname>Rossini</surname> <given-names>PM</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Sources of cortical rhythms in adults during physiological aging: a multicentric EEG study</article-title><source>Human Brain Mapping</source><volume>27</volume><fpage>162</fpage><lpage>172</lpage><pub-id pub-id-type="doi">10.1002/hbm.20175</pub-id><pub-id pub-id-type="pmid">16108018</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname> <given-names>JD</given-names></name><name><surname>Gluecklich</surname> <given-names>B</given-names></name><name><surname>Watson</surname> <given-names>CW</given-names></name><name><surname>Marcus</surname> <given-names>E</given-names></name><name><surname>Kamat</surname> <given-names>V</given-names></name><name><surname>Callow</surname> <given-names>AD</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>An evaluation of electroencephalographic monitoring for carotid study</article-title><source>Surgery</source><volume>78</volume><fpage>787</fpage><lpage>794</lpage><pub-id pub-id-type="doi">10.5555/uri:pii:0039606075902068</pub-id><pub-id pub-id-type="pmid">1188621</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname> <given-names>AP</given-names></name><name><surname>Brookes</surname> <given-names>MJ</given-names></name><name><surname>Rezek</surname> <given-names>IA</given-names></name><name><surname>Smith</surname> <given-names>SM</given-names></name><name><surname>Behrens</surname> <given-names>T</given-names></name><name><surname>Probert Smith</surname> <given-names>PJ</given-names></name><name><surname>Woolrich</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Fast transient networks in spontaneous human brain activity</article-title><source>eLife</source><volume>3</volume><elocation-id>e01867</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.01867</pub-id><pub-id pub-id-type="pmid">24668169</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barttfeld</surname> <given-names>P</given-names></name><name><surname>Uhrig</surname> <given-names>L</given-names></name><name><surname>Sitt</surname> <given-names>JD</given-names></name><name><surname>Sigman</surname> <given-names>M</given-names></name><name><surname>Jarraya</surname> <given-names>B</given-names></name><name><surname>Dehaene</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Signature of consciousness in the dynamics of resting-state brain activity</article-title><source>PNAS</source><volume>112</volume><fpage>887</fpage><lpage>892</lpage><pub-id pub-id-type="doi">10.1073/pnas.1418031112</pub-id><pub-id pub-id-type="pmid">25561541</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellec</surname> <given-names>P</given-names></name><name><surname>Rosa-Neto</surname> <given-names>P</given-names></name><name><surname>Lyttelton</surname> <given-names>OC</given-names></name><name><surname>Benali</surname> <given-names>H</given-names></name><name><surname>Evans</surname> <given-names>AC</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Multi-level bootstrap analysis of stable clusters in resting-state fMRI</article-title><source>NeuroImage</source><volume>51</volume><fpage>1126</fpage><lpage>1139</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.02.082</pub-id><pub-id pub-id-type="pmid">20226257</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Biecek</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Dalex: explainers for complex predictive models in r</article-title><source>The Journal of Machine Learning Research</source><volume>19</volume><fpage>3245</fpage><lpage>3249</lpage></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Breiman</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Random forests</article-title><source>Machine Learning</source><volume>45</volume><fpage>5</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1023/A:1010933404324</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brookes</surname> <given-names>MJ</given-names></name><name><surname>Woolrich</surname> <given-names>M</given-names></name><name><surname>Luckhoo</surname> <given-names>H</given-names></name><name><surname>Price</surname> <given-names>D</given-names></name><name><surname>Hale</surname> <given-names>JR</given-names></name><name><surname>Stephenson</surname> <given-names>MC</given-names></name><name><surname>Barnes</surname> <given-names>GR</given-names></name><name><surname>Smith</surname> <given-names>SM</given-names></name><name><surname>Morris</surname> <given-names>PG</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Investigating the electrophysiological basis of resting state networks using magnetoencephalography</article-title><source>PNAS</source><volume>108</volume><fpage>16783</fpage><lpage>16788</lpage><pub-id pub-id-type="doi">10.1073/pnas.1112685108</pub-id><pub-id pub-id-type="pmid">21930901</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Bzdok</surname> <given-names>D</given-names></name><name><surname>Engemann</surname> <given-names>D</given-names></name><name><surname>Grisel</surname> <given-names>O</given-names></name><name><surname>Varoquaux</surname> <given-names>G</given-names></name><name><surname>Thirion</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Prediction and inference diverge in biomedicine: simulations and Real-World data</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/327437</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bzdok</surname> <given-names>D</given-names></name><name><surname>Ioannidis</surname> <given-names>JPA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Exploration, inference, and prediction in neuroscience and biomedicine</article-title><source>Trends in Neurosciences</source><volume>42</volume><fpage>251</fpage><lpage>262</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2019.02.001</pub-id><pub-id pub-id-type="pmid">30808574</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bzdok</surname> <given-names>D</given-names></name><name><surname>Yeo</surname> <given-names>BTT</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Inference in the age of big data: future perspectives on neuroscience</article-title><source>NeuroImage</source><volume>155</volume><fpage>549</fpage><lpage>564</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.04.061</pub-id><pub-id pub-id-type="pmid">28456584</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Canty</surname> <given-names>A</given-names></name><name><surname>Ripley</surname> <given-names>BD</given-names></name></person-group><year iso-8601-date="2017">2017</year><data-title>Boot: Bootstrap R (S-Plus) Functions</data-title><source>R Package</source></element-citation></ref><ref id="bib18"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>Y</given-names></name><name><surname>Wiesel</surname> <given-names>A</given-names></name><name><surname>Eldar</surname> <given-names>YC</given-names></name><name><surname>Hero</surname> <given-names>AO</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Shrinkage algorithms for MMSE covariance estimation</article-title><conf-name>IEEE Transactions on Signal Processing</conf-name><fpage>5016</fpage><lpage>5029</lpage><pub-id pub-id-type="doi">10.1109/TSP.2010.2053029</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Clarke</surname> <given-names>E</given-names></name><name><surname>Sherrill-Mix</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><data-title>ggbeeswarm: Categorical Scatter (Violin Point) Plots</data-title><source>R Package</source></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cole</surname> <given-names>JH</given-names></name><name><surname>Leech</surname> <given-names>R</given-names></name><name><surname>Sharp</surname> <given-names>DJ</given-names></name><collab>Alzheimer's Disease Neuroimaging Initiative</collab></person-group><year iso-8601-date="2015">2015</year><article-title>Prediction of brain age suggests accelerated atrophy after traumatic brain injury</article-title><source>Annals of Neurology</source><volume>77</volume><fpage>571</fpage><lpage>581</lpage><pub-id pub-id-type="doi">10.1002/ana.24367</pub-id><pub-id pub-id-type="pmid">25623048</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cole</surname> <given-names>JH</given-names></name><name><surname>Ritchie</surname> <given-names>SJ</given-names></name><name><surname>Bastin</surname> <given-names>ME</given-names></name><name><surname>Valdés Hernández</surname> <given-names>MC</given-names></name><name><surname>Muñoz Maniega</surname> <given-names>S</given-names></name><name><surname>Royle</surname> <given-names>N</given-names></name><name><surname>Corley</surname> <given-names>J</given-names></name><name><surname>Pattie</surname> <given-names>A</given-names></name><name><surname>Harris</surname> <given-names>SE</given-names></name><name><surname>Zhang</surname> <given-names>Q</given-names></name><name><surname>Wray</surname> <given-names>NR</given-names></name><name><surname>Redmond</surname> <given-names>P</given-names></name><name><surname>Marioni</surname> <given-names>RE</given-names></name><name><surname>Starr</surname> <given-names>JM</given-names></name><name><surname>Cox</surname> <given-names>SR</given-names></name><name><surname>Wardlaw</surname> <given-names>JM</given-names></name><name><surname>Sharp</surname> <given-names>DJ</given-names></name><name><surname>Deary</surname> <given-names>IJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Brain age predicts mortality</article-title><source>Molecular Psychiatry</source><volume>23</volume><fpage>1385</fpage><lpage>1392</lpage><pub-id pub-id-type="doi">10.1038/mp.2017.62</pub-id><pub-id pub-id-type="pmid">28439103</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dadi</surname> <given-names>K</given-names></name><name><surname>Rahim</surname> <given-names>M</given-names></name><name><surname>Abraham</surname> <given-names>A</given-names></name><name><surname>Chyzhyk</surname> <given-names>D</given-names></name><name><surname>Milham</surname> <given-names>M</given-names></name><name><surname>Thirion</surname> <given-names>B</given-names></name><name><surname>Varoquaux</surname> <given-names>G</given-names></name><collab>Alzheimer's Disease Neuroimaging Initiative</collab></person-group><year iso-8601-date="2019">2019</year><article-title>Benchmarking functional connectome-based predictive models for resting-state fMRI</article-title><source>NeuroImage</source><volume>192</volume><fpage>115</fpage><lpage>134</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.02.062</pub-id><pub-id pub-id-type="pmid">30836146</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dale</surname> <given-names>AM</given-names></name><name><surname>Fischl</surname> <given-names>B</given-names></name><name><surname>Sereno</surname> <given-names>MI</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Cortical surface-based analysis. I. segmentation and surface reconstruction</article-title><source>NeuroImage</source><volume>9</volume><fpage>179</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1006/nimg.1998.0395</pub-id><pub-id pub-id-type="pmid">9931268</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desikan</surname> <given-names>RS</given-names></name><name><surname>Ségonne</surname> <given-names>F</given-names></name><name><surname>Fischl</surname> <given-names>B</given-names></name><name><surname>Quinn</surname> <given-names>BT</given-names></name><name><surname>Dickerson</surname> <given-names>BC</given-names></name><name><surname>Blacker</surname> <given-names>D</given-names></name><name><surname>Buckner</surname> <given-names>RL</given-names></name><name><surname>Dale</surname> <given-names>AM</given-names></name><name><surname>Maguire</surname> <given-names>RP</given-names></name><name><surname>Hyman</surname> <given-names>BT</given-names></name><name><surname>Albert</surname> <given-names>MS</given-names></name><name><surname>Killiany</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest</article-title><source>NeuroImage</source><volume>31</volume><fpage>968</fpage><lpage>980</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.01.021</pub-id><pub-id pub-id-type="pmid">16530430</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dosenbach</surname> <given-names>NU</given-names></name><name><surname>Nardos</surname> <given-names>B</given-names></name><name><surname>Cohen</surname> <given-names>AL</given-names></name><name><surname>Fair</surname> <given-names>DA</given-names></name><name><surname>Power</surname> <given-names>JD</given-names></name><name><surname>Church</surname> <given-names>JA</given-names></name><name><surname>Nelson</surname> <given-names>SM</given-names></name><name><surname>Wig</surname> <given-names>GS</given-names></name><name><surname>Vogel</surname> <given-names>AC</given-names></name><name><surname>Lessov-Schlaggar</surname> <given-names>CN</given-names></name><name><surname>Barnes</surname> <given-names>KA</given-names></name><name><surname>Dubis</surname> <given-names>JW</given-names></name><name><surname>Feczko</surname> <given-names>E</given-names></name><name><surname>Coalson</surname> <given-names>RS</given-names></name><name><surname>Pruett</surname> <given-names>JR</given-names></name><name><surname>Barch</surname> <given-names>DM</given-names></name><name><surname>Petersen</surname> <given-names>SE</given-names></name><name><surname>Schlaggar</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Prediction of individual brain maturity using fMRI</article-title><source>Science</source><volume>329</volume><fpage>1358</fpage><lpage>1361</lpage><pub-id pub-id-type="doi">10.1126/science.1194144</pub-id><pub-id pub-id-type="pmid">20829489</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Efron</surname> <given-names>B</given-names></name><name><surname>Hastie</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><source>Computer Age Statistical Inference</source><publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1017/CBO9781316576533</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engemann</surname> <given-names>DA</given-names></name><name><surname>Raimondo</surname> <given-names>F</given-names></name><name><surname>King</surname> <given-names>JR</given-names></name><name><surname>Rohaut</surname> <given-names>B</given-names></name><name><surname>Louppe</surname> <given-names>G</given-names></name><name><surname>Faugeras</surname> <given-names>F</given-names></name><name><surname>Annen</surname> <given-names>J</given-names></name><name><surname>Cassol</surname> <given-names>H</given-names></name><name><surname>Gosseries</surname> <given-names>O</given-names></name><name><surname>Fernandez-Slezak</surname> <given-names>D</given-names></name><name><surname>Laureys</surname> <given-names>S</given-names></name><name><surname>Naccache</surname> <given-names>L</given-names></name><name><surname>Dehaene</surname> <given-names>S</given-names></name><name><surname>Sitt</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Robust EEG-based cross-site and cross-protocol classification of states of consciousness</article-title><source>Brain</source><volume>141</volume><fpage>3179</fpage><lpage>3192</lpage><pub-id pub-id-type="doi">10.1093/brain/awy251</pub-id><pub-id pub-id-type="pmid">30285102</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Engemann</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>paper-brain-age-figures</data-title><source>GitHub</source><version designator="8df48c3">8df48c3</version><ext-link ext-link-type="uri" xlink:href="https://github.com/dengemann/meg-mri-surrogate-biomarkers-aging-2020">https://github.com/dengemann/meg-mri-surrogate-biomarkers-aging-2020</ext-link></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engemann</surname> <given-names>DA</given-names></name><name><surname>Gramfort</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Automated model selection in covariance estimation and spatial whitening of MEG and EEG signals</article-title><source>NeuroImage</source><volume>108</volume><fpage>328</fpage><lpage>342</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.12.040</pub-id><pub-id pub-id-type="pmid">25541187</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Esteva</surname> <given-names>A</given-names></name><name><surname>Kuprel</surname> <given-names>B</given-names></name><name><surname>Novoa</surname> <given-names>RA</given-names></name><name><surname>Ko</surname> <given-names>J</given-names></name><name><surname>Swetter</surname> <given-names>SM</given-names></name><name><surname>Blau</surname> <given-names>HM</given-names></name><name><surname>Thrun</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dermatologist-level classification of skin Cancer with deep neural networks</article-title><source>Nature</source><volume>542</volume><fpage>115</fpage><lpage>118</lpage><pub-id pub-id-type="doi">10.1038/nature21056</pub-id><pub-id pub-id-type="pmid">28117445</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname> <given-names>B</given-names></name><name><surname>Sereno</surname> <given-names>MI</given-names></name><name><surname>Dale</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Cortical surface-based analysis. II: inflation, flattening, and a surface-based coordinate system</article-title><source>NeuroImage</source><volume>9</volume><fpage>195</fpage><lpage>207</lpage><pub-id pub-id-type="doi">10.1006/nimg.1998.0396</pub-id><pub-id pub-id-type="pmid">9931269</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname> <given-names>B</given-names></name><name><surname>Liu</surname> <given-names>A</given-names></name><name><surname>Dale</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Automated manifold surgery: constructing geometrically accurate and topologically correct models of the human cerebral cortex</article-title><source>IEEE Transactions on Medical Imaging</source><volume>20</volume><fpage>70</fpage><lpage>80</lpage><pub-id pub-id-type="doi">10.1109/42.906426</pub-id><pub-id pub-id-type="pmid">11293693</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname> <given-names>B</given-names></name><name><surname>Salat</surname> <given-names>DH</given-names></name><name><surname>Busa</surname> <given-names>E</given-names></name><name><surname>Albert</surname> <given-names>M</given-names></name><name><surname>Dieterich</surname> <given-names>M</given-names></name><name><surname>Haselgrove</surname> <given-names>C</given-names></name><name><surname>van der Kouwe</surname> <given-names>A</given-names></name><name><surname>Killiany</surname> <given-names>R</given-names></name><name><surname>Kennedy</surname> <given-names>D</given-names></name><name><surname>Klaveness</surname> <given-names>S</given-names></name><name><surname>Montillo</surname> <given-names>A</given-names></name><name><surname>Makris</surname> <given-names>N</given-names></name><name><surname>Rosen</surname> <given-names>B</given-names></name><name><surname>Dale</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Whole brain segmentation</article-title><source>Neuron</source><volume>33</volume><fpage>341</fpage><lpage>355</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(02)00569-X</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname> <given-names>B</given-names></name><name><surname>Salat</surname> <given-names>DH</given-names></name><name><surname>van der Kouwe</surname> <given-names>AJ</given-names></name><name><surname>Makris</surname> <given-names>N</given-names></name><name><surname>Ségonne</surname> <given-names>F</given-names></name><name><surname>Quinn</surname> <given-names>BT</given-names></name><name><surname>Dale</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Sequence-independent segmentation of magnetic resonance images</article-title><source>NeuroImage</source><volume>23 Suppl 1</volume><fpage>S69</fpage><lpage>S84</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.07.016</pub-id><pub-id pub-id-type="pmid">15501102</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>FreeSurfer</article-title><source>NeuroImage</source><volume>62</volume><fpage>774</fpage><lpage>781</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.01.021</pub-id><pub-id pub-id-type="pmid">22248573</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname> <given-names>B</given-names></name><name><surname>Dale</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Measuring the thickness of the human cerebral cortex from magnetic resonance images</article-title><source>PNAS</source><volume>97</volume><fpage>11050</fpage><lpage>11055</lpage><pub-id pub-id-type="doi">10.1073/pnas.200033797</pub-id><pub-id pub-id-type="pmid">10984517</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedman</surname> <given-names>NP</given-names></name><name><surname>Miyake</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>The relations among inhibition and interference control functions: a Latent-Variable analysis</article-title><source>Journal of Experimental Psychology: General</source><volume>133</volume><fpage>101</fpage><lpage>135</lpage><pub-id pub-id-type="doi">10.1037/0096-3445.133.1.101</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Fruehwirt</surname> <given-names>W</given-names></name><name><surname>Gerstgrasser</surname> <given-names>M</given-names></name><name><surname>Zhang</surname> <given-names>P</given-names></name><name><surname>Weydemann</surname> <given-names>L</given-names></name><name><surname>Waser</surname> <given-names>M</given-names></name><name><surname>Schmidt</surname> <given-names>R</given-names></name><name><surname>Benke</surname> <given-names>T</given-names></name><name><surname>Dal-Bianco</surname> <given-names>P</given-names></name><name><surname>Ransmayr</surname> <given-names>G</given-names></name><name><surname>Grossegger</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Riemannian tangent space mapping and elastic net regularization for cost-effective eeg markers of brain atrophy in Alzheimer’s disease</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1711.08359">https://arxiv.org/abs/1711.08359</ext-link></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garcés</surname> <given-names>P</given-names></name><name><surname>López-Sanz</surname> <given-names>D</given-names></name><name><surname>Maestú</surname> <given-names>F</given-names></name><name><surname>Pereda</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Choice of magnetometers and gradiometers after signal space separation</article-title><source>Sensors</source><volume>17</volume><elocation-id>2926</elocation-id><pub-id pub-id-type="doi">10.3390/s17122926</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gaubert</surname> <given-names>S</given-names></name><name><surname>Raimondo</surname> <given-names>F</given-names></name><name><surname>Houot</surname> <given-names>M</given-names></name><name><surname>Corsi</surname> <given-names>MC</given-names></name><name><surname>Naccache</surname> <given-names>L</given-names></name><name><surname>Diego Sitt</surname> <given-names>J</given-names></name><name><surname>Hermann</surname> <given-names>B</given-names></name><name><surname>Oudiette</surname> <given-names>D</given-names></name><name><surname>Gagliardi</surname> <given-names>G</given-names></name><name><surname>Habert</surname> <given-names>MO</given-names></name><name><surname>Dubois</surname> <given-names>B</given-names></name><name><surname>De Vico Fallani</surname> <given-names>F</given-names></name><name><surname>Bakardjian</surname> <given-names>H</given-names></name><name><surname>Epelbaum</surname> <given-names>S</given-names></name><collab>Alzheimer’s Disease Neuroimaging Initiative</collab></person-group><year iso-8601-date="2019">2019</year><article-title>EEG evidence of compensatory mechanisms in preclinical alzheimer's disease</article-title><source>Brain</source><volume>142</volume><fpage>2096</fpage><lpage>2112</lpage><pub-id pub-id-type="doi">10.1093/brain/awz150</pub-id><pub-id pub-id-type="pmid">31211359</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geerligs</surname> <given-names>L</given-names></name><name><surname>Tsvetanov</surname> <given-names>KA</given-names></name><collab>Cam-CAN</collab><name><surname>Henson</surname> <given-names>RN</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Challenges in measuring individual differences in functional connectivity using fMRI: The case of healthy aging</article-title><source>Human Brain Mapping</source><volume>38</volume><fpage>4125</fpage><lpage>4156</lpage><pub-id pub-id-type="doi">10.1002/hbm.23653</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Gemein</surname> <given-names>LAW</given-names></name><name><surname>Schirrmeister</surname> <given-names>RT</given-names></name><name><surname>Chrabąszcz</surname> <given-names>P</given-names></name><name><surname>Wilson</surname> <given-names>D</given-names></name><name><surname>Boedecker</surname> <given-names>J</given-names></name><name><surname>Schulze-Bonhage</surname> <given-names>A</given-names></name><name><surname>Hutter</surname> <given-names>F</given-names></name><name><surname>Ball</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Machine-learning-based diagnostics of EEG pathology</article-title><source>NeuroImage</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2020.117021">https://doi.org/10.1016/j.neuroimage.2020.117021</ext-link></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geurts</surname> <given-names>P</given-names></name><name><surname>Ernst</surname> <given-names>D</given-names></name><name><surname>Wehenkel</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Extremely randomized trees</article-title><source>Machine Learning</source><volume>63</volume><fpage>3</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1007/s10994-006-6226-1</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gobbelé</surname> <given-names>R</given-names></name><name><surname>Buchner</surname> <given-names>H</given-names></name><name><surname>Curio</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>High-frequency (600 hz) SEP activities originating in the subcortical and cortical human somatosensory system</article-title><source>Electroencephalography and Clinical Neurophysiology/Evoked Potentials Section</source><volume>108</volume><fpage>182</fpage><lpage>189</lpage><pub-id pub-id-type="doi">10.1016/S0168-5597(97)00100-7</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gola</surname> <given-names>M</given-names></name><name><surname>Magnuski</surname> <given-names>M</given-names></name><name><surname>Szumska</surname> <given-names>I</given-names></name><name><surname>Wróbel</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>EEG beta band activity is related to attention and attentional deficits in the visual performance of elderly subjects</article-title><source>International Journal of Psychophysiology</source><volume>89</volume><fpage>334</fpage><lpage>341</lpage><pub-id pub-id-type="doi">10.1016/j.ijpsycho.2013.05.007</pub-id><pub-id pub-id-type="pmid">23688673</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Golub</surname> <given-names>GH</given-names></name><name><surname>Heath</surname> <given-names>M</given-names></name><name><surname>Wahba</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Generalized Cross-Validation as a method for choosing a good ridge parameter</article-title><source>Technometrics</source><volume>21</volume><fpage>215</fpage><lpage>223</lpage><pub-id pub-id-type="doi">10.1080/00401706.1979.10489751</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorgolewski</surname> <given-names>K</given-names></name><name><surname>Burns</surname> <given-names>CD</given-names></name><name><surname>Madison</surname> <given-names>C</given-names></name><name><surname>Clark</surname> <given-names>D</given-names></name><name><surname>Halchenko</surname> <given-names>YO</given-names></name><name><surname>Waskom</surname> <given-names>ML</given-names></name><name><surname>Ghosh</surname> <given-names>SS</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in Python</article-title><source>Frontiers in Neuroinformatics</source><volume>5</volume><elocation-id>13</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2011.00013</pub-id><pub-id pub-id-type="pmid">21897815</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gramfort</surname> <given-names>A</given-names></name><name><surname>Luessi</surname> <given-names>M</given-names></name><name><surname>Larson</surname> <given-names>E</given-names></name><name><surname>Engemann</surname> <given-names>DA</given-names></name><name><surname>Strohmeier</surname> <given-names>D</given-names></name><name><surname>Brodbeck</surname> <given-names>C</given-names></name><name><surname>Goj</surname> <given-names>R</given-names></name><name><surname>Jas</surname> <given-names>M</given-names></name><name><surname>Brooks</surname> <given-names>T</given-names></name><name><surname>Parkkonen</surname> <given-names>L</given-names></name><name><surname>Hämäläinen</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>MEG and EEG data analysis with MNE-Python</article-title><source>Frontiers in Neuroscience</source><volume>7</volume><elocation-id>267</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2013.00267</pub-id><pub-id pub-id-type="pmid">24431986</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gramfort</surname> <given-names>A</given-names></name><name><surname>Luessi</surname> <given-names>M</given-names></name><name><surname>Larson</surname> <given-names>E</given-names></name><name><surname>Engemann</surname> <given-names>DA</given-names></name><name><surname>Strohmeier</surname> <given-names>D</given-names></name><name><surname>Brodbeck</surname> <given-names>C</given-names></name><name><surname>Parkkonen</surname> <given-names>L</given-names></name><name><surname>Hämäläinen</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>MNE software for processing MEG and EEG data</article-title><source>NeuroImage</source><volume>86</volume><fpage>446</fpage><lpage>460</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.10.027</pub-id><pub-id pub-id-type="pmid">24161808</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hämäläinen</surname> <given-names>MS</given-names></name><name><surname>Ilmoniemi</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Interpreting magnetic fields of the brain: minimum norm estimates</article-title><source>Medical &amp; Biological Engineering &amp; Computing</source><volume>32</volume><fpage>35</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1007/BF02512476</pub-id><pub-id pub-id-type="pmid">8182960</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hari</surname> <given-names>R</given-names></name><name><surname>Levänen</surname> <given-names>S</given-names></name><name><surname>Raij</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Timing of human cortical functions during cognition: role of MEG</article-title><source>Trends in Cognitive Sciences</source><volume>4</volume><fpage>455</fpage><lpage>462</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(00)01549-7</pub-id><pub-id pub-id-type="pmid">11115759</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hastie</surname> <given-names>T</given-names></name><name><surname>Tibshirani</surname> <given-names>R</given-names></name><name><surname>Friedman</surname> <given-names>J</given-names></name><name><surname>Franklin</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2005">2005</year><chapter-title>The elements of statistical learning: data mining, inference and prediction</chapter-title><person-group person-group-type="editor"><name><surname>Tibshirani</surname> <given-names>R</given-names></name><name><surname>Friedman</surname> <given-names>J. H</given-names></name><name><surname>Hastie</surname> <given-names>T</given-names></name></person-group><source>The Mathematical Intelligencer</source><volume>27</volume><publisher-name>Springer</publisher-name><fpage>83</fpage><lpage>85</lpage><pub-id pub-id-type="doi">10.1007/978-0-387-84858-7</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haufe</surname> <given-names>S</given-names></name><name><surname>Meinecke</surname> <given-names>F</given-names></name><name><surname>Görgen</surname> <given-names>K</given-names></name><name><surname>Dähne</surname> <given-names>S</given-names></name><name><surname>Haynes</surname> <given-names>JD</given-names></name><name><surname>Blankertz</surname> <given-names>B</given-names></name><name><surname>Bießmann</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>On the interpretation of weight vectors of linear models in multivariate neuroimaging</article-title><source>NeuroImage</source><volume>87</volume><fpage>96</fpage><lpage>110</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.10.067</pub-id><pub-id pub-id-type="pmid">24239590</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hipp</surname> <given-names>JF</given-names></name><name><surname>Hawellek</surname> <given-names>DJ</given-names></name><name><surname>Corbetta</surname> <given-names>M</given-names></name><name><surname>Siegel</surname> <given-names>M</given-names></name><name><surname>Engel</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Large-scale cortical correlation structure of spontaneous oscillatory activity</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>884</fpage><lpage>890</lpage><pub-id pub-id-type="doi">10.1038/nn.3101</pub-id><pub-id pub-id-type="pmid">22561454</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hipp</surname> <given-names>JF</given-names></name><name><surname>Siegel</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>BOLD fMRI correlation reflects Frequency-Specific neuronal correlation</article-title><source>Current Biology</source><volume>25</volume><fpage>1368</fpage><lpage>1374</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.03.049</pub-id><pub-id pub-id-type="pmid">25936551</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoerl</surname> <given-names>AE</given-names></name><name><surname>Kennard</surname> <given-names>RW</given-names></name></person-group><year iso-8601-date="1970">1970</year><article-title>Ridge regression: biased estimation for nonorthogonal problems</article-title><source>Technometrics</source><volume>12</volume><fpage>55</fpage><lpage>67</lpage><pub-id pub-id-type="doi">10.1080/00401706.1970.10488634</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hosford</surname> <given-names>PS</given-names></name><name><surname>Gourine</surname> <given-names>AV</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>What is the key mediator of the neurovascular coupling response?</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><volume>96</volume><fpage>174</fpage><lpage>181</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2018.11.011</pub-id><pub-id pub-id-type="pmid">30481531</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Hoyos-Idrobo</surname> <given-names>A</given-names></name><name><surname>Varoquaux</surname> <given-names>G</given-names></name><name><surname>Kahn</surname> <given-names>J</given-names></name><name><surname>Thirion</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Recursive nearest agglomeration (ReNA): Fast clustering for approximation of structured signals</article-title><conf-name>IEEE Transactions on Pattern Analysis and Machine Intelligence</conf-name><fpage>669</fpage><lpage>681</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.2018.2815524</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>James</surname> <given-names>W</given-names></name><name><surname>Stein</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="1992">1992</year><chapter-title>Estimation with quadratic loss</chapter-title><person-group person-group-type="editor"><name><surname>Kotz</surname> <given-names>S</given-names></name><name><surname>Johnson</surname> <given-names>N. L</given-names></name></person-group><source>Breakthroughs in Statistics</source><publisher-name>Springer</publisher-name><fpage>443</fpage><lpage>447</lpage><pub-id pub-id-type="doi">10.1007/978-1-4612-0919-5_30</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jas</surname> <given-names>M</given-names></name><name><surname>Engemann</surname> <given-names>DA</given-names></name><name><surname>Bekhti</surname> <given-names>Y</given-names></name><name><surname>Raimondo</surname> <given-names>F</given-names></name><name><surname>Gramfort</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Autoreject: automated artifact rejection for MEG and EEG data</article-title><source>NeuroImage</source><volume>159</volume><fpage>417</fpage><lpage>429</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.06.030</pub-id><pub-id pub-id-type="pmid">28645840</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jonas</surname> <given-names>E</given-names></name><name><surname>Kording</surname> <given-names>KP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Could a neuroscientist understand a microprocessor?</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005268</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005268</pub-id><pub-id pub-id-type="pmid">28081141</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Josse</surname> <given-names>J</given-names></name><name><surname>Prost</surname> <given-names>N</given-names></name><name><surname>Scornet</surname> <given-names>E</given-names></name><name><surname>Varoquaux</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>On the consistency of supervised learning with missing values</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1902.06931">https://arxiv.org/abs/1902.06931</ext-link></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalpouzos</surname> <given-names>G</given-names></name><name><surname>Persson</surname> <given-names>J</given-names></name><name><surname>Nyberg</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Local brain atrophy accounts for functional activity differences in normal aging</article-title><source>Neurobiology of Aging</source><volume>33</volume><fpage>623.e1</fpage><lpage>62623</lpage><pub-id pub-id-type="doi">10.1016/j.neurobiolaging.2011.02.021</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karrer</surname> <given-names>TM</given-names></name><name><surname>Bassett</surname> <given-names>DS</given-names></name><name><surname>Derntl</surname> <given-names>B</given-names></name><name><surname>Gruber</surname> <given-names>O</given-names></name><name><surname>Aleman</surname> <given-names>A</given-names></name><name><surname>Jardri</surname> <given-names>R</given-names></name><name><surname>Laird</surname> <given-names>AR</given-names></name><name><surname>Fox</surname> <given-names>PT</given-names></name><name><surname>Eickhoff</surname> <given-names>SB</given-names></name><name><surname>Grisel</surname> <given-names>O</given-names></name><name><surname>Varoquaux</surname> <given-names>G</given-names></name><name><surname>Thirion</surname> <given-names>B</given-names></name><name><surname>Bzdok</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Brain-based ranking of cognitive domains to predict schizophrenia</article-title><source>Human Brain Mapping</source><volume>40</volume><fpage>4487</fpage><lpage>4507</lpage><pub-id pub-id-type="doi">10.1002/hbm.24716</pub-id><pub-id pub-id-type="pmid">31313451</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaufmann</surname> <given-names>T</given-names></name><name><surname>van der Meer</surname> <given-names>D</given-names></name><name><surname>Doan</surname> <given-names>NT</given-names></name><name><surname>Schwarz</surname> <given-names>E</given-names></name><name><surname>Lund</surname> <given-names>MJ</given-names></name><name><surname>Agartz</surname> <given-names>I</given-names></name><name><surname>Alnæs</surname> <given-names>D</given-names></name><name><surname>Barch</surname> <given-names>DM</given-names></name><name><surname>Baur-Streubel</surname> <given-names>R</given-names></name><name><surname>Bertolino</surname> <given-names>A</given-names></name><name><surname>Bettella</surname> <given-names>F</given-names></name><name><surname>Beyer</surname> <given-names>MK</given-names></name><name><surname>Bøen</surname> <given-names>E</given-names></name><name><surname>Borgwardt</surname> <given-names>S</given-names></name><name><surname>Brandt</surname> <given-names>CL</given-names></name><name><surname>Buitelaar</surname> <given-names>J</given-names></name><name><surname>Celius</surname> <given-names>EG</given-names></name><name><surname>Cervenka</surname> <given-names>S</given-names></name><name><surname>Conzelmann</surname> <given-names>A</given-names></name><name><surname>Córdova-Palomera</surname> <given-names>A</given-names></name><name><surname>Dale</surname> <given-names>AM</given-names></name><name><surname>de Quervain</surname> <given-names>DJF</given-names></name><name><surname>Di Carlo</surname> <given-names>P</given-names></name><name><surname>Djurovic</surname> <given-names>S</given-names></name><name><surname>Dørum</surname> <given-names>ES</given-names></name><name><surname>Eisenacher</surname> <given-names>S</given-names></name><name><surname>Elvsåshagen</surname> <given-names>T</given-names></name><name><surname>Espeseth</surname> <given-names>T</given-names></name><name><surname>Fatouros-Bergman</surname> <given-names>H</given-names></name><name><surname>Flyckt</surname> <given-names>L</given-names></name><name><surname>Franke</surname> <given-names>B</given-names></name><name><surname>Frei</surname> <given-names>O</given-names></name><name><surname>Haatveit</surname> <given-names>B</given-names></name><name><surname>Håberg</surname> <given-names>AK</given-names></name><name><surname>Harbo</surname> <given-names>HF</given-names></name><name><surname>Hartman</surname> <given-names>CA</given-names></name><name><surname>Heslenfeld</surname> <given-names>D</given-names></name><name><surname>Hoekstra</surname> <given-names>PJ</given-names></name><name><surname>Høgestøl</surname> <given-names>EA</given-names></name><name><surname>Jernigan</surname> <given-names>TL</given-names></name><name><surname>Jonassen</surname> <given-names>R</given-names></name><name><surname>Jönsson</surname> <given-names>EG</given-names></name><name><surname>Kirsch</surname> <given-names>P</given-names></name><name><surname>Kłoszewska</surname> <given-names>I</given-names></name><name><surname>Kolskår</surname> <given-names>KK</given-names></name><name><surname>Landrø</surname> <given-names>NI</given-names></name><name><surname>Le Hellard</surname> <given-names>S</given-names></name><name><surname>Lesch</surname> <given-names>KP</given-names></name><name><surname>Lovestone</surname> <given-names>S</given-names></name><name><surname>Lundervold</surname> <given-names>A</given-names></name><name><surname>Lundervold</surname> <given-names>AJ</given-names></name><name><surname>Maglanoc</surname> <given-names>LA</given-names></name><name><surname>Malt</surname> <given-names>UF</given-names></name><name><surname>Mecocci</surname> <given-names>P</given-names></name><name><surname>Melle</surname> <given-names>I</given-names></name><name><surname>Meyer-Lindenberg</surname> <given-names>A</given-names></name><name><surname>Moberget</surname> <given-names>T</given-names></name><name><surname>Norbom</surname> <given-names>LB</given-names></name><name><surname>Nordvik</surname> <given-names>JE</given-names></name><name><surname>Nyberg</surname> <given-names>L</given-names></name><name><surname>Oosterlaan</surname> <given-names>J</given-names></name><name><surname>Papalino</surname> <given-names>M</given-names></name><name><surname>Papassotiropoulos</surname> <given-names>A</given-names></name><name><surname>Pauli</surname> <given-names>P</given-names></name><name><surname>Pergola</surname> <given-names>G</given-names></name><name><surname>Persson</surname> <given-names>K</given-names></name><name><surname>Richard</surname> <given-names>G</given-names></name><name><surname>Rokicki</surname> <given-names>J</given-names></name><name><surname>Sanders</surname> <given-names>AM</given-names></name><name><surname>Selbæk</surname> <given-names>G</given-names></name><name><surname>Shadrin</surname> <given-names>AA</given-names></name><name><surname>Smeland</surname> <given-names>OB</given-names></name><name><surname>Soininen</surname> <given-names>H</given-names></name><name><surname>Sowa</surname> <given-names>P</given-names></name><name><surname>Steen</surname> <given-names>VM</given-names></name><name><surname>Tsolaki</surname> <given-names>M</given-names></name><name><surname>Ulrichsen</surname> <given-names>KM</given-names></name><name><surname>Vellas</surname> <given-names>B</given-names></name><name><surname>Wang</surname> <given-names>L</given-names></name><name><surname>Westman</surname> <given-names>E</given-names></name><name><surname>Ziegler</surname> <given-names>GC</given-names></name><name><surname>Zink</surname> <given-names>M</given-names></name><name><surname>Andreassen</surname> <given-names>OA</given-names></name><name><surname>Westlye</surname> <given-names>LT</given-names></name><collab>Karolinska Schizophrenia Project (KaSP)</collab></person-group><year iso-8601-date="2019">2019</year><article-title>Common brain disorders are associated with heritable patterns of apparent aging of the brain</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1617</fpage><lpage>1623</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0471-7</pub-id><pub-id pub-id-type="pmid">31551603</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keitel</surname> <given-names>A</given-names></name><name><surname>Gross</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Individual human brain Areas can be identified from their characteristic spectral activation fingerprints</article-title><source>PLOS Biology</source><volume>14</volume><elocation-id>e1002498</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002498</pub-id><pub-id pub-id-type="pmid">27355236</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khan</surname> <given-names>S</given-names></name><name><surname>Hashmi</surname> <given-names>JA</given-names></name><name><surname>Mamashli</surname> <given-names>F</given-names></name><name><surname>Michmizos</surname> <given-names>K</given-names></name><name><surname>Kitzbichler</surname> <given-names>MG</given-names></name><name><surname>Bharadwaj</surname> <given-names>H</given-names></name><name><surname>Bekhti</surname> <given-names>Y</given-names></name><name><surname>Ganesan</surname> <given-names>S</given-names></name><name><surname>Garel</surname> <given-names>KA</given-names></name><name><surname>Whitfield-Gabrieli</surname> <given-names>S</given-names></name><name><surname>Gollub</surname> <given-names>RL</given-names></name><name><surname>Kong</surname> <given-names>J</given-names></name><name><surname>Vaina</surname> <given-names>LM</given-names></name><name><surname>Rana</surname> <given-names>KD</given-names></name><name><surname>Stufflebeam</surname> <given-names>SM</given-names></name><name><surname>Hämäläinen</surname> <given-names>MS</given-names></name><name><surname>Kenet</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Maturation trajectories of cortical resting-state networks depend on the mediating frequency band</article-title><source>NeuroImage</source><volume>174</volume><fpage>57</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.02.018</pub-id><pub-id pub-id-type="pmid">29462724</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname> <given-names>JR</given-names></name><name><surname>Dehaene</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Characterizing the dynamics of mental representations: the temporal generalization method</article-title><source>Trends in Cognitive Sciences</source><volume>18</volume><fpage>203</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2014.01.002</pub-id><pub-id pub-id-type="pmid">24593982</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumral</surname> <given-names>D</given-names></name><name><surname>Şansal</surname> <given-names>F</given-names></name><name><surname>Cesnaite</surname> <given-names>E</given-names></name><name><surname>Mahjoory</surname> <given-names>K</given-names></name><name><surname>Al</surname> <given-names>E</given-names></name><name><surname>Gaebler</surname> <given-names>M</given-names></name><name><surname>Nikulin</surname> <given-names>VV</given-names></name><name><surname>Villringer</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>BOLD and EEG signal variability at rest differently relate to aging in the human brain</article-title><source>NeuroImage</source><volume>207</volume><elocation-id>116373</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116373</pub-id><pub-id pub-id-type="pmid">31759114</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larson-Prior</surname> <given-names>LJ</given-names></name><name><surname>Oostenveld</surname> <given-names>R</given-names></name><name><surname>Della Penna</surname> <given-names>S</given-names></name><name><surname>Michalareas</surname> <given-names>G</given-names></name><name><surname>Prior</surname> <given-names>F</given-names></name><name><surname>Babajani-Feremi</surname> <given-names>A</given-names></name><name><surname>Schoffelen</surname> <given-names>JM</given-names></name><name><surname>Marzetti</surname> <given-names>L</given-names></name><name><surname>de Pasquale</surname> <given-names>F</given-names></name><name><surname>Di Pompeo</surname> <given-names>F</given-names></name><name><surname>Stout</surname> <given-names>J</given-names></name><name><surname>Woolrich</surname> <given-names>M</given-names></name><name><surname>Luo</surname> <given-names>Q</given-names></name><name><surname>Bucholz</surname> <given-names>R</given-names></name><name><surname>Fries</surname> <given-names>P</given-names></name><name><surname>Pizzella</surname> <given-names>V</given-names></name><name><surname>Romani</surname> <given-names>GL</given-names></name><name><surname>Corbetta</surname> <given-names>M</given-names></name><name><surname>Snyder</surname> <given-names>AZ</given-names></name><collab>WU-Minn HCP Consortium</collab></person-group><year iso-8601-date="2013">2013</year><article-title>Adding dynamics to the human connectome project with MEG</article-title><source>NeuroImage</source><volume>80</volume><fpage>190</fpage><lpage>201</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.056</pub-id><pub-id pub-id-type="pmid">23702419</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Le</surname> <given-names>TT</given-names></name><name><surname>Kuplicki</surname> <given-names>RT</given-names></name><name><surname>McKinney</surname> <given-names>BA</given-names></name><name><surname>Yeh</surname> <given-names>HW</given-names></name><name><surname>Thompson</surname> <given-names>WK</given-names></name><name><surname>Paulus</surname> <given-names>MP</given-names></name><collab>Tulsa 1000 Investigators</collab></person-group><year iso-8601-date="2018">2018</year><article-title>A nonlinear simulation framework supports adjusting for age when analyzing BrainAGE</article-title><source>Frontiers in Aging Neuroscience</source><volume>10</volume><elocation-id>317</elocation-id><pub-id pub-id-type="doi">10.3389/fnagi.2018.00317</pub-id><pub-id pub-id-type="pmid">30405393</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>PH</given-names></name><name><surname>Yu</surname> <given-names>PL</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>An R package for analyzing and modeling ranking data</article-title><source>BMC Medical Research Methodology</source><volume>13</volume><elocation-id>65</elocation-id><pub-id pub-id-type="doi">10.1186/1471-2288-13-65</pub-id><pub-id pub-id-type="pmid">23672645</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lehtelä</surname> <given-names>L</given-names></name><name><surname>Salmelin</surname> <given-names>R</given-names></name><name><surname>Hari</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Evidence for reactive magnetic 10-Hz rhythm in the human auditory cortex</article-title><source>Neuroscience Letters</source><volume>222</volume><fpage>111</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1016/S0304-3940(97)13361-4</pub-id><pub-id pub-id-type="pmid">9111741</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lemaitre</surname> <given-names>H</given-names></name><name><surname>Goldman</surname> <given-names>AL</given-names></name><name><surname>Sambataro</surname> <given-names>F</given-names></name><name><surname>Verchinski</surname> <given-names>BA</given-names></name><name><surname>Meyer-Lindenberg</surname> <given-names>A</given-names></name><name><surname>Weinberger</surname> <given-names>DR</given-names></name><name><surname>Mattay</surname> <given-names>VS</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Normal age-related brain morphometric changes: nonuniformity across cortical thickness, surface area and gray matter volume?</article-title><source>Neurobiology of Aging</source><volume>33</volume><elocation-id>617.e1</elocation-id><pub-id pub-id-type="doi">10.1016/j.neurobiolaging.2010.07.013</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liem</surname> <given-names>F</given-names></name><name><surname>Varoquaux</surname> <given-names>G</given-names></name><name><surname>Kynast</surname> <given-names>J</given-names></name><name><surname>Beyer</surname> <given-names>F</given-names></name><name><surname>Kharabian Masouleh</surname> <given-names>S</given-names></name><name><surname>Huntenburg</surname> <given-names>JM</given-names></name><name><surname>Lampe</surname> <given-names>L</given-names></name><name><surname>Rahim</surname> <given-names>M</given-names></name><name><surname>Abraham</surname> <given-names>A</given-names></name><name><surname>Craddock</surname> <given-names>RC</given-names></name><name><surname>Riedel-Heller</surname> <given-names>S</given-names></name><name><surname>Luck</surname> <given-names>T</given-names></name><name><surname>Loeffler</surname> <given-names>M</given-names></name><name><surname>Schroeter</surname> <given-names>ML</given-names></name><name><surname>Witte</surname> <given-names>AV</given-names></name><name><surname>Villringer</surname> <given-names>A</given-names></name><name><surname>Margulies</surname> <given-names>DS</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Predicting brain-age from multimodal imaging data captures cognitive impairment</article-title><source>NeuroImage</source><volume>148</volume><fpage>179</fpage><lpage>188</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.11.005</pub-id><pub-id pub-id-type="pmid">27890805</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname> <given-names>FH</given-names></name><name><surname>Witzel</surname> <given-names>T</given-names></name><name><surname>Ahlfors</surname> <given-names>SP</given-names></name><name><surname>Stufflebeam</surname> <given-names>SM</given-names></name><name><surname>Belliveau</surname> <given-names>JW</given-names></name><name><surname>Hämäläinen</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Assessing and improving the spatial accuracy in MEG source localization by depth-weighted minimum-norm estimates</article-title><source>NeuroImage</source><volume>31</volume><fpage>160</fpage><lpage>171</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2005.11.054</pub-id><pub-id pub-id-type="pmid">16520063</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lindquist</surname> <given-names>MA</given-names></name><name><surname>Geuter</surname> <given-names>S</given-names></name><name><surname>Wager</surname> <given-names>TD</given-names></name><name><surname>Caffo</surname> <given-names>BS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Modular preprocessing pipelines can reintroduce artifacts into fMRI data</article-title><source>Human Brain Mapping</source><volume>40</volume><fpage>2358</fpage><lpage>2376</lpage><pub-id pub-id-type="doi">10.1002/hbm.24528</pub-id><pub-id pub-id-type="pmid">30666750</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Louppe</surname> <given-names>G</given-names></name><name><surname>Wehenkel</surname> <given-names>L</given-names></name><name><surname>Sutera</surname> <given-names>A</given-names></name><name><surname>Geurts</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Understanding variable importances in forests of randomized trees</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>431</fpage><lpage>439</lpage></element-citation></ref><ref id="bib79"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Mensch</surname> <given-names>A</given-names></name><name><surname>Mairal</surname> <given-names>J</given-names></name><name><surname>Thirion</surname> <given-names>B</given-names></name><name><surname>Varoquaux</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Dictionary learning for massive matrix factorization</article-title><conf-name>Proceedings of the 33rd International Conference on Machine Learning, Volume 48 of Proceedings of Machine Learning Research. :</conf-name><fpage>1737</fpage><lpage>1746</lpage></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miyake</surname> <given-names>A</given-names></name><name><surname>Friedman</surname> <given-names>NP</given-names></name><name><surname>Emerson</surname> <given-names>MJ</given-names></name><name><surname>Witzki</surname> <given-names>AH</given-names></name><name><surname>Howerter</surname> <given-names>A</given-names></name><name><surname>Wager</surname> <given-names>TD</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>The unity and diversity of executive functions and their contributions to complex &quot;Frontal Lobe&quot; tasks: a latent variable analysis</article-title><source>Cognitive Psychology</source><volume>41</volume><fpage>49</fpage><lpage>100</lpage><pub-id pub-id-type="doi">10.1006/cogp.1999.0734</pub-id><pub-id pub-id-type="pmid">10945922</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname> <given-names>DG</given-names></name><name><surname>DeCarli</surname> <given-names>C</given-names></name><name><surname>Schapiro</surname> <given-names>MB</given-names></name><name><surname>Rapoport</surname> <given-names>SI</given-names></name><name><surname>Horwitz</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Age-related differences in volumes of subcortical nuclei, brain matter, and cerebrospinal fluid in healthy men as measured with magnetic resonance imaging</article-title><source>Archives of Neurology</source><volume>49</volume><fpage>839</fpage><lpage>845</lpage><pub-id pub-id-type="doi">10.1001/archneur.1992.00530320063013</pub-id><pub-id pub-id-type="pmid">1343082</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nentwich</surname> <given-names>M</given-names></name><name><surname>Ai</surname> <given-names>L</given-names></name><name><surname>Madsen</surname> <given-names>J</given-names></name><name><surname>Telesford</surname> <given-names>QK</given-names></name><name><surname>Haufe</surname> <given-names>S</given-names></name><name><surname>Milham</surname> <given-names>MP</given-names></name><name><surname>Parra</surname> <given-names>LC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Functional connectivity of EEG is subject-specific, associated with phenotype, and different from fMRI</article-title><source>NeuroImage</source><volume>218</volume><fpage>117001</fpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117001</pub-id><pub-id pub-id-type="pmid">32492509</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ouyang</surname> <given-names>G</given-names></name><name><surname>Hildebrandt</surname> <given-names>A</given-names></name><name><surname>Schmitz</surname> <given-names>F</given-names></name><name><surname>Herrmann</surname> <given-names>CS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Decomposing alpha and 1/f brain activities reveals their differential associations with cognitive processing speed</article-title><source>NeuroImage</source><volume>205</volume><elocation-id>116304</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116304</pub-id><pub-id pub-id-type="pmid">31654760</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Pan</surname> <given-names>SJ</given-names></name><name><surname>Yang</surname> <given-names>Q</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A survey on transfer learning</article-title><conf-name>IEEE Transactions on Knowledge and Data Engineering</conf-name><fpage>1345</fpage><lpage>1359</lpage><pub-id pub-id-type="doi">10.1109/TKDE.2009.191</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname> <given-names>F</given-names></name><name><surname>Varoquaux</surname> <given-names>G</given-names></name><name><surname>Gramfort</surname> <given-names>A</given-names></name><name><surname>Michel</surname> <given-names>V</given-names></name><name><surname>Thirion</surname> <given-names>B</given-names></name><name><surname>Grisel</surname> <given-names>O</given-names></name><name><surname>Blondel</surname> <given-names>M</given-names></name><name><surname>Prettenhofer</surname> <given-names>P</given-names></name><name><surname>Weiss</surname> <given-names>R</given-names></name><name><surname>Dubourg</surname> <given-names>V</given-names></name><name><surname>Vanderplas</surname> <given-names>J</given-names></name><name><surname>Passos</surname> <given-names>A</given-names></name><name><surname>Cournapeau</surname> <given-names>D</given-names></name><name><surname>Brucher</surname> <given-names>M</given-names></name><name><surname>Perrot</surname> <given-names>M</given-names></name><name><surname>Duchesnay</surname> <given-names>É</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Scikit-learn: machine learning in Python</article-title><source>JMLR</source><volume>12</volume><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Price</surname> <given-names>D</given-names></name><name><surname>Tyler</surname> <given-names>LK</given-names></name><name><surname>Neto Henriques</surname> <given-names>R</given-names></name><name><surname>Campbell</surname> <given-names>KL</given-names></name><name><surname>Williams</surname> <given-names>N</given-names></name><name><surname>Treder</surname> <given-names>MS</given-names></name><name><surname>Taylor</surname> <given-names>JR</given-names></name><name><surname>Henson</surname> <given-names>RNA</given-names></name><collab>Cam-CAN</collab></person-group><year iso-8601-date="2017">2017</year><article-title>Age-related delay in visual and auditory evoked responses is mediated by white- and grey-matter differences</article-title><source>Nature Communications</source><volume>8</volume><elocation-id>15671</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms15671</pub-id><pub-id pub-id-type="pmid">28598417</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="software"><person-group person-group-type="author"><collab>R Development Core Team</collab></person-group><year iso-8601-date="2019">2019</year><data-title>R: A Language and Environment for Statistical Computing</data-title><publisher-loc>Vienna, Austria</publisher-loc><publisher-name>R Foundation for Statistical Computing</publisher-name><ext-link ext-link-type="uri" xlink:href="http://www.r-project.org">http://www.r-project.org</ext-link></element-citation></ref><ref id="bib88"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rahim</surname> <given-names>M</given-names></name><name><surname>Thirion</surname> <given-names>B</given-names></name><name><surname>Abraham</surname> <given-names>A</given-names></name><name><surname>Eickenberg</surname> <given-names>M</given-names></name><name><surname>Dohmatob</surname> <given-names>E</given-names></name><name><surname>Comtat</surname> <given-names>C</given-names></name><name><surname>Varoquaux</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2015">2015</year><chapter-title>Integrating multimodal priors in predictive models for the functional characterization of Alzheimer’s disease</chapter-title><person-group person-group-type="editor"><name><surname>Navab</surname> <given-names>N</given-names></name><name><surname>Hornegger</surname> <given-names>J</given-names></name><name><surname>Wells</surname> <given-names>W. M</given-names></name><name><surname>Frangi</surname> <given-names>A</given-names></name></person-group><source>Medical Image Computing and Computer-Assisted Intervention – MICCAI 2015</source><publisher-loc>Cham</publisher-loc><publisher-name>Springer International Publishing</publisher-name><fpage>207</fpage><lpage>214</lpage><pub-id pub-id-type="doi">10.1007/978-3-319-24571-3</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ran</surname> <given-names>AR</given-names></name><name><surname>Cheung</surname> <given-names>CY</given-names></name><name><surname>Wang</surname> <given-names>X</given-names></name><name><surname>Chen</surname> <given-names>H</given-names></name><name><surname>Luo</surname> <given-names>LY</given-names></name><name><surname>Chan</surname> <given-names>PP</given-names></name><name><surname>Wong</surname> <given-names>MOM</given-names></name><name><surname>Chang</surname> <given-names>RT</given-names></name><name><surname>Mannil</surname> <given-names>SS</given-names></name><name><surname>Young</surname> <given-names>AL</given-names></name><name><surname>Yung</surname> <given-names>HW</given-names></name><name><surname>Pang</surname> <given-names>CP</given-names></name><name><surname>Heng</surname> <given-names>P-A</given-names></name><name><surname>Tham</surname> <given-names>CC</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Detection of glaucomatous optic neuropathy with spectral-domain optical coherence tomography: a retrospective training and validation deep-learning analysis</article-title><source>The Lancet Digital Health</source><volume>1</volume><fpage>e172</fpage><lpage>e182</lpage><pub-id pub-id-type="doi">10.1016/S2589-7500(19)30085-8</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reuter</surname> <given-names>M</given-names></name><name><surname>Rosas</surname> <given-names>HD</given-names></name><name><surname>Fischl</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Highly accurate inverse consistent registration a robust approach</article-title><source>NeuroImage</source><volume>53</volume><fpage>1181</fpage><lpage>1196</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.07.020</pub-id><pub-id pub-id-type="pmid">20637289</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richard Clark</surname> <given-names>C</given-names></name><name><surname>Veltmeyer</surname> <given-names>MD</given-names></name><name><surname>Hamilton</surname> <given-names>RJ</given-names></name><name><surname>Simms</surname> <given-names>E</given-names></name><name><surname>Paul</surname> <given-names>R</given-names></name><name><surname>Hermens</surname> <given-names>D</given-names></name><name><surname>Gordon</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Spontaneous alpha peak frequency predicts working memory performance across the age span</article-title><source>International Journal of Psychophysiology</source><volume>53</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1016/j.ijpsycho.2003.12.011</pub-id><pub-id pub-id-type="pmid">15172130</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rocca</surname> <given-names>MA</given-names></name><name><surname>Pravatà</surname> <given-names>E</given-names></name><name><surname>Valsasina</surname> <given-names>P</given-names></name><name><surname>Radaelli</surname> <given-names>M</given-names></name><name><surname>Colombo</surname> <given-names>B</given-names></name><name><surname>Vacchi</surname> <given-names>L</given-names></name><name><surname>Gobbi</surname> <given-names>C</given-names></name><name><surname>Comi</surname> <given-names>G</given-names></name><name><surname>Falini</surname> <given-names>A</given-names></name><name><surname>Filippi</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Hippocampal-DMN disconnectivity in MS is related to WM lesions and depression</article-title><source>Human Brain Mapping</source><volume>36</volume><fpage>5051</fpage><lpage>5063</lpage><pub-id pub-id-type="doi">10.1002/hbm.22992</pub-id><pub-id pub-id-type="pmid">26366641</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ronan</surname> <given-names>L</given-names></name><name><surname>Alexander-Bloch</surname> <given-names>AF</given-names></name><name><surname>Wagstyl</surname> <given-names>K</given-names></name><name><surname>Farooqi</surname> <given-names>S</given-names></name><name><surname>Brayne</surname> <given-names>C</given-names></name><name><surname>Tyler</surname> <given-names>LK</given-names></name><name><surname>Fletcher</surname> <given-names>PC</given-names></name><collab>Cam-CAN</collab></person-group><year iso-8601-date="2016">2016</year><article-title>Obesity associated with increased brain age from midlife</article-title><source>Neurobiology of Aging</source><volume>47</volume><fpage>63</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1016/j.neurobiolaging.2016.07.010</pub-id><pub-id pub-id-type="pmid">27562529</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Sabbagh</surname> <given-names>D</given-names></name><name><surname>Ablin</surname> <given-names>P</given-names></name><name><surname>Varoquaux</surname> <given-names>G</given-names></name><name><surname>Gramfort</surname> <given-names>A</given-names></name><name><surname>Engeman</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Manifold-regression to predict from MEG/EEG brain signals without source modeling</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sabbagh</surname> <given-names>D</given-names></name><name><surname>Ablin</surname> <given-names>P</given-names></name><name><surname>Varoquaux</surname> <given-names>G</given-names></name><name><surname>Gramfort</surname> <given-names>A</given-names></name><name><surname>Engemann</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Predictive regression modeling with MEG/EEG: from source power to signals and cognitive states</article-title><source>NeuroImage</source><elocation-id>116893</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116893</pub-id><pub-id pub-id-type="pmid">32439535</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ségonne</surname> <given-names>F</given-names></name><name><surname>Dale</surname> <given-names>AM</given-names></name><name><surname>Busa</surname> <given-names>E</given-names></name><name><surname>Glessner</surname> <given-names>M</given-names></name><name><surname>Salat</surname> <given-names>D</given-names></name><name><surname>Hahn</surname> <given-names>HK</given-names></name><name><surname>Fischl</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>A hybrid approach to the skull stripping problem in MRI</article-title><source>NeuroImage</source><volume>22</volume><fpage>1060</fpage><lpage>1075</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.03.032</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shafto</surname> <given-names>MA</given-names></name><name><surname>Tyler</surname> <given-names>LK</given-names></name><name><surname>Dixon</surname> <given-names>M</given-names></name><name><surname>Taylor</surname> <given-names>JR</given-names></name><name><surname>Rowe</surname> <given-names>JB</given-names></name><name><surname>Cusack</surname> <given-names>R</given-names></name><name><surname>Calder</surname> <given-names>AJ</given-names></name><name><surname>Marslen-Wilson</surname> <given-names>WD</given-names></name><name><surname>Duncan</surname> <given-names>J</given-names></name><name><surname>Dalgleish</surname> <given-names>T</given-names></name><name><surname>Henson</surname> <given-names>RN</given-names></name><name><surname>Brayne</surname> <given-names>C</given-names></name><name><surname>Matthews</surname> <given-names>FE</given-names></name><collab>Cam-CAN</collab></person-group><year iso-8601-date="2014">2014</year><article-title>The Cambridge centre for ageing and neuroscience (Cam-CAN) study protocol: a cross-sectional, lifespan, multidisciplinary examination of healthy cognitive ageing</article-title><source>BMC Neurology</source><volume>14</volume><fpage>1</fpage><lpage>25</lpage><pub-id pub-id-type="doi">10.1186/s12883-014-0204-1</pub-id><pub-id pub-id-type="pmid">25412575</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheline</surname> <given-names>YI</given-names></name><name><surname>Barch</surname> <given-names>DM</given-names></name><name><surname>Price</surname> <given-names>JL</given-names></name><name><surname>Rundle</surname> <given-names>MM</given-names></name><name><surname>Vaishnavi</surname> <given-names>SN</given-names></name><name><surname>Snyder</surname> <given-names>AZ</given-names></name><name><surname>Mintun</surname> <given-names>MA</given-names></name><name><surname>Wang</surname> <given-names>S</given-names></name><name><surname>Coalson</surname> <given-names>RS</given-names></name><name><surname>Raichle</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The default mode network and self-referential processes in depression</article-title><source>PNAS</source><volume>106</volume><fpage>1942</fpage><lpage>1947</lpage><pub-id pub-id-type="doi">10.1073/pnas.0812686106</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silver</surname> <given-names>NC</given-names></name><name><surname>Dunlap</surname> <given-names>WP</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Averaging correlation coefficients: should Fisher's z transformation be used?</article-title><source>Journal of Applied Psychology</source><volume>72</volume><fpage>146</fpage><lpage>148</lpage><pub-id pub-id-type="doi">10.1037/0021-9010.72.1.146</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simmons</surname> <given-names>JP</given-names></name><name><surname>Nelson</surname> <given-names>LD</given-names></name><name><surname>Simonsohn</surname> <given-names>U</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>False-positive psychology: undisclosed flexibility in data collection and analysis allows presenting anything as significant</article-title><source>Psychological Science</source><volume>22</volume><fpage>1359</fpage><lpage>1366</lpage><pub-id pub-id-type="doi">10.1177/0956797611417632</pub-id><pub-id pub-id-type="pmid">22006061</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skov</surname> <given-names>ER</given-names></name><name><surname>Simons</surname> <given-names>DG</given-names></name></person-group><year iso-8601-date="1965">1965</year><article-title>EEG electrodes for in-flight monitoring</article-title><source>Psychophysiology</source><volume>2</volume><fpage>161</fpage><lpage>167</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.1965.tb03260.x</pub-id><pub-id pub-id-type="pmid">5846480</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sled</surname> <given-names>JG</given-names></name><name><surname>Zijdenbos</surname> <given-names>AP</given-names></name><name><surname>Evans</surname> <given-names>AC</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>A nonparametric method for automatic correction of intensity nonuniformity in MRI data</article-title><source>IEEE Transactions on Medical Imaging</source><volume>17</volume><fpage>87</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1109/42.668698</pub-id><pub-id pub-id-type="pmid">9617910</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Slowikowski</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019</year><data-title>ggrepel: Automatically Position Non-Overlapping Text Labels with ’ggplot2’</data-title><source>R Package</source><version designator=" 0.8.1"> 0.8.1</version></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname> <given-names>SM</given-names></name><name><surname>Vidaurre</surname> <given-names>D</given-names></name><name><surname>Alfaro-Almagro</surname> <given-names>F</given-names></name><name><surname>Nichols</surname> <given-names>TE</given-names></name><name><surname>Miller</surname> <given-names>KL</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Estimation of brain age Delta from brain imaging</article-title><source>NeuroImage</source><volume>200</volume><fpage>528</fpage><lpage>539</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.06.017</pub-id><pub-id pub-id-type="pmid">31201988</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stockmeier</surname> <given-names>CA</given-names></name><name><surname>Mahajan</surname> <given-names>GJ</given-names></name><name><surname>Konick</surname> <given-names>LC</given-names></name><name><surname>Overholser</surname> <given-names>JC</given-names></name><name><surname>Jurjus</surname> <given-names>GJ</given-names></name><name><surname>Meltzer</surname> <given-names>HY</given-names></name><name><surname>Uylings</surname> <given-names>HB</given-names></name><name><surname>Friedman</surname> <given-names>L</given-names></name><name><surname>Rajkowska</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Cellular changes in the postmortem Hippocampus in major depression</article-title><source>Biological Psychiatry</source><volume>56</volume><fpage>640</fpage><lpage>650</lpage><pub-id pub-id-type="doi">10.1016/j.biopsych.2004.08.022</pub-id><pub-id pub-id-type="pmid">15522247</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stokes</surname> <given-names>MG</given-names></name><name><surname>Wolff</surname> <given-names>MJ</given-names></name><name><surname>Spaak</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Decoding rich spatial information with high temporal resolution</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>636</fpage><lpage>638</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.08.016</pub-id><pub-id pub-id-type="pmid">26440122</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tallon-Baudry</surname> <given-names>C</given-names></name><name><surname>Bertrand</surname> <given-names>O</given-names></name><name><surname>Fischer</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Oscillatory synchrony between human extrastriate Areas during visual short-term memory maintenance</article-title><source>The Journal of Neuroscience</source><volume>21</volume><elocation-id>RC177</elocation-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.21-20-j0008.2001</pub-id><pub-id pub-id-type="pmid">11588207</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taulu</surname> <given-names>S</given-names></name><name><surname>Kajola</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Presentation of electromagnetic multichannel data: the signal space separation method</article-title><source>Journal of Applied Physics</source><volume>97</volume><elocation-id>124905</elocation-id><pub-id pub-id-type="doi">10.1063/1.1935742</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname> <given-names>JR</given-names></name><name><surname>Williams</surname> <given-names>N</given-names></name><name><surname>Cusack</surname> <given-names>R</given-names></name><name><surname>Auer</surname> <given-names>T</given-names></name><name><surname>Shafto</surname> <given-names>MA</given-names></name><name><surname>Dixon</surname> <given-names>M</given-names></name><name><surname>Tyler</surname> <given-names>LK</given-names></name><collab>Cam-CAN</collab><name><surname>Henson</surname> <given-names>RN</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The Cambridge Centre for Ageing and Neuroscience (Cam-CAN) data repository: Structural and functional MRI, MEG, and cognitive data from a cross-sectional adult lifespan sample</article-title><source>NeuroImage</source><volume>144</volume><fpage>262</fpage><lpage>269</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.09.018</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thambisetty</surname> <given-names>M</given-names></name><name><surname>Wan</surname> <given-names>J</given-names></name><name><surname>Carass</surname> <given-names>A</given-names></name><name><surname>An</surname> <given-names>Y</given-names></name><name><surname>Prince</surname> <given-names>JL</given-names></name><name><surname>Resnick</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Longitudinal changes in cortical thickness associated with normal aging</article-title><source>NeuroImage</source><volume>52</volume><fpage>1215</fpage><lpage>1223</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.04.258</pub-id><pub-id pub-id-type="pmid">20441796</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="software"><person-group person-group-type="author"><collab>The Wellcome Centre for Human Neuroimaging</collab></person-group><year iso-8601-date="2018">2018</year><data-title>SPM</data-title><source>Statistical Parametric Mapping</source></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsvetanov</surname> <given-names>KA</given-names></name><name><surname>Henson</surname> <given-names>RNA</given-names></name><name><surname>Tyler</surname> <given-names>LK</given-names></name><name><surname>Davis</surname> <given-names>SW</given-names></name><name><surname>Shafto</surname> <given-names>MA</given-names></name><name><surname>Taylor</surname> <given-names>JR</given-names></name><name><surname>Williams</surname> <given-names>N</given-names></name><collab>Cam-CAN</collab><name><surname>Rowe</surname> <given-names>JB</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The effect of ageing on fMRI: Correction for the confounding effects of vascular reactivity evaluated by joint fMRI and MEG in 335 adults</article-title><source>Human Brain Mapping</source><volume>36</volume><fpage>2248</fpage><lpage>2269</lpage><pub-id pub-id-type="doi">10.1002/hbm.22768</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsvetanov</surname> <given-names>KA</given-names></name><name><surname>Henson</surname> <given-names>RNA</given-names></name><name><surname>Tyler</surname> <given-names>LK</given-names></name><name><surname>Razi</surname> <given-names>A</given-names></name><name><surname>Geerligs</surname> <given-names>L</given-names></name><name><surname>Ham</surname> <given-names>TE</given-names></name><name><surname>Rowe</surname> <given-names>JB</given-names></name><collab>Cambridge Centre for Ageing and Neuroscience</collab></person-group><year iso-8601-date="2016">2016</year><article-title>Extrinsic and intrinsic brain network connectivity maintains cognition across the lifespan despite accelerated decay of regional brain activation</article-title><source>Journal of Neuroscience</source><volume>36</volume><fpage>3115</fpage><lpage>3126</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2733-15.2016</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Tsvetanov</surname> <given-names>KA</given-names></name><name><surname>Henson</surname> <given-names>RN</given-names></name><name><surname>Rowe</surname> <given-names>JB</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Separating vascular and neuronal effects of age on fmri bold signals</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1912.02899">https://arxiv.org/abs/1912.02899</ext-link></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uusitalo</surname> <given-names>MA</given-names></name><name><surname>Ilmoniemi</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Signal-space projection method for separating MEG or EEG into components</article-title><source>Medical &amp; Biological Engineering &amp; Computing</source><volume>35</volume><fpage>135</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1007/BF02534144</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Schependom</surname> <given-names>J</given-names></name><name><surname>Vidaurre</surname> <given-names>D</given-names></name><name><surname>Costers</surname> <given-names>L</given-names></name><name><surname>Sjøgård</surname> <given-names>M</given-names></name><name><surname>D'hooghe</surname> <given-names>MB</given-names></name><name><surname>D'haeseleer</surname> <given-names>M</given-names></name><name><surname>Wens</surname> <given-names>V</given-names></name><name><surname>De Tiège</surname> <given-names>X</given-names></name><name><surname>Goldman</surname> <given-names>S</given-names></name><name><surname>Woolrich</surname> <given-names>M</given-names></name><name><surname>Nagels</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Altered transient brain dynamics in multiple sclerosis: treatment or pathology?</article-title><source>Human Brain Mapping</source><volume>40</volume><fpage>4789</fpage><lpage>4800</lpage><pub-id pub-id-type="doi">10.1002/hbm.24737</pub-id><pub-id pub-id-type="pmid">31361073</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Varoquaux</surname> <given-names>G</given-names></name><name><surname>Baronnet</surname> <given-names>F</given-names></name><name><surname>Kleinschmidt</surname> <given-names>A</given-names></name><name><surname>Fillard</surname> <given-names>P</given-names></name><name><surname>Thirion</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2010">2010</year><chapter-title>Detection of Brain Functional-Connectivity Difference in Post-stroke Patients Using Group-Level Covariance Modeling</chapter-title><person-group person-group-type="editor"><name><surname>Jiang</surname> <given-names>T</given-names></name><name><surname>Navab</surname> <given-names>N</given-names></name><name><surname>Pluim</surname> <given-names>J. P. W</given-names></name><name><surname>Viergever</surname> <given-names>M. A</given-names></name></person-group><source>Medical Image Computing and Computer-Assisted Intervention – MICCAI 2010</source><publisher-loc>Berlin, Heidelberg</publisher-loc><publisher-name>Springer Berlin Heidelberg</publisher-name><fpage>200</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1007/978-3-642-15705-9</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Varoquaux</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Cross-validation failure: small sample sizes lead to large error bars</article-title><source>NeuroImage</source><volume>180</volume><fpage>68</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.06.061</pub-id><pub-id pub-id-type="pmid">28655633</pub-id></element-citation></ref><ref id="bib119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vidaurre</surname> <given-names>D</given-names></name><name><surname>Hunt</surname> <given-names>LT</given-names></name><name><surname>Quinn</surname> <given-names>AJ</given-names></name><name><surname>Hunt</surname> <given-names>BAE</given-names></name><name><surname>Brookes</surname> <given-names>MJ</given-names></name><name><surname>Nobre</surname> <given-names>AC</given-names></name><name><surname>Woolrich</surname> <given-names>MW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Spontaneous cortical activity transiently organises into frequency specific phase-coupling networks</article-title><source>Nature Communications</source><volume>9</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1038/s41467-018-05316-z</pub-id><pub-id pub-id-type="pmid">30061566</pub-id></element-citation></ref><ref id="bib120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voytek</surname> <given-names>B</given-names></name><name><surname>Kramer</surname> <given-names>MA</given-names></name><name><surname>Case</surname> <given-names>J</given-names></name><name><surname>Lepage</surname> <given-names>KQ</given-names></name><name><surname>Tempesta</surname> <given-names>ZR</given-names></name><name><surname>Knight</surname> <given-names>RT</given-names></name><name><surname>Gazzaley</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Age-Related changes in 1/f neural electrophysiological noise</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>13257</fpage><lpage>13265</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2332-14.2015</pub-id><pub-id pub-id-type="pmid">26400953</pub-id></element-citation></ref><ref id="bib121"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wickham</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><source>Ggplot2: Elegant Graphics for Data Analysis</source><publisher-loc>New York</publisher-loc><publisher-name>Springer-Verlag </publisher-name><pub-id pub-id-type="doi">10.1007/978-0-387-98141-3</pub-id></element-citation></ref><ref id="bib122"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolpert</surname> <given-names>DH</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Stacked generalization</article-title><source>Neural Networks</source><volume>5</volume><fpage>241</fpage><lpage>259</lpage><pub-id pub-id-type="doi">10.1016/S0893-6080(05)80023-1</pub-id></element-citation></ref><ref id="bib123"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woo</surname> <given-names>CW</given-names></name><name><surname>Chang</surname> <given-names>LJ</given-names></name><name><surname>Lindquist</surname> <given-names>MA</given-names></name><name><surname>Wager</surname> <given-names>TD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Building better biomarkers: brain models in translational neuroimaging</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>365</fpage><lpage>377</lpage><pub-id pub-id-type="doi">10.1038/nn.4478</pub-id><pub-id pub-id-type="pmid">28230847</pub-id></element-citation></ref><ref id="bib124"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoo</surname> <given-names>TK</given-names></name><name><surname>Ryu</surname> <given-names>IH</given-names></name><name><surname>Lee</surname> <given-names>G</given-names></name><name><surname>Kim</surname> <given-names>Y</given-names></name><name><surname>Kim</surname> <given-names>JK</given-names></name><name><surname>Lee</surname> <given-names>IS</given-names></name><name><surname>Kim</surname> <given-names>JS</given-names></name><name><surname>Rim</surname> <given-names>TH</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Adopting machine learning to automatically identify candidate patients for corneal refractive surgery</article-title><source>Npj Digital Medicine</source><volume>2</volume><elocation-id>59</elocation-id><pub-id pub-id-type="doi">10.1038/s41746-019-0135-8</pub-id><pub-id pub-id-type="pmid">31304405</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.54055.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Shackman</surname><given-names>Alexander</given-names></name><role>Reviewing Editor</role><aff><institution>University of Maryland</institution><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Tsvetanov</surname><given-names>Kamen</given-names> </name><role>Reviewer</role><aff><institution/></aff></contrib><contrib contrib-type="reviewer"><name><surname>Trujillo-Barreto</surname><given-names>Nelson</given-names> </name><role>Reviewer</role><aff><institution>The University of Manchester</institution><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>The authors describe a novel machine learning approach-opportunistic prediction stacking-with the aim of combining multiple neuroimaging modalities into a single predictive model (“biomarker”) in the face of missing data. Leveraging structural MRI, functional MRI, and MEG data from a large public biobank (Cam-Can), the authors show that each modality had additive incremental value in predicting age.</p><p>The reviewers and I were enthusiastic about the report. This approach has the potential to extract valuable information from multimodal databases and improve diagnostic power based on the surrogate biomarker idea. From a translational neuroscience perspective, the paper addresses (1) whether adding MEG improves age prediction and provides incremental predictive validity over sMRI or sMRI + fMRI alone; (2) which MEG features are most predictive of age. From a methodological perspective, the paper extends the original stacking method to address missing data, a common occurrence.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Combining electrophysiology with MRI enhances learning of surrogate-biomarkers&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by two peer reviewers, and the evaluation has been overseen by Alex Shackman as the Reviewing Editor and Floris de Lange as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Kamen Tsvetanov (Reviewer #1); Nelson Trujillo-Barreto (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>The authors describe a novel machine learning approach-opportunistic prediction stacking-with the aim of combining multiple neuroimaging modalities into a single predictive model (“biomarker”) in the face of missing data. Leveraging structural MRI, functional MRI, and MEG data from a large public biobank (Cam-Can), the authors show that each modality had additive incremental value in predicting age.</p><p>The reviewers and I were enthusiastic about the report:</p><p>• The paper is written and presented well.</p><p>• The research idea is interesting and timely and the proposed method has the potential to extract valuable information from multimodal databases and improve diagnostic power based on the surrogate biomarker idea.</p><p>• From a translational neuroscience perspective, the paper addresses (1) whether adding MEG improves age prediction and provides incremental predictive validity over sMRI or sMRI + fMRI alone; (2) which MEG features are most predictive of age.</p><p>• From a methodological perspective, the paper extends the original stacking method to address missing data, a common occurrence.</p><p>Challenges and Recommendations:</p><p>Nevertheless, our enthusiasm was somewhat tempered by several key limitations of the report. In this section, I briefly summarize the most important comments.</p><p>1) Challenge: – The motivation for including MEG seems to be exclusively based on EEG evidence. In the Introduction, all the evidence about the relationship between electrophysiology and ageing (and the complementarity to fMRI in that context) to motivate its inclusion as an additional modality is drawn from the EEG literature, which is odd, given that the paper uses MEG instead.</p><p>Recommendation: – The authors should motivate the use of MEG directly or at least link the evidence from EEG to the use of MEG in a more convincing way. This might be as simple as saying that, although a lot of evidence from EEG is available, there is no available EEG data in multimodal databases (which I think would be a fair statement in general), but given the relationship between the two techniques, it is expected that inclusion of MEG would be valuable as well, this link is not clear in the text.</p><p>2) Challenge: – The Materials and methods are not entirely clear. Some of the processing/feature extraction steps are not completely explained or appropriately justified. The taxonomy used for the extracted features in MEG is confusing.</p><p>Recommendation: – Clarify the Materials and methods.</p><p>3) Challenge: – Missing Statistics. – Statistical significance of some of the results are missing: Many of the results do not report any statistical significance threshold (or p-value), which makes claims about results being above chance, not rigorously justified. (e.g. &quot;…All stacking models performed consistently better than chance…&quot; What does it mean to perform better than chance here? Was a statistical significance test carried out? What was the null hypothesis tested? If so, report the p-value or equivalent used? In some cases, statistical significance is obvious, in others, it is difficult to assess via visual inspection.</p><p>Recommendation: – Report statistical significance of any comparisons made (either corrected or not) in the main report and in the supplement e.g. for MAE differences and MAE PE correlations.</p><p>4) Challenge: – Generality. – It is important to demonstrate the robustness and reliability of these features to generalize in unseen data.</p><p>Recommendation: – The authors could readily address this in the available data by splitting the sample in half (while maintaining the age distribution and data missingness) and test how similar are the loadings of each feature across data splits. The process could be repeated multiple times (1000s) to create a distribution, which can be compared to the distribution from a permuted data.</p><p>5) Challenge: – Non-random Missing Data. – It is important to show that the approach is not susceptible to confounds in the missing data (non-random missingness; e.g. more missing data coming from older individuals, which “helps” to learn an age-related effects).</p><p>Recommendation: – This could be easily addressed e.g. by comparing model performance between two scenarios of missingness in the fully available dataset. In one scenario the missing data come from subjects with uniform age distribution and in the other scenario a bias in age selection is introduced, i.e. larger portion of missing data comes from older individuals.</p><p>6) Challenge: – Need to better integrate or segregate the main report and the supplement. Extensive text is dedicated to supplementary figures (e.g. Figure 2 and Figure 4 figure supplements).</p><p>Recommendation: – If the supplementary material so important for reaching the conclusions of the paper, perhaps it would be more helpful to include them in the body of the paper. Otherwise I would suggest the authors to move the relevant explanations to the supplements.</p><p>7) Challenge: – The authors demonstrate that their approach can identify variability in the detected signals with behavioral relevance. The authors investigated this question by testing relations between brain age residuals and cognitive measures orthogonalized wrt chronological age. It is interesting why the authors have adopted this modular process, which has faced some criticism, as opposed to a single level model that can flexibly accommodate all variables in a single model (Lindquist, Geuter, Wager and Caffo, 2019).</p><p>Recommendation: – Authors should at least address this choice in the paper. (Lindquist, et al., 2019)</p><p>8) Challenge: – The authors do not seem to have considered the inclusion of variables of not interest which may lead to spurious correlations.</p><p>Recommendation: – Variables such as gender, handedness, head motion, total grey matter and total intracranial volume should be controlled for to ensure the specificity of the findings. One way to address both points would be to evaluate a model with multiple predictors including age, cognitive variable (e.g. Cattell) and covariates of not interest, where the dependent variable is brain age. Then the statistics on the cognitive variable of interest, which would indicate unique contribution to predict brain age over and above chronological age and covariates (i.e. individual variability), can be reported in the format of Figure 3.</p><p>9) Challenge: – The previous comment raised the concern about covariates of no interest and their consideration in the post hoc analysis.</p><p>Recommendation: – It would be really worthwhile having the authors' view whether the approach can/should include covariates of no interest in Layer I. This could be particularly relevant if each modality is associated with &quot;unique&quot; covariates of no interest (e.g. head motion in fMRI, or empty room recording SNR in MEG). Though, I assume that the combination of multiple datasets will reduce this bias, which brings me to my next point.</p><p>10) Recommendation: – It would be a really worthwhile the authors could consider reporting what part of the data in Level I contributed to the overall model performance, i.e. what is the topography in each modality that matters (e.g. atrophy in frontal regions, connectivity in DMN etc.)?</p><p>11) Challenge: – Some of the results or explanations for the results in the Discussion are not intuitive or perhaps adequately explained in the context of the existent literature and the design of the analysis.</p><p>Recommendation: – Revise the Discussion to address this concern.</p><p>12) Challenge: – Limitations – Limitations of the methodology (i.e. its assumptions) or the choice of the features (i.e. static vs dynamic) are not adequately put in context or discussed.</p><p>Recommendation: – Authors need to, at least briefly, discuss about how potential assumption violations might affect the results.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.54055.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Challenges and Recommendations:</p><p>Nevertheless, our enthusiasm was somewhat tempered by several key limitations of the report. In this section, I briefly summarize the most important comments.</p><p>1) Challenge: The motivation for including MEG seems to be exclusively based on EEG evidence. In the Introduction, all the evidence about the relationship between electrophysiology and ageing (and the complementarity to fMRI in that context) to motivate its inclusion as an additional modality is drawn from the EEG literature, which is odd, given that the paper uses MEG instead.</p><p>Recommendation: The authors should motivate the use of MEG directly or at least link the evidence from EEG to the use of MEG in a more convincing way. This might be as simple as saying that, although a lot of evidence from EEG is available, there is no available EEG data in multimodal databases (which I think would be a fair statement in general), but given the relationship between the two techniques, it is expected that inclusion of MEG would be valuable as well, this link is not clear in the text.</p></disp-quote><p>We thank the reviewers for this suggestion. We have now reworked the arguments connecting MEG and EEG to yield a more coherent and stringent motivation and emphasizing their differences more concretely. We have now expanded our review on multimodal MRI/electrophysiology datasets. Note that we have also adjusted the scope of the title to refocus the paper more strongly on MEG.</p><p>The paper is now entitled “Combining magnetoencephalography with magnetic resonance imaging enhances learning of surrogate-biomarkers”.</p><p>Please find below one new passage from the Introduction that best captures the spirit of this particular revision:</p><p>“At this point, there are very few multimodal databases providing access to electrophysiology alongside MRI and fMRI. […] MEG is, therefore, an interesting modality in its own right for developing neuro-cognitive biomarkers while its close link with EEG may potentially open the door to translatable electrophysiology markers suitable for massive deployment with clinical EEG.”</p><disp-quote content-type="editor-comment"><p>2) Challenge: The Materials and methods are not entirely clear. Some of the processing/feature extraction steps are not completely explained or appropriately justified. The taxonomy used for the extracted features in MEG is confusing.</p><p>Recommendation: Clarify the Materials and methods.</p></disp-quote><p>We thank the reviewers for having shared their concerns. We have worked through the list of issues and revised the manuscript.</p><disp-quote content-type="editor-comment"><p>3) Challenge: Missing Statistics. Statistical significance of some of the results are missing: Many of the results do not report any statistical significance threshold (or p-value), which makes claims about results being above chance, not rigorously justified. (e.g. &quot;…All stacking models performed consistently better than chance…&quot; What does it mean to perform better than chance here? Was a statistical significance test carried out? What was the null hypothesis tested? If so, report the p-value or equivalent used? In some cases, statistical significance is obvious, in others, it is difficult to assess via visual inspection.</p><p>Recommendation: Report statistical significance of any comparisons made (either corrected or not) in the main report and in the supplement e.g. for MAE differences and MAE PE correlations.</p></disp-quote><p>We understand the reviewers desire for a numerical estimate of statistical significance. While p-values can in principle be readily computed in the current setting for the question whether a model performed better than chance, e.g., by permuting the labels, the situation is less clear for model comparisons targeting differences in performance between two models. Rejecting a null-hypothesis that differences between models are due to chance would require several, ie., many independent datasets. Here, we computed uncertainty estimates of paired differences using the repeated 10-fold cross validation. For reasons of computational tractability, we estimated chance-level prediction using a dummy regressor that predicts the average of the training-set target using the same cross-validation procedure and identical random seeds to ensure split-wise comparability with non-trivial models.</p><p>To provide a more compact summary of the performance distributions that may help the reader to assess statistical inference, we extracted additional summary statistics of the distributions of mean absolute error scores and its paired differences with a reference model, where appropriate. These summaries included the mean, the standard deviation, the 2.5 and 97.5 percentiles and the number of splits in which the model was better than the reference. We have reworked the main text to make explicit the statistical approach and supplemented our report of the main findings inside the main text with these numerical uncertainty statistics. The following new section in the Materials and methods section explains our position and our methodological approach:</p><p>“Statistical Inference</p><p>Rejecting a null-hypothesis regarding differences between two cross-validated models is problematic in the absence of sufficiently large unseen data or independent datasets: cross-validated scores are not statistically independent. […] It should be clear, however, that hypothesis-testing, here, provides a quantitative orientation that needs to be contextualized by empirical estimates of effect sizes and their uncertainty to support inference.”</p><p>Finally, in the light of the cumulative comments made regarding the analysis of prediction errors across age, we have reworked that analysis to be visually more clearly represented and better integrated into the main text as Figure 2—figure supplement 2. In the process, we have attenuated our conclusions to be more nuanced and made the attempt to formalize inference by using an ANOVA model with age group, model family and their interactions as factors.</p><disp-quote content-type="editor-comment"><p>4) Challenge: Generality. It is important to demonstrate the robustness and reliability of these features to generalize in unseen data.</p><p>Recommendation: The authors could readily address this in the available data by splitting the sample in half (while maintaining the age distribution and data missingness) and test how similar are the loadings of each feature across data splits. The process could be repeated multiple times (1000s) to create a distribution, which can be compared to the distribution from a permuted data.</p></disp-quote><p>We thank the reviewers for this suggestion. Our principal method across analyses for assessing robustness and reliability of features was the model comparisons method. This approach allowed us to track changes in performance as semantically and logically related blocks of intercorrelated variables are included or excluded. We used cross-validation to obtain an asymptotically unbiased estimate of the expected generalization error and its uncertainty distributions. Note that cross-validation already implements the resampling procedure suggested in this comment with the difference that 90% of the data were used for training in each round and duplication of procedures is not necessary as the cross validation distribution is sufficient to obtain useful inferences (see point above). However, we strongly agree that while expectations and their uncertainties are captured by the visualization and the newly added summary statistics, the relative stability of the model rankings may not be obvious based on our previous reports. We have therefore extended the reports to visualize and quantify the out-of-sample stability of the model ranking across the testing-set splits, which has given rise to novel supplementary figures.</p><p>For the specific inspection of the MEG model, we have now reported additional results based on two alternative variable importance metrics: 1) The out-of-sample permutations assessing the average permutation importance across cross-validation splits, which may yield an estimate of variables importance that is less prone to overfitting, and, 2) MDI importance potentially sensitive to the conditional dependencies between the variables but more prone to overfitting and false negatives/false positives. These additional analyses suggested that the importance ranking was highly consistent across methods with intercorrelations above .9. (Spearman rank correlation).</p><p>We have now reported the additional results in new supplementary figures, Figure 2—figure supplement 1 and Figure 4—figure supplements 1 and 2.</p><disp-quote content-type="editor-comment"><p>5) Challenge: Non-random Missing Data. It is important to show that the approach is not susceptible to confounds in the missing data (non-random missingness; e.g. more missing data coming from older individuals, which “helps” to learn an age-related effects).</p><p>Recommendation: This could be easily addressed e.g. by comparing model performance between two scenarios of missingness in the fully available dataset. In one scenario the missing data come from subjects with uniform age distribution and in the other scenario a bias in age selection is introduced, i.e. larger portion of missing data comes from older individuals.</p></disp-quote><p>We thank the reviewers for raising this point. We feel that we may not have stated clearly enough that the sensitivity of our method with regard to non-random missingness is not a bug but a feature. Our method, by design, necessarily learns from any non-random missingness, which can be desired or undesired in different contexts. We have now extended the related Results section to make this point explicit and proposed as a diagnostic instrument to detect non-random missingness by training the random forest from the input data only including zeros or missingness indicators. In our case, the resulting model performance was well aligned with the distribution of chance-level scores, suggesting that missing values were not related to aging:</p><p>“It is important to emphasize that if missing values depend on age, the opportunistic model inevitably captures this information, hence, bases its predictions on the non-random missing data. […] In the current setting, the model trained on missing data indicators performed at chance level (<italic>Pr</italic><sub>&lt;<italic>Chance</italic></sub> = 30.00%, <italic>M</italic> = 0.65, <italic>SD</italic> = 1.68, <italic>P</italic><sub>2.5,97.5</sub> = [–2.96,3.60]), suggesting that the missing values were not informative of age.”</p><disp-quote content-type="editor-comment"><p>6) Challenge: Need to better integrate or segregate the main report and the supplement – Extensive text is dedicated to supplementary figures (e.g. Figure 2 and Figure 4 figure supplements).</p><p>Recommendation: If the supplementary material so important for reaching the conclusions of the paper, perhaps it would be more helpful to include them in the body of the paper. Otherwise I would suggest the authors to move the relevant explanations to the supplements.</p></disp-quote><p>We have now revised the presentation of the results to yield a clearer division of labor between main text and supplement. Each supplementary analysis is now summarized by one sentence in the main text while providing the detailed contextual discussion in the respective supplementary figure captions:</p><p>For Figure 2 supplements:</p><p>“This additive component also became apparent when considering predictive simulations on how the model actually combined MEG, fMRI and MRI (Figure 2—figure supplement 2) using two dimensional partial dependence analysis (Karrer et al., 2019; Hastie et al., 2005, chapter 10.13.2). Moreover, exploration of the age-dependent improvements through stacking suggest that stacking predominantly reduced prediction errors uniformly (Figure 2—figure supplement 3) instead of systematically mitigating brain age bias (Le et al., 2018; Smith et al., 2019). ”</p><p>For Figure 4 supplements:</p><p>“Moreover, partial dependence analysis (Karrer et al., 2019; Hastie et al., 2005, chapter 10.13.2) suggested that the Layer-II random forest extracted non-linear functions (Figure 4—figure supplement 3). Finally, the best stacked models scored lower errors than the best linear models (Figure 4—figure supplement 4), suggesting that stacking achieved more than mere variable selection by extracting non-redundant information from the inputs.”</p><disp-quote content-type="editor-comment"><p>7) Challenge: The authors demonstrate that their approach can identify variability in the detected signals with behavioral relevance. The authors investigated this question by testing relations between brain age residuals and cognitive measures orthogonalized wrt chronological age. It is interesting why the authors have adopted this modular process, which has faced some criticism, as opposed to a single level model that can flexibly accommodate all variables in a single model (Lindquist, Geuter, Wager and Caffo, 2019).</p><p>Recommendation: Authors should at least address this choice in the paper. (Lindquist et al., 2019).</p><p>8) Challenge: The authors do not seem to have considered the inclusion of variables of not interest which may lead to spurious correlations.</p><p>Recommendation: Variables such as gender, handedness, head motion, total grey matter and total intracranial volume should be controlled for to ensure the specificity of the findings. One way to address both points would be to evaluate a model with multiple predictors including age, cognitive variable (e.g. Cattell) and covariates of not interest, where the dependent variable is brain age. Then the statistics on the cognitive variable of interest, which would indicate unique contribution to predict brain age over and above chronological age and covariates (i.e. individual variability), can be reported in the format of Figure 3.</p></disp-quote><p>We thank the reviewers for sharing this reference and suggesting extended deconfounding. In fact, our method was based on the discussion in Smith et al., 2019</p><p>(https://doi.org/10.1016/j.neuroimage.2019.06.017) and pragmatically motivated : modular methods may be simpler to explain. To go beyond a modular model, we also performed a joint model with polynomial confounds such that $score = brain_age + poly(age, 3) + error$ and then extracted the brain age coef, this time quantifying effects conditional on the confounders. Moreover, we have included the additional confounders gender, handedness and motion parameters in a third model.</p><p>Note that motion correction was already performed during fMRI-preprocessing and that MEG source localization took into account individual head geometry as well as potentially confounding environmental noise through whitening with the noise covariance obtained from empty room recordings. Likewise, following the work by Liem et al., 2017, we included total grey matter and total intracranial volume as important features of interest among the MRI-features.</p><p>We found that the alternative models did not affect our conclusions and observed that deconfounding seemed to even improve the effect sizes of the models.</p><p>We have reworked and extended the Materials and methods description, included the citation regarding modularity and reported the alternative regression models in the subsection “Analysis of brain-behavior correlation”.</p><p>“The brain age Δ was defined as the difference between predicted and actual age of the person <inline-formula><mml:math id="inf124"><mml:mrow><mml:msub><mml:mtext mathvariant="normal">BrainAge</mml:mtext><mml:mi>Δ</mml:mi></mml:msub><mml:mspace width="0.222em"/><mml:mo>=</mml:mo><mml:mspace width="0.222em"/><mml:msub><mml:mtext mathvariant="normal">age</mml:mtext><mml:mtext mathvariant="normal">pred</mml:mtext></mml:msub><mml:mo>−</mml:mo><mml:mtext mathvariant="normal">age</mml:mtext></mml:mrow></mml:math></inline-formula>, such that positive values quantify overestimation and negative value underestimation. […] Following the work by Liem et al., 2017, we included total grey matter and total intracranial volume as important features of interest among the MRI-features.”</p><p>See Figure 3—figure supplement 4 and Figure 3—figure supplement 5.</p><disp-quote content-type="editor-comment"><p>9) Challenge: The previous comment raised the concern about covariates of no interest and their consideration in the post hoc analysis.</p><p>Recommendation: It would be really worthwhile having the authors' view whether the approach can/should include covariates of no interest in Layer I. This could be particularly relevant if each modality is associated with &quot;unique&quot; covariates of no interest (e.g. head motion in fMRI, or empty room recording SNR in MEG). Though, I assume that the combination of multiple datasets will reduce this bias, which brings me to my next point.</p></disp-quote><p>We thank the reviewers for raising this interesting point. We are somewhat worried that including covariates at the first level may unnecessarily inflate the number of estimated parameters while, at the same time, leading to limited results due to the lack of expressiveness in the ridge model. However, including covariates in the second layer should be more promising as the number of variables will remain small and the Random Forest can learn arbitrarily deep interaction effects between covariates and brainage models. The change in performance and variable importance can then be used to assess the impact of confounds. This question is methodologically interesting and motivates a dedicated study in a more specialized journal. We once more thank the reviewers for stimulating that interesting direction of thinking.</p><disp-quote content-type="editor-comment"><p>10) Recommendation: It would be a really worthwhile the authors could consider reporting what part of the data in Level I contributed to the overall model performance, i.e. what is the topography in each modality that matters (e.g. atrophy in frontal regions, connectivity in DMN etc.)?</p></disp-quote><p>We thank the reviewer for this remark. Interpreting high-dimensional linear models by their parameters is not necessarily an easy task. Collinearity and noise can induce strong weights on features that are not intrinsically important. Showing weights maps in such high dimensional settings requires dedicated tools (ReNa https://dx.doi.org/10.1109/TPAMI.2018.2815524, etc;) leading to modifications of the predictive models used in layer-1 which were optimized for prediction but not interpretability. Adopting interpretability methods would necessarily lead to a parallel method pipeline whose integration would exceed the scope of the paper. We have admitted this important limitation in the new dedicated limitations section at the end of the Discussion.</p><p>“For the present study, we see four principal limitations: availability of data, interpretability, nonexhaustive feature-engineering and potential lack of generalizability due to the focus on MEG. […] We hope, nevertheless, that the insights from our work will stimulate studies investigating the link between MEG, fMRI and MRI across the life-span using an inference-oriented framework.”</p><disp-quote content-type="editor-comment"><p>11) Challenge: Some of the results or explanations for the results in the Discussion are not intuitive or perhaps adequately explained in the context of the existent literature and the design of the analysis.</p><p>Recommendation: Revise the Discussion to address this concern.</p></disp-quote><p>We thank the reviewers for pointing out the issues concerning the interpretation of the results. We have worked through the issues and updated the manuscript accordingly.</p><disp-quote content-type="editor-comment"><p>12) Challenge: Limitations – Limitations of the methodology (i.e. its assumptions) or the choice of the features (i.e. static vs dynamic) are not adequately put in context or discussed.</p><p>Recommendation: Authors need to, at least briefly, discuss about how potential assumption violations might affect the results.</p></disp-quote><p>We thank the reviewers for this suggestion. We have now included an explicit limitations section at the end of the Discussion passage.</p></body></sub-article></article>