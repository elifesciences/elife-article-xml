<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">84955</article-id><article-id pub-id-type="doi">10.7554/eLife.84955</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Neural population dynamics underlying evidence accumulation in multiple rat brain regions</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>DePasquale</surname><given-names>Brian</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3830-3184</contrib-id><email>bddepasq@bu.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="pa1">‡</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes"><name><surname>Brody</surname><given-names>Carlos D</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4201-561X</contrib-id><email>brody@princeton.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" equal-contrib="yes"><name><surname>Pillow</surname><given-names>Jonathan W</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3638-8831</contrib-id><email>pillow@princeton.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hx57361</institution-id><institution>Princeton Neuroscience Institute, Princeton University</institution></institution-wrap><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hx57361</institution-id><institution>Howard Hughes Medical Institute, Princeton University</institution></institution-wrap><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hx57361</institution-id><institution>Department of Psychology, Princeton University</institution></institution-wrap><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Forstmann</surname><given-names>Birte U</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04dkp9463</institution-id><institution>University of Amsterdam</institution></institution-wrap><country>Netherlands</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn><fn fn-type="present-address" id="pa1"><label>‡</label><p>Department of Biomedical Engineering, Boston University, Boston, United States</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>20</day><month>08</month><year>2024</year></pub-date><volume>13</volume><elocation-id>e84955</elocation-id><history><date date-type="received" iso-8601-date="2022-11-16"><day>16</day><month>11</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2024-08-07"><day>07</day><month>08</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2021-10-29"><day>29</day><month>10</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.10.28.465122"/></event></pub-history><permissions><copyright-statement>© 2024, DePasquale et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>DePasquale et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-84955-v3.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-84955-figures-v3.pdf"/><abstract><p>Accumulating evidence to make decisions is a core cognitive function. Previous studies have tended to estimate accumulation using either neural or behavioral data alone. Here, we develop a unified framework for modeling stimulus-driven behavior and multi-neuron activity simultaneously. We applied our method to choices and neural recordings from three rat brain regions—the posterior parietal cortex (PPC), the frontal orienting fields (FOF), and the anterior-dorsal striatum (ADS)—while subjects performed a pulse-based accumulation task. Each region was best described by a distinct accumulation model, which all differed from the model that best described the animal’s choices. FOF activity was consistent with an accumulator where early evidence was favored while the ADS reflected near perfect accumulation. Neural responses within an accumulation framework unveiled a distinct association between each brain region and choice. Choices were better predicted from all regions using a comprehensive, accumulation-based framework and different brain regions were found to differentially reflect choice-related accumulation signals: FOF and ADS both reflected choice but ADS showed more instances of decision vacillation. Previous studies relating neural data to behaviorally inferred accumulation dynamics have implicitly assumed that individual brain regions reflect the whole-animal level accumulator. Our results suggest that different brain regions represent accumulated evidence in dramatically different ways and that accumulation at the whole-animal level may be constructed from a variety of neural-level accumulators.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>decision-making</kwd><kwd>latent variable models</kwd><kwd>evidence accumulation</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rat</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>SCGB AWD543027</award-id><principal-award-recipient><name><surname>Brody</surname><given-names>Carlos D</given-names></name><name><surname>Pillow</surname><given-names>Jonathan W</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>SCGB AWD542593</award-id><principal-award-recipient><name><surname>Brody</surname><given-names>Carlos D</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><award-id>BRAIN Initiative Award 5U19NS104648-02</award-id><principal-award-recipient><name><surname>Pillow</surname><given-names>Jonathan W</given-names></name><name><surname>Brody</surname><given-names>Carlos D</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000070</institution-id><institution>National Institute of Biomedical Imaging and Bioengineering</institution></institution-wrap></funding-source><award-id>R01 EB026946</award-id><principal-award-recipient><name><surname>Pillow</surname><given-names>Jonathan W</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000070</institution-id><institution>National Institute of Biomedical Imaging &amp; Bioengineering</institution></institution-wrap></funding-source><award-id>9RF1DA065404 - 04</award-id><principal-award-recipient><name><surname>Pillow</surname><given-names>Jonathan W</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A computational framework for combining neural and behavioral data to infer latent dynamics underlying decision-making reveals distinct accumulation dynamics in different brain regions in the rat.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Accumulation of evidence is a critical process underlying decision-making in complex environments where relevant information is distributed across time. Choice data from evidence accumulation tasks e.g., <xref ref-type="bibr" rid="bib12">Brunton et al., 2013</xref>; <xref ref-type="bibr" rid="bib40">Raposo et al., 2012</xref>; <xref ref-type="bibr" rid="bib47">Sanders and Kepecs, 2012</xref> have allowed for the development of sophisticated models of animals’ accumulation strategies (e.g., <xref ref-type="bibr" rid="bib6">Bogacz et al., 2006</xref>; <xref ref-type="bibr" rid="bib12">Brunton et al., 2013</xref>; <xref ref-type="bibr" rid="bib22">Genkin et al., 2021</xref>; <xref ref-type="bibr" rid="bib24">Gold and Shadlen, 2007</xref>; <xref ref-type="bibr" rid="bib43">Ratcliff et al., 2016</xref>; <xref ref-type="bibr" rid="bib42">Ratcliff and McKoon, 2008</xref>; <xref ref-type="bibr" rid="bib49">Shinn et al., 2020</xref>; <xref ref-type="bibr" rid="bib53">Wiecki et al., 2013</xref>). In parallel, neural correlates of accumulated evidence have been found in a wide variety of brain regions (e.g., <xref ref-type="bibr" rid="bib9">Brody and Hanks, 2016</xref>; <xref ref-type="bibr" rid="bib15">Churchland et al., 2011</xref>; <xref ref-type="bibr" rid="bib16">Ding and Gold, 2010</xref>; <xref ref-type="bibr" rid="bib19">Erlich et al., 2011</xref>; <xref ref-type="bibr" rid="bib24">Gold and Shadlen, 2007</xref>; <xref ref-type="bibr" rid="bib25">Hanks et al., 2015</xref>; <xref ref-type="bibr" rid="bib27">Huk and Shadlen, 2005</xref>; <xref ref-type="bibr" rid="bib30">Kim and Shadlen, 1999</xref>; <xref ref-type="bibr" rid="bib35">Mante et al., 2013</xref>; <xref ref-type="bibr" rid="bib41">Ratcliff et al., 2003</xref>; <xref ref-type="bibr" rid="bib46">Roitman and Shadlen, 2002</xref>; <xref ref-type="bibr" rid="bib48">Shadlen and Newsome, 2001</xref>; <xref ref-type="bibr" rid="bib54">Yartsev et al., 2018</xref>) and methods have been developed to describe the statistical relationship between neural activity and accumulated evidence (e.g., <xref ref-type="bibr" rid="bib3">Aoi et al., 2020</xref>; <xref ref-type="bibr" rid="bib4">Beck et al., 2008</xref>; <xref ref-type="bibr" rid="bib15">Churchland et al., 2011</xref>; <xref ref-type="bibr" rid="bib25">Hanks et al., 2015</xref>; <xref ref-type="bibr" rid="bib31">Latimer et al., 2015</xref>; <xref ref-type="bibr" rid="bib32">Latimer and Freedman, 2021</xref>; <xref ref-type="bibr" rid="bib36">Park et al., 2014</xref>; <xref ref-type="bibr" rid="bib55">Zoltowski et al., 2019</xref>; <xref ref-type="bibr" rid="bib56">Zoltowski et al., 2020</xref>).</p><p>Obtaining a comprehensive account of how stimulus-influenced accumulated evidence underlies neural activity and subject choice remains an open problem. For example, few analysis methods which use precise spike timing information take into account the timing of stimulus information or use choice data directly (e.g., <xref ref-type="bibr" rid="bib31">Latimer et al., 2015</xref>). Likewise few methods that use the precise timing of stimulus information to infer accumulated evidence use neural responses directly (e.g., <xref ref-type="bibr" rid="bib25">Hanks et al., 2015</xref>). To address this gap, we developed a framework for inferring probabilistic evidence accumulation models jointly from choice data, neural activity, and precisely controlled stimuli.</p><p>A complete understanding of decision-making necessitates models that can comprehensively combine stimuli, neural activity, and behavior. The evidence accumulation process inferred from behavioral data alone need not correspond to the accumulation process that best matches data from a single brain region; behavior is the result of interactions between multiple brain regions. For example, two brain regions, one favoring accumulation of early evidence (e.g., an unstable accumulator) and the other favoring accumulation of late evidence (e.g., a leaky accumulator) could together support stable behavior-level accumulation. By fitting accumulator models to neural data from multiple brain regions and to subject choice data, we gained the opportunity to probe for the first time whether different brain regions reflect the same, or different, accumulation processes and how those individual processes correspond to the animal’s overall behavior.</p><p>We applied our model to choices and neural responses from three brain regions known to be involved in evidence accumulation while animals perform a pulse-based evidence accumulation task. A single variable representing accumulated evidence, shared across neurons within a brain region, accurately accounted for both neural and choice data. We identified distinct signatures of accumulation reflected in each brain region, all of which differed from the accumulation model that best described behavior, supporting the idea that whole-organism accumulation likely results from multiple accumulation processes. Prior analysis of these data found that the anterodorsal striatum (ADS) represented accumulated evidence in a graded manner (<xref ref-type="bibr" rid="bib54">Yartsev et al., 2018</xref>) while the frontal orienting fields (FOF) represented choice more categorically (<xref ref-type="bibr" rid="bib25">Hanks et al., 2015</xref>). Our analysis confirms the ADS as a veracious representation of accumulated evidence while offering a more nuanced view of the FOF: the accumulation model that best described FOF activity was dynamically unstable, producing neural responses that looked like a categorical representation of choice but that were in fact unstable accumulators sensitive to early stimulus information. Additionally, we analyzed recordings from the posterior parietal cortex (PPC), a brain region long studied in connection to evidence accumulation (<xref ref-type="bibr" rid="bib25">Hanks et al., 2015</xref>; <xref ref-type="bibr" rid="bib46">Roitman and Shadlen, 2002</xref>; <xref ref-type="bibr" rid="bib48">Shadlen and Newsome, 2001</xref>), where we identified neural correlates of graded evidence accumulation, albeit more weakly than in the ADS.</p><p>Incorporating neural activity into accumulation models reduced the uncertainty in the moment-by-moment value of accumulated evidence when compared to models fit only to animal choices. This reduction in uncertainty led to a more refined picture of the moment-by-moment value of accumulated evidence, which made the model more informative about what choice the animal intended to make. Our model allowed us to implement a novel analysis to examine how subject provisional choice changed during individual trials, commonly referred to as ‘changes of mind’ (<xref ref-type="bibr" rid="bib8">Boyd-Meredith et al., 2022</xref>; <xref ref-type="bibr" rid="bib29">Kiani et al., 2014</xref>; <xref ref-type="bibr" rid="bib37">Peixoto et al., 2021</xref>), that revealed extensive choice vacillation reflected in ADS activity and greater choice certainty reflected in FOF activity.</p><p>Broadly, our framework offers a unified, mechanistic, and probabilistic description of the moment-by-moment accumulation process that underlies decision-making. Our flexible framework offers a computationally efficient method for identifying a key normative decision-making model using multiple types of data, and can easily accommodate simultaneous recordings from many neurons or recordings performed sequentially over many days. It provides a platform for quantitatively characterizing choice-related information in neural responses and can be used to understand how different brain regions implement an accumulation strategy.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We analyzed behavioral and neural data from rats trained to perform a perceptual decision-making task (<xref ref-type="bibr" rid="bib12">Brunton et al., 2013</xref>). Rats listened to two simultaneous series of randomly timed auditory clicks, one from a speaker on the left and one from a speaker on the right. After the end of the click train, the rat had to orient to the side with a greater number of clicks to receive a reward (<xref ref-type="fig" rid="fig1">Figure 1A</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Accumulating evidence task and latent variable model.</title><p>(<bold>A</bold>) Rats performed a pulse-based evidence accumulation task. A central LED illuminates indicating that the rat can begin a trial by poking its nose in a central port. After a delay of random duration, an auditory stimulus of variable duration is delivered—a series of brief auditory pulses played from a left and a right speaker. Upon cessation of the stimulus, the rat must orient to the direction of the greater number of pulses to receive a water reward. (<bold>B</bold>) The model relates the click-based sensory stimulus to two types of observations—the animal’s choice and neural activity observed during the task. The latent variable model is a bounded accumulator. Left and right clicks (green and red arrows, respectively) push the variable to one side or the other; if the accumulator variable reaches the bound <italic>B</italic> (dotted line) accumulation ceases. Seven parameters govern the dynamics of <italic>a</italic>(<italic>t</italic>) (see main text). Two different hypothetical trajectories of <italic>a(t</italic>) are illustrated (black and blue) for the same click stimulus; the two trajectories differ due to the diffusive and stimulus noise in the model. <italic>a</italic>(<italic>t</italic>) relates to the animal’s choice by a Heaviside step function and to neural activity by way of a softplus nonlinearity and a Poisson distribution. <italic>a</italic>(<italic>t</italic>) is common for all simultaneously recorded neurons and each neuron has its own parameters that determine its tuning curve.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84955-fig1-v3.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Recovering the parameters of synthetic data.</title><p>Synthetic data was generated with parameters <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <italic>B</italic>=15, <inline-formula><mml:math id="inf2"><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mn>0.5</mml:mn></mml:math></inline-formula>, <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>20</mml:mn></mml:math></inline-formula>, <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.02</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. Two synthetic ’sessions’ were generated, with 400 trials and 3 neurons each. Softplus gain parameters were randomly generated between –2 and 2. Parameters for decisions were <italic>c</italic>=1 (bias), <inline-formula><mml:math id="inf7"><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math></inline-formula> (lapse). (<bold>A</bold>) Peri-stimulus time histograms (PSTHs) for two example neurons for synthetic data and simulated data after model fitting. Trials were averaged for strong evidence to the right (red) and left (brown). (<bold>B</bold>) Psychometric curves for synthetic data and simulated data after model fitting. (<bold>C</bold>) Optimization was initialized at a random set of parameters (‘initial’). Maximum likelihood parameters (‘final’) converged to within two standard deviations (error bars computed by Laplace approximation) of the parameters used to generate the data (dotted lines). <inline-formula><mml:math id="inf8"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> refers to the neuron parameters for the <italic>j</italic>th neuron from the <italic>i</italic>th session.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84955-fig1-figsupp1-v3.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Recovering the parameters of synthetic data for multiple datasets.</title><p>Four synthetic datasets with different model parameters (red, cyan, green, blue) were generated as in <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> (two sessions per dataset, with three neurons in each session). Dotted lines in each panel indicate the generative parameters. Optimization was initialized at a random set of parameters (‘init.’). Maximum likelihood parameters (‘final’) almost always converge to within two standard deviations (error bars computed by Laplace approximation) of the parameters used to generate the data. <inline-formula><mml:math id="inf9"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> refers to the neuron parameters for the <italic>j</italic>th neuron from the <italic>i</italic>th session.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84955-fig1-figsupp2-v3.tif"/></fig></fig-group><p>We analyzed behavioral choice data and electrophysiological neural recordings from 11 rats. In total, we analyzed 37,179 behavioral choices and 141 neurons from three brain areas—the PPC, the FOF, and the ADS. Prior electrophysiological and lesions studies have shown that these brain regions play a key role in evidence accumulation (<xref ref-type="bibr" rid="bib17">Ding and Gold, 2013</xref>; <xref ref-type="bibr" rid="bib16">Ding and Gold, 2010</xref>; <xref ref-type="bibr" rid="bib20">Erlich et al., 2015</xref>; <xref ref-type="bibr" rid="bib19">Erlich et al., 2011</xref>; <xref ref-type="bibr" rid="bib24">Gold and Shadlen, 2007</xref>; <xref ref-type="bibr" rid="bib23">Gold and Shadlen, 2000</xref>; <xref ref-type="bibr" rid="bib25">Hanks et al., 2015</xref>; <xref ref-type="bibr" rid="bib27">Huk and Shadlen, 2005</xref>; <xref ref-type="bibr" rid="bib30">Kim and Shadlen, 1999</xref>; <xref ref-type="bibr" rid="bib35">Mante et al., 2013</xref>; <xref ref-type="bibr" rid="bib46">Roitman and Shadlen, 2002</xref>; <xref ref-type="bibr" rid="bib48">Shadlen and Newsome, 2001</xref>; <xref ref-type="bibr" rid="bib54">Yartsev et al., 2018</xref>).</p><p>Data were collected after the animals were well trained and exhibiting a high level of performance (<xref ref-type="bibr" rid="bib12">Brunton et al., 2013</xref>; <xref ref-type="bibr" rid="bib25">Hanks et al., 2015</xref>; <xref ref-type="bibr" rid="bib54">Yartsev et al., 2018</xref>); these data were collected as part of two earlier studies and have been previously analyzed (<xref ref-type="bibr" rid="bib25">Hanks et al., 2015</xref>; <xref ref-type="bibr" rid="bib54">Yartsev et al., 2018</xref>). Data were subject to a selection criterion for inclusion in our study. We selected neurons with significant tuning for choice during the stimulus period (two-sample t-test, p&lt;0.01) because choice tuning is a prerequisite for reflecting accumulation-like signals. Information about the data is summarized in <xref ref-type="table" rid="table1">Table 1</xref>. Once tuning significance was determined, our dataset consisted of 68 neurons from FOF, with 7382 behavioral choices recorded from five rats over 46 behavioral sessions; 25 neurons from PPC, with 9037 behavioral choices from three rats over 24 sessions; and 48 neurons from ADS, with 10,760 behavioral choices from three rats over 27 behavioral sessions.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Number of neurons, sessions, and trials for each rat.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Rat</th><th align="left" valign="bottom">Region</th><th align="left" valign="bottom">Sessions</th><th align="left" valign="bottom">Neurons</th><th align="left" valign="bottom">Trials</th><th align="left" valign="bottom">Sessions with greater than 1 neuron</th><th align="left" valign="bottom">Max. # of simultaneously recorded neurons</th></tr></thead><tbody><tr><td align="left" valign="bottom">B068</td><td align="left" valign="bottom">FOF</td><td align="char" char="." valign="bottom">11</td><td align="char" char="." valign="bottom">13</td><td align="char" char="." valign="bottom">5859</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">2</td></tr><tr><td align="left" valign="bottom">T034</td><td align="left" valign="bottom">FOF</td><td align="char" char="." valign="bottom">9</td><td align="char" char="." valign="bottom">10</td><td align="char" char="." valign="bottom">4138</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">2</td></tr><tr><td align="left" valign="bottom">T036</td><td align="left" valign="bottom">FOF</td><td align="char" char="." valign="bottom">8</td><td align="char" char="." valign="bottom">12</td><td align="char" char="." valign="bottom">3026</td><td align="char" char="." valign="bottom">4</td><td align="char" char="." valign="bottom">2</td></tr><tr><td align="left" valign="bottom">T063</td><td align="left" valign="bottom">FOF</td><td align="char" char="." valign="bottom">17</td><td align="char" char="." valign="bottom">32</td><td align="char" char="." valign="bottom">4002</td><td align="char" char="." valign="bottom">9</td><td align="char" char="." valign="bottom">3</td></tr><tr><td align="left" valign="bottom">T030</td><td align="left" valign="bottom">FOF</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">357</td><td align="char" char="." valign="bottom">0</td><td align="char" char="." valign="bottom">1</td></tr><tr><td align="left" valign="bottom">T035</td><td align="left" valign="bottom">PPC</td><td align="char" char="." valign="bottom">15</td><td align="char" char="." valign="bottom">16</td><td align="char" char="." valign="bottom">5919</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">2</td></tr><tr><td align="left" valign="bottom">T011</td><td align="left" valign="bottom">PPC</td><td align="char" char="." valign="bottom">7</td><td align="char" char="." valign="bottom">7</td><td align="char" char="." valign="bottom">2235</td><td align="char" char="." valign="bottom">0</td><td align="char" char="." valign="bottom">1</td></tr><tr><td align="left" valign="bottom">B053</td><td align="left" valign="bottom">PPC</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">883</td><td align="char" char="." valign="bottom">0</td><td align="char" char="." valign="bottom">1</td></tr><tr><td align="left" valign="bottom">T080</td><td align="left" valign="bottom">ADS</td><td align="char" char="." valign="bottom">5</td><td align="char" char="." valign="bottom">6</td><td align="char" char="." valign="bottom">1731</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">2</td></tr><tr><td align="left" valign="bottom">T103</td><td align="left" valign="bottom">ADS</td><td align="char" char="." valign="bottom">19</td><td align="char" char="." valign="bottom">38</td><td align="char" char="." valign="bottom">8332</td><td align="char" char="." valign="bottom">9</td><td align="char" char="." valign="bottom">5</td></tr><tr><td align="left" valign="bottom">E021</td><td align="left" valign="bottom">ADS</td><td align="char" char="." valign="bottom">3</td><td align="char" char="." valign="bottom">4</td><td align="char" char="." valign="bottom">697</td><td align="char" char="." valign="bottom">1</td><td align="char" char="." valign="bottom">2</td></tr></tbody></table></table-wrap><sec id="s2-1"><title>A latent variable model of behavioral choice and neural activity</title><p>One of the most common normative models of the internal mental processes that underlie evidence accumulation is the drift-diffusion to bound model (DDM; <xref ref-type="fig" rid="fig1">Figure 1B</xref>; <xref ref-type="bibr" rid="bib6">Bogacz et al., 2006</xref>; <xref ref-type="bibr" rid="bib12">Brunton et al., 2013</xref>; <xref ref-type="bibr" rid="bib24">Gold and Shadlen, 2007</xref>; <xref ref-type="bibr" rid="bib42">Ratcliff and McKoon, 2008</xref>). While previous work has tended to fit this model (either explicitly or implicitly) using either choice data (e.g., <xref ref-type="bibr" rid="bib12">Brunton et al., 2013</xref>; <xref ref-type="bibr" rid="bib13">Chandrasekaran and Hawkins, 2019</xref>; <xref ref-type="bibr" rid="bib24">Gold and Shadlen, 2007</xref>; <xref ref-type="bibr" rid="bib43">Ratcliff et al., 2016</xref>; <xref ref-type="bibr" rid="bib49">Shinn et al., 2020</xref>; <xref ref-type="bibr" rid="bib53">Wiecki et al., 2013</xref>; <xref ref-type="bibr" rid="bib57">Zylberberg et al., 2016</xref>) or neural response data (e.g., <xref ref-type="bibr" rid="bib7">Bollimunta et al., 2012</xref>; <xref ref-type="bibr" rid="bib9">Brody and Hanks, 2016</xref>; <xref ref-type="bibr" rid="bib15">Churchland et al., 2011</xref>; <xref ref-type="bibr" rid="bib18">Ditterich, 2006</xref>; <xref ref-type="bibr" rid="bib22">Genkin et al., 2021</xref>; <xref ref-type="bibr" rid="bib25">Hanks et al., 2015</xref>; <xref ref-type="bibr" rid="bib26">Howard et al., 2018</xref>; <xref ref-type="bibr" rid="bib31">Latimer et al., 2015</xref>; <xref ref-type="bibr" rid="bib55">Zoltowski et al., 2019</xref>; <xref ref-type="bibr" rid="bib56">Zoltowski et al., 2020</xref>), here, we seek to jointly model the relationship between accumulated evidence, choices, and neural activity.</p><p>The essence of our model is to describe a DDM-based accumulation process driven by sensory stimuli following <xref ref-type="bibr" rid="bib12">Brunton et al., 2013</xref>, and relate the latent accumulation process to both neural responses and the rat’s choice. Previous results have shown that this model is sufficiently flexible to accommodate the various behavioral strategies rats exhibit while performing this task (<xref ref-type="bibr" rid="bib12">Brunton et al., 2013</xref>). The resulting model has a single latent variable, denoted <italic>a</italic>(<italic>t</italic>), that evolves in time and represents the current, inner mental representation of the evidence in support of a left or right choice at each moment in time. This latent variable is shared by the neurons within a region (except where explicitly noted), so that each neuron’s time-varying firing rate is a function of <italic>a</italic>(<italic>t</italic>) on each trial. The key distinction of our approach is that the accumulator variable <italic>a</italic>(<italic>t</italic>) drives both choices and neural activity, as described below.</p><p>Formally, the temporal evolution of the latent evidence <italic>a</italic>(<italic>t</italic>) is governed by:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mi>W</mml:mi><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>η</mml:mi><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <italic>da</italic> is the amount <italic>a</italic>(<italic>t</italic>) changes in a time <italic>dt</italic>. <italic>λ</italic> is a leak parameter. <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> indicate the difference and sum, respectively, of the number of right and left sensory clicks at time <italic>t</italic>, after the magnitude of the clicks has been adapted based on recent stimulus history (see parameters governing adaptation below, and Methods for additional details). <inline-formula><mml:math id="inf12"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mi>W</mml:mi></mml:math></inline-formula> is a diffusive Gaussian noise process (or Weiner process) with scaling <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>η</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is additive Gaussian noise induced by each click input, where <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is the standard deviation of the click noise and <inline-formula><mml:math id="inf16"><mml:mi>η</mml:mi></mml:math></inline-formula> is a Gaussian random variable with a mean of 0 and standard deviation 1.</p><p>If <italic>a</italic>(<italic>t</italic>) becomes greater in magnitude than a symmetric boundary with magnitude <italic>B</italic> (<xref ref-type="fig" rid="fig1">Figure 1B</xref>, dotted lines), then <italic>da</italic> = 0, and accumulation ceases for the remainder of the trial. To illustrate, the blue trajectory in <xref ref-type="fig" rid="fig1">Figure 1B</xref> crosses the boundary <italic>B</italic> roughly one-third of the way through the trial, and thus remains constant thereafter.</p><p>The four terms of <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> each account for specific ways <italic>a</italic>(<italic>t</italic>) might reflect accumulated evidence. The first two terms are designed to account for deterministic (non-random) dynamics exhibited by <italic>a</italic>(<italic>t</italic>). The first term specifies how recent values of <italic>a</italic>(<italic>t</italic>) influence future values and is governed by <italic>λ</italic> that determines the timescale of this effect. Positive values of <italic>λ</italic> correspond to unstable dynamics so that <italic>a</italic>(<italic>t</italic>) grows exponentially. In this setting, early clicks have greater influence on <italic>a</italic>(<italic>t</italic>) than recent clicks, because their impact grows with time. By contrast, negative values of <italic>λ</italic> correspond to leaky dynamics. In this setting, early clicks have a weaker influence on <italic>a</italic>(<italic>t</italic>) than recent clicks because the impact of early clicks decays with time. When <italic>λ</italic> equals zero, the sensory clicks are perfectly integrated. Previous results have shown that rats exhibit a range of accumulation strategies spanning these values of <italic>λ</italic> (<xref ref-type="bibr" rid="bib12">Brunton et al., 2013</xref>). The second term, <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, specifies how the click stimulus is incorporated into <italic>a</italic>(<italic>t</italic>). Because the task requires reporting whether there was a greater number of left or right clicks, only the total click difference is required to correctly perform it.</p><p>To account for stochasticity in the accumulation dynamics, the model also contains two forms of noise in <italic>a</italic>(<italic>t</italic>). The first noise term, <inline-formula><mml:math id="inf18"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mi>W</mml:mi></mml:math></inline-formula>, corresponds to diffusive noise that corrupts <italic>a</italic>(<italic>t</italic>) continuously in time. The final term, <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>η</mml:mi><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, introduces noise into <italic>a</italic>(<italic>t</italic>) that is proportional to the total number of clicks that occur at a given moment. The sum of clicks <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is included so that the magnitude of the noise increases depending on the number of sensory clicks experienced at time <italic>t</italic>. <xref ref-type="fig" rid="fig1">Figure 1B</xref> illustrates the effects of these two noise terms: although the sensory inputs and leak are identical for both blue and black trajectories of <italic>a</italic>(<italic>t</italic>), differences in noise lead the two trajectories to diverge so that one hits the boundary +<italic>B</italic> while the other remains sub-threshold and continues to integrate the sensory stimulus.</p><p>To model animal choices, we assume that the accumulation variable <italic>a</italic>(<italic>t</italic>) directly governs the animal’s choice on each trial. Specifically, we describe the probability of a rightward choice as depending on <italic>a</italic>(<italic>T</italic>), the accumulated evidence at the end of the stimulus period <italic>T</italic>, using a step function with ‘lapses’. With probability <inline-formula><mml:math id="inf21"><mml:mi>γ</mml:mi></mml:math></inline-formula> the animal picks one of the two sides without considering the stimulus, referred to as a ‘lapse’. With probability <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> the animal does not lapse, and makes a rightward choice if <italic>a</italic>(<italic>T</italic>)&gt;<italic>c</italic> and a leftward choice if <italic>a</italic>(<italic>T</italic>)&lt;<italic>c</italic>, where <italic>c</italic> denotes the choice criterion. This model can be expressed as:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>γ</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>γ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf23"><mml:mi>d</mml:mi><mml:mo>∈</mml:mo><mml:mo>{</mml:mo><mml:mi>L</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo>}</mml:mo></mml:math></inline-formula> is the decision variable and <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is the Heaviside step function. As described above, when <italic>a</italic>(<italic>t</italic>) crosses the decision bound <italic>B</italic> a choice commitment is made, either to the left or the right, and no further evidence accumulation occurs. Previous work has found that parameterizing choice this way creates a model that is sufficiently flexible to describe animals’ choice (<xref ref-type="bibr" rid="bib12">Brunton et al., 2013</xref>) while remaining as simple as possible.</p><p>To model spike train data, we describe the time-varying firing rate of each neuron as a soft rectified linear function of the same accumulated evidence variable <italic>a</italic>(<italic>t</italic>):<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mspace width="thinmathspace"/><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <italic>n</italic> indexes neurons, the softplus function (<xref ref-type="fig" rid="fig1">Figure 1B</xref>) is given by softplus(<italic>x</italic>)=log(1+exp(<italic>x</italic>)), and <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes the slope of the linear relationship between <italic>a</italic>(<italic>t</italic>) and neuron <italic>n</italic>’s firing rate. The slope parameter, <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, is fit separately for each neuron. A time-varying offset, <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, is included to capture time-varying changes in firing rate that do not depend on <italic>a</italic>(<italic>t</italic>) (see Methods). The spikes of each neuron are modeled as a Poisson process with a time-dependent conditional intensity function <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. The softplus function (smooth rectified linear function) was used to ensure the expected firing rate was positive, and was selected because it is the simplest function to achieve this goal, and also based on prior success in similar studies (e.g., <xref ref-type="bibr" rid="bib31">Latimer et al., 2015</xref>).</p><p>We refer to the set of all parameters that govern <italic>a(t</italic>) and its relationship to the neural activity and choice data as <inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf30"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the variance of <italic>a</italic>(<italic>t</italic>) at the start of the trial, and <italic>φ</italic> and <inline-formula><mml:math id="inf31"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> determine how the magnitude of each click is adapted based on the timing of recent clicks (see Methods). We fit Θ separately for each brain region using maximum likelihood (see Methods). Maximizing the likelihood of the data requires computing the temporal evolution of the probability distribution of <italic>a</italic>(<italic>t</italic>) over the duration of a single trial, for all trials, and computing the probability of the observed spikes and choices under this distribution. The dynamics of this probability distribution can be expressed using the Fokker-Planck equation, and previous work has developed methods for numerically solving it (<xref ref-type="bibr" rid="bib12">Brunton et al., 2013</xref>; see Methods). We refer to the value of Θ that maximizes the likelihood of the data as <inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. We verified that our method was able to recover the parameters that generated synthetic physiologically relevant spiking and choices data (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>), and that parameter recovery was robust across a range of parameter values (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>).</p></sec><sec id="s2-2"><title>Shared accumulator model captures neural responses and choices</title><p>We fit the model separately to data from each brain region. To verify model fits were consistent with data, we compared the peri-stimulus time histograms (PSTHs; <xref ref-type="fig" rid="fig2">Figure 2A and B</xref>) and psychometric curves (<xref ref-type="fig" rid="fig2">Figure 2C</xref>) of the empirical data to synthetic data simulated from the fitted model for each brain region. The PSTH of most neurons showed a characteristic choice preference that increased over time, consistent with accumulation. The model was able to capture this (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). The model provided an accurate account of mean responses in all three brain areas (<xref ref-type="fig" rid="fig2">Figure 2B</xref>), with a median <italic>R</italic><sup>2</sup> of 0.91, 0.68, and 0.87 for the FOF, PPC, and ADS, respectively (<xref ref-type="fig" rid="fig2">Figure 2B</xref>, colored lines). <xref ref-type="fig" rid="fig2">Figure 2C</xref> shows a comparison between true psychometric curves and the psychometric curve of the fitted model, confirming that the model also accounted for psychophysical choice behavior (<italic>R</italic><sup>2</sup>: 0.99—FOF; 0.99—PPC; ADS—0.97; see Methods for details). These analyses confirm that a shared accumulator model for each brain region is sufficient to capture the animals’ choice sensitivity to the stimulus and strength of accumulated evidence reflected in each neuron’s response.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>A shared accumulator model captures neural response and choice for each brain region.</title><p>(<bold>A</bold>) Peri-stimulus time histograms (PSTHs) of three example neurons for each brain region (each row; frontal orienting fields [FOF]: red/green, posterior parietal cortex [PPC]: blue/orange, anterior-dorsal striatum [ADS]: purple/yellow). Spike trains were binned, filtered with a Gaussian kernel (std = 50 ms), grouped based on the strength of evidence, and averaged. Transparent shaded regions are ±1 standard error of the mean for the empirical data for each grouping. Colored curves are the mean of synthetic data simulated from the model with the parameters that maximize the likelihood of the data, grouped in a similar fashion. The black curve shows the trial-averaged firing rate, for all evidence strengths. Gray vertical lines indicate the average delay between the stimulus and the response for each brain region (see Methods). (<bold>B</bold>) Coefficient of determination (<italic>R</italic><sup>2</sup>) between empirical PSTH and synthetic data PSTH, for each neuron in each brain region. The data are plotted as a function of average firing rate. The median across the population is shown as a line. Points indicated with a ‘star’ refer to the data plotted in (<bold>A</bold>). (<bold>C</bold>) Probability of making a rightward choice as a function of cumulative difference in the number of clicks (psychometric curves) for empirical data (black lines) and data simulated from the model with the best fitting parameters (colored curves; FOF: red, PPC: blue, ADS: purple). Each curve is the curve of best fit, as computed by logistic regression. Rectangles indicate 25-th and 75-th quantiles of the data.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84955-fig2-v3.tif"/></fig></sec><sec id="s2-3"><title>Different regions reflect different accumulator models, which all differ from model describing behavior</title><p>The primary motivation of our study was to learn accumulator models that incorporate precise stimulus-timing information and describe the animal’s choices and temporally structured neural activity. Previous efforts only modeled choices using stimulus-timing information (<xref ref-type="bibr" rid="bib12">Brunton et al., 2013</xref>) or modeled neural activity without choices for tasks without detailed stimulus-timing information (<xref ref-type="bibr" rid="bib31">Latimer et al., 2015</xref>; <xref ref-type="bibr" rid="bib55">Zoltowski et al., 2019</xref>). We refer to our model that describes both neural activity and choices as the ‘joint neural-behavioral model’ or the ‘joint model’. We compared the joint neural-behavioral model to a model where only the stimulus is used to model the animal’s choice (i.e., neural activity is not used). To fit such a ‘choice-only’ accumulator model, we fit the same latent variable model using only choice data (see Methods).</p><p><xref ref-type="fig" rid="fig3">Figure 3A</xref> shows the maximum likelihood parameters for the joint and choice-only accumulator models for each brain region. Neural data was not used for the choice model so brain region designates the cohort of animals from which the choice data was taken. We stress that because of this, each fitted choice model uses different behavioral choice data, and thus the fitted parameters vary from fitted model to fitted model. Both fitted models exhibited strong adaptation (<inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>&lt;&lt;</mml:mo><mml:mtext> </mml:mtext><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) consistent with prior work fitting choice accumulator models (<xref ref-type="bibr" rid="bib12">Brunton et al., 2013</xref>). This indicates that a stimulus pulse that occurs in rapid succession following other pulses has a smaller effect on <italic>a</italic>(<italic>t</italic>) than an isolated pulse. Each model was impacted by different forms of noise: choice models exhibited small diffusive noise <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and large stimulus noise (<inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;&gt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>), consistent with earlier findings, while joint models exhibited large diffusive noise <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and large initial variability in <italic>a</italic>(<italic>t</italic>) <inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;&gt;</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. The effect of these different parameters can be seen in <xref ref-type="fig" rid="fig3">Figure 3B</xref>: choice models have smaller initial variance and more variability when clicks arrive, while joint accumulator models have larger initial variance and diffusive noise. Large initial variance in the joint model likely reflects variability in neural responses prior to stimulus onset (<xref ref-type="bibr" rid="bib14">Churchland et al., 2010</xref>). Strong accumulation noise in the joint model was also found when the negative binomial distribution, a more flexible observation model, was used, suggesting that this finding was not sensitive to the Poisson observation model (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Differences in diffusive noise between the joint and choice-only models suggest that accumulation dynamics underlying neural activity is impacted by noise that is resolved at the level of a behavioral accumulator model.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Data from different regions is best fit by different accumulator models.</title><p>(<bold>A</bold>) Maximum likelihood parameters that govern <italic>a</italic>(<italic>t</italic>) for the joint neural-behavioral model and the choice-only model. Error bars, computed by the Laplace approximation (Methods), are ±2 standard deviations. Parameters are <italic>σ</italic><sub><italic>i</italic></sub>: initial variance, <italic>B</italic>: accumulation bound, <italic>λ</italic>: drift, <italic>σ</italic><sub><italic>a</italic></sub>: accumulation noise variance, <italic>σ</italic><sub><italic>s</italic></sub>: click noise variance, <italic>φ</italic>: adaptation strength, <italic>τ</italic><sub><italic>ɸ</italic></sub>: adaptation timescale. (<bold>B</bold>) 10 example trajectories with different noise instantiations for one trial for the choice model (top) and the joint model (middle) for each brain region, and cumulative sum of the click stimulus for each trial (bottom). The dotted black lines (top and middle) indicate the accumulation boundary value for each model.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84955-fig3-v3.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Model comparison using Poisson or negative binomial observation model.</title><p>(<bold>A</bold>) Parameters are <inline-formula><mml:math id="inf38"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>: initial variance, <italic>B</italic>: accumulation bound, <italic>λ</italic>: drift, <inline-formula><mml:math id="inf39"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>: accumulation noise variance, <inline-formula><mml:math id="inf40"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>: click noise variance, <italic>φ</italic>: adaptation strength, <inline-formula><mml:math id="inf41"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>: adaptation timescale. Each point is a data fold (1 of 5). Maximum likelihood parameters were similar for the two observation models. Cross-validated log-likelihood was statistically indistinguishable (frontal orienting fields [FOF]: p=0.99; posterior parietal cortex [PPC]: 0.93; anterior-dorsal striatum [ADS]: 0.98) and the average difference in cross-validated log-likelihood was small (FOF: 1.11e-5; PPC: –0.036; ADS: –0.035). (<bold>B</bold>) Histogram of the negative binomial dispersion parameter (<bold><italic>r</italic></bold>) across all neurons for each region. For large values of <italic>r</italic>, as seen here, the negative binomial approaches the Poisson distribution.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84955-fig3-figsupp1-v3.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Generalized linear model (GLM) analysis of individual sessions.</title><p>(<bold>A</bold>) Poisson GLM with a softplus nonlinearity was fit with exponentially filtered clicks as the regressors (see Methods), using the same data as in <xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="fig" rid="fig3">Figure 3</xref>. Each dot is the maximum likelihood drift (<italic>λ</italic>) parameter for a session. Sessions are ordered (from left to right) based on the fraction of the cumulative sum (across all sessions for a brain region) of the change in log-likelihood (LL) over the null model (see Methods for null model). For example, the leftmost dot for each brain region is the session with the largest change in LL. Dots on the right were from sessions with the smallest change in LL over the null. The colored lines are the cumulative mean of <italic>λ</italic> weighted by that session’s normalized change in LL. Dots on the far right have little change in LL and thus contribute to this mean only weakly. (<bold>B</bold>) GLM as in (<bold>A</bold>) but fit with a boundary, such that if the filtered clicks crossed a boundary <italic>B</italic>, the value of the regressors remained equal to <italic>B</italic> henceforth in a trial (see Methods). In each plot, the dashed colored lines are the values of <italic>λ</italic> from the full model fit (as in <xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="fig" rid="fig3">Figure 3</xref>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84955-fig3-figsupp2-v3.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Maximum likelihood parameters of joint model for each frontal orienting fields (FOF) rat individually.</title><p>Error bars, computed by the Laplace approximation (Methods), are ±2 standard deviations. Parameters are <inline-formula><mml:math id="inf42"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>: initial variance, <italic>B</italic>: accumulation bound, <italic>λ</italic>: drift, <inline-formula><mml:math id="inf43"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>: accumulation noise variance, <inline-formula><mml:math id="inf44"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>: click noise variance, <italic>φ</italic>: adaptation strength, <inline-formula><mml:math id="inf45"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>: adaptation timescale.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84955-fig3-figsupp3-v3.tif"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 4.</label><caption><title>Comparison of maximum likelihood parameters for three models: joint (neural/choice) model, choice-only model, and independent-noise joint model, when fit to all data, or using cross-validation data.</title><p>(<bold>A</bold>) Circles with error bars are for models fit to all data. Error bars for models fit to full data computed by the Laplace approximation (Methods) are ±2 standard deviations. ‘Plus (+) ’ marks are models (five for each model type) fit to cross-validation data (fivefold). Parameters are <inline-formula><mml:math id="inf46"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>: initial variance, <italic>B</italic>: accumulation bound, <italic>λ</italic>: drift, <inline-formula><mml:math id="inf47"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>: accumulation noise variance, <inline-formula><mml:math id="inf48"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>: click noise variance, <italic>φ</italic>: adaptation strength, <inline-formula><mml:math id="inf49"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>: adaptation timescale. (<bold>B</bold>) Test log-likelihood for models fit to all data (i.e., using trials reserved as testing trials when cross-validation is done) plotted against test log-likelihood for cross-validation models, for each model type (joint, choice, joint (ind.)), for all three brain regions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84955-fig3-figsupp4-v3.tif"/></fig></fig-group><p>We also compared the best-fit parameters across the three, separately fit, brain regions (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). We focus on one of the most salient differences—the leak or instability parameter <italic>λ</italic>. Although there was no significant difference in the value of <italic>λ</italic> across the cohorts of animals in the choice-only model, we found substantial differences across brain regions in the joint model fits (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). The PPC and ADS data were best fit by leaky accumulator models (<inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>). Surprisingly however, the FOF data was best described by a model with unstable accumulation dynamics (<inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) meaning that the model’s accumulator (and thus firing rates) are more strongly affected by early stimulus clicks. The stronger weighting of earlier clicks was compounded further by the low accumulation bound of the model that best described FOF data. Such a low bound, in conjunction with unstable accumulation, causes <italic>a</italic>(<italic>t</italic>) to stop evolving early in the trial (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). This results in a phenomenon known as ‘primacy encoding’, in which early clicks more strongly impact the animal’s choice while later clicks are ignored. We confirmed this finding in the FOF using a generalized linear model (GLM; see Methods and <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). This result is consistent with previous work suggesting that the FOF has a categorical representation of <italic>a</italic>(<italic>t</italic>) (<xref ref-type="bibr" rid="bib25">Hanks et al., 2015</xref>). We expand on these findings in light of other studies of the FOF in the Discussion. Collectively, these results indicate that all three brain regions were best described by accumulator models that differed in their best fitting parameters (and thus exhibit dramatically different accumulation dynamics), and that each region’s data was likewise best described by a model that differed from that which best described accumulation at the level of the animal’s choice.</p></sec><sec id="s2-4"><title>ADS is better described by multiple, independent accumulators</title><p>Our model describes the spiking activity of a population of simultaneously recorded neurons as relying on a single shared latent variable. To assess whether this is indeed the best description of the data, we compared it to an ‘independent-noise accumulator model’ where each neuron is driven by an accumulator with its own independent noise (<xref ref-type="fig" rid="fig4">Figure 4A</xref>; Methods). It is worth emphasizing that the independent-noise model is identical to the shared-noise model in the way it is parameterized (i.e., number and form of the model parameters) but only differs in the structure of the latent accumulation noise. If trial-to-trial spiking covariation is produced by temporal covariation in the accumulator due to noise, the independent-noise model (which does not share this covariation) should not account for the data as well, suggesting that correlations in the data can be attributed to correlated diffusive noise reflected in the shared model. We fit the parameters of the independent-noise model using the same optimization method but with a different log-likelihood function (see Methods). Because the independent-noise model contained multiple accumulators (one for each neuron), the animal’s choice was modeled differently than for the shared-noise model (see Methods). We focused on the FOF and ADS datasets because they contained a sufficient number of simultaneously recorded neurons to make this comparison (<xref ref-type="table" rid="table1">Table 1</xref>). The maximum likelihood parameters for the two models for both regions were similar (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>), except for the initial accumulator variance parameter which differed significantly.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Anterior-dorsal striatum (ADS) is better described by independent accumulators.</title><p>(<bold>A</bold>) For the shared-noise accumulator model (top), a set of parameters defines the dynamics of a single accumulator, which drives the spiking activity of the entire population. In the independent-noise accumulator model, a set of parameters defines the dynamics of an ensemble of independent accumulator models, which each individually determine the spiking of a single neuron. (<bold>B</bold>) Difference in test log-likelihood (bits/trial) for the shared-noise vs. independent-noise accumulator models. (<bold>C</bold>) Empirical (red) and synthetic (shared: black; independent; gray) shuffle-corrected cross-correlation function for three simultaneously recorded neurons from the frontal orienting fields (FOF). Corresponding peri-stimulus time histograms (PSTHs) are shown below for reference. (<bold>D</bold>) Same as (<bold>C</bold>) for three (of five) simultaneously recorded neurons from the ADS.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84955-fig4-v3.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Maximum likelihood parameters for the joint (neural/choice, i.e., shared-noise) model and independent (‘ind.’) noise joint model.</title><p>Error bars, computed by the Laplace approximation (Methods), are ±2 standard deviations. Parameters are <inline-formula><mml:math id="inf52"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>: initial variance, <italic>B</italic>: accumulation bound, <italic>λ</italic>: drift, <inline-formula><mml:math id="inf53"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>: accumulation noise variance, <inline-formula><mml:math id="inf54"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>: click noise variance, <italic>φ</italic>: adaptation strength, <inline-formula><mml:math id="inf55"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>: adaptation timescale.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84955-fig4-figsupp1-v3.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title><inline-formula><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> between the shared-noise and independent-noise accumulator model.</title><p>(<bold>A</bold>) Difference in log-likelihood for each session for frontal orienting fields (FOF) and anterior-dorsal striatum (ADS) data plotted as a function of the number of neurons in each session. (<bold>B</bold>) When the number of neurons in each session for the ADS dataset was subsampled to match the maximum number of neurons in an FOF session (three neurons) the ADS was still favored by an independent-noise accumulator model (purple, no fill; averaged across two subsample permutations of the ADS recordings). (<bold>C</bold>) Same as (<bold>A</bold>) but plotted as a function of dimension, as computed by the participation ratio (see Methods). Sessions in the ADS with higher dimension favored the independent-noise accumulator model, leading to the net effect seen in <xref ref-type="fig" rid="fig4">Figure 4B</xref>. (<bold>D</bold>) The difference in log-likelihood was similar when the choice data was omitted from both models.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84955-fig4-figsupp2-v3.tif"/></fig></fig-group><p>We used fivefold cross-validation to determine which model better described each dataset. Comparing the cross-validated log-likelihood, we found that the independent-noise model provided a better description of choices and neural activity from ADS, while the shared-noise model provided a slightly better description of FOF data (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). This finding supports the conclusion that neural responses within the ADS reflect independent accumulation processes, while neurons in the FOF reflect a single latent accumulator. Although ADS datasets with four or more neurons provided the primary contribution to these results (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2A</xref>), when the number of neurons in ADS datasets was subsampled to match the maximum number of neurons in FOF sessions (three neurons), the ADS recordings still favored an independent-noise accumulator model (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2B</xref>). We fit the shared-noise and independent-noise model to neural data only (excluding choice data) and found consistent results (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2D</xref>), suggesting this difference is not due to contributions from the animal’s choice, which was modeled differently in each model (see above).</p><p>To further examine this result, we computed the ‘shuffle-corrected’ cross-correlation function (Methods; <xref ref-type="bibr" rid="bib38">Perkel et al., 1967</xref>; <xref ref-type="bibr" rid="bib50">Smith and Kohn, 2008</xref>) for all pairs of simultaneously recorded neurons to examine spiking covariation in the empirical data and synthetic data from the fit models (<xref ref-type="fig" rid="fig4">Figure 4C and D</xref>). To shuffle-correct, we took the raw cross-correlation and subtracted the cross-correlation of the PSTHs of two neurons (for left and for right trials separately). This provides a measure of the neurons’ correlation beyond what is to be expected from the PSTHs (i.e., <xref ref-type="fig" rid="fig2">Figure 2A</xref>).</p><p>Synthetic data of both models captured trends in the shuffle-corrected cross-correlation function at slower timescales but failed to capture fluctuations on short timescales. Across all pairs of simultaneously recorded neurons (70 pairs in total), we found that the shared and independent-noise accumulator models provided approximately equally accurate fits to the shuffle-corrected cross-correlations (mean <italic>r</italic> of 0.55 for shared model and 0.57 for independent-noise model for FOF; 0.63 for shared model and 0.60 for independent-noise model for ADS). This shows that both models capture correlations in trial-to-trial neural responses beyond those accounted for by the PSTH. These correlations likely arise from trial-to-trial differences in the exact sequence of clicks, which are not reflected in the PSTH for left- or right-choice trials. Although FOF weakly favored a shared-noise model and ADS favored an independent-noise model (<xref ref-type="fig" rid="fig4">Figure 4B</xref>) the comparable ability for each model to capture the shuffle-corrected cross-correlation function for each region suggests that these correlations are primarily stimulus-induced and not a manifestation of non-stimulus-induced (i.e., ‘noise’) correlations, which are weak if present at all. Although these results suggest that each model fits the data equally well, the results of <xref ref-type="fig" rid="fig4">Figure 4B</xref> suggest that the independent-noise model may be accounting for intricate features of the ADS data not reflected in the shuffle-corrected cross-correlation function.</p><p>To validate that neural responses in the ADS weakly covary, as suggested by an independent-noise model, we computed a measure of response dimensionality known as the participation ratio (<xref ref-type="bibr" rid="bib33">Litwin-Kumar et al., 2017</xref>). The participation ratio is computed using the eigenvalues of the covariance matrix of firing rates (Methods). If all firing rates are independent the eigenvalues will all be equal and the participation ratio will equal the number of neurons. If the firing rates are correlated such that some eigenvalues are small (or perhaps zero) the participation ratio will reflect this and the dimensionality of the data will be less than the number of neurons. Consistent with our modeling results, we found that responses in ADS had higher dimensionality than in FOF (i.e., ADS exhibited less firing rate covariation) and that ADS sessions with greater dimensionality were those that favored the independent-noise model (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2C</xref>).</p></sec><sec id="s2-5"><title>Neural data provides more information about accumulated evidence than choice</title><p>Next we examined how neural data affected inferences about accumulated evidence. We computed the posterior distribution over the accumulator variable <italic>a</italic>(<italic>t</italic>) for the joint model, given choice data only, or given neural and choice data. The posterior distribution combines information from multiple sources—stimulus, choice, and neural activity—to offer a concise window into the animal’s internal state of evidence accumulation. <xref ref-type="fig" rid="fig5">Figure 5A</xref> shows the posterior distribution for three example trials (one for each brain region) when only choice data was included and when both choice and neural data were included. The choice data posterior was broad; a large set of <italic>a</italic>(<italic>t</italic>) trajectories were all consistent with the animal’s choice. However, when we considered both choice and neural spiking activity, we obtained a substantially narrower distribution over <italic>a</italic>(<italic>t</italic>), meaning including neural data in the joint model offers greater confidence in the precise value of accumulated evidence at each moment within a trial.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Neural data provides more information about accumulated evidence on single trials than choice alone.</title><p>(<bold>A</bold>) Posterior distribution of <italic>a</italic>(<italic>t</italic>) under the joint model (excluding captured mass at the boundary) given only the choice (top row) and given spike times and choice (bottom row), for a single example trial. Columns show example trials for different brain regions. (<bold>B</bold>) Histogram of joint model posterior standard deviations given choice data (<italic>black</italic>) or both neural and choice data (<italic>colors</italic>) for all three brain regions. (<bold>C</bold>) Difference in choice-conditioned joint posterior standard deviation and neural- and choice-conditioned joint posterior standard deviation as a function of the number of simultaneously recorded neurons. Each point is the difference in the average posterior standard deviation for a session. Negative values indicate that the neural- and choice-conditioned posterior had smaller average standard deviation than the choice-conditioned posterior.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84955-fig5-v3.tif"/></fig><p>To quantify this difference, we computed the standard deviation of the two posteriors (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). For all brain regions, the median posterior standard deviation given neural data and choice was substantially smaller than when conditioning only on choice (<xref ref-type="fig" rid="fig5">Figure 5B</xref>; median difference FOF: 0.46; PPC: 0.72; ADS: 2.23). This reduction in the posterior width increased with the number of neurons (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). The increased certainty about <italic>a</italic>(<italic>t</italic>) provided by neural activity makes intuitive sense: temporally specific spiking activity (e.g., in the middle of a trial) allows one to infer that <italic>a</italic>(<italic>t</italic>) has increased in favor of a choice, whereas choice information can only offer certainty about the range of <italic>a</italic>(<italic>t</italic>) at the end of the trial.</p></sec><sec id="s2-6"><title>Joint neural-behavioral model improves choice decoding</title><p>We designed our joint model with the expectation that combining choice data, neural responses, and stimulus information within an accumulation framework would lead to greater insight into decision-making than models that lacked these features. We tested this expectation by comparing choice decoding accuracy of the joint model on single trials to models that used stimulus information and only choice data or only neural data (see Methods). We found that choices could be predicted more accurately under the joint model, which took into account the stimulus, neural activity, and choices, than under the choice model, which used stimulus information and choices alone. We quantified this improvement in test log-likelihood and percent correct (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). The joint model had higher test log-likelihood for choice data and choice-prediction accuracy for all three brain regions, with the joint model of FOF data showing an almost 50% improvement in test log-likelihood and a 6% increase in prediction accuracy. The posterior mean of the joint model and the posterior mean of the choice model is shown in <xref ref-type="fig" rid="fig6">Figure 6B</xref> for three example trials. In all examples, the joint model correctly predicted the choice the animal made (indicated by the arrow), whereas the choice-only model failed because its prediction was based on the stimulus. This increased performance derives from the choice-informative spiking information contained in the posterior (<xref ref-type="fig" rid="fig5">Figure 5</xref>) that the choice model lacks.</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Joint neural-behavioral model improves choice decoding.</title><p>(<bold>A</bold>) Choice-prediction accuracy, quantified with log-likelihood (left) and percent correct (right) on test choice data for four models: joint neural-behavioral model, choice-only model, and two logistic regression models (Methods). Values greater than zero indicate that the model can predict choices better than a baseline model that only knows the marginal probability of a rightward choice. (<bold>B</bold>) Posterior mean of <italic>a</italic>(<italic>t</italic>) conditioned on the neural activity for the joint model (colors), the distribution of <italic>a</italic>(<italic>t</italic>) for the choice-only model (black), and the cumulative click difference (gray) for three example trials (one for each brain region). ‘Animal’s choice’ arrow indicates the choice (left or right) the animal made on that trial. (<bold>C</bold>) Putative change of mind events, where the posterior mean of the joint model crossed the decision threshold. The corresponding distribution of <italic>a</italic>(<italic>t</italic>) for the choice-only model (black) and the cumulative click difference (gray) for the same trial are shown for comparison. ‘Animal’s choice’ arrow indicates the choice (left or right) the animal made on that trial. (<bold>D</bold>) Fraction of trials that contain at least one putative change of mind event for the cumulative click difference, the choice model, and the joint model, for each brain region. (<bold>E</bold>) Fraction of trials for which a putative change of mind event occurs at the specified time relative to the end of the stimulus for the joint model (color) and the cumulative click difference (black) for each brain region. (<bold>F</bold>) Choice response latency as a function of timing of putative change of mind events relative to stimulus offset for each brain region. Bar plots show the 25–75 percentiles of the choice response latency for putative change of mind events occurring at similar times. The colored lines indicate the line of best fit for each brain region computed by linear regression.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84955-fig6-v3.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Generalized linear model (GLM) choice decoding (as in <xref ref-type="fig" rid="fig6">Figure 6A</xref>) using spikes in different time windows relative to stimulus offset.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84955-fig6-figsupp1-v3.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 2.</label><caption><title>Accuracy on putative change of mind event trials and non-event trials.</title><p>(<bold>A</bold>) Accuracy of the rat for data from each brain region for putative change of mind event trials and trials that lacked events (‘no event’). (<bold>B</bold>) Same as (<bold>A</bold>) but for accuracy of the joint model for each brain region.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84955-fig6-figsupp2-v3.tif"/></fig></fig-group><p>If neural activity is highly correlated with the motor report (e.g., activity from motor neurons controlling orientation), we would expect the neural activity to be a good predictor of the animal’s choice. In such a case, a model that predicted choice without the framework of the DDM accumulator but using neural activity would have high accuracy. We compared our accumulator-based joint model to a logistic regression model (i.e., Bernoulli GLM) which used the final accumulated click difference and the trial-summed spike count for each neuron as regressors (Methods). Decoding under the joint accumulator model significantly outperformed logistic regression (<xref ref-type="fig" rid="fig6">Figure 6A</xref>, <italic>GLM</italic>). The performance of the GLM did not depend strongly on the time window considered: decoding of choice using spikes from the last 50 ms (<xref ref-type="fig" rid="fig6">Figure 6A</xref>, <italic>GLM</italic> 50 ms), 100 ms, 150 ms, 200 ms, and 250 ms before a decision all performed similarly (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). This shows that the joint accumulation framework and the fine timescale dynamics of the joint model captures features of the spike trains that are useful for predicting the animal’s choice, above and beyond the information carried by spike counts in particular time windows before the choice.</p></sec><sec id="s2-7"><title>Putative changes of mind are common in ADS, rare in FOF</title><p>The previous analysis illustrated how the joint accumulation framework, combined with temporally precise neural responses, can accurately predict animal choices. Numerous studies have shown that subjects making decisions based on noisy stimuli will vacillate before reporting a decision (<xref ref-type="bibr" rid="bib28">Kaufman et al., 2015</xref>; <xref ref-type="bibr" rid="bib29">Kiani et al., 2014</xref>; <xref ref-type="bibr" rid="bib44">Resulaj et al., 2009</xref>). Switches of a subject’s provisional decision have been referred to as ‘changes of mind’ (<xref ref-type="bibr" rid="bib8">Boyd-Meredith et al., 2022</xref>; <xref ref-type="bibr" rid="bib37">Peixoto et al., 2021</xref>). We used our joint accumulator model to identify putative changes of mind from our neural recordings, to examine how decision commitment is manifested in different brain regions. We examined the temporal dynamics of the joint model posterior, conditioned on neural activity only, to find putative changes of mind: moments when posterior mean crossed from one side of the decision threshold to the other. We required that the conditioned posterior mean remained on one side of the decision threshold for at least 50 ms before and after the crossing and achieved an absolute magnitude greater than 2 during that 100 ms window (see Methods).</p><p><xref ref-type="fig" rid="fig6">Figure 6C</xref> shows three example putative change of mind trials. We also plot the posterior mean of the choice model (black) and the cumulative click difference (gray) for comparison. In all three examples, the joint model posterior mean crossed the decision threshold, ending on the side corresponding to the animal’s choice. Sign changes in the cumulative click difference were rare, as were putative change of mind events under the choice-only model, both of which could only be caused by the stimulus (<xref ref-type="fig" rid="fig6">Figure 6D</xref>). In contrast, putative change of mind events were observed frequently under the joint model for all three brain regions (<xref ref-type="fig" rid="fig6">Figure 6D</xref>). This shows that putative change of mind events reflect information about the accumulator carried in neural activity. Putative change of mind events were observed least frequently in the FOF and most frequently in the ADS (<xref ref-type="fig" rid="fig6">Figure 6D</xref>); compounded by our initial finding, that different brain regions are best fit by different accumulator models (<xref ref-type="fig" rid="fig3">Figure 3</xref>), these results further support the view that the decision-making dynamics in each brain region are fundamentally and consequentially different.</p><p>The animal’s performance improved on putative change of mind event trials (fraction correct: FOF: 0.88 vs 0.74; PPC: 0.87 vs 0.74; ADS: 0.85 vs 0.76; <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2A</xref>) and the choice prediction of the joint model was also more accurate (fraction correct: FOF: 0.92 vs 0.80; PPC: 0.88 vs 0.77; ADS: 0.88 vs 0.78; <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2B</xref>), suggesting that the decision-making dynamics that give rise to these events primarily correct incorrect decision-making dynamics early within a trial. Initial variability in the accumulation dynamics, as reflected in neural responses, was found to be greater in both PPC and ADS (<xref ref-type="fig" rid="fig3">Figure 3A</xref>), regions for which putative changes of mind were more likely (<xref ref-type="fig" rid="fig6">Figure 6D</xref>), consistent with this assumption. Furthermore, putative change of mind events were more likely to occur at later moments in the trial, usually not long before the stimulus ended (<xref ref-type="fig" rid="fig6">Figure 6E</xref>), consistent with the assumption that they generally correct incorrect early-trial dynamics. To more firmly connect putative change of mind events to the animal’s behavior, we performed linear regression to compare the time of the event relative to the end of the stimulus to the response latency (<xref ref-type="fig" rid="fig6">Figure 6F</xref>). We found a statistically significant effect for the PPC and the ADS (PPC: p&lt;0.003; ADS: p&lt;0.0008; two-sided t-test), which both showed a slower response time when a change of mind event occurred closer to the end of the stimulus. These results illustrate the potential of our framework for uncovering putative covert changes of mind within neural activity, and demonstrate the varying way in which decision-making dynamics—both prior to stimulus onset and during the stimulus period—differ in different brain regions.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We developed a probabilistic latent process model to simultaneously describe neural activity and choices during an evidence accumulation decision-making task. We fit the model to data from three brain regions and found that the dynamics of accumulation that best-fit choices and neural data from each brain region differed significantly across brain regions, and from the accumulation model that best described the animal’s choices. We found that including neural activity in the model provided rich, moment-by-moment information about the animal’s choice. The inferred accumulation model could be used to examine estimates of the animal’s moment-by-moment provisional choice, and by doing so, we found differing choice-related dynamics in each brain region, dynamics that meaningfully related to other measures of behavior such as reaction time. Collectively, our results argue for the existence of very different accumulation dynamics in different brain regions, dynamics which each differ greatly from the dynamics giving rise to behavior. An exciting future application of our modeling framework is to model multiple, independent accumulators in several brain regions which collectively give rise to the animal’s behavior. Such a model would provide incredible insight into how the brain collectively gives rise to behavioral choices.</p><p>There has been substantial work relating neural activity to evidence accumulation. The logic underlying this work (e.g., <xref ref-type="bibr" rid="bib15">Churchland et al., 2011</xref>; <xref ref-type="bibr" rid="bib24">Gold and Shadlen, 2007</xref>; <xref ref-type="bibr" rid="bib25">Hanks et al., 2015</xref>; <xref ref-type="bibr" rid="bib35">Mante et al., 2013</xref>; <xref ref-type="bibr" rid="bib41">Ratcliff et al., 2003</xref>; <xref ref-type="bibr" rid="bib54">Yartsev et al., 2018</xref>) is that behavior is well approximated by gradual evidence accumulation (<xref ref-type="bibr" rid="bib42">Ratcliff and McKoon, 2008</xref>). Numerous studies have probed whether neurons in any given brain are involved in encoding or computing a correlate of this behavior-level evidence accumulation. A rarely emphasized assumption is that the accumulation process, at the level of individual brain regions, will be similar to the accumulation process at the level of the organism’s behavior. This assumption need not be correct. As in the example mentioned in the Introduction, two brain regions, one representing a leaky accumulator from which recent evidence is best decoded, and another representing an unstable accumulator from which the earliest evidence is best decoded, could combine to generate behavior that is well described by stable evidence accumulation, in which evidence from throughout behavioral trials is weighted approximately equally. One should not conclude that neural activity best explained by a leaky or by an unstable accumulator is unrelated to behavior that is best explained by stable accumulation. Other properties, in addition to leakiness/instability, may also differ across contributing brain regions. Developing a formal approach to fit the parameters of evidence accumulation models from neural data as well as from choices provided us with the opportunity to probe this assumption. Our results suggest that it is <italic>not</italic> correct. Elucidating the neural basis of evidence accumulation for decision-making may require understanding how brain regions with neural activity that appears driven by accumulators with potentially very different properties combine, and perhaps counterbalance each other, so as to produce the organism’s behavior.</p><p>Our approach extends and complements existing approaches that construct formal mathematical models of decision-making which combine both behavioral data and neural data. These models leverage both neural and behavioral observations to jointly infer decision-making parameters, as we’ve done here (see <xref ref-type="bibr" rid="bib52">Turner et al., 2019</xref> for a comprehensive overview). However, the majority of these approaches have tended to emerge from the field of cognitive neuroscience, and as such, have predominantly focused on models for application to neural data acquired by other methods, such as EEG, fMRI, etc. (e.g., <xref ref-type="bibr" rid="bib51">Turner et al., 2015</xref>; but also see <xref ref-type="bibr" rid="bib21">Frank et al., 2015</xref>). Our approach adds to these efforts by offering a method that can combine fine timescale single-unit recordings with behavioral measurements specifically during pulse-based evidence accumulation tasks, thereby offering a moment-by-moment picture into the latent dynamics that underlies cognition. Continued development of joint models such as our approach and existing approaches in the field of cognitive neuroscience are critical to quantitatively understand the latent processes underlying cognition.</p><p>One of our most surprising discoveries was that neural data from the FOF was best modeled by an accumulator consistent with a ‘primacy’ strategy in which early stimulus clicks have an outsize impact on neural activity and choice compared to later clicks. Coupled with the low accumulation bound of the model fit to the FOF, our analysis suggests a model of FOF accumulation where a subject prematurely commits to a decision based on early sensory evidence. Previous analysis of these data did not find that FOF activity was described by an unstable accumulator because the accumulator model was not learned from neural activity, only choices (<xref ref-type="bibr" rid="bib25">Hanks et al., 2015</xref>). This prior analysis identified an alternative interpretation of FOF activity: FOF activity exhibited a step-like encoding of accumulated evidence that was unbounded, consistent with the FOF encoding a categorical representation of choice (<xref ref-type="bibr" rid="bib25">Hanks et al., 2015</xref>). At a strategic level, this interpretation is consistent with the model of FOF activity we identified. Noting that, in this task, the stimulus will rarely cause the accumulator to switch sign (<xref ref-type="fig" rid="fig6">Figure 6D</xref>), a step-like encoding of an unbounded accumulator that does not switch sign will appear very much like an bounded accumulator: for either model, the accumulator will quickly jump to its largest value and remain there. Additional experiments and modeling are required to differentiate these two models.</p><p>A primacy encoding model of the FOF is supported by our change of mind analysis. Putative change of mind events identified from neural activity occurred less frequently in the FOF than other regions (p&lt;4.5694e-82 FOF vs. PPC; p&lt;3.4585e-323 FOF vs. ADS; Fisher’s exact test) consistent with an early-commitment strategy in the FOF. A recent study of the FOF during an accumulation task in which evidence dynamically changed throughout a trial found that FOF activity reflected evidence across stimulus-induced ‘overt’ changes of mind, and that these events were common in the FOF (<xref ref-type="bibr" rid="bib8">Boyd-Meredith et al., 2022</xref>). It’s important to note that we likewise found that FOF reflects evidence across changes of mind, but we identified rarely occurring non-stimulus-induced ‘covert’ changes of mind during a task in which the evidence was static, and thus our results do not conflict with those findings.</p><p>A primacy encoding model of the FOF is also both supported by and offers context to prior FOF inactivation studies (<xref ref-type="bibr" rid="bib20">Erlich et al., 2015</xref>). Behavioral modeling of choices in conjunction with bilateral pharmacological inactivation found that FOF inactivation led to leakier accumulation when producing choices (<xref ref-type="bibr" rid="bib20">Erlich et al., 2015</xref>). Leakier accumulation at the level of choice also implies that later stimulus information disproportionately impacts choice, precisely the impact predicted if an early stimulus favoring brain region, such as the FOF, was silenced. A more complete model relating accumulation dynamics in multiple brain regions to choice-related accumulation dynamics at the level of behavior would aid in understanding how silencing individual brain regions, with their region-specific accumulation dynamics, impacts accumulation at the level of behavior.</p><p>Our novel change of mind analysis identified both the ADS and PPC as regions that showed frequent instances of choice vacillation during this task. Prior studies in related tasks found that neural responses in one of these regions, the PPC (or its primate homolog), reflect information related to already experienced trials (<xref ref-type="bibr" rid="bib2">Akrami et al., 2018</xref>; <xref ref-type="bibr" rid="bib39">Purcell and Kiani, 2016</xref>), consistent with our interpretation of prestimulus neural responses being suboptimally tuned for the upcoming trial and thus requiring mid-trial correction. Given the large initial accumulator variance of ADS and the presence of frequent putative change of mind events in this region, activity in ADS seems poised to also reflect these types of trial history-dependent responses as well. Future experiments and analysis are required to determine this.</p><p>Previous studies that fit this model to only choices developed specific interpretations of the accumulation strategy used by animals (<xref ref-type="bibr" rid="bib12">Brunton et al., 2013</xref>). One difference between choice accumulator models and joint neural-behavior models is the differential impact of accumulator noise vs. stimulus noise. Choice-only models have typically indicated that stimulus noise is the primary cause of systematic behavioral uncertainty (<xref ref-type="bibr" rid="bib12">Brunton et al., 2013</xref>), whereas our joint models suggest that this impact is weaker than diffusion noise. One interpretation of this difference is that at the level of a single neural population, diffusive noise plays a stronger role in producing uncertainty in <italic>a</italic>(<italic>t</italic>) than stimulus noise, whereas at the level of the entire brain’s encoding of accumulated evidence, this diffusive noise ‘averages out’ and residual stimulus noise remains. Understanding how multiple brain regions work together to produce a model of accumulated evidence at the level of behavior is an important future direction of this work.</p><p>Several extensions of our framework are readily apparent. Increasing the number of recorded neurons led to an improved estimate of <italic>a</italic>(<italic>t</italic>). As the density of neural recordings increases (<xref ref-type="bibr" rid="bib34">Luo et al., 2020</xref>), the explanatory power of our model will increase. Although we have extended the evidence accumulation model to include neural responses and choice, we could extend it further to describe additional physiological or behavioral variables (e.g., from annotated video data, pupil-dilation measurements, response time, etc.). Including these additional behavioral measures would further inform the inferred accumulator model, providing a clearer window into the internal factors governing choices. Although we considered a specific evidence accumulation model due to its normative interpretation, our framework can readily accept modifications and extensions of its dynamical equations (e.g., <xref ref-type="bibr" rid="bib22">Genkin et al., 2021</xref>). More sophisticated (e.g., nonlinear) dynamics of accumulated evidence or more refined models of accumulation noise are two examples. Our framework can also accommodate more elaborate and/or appropriate relationships between accumulated evidence and neural responses, as we briefly explored by considering the negative binomial distribution (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Changing this relationship would open the door to using this approach with other types of data, such as imaging data. Although our framework was developed with the specific application to a pulse-based accumulation task in mind, it is not confined to this. Our framework can be adapted to any task where noisy temporal accumulation of evidence is thought to play a role, and for which neural recordings and behavioral choices reflect this process (<xref ref-type="bibr" rid="bib1">Aguillon-Rodriguez et al., 2021</xref>). Finally, while a major motivation of our approach was to develop a framework for identifying a specific normative and mechanistic accumulation model, its rigidity makes it difficult to capture varying features present in the data. Extending the model to include additional latent processes alongside a rigid accumulation model (<xref ref-type="bibr" rid="bib56">Zoltowski et al., 2020</xref>) would enable the model to simultaneously account for currently unexplained variance in the data while preserving the model’s ability to account for variance with an accumulation model. Doing so may offer a clearer picture of the evidence accumulation process by sweeping away unrelated variance with a more flexible, but less interpretable, latent process model.</p></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Latent variable model</title><p>We model accumulated evidence as a one-dimensional DDM with a symmetric absorbing boundary (<xref ref-type="bibr" rid="bib12">Brunton et al., 2013</xref>). On a single behavioral trial, the evolution of the accumulated evidence, <italic>a</italic>(<italic>t</italic>), is governed by<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mi>W</mml:mi><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>η</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf57"><mml:mi>λ</mml:mi></mml:math></inline-formula> is the inverse of the drift time constant. <inline-formula><mml:math id="inf58"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mi>W</mml:mi></mml:math></inline-formula> is a Wiener process with scaling <inline-formula><mml:math id="inf59"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. <inline-formula><mml:math id="inf60"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>`</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> are Gaussian variables with variance <inline-formula><mml:math id="inf61"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> and mean 1. <inline-formula><mml:math id="inf62"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf63"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula> are the timing of left and right pulses, respectively, and <inline-formula><mml:math id="inf64"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> and <inline-formula><mml:math id="inf65"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> are the magnitude that each left or right click, respectively, has at time <italic>t</italic>. The impact of each click is modulated by sensory adaptation, based on the following equation:<disp-formula id="equ5">, <label>(5)</label><mml:math id="m5"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>α</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf66"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>L</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo>}</mml:mo></mml:math></inline-formula>. We define the difference of the adapted click magnitude at time <italic>t</italic> as <inline-formula><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and the sum of the adapted click magnitude at time <italic>t</italic> as <inline-formula><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. By doing so, we can express <xref ref-type="disp-formula" rid="equ4">Equation 4</xref> as:<disp-formula id="equ6">, <label>(6)</label><mml:math id="m6"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mi>d</mml:mi><mml:mi>W</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>η</mml:mi><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf69"><mml:mi>η</mml:mi></mml:math></inline-formula> is a standard Normal. An absorbing boundary, <italic>B</italic>, if crossed, prevents <italic>a(t</italic>) from evolving further (i.e. <italic>da</italic> = 0 if <italic>a(t</italic>)&gt;<italic>B</italic>). The initial state of <italic>a</italic>(<italic>t</italic>) is distributed normally with mean 0 and variance <inline-formula><mml:math id="inf70"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>. We refer to all parameters that govern the dynamics of <italic>a</italic>(<italic>t</italic>) as <inline-formula><mml:math id="inf71"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></sec><sec id="s4-2"><title>Computing the distribution of the latent state</title><p>The temporal dynamics of the probability distribution of <italic>a</italic>(<italic>t</italic>), P(<italic>a</italic>(<italic>t</italic>)), can be expressed as a Fokker-Planck equation,<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mfrac><mml:mrow><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msup><mml:mi>a</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mi>a</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>We numerically compute the solution to <xref ref-type="disp-formula" rid="equ7">Equation 7</xref> by dividing <inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> into a set of <italic>n</italic> discrete spatial bins, and determine how mass moves after a discrete temporal interval, <inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. The discrete time dynamics of <inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> are Markov, and obey the following equation:<disp-formula id="equ8">, <label>(8)</label><mml:math id="m8"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>M</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf75"><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the collection of left and right clicks at time <italic>t</italic>. The transition matrix <inline-formula><mml:math id="inf76"><mml:mi>M</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> is determined using methods established in <xref ref-type="bibr" rid="bib12">Brunton et al., 2013</xref>. Briefly, for each spatial bin, the deterministic effect of the dynamics on the probability mass is computed, and this is convolved with a discrete approximation to a Gaussian distribution with the appropriate variance and a finer spatial resolution than the initial spatial resolution described above, to determine the various locations of that probability mass at the next time bin. Because the location of each bin of mass after the Gaussian convolution is not likely to correspond to the spatial grid defined for <inline-formula><mml:math id="inf77"><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula>, the mass is ‘settled’ into appropriate bins based on the distance of each bit of mass and the nearest two bins. Mass located in the first and last bin, corresponding to mass that has been captured by the boundary, cannot change locations, and the entries of <inline-formula><mml:math id="inf78"><mml:mi>M</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>δ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> that determines how the mass in these bins moves reflects this. <italic>n</italic>=53 and <inline-formula><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> = 10 ms for all results presented here.</p></sec><sec id="s4-3"><title>Relating <italic>a</italic>(<italic>t</italic>) to spikes and choices</title><p>On a single behavioral trial, the observed spike count of the <italic>n-</italic>th neuron at time <italic>t</italic>, <inline-formula><mml:math id="inf80"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, is a Poisson random variable,<disp-formula id="equ9">, <label>(9)</label><mml:math id="m9"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf81"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> defines the expected firing rate function <italic>f</italic> for the <italic>n-</italic>th neuron. We choose <inline-formula><mml:math id="inf82"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula> to be a softplus function, i.e., softplus(<italic>x</italic>)=log(1+exp(<italic>x</italic>)). Each neuron has their own parameter <inline-formula><mml:math id="inf83"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> that relates <inline-formula><mml:math id="inf84"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math></inline-formula> to <inline-formula><mml:math id="inf85"><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. <inline-formula><mml:math id="inf86"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:math></inline-formula> is the collection of all neural parameters for the population of <italic>N</italic> neurons.</p><p>We define <inline-formula><mml:math id="inf87"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> as<disp-formula id="equ10">, <label>(10)</label><mml:math id="m10"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf88"><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> accounts for the time-varying trial-average (i.e., invariant to <italic>a</italic>(<italic>t</italic>)) firing rate of the <italic>n-</italic>th neuron. <inline-formula><mml:math id="inf89"><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is learned prior to fitting the full model, i.e., before learning <inline-formula><mml:math id="inf90"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf91"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. We approximate <inline-formula><mml:math id="inf92"><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> with a set of six Gaussian radial basis functions<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>6</mml:mn></mml:mrow></mml:munderover><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>B</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msubsup><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>B</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>The mean of the functions, <inline-formula><mml:math id="inf93"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, are spaced uniformly from time 0 to the maximum trial length for each respective neuron. The variance of the functions, <inline-formula><mml:math id="inf94"><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>B</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, is equal to the distance between the function means. We learn <inline-formula><mml:math id="inf95"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>B</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> by assuming that <inline-formula><mml:math id="inf96"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is distributed Poisson with an intensity function <inline-formula><mml:math id="inf97"><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and maximize the likelihood. In other words, for the <italic>n-</italic>th neuron we define the likelihood of the observed spikes for a trial of duration <italic>T</italic>, <inline-formula><mml:math id="inf98"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, assuming a time-varying intensity function <inline-formula><mml:math id="inf99"><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula><disp-formula id="equ12">, <label>(12)</label><mml:math id="m12"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>and maximize this likelihood across <italic>K</italic> trials with respect to the parameters <inline-formula><mml:math id="inf100"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mi>B</mml:mi><mml:mi>F</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula>.</p><p>Although both <inline-formula><mml:math id="inf101"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>a</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> and <inline-formula><mml:math id="inf102"><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> vary in time to define each neuron’s expected firing rate, they are uniquely identifiable, because <inline-formula><mml:math id="inf103"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>a</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> varies from trial to trial depending on the stimulus while <inline-formula><mml:math id="inf104"><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> does not. We verified through numerical experimentation and parameter recovery using synthetic data that each process can be identified.</p><p>On a single behavioral trial, with a probability <inline-formula><mml:math id="inf105"><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>γ</mml:mi></mml:math></inline-formula> the subject’s choice, <italic>d</italic>, is a deterministic function of <italic>a</italic>(<italic>t</italic>) at the end of the trial (time <italic>T</italic>), (<xref ref-type="bibr" rid="bib12">Brunton et al., 2013</xref>); with probability <inline-formula><mml:math id="inf106"><mml:mi>γ</mml:mi></mml:math></inline-formula> the choice is made without considering <italic>a</italic>(<italic>t</italic>). <inline-formula><mml:math id="inf107"><mml:mi>γ</mml:mi></mml:math></inline-formula> captures ‘lapses’ in the subject’s performance. For choices that depend on <italic>a</italic>(<italic>t</italic>), if <italic>a</italic>(<italic>T</italic>) is greater than a cutoff value <italic>c</italic>, <italic>d</italic>=1, otherwise <italic>d</italic>=0. Thus, the probability of the choice, given <italic>a</italic>(<italic>t</italic>) and <inline-formula><mml:math id="inf108"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, can be written as:,<disp-formula id="equ13">, <label>(13)</label><mml:math id="m13"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>γ</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>γ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mi>γ</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>γ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf109"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is the Heaviside function. We refer to the parameters relating <italic>a</italic>(<italic>t</italic>) to the likelihood of a subject’s choice as <inline-formula><mml:math id="inf110"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo>}</mml:mo></mml:math></inline-formula>.</p></sec><sec id="s4-4"><title>Relative binning of clicks and spikes</title><p>A minor but key implementation detail concerns defining the start and end times of the temporal bin edges that are used to bin the click inputs and the spikes trains. Through numerical experimentation, we identified that our numerical procedure produces a systematic error in estimating the model parameters when the temporal bins for the clicks are aligned with the temporal bins for the spikes. To circumvent this issue, we offset the bins for the spikes by <inline-formula><mml:math id="inf111"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, so that the bin edges for spikes at time <italic>t</italic> surround the forward bin edge of the clicks by ±<inline-formula><mml:math id="inf112"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. This procedure is similar to the central difference formulation of a finite difference approximation to a differential equation.</p></sec><sec id="s4-5"><title>Inferring model parameters with maximum likelihood</title><p>We refer to the set of all parameters for models fit to spikes and choices as <inline-formula><mml:math id="inf113"><mml:msub><mml:mrow><mml:mi>Θ</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:math></inline-formula>. Given the Markov dynamics described above, the relationship between <italic>a</italic>(<italic>t</italic>) and the observed data, and the model parameters, we can write out the likelihood of the spike train data <italic>Y</italic> from <italic>N</italic> neurons for <italic>T</italic> time bins, the behavioral choice <italic>d</italic>, and the latent variable <italic>a</italic> for <italic>T</italic> time bins as:<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:munderover><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>We compute the likelihood of the data by integrating over <italic>a</italic><disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:munder><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Because of the way in which we compute <inline-formula><mml:math id="inf114"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> (see above) computing the log-likelihood of the data can be done with a single forward pass over the data using the ‘forward-backward’ algorithm method for hidden Markov models (<xref ref-type="bibr" rid="bib5">Bishop, 2006</xref>). We maximize the sum over <italic>K</italic> behavioral trials of the logarithm of this quantity with respect to <inline-formula><mml:math id="inf115"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> via gradient ascent. To compute the gradient of <inline-formula><mml:math id="inf116"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mi>k</mml:mi><mml:mrow><mml:mi>K</mml:mi></mml:mrow></mml:munderover><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> with respect to Θ, we use a standard automatic differentiation package (<xref ref-type="bibr" rid="bib45">Revels et al., 2016</xref>). We refer to the set of parameters that maximizes the likelihood as <inline-formula><mml:math id="inf117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p><p>We note that all <italic>K</italic> trials for many of the models we fit were not recorded on the same behavioral session, and therefore, all <italic>N</italic> neurons are not recorded for every trial. For example, neurons 1–3 might be recorded on trials 1–500, while neurons 4–6 might be recorded on trials 501–1000. Although our notation does not reflect this in order to keep the notation simple, only neurons recorded on a trial contribute to the likelihood on that trial.</p></sec><sec id="s4-6"><title>Bounded optimization</title><p>Several model parameters are only defined within a restricted domain; for example, all variances parameters, such as <inline-formula><mml:math id="inf118"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula>, are only defined on the positive real axis. Alternatively, other parameters, although defined on a more expansive domain, have values that correspond to models that are not very likely; for example, although <italic>B</italic> is defined on the positive real axis, values much greater than 40 are not likely to be exhibited in the data, given the specifics of the stimulus, where greater than 40 clicks were rare. For these reasons, we define the following domain over which parameter optimization was performed:</p><list list-type="bullet" id="list1"><list-item><p><inline-formula><mml:math id="inf119"><mml:mn>1</mml:mn><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo>≤</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>≤</mml:mo><mml:mn>100</mml:mn></mml:math></inline-formula></p></list-item><list-item><p><inline-formula><mml:math id="inf120"><mml:mn>8</mml:mn><mml:mo>≤</mml:mo><mml:mi>B</mml:mi><mml:mo>≤</mml:mo><mml:mn>40</mml:mn></mml:math></inline-formula></p></list-item><list-item><p><inline-formula><mml:math id="inf121"><mml:mo>-</mml:mo><mml:mn>5</mml:mn><mml:mo>≤</mml:mo><mml:mi>λ</mml:mi><mml:mo>≤</mml:mo><mml:mn>5</mml:mn></mml:math></inline-formula></p></list-item><list-item><p><inline-formula><mml:math id="inf122"><mml:mn>1</mml:mn><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo>≤</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>≤</mml:mo><mml:mn>400</mml:mn></mml:math></inline-formula></p></list-item><list-item><p><inline-formula><mml:math id="inf123"><mml:mn>1</mml:mn><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo>≤</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>≤</mml:mo><mml:mn>10</mml:mn></mml:math></inline-formula></p></list-item><list-item><p><inline-formula><mml:math id="inf124"><mml:mn>1</mml:mn><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo>≤</mml:mo><mml:mi>ϕ</mml:mi><mml:mo>≤</mml:mo><mml:mn>1.2</mml:mn></mml:math></inline-formula></p></list-item><list-item><p><inline-formula><mml:math id="inf125"><mml:mn>5</mml:mn><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo>≤</mml:mo><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula></p></list-item><list-item><p><inline-formula><mml:math id="inf126"><mml:mo>-</mml:mo><mml:mn>10</mml:mn><mml:mo>≤</mml:mo><mml:mi>c</mml:mi><mml:mo>≤</mml:mo><mml:mn>10</mml:mn></mml:math></inline-formula></p></list-item><list-item><p><inline-formula><mml:math id="inf127"><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mi>γ</mml:mi><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula></p></list-item><list-item><p><inline-formula><mml:math id="inf128"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:mn>10</mml:mn><mml:mo>≤</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:mn>10</mml:mn><mml:mi mathvariant="normal">∀</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></p></list-item></list><p>The occurrence of parameters hitting the bound can be seen in <xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>. The most common boundary hitting situation was a variance parameter (<inline-formula><mml:math id="inf129"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf130"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf131"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) hitting the lower boundary of zero, which means that the model did not support noise of that kind in the model fit. <inline-formula><mml:math id="inf132"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf133"><mml:msub><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> were found to do this for the choice-only model, consistent with the results of Brunton et al. The other bound that was frequently hit was the upper bound for the accumulation bound parameter <italic>B</italic>, a result also consistent with the results of Brunton et al. The log-likelihood surface as <italic>B</italic> grows very large becomes very flat, because it becomes increasingly unlikely that probability mass <inline-formula><mml:math id="inf134"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> crosses the boundary. Thus, the model fits do not change appreciably if this optimization boundary is relaxed.</p></sec><sec id="s4-7"><title>Confidence intervals for maximum likelihood parameters</title><p>To compute confidence bounds of estimated parameters (as in <xref ref-type="fig" rid="fig3">Figure 3</xref> and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>, <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>), we use the Laplace approximation to the log-likelihood. Using automatic differentiation, we compute the Hessian (the matrix of second derivatives) of the log-likelihood at the maximum likelihood parameters. The diagonal entries of the Hessian’s inverse quantify the sharpness of the curvature of the log-likelihood surface, and therefore the uncertainty of the estimate of each parameter. We define the confidence bound as ±2 times the square root of each diagonal entry; approximating the log-likelihood surface as Gaussian, this describes the range of parameters that would fall within approximately 95% of the log-likelihood volume.</p><p>For some sets of maximum likelihood parameters, further consideration was necessary. In cases where confidence bounds extend beyond an optimization bound that corresponds to a strict boundary on the domain of a parameter (e.g., variance parameters being strictly positive), we truncate these intervals at the bound. In some cases, we found that Hessian was not positive semi-definite, a necessary condition to invert it. This most often occurred when a maximum likelihood parameter encroached upon a strict parameter boundary (e.g., variance parameters being strictly positive). We dealt with these scenarios in two ways. In some cases, numerical line search along any Hessian eigenvector with negative eigenvalue confirmed the convexity of the log-likelihood was local whereas more globally the log-likelihood was concave. In light of this, we numerically computed the global concavity of the log-likelihood with a numerical line search and approximated this curve with a quadratic function. We replaced the negative eigenvalue of the Hessian with two times the coefficient of this quadratic approximation (the multiplier two is used because the Hessian is two times the second-order approximation of the log-likelihood via Taylor series approximation, where the second-order term contains a 1/2 prefactor). In other cases, computing the Hessian in a transformed space (e.g., log space) where troublesome parameters were free to take on any value rectified the non-concavity (<xref ref-type="bibr" rid="bib54">Yartsev et al., 2018</xref>). After computing confidence intervals in the transformed space, we mapped these values back into the standard space by the inverse transform.</p></sec><sec id="s4-8"><title>Data selection</title><p>Details regarding behavioral data collection and neural recordings and spike sorting can be found in <xref ref-type="bibr" rid="bib25">Hanks et al., 2015</xref> and <xref ref-type="bibr" rid="bib54">Yartsev et al., 2018</xref>. To select which neurons were used, a firing rate for each neuron was computed by summing spikes over the duration of the stimulus period and dividing this by the length of the stimulus period. A two-sided t-test was applied, comparing the firing rate distribution on trials when the animal chose left and when the animal chose right. Neurons with a p-value less than 0.01 were included for analysis.</p></sec><sec id="s4-9"><title>Data grouping</title><p>We grouped together rats that had neural recordings from the same brain region (five FOF rats, three PPC rats, three ADS rats; see <xref ref-type="table" rid="table1">Table 1</xref> for information about the data) to improve our estimation of the model parameters for each region. For the PPC and ADS recordings, the majority of recorded neurons came from a single rat (<xref ref-type="table" rid="table1">Table 1</xref>). Although individual FOF rats had enough neurons to support fitting each rat alone, the maximum likelihood parameters for FOF rats fit individually were qualitatively similar (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>).</p></sec><sec id="s4-10"><title>Response latency</title><p>Previous analyses have identified a response latency between the stimulus and the neural responses, and that this latency can be different in different brain regions (<xref ref-type="bibr" rid="bib25">Hanks et al., 2015</xref>). To account for this, we shifted the time of the neural responses relative to the clicks based on these prior results. FOF and ADS responses had a latency of 60 ms, while PPC responses had a latency of 120 ms.</p></sec><sec id="s4-11"><title>Specifics of data selection for each analyses</title><p>Our reports of the maximum likelihood parameters for each model are for models fit to the entire dataset. Each model was also fit using cross-validation (i.e., training on a subset of the data, while reserving data for testing) but the maximum likelihood parameters did not qualitatively change from those identified using the entire dataset, and the log-likelihood computed on test data using parameters identified with training data did not differ appreciably from the log-likelihood computed on those same trials using parameters identified with the entire dataset (<xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>). This consistency is likely due to the modest number of model parameters.</p><p>When we compute various quantities related to the data, such as PSTHs, cross-correlation functions, and psychometric functions, we likewise use the entire dataset. We did not find that we could accurately estimate the PSTH when only using a small subset of the data (i.e., test data) due to the fact that our task lacks repeated stimulus conditions. Additionally, when we simulate data from a fit model (e.g., <xref ref-type="fig" rid="fig2">Figure 2A</xref>), we used the maximum likelihood parameters derived from model fits to the entire dataset, and used the stimuli of the entire dataset to generate these data. Again, because the maximum likelihood parameters did not qualitatively change when the model was fit to a subset of the data, we found it easier to focus our analyses on a single model. The above statements apply to analyses in the following figures: <xref ref-type="fig" rid="fig2">Figure 2</xref>, <xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig4">Figure 4C, D</xref>, <xref ref-type="fig" rid="fig5">Figure 5</xref>, <xref ref-type="fig" rid="fig6">Figure 6B–F</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>, <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>.</p><p>When comparing performance across models, cross-validation is necessary, and we did so in those cases (e.g. <xref ref-type="fig" rid="fig4">Figure 4B</xref>, <xref ref-type="fig" rid="fig6">Figure 6A</xref>, <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>, <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>, <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4B</xref>). In these cases, we performed fivefold cross-validation by dividing the dataset into a training set that consisted of 80% of the data and a test set that consisted of 20% of the data. We fit each model using the training data of each fold, and computed the test log-likelihood using the test data and the parameters derived from the training data. Test performance was averaged across the five folds. Again, we stress that the test performance on cross-validated data did not appreciably differ from that computed using a model trained to the entire dataset (<xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>). We note, however, that even in cases when we performed cross-validation, we still computed an approximation to each neuron’s trial-averaged firing rates, <inline-formula><mml:math id="inf135"><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, using all available data, prior to fitting the full model.</p><p>Because most of our models were fit simultaneously to data from multiple experimental sessions (in which different neurons are recorded), to perform cross-validation, we randomly divided trials within each session into a train and test set, and trained and tested the model collectively on those groups of trials. Testing the model in this way will determine parameter robustness across all sessions (for model parameters that are shared across all sessions) and individual parameter robustness within a session (for parameters that are specific to an individual session). This procedure also worked for the ‘independent-noise model’, for which model parameters were shared across all sessions, but individual neuron parameters were session specific.</p></sec><sec id="s4-12"><title>Other fit models</title><sec id="s4-12-1"><title>Independent-noise accumulator models</title><p>We refer to the set of all parameters for the model with independent accumulator noise per neuron as <inline-formula><mml:math id="inf136"><mml:msub><mml:mrow><mml:mi>Θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. The likelihood of the spike train data from the <italic>n-</italic>th neuron <inline-formula><mml:math id="inf137"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for <italic>T</italic> time bins is<disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:munderover><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>The joint likelihood for the spike train data from all neurons is the product of the likelihood for each neuron: <inline-formula><mml:math id="inf138"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. Our primary interest in this analysis was capturing the neural responses, so we considered a simple model of choice for this model: on each trial, choice is determined by randomly selecting one of the accumulators. The likelihood of the choice <italic>d</italic> under such a model is the average of the <italic>n</italic> accumulators at time <italic>T</italic>:<disp-formula id="equ17"><label>(17)</label><mml:math id="m17"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>The full likelihood is the product of these terms: <inline-formula><mml:math id="inf139"><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mi>Y</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>Θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mi>d</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>Θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mi>P</mml:mi><mml:mo>(</mml:mo><mml:mi>Y</mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>Θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula>.</p></sec><sec id="s4-12-2"><title>Choice-only model</title><p>We refer to the set of all parameters for the model fit to choices only as <inline-formula><mml:math id="inf140"><mml:msub><mml:mrow><mml:mi>Θ</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>}</mml:mo></mml:math></inline-formula>. The likelihood of the behavioral choice <italic>d</italic> is<disp-formula id="equ18"><label>(18)</label><mml:math id="m18"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:munder><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:munderover><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-12-3"><title>Bernoulli GLM</title><p>To benchmark our method’s ability to predict the animal’s choice, we considered a basic logistic regression model (i.e., Bernoulli GLM) that included stimulus information and neural activity (e.g., <xref ref-type="fig" rid="fig6">Figure 6A</xref> and <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). For each trial, we computed the total number of spikes each neuron produced during the specified temporal window and the final cumulative click difference, and used them as regressors in a standard Bernoulli GLM to predict the animal’s choice. A constant bias was also included, as well as a single lapse parameter that scaled the minimum and maximum values of the logistic inverse link function. Cross-validation was performed on this model as described above.</p></sec><sec id="s4-12-4"><title>Null choice model</title><p>In <xref ref-type="fig" rid="fig6">Figure 6A</xref>, we assess how well each of our fitted models can predict choice. We compare all models against a baseline model where each choice is a Bernoulli random variable with probability of making a right choice equal to the empirical fraction of choices made to the right.</p></sec><sec id="s4-12-5"><title>Null joint model</title><p>To compare the improvement of the joint model in absolute terms (i.e., when not comparing two fitted models), we compute a null model of the spiking activity and choices (<xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4B</xref>). The null likelihood of the choice data is as described above. The null likelihood of the spike train data assumes that the time-varying expected firing rate of each neuron is equal to its estimated time-varying trial-average firing rate, i.e., <inline-formula><mml:math id="inf141"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>.</p><p>The improved performance (i.e., cross-validated log-likelihood) of our joint model over the null model shown in <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref> further confirms that <inline-formula><mml:math id="inf142"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>a</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> and <inline-formula><mml:math id="inf143"><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> are uniquely identifiable, and that they are not redundant (i.e., the joint model is not overparameterized).</p></sec><sec id="s4-12-6"><title>Poisson GLM</title><p>To validate the maximum likelihood parameters derived from the joint model, we fit a variant of a Poisson GLM to the spiking responses (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). As a regressor, we used the adapted, exponentially filtered click inputs,<disp-formula id="equ19">, <label>(19)</label><mml:math id="m19"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf144"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is defined as above. The expected firing rate of each neuron is defined as in the full model, by <xref ref-type="disp-formula" rid="equ10">Equation 10</xref>. For the bounded Poisson GLM model, the dynamics of <italic>a</italic>(<italic>t</italic>) follow <xref ref-type="disp-formula" rid="equ19">Equation 19</xref>, except that if <italic>a</italic>(<italic>t</italic>) crosses <italic>B</italic>, <italic>a</italic>(<italic>t</italic>) stops evolving (i.e. <italic>da</italic> = 0 if <italic>a</italic>(<italic>t</italic>)&gt;<italic>B</italic>). The parameters <inline-formula><mml:math id="inf145"><mml:mi>λ</mml:mi></mml:math></inline-formula>, <italic>B</italic>, <inline-formula><mml:math id="inf146"><mml:mi>ϕ</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf147"><mml:msub><mml:mrow><mml:mi>τ</mml:mi></mml:mrow><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, and <inline-formula><mml:math id="inf148"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> that maximize the likelihood of the spike data were learned using gradient ascent. The null model described in <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref> is the null joint model, described above.</p></sec><sec id="s4-12-7"><title>Negative binomial</title><p>In <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>, we compare a Poisson observation model to a negative binomial model. To do this, we model the spikes as:<disp-formula id="equ20"><label>(20)</label><mml:math id="m20"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mi>B</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mfrac><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf149"><mml:mi>N</mml:mi><mml:mi>B</mml:mi><mml:mo>(</mml:mo><mml:mo>⋅</mml:mo><mml:mo>,</mml:mo><mml:mo>⋅</mml:mo><mml:mo>)</mml:mo></mml:math></inline-formula> is the negative binomial distribution, and <inline-formula><mml:math id="inf150"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> controls the variance of the distribution for each neuron and can take values between 0 and positive infinity. When <inline-formula><mml:math id="inf151"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> becomes large the negative binomial distribution approaches the Poisson distribution. <inline-formula><mml:math id="inf152"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mi>B</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> was fit for each neuron using gradient ascent, as described above.</p></sec></sec><sec id="s4-13"><title>Quantifying model fit</title><sec id="s4-13-1"><title>Computing PSTHs and cross-correlation functions on empirical data</title><p>We computed a ‘single-trial’ firing rate for each neuron by convolving its binned spikes with a Gaussian kernel of standard deviation 50 ms. We call this single-trial rate <inline-formula><mml:math id="inf153"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for the <italic>n-</italic>th neuron on the <italic>k-</italic>th trial at time <italic>t</italic>. We divide all the trials into two equally sized groups based on the cumulative click difference at the end of the trial and average <inline-formula><mml:math id="inf154"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> based on these groupings. Because trials are not of equal duration, at time <italic>t</italic> we use whichever trials have data at that time. We refer to this average as <inline-formula><mml:math id="inf155"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo>̄</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> where the index <italic>c</italic> runs from 1 to 2.</p><p>We used the empirical binned spikes counts to compute cross-correlation functions. Raw cross-correlation functions were normalized by the (across time) mean firing rates of the two neurons being used so they provided a measure of excess spike rate. The equation for the raw cross-correlation function was<disp-formula id="equ21">, <label>(21)</label><mml:math id="m21"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>K</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:munderover><mml:mfrac><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <italic>t</italic> is over all bins for the <italic>k-</italic>th trial, <inline-formula><mml:math id="inf156"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf157"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are the binned spike train of neuron <italic>n</italic> and <italic>m</italic> at time <italic>t</italic> and <inline-formula><mml:math id="inf158"><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>τ</mml:mi></mml:math></inline-formula> respectively, and <inline-formula><mml:math id="inf159"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> is the number of bins such that both <inline-formula><mml:math id="inf160"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf161"><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are valid. <inline-formula><mml:math id="inf162"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf163"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are the mean firing rates of the <italic>n-</italic>th and <italic>m</italic>th neuron respectively, computed by taking the average spike count across all times.</p><p>To compute the shuffled-corrected cross-correlation, we computed the cross-correlation of the expected firing rate of each neuron provided by the PSTH, i.e., <inline-formula><mml:math id="inf164"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo>̄</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>,<disp-formula id="equ22">, <label>(22)</label><mml:math id="m22"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>S</mml:mi><mml:mi>T</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>C</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:munderover><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <italic>C</italic>=2 is the number of conditions used to define the PSTH, <inline-formula><mml:math id="inf165"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> is defined similarly as above, and <inline-formula><mml:math id="inf166"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf167"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are as defined above. The shuffle-corrected cross-correlation is the raw cross-correlation minus the cross-correlation of the expected firing rate: <inline-formula><mml:math id="inf168"><mml:msub><mml:mrow><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo><mml:mo>-</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mi>S</mml:mi><mml:mi>T</mml:mi><mml:mi>H</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula>.</p></sec><sec id="s4-13-2"><title>Computing PSTHs and cross-correlation functions on synthetic data</title><p>We generated synthetic data from a model by using the maximum likelihood parameters to generate the expected firing rate of each neuron on each trial, i.e., <inline-formula><mml:math id="inf169"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. We averaged this expected rate for each neuron on each trial over 20 different realizations of the latent noise to reduce variation due to the latent process. We then grouped and averaged these average expected rates, as described above, to generate a synthetic PSTH, which we denote by <inline-formula><mml:math id="inf170"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>̄</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, as used in <xref ref-type="fig" rid="fig2">Figure 2</xref> and <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>.</p><p>We used the synthetic expected firing rate, <inline-formula><mml:math id="inf171"><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, to compute cross-correlation function for synthetic data,<disp-formula id="equ23">, <label>(23)</label><mml:math id="m23"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>K</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:munderover><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>τ</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <italic>K</italic>, <inline-formula><mml:math id="inf172"><mml:msub><mml:mrow><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>τ</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula>, <inline-formula><mml:math id="inf173"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, and <inline-formula><mml:math id="inf174"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are as defined above. The shuffle-corrected cross-correlation function of synthetic data is the raw cross-correlation function minus the cross-correlation function of the expected synthetic firing rate provided by the synthetic PSTH, <inline-formula><mml:math id="inf175"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>̄</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>.</p></sec><sec id="s4-13-3"><title>Goodness-of-fit metrics</title><p>To compare empirical and synthetic PSTHs, we computed the coefficient of determination. Because fewer and fewer trials were included in computing the PSTH at large time values (because trials of great length were rare), we included PSTH values 200 ms before the stimulus onset up until 500 ms after stimulus onset in this calculation. Based on the definitions of the empirical and synthetic PSTHs, the coefficient of determination is defined as:<disp-formula id="equ24">, <label>(24)</label><mml:math id="m24"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mi>C</mml:mi></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mi>T</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mo>&gt;</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf176"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&lt;</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>r</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mo>&gt;</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the mean of <inline-formula><mml:math id="inf177"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo>̄</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> over trial groupings and times. Pearson correlation (<italic>r</italic>) was used to compare empirical and synthetic cross-correlation functions. When computing <italic>r</italic> we considered values of <inline-formula><mml:math id="inf178"><mml:mi>τ</mml:mi></mml:math></inline-formula> between –800 and 800 ms.</p></sec><sec id="s4-13-4"><title>Psychometric functions</title><p>We used a Bernoulli GLM (i.e., logistic regression) to compute psychometric functions for empirical and synthetic data. We generated synthetic data from a model by using the maximum likelihood parameters to generate the probability of a choice, and sampled the choice from a Bernoulli distribution. For the Bernoulli GLM, for each trial, we computed the final click difference and used it as a regressor to predict the animal’s choice. A constant bias was also included, as well as a single lapse parameter that scaled the minimum and maximum values of the logistic inverse link function. <inline-formula><mml:math id="inf179"><mml:msup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> values comparing empirical and synthetic psychometric functions were defined as above, but using the psychometric functions whose domain was from the minimum final cumulative click difference to the maximum final cumulative click difference.</p></sec><sec id="s4-13-5"><title>Choice decoding</title><p>We used two metrics to determine how well choice could be decoded from various models: choice-prediction accuracy and test log-likelihood. Test likelihood was reported in bits per trial, i.e.,<disp-formula id="equ25"><label>(25)</label><mml:math id="m25"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>L</mml:mi><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>L</mml:mi><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>L</mml:mi><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>K</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <italic>K</italic> is the number of trials in the test set and <inline-formula><mml:math id="inf180"><mml:mi>L</mml:mi><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the appropriate null model, as described above, or a second model with which to test against. Fivefold cross-validation was performed, as described above. Accuracy was determined, depending on the model, by computing the probability that the model predicted a right choice, given all available data (i.e. inputs and spikes in a model that includes spikes). If the model had a greater than 0.5 probability of choosing right, we considered that a prediction of a rightward choice. Accuracy is the fraction of correct choice predictions.</p></sec><sec id="s4-13-6"><title>Identifying putative changes of mind</title><p>Based on a recent study (<xref ref-type="bibr" rid="bib37">Peixoto et al., 2021</xref>) we defined putative changes in mind in the following way. For each model and each trial, we computed the posterior distribution of <italic>a</italic>(<italic>t</italic>) given all available data except for the choice. In the case of the choice-only model, this means using only the stimulus, and is equivalent to the forward pass of the model. In the case of the joint model, this is equivalent to the posterior distribution of <italic>a</italic>(<italic>t</italic>) given the spikes on that trial. We computed the expected value of the posterior distribution for each trial and identified moments when it crossed the decision threshold as determined for each model (i.e., the <italic>c</italic> parameter of the choice likelihood). We required that the expected value remain on one side of the threshold for 50 ms, remain on the other side following the crossing for 50 ms, and achieve an absolute magnitude greater than or equal to 2 at some point during that 100 ms window.</p><p>To relate putative change of mind events to the animal’s behavior, we performed linear regression between the time of the event relative to the end of the stimulus (i.e., how close to a decision the event occurred) and a measure of the animal’s reaction time. In this task, the animal is required to fixate in the center poke for the duration of the stimulus, so it does not exhibit a true reaction time in the standard sense of the term. However, following the end of the stimulus, it does take the animal time to withdraw from the center port to make its choice (see <xref ref-type="fig" rid="fig1">Figure 1A</xref>, bottom, upper two lines). We refer to the difference between the end of the stimulus and when the animal withdrew from the center port as the animal’s reaction time, which we used in our analysis.</p></sec><sec id="s4-13-7"><title>Estimating dimension</title><p>To estimate the effective dimension of groups of simultaneously recorded neurons, we computed the ‘participation ratio’ (<xref ref-type="bibr" rid="bib33">Litwin-Kumar et al., 2017</xref>). Single-trial firing rates were computed by convolving the spike trains with a Gaussian kernel (std = 50 ms), and the covariance matrix of these rates was computed. The participation ratio is<disp-formula id="equ26">, <label>(26)</label><mml:math id="m26"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf181"><mml:mi>λ</mml:mi></mml:math></inline-formula> are the eigenvalues of the covariance matrix. If the firing rates are independent, the eigenvalues will all be equal and the participation ratio will equal the number of neurons. If the firing rates are correlated such that some eigenvalues are small (or perhaps even zero) the participation ratio will be less than the number of neurons.</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>Reviewing editor, eLife</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Investigation, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Supervision, Funding acquisition, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Supervision, Funding acquisition, Project administration, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-84955-mdarchecklist1-v3.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All code was written in the Julia programming language. The core codebase for fitting the models described in this manuscript can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/Brody-Lab/PulseInputDDM.jl">https://github.com/Brody-Lab/PulseInputDDM.jl</ext-link> (copy archived at <xref ref-type="bibr" rid="bib10">Brody-Lab, 2024a</xref>). All data analyzed during this study and original analysis computer code has been deposited at <ext-link ext-link-type="uri" xlink:href="https://github.com/Brody-Lab/DePasquale-eLife-2024">https://github.com/Brody-Lab/DePasquale-eLife-2024</ext-link> (copy archived at <xref ref-type="bibr" rid="bib11">Brody-Lab, 2024b</xref>).</p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported by Simons Collaboration on the Global Brain (SCGB AWD543027 and AWD542593), and NIH-NINDS BRAIN Initiative Award (5U19NS104648-02). We thank Michael Yartsev, Tim Hanks, and Charles Kopec for providing the neural and behavioral data analyzed here. We thank members of the Brody and Pillow labs for comments on this work, especially Thomas Luo, Tim Kim, Diksha Gupta, and Tyler Boyd-Meredith. BD would like to thank Carol Mason, Paul DiMaggio, Betsy Levy Paluck, and Nathan Paluck for their support while this study was conducted.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aguillon-Rodriguez</surname><given-names>V</given-names></name><name><surname>Angelaki</surname><given-names>D</given-names></name><name><surname>Bayer</surname><given-names>H</given-names></name><name><surname>Bonacchi</surname><given-names>N</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Cazettes</surname><given-names>F</given-names></name><name><surname>Chapuis</surname><given-names>G</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name><name><surname>Dan</surname><given-names>Y</given-names></name><name><surname>Dewitt</surname><given-names>E</given-names></name><name><surname>Faulkner</surname><given-names>M</given-names></name><name><surname>Forrest</surname><given-names>H</given-names></name><name><surname>Haetzel</surname><given-names>L</given-names></name><name><surname>Häusser</surname><given-names>M</given-names></name><name><surname>Hofer</surname><given-names>SB</given-names></name><name><surname>Hu</surname><given-names>F</given-names></name><name><surname>Khanal</surname><given-names>A</given-names></name><name><surname>Krasniak</surname><given-names>C</given-names></name><name><surname>Laranjeira</surname><given-names>I</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name><name><surname>Meijer</surname><given-names>G</given-names></name><name><surname>Miska</surname><given-names>NJ</given-names></name><name><surname>Mrsic-Flogel</surname><given-names>TD</given-names></name><name><surname>Murakami</surname><given-names>M</given-names></name><name><surname>Noel</surname><given-names>JP</given-names></name><name><surname>Pan-Vazquez</surname><given-names>A</given-names></name><name><surname>Rossant</surname><given-names>C</given-names></name><name><surname>Sanders</surname><given-names>J</given-names></name><name><surname>Socha</surname><given-names>K</given-names></name><name><surname>Terry</surname><given-names>R</given-names></name><name><surname>Urai</surname><given-names>AE</given-names></name><name><surname>Vergara</surname><given-names>H</given-names></name><name><surname>Wells</surname><given-names>M</given-names></name><name><surname>Wilson</surname><given-names>CJ</given-names></name><name><surname>Witten</surname><given-names>IB</given-names></name><name><surname>Wool</surname><given-names>LE</given-names></name><name><surname>Zador</surname><given-names>AM</given-names></name><collab>The International Brain Laboratory</collab></person-group><year iso-8601-date="2021">2021</year><article-title>Standardized and reproducible measurement of decision-making in mice</article-title><source>eLife</source><volume>10</volume><elocation-id>e63711</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.63711</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Akrami</surname><given-names>A</given-names></name><name><surname>Kopec</surname><given-names>CD</given-names></name><name><surname>Diamond</surname><given-names>ME</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Posterior parietal cortex represents sensory history and mediates its effects on behaviour</article-title><source>Nature</source><volume>554</volume><fpage>368</fpage><lpage>372</lpage><pub-id pub-id-type="doi">10.1038/nature25510</pub-id><pub-id pub-id-type="pmid">29414944</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aoi</surname><given-names>MC</given-names></name><name><surname>Mante</surname><given-names>V</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Prefrontal cortex exhibits multidimensional dynamic encoding during decision-making</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>1410</fpage><lpage>1420</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-0696-5</pub-id><pub-id pub-id-type="pmid">33020653</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beck</surname><given-names>JM</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Hanks</surname><given-names>T</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name><name><surname>Roitman</surname><given-names>J</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Probabilistic population codes for Bayesian decision making</article-title><source>Neuron</source><volume>60</volume><fpage>1142</fpage><lpage>1152</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.09.021</pub-id><pub-id pub-id-type="pmid">19109917</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bishop</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>Pattern Recognition and Machine Learning</source><publisher-name>Springer-Verlag</publisher-name></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogacz</surname><given-names>R</given-names></name><name><surname>Brown</surname><given-names>E</given-names></name><name><surname>Moehlis</surname><given-names>J</given-names></name><name><surname>Holmes</surname><given-names>P</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The physics of optimal decision making: a formal analysis of models of performance in two-alternative forced-choice tasks</article-title><source>Psychological Review</source><volume>113</volume><fpage>700</fpage><lpage>765</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.113.4.700</pub-id><pub-id pub-id-type="pmid">17014301</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bollimunta</surname><given-names>A</given-names></name><name><surname>Totten</surname><given-names>D</given-names></name><name><surname>Ditterich</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural dynamics of choice: single-trial analysis of decision-related activity in parietal cortex</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>12684</fpage><lpage>12701</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5752-11.2012</pub-id><pub-id pub-id-type="pmid">22972993</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boyd-Meredith</surname><given-names>JT</given-names></name><name><surname>Piet</surname><given-names>AT</given-names></name><name><surname>Dennis</surname><given-names>EJ</given-names></name><name><surname>El Hady</surname><given-names>A</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Stable choice coding in rat frontal orienting fields across model-predicted changes of mind</article-title><source>Nature Communications</source><volume>13</volume><elocation-id>3235</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-022-30736-3</pub-id><pub-id pub-id-type="pmid">35688813</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brody</surname><given-names>CD</given-names></name><name><surname>Hanks</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural underpinnings of the evidence accumulator</article-title><source>Current Opinion in Neurobiology</source><volume>37</volume><fpage>149</fpage><lpage>157</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2016.01.003</pub-id><pub-id pub-id-type="pmid">26878969</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="software"><person-group person-group-type="author"><collab>Brody-Lab</collab></person-group><year iso-8601-date="2024">2024a</year><data-title>PulseInputDDM.jl</data-title><version designator="swh:1:rev:3a936a9eae15bdcd77f53480f3190b621483b91d">swh:1:rev:3a936a9eae15bdcd77f53480f3190b621483b91d</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:f8fd4546cb4482b17b11780107f17db6b9a8b32a;origin=https://github.com/Brody-Lab/PulseInputDDM.jl;visit=swh:1:snp:8a79ae9bf35905662121217fc4a25df38b362288;anchor=swh:1:rev:3a936a9eae15bdcd77f53480f3190b621483b91d">https://archive.softwareheritage.org/swh:1:dir:f8fd4546cb4482b17b11780107f17db6b9a8b32a;origin=https://github.com/Brody-Lab/PulseInputDDM.jl;visit=swh:1:snp:8a79ae9bf35905662121217fc4a25df38b362288;anchor=swh:1:rev:3a936a9eae15bdcd77f53480f3190b621483b91d</ext-link></element-citation></ref><ref id="bib11"><element-citation publication-type="software"><person-group person-group-type="author"><collab>Brody-Lab</collab></person-group><year iso-8601-date="2024">2024b</year><data-title>DePasquale-elife-2024</data-title><version designator="swh:1:rev:fad3c8f771afb3371b16e474a68e70e2e3e4597e">swh:1:rev:fad3c8f771afb3371b16e474a68e70e2e3e4597e</version><source>Software Hteritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:19eec34ccb4d82707e9972e8362361014cba0936;origin=https://github.com/Brody-Lab/DePasquale-eLife-2024;visit=swh:1:snp:6d0c56200ea1d07c9915fd8e220d307bc52f2c7a;anchor=swh:1:rev:fad3c8f771afb3371b16e474a68e70e2e3e4597e">https://archive.softwareheritage.org/swh:1:dir:19eec34ccb4d82707e9972e8362361014cba0936;origin=https://github.com/Brody-Lab/DePasquale-eLife-2024;visit=swh:1:snp:6d0c56200ea1d07c9915fd8e220d307bc52f2c7a;anchor=swh:1:rev:fad3c8f771afb3371b16e474a68e70e2e3e4597e</ext-link></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunton</surname><given-names>BW</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Rats and humans can optimally accumulate evidence for decision-making</article-title><source>Science</source><volume>340</volume><fpage>95</fpage><lpage>98</lpage><pub-id pub-id-type="doi">10.1126/science.1233912</pub-id><pub-id pub-id-type="pmid">23559254</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chandrasekaran</surname><given-names>C</given-names></name><name><surname>Hawkins</surname><given-names>GE</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>ChaRTr: An R toolbox for modeling choices and response times in decision-making tasks</article-title><source>Journal of Neuroscience Methods</source><volume>328</volume><elocation-id>108432</elocation-id><pub-id pub-id-type="doi">10.1016/j.jneumeth.2019.108432</pub-id><pub-id pub-id-type="pmid">31586868</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Yu</surname><given-names>BM</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Sugrue</surname><given-names>LP</given-names></name><name><surname>Cohen</surname><given-names>MR</given-names></name><name><surname>Corrado</surname><given-names>GS</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Clark</surname><given-names>AM</given-names></name><name><surname>Hosseini</surname><given-names>P</given-names></name><name><surname>Scott</surname><given-names>BB</given-names></name><name><surname>Bradley</surname><given-names>DC</given-names></name><name><surname>Smith</surname><given-names>MA</given-names></name><name><surname>Kohn</surname><given-names>A</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name><name><surname>Armstrong</surname><given-names>KM</given-names></name><name><surname>Moore</surname><given-names>T</given-names></name><name><surname>Chang</surname><given-names>SW</given-names></name><name><surname>Snyder</surname><given-names>LH</given-names></name><name><surname>Lisberger</surname><given-names>SG</given-names></name><name><surname>Priebe</surname><given-names>NJ</given-names></name><name><surname>Finn</surname><given-names>IM</given-names></name><name><surname>Ferster</surname><given-names>D</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Santhanam</surname><given-names>G</given-names></name><name><surname>Sahani</surname><given-names>M</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Stimulus onset quenches neural variability: a widespread cortical phenomenon</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>369</fpage><lpage>378</lpage><pub-id pub-id-type="doi">10.1038/nn.2501</pub-id><pub-id pub-id-type="pmid">20173745</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname><given-names>AK</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Chaudhuri</surname><given-names>R</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Variance as a signature of neural computations during decision making</article-title><source>Neuron</source><volume>69</volume><fpage>818</fpage><lpage>831</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.12.037</pub-id><pub-id pub-id-type="pmid">21338889</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>L</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Caudate encodes multiple computations for perceptual decisions</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>15747</fpage><lpage>15759</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2894-10.2010</pub-id><pub-id pub-id-type="pmid">21106814</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>L</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The basal ganglia’s contributions to perceptual decision making</article-title><source>Neuron</source><volume>79</volume><fpage>640</fpage><lpage>649</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.07.042</pub-id><pub-id pub-id-type="pmid">23972593</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ditterich</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Stochastic models of decisions about motion direction: behavior and physiology</article-title><source>Neural Networks</source><volume>19</volume><fpage>981</fpage><lpage>1012</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2006.05.042</pub-id><pub-id pub-id-type="pmid">16952441</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erlich</surname><given-names>JC</given-names></name><name><surname>Bialek</surname><given-names>M</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A cortical substrate for memory-guided orienting in the rat</article-title><source>Neuron</source><volume>72</volume><fpage>330</fpage><lpage>343</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.07.010</pub-id><pub-id pub-id-type="pmid">22017991</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erlich</surname><given-names>JC</given-names></name><name><surname>Brunton</surname><given-names>BW</given-names></name><name><surname>Duan</surname><given-names>CA</given-names></name><name><surname>Hanks</surname><given-names>TD</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Distinct effects of prefrontal and parietal cortex inactivations on an accumulation of evidence task in the rat</article-title><source>eLife</source><volume>4</volume><elocation-id>e05457</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.05457</pub-id><pub-id pub-id-type="pmid">25869470</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname><given-names>MJ</given-names></name><name><surname>Gagne</surname><given-names>C</given-names></name><name><surname>Nyhus</surname><given-names>E</given-names></name><name><surname>Masters</surname><given-names>S</given-names></name><name><surname>Wiecki</surname><given-names>TV</given-names></name><name><surname>Cavanagh</surname><given-names>JF</given-names></name><name><surname>Badre</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>fMRI and EEG predictors of dynamic decision parameters during human reinforcement learning</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>485</fpage><lpage>494</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2036-14.2015</pub-id><pub-id pub-id-type="pmid">25589744</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Genkin</surname><given-names>M</given-names></name><name><surname>Hughes</surname><given-names>O</given-names></name><name><surname>Engel</surname><given-names>TA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Learning non-stationary Langevin dynamics from stochastic observations of latent trajectories</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>5986</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-26202-1</pub-id><pub-id pub-id-type="pmid">34645828</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Representation of a perceptual decision in developing oculomotor commands</article-title><source>Nature</source><volume>404</volume><fpage>390</fpage><lpage>394</lpage><pub-id pub-id-type="doi">10.1038/35006062</pub-id><pub-id pub-id-type="pmid">10746726</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The neural basis of decision making</article-title><source>Annual Review of Neuroscience</source><volume>30</volume><fpage>535</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.29.051605.113038</pub-id><pub-id pub-id-type="pmid">17600525</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanks</surname><given-names>TD</given-names></name><name><surname>Kopec</surname><given-names>CD</given-names></name><name><surname>Brunton</surname><given-names>BW</given-names></name><name><surname>Duan</surname><given-names>CA</given-names></name><name><surname>Erlich</surname><given-names>JC</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Distinct relationships of parietal and prefrontal cortices to evidence accumulation</article-title><source>Nature</source><volume>520</volume><fpage>220</fpage><lpage>223</lpage><pub-id pub-id-type="doi">10.1038/nature14066</pub-id><pub-id pub-id-type="pmid">25600270</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Luzardo</surname><given-names>A</given-names></name><name><surname>Tiganj</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Evidence accumulation in a Laplace domain decision space</article-title><source>Computational Brain &amp; Behavior</source><volume>1</volume><fpage>237</fpage><lpage>251</lpage><pub-id pub-id-type="doi">10.1007/s42113-018-0016-2</pub-id><pub-id pub-id-type="pmid">31131363</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huk</surname><given-names>AC</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Neural activity in macaque parietal cortex reflects temporal integration of visual motion signals during perceptual decision making</article-title><source>The Journal of Neuroscience</source><volume>25</volume><fpage>10420</fpage><lpage>10436</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4684-04.2005</pub-id><pub-id pub-id-type="pmid">16280581</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Vacillation, indecision and hesitation in moment-by-moment decoding of monkey motor cortex</article-title><source>eLife</source><volume>4</volume><elocation-id>e04677</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.04677</pub-id><pub-id pub-id-type="pmid">25942352</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Cueva</surname><given-names>CJ</given-names></name><name><surname>Reppas</surname><given-names>JB</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dynamics of neural population responses in prefrontal cortex indicate changes of mind on single trials</article-title><source>Current Biology</source><volume>24</volume><fpage>1542</fpage><lpage>1547</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2014.05.049</pub-id><pub-id pub-id-type="pmid">24954050</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>JN</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Neural correlates of a decision in the dorsolateral prefrontal cortex of the macaque</article-title><source>Nature Neuroscience</source><volume>2</volume><fpage>176</fpage><lpage>185</lpage><pub-id pub-id-type="doi">10.1038/5739</pub-id><pub-id pub-id-type="pmid">10195203</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Latimer</surname><given-names>KW</given-names></name><name><surname>Yates</surname><given-names>JL</given-names></name><name><surname>Meister</surname><given-names>MLR</given-names></name><name><surname>Huk</surname><given-names>AC</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neuronal modeling. Single-trial spike trains in parietal cortex reveal discrete steps during decision-making</article-title><source>Science</source><volume>349</volume><fpage>184</fpage><lpage>187</lpage><pub-id pub-id-type="doi">10.1126/science.aaa4056</pub-id><pub-id pub-id-type="pmid">26160947</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Latimer</surname><given-names>KW</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Low-Dimensional Encoding of Decisions in Parietal Cortex Reflects Long-Term Training History</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.10.07.463576</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Litwin-Kumar</surname><given-names>A</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Axel</surname><given-names>R</given-names></name><name><surname>Sompolinsky</surname><given-names>H</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Optimal degrees of synaptic connectivity</article-title><source>Neuron</source><volume>93</volume><fpage>1153</fpage><lpage>1164</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.01.030</pub-id><pub-id pub-id-type="pmid">28215558</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>TZ</given-names></name><name><surname>Bondy</surname><given-names>AG</given-names></name><name><surname>Gupta</surname><given-names>D</given-names></name><name><surname>Elliott</surname><given-names>VA</given-names></name><name><surname>Kopec</surname><given-names>CD</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>An approach for long-term, multi-probe Neuropixels recordings in unrestrained rats</article-title><source>eLife</source><volume>9</volume><elocation-id>e59716</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.59716</pub-id><pub-id pub-id-type="pmid">33089778</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mante</surname><given-names>V</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Context-dependent computation by recurrent dynamics in prefrontal cortex</article-title><source>Nature</source><volume>503</volume><fpage>78</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1038/nature12742</pub-id><pub-id pub-id-type="pmid">24201281</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>IM</given-names></name><name><surname>Meister</surname><given-names>MLR</given-names></name><name><surname>Huk</surname><given-names>AC</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Encoding and decoding in parietal cortex during sensorimotor decision-making</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1395</fpage><lpage>1403</lpage><pub-id pub-id-type="doi">10.1038/nn.3800</pub-id><pub-id pub-id-type="pmid">25174005</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peixoto</surname><given-names>D</given-names></name><name><surname>Verhein</surname><given-names>JR</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Kao</surname><given-names>JC</given-names></name><name><surname>Nuyujukian</surname><given-names>P</given-names></name><name><surname>Chandrasekaran</surname><given-names>C</given-names></name><name><surname>Brown</surname><given-names>J</given-names></name><name><surname>Fong</surname><given-names>S</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Decoding and perturbing decision states in real time</article-title><source>Nature</source><volume>591</volume><fpage>604</fpage><lpage>609</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-03181-9</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perkel</surname><given-names>DH</given-names></name><name><surname>Gerstein</surname><given-names>GL</given-names></name><name><surname>Moore</surname><given-names>GP</given-names></name></person-group><year iso-8601-date="1967">1967</year><article-title>Neuronal spike trains and stochastic point processes. II. Simultaneous spike trains</article-title><source>Biophysical Journal</source><volume>7</volume><fpage>419</fpage><lpage>440</lpage><pub-id pub-id-type="doi">10.1016/S0006-3495(67)86597-4</pub-id><pub-id pub-id-type="pmid">4292792</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Purcell</surname><given-names>BA</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural mechanisms of post-error adjustments of decision policy in parietal cortex</article-title><source>Neuron</source><volume>89</volume><fpage>658</fpage><lpage>671</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.12.027</pub-id><pub-id pub-id-type="pmid">26804992</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raposo</surname><given-names>D</given-names></name><name><surname>Sheppard</surname><given-names>JP</given-names></name><name><surname>Schrater</surname><given-names>PR</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Multisensory decision-making in rats and humans</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>3726</fpage><lpage>3735</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4998-11.2012</pub-id><pub-id pub-id-type="pmid">22423093</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R</given-names></name><name><surname>Cherian</surname><given-names>A</given-names></name><name><surname>Segraves</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>A comparison of macaque behavior and superior colliculus neuronal activity to predictions from models of two-choice decisions</article-title><source>Journal of Neurophysiology</source><volume>90</volume><fpage>1392</fpage><lpage>1407</lpage><pub-id pub-id-type="doi">10.1152/jn.01049.2002</pub-id><pub-id pub-id-type="pmid">12761282</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R</given-names></name><name><surname>McKoon</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The diffusion decision model: theory and data for two-choice decision tasks</article-title><source>Neural Computation</source><volume>20</volume><fpage>873</fpage><lpage>922</lpage><pub-id pub-id-type="doi">10.1162/neco.2008.12-06-420</pub-id><pub-id pub-id-type="pmid">18085991</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R</given-names></name><name><surname>Smith</surname><given-names>PL</given-names></name><name><surname>Brown</surname><given-names>SD</given-names></name><name><surname>McKoon</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Diffusion decision model: Current issues and history</article-title><source>Trends in Cognitive Sciences</source><volume>20</volume><fpage>260</fpage><lpage>281</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2016.01.007</pub-id><pub-id pub-id-type="pmid">26952739</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Resulaj</surname><given-names>A</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Wolpert</surname><given-names>DM</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Changes of mind in decision-making</article-title><source>Nature</source><volume>461</volume><fpage>263</fpage><lpage>266</lpage><pub-id pub-id-type="doi">10.1038/nature08275</pub-id><pub-id pub-id-type="pmid">19693010</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Revels</surname><given-names>J</given-names></name><name><surname>Lubin</surname><given-names>M</given-names></name><name><surname>Papamarko</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Forward-Mode Automatic Differentiation in Julia</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1607.07892">http://arxiv.org/abs/1607.07892</ext-link></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roitman</surname><given-names>JD</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Response of neurons in the lateral intraparietal area during a combined visual discrimination reaction time task</article-title><source>The Journal of Neuroscience</source><volume>22</volume><fpage>9475</fpage><lpage>9489</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.22-21-09475.2002</pub-id><pub-id pub-id-type="pmid">12417672</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanders</surname><given-names>JI</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Choice ball: a response interface for two-choice psychometric discrimination in head-fixed mice</article-title><source>Journal of Neurophysiology</source><volume>108</volume><fpage>3416</fpage><lpage>3423</lpage><pub-id pub-id-type="doi">10.1152/jn.00669.2012</pub-id><pub-id pub-id-type="pmid">23019000</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Neural basis of a perceptual decision in the parietal cortex (area LIP) of the rhesus monkey</article-title><source>Journal of Neurophysiology</source><volume>86</volume><fpage>1916</fpage><lpage>1936</lpage><pub-id pub-id-type="doi">10.1152/jn.2001.86.4.1916</pub-id><pub-id pub-id-type="pmid">11600651</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shinn</surname><given-names>M</given-names></name><name><surname>Lam</surname><given-names>NH</given-names></name><name><surname>Murray</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A flexible framework for simulating and fitting generalized drift-diffusion models</article-title><source>eLife</source><volume>9</volume><elocation-id>e56938</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.56938</pub-id><pub-id pub-id-type="pmid">32749218</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>MA</given-names></name><name><surname>Kohn</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Spatial and temporal scales of neuronal correlation in primary visual cortex</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>12591</fpage><lpage>12603</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2929-08.2008</pub-id><pub-id pub-id-type="pmid">19036953</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turner</surname><given-names>BM</given-names></name><name><surname>van Maanen</surname><given-names>L</given-names></name><name><surname>Forstmann</surname><given-names>BU</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Informing cognitive abstractions through neuroimaging: the neural drift diffusion model</article-title><source>Psychological Review</source><volume>122</volume><fpage>312</fpage><lpage>336</lpage><pub-id pub-id-type="doi">10.1037/a0038894</pub-id><pub-id pub-id-type="pmid">25844875</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Turner</surname><given-names>BM</given-names></name><name><surname>Forstmann</surname><given-names>BU</given-names></name><name><surname>Steyvers</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><source>Joint Models of Neural and Behavioral Data</source><publisher-name>Springer</publisher-name><pub-id pub-id-type="doi">10.1007/978-3-030-03688-1</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiecki</surname><given-names>TV</given-names></name><name><surname>Sofer</surname><given-names>I</given-names></name><name><surname>Frank</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>HDDM: Hierarchical bayesian estimation of the drift-diffusion model in python</article-title><source>Frontiers in Neuroinformatics</source><volume>7</volume><elocation-id>14</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2013.00014</pub-id><pub-id pub-id-type="pmid">23935581</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yartsev</surname><given-names>MM</given-names></name><name><surname>Hanks</surname><given-names>TD</given-names></name><name><surname>Yoon</surname><given-names>AM</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Causal contribution and dynamical encoding in the striatum during evidence accumulation</article-title><source>eLife</source><volume>7</volume><elocation-id>e34929</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.34929</pub-id><pub-id pub-id-type="pmid">30141773</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zoltowski</surname><given-names>DM</given-names></name><name><surname>Latimer</surname><given-names>KW</given-names></name><name><surname>Yates</surname><given-names>JL</given-names></name><name><surname>Huk</surname><given-names>AC</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Discrete stepping and nonlinear ramping dynamics underlie spiking responses of LIP neurons during decision-making</article-title><source>Neuron</source><volume>102</volume><fpage>1249</fpage><lpage>1258</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.04.031</pub-id><pub-id pub-id-type="pmid">31130330</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Zoltowski</surname><given-names>D</given-names></name><name><surname>Pillow</surname><given-names>J</given-names></name><name><surname>Linderman</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A general recurrent state space framework for modeling neural dynamics during decision-making</article-title><conf-name>Proceedings of the 37th International Conference on Machine Learning, Proceedings of Machine Learning Research</conf-name><fpage>11680</fpage><lpage>11691</lpage></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zylberberg</surname><given-names>A</given-names></name><name><surname>Fetsch</surname><given-names>CR</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The influence of evidence volatility on choice, reaction time and confidence in a perceptual decision</article-title><source>eLife</source><volume>5</volume><elocation-id>e17688</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.17688</pub-id><pub-id pub-id-type="pmid">27787198</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.84955.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Forstmann</surname><given-names>Birte U</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04dkp9463</institution-id><institution>University of Amsterdam</institution></institution-wrap><country>Netherlands</country></aff></contrib></contrib-group></front-stub><body><p>This valuable paper presents findings showing that different brain regions were best described by a distinct accumulation model, which all differed from the model that best described the rat's choices. These findings are solid because the authors present a very strong methodological approach. This work will be of interest to a wide neuroscientific audience.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.84955.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Forstmann</surname><given-names>Birte U</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04dkp9463</institution-id><institution>University of Amsterdam</institution></institution-wrap><country>Netherlands</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Turner</surname><given-names>Brandon</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00rs6vg23</institution-id><institution>The Ohio State University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2021.10.28.465122">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.10.28.465122v2">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Neural population dynamics underlying evidence accumulation in multiple rat brain regions&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Michael Frank as the Senior Editor. The following individual involved in the review of your submission has agreed to reveal their identity: Brandon Turner (Reviewer #1).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions (for the authors):</p><p>1. I found some of the decisions about the model development to be somewhat unusual, and I wondered whether the results hinged on these assumptions. To be clear, I am fine with unusual, but I was not clear how the authors came to the decisions they made. I think it would be better to describe why some decisions were made. For example, Equation 1 uses both the sum and difference of the evidence directly in the accumulation dynamics, but I wonder why the authors used this expression and not the standard DDM. It was also unclear why leakage was added in this way (where λ can be negative) for a model that uses a two-boundary setup (i.e., a non-racing accumulator structure). Other unusual things were the step function combined with a contaminant process (lapse) to relate to a probability of choice and a softplus function for the neural activity (Equations 2 and 3). Because these were choices I was unfamiliar with, I wondered where they were from and whether their incorporation had any impact on the results.</p><p>2. I also felt that the paper was lacking some connection to other joint modeling efforts that use trial-by-trial parameters to link neural and behavioral data. These are not quite the same as the authors' approach, but it could be good to link to those many lines of research to leave some 'breadcrumbs' for other researchers who are interested in modeling brain-behavior links.</p><p>3. Why are there two absorbing bounds, one for a(t) and one for the choice criterion? Evidence accumulation models typically impose an absorbing bound for (an analogue of) a(t), and assume a choice is made when that bound is reached. Can the authors clarify the purpose of deviating from this assumption?</p><p>4. Page 13: Reference to Figure 4A might mean 4B.</p><p>5. Equations 10-11: I'm wondering to what extent there might be a collinearity issue here. These models allow firing rates to vary over time as a function of two mechanisms: \theta_{n}a_t, which is time-varying because a varies over time; and \theta_{n,t}^{0}, which is time-varying by itself through equation 11. I was wondering: If firing rates indeed covary with a, then doesn't the model have two options to model this: both via \theta_{n} and via \theta_{n,t}^0?</p><p>This point is especially relevant for the section on the independent noise accumulator models, where \theta_{y} is fit for every neuron individually, and as such, these parameters are informed by relatively little information which might increase the uncertainty on these parameters. Are the results shown in Figure 4B not potentially an overfitting issue? A related question here pertains to the cross-validation procedure: How exactly are the data partitioned? If the parameters fit on the individual neuron level, then the split between train and test data should only split trials of the same neurons (under the independent noise model, \theta_{1,T} cannot be expected to predict \theta_{2,T}, as these are different neurons, I would think? Or am I missing something?).</p><p>6. Page 39: were the bounds of optimization ever reached?</p><p>7. Null joint model: This is related to the point above, but I'm not sure if Figure S9B (referred to on page 42) actually shows the results of this model. I was indeed wondering how well this model cross-validates, in light of the potential collinearity issue raised in point 3 above.</p><p>8. Figure S9A: I don't see '+'-symbols.</p><p>9. Typos.</p><p>Page 21, Figure S1C title: &quot;Example recovered parameters&quot; (missing e in parameters).</p><p>Page 36: &quot;The transition matrix M(θa, δt) it is determined using methods established in Brunton (2013)&quot;. &quot;it&quot; should probably be removed.</p><p>10. Code availability:</p><p>The authors state they will make the code publicly accessible upon publication. It would be useful to include a persistent link (to e.g. osf or github) in the manuscript to facilitate finding the manuscript after it has been published. The code itself could still remain under embargo as long as the review lasts, should the authors prefer this.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.84955.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions (for the authors):</p><p>1. I found some of the decisions about the model development to be somewhat unusual, and I wondered whether the results hinged on these assumptions. To be clear, I am fine with unusual, but I was not clear how the authors came to the decisions they made. I think it would be better to describe why some decisions were made. For example, Equation 1 uses both the sum and difference of the evidence directly in the accumulation dynamics, but I wonder why the authors used this expression and not the standard DDM. It was also unclear why leakage was added in this way (where λ can be negative) for a model that uses a two-boundary setup (i.e., a non-racing accumulator structure). Other unusual things were the step function combined with a contaminant process (lapse) to relate to a probability of choice and a softplus function for the neural activity (Equations 2 and 3). Because these were choices I was unfamiliar with, I wondered where they were from and whether their incorporation had any impact on the results.</p></disp-quote><p>Our apologies for the lack of clarity. In equation (1), we should have clarified how our choices are closer to the standard DDM than they might appear. Our motivation for selecting the parameters of the latent accumulator as we did was the findings presented in Brunton et al. 2013. In this study, the authors fit an identical model to the choices of rats and humans performing the same pulse-based evidence accumulation task and found that the model was sufficiently flexible to characterize the variety of behavioral strategies they employed (see Figure 2E-J of Brunton et al. 2013). For this reason, we felt it also presented an appropriate and flexible starting point for considering how well neural activity reflected accumulation dynamics. Fitting this model jointly to neural activity and choices, or choices alone, allowed us to understand how incorporating neural responses into the model compared to the existing literature related to this model and rat behavior. We now state this motivation more explicitly:</p><p>“The essence of our model is to describe a DDM-based accumulation process driven by sensory stimuli following Brunton et al., 2013 and relate the latent accumulation process to both neural responses and the rat’s choice. Previous results have shown that this model is sufficiently flexible to accommodate the various behavioral strategies rats exhibit while performing this task (Brunton et al., 2013).”</p><p>Regarding why the sum and difference were used, the difference reflects the moment to moment evidence in favor of a choice (left vs. right) while the sum is necessary to ensure that the magnitude of the sensory noise scales with the number of sensory pulses experienced at each moment in time. We now explain this more carefully:</p><p>“The final term, <inline-formula><mml:math id="sa2m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>η</mml:mi><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, introduces noise into <italic>a(t)</italic> that is proportional to the total number of clicks that occur at a given moment. The sum of clicks <inline-formula><mml:math id="sa2m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is included so that the magnitude of the noise increases depending on the number of sensory clicks experienced at time <italic>t</italic>.”</p><p>Regarding the leak term, again following Brunton, we wanted to allow the model the flexibility to fit the various behavioral strategies that rats were found to exhibit, including leaky accumulation (negative λ) and impulsive decision-making (positive λ). This proved to be crucial, as we found that the FOF was best described by a positive λ, an intriguing feature of the data that would have been otherwise overlooked. We have modified the text to indicate this:</p><p>“Previous results have shown that rats exhibit a range of accumulation strategies spanning these values of <inline-formula><mml:math id="sa2m3"><mml:mi id="c9094cb1-b51f-4557-8058-323e1a58166e">λ</mml:mi></mml:math></inline-formula> (Brunton et al., 2013).”</p><p>Regarding the step function with lapses to model choice, in our experience, this choice is standard: a step function being the deterministic discriminant to map a continuous variable (accumulated evidence) to a binary choice, and lapses being the standard method for modeling choices that do not depend on the stimulus. An alternative way to view this choice is as an infinitely steep logistic function. These choices were based on the approach of Brunton et al. We have modified the text to explain our choice:</p><p>“Previous work has found that parameterizing choice this way creates a model that is sufficiently flexible to describe animals’ choice (Brunton et al., 2013) while remaining as simple as possible.”</p><p>The softplus function for determining neural activity is a standard choice in our experience. The softplus function is often chosen when relating a variable of interest to the spike count of a neuron because it is the simplest rectified function that is differentiable (it is a differentiable approximation to a rectified-linear function). The work that is most related to our is Latimer et al. 2015 which uses a softplus. We have modified the text to explain our choice:</p><p>“The softplus function (smooth rectified linear function) was used to ensure the expected firing rate was positive, and was selected because it is the simplest function to achieve this goal, and also based on prior success in similar studies (e.g., Latimer et al. 2015).”</p><disp-quote content-type="editor-comment"><p>2. I also felt that the paper was lacking some connection to other joint modeling efforts that use trial-by-trial parameters to link neural and behavioral data. These are not quite the same as the authors' approach, but it could be good to link to those many lines of research to leave some 'breadcrumbs' for other researchers who are interested in modeling brain-behavior links.</p></disp-quote><p>We thank the reviewers for catching this and we apologize for failing to link our work to important existing results. We have added a paragraph to the Discussion section highlighting these works, including several new references, and how they relate to our results:</p><p>“Our approach extends and complements existing approaches that construct formal mathematical models of decision making which combine both behavioral data and neural data. These models leverage both neural and behavioral observations to jointly infer decision making parameters, as we’ve done here (see Turner et al., 2019 for a comprehensive overview). However, the majority of these approaches have tended to emerge from the field of cognitive neuroscience, and as such, have predominantly focused on models for application to neural data acquired by other methods, such as EEG, fMRI, etc. (e.g., Turner et al. 2015; but also see Frank et al., 2015). Our approach adds to these efforts by offering a method that can combine fine timescale single unit recordings with behavioral measurements specifically during pulse-based evidence accumulation tasks, thereby offering a moment-by-moment picture into the latent dynamics that underlies cognition. Continued development of joint models such as our and existing approaches in the field of cognitive neuroscience are critical to quantitatively understand the latent processes underlying cognition.”</p><p>New References:</p><p>Turner, B.M., Forstmann, B.U., Steyvers, M, 2019. Joint Models of Neural and Behavioral Data, Springer International Publishing.</p><p>Turner BM, van Maanen L, Forstmann BU. Informing cognitive abstractions through neuroimaging: the neural drift diffusion model. Psychol Rev. 2015 Apr;122(2):312-336. doi: 10.1037/a0038894. PMID: 25844875.</p><p>Frank MJ, Gagne C, Nyhus E, Masters S, Wiecki TV, Cavanagh JF, Badre D. 2015. fMRI and EEG predictors of dynamic decision parameters during human reinforcement learning. J Neurosci. 2015 Jan 14;35(2):485-94. doi: 10.1523/JNEUROSCI.2036-14.2015. PMID: 25589744; PMCID: PMC4293405.</p><disp-quote content-type="editor-comment"><p>3. Why are there two absorbing bounds, one for a(t) and one for the choice criterion? Evidence accumulation models typically impose an absorbing bound for (an analogue of) a(t), and assume a choice is made when that bound is reached. Can the authors clarify the purpose of deviating from this assumption?</p></disp-quote><p>We apologize for the confusion. There is only a single symmetric absorbing boundary that dictates the dynamics of <italic>a(t)</italic>. It has a magnitude of <italic>B</italic> and there are boundaries at +<italic>B</italic> and -<italic>B</italic>. A choice commitment is made when the bound is reached. We have modified the text to explain this more clearly:</p><p>“As described above, when <italic>a(t)</italic> crosses the decision bound <italic>B</italic> a choice commitment is made, either to the left or the right, and no further evidence accumulation occurs.”</p><disp-quote content-type="editor-comment"><p>4. Page 13: Reference to Figure 4A might mean 4B.</p></disp-quote><p>Thank you, we have made this correction.</p><disp-quote content-type="editor-comment"><p>5. Equations 10-11: I'm wondering to what extent there might be a collinearity issue here. These models allow firing rates to vary over time as a function of two mechanisms: \theta_{n}a_t, which is time-varying because a varies over time; and \theta_{n,t}^{0}, which is time-varying by itself through equation 11. I was wondering: If firing rates indeed covary with a, then doesn't the model have two options to model this: both via \theta_{n} and via \theta_{n,t}^0?</p></disp-quote><p>Thank you for bringing up this subtle issue. <inline-formula><mml:math id="sa2m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="sa2m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> are not collinear, and are both identifiable because the trajectory of <inline-formula><mml:math id="sa2m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> varies from trial to trial (via its dependence on the stimulus) whereas <inline-formula><mml:math id="sa2m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> does not. The <inline-formula><mml:math id="sa2m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> term captures the component of time-varying firing rate that depends on the arrival times of the clicks in any given trial. (For example, a trial with no clicks present will have the <inline-formula><mml:math id="sa2m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> term but the <inline-formula><mml:math id="sa2m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> term will be zero). Because of this <inline-formula><mml:math id="sa2m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> will capture changes in firing rate specific to an individual trials accumulated evidence while <inline-formula><mml:math id="sa2m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> will only capture changes in firing rate that occur in time on <italic>all</italic> trials, regardless of the stimulus.</p><p>To reassure the reviewers, we conducted two numerical experiments. First, we simulated data from a simplified model in which <italic>a(t)</italic> was sampled from a Wiener process, i.e. a Gaussian random walk, for <italic>T</italic> timepoints and across a set of <italic>K</italic> trials (see Author response image 2). This is a logical simplification of our more complicated model because a random walk assumes perfect integration of a Gaussian random variable as an input. In other words, we are making two simplifications from our more complicated model: integration is perfect and the inputs are Gaussian not Poisson. We modeled the trial-dependent term of the expected firing rate (i.e., <inline-formula><mml:math id="sa2m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>) with <inline-formula><mml:math id="sa2m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> and the trial-independent term as a linear function with one parameter: i.e. <inline-formula><mml:math id="sa2m15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. These simplifications are not likely to alter the core finding. We computed the Pearson correlation between <italic>a(t)</italic> and <italic>t</italic> for all <italic>K</italic> trials: it was roughly 0, i.e. uncorrelated. The pseudocode (<xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>) recapitulates the simplified model:</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84955-sa2-fig1-v3.tif"/></fig><p><xref ref-type="fig" rid="sa2fig2">Author response image 2</xref> is an image of the simulated data, in which the computed correlation was -0.003:</p><fig id="sa2fig2" position="float"><label>Author response image 2.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84955-sa2-fig2-v3.tif"/></fig><p>Thus in this simplified model we found that these two temporal components were not conlinear. Again the central reason for this is that <italic>a(t)</italic> varies across trials while <inline-formula><mml:math id="sa2m16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> does not.The second experiment was to examine if generative parameters could be uniquely recovered. To do this, we assumed an expected firing rate of a neuron as we did in our model, but assumed the simplified form for the underlying processes, i.e., <italic>a(t)</italic> was as a Gaussian random walk and the expected firing rate was determined by <inline-formula><mml:math id="sa2m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mrow><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>θ</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mrow><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. We found that when we simulated data with known values of <inline-formula><mml:math id="sa2m18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>θ</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="sa2m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mtext> </mml:mtext><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> that they could be reliably recovered.</p><p>To compactly summarize these finding in the manuscript, we have added the following text to the Methods:</p><p>“Although both <inline-formula><mml:math id="sa2m20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="sa2m21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> vary in time to define each neuron’s expected firing rate, they are uniquely identifiable, because <inline-formula><mml:math id="sa2m22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> varies from trial to trial depending on the stimulus while <inline-formula><mml:math id="sa2m23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> does not. We verified through numerical experimentation and parameter recovery using synthetic data that each process can be identified.”</p><disp-quote content-type="editor-comment"><p>This point is especially relevant for the section on the independent noise accumulator models, where \theta_{y} is fit for every neuron individually, and as such, these parameters are informed by relatively little information which might increase the uncertainty on these parameters. Are the results shown in Figure 4B not potentially an overfitting issue?</p></disp-quote><p>In light of the above analysis, we believe the same argument will hold for the independent noise model. Additionally, we do not believe overfitting to be an issue for this model, in the way that the reviewer is concerned about, because both models have an identical number of parameters, a point that we perhaps explained poorly and may have been misunderstood by the reviewer. We have modified the relevant text to make this more clear.</p><p>“It is worth emphasizing that the independent noise model is identical to the shared noise model in the way it is parameterized (i.e. number and form of the model parameters) but only differs in the structure of the latent accumulation noise.”</p><disp-quote content-type="editor-comment"><p>A related question here pertains to the cross-validation procedure: How exactly are the data partitioned? If the parameters fit on the individual neuron level, then the split between train and test data should only split trials of the same neurons (under the independent noise model, \theta_{1,T} cannot be expected to predict \theta_{2,T}, as these are different neurons, I would think? Or am I missing something?).</p></disp-quote><p>This is a good question, thank you for bringing it up. We have added the following text to the Methods section to better explain our cross-validation procedure.</p><p>“Because most of our models were fit simultaneously to data from multiple experimental sessions (in which different neurons are recorded), to perform cross-validation, we randomly divided trials within each session into a train and test set, and trained and tested the model collectively on those groups of trials. Testing the model in this way will determine parameter robustness across all sessions (for model parameters that are shared across all sessions) and individual parameter robustness within a session (for parameters that are specific to an individual session). This procedure also worked for the ‘independent noise model’, for which model parameters were shared across all sessions, but individual neuron parameters were session specific.”</p><disp-quote content-type="editor-comment"><p>6. Page 39: were the bounds of optimization ever reached?</p></disp-quote><p>The bounds were occasionally reached for specific datasets, and common themes emerged for the different models (e.g., fitting to choice only, or a jointly fit model) about when the bounds were reached. We have augmented the relevant section to make note of this finding:</p><p>“The occurrence of parameters hitting the bound can be seen in Figure 3 &amp; Figure 3 — figure supplement 4. The most common boundary hitting situation was a variance parameter (<inline-formula><mml:math id="sa2m24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="sa2m25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="sa2m26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) hitting the lower boundary of zero, which means that the model did not support noise of that kind in the model fit. <inline-formula><mml:math id="sa2m27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="sa2m28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> were found to do this for the choice only model, consistent with the results of Brunton et al. The other bound that was frequently hit was the upper bound for the accumulation bound parameter <italic>B</italic>, a result also consistent with the results of Brunton et al. The log-likelihood surface as <italic>B</italic> grows very large becomes very flat, because it becomes increasingly unlikely that probability mass <italic>P(a(t))</italic> crosses the boundary. Thus, the model fits do not change appreciably if this optimization boundary is relaxed.”</p><disp-quote content-type="editor-comment"><p>7. Null joint model: This is related to the point above, but I'm not sure if Figure S9B (referred to on page 42) actually shows the results of this model. I was indeed wondering how well this model cross-validates, in light of the potential collinearity issue raised in point 3 above.</p></disp-quote><p>We apologize for the confusion here. Figure S9B (now titled Figure 3 — figure supplement 4) does not explicitly show the results of the null joint model. It compares the model fit improvement of each model over a null model when using subsets of the data (as one would do during multi-fold cross-validation) to the model fit improvement when using all of the data. The purpose of doing this is to justify our choice of illustrating results (e.g. parameters and data synthesize from best fitting models) from models fit to <italic>all</italic> the data. (In other words, any model fit to subsets of the data does not differ appreciably to a model fit to <italic>all</italic> the data.) Figure S9B only shows the results of the null joint model in the sense that it less accurately captures the data compared to the fitted joint model (i.e. the log likelihood is greater than zero for the joint model).</p><p>Figure S9B does illustrate that the joint model cross-validates well, i.e., the cross-validated log likelihood per fold when comparing the joint model to the null model is greater than zero, indicating that the joint model is not overparameterized, consistent with our discussion and analysis of this issue in point 5. We believe this provides strong evidence that our null models were appropriately designed — our model justifies the use of the additional parameters our model provides. We have added text relevant to the joint models regarding this point to the Methods:</p><p>“The improved performance (i.e. cross-validated log likelihood) of our joint model over the null model shown in Figure 3 — figure supplement 4 further confirms that <inline-formula><mml:math id="sa2m29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>a</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="sa2m30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> are uniquely identifiable, and that they are not redundant (i.e. the joint model is not overparameterized).”</p><disp-quote content-type="editor-comment"><p>8. Figure S9A: I don't see '+'-symbols.</p></disp-quote><p>We have modified the figure so what was formerly a ‘+” is now a diamond, which is easier to see.</p><disp-quote content-type="editor-comment"><p>9. Typos.</p><p>Page 21, Figure S1C title: &quot;Example recovered parameters&quot; (missing e in parameters).</p><p>Page 36: &quot;The transition matrix M(θa, δt) it is determined using methods established in Brunton (2013)&quot;. &quot;it&quot; should probably be removed.</p></disp-quote><p>Thank you — corrected!</p><disp-quote content-type="editor-comment"><p>10. Code availability:</p><p>The authors state they will make the code publicly accessible upon publication. It would be useful to include a persistent link (to e.g. osf or github) in the manuscript to facilitate finding the manuscript after it has been published. The code itself could still remain under embargo as long as the review lasts, should the authors prefer this.</p></disp-quote><p>We strongly agree with the reviewers. We have updated our code availability statement to reflect the persistent links to the core codebase for fitting models described, and a second repository for reproducing the results of the manuscript.</p></body></sub-article></article>