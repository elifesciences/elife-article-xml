<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">77430</article-id><article-id pub-id-type="doi">10.7554/eLife.77430</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A partially nested cortical hierarchy of neural states underlies event segmentation in the human brain</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-107170"><name><surname>Geerligs</surname><given-names>Linda</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1624-8380</contrib-id><email>Linda.Geerligs@donders.ru.nl</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-271753"><name><surname>Gözükara</surname><given-names>Dora</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-271754"><name><surname>Oetringer</surname><given-names>Djamari</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-155910"><name><surname>Campbell</surname><given-names>Karen L</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-113897"><name><surname>van Gerven</surname><given-names>Marcel</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2206-9098</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-271755"><name><surname>Güçlü</surname><given-names>Umut</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/016xsfp80</institution-id><institution>Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen</institution></institution-wrap><addr-line><named-content content-type="city">Nijmegen</named-content></addr-line><country>Netherlands</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/056am2717</institution-id><institution>Department of Psychology, Brock University</institution></institution-wrap><addr-line><named-content content-type="city">St. Catharines</named-content></addr-line><country>Canada</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Badre</surname><given-names>David</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>16</day><month>09</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e77430</elocation-id><history><date date-type="received" iso-8601-date="2022-02-03"><day>03</day><month>02</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2022-09-14"><day>14</day><month>09</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2021-02-05"><day>05</day><month>02</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.02.05.429165"/></event></pub-history><permissions><copyright-statement>© 2022, Geerligs et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Geerligs et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-77430-v2.pdf"/><abstract><p>A fundamental aspect of human experience is that it is segmented into discrete events. This may be underpinned by transitions between distinct neural states. Using an innovative data-driven state segmentation method, we investigate how neural states are organized across the cortical hierarchy and where in the cortex neural state boundaries and perceived event boundaries overlap. Our results show that neural state boundaries are organized in a temporal cortical hierarchy, with short states in primary sensory regions, and long states in lateral and medial prefrontal cortex. State boundaries are shared within and between groups of brain regions that resemble well-known functional networks. Perceived event boundaries overlap with neural state boundaries across large parts of the cortical hierarchy, particularly when those state boundaries demarcate a strong transition or are shared between brain regions. Taken together, these findings suggest that a partially nested cortical hierarchy of neural states forms the basis of event segmentation.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>event segmentation</kwd><kwd>naturalistic viewing</kwd><kwd>fMRI</kwd><kwd>timescales</kwd><kwd>functional networks</kwd><kwd>hierarchy</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003246</institution-id><institution>Nederlandse Organisatie voor Wetenschappelijk Onderzoek</institution></institution-wrap></funding-source><award-id>VI.Vidi.201.150</award-id><principal-award-recipient><name><surname>Geerligs</surname><given-names>Linda</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000038</institution-id><institution>Natural Sciences and Engineering Research Council of Canada</institution></institution-wrap></funding-source><award-id>RGPIN-2017-03804</award-id><principal-award-recipient><name><surname>Campbell</surname><given-names>Karen L</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The ongoing stream of information that comes in through our senses is segmented into distinct neural states at each level of the cortical hierarchy, which underpins our experience of distinct events.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Segmentation of information into meaningful units is a fundamental feature of our conscious experience in real-life contexts. Spatial information processing is characterized by segmenting spatial regions into objects (e.g., <xref ref-type="bibr" rid="bib22">DiCarlo and Cox, 2007</xref>). In a similar way, temporal information processing is characterized by segmenting our ongoing experience into separate events (<xref ref-type="bibr" rid="bib43">Kurby and Zacks, 2008</xref>; <xref ref-type="bibr" rid="bib53">Newtson et al., 1977</xref>). Segmentation improves our understanding of ongoing perceptual input (<xref ref-type="bibr" rid="bib82">Zacks et al., 2001a</xref>) and allows us to recall distinct events from our past (<xref ref-type="bibr" rid="bib25">Flores et al., 2017</xref>; <xref ref-type="bibr" rid="bib63">Sargent et al., 2013</xref>; <xref ref-type="bibr" rid="bib84">Zacks et al., 2006</xref>). Recent work has shown that the end of an event triggers an evoked response in the hippocampus (<xref ref-type="bibr" rid="bib4">Baldassano et al., 2017</xref>; <xref ref-type="bibr" rid="bib8">Ben-Yakov and Henson, 2018</xref>), suggesting that events form the basis of long-term memory representations. Events that are identified in written, auditory, and audiovisual narratives (movies) are often very similar across individuals and can be segmented hierarchically on different timescales (<xref ref-type="bibr" rid="bib54">Newtson and Rindner, 1979</xref>; <xref ref-type="bibr" rid="bib82">Zacks et al., 2001a</xref>). According to event segmentation theory (EST), perceptual systems spontaneously segment activity into meaningful events as a side effect of predicting future information (<xref ref-type="bibr" rid="bib85">Zacks et al., 2007</xref>). That is, event boundaries are perceived when predictions become less accurate, which can be due to a change in motion or features of the situation such as characters, causes, goals, and spatial location (<xref ref-type="bibr" rid="bib86">Zacks et al., 2009</xref>). However, event boundaries are observed even when a change is predictable, suggesting that other mechanisms play a role (<xref ref-type="bibr" rid="bib56">Pettijohn and Radvansky, 2016</xref>). One proposal is that experiences are grouped into categories (or event types), which we have learned previously. When a new event type is detected, an event boundary occurs (<xref ref-type="bibr" rid="bib65">Shin and DuBrow, 2021</xref>).</p><p>While much is known about temporal event segmentation at a behavioral level, less is known about its neural underpinnings. A number of studies have investigated which brain regions show evoked responses around event boundaries. Although the exact regions vary across studies, commonly identified regions include the precuneus and medial visual cortex, as well as area V5 and the intraparietal sulcus (<xref ref-type="bibr" rid="bib44">Kurby and Zacks, 2018</xref>; <xref ref-type="bibr" rid="bib68">Speer et al., 2007</xref>; <xref ref-type="bibr" rid="bib83">Zacks et al., 2001b</xref>; <xref ref-type="bibr" rid="bib87">Zacks et al., 2010</xref>). Increased brain responses at event boundaries in these regions likely reflect updating processes that occur when shifting to a new event model (<xref ref-type="bibr" rid="bib24">Ezzyat and Davachi, 2011</xref>). Recently, a different approach has been introduced to investigate the neural underpinnings of event segmentation (<xref ref-type="bibr" rid="bib4">Baldassano et al., 2017</xref>). These authors applied a data-driven method, based on hidden Markov models (HMMs) to functional magnetic resonance imaging (fMRI) data obtained during movie watching to identify timepoints where brain activity in a particular region transitioned from one temporarily stable activity pattern to a different pattern. We refer to these periods of relative stability as neural states to distinguish them from subjectively perceived events (<xref ref-type="bibr" rid="bib28">Geerligs et al., 2021</xref>; <xref ref-type="bibr" rid="bib85">Zacks et al., 2007</xref>).</p><p>These neural states occur on different timescales across the cortical hierarchy, with short-lived states in early sensory regions and long-lasting states in higher-level regions such as the precuneus and angular gyrus (<xref ref-type="bibr" rid="bib4">Baldassano et al., 2017</xref>), in line with previous observations of a temporal hierarchy of information processing in the brain (<xref ref-type="bibr" rid="bib35">Hasson et al., 2008</xref>; <xref ref-type="bibr" rid="bib39">Honey et al., 2012</xref>; <xref ref-type="bibr" rid="bib49">Lerner et al., 2011</xref>; <xref ref-type="bibr" rid="bib69">Stephens et al., 2013</xref>). Interestingly, for a set of four brain regions, <xref ref-type="bibr" rid="bib4">Baldassano et al., 2017</xref> showed that neural state boundaries overlapped across different regions and with subjectively experienced event boundaries. These results suggest that neural state segmentation could be the source of perceived event boundaries and that states may be organized in a nested cortical hierarchy, such that the boundaries of faster states in regions lower in the cortical hierarchy are nested within the boundaries of slower regions higher up in the hierarchy. In such a nested hierarchy, each brain region integrates information within discretized neural states that may align with sensory units in the external environment (e.g., phonemes, words, sentences) and provide its output to the brain regions higher in the cortical hierarchy (<xref ref-type="bibr" rid="bib52">Nelson et al., 2017</xref>), until neural states at the highest level of the hierarchy align with subjectively experienced events. This way information traveling up the hierarchy is gradually integrated into complex and long-lasting multimodal representations (<xref ref-type="bibr" rid="bib37">Hasson et al., 2015</xref>). Although this is an intriguing hypothesis, the evidence for it is limited, as it has only been investigated in one previous study using four predefined regions of interest (<xref ref-type="bibr" rid="bib4">Baldassano et al., 2017</xref>). In addition, it remains unknown which brain regions show neural state boundaries that align with perceived event boundaries and the temporal hierarchy of state segmentation remains unexplored across large parts of the cortex.</p><p>This study had two main aims. First, to investigate whether event segmentation is indeed underpinned by neural state segmentation occurring in a nested cortical hierarchy. Second, to characterize the temporal hierarchy of neural state segmentation across the entire cortex. If the brain segments ongoing input in a nested hierarchical fashion, we would expect to find especially long-lasting neural states in the frontal cortex, which is often considered the top of the cortical hierarchy (<xref ref-type="bibr" rid="bib26">Fuster, 2001</xref>). We would also expect to find overlap between neural state boundaries and event boundaries across all levels of the cortical hierarchy, although this overlap should be most consistent for areas at higher levels of the hierarchy where the timescales of neural state segmentation should closely match the experienced timescale of events. Finally, we would expect that state boundaries are most strongly shared between groups of brain regions involved in similar cognitive functions (i.e., networks) and to a lesser extent between more distinct sets of brain areas.</p><p>To test these hypotheses, we used a novel data-driven state segmentation method that was specifically designed to reliably detect boundaries between distinct neural states (<xref ref-type="bibr" rid="bib28">Geerligs et al., 2021</xref>). By using a large movie fMRI dataset from the Cam-CAN project (<xref ref-type="bibr" rid="bib64">Shafto et al., 2014</xref>) that shows reliable stimulus-driven activity (i.e., significant inter-subject correlations) over nearly all cortical brain regions (<xref ref-type="bibr" rid="bib15">Campbell et al., 2015</xref>; <xref ref-type="bibr" rid="bib27">Geerligs and Campbell, 2018</xref>), we were able to study neural state segmentation across the entire cortex for the first time. In comparison to previous work, we investigate state segmentation in a more focused and extensive way by identifying the degree of change moving from one neural state to the next (i.e., boundary strength) and examining relationships between neural state boundaries across functional networks.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>To identify neural state boundaries, we applied an improved version of the greedy state boundary search (GSBS; <xref ref-type="bibr" rid="bib28">Geerligs et al., 2021</xref>) to a large fMRI dataset in which 265 participants (aged 18–50 years) viewed an 8 min Alfred Hitchcock movie (<xref ref-type="bibr" rid="bib64">Shafto et al., 2014</xref>). After hyperaligning the data (<xref ref-type="bibr" rid="bib32">Guntupalli et al., 2016</xref>) and hemodynamic deconvolution, GSBS was applied to multi-voxel brain activity time courses from overlapping spherical searchlights covering the entire cortex. GSBS identifies a set of neural state boundaries for each searchlight and for different numbers of states (<italic>k</italic>). GSBS then uses the t-distance metric to identify the optimal number of state boundaries in each searchlight (<xref ref-type="bibr" rid="bib28">Geerligs et al., 2021</xref>). This metric identifies the optimal number of state boundaries such that the Pearson correlations (across voxels) of timepoints within a state are maximized and correlations of timepoints in consecutive states are minimized. To optimize the validity and reliability of the neural states detected by GSBS, we improved the algorithm in several ways, as shown in the ‘Supplementary methods’ section in Appendix 1. Searchlights in which we were unable to identify reliable neural state boundaries were excluded from further analysis (see <xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5</xref>). Searchlight-level results were projected to the voxel level by averaging results across overlapping searchlights.</p><p>The median duration of neural states differed greatly between brain regions, ranging from 4.5 s in the voxels with shortest states up to 27.2 s in the voxels with the longest states (see <xref ref-type="fig" rid="fig1">Figure 1A</xref>). Most voxels showed median state durations between 5.1 and 18.5 s per state. To determine whether regional differences in state duration were reliable, neural state boundaries were identified in two independent groups of participants. At the voxel level, there was a very high Pearson correlation between the median state durations of the two groups (<italic>r</italic> = 0.85; see <xref ref-type="fig" rid="fig1">Figure 1A</xref>). This correlation was lower when we computed it at the level of searchlights (i.e., before projecting to the voxel level; <italic>r</italic> = 0.62). This suggests that regional differences in neural state timescales are highly reliable across participant groups and that the variability present in specific searchlights can be reduced substantially by averaging across overlapping searchlights. The timing of neural state boundaries was not associated with head motion (see ‘Supplementary results’ in Appendix 1).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>The cortical hierarchy of neural state durations.</title><p>(<bold>A</bold>) The optimal number of states varied greatly across regions, with many shorter states in the primary visual, auditory, and sensorimotor cortices and few longer states in the association cortex, such as the medial and lateral prefrontal gyrus. These results are highly consistent across two independent groups of participants. Parts of the correlation matrices for two selected searchlights are shown in the insets for each of the groups, representing approximately 1.6 min of the movie. The white lines in these insets are the neural state boundaries that are detected by greedy state boundary search (GSBS). (<bold>B</bold>) The variability in state durations, as quantified by the interquartile range (IQR)/median state duration, was particularly high in the middle and superior temporal gyri and the anterior insula.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77430-fig1-v2.tif"/></fig><p><xref ref-type="fig" rid="fig1">Figure 1A</xref> shows that there were particularly short neural states in visual cortex, early auditory cortex, and somatosensory cortex. State transitions were less frequent in areas further up cortical hierarchy, such as the angular gyrus, areas in posterior middle/inferior temporal cortex, precuneus, the anterior temporal pole, and anterior insula. Particularly long-lasting states were observed in high-level regions such as the medial prefrontal gyrus and anterior portions of the lateral prefrontal cortex, particularly in the left hemisphere.</p><p>We also investigated how the variability of state durations differed across the cortex. Because variability of state duration, as measured by the interquartile range (IQR), tends to increase as the median state duration increases, we used a nonparametric alternative to the coefficient of variation (IQR divided by the median). We found very pronounced variability in state durations in the middle and superior temporal gyri and the anterior insula, while the variability was consistently lower in all other cortical areas. This effect was highly reliable across the two independent groups of participants (<italic>r</italic> = 0.84 at voxel level; <italic>r</italic> = 0.54 at the searchlight level).</p><sec id="s2-1"><title>Neural states and perceived event boundaries</title><p>In a nested cortical hierarchy, some boundaries at lower levels of the cortical hierarchy are thought to propagate to higher levels of the hierarchy until they are consciously experienced as event boundaries. Therefore, we would expect state boundaries to align with perceived event boundaries across all of the different levels of the hierarchy. The most consistent alignment would be expected in higher-level cortical areas where the number of states should more closely align with the number of perceived events. Event boundaries were determined by asking participants to indicate when they felt one event (meaningful unit) ended and another began (<xref ref-type="bibr" rid="bib8">Ben-Yakov and Henson, 2018</xref>). To determine the similarity between neural state boundaries and perceived event boundaries, we computed the absolute boundary overlap. This is defined as the number of timepoints where neural state and perceived event boundaries overlapped, scaled such that the measure is one when all neural state boundaries align with a perceived event boundary and zero when the overlap is equal to the overlap that would be expected given the number of boundaries.</p><p>We found that a large number of brain regions, throughout the cortical hierarchy, showed significant absolute boundary overlap between neural states and perceived event boundaries after false discovery rate (FDR) correction for multiple comparisons (see <xref ref-type="fig" rid="fig2">Figure 2A</xref>). In particular, we observed that the anterior cingulate cortex, dorsal medial prefrontal cortex, left superior and middle frontal gyrus, and anterior insula show the strongest absolute overlap between neural state boundaries and perceived boundaries. This suggests that neural state boundaries in these regions are most likely to underlie the experience of an event boundary.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Overlap between neural state and event boundaries.</title><p>(<bold>A</bold>) Absolute boundary overlap between neural state boundaries and the perceived event boundaries identified by a different group of participants outside the scanner. The metric is scaled between zero (expected overlap) and one (all neural state boundaries overlap with an event boundary). The medial prefrontal cortex, anterior insula, anterior cingulate cortex, and left superior and middle frontal gyrus show the strongest alignment between neural state boundaries and perceived event boundaries. (<bold>B</bold>) Relative overlap between neural state boundaries and perceived event boundaries (scaled w.r.t. the maximal possible overlap given the number of neural state boundaries). Regions in different parts of the cortical hierarchy (early and late) show a significant association between the neural state boundaries and perceived event boundaries. (<bold>C</bold>) Increase in absolute overlap between neural state boundaries and event boundaries when neural state boundaries are weighted by their strengths, in comparison to using binary boundaries (as in <bold>A</bold>). Regions with strong neural state boundaries (i.e., a large change between successive states) were more likely to overlap with perceived event boundaries than weak boundaries. Statistical analyses for (<bold>A–C</bold>) were based on data from 15 independent groups of participants, the depicted difference/overlap values were based on data in which all 265 participants were averaged together. All of the colored regions showed a significant association after false discovery rate (FDR) correction for multiple comparisons.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77430-fig2-v2.tif"/></fig><p>The absolute boundary overlap is partly driven by regional differences in the number of neural state boundaries. However, our hypothesis of a nested cortical hierarchy suggests that regions in early stages of the cortical hierarchy, with many neural state boundaries, should also show overlap between neural state and perceived event boundaries. To correct for regional differences in the possibility for overlap, due to the differing number of neural state boundaries in a region, we computed the relative boundary overlap. The relative boundary overlap is scaled by the maximum possible overlap given the number of state and event boundaries. It is one when all perceived event boundaries coincide with a neural state boundary (even if there are many more neural states than events) or when all neural state boundaries coincide with an event boundary. A value of zero indicates that the overlap is equal to the expected overlap. This metric gives a different pattern of results, showing that regions across different levels of the cortical hierarchy (early and late) have strong overlap between neural states and perceived event boundaries (see <xref ref-type="fig" rid="fig2">Figure 2B</xref>). Regions early in the cortical hierarchy, such as the medial visual cortex, the medial and superior temporal gyri, and the postcentral gyrus, show strong relative overlap. The same is true for regions later in the hierarchy, including the anterior insula, most areas of the default mode network (DMN), including the medial frontal gyrus, anterior parts of the precuneus and the angular gyrus, and large parts of the lateral frontal cortex. These results suggest that there is overlap between event and neural state boundaries throughout the cortical hierarchy.</p><p>To understand why some neural state boundaries are associated with event boundaries and some are not, we investigated the degree of neural state change at each boundary. Specifically, we define boundary strength as the Pearson correlation distance between the neural activity patterns of consecutive neural states. We weighted each neural state boundary by the boundary strength and then recomputed the absolute overlap between neural state and event boundaries. Like before, the absolute overlap is one when all neural state boundaries align with a perceived event boundary and zero when the overlap is equal to the overlap that would be expected given the strengths of all neural state boundaries. However, after weighting boundaries by strength, given the same number of boundaries that overlap, the absolute overlap will be higher when the weaker neural state boundaries do not overlap with events and strong boundaries do overlap with event boundaries.</p><p>When we took the strength of neural state boundaries into account in this way, the absolute overlap with event boundaries increased compared to when we used a binary definition of neural state boundaries. This was observed particularly in the middle and superior temporal gyri, extending into the inferior frontal gyrus (see <xref ref-type="fig" rid="fig2">Figure 2C</xref>), but also in the precuneus and medial prefrontal cortex. This means that boundaries that coincided with a larger shift in brain activity patterns were more often associated with an experienced event boundary.</p></sec><sec id="s2-2"><title>Neural state networks</title><p>If neural state boundaries are organized in a nested cortical hierarchy, different brain regions would be expected to show substantial overlap in their neural state boundaries. Therefore, we investigated for each pair of searchlights whether the relative neural state boundary overlap was larger than would be expected by chance, given the number of boundaries in these regions. We observed that the overlap was significantly larger than chance for 85% of all pairs of searchlights, suggesting that neural state boundaries are indeed shared across large parts of the cortical hierarchy (see <xref ref-type="fig" rid="fig3">Figure 3A</xref>). Although the overlap was highly significant for the majority of searchlight pairs, we did not observe a perfectly nested architecture. If that were the case, the relative boundary overlap between searchlights would have been one. To make sure the observed relative boundary overlap between searchlights was not caused by noise shared across brain regions, we also computed the relative boundary overlap across two independent groups of participants (similar to the rationale of inter-subject functional connectivity analyses; <xref ref-type="bibr" rid="bib66">Simony et al., 2016</xref>). We observed that the relative boundary overlap computed in this way was similar to the relative overlap computed within a participant group (<italic>r</italic> = 0.69; see <xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref>), suggesting that shared noise is not the cause of the observed regional overlap in neural state boundaries.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Neural state boundaries are shared within and across distinct functional networks that span the cortical hierarchy.</title><p>(<bold>A</bold>) The relative boundary overlap between each pair of searchlights, ordered according the functional networks they are in. The black lines show the boundaries between functional networks. Searchlight pairs shown in white did not have significant relative boundary overlap after false discovery rate (FDR) correction for multiple comparisons. (<bold>B</bold>) Visualization of the detected functional networks. The network label at each voxel is determined by the functional network that occurs most often in all the searchlights that overlap with that voxel. (<bold>C</bold>) Visualization of the neural state durations within each network. Each searchlight is shown as a dot. The colored bars show the mean and 1 standard deviation around the mean for each network. The data shown in (<bold>A–C</bold>) are based on data averaged across all participants. The test for statistical significance in (<bold>A</bold>) was performed with data of 15 independent groups of participants. All of the colored regions in (<bold>A</bold>) showed a significant association after FDR correction for multiple comparisons.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77430-fig3-v2.tif"/></fig><p>To investigate the overlap between regions in more detail, we identified networks of brain regions that shared state boundaries by computing the relative boundary overlap between each pair of searchlights and using consensus partitioning based on Louvain modularity maximization to identify networks (<xref ref-type="bibr" rid="bib11">Blondel et al., 2008</xref>; <xref ref-type="bibr" rid="bib46">Lancichinetti and Fortunato, 2012</xref>). We found that state boundaries were shared within long-range networks. Some of these networks resembled canonical networks typically identified based on (resting state) time-series correlations (see <xref ref-type="fig" rid="fig3">Figure 3B</xref>). To quantify this, we computed the proportion of searchlights overlapping with each of the networks defined by <xref ref-type="bibr" rid="bib57">Power et al., 2011</xref> (see <xref ref-type="table" rid="app1table1">Appendix 1—table 1</xref>). We identified an auditory network that extended into regions involved in language processing in the left inferior frontal gyrus, a fronto-parietal control network (FPCN), a cingulo-opercular network (CON), and a motor network. The DMN we identified was fractionated into anterior, superior, and posterior components. It should be noted that all three of the DMN subnetworks include some anterior, superior, and posterior subregions; the names of these subnetworks indicate which aspects of the networks are most strongly represented. <xref ref-type="table" rid="app1table2">Appendix 1—table 2</xref> shows the overlap of each of these subnetworks with the anterior and posterior DMN as identified in <xref ref-type="bibr" rid="bib14">Campbell et al., 2013</xref>. The sensorimotor network (SMN) we identified was split into a lateral and medial component. We also identified a network overlapping with the dorsal attention network (DAN), although the network we identified only covered posterior parts of the DAN but not the frontal eye fields. While the visual network is typically identified as a single network in functional connectivity studies, we observed two networks, roughly corresponding to different levels of the visual hierarchy (early and late). <xref ref-type="fig" rid="fig3">Figure 3</xref> visualizes for each voxel which functional network label occurs most frequently for the searchlights overlapping that voxel. In contrast, the full extent of each of the functional networks can be seen in <xref ref-type="fig" rid="fig4">Figure 4</xref>.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Separate visualizations for each of the identified functional networks.</title><p>The colors indicate the median state duration for each of the searchlights within the functional network. SMN, sensorimotor network; DMN, default mode network; FPCN, fronto-parietal control network; CON, cingulo-opercular network; DAN, dorsal attention network. The median state duration estimates are based on data averaged across all participants.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77430-fig4-v2.tif"/></fig><p><xref ref-type="fig" rid="fig3">Figure 3C</xref> shows the average timescale within each of these functional networks. The networks with the longest state durations were the anterior DMN and the FPCN, while the early visual network, lateral SMN, and DAN had particularly short state durations. Although regions within functional networks tended to operate on a similar temporal scale, we also observed a lot of variability in state duration within networks, particularly in the auditory network (see <xref ref-type="fig" rid="fig3">Figure 3C</xref>). Many networks also showed a clear within-network gradient of timescales, such as the auditory network, the SMNs, the posterior DMN, and the FPCN (see <xref ref-type="fig" rid="fig4">Figure 4</xref>). These results suggest that the relative boundary overlap between regions is not simply driven by a similarity in the number of states, but rather by a similarity in the state boundary timings. This is also supported by the results in <xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref>, showing that the relative boundary overlap was highly distinct from the absolute pairwise differences in median state duration (<italic>r</italic> = −0.05).</p><p>Although the networks we identified show overlap with functional networks previously identified in resting state, they clearly diverged for some networks (e.g., the visual network). Some divergence is expected because neural state boundaries are driven by shifts in voxel-activity patterns over time, rather than by the changes in mean activity that we typically use to infer functional connectivity. This divergence was supported by the overall limited similarity with the previously identified networks by <xref ref-type="bibr" rid="bib57">Power et al., 2011</xref> (adjusted mutual information [aMI] = 0.39), as well as the differences between the correlation matrix that was computed based on the mean activity time courses in each searchlight and the relative boundary overlap between each pair of searchlights (<xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref>; r = 0.31). Interestingly, regions with strongly negatively correlated mean activity time courses typically showed overlap that was similar to or larger than the overlap expected by chance. Indeed, the relative boundary overlap between each pair of searchlights was more similar to the absolute Pearson correlation coefficient between searchlights (<italic>r</italic> = 0.39) than when the sign of the correlation coefficient was preserved (<italic>r</italic> = 0.31). This suggests that pairs of regions that show negatively correlated BOLD activity still tend to show neural state boundaries at the same time.</p><p>It should be noted that although the overlap in neural state boundaries was strongest for the searchlights that were part of the same functional networks, we also found a lot of evidence for the hypothesis that boundaries are shared across different levels of the cortical hierarchy (see <xref ref-type="fig" rid="fig3">Figure 3A</xref>). Overlap was particularly strong between all higher-order networks (DAN, CON, FPCN, and DMNs), as well as between the motor network and SMN. The sensorimotor, motor, and auditory networks also showed highly significant overlap with the higher-order networks. Lower levels of overlap were observed between the early visual network and all other networks (except the DAN), as well as between the auditory and the sensorimotor networks.</p></sec><sec id="s2-3"><title>Shared neural state boundaries and event boundaries</title><p>Previous research on event segmentation has shown that the perception of an event boundary is more likely when multiple features of a stimulus change at the same time (<xref ref-type="bibr" rid="bib18">Clewett et al., 2019</xref>). When multiple sensory features changes at the same time, this could be reflected in many regions within the same functional network showing a state boundary at the same time (e.g., in the visual network when many aspects of the visual environment change), or in neural state boundaries that are shared across functional networks (e.g., across the auditory and visual networks when a visual and auditory change coincide). Similarly, boundaries shared between many brain regions within or across higher-level cortical networks might reflect a more pronounced change in conceptual features of the narrative (e.g., the goals or emotional state of the character). Therefore, we expect that in a nested cortical hierarchy neural state boundaries that are shared between many brain regions within functional networks, and particularly those shared widely across functional networks, would be more likely to be associated with the perception of an event boundary. To investigate this, we first weighted each neural state boundary in each searchlight by the proportion of searchlights within the same network that also showed a boundary at the same time. This is very similar to how we investigated the role of boundary strength above.</p><p>We found that when we took the within-network co-occurrence of neural state boundaries into account in this way, the absolute overlap with event boundaries increased compared to when we used a binary definition of neural state boundaries. So when a particular neural state boundary is shared with more regions within the same network, it is more likely to coincide with an event boundary (see <xref ref-type="fig" rid="fig5">Figure 5A</xref>). This effect was observed across all networks, except the early visual network. It was strongest for regions in the anterior DMN, the FPCN, and the auditory network and slightly less pronounced for regions in the posterior and superior DMN, as well as the CON. On a regional level, the strongest effects were observed within the precuneus, angular gyrus, medial prefrontal cortex, temporal pole, insula, superior temporal gyrus, and the middle frontal gyrus.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Increase in absolute overlap between neural state boundaries and event boundaries when boundary co-occurence is taken into account.</title><p>Increase in absolute overlap between neural state boundaries and event boundaries when neural state boundaries are weighted by the percentage of searchlights in the same functional networks or across the whole brain that also have a boundary at the same timepoint<italic>.</italic> (<bold>A</bold>) Within-network-weighted absolute overlap is compared to using binary boundaries (as in <xref ref-type="fig" rid="fig2">Figure 2A</xref>). (<bold>B</bold>) Whole-brain-weighted absolute overlap is compared to within-network-weighted absolute overlap. (<bold>C</bold>) The average absolute boundary overlap between events and neural states within each functional network. This is done for both binary boundaries, boundaries weighted by within-network co-occurrence, and boundaries weighted by whole-brain co-occurrence. A red star indicates a significant difference between binary boundaries and boundaries weighted by within-network co-occurrence. A blue star indicates a significant difference between boundaries weighted by whole-brain co-occurrence and boundaries weighted by within-network co-occurrence. The data shown in (<bold>A–C</bold>) are based on data averaged across all participants. The tests for statistical significance were performed with data of 15 independent groups of participants. All of the colored regions in (<bold>A, B</bold>) showed a significant association after false discovery rate (FDR) correction for multiple comparisons.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77430-fig5-v2.tif"/></fig><p>Next, we weighted each neural state boundary by the proportion of searchlights across the whole brain that showed a boundary at the same time. We investigated where absolute overlap for this whole-brain co-occurrence was stronger than when the neural state boundaries were weighted by within-network co-occurrence (see <xref ref-type="fig" rid="fig5">Figure 5B</xref>). This was the case specifically for the early and late visual networks, the DAN, the lateral and medial SMN networks, and the motor network. For the auditory network, the opposite effect was observed; whole-brain co-occurrence showed lower absolute overlap with event boundaries than within-network co-occurrence. On a regional level, increases in overlap with event boundaries were most pronounced in the medial parts of the occipital lobe, the supplementary motor area and precentral gyri, as well as the superior parietal gyri.</p><p>To investigate the role of boundary co-occurrence across networks in more detail, we investigated for each pair of searchlights whether boundaries that are shared have a stronger association with perceived event boundaries as compared to boundaries that are unique to one of the two searchlights. We found that boundary sharing had a positive impact on overlap with perceived boundaries, particularly for pairs of searchlights within the auditory network and between the auditory network and the anterior DMN (see <xref ref-type="fig" rid="fig6">Figure 6A and B</xref>). In addition, we saw that neural state boundaries that were shared between the auditory network and the early and late visual networks, and the superior and posterior DMN were more likely to be associated with a perceived event boundary than non-shared boundaries. The same was true for boundaries shared between the anterior DMN and the lateral and medial SMN network and the posterior DMN. Boundary sharing between the other higher-level networks (pDMN, sDMN, FPCN, and CON) as well as between these higher-level networks and the SMN networks was also beneficial for overlap with event boundaries. On a regional level, the strongest effects of boundary sharing were observed in the medial prefrontal cortex, medial occipital cortex, precuneus, middle and superior temporal gyrus, and insula (see <xref ref-type="fig" rid="fig6">Figure 6B</xref>). Analyses shown in the ‘Supplementary results’ section in Appendix 1 demonstrate that these increases in overlap for shared vs. non-shared boundaries cannot be attributed to effects of noise (see also <xref ref-type="fig" rid="app1fig7">Appendix 1—figure 7</xref>).</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Increase in absolute overlap with event boundaries for shared vs. non-shared neural state boundaries.</title><p>(<bold>A</bold>) For each pair of searchlights, we compare the relative boundary overlap between neural state boundaries between boundaries that are shared and boundaries that are not shared. In particular, for each pair of searchlights, the searchlight with the highest relative boundary overlap with events is used as the reference in the comparison. The white lines show the boundaries between functional networks. (<bold>B</bold>) shows the percentage of connections in (<bold>A</bold>) that show a significant increase in relative boundary overlap with events for shared vs. non-shared neural state boundaries. Here, the data are summarized to a network-by-network matrix for ease of interpretation. The data shown in this figure are based on data averaged across all participants. The tests for statistical significance were performed with data of 15 independent groups of participants. All of the colored regions in (<bold>A</bold>) showed a significant association after false discovery rate (FDR) correction for multiple comparisons.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77430-fig6-v2.tif"/></fig><p>So far, we have focused on comparing state boundary time series across regions or between brain regions and events. However, that approach does not allow us to fully understand the different ways in which boundaries can be shared across parts of the cortical hierarchy at specific points in time. To investigate this, we can group timepoints together based on the similarity of their boundary profiles; that is, which searchlights do or do not have a neural state boundary at the same timepoint. We used a weighted stochastic block model (WSBM) to identify groups of timepoints, which we will refer to as ‘communities.’ We found an optimal number of four communities (see <xref ref-type="fig" rid="fig7">Figure 7</xref>). These communities group together timepoints that vary in how the degree to their neural state boundaries are shared across the cortical hierarchy: timepoints in the first community show the most widely spread neural state boundaries across the hierarchy, while timepoints in the later communities show less widespread state transitions. We found that from community 1–4, the prevalence of state boundaries decreased for all networks, but most strongly for the FPCN and CON, sDMN, aDMN, and auditory networks. However, the same effect was also seen in the higher visual and SMN and motor networks. This might suggest that boundaries that are observed widely across lower-level networks are more likely to traverse the cortical hierarchy.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Communities of timepoints identified with weighted stochastic block model (WSBM).</title><p>This algorithm groups together timepoints that show similar boundary profiles (presence or absence of boundaries across searchlights). (<bold>A</bold>) Neural state boundaries are shown for each community per timepoint for each searchlight, grouped in functional networks. Boundaries shown in red coincide with an event boundary. (<bold>B</bold>) Per functional network, we show the ratio of the average state boundary occurrence within each community versus the average occurrence across all timepoints. The same is shown for the event boundaries. The data shown in this figure are based on data averaged across all participants.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77430-fig7-v2.tif"/></fig><p>We also found a similar drop in prevalence of event boundaries across communities, supporting our previous observation that the perception of event boundaries is associated with the sharing of neural state boundaries across large parts of the cortical hierarchy. We repeated this analysis in two independent groups of participants to be able to assess the stability of this pattern of results. Although group 1 showed an optimum of four communities and group 2 an optimum of five communities, the pattern of results was highly similar across both groups (see <xref ref-type="fig" rid="app1fig8">Appendix 1—figure 8</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>While event segmentation is a critical aspect of our ongoing experience, the neural mechanisms that underlie this ability are not yet clear. The aim of this article was to investigate the cortical organization of neural states that may underlie our experience of distinct events. By combining an innovative data-driven state segmentation method with a movie dataset of many participants, we were able to identify neural states across the entire cortical hierarchy for the first time. We observed particularly fast states in primary sensory regions and long periods of information integration in the left middle frontal gyrus and medial prefrontal cortex. Across the entire cortical hierarchy, we observed associations between neural state and perceived event boundaries and our findings demonstrate that neural state boundaries are shared within long-range functional networks as well as across the temporal hierarchy between distinct functional networks.</p><sec id="s3-1"><title>A partially nested cortical hierarchy of neural states</title><p>Previous findings have suggested that neural states may be organized in a nested cortical hierarchy (<xref ref-type="bibr" rid="bib4">Baldassano et al., 2017</xref>). In line with this hypothesis, we observed that neural state boundaries throughout the entire hierarchy overlap with perceived event boundaries, but this overlap is particularly strong for transmodal regions such as the dorsal medial prefrontal cortex, anterior cingulate cortex, left superior and middle frontal gyrus, and anterior insula. In line with EST, the strong alignment in the anterior cingulate cortex suggests that the disparity between predicted and perceived sensory input may play a role in the experience of an event boundary (<xref ref-type="bibr" rid="bib38">Holroyd and Coles, 2002</xref>; <xref ref-type="bibr" rid="bib43">Kurby and Zacks, 2008</xref>), while the involvement of the dorsal medial prefrontal cortex is in line with previous studies linking this region to representations of specific events (<xref ref-type="bibr" rid="bib5">Baldassano et al., 2018</xref>; <xref ref-type="bibr" rid="bib40">Krueger et al., 2009</xref>; <xref ref-type="bibr" rid="bib50">Liu et al., 2022</xref>).</p><p>Once we accounted for the maximal possible overlap given the number of neural states in a particular brain region, we also found strong overlap in unimodal areas such as the visual, auditory, and somatosensory cortices. This finding suggests that some of the neural state boundaries that can be identified in early sensory regions are also consciously experienced as an event boundary. Potentially because these boundaries are propagated to regions further up in the cortical hierarchy. Which of the boundaries in lower-level areas propagate to higher-order cortical areas may be moderated by attentional mechanisms, which are known to alter cortical information processing through long-range signals (<xref ref-type="bibr" rid="bib13">Buschman and Miller, 2007</xref>; <xref ref-type="bibr" rid="bib31">Gregoriou et al., 2009</xref>). When participants are not attending the sensory input (i.e., during daydreaming), there may be much lower correspondence between neural state boundaries in higher- and lower-level regions.</p><p>So, what do these neural states represent? Recent work by <xref ref-type="bibr" rid="bib16">Chien and Honey, 2020</xref> has shown that neural activity around an artificially introduced event boundary can be effectively modeled by ongoing information integration, which is reset by a gating mechanism, very much in line with the mechanism proposed to underlie event segmentation (<xref ref-type="bibr" rid="bib43">Kurby and Zacks, 2008</xref>). Similarly, neural states may represent information integration about a particular stable feature of the environment, which is reset when that feature undergoes a substantial change (<xref ref-type="bibr" rid="bib12">Bromis et al., 2022</xref>). This suggests that neural states in early visual cortex may represent short-lived visual features of the external environment, while states in anterior temporal cortex may contain high-level semantic representations related to the ongoing narrative (<xref ref-type="bibr" rid="bib17">Clarke and Tyler, 2015</xref>). For transmodal regions such as the medial prefrontal cortex, or middle frontal gyrus, that have been associated with many different high level cognitive processes (<xref ref-type="bibr" rid="bib23">Duncan, 2010</xref>; <xref ref-type="bibr" rid="bib74">van Kesteren et al., 2012</xref>; <xref ref-type="bibr" rid="bib66">Simony et al., 2016</xref>), it is not yet clear what a distinct neural state might represent. Just as perceived event boundaries can be related to changes in one or multiple situational dimensions, such as changes in goals or locations (<xref ref-type="bibr" rid="bib18">Clewett et al., 2019</xref>; <xref ref-type="bibr" rid="bib86">Zacks et al., 2009</xref>), neural state boundaries in transmodal cortical areas may not necessarily reflect one particular type of change. State boundaries in these regions are likely also dependent on the goals of the viewer (<xref ref-type="bibr" rid="bib76">Wen et al., 2020</xref>).</p><p>We also investigated the factors that distinguish neural state boundaries that traverse the hierarchy from those that do not. It has previously been shown that changes across multiple aspects of the narrative are more likely to result in an experienced event boundary (<xref ref-type="bibr" rid="bib87">Zacks et al., 2010</xref>). In line with this, we observed that boundaries that were represented in more brain regions at the same time were also more likely to be associated with the experience of an event boundary. The strength of the neural state boundary, as measured by the amount of change in neural activity patterns, was also identified as a factor that can to some degree distinguish neural states that appear in subjective experience from the neural states that do not, particularly in temporal cortex, inferior frontal gyrus, precuneus, and medial prefrontal gyrus. This suggests that a neural state boundary is not an all or none occurrence. Instead, the reset of representations at neural state boundaries (<xref ref-type="bibr" rid="bib16">Chien and Honey, 2020</xref>) may differ based on what is happening in other brain regions, on the current attentional focus, or based on the degree of change in the representations of the environment in that particular brain region.</p><p>More evidence for the idea of a nested cortical hierarchy of neural state boundaries comes from our connectivity analyses, which show that neural state boundaries are shared both within and across groups of regions that partly resemble well-known functional brain networks. This sharing of boundaries across different cortical areas may suggest that neural states in higher-level cortical regions represent an overarching representation that corresponds to many distinct states in lower-level cortical areas, which all represent different features of that overarching representation (e.g., words spoken, characters on screen, or locations within a particular situation). This is in line with previous conceptualizations of events as partonomic hierarchies (<xref ref-type="bibr" rid="bib82">Zacks et al., 2001a</xref>) and with other models of hierarchical neural representations, such as the hub-and-spokes model for semantic representations, which proposes that semantic knowledge is represented by the interaction between modality-specific brain regions and a transmodal semantic representational hub in the anterior temporal lobe (<xref ref-type="bibr" rid="bib45">Lambon Ralph et al., 2010</xref>; <xref ref-type="bibr" rid="bib60">Rogers et al., 2004</xref>). It is also in line with a recently proposed hierarchical representation of episodic memories, in which items that are linked within small-scale events are in turn linked within large-scale episodic narratives (<xref ref-type="bibr" rid="bib2">Andermane et al., 2021</xref>).</p></sec><sec id="s3-2"><title>Timescales of information processing across the cortex</title><p>While previous studies have been able to show regional differences in the timescale of information processing across parts of the cortex (<xref ref-type="bibr" rid="bib4">Baldassano et al., 2017</xref>; <xref ref-type="bibr" rid="bib35">Hasson et al., 2008</xref>; <xref ref-type="bibr" rid="bib39">Honey et al., 2012</xref>; <xref ref-type="bibr" rid="bib49">Lerner et al., 2011</xref>; <xref ref-type="bibr" rid="bib69">Stephens et al., 2013</xref>), here we were able to reveal neural state timescales across the entire cortex for the first time. The validity of our results is supported by extensive validations using simulations (see ‘Supplementary methods’ in Appendix 1 and <xref ref-type="bibr" rid="bib28">Geerligs et al., 2021</xref>) and the reliability of our observations across independent groups of participants. It is also supported by the similarity between our results and previous findings based on very different approaches, such as experiments with movies and auditory narratives that have been scrambled at different timescales (<xref ref-type="bibr" rid="bib35">Hasson et al., 2008</xref>; <xref ref-type="bibr" rid="bib39">Honey et al., 2012</xref>; <xref ref-type="bibr" rid="bib49">Lerner et al., 2011</xref>), or resting-state fluctuations in electrocorticography (<xref ref-type="bibr" rid="bib39">Honey et al., 2012</xref>) and fMRI data (<xref ref-type="bibr" rid="bib69">Stephens et al., 2013</xref>).</p><p>Although we characterized brain areas based on their median state length, we observed that neural states within a region were not of equal duration, suggesting that regional timescales may change dynamically based on the features of the stimulus. This is also in line with the observed correspondence between neural state and perceived event boundaries. Event boundaries have previously been shown to align with changes in features of the narrative, such as characters, causes, goals, and spatial locations (<xref ref-type="bibr" rid="bib86">Zacks et al., 2009</xref>). Therefore, the overlap between state boundaries and perceived event boundaries across the cortex also suggests that characteristics of the sensory input are driving the occurrence of neural state boundaries. Together, these findings show that the timescale of information processing in particular brain regions is not only driven by stable differences in the rate of temporal integration of information, which may be associated with interregional interactions in the neural circuitry (<xref ref-type="bibr" rid="bib39">Honey et al., 2012</xref>), but also by the properties of the input that is received from the environment. Our results show that some of the areas that were not covered in previous investigations (<xref ref-type="bibr" rid="bib4">Baldassano et al., 2017</xref>; <xref ref-type="bibr" rid="bib35">Hasson et al., 2008</xref>; <xref ref-type="bibr" rid="bib39">Honey et al., 2012</xref>; <xref ref-type="bibr" rid="bib49">Lerner et al., 2011</xref>; <xref ref-type="bibr" rid="bib69">Stephens et al., 2013</xref>), such as the medial prefrontal cortex and middle frontal gyrus, have the longest timescales of information processing. This suggests these regions at the top of the cortical hierarchy (<xref ref-type="bibr" rid="bib17">Clarke and Tyler, 2015</xref>; <xref ref-type="bibr" rid="bib26">Fuster, 2001</xref>) also have the slowest timescales of information processing, in line with expectations based on the hierarchical process memory framework (<xref ref-type="bibr" rid="bib37">Hasson et al., 2015</xref>).</p></sec><sec id="s3-3"><title>Functional networks of neural state boundaries</title><p>In line with previous work (<xref ref-type="bibr" rid="bib4">Baldassano et al., 2017</xref>), we found that neural state boundaries are shared across brain regions. Our results show for the first time that these boundaries are shared within distinct functional networks. Interestingly, the networks we identify partially resemble the functional networks that are typically found using regular functional connectivity analyses (c.f. <xref ref-type="bibr" rid="bib57">Power et al., 2011</xref>; <xref ref-type="bibr" rid="bib81">Yeo et al., 2011</xref>), though there are some differences. For instance, the visual network was segregated into two smaller subnetworks, and for other networks, the topographies sometimes deviated somewhat from those observed in prior work.</p><p>Our results show that functional networks defined by state boundaries differ in their timescales of information processing. While some networks have a particular temporal mode of information processing, other networks show a within-network gradient of neural state timescales. For the DMN, we observed a split into posterior, superior, and anterior subnetworks with markedly different timescales. The anterior and posterior subnetworks closely resemble previously observed posterior and anterior DMN subnetworks (<xref ref-type="bibr" rid="bib3">Andrews-Hanna et al., 2010</xref>; <xref ref-type="bibr" rid="bib14">Campbell et al., 2013</xref>; <xref ref-type="bibr" rid="bib48">Lei et al., 2014</xref>), while the superior subnetwork resembles the right dorsal lateral DMN subnetwork (<xref ref-type="bibr" rid="bib30">Gordon et al., 2020</xref>). The posterior/fast DMN is particularly prominent in the precuneus and angular gyri, which are thought to engage in episodic memory retrieval through connectivity with the hippocampal formation (<xref ref-type="bibr" rid="bib3">Andrews-Hanna et al., 2010</xref>). The posterior DMN has also been proposed to be involved in forming mental scenes or situation models (<xref ref-type="bibr" rid="bib58">Ranganath and Ritchey, 2012</xref>). Thus, neural states in this subnetwork may reflect the construction of mental scenes of the movie and/or retrieval of related episodic memories. The superior DMN (or right dorsal lateral DMN) showed timescales of neural states that were in between those of the anterior and posterior DMN. This network has previously been suggested to be a connector hub within the DMN, through which the FPCN exerts top-down control over the DMN. This is in line with the strong state boundary overlap we observed between searchlights in the sDMN and the FPCN. The anterior/slow DMN is particularly prominent in the medial prefrontal cortex that has been related to self-referential thought, affective processing, and integrating current information with prior knowledge (<xref ref-type="bibr" rid="bib10">Benoit et al., 2014</xref>; <xref ref-type="bibr" rid="bib29">Gilboa and Marlatte, 2017</xref>; <xref ref-type="bibr" rid="bib74">van Kesteren et al., 2012</xref>; <xref ref-type="bibr" rid="bib55">Northoff et al., 2006</xref>). The current results suggest that these processes require integration of information over longer timescales.</p></sec><sec id="s3-4"><title>Real-life experience</title><p>Although event segmentation is thought to be a pivotal aspect of how information is processed in real life (<xref ref-type="bibr" rid="bib85">Zacks et al., 2007</xref>), it is often not considered in experimental settings, where events are predetermined by the trial or block structure. This study and previous work (<xref ref-type="bibr" rid="bib4">Baldassano et al., 2017</xref>) show that we are now able to investigate brain activity as it unfolds over time without asking participants to perform a task. This allows us to study brain function in a way that is much more similar to our daily life experience than typical cognitive neuroscience experiments (<xref ref-type="bibr" rid="bib33">Hamilton and Huth, 2020</xref>; <xref ref-type="bibr" rid="bib47">Lee et al., 2020</xref>; <xref ref-type="bibr" rid="bib78">Willems et al., 2020</xref>). This opens the door for investigations of neural differences during narrative comprehension between groups of participants, such as participants with autism who may have trouble distinguishing events that require them to infer the state of mind of others (<xref ref-type="bibr" rid="bib6">Baron-Cohen, 2000</xref>; <xref ref-type="bibr" rid="bib36">Hasson et al., 2009</xref>), or participants with Alzheimer’s disease, who may have trouble with segmenting and encoding events in memory (<xref ref-type="bibr" rid="bib84">Zacks et al., 2006</xref>).</p><p>It should be noted that this more naturalistic way of investigating brain activity comes at a cost of reduced experimental control (<xref ref-type="bibr" rid="bib78">Willems et al., 2020</xref>). For example, some of the differences in brain activity that we observe over time may be associated with eye movements. Preparation of eye movements may cause activity changes in the frontal-eye-fields (<xref ref-type="bibr" rid="bib75">Vernet et al., 2014</xref>), while execution of eye movements may alter the input in early sensory regions (<xref ref-type="bibr" rid="bib51">Lu et al., 2016</xref>; <xref ref-type="bibr" rid="bib67">Son et al., 2020</xref>). However, in a related study (<xref ref-type="bibr" rid="bib20">Davis et al., 2021</xref>), we found no age difference in eye movement synchrony while viewing the same movie, despite our previous observation of reduced synchrony with age in several areas (particularly the hippocampus, medial PFC, and FPCN; <xref ref-type="bibr" rid="bib27">Geerligs and Campbell, 2018</xref>), suggesting a disconnect between eye movements and neural activity in higher-order areas. In addition, reducing this potential confound by asking participants to fixate leads to an unnatural mode of information processing, which could arguably bias the results in different ways by requiring participants to perform a double task (monitoring eye movements in addition to watching the movie).</p></sec><sec id="s3-5"><title>Conclusion</title><p>Here, we demonstrate that event segmentation is underpinned by neural state boundaries that occur in a nested cortical hierarchy. This work also provides the first cortex-wide mapping of timescales of information processing and shows that the DMN fractionates into faster and slower subnetworks. Together, these findings provide new insights into the neural mechanisms that underlie event segmentation, which in turn is a critical component of real-world perception, narrative comprehension, and episodic memory formation. What remains to be addressed is how timescales of different brain regions relate to the types of neural representations that are contained within these regions. For example, does the dissociation between the posterior and anterior DMN reflect relatively fast construction of mental scenes and slow integration with existing knowledge, respectively? Studying brain function from this perspective provides us with a new view on the organizational principles of the human brain.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>This study included data from 265 adults (131 females) who were aged 18–50 (mean age 36.3, SD = 8.6) from the healthy, population-derived cohort tested in stage II of the Cam-CAN project (<xref ref-type="bibr" rid="bib64">Shafto et al., 2014</xref>; <xref ref-type="bibr" rid="bib71">Taylor et al., 2017</xref>). Participants were native English speakers, had normal or corrected-to-normal vision and hearing, and had no neurological disorders (<xref ref-type="bibr" rid="bib64">Shafto et al., 2014</xref>). Ethical approval for the study was obtained from the Cambridgeshire 2 (now East of England – Cambridge Central) Research Ethics Committee. Participants gave written informed consent.</p></sec><sec id="s4-2"><title>Movie</title><p>Participants watched a black-and-white television drama by Alfred Hitchcock called <italic>Bang! You’re Dead</italic> while they were scanned with fMRI. The full 25 min episode was shortened to 8 min, preserving the narrative of the episode (<xref ref-type="bibr" rid="bib64">Shafto et al., 2014</xref>). This shortened version of the movie has been shown to elicit robust brain activity, synchronized across participants (<xref ref-type="bibr" rid="bib15">Campbell et al., 2015</xref>; <xref ref-type="bibr" rid="bib27">Geerligs and Campbell, 2018</xref>). Participants were instructed to watch, listen, and pay attention to the movie.</p></sec><sec id="s4-3"><title>fMRI data acquisition</title><p>The details of the fMRI data acquisition are described in <xref ref-type="bibr" rid="bib27">Geerligs and Campbell, 2018</xref>. In short, 193 volumes of movie data were acquired with a 32-channel head-coil, using a multi-echo, T2*-weighted EPI sequence. Each volume contained 32 axial slices (acquired in descending order), with slice thickness of 3.7 mm and interslice gap of 20% (TR = 2470 ms; five echoes [TE = 9.4 ms, 21.2 ms, 33 ms, 45 ms, 57 ms]; flip angle = 78°; FOV = 192 mm × 192 mm; voxel size = 3 mm × 3 mm × 4.44 mm), the acquisition time was 8 min and 13 s. High-resolution (1 mm × 1mm × 1 mm) T1- and T2-weighted images were also acquired.</p></sec><sec id="s4-4"><title>Data preprocessing and hyperalignment</title><p>The initial steps of data preprocessing for the movie data were the same as in <xref ref-type="bibr" rid="bib27">Geerligs and Campbell, 2018</xref> and are described there in detail. Briefly, the preprocessing steps included deobliquing of each TE, slice time correction, and realignment of each TE to the first TE in the run, using AFNI (version AFNI_17.1.01; <ext-link ext-link-type="uri" xlink:href="https://afni.nimh.nih.gov">https://afni.nimh.nih.gov</ext-link>; <xref ref-type="bibr" rid="bib19">Cox, 1996</xref>). To denoise the data for each participant, we used multi-echo independent component analysis (ME-ICA), which is a very promising method for removal of non-BOLD-like components from the fMRI data, including effects of head motion (<xref ref-type="bibr" rid="bib41">Kundu et al., 2012</xref>; <xref ref-type="bibr" rid="bib42">Kundu et al., 2013</xref>). Co-registration followed by DARTEL intersubject alignment was used to align participants to MNI space using SPM12 software (<ext-link ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm">http://www.fil.ion.ucl.ac.uk/spm</ext-link>).</p><p>To optimally align voxels across participants in the movie dataset, we subsequently used whole-brain searchlight hyperalignment as implemented in the PyMVPA toolbox (<xref ref-type="bibr" rid="bib32">Guntupalli et al., 2016</xref>; <xref ref-type="bibr" rid="bib34">Hanke et al., 2009</xref>). Hyperalignment is an important step in the pipeline because the neural state segmentation method relies on group-averaged voxel-level data. Hyperalignment uses Procrustes transformations to derive the optimal rotation parameters that minimize intersubject distances between responses to the same timepoints in the movie. The details of the procedure are identical to those in <xref ref-type="bibr" rid="bib28">Geerligs et al., 2021</xref>. After hyperalignment, the data were highpass-filtered with a cut-off of 0.008 Hz. For the analyses that included 2 or 15 independent groups of participants, we ran hyperalignment separately within each subgroup to make sure that datasets remained fully independent.</p></sec><sec id="s4-5"><title>Data-driven detection of neural state boundaries</title><p>To identify neural state boundaries in the fMRI data, we used GSBS (<xref ref-type="bibr" rid="bib28">Geerligs et al., 2021</xref>). GSBS performs an iterative search for state boundary locations that optimize the similarity between the average activity patterns in a neural state and the (original) brain activity at each corresponding timepoint. At each iteration of the algorithm, previous boundary locations are fine-tuned by shifting them by 1 TR (earlier or later) if this further improves the fit. To determine the optimal number of boundaries in each brain region, we used the t-distance metric. This metric identifies the optimal number of states, such that timepoints within a state have maximally similar brain activity patterns, while timepoints in consecutive states are maximally dissimilar. The validity of these methods has been tested extensively in previous work, with both simulated and empirical data (<xref ref-type="bibr" rid="bib28">Geerligs et al., 2021</xref>). The input to the GSBS algorithm consists of a set of voxel time courses within a searchlight and a maximum value for the number of states, which we set to 100, roughly corresponding to half the number of TRs in our data (<xref ref-type="bibr" rid="bib28">Geerligs et al., 2021</xref>).</p><p>Here we improved on the existing method in three ways to increase the validity and reliability of our results. First, GSBS previously placed one boundary in each iteration. We found that for some brain regions this version of the algorithm showed suboptimal performance. A boundary corresponding to a strong state transition was placed in a relatively late iteration of the GSBS algorithm. This led to a steep increase in the t-distance in this particular iteration, resulting in a solution with more neural state boundaries than might be necessary or optimal (for more details, see the ‘Supplementary methods’ section in Appendix 1 and , <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1A</xref>). We were able to address this issue by allowing the algorithm to place two boundaries at a time. A 2-D search is performed, which allows the algorithm to determine the location of a new state, rather than identifying a boundary between two states. A restriction to the search is that both boundaries must be placed within a single previously existing state. In some cases, it may be more optimal to place one new boundary than two, for example, when an existing state should be split in two (rather than three) substates. To accommodate this, we allow the algorithm to determine whether one or two boundaries should be placed at a time, based on which of these options results in the highest t-distance.</p><p>As a consequence of this change in the fitting procedure, we also adjusted the boundary fine-tuning. While we previously fine-tuned boundaries in the order they were detected (i.e., first to last), we now perform the fine-tuning starting from the weakest boundary and ending with the strongest boundary. These changes to the algorithm are all evaluated extensively in the ‘Supplementary methods’ section in Appendix 1. Code that implements the improved version of GSBS in Python is available in the StateSegmentation Python package (<ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/statesegmentation/">https://pypi.org/project/statesegmentation/</ext-link>).</p><p>The final change compared to our previous work entails the use of deconvolved data. We observed that the algorithm was often unable to differentiate short states from transitions between longer states due to the slow nature of the hemodynamic response. This issue can be resolved by first deconvolving the data. Simulations and empirical results demonstrate that these changes resulted in stark increases in the reliability of our results (see ‘Supplementary methods’ in Appendix 1). The data were deconvolved using Wiener deconvolution as implemented in the rsHRF toolbox (version 1.5.8), based the canonical hemodynamic response function (HRF; <xref ref-type="bibr" rid="bib79">Wu et al., 2021</xref>). Importantly, we did not use the iterative Wiener filter algorithm as we noticed that this blurred the boundaries between neural states. We also investigated the effects of estimating the HRF shape based on the movie fMRI data instead of using the canonical HRF and found that this did not have a marked impact on the results (see ‘Supplementary methods’ in Appendix 1).</p></sec><sec id="s4-6"><title>Whole-brain search for neural state boundaries</title><p>We applied GSBS in a searchlight to the hyperaligned movie data. Spherical searchlights were scanned within the Harvard-Oxford cortical mask with a step size of two voxels and a radius of three voxels (<xref ref-type="bibr" rid="bib21">Desikan et al., 2006</xref>). This resulted in searchlights with an average size of 97 voxels (max: 123; IQR: 82–115); this variation in searchlight size was due to the exclusion of out-of-brain voxels. Only searchlights with more than 15 voxels were included in the analysis.</p><p>Previous analyses have shown that neural state boundaries cannot be identified reliably in single-subject data. Instead data should be averaged across a group of at least ~17 participants to eliminate sources of noise from the data (<xref ref-type="bibr" rid="bib28">Geerligs et al., 2021</xref>). As the group size increases, the reliability of the results also increases. Therefore, all the results reported here are with the maximal possible group size. To illustrate the reliability of the cortical hierarchy of state durations and the communities of timepoints, we randomly divided the data into two independent samples of ~135 participants each before identifying the optimal number of states. In all other analyses, the figures in the ‘Results’ section are derived from data with all participants averaged in one big group. Statistical testing to determine statistical significance of these results is done with data in which participants were grouped in 15 smaller independent subgroups of 17/18 randomly selected participants per group.</p></sec><sec id="s4-7"><title>Defining event boundaries</title><p>Event boundaries in the Cam-CAN movie dataset were identified by <xref ref-type="bibr" rid="bib8">Ben-Yakov and Henson, 2018</xref> based on data from 16 observers. These participants watched the movie outside the scanner and indicated with a keypress when they felt ‘one event (meaningful unit) ended and another began.’ Participants were not able to rewind the movie. <xref ref-type="bibr" rid="bib8">Ben-Yakov and Henson, 2018</xref> referred to the number of observers that identified a boundary at the same time as the boundary salience. In line with their approach, we only included boundaries identified by at least five observers. This resulted in a total of 19 boundaries separated by 6.5–93.7 s, with a salience varying from 5 to 16 observers (mean = 10).</p></sec><sec id="s4-8"><title>Comparison of neural state boundaries to event boundaries</title><p>To compare the neural state boundaries across regions to the event boundaries, we computed two overlap metrics; the absolute and relative boundary overlap. Both overlap measures were scaled with respect to the expected number of overlapping boundaries. To compute these values, we define <italic>E</italic> as the event boundary time series and <italic>S<sub>i</sub></italic> as the neural state boundary time series for searchlight <italic>i</italic>. These time series contain zeros at each timepoint <italic>t</italic> when there is no change in state/event and ones at each timepoint when there is a transition to a different state/event.</p><p>The overlap between event boundaries and state boundaries in searchlight <italic>i</italic> is defined as<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <italic>n</italic> is the number of TRs.</p><p>If we assume that there is no association between the occurrence of event boundaries and state boundaries, the expected number of overlapping boundaries is defined as in <xref ref-type="bibr" rid="bib82">Zacks et al., 2001a</xref> as:<disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:mi>O</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:mo>⋅</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Because the number of overlapping boundaries will increase as the number of state boundaries increases, the absolute overlap (<italic>OA</italic>) was scaled such that it was zero when it was equal to the expected overlap and one when all neural state boundaries overlapped with an event boundary. The absolute overlap therefore quantifies the proportion of the neural state boundaries that overlap with an event boundary:<disp-formula id="equ3"><mml:math id="m3"><mml:mrow><mml:mi>O</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>O</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>O</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Instead, the relative overlap (<italic>OR</italic>) was scaled such that is was one when all event boundaries overlapped with a neural state (or when all neural state boundaries overlapped with an event boundary if there were fewer state boundaries than event boundaries). In this way, this metric quantifies the overlap without penalizing regions that have more or fewer state boundaries than event boundaries. The relative overlap is defined as<disp-formula id="equ4"><mml:math id="m4"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>O</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>O</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>O</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>For each searchlight, we tested whether the boundary overlap was significantly different from zero across the 15 independent samples.</p><p>In addition to investigating the overlap between the event boundaries and the state boundaries, we also investigated the effect of boundary strength. We define boundary strength as the Pearson correlation distance between the neural activity patterns of consecutive neural states. We investigated whether taking the strength of state boundaries into account improved the absolute overlap compared to using the binary definition of state boundaries. To do this, we change the neural state boundary time series for searchlight <italic>S<sub>i</sub></italic> such that, instead of ones, it contains the observed state boundary strength when there is a transition to a different state. After redefining <italic>S<sub>i</sub></italic> in this way, we recomputed the absolute overlap and investigated which brain regions showed a significant increase in overlap when we compare the strength-based absolute overlap (<inline-formula><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>A</mml:mi><mml:mo>-</mml:mo><mml:mi>S</mml:mi><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) to the binary absolute overlap (<inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>)<italic>,</italic> across the 15 independent samples.</p></sec><sec id="s4-9"><title>Quantification of boundary overlap between searchlights</title><p>In order to quantify whether the overlap between neural state boundaries between different brain regions was larger than expected based on the number of state boundaries, we computed the relative boundary overlap as described above. We used the relative, instead of the absolute overlap, to make sure that the overlap between regions was not biased by regional differences in the number of states. The relative boundary overlap allows us to quantify the degree to which state boundaries are nested. The overlap between the neural state time series of searchlights <italic>i</italic> and <italic>j</italic> is defined as<disp-formula id="equ5"><mml:math id="m5"><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Here, we used the binary definition of <italic>S<sub>i</sub></italic> and <italic>S<sub>j</sub></italic>, containing ones when there was a transition between states and zeros when there was no transition.</p><p>The expected overlap between neural state boundaries was quantified as<disp-formula id="equ6"><mml:math id="m6"><mml:mrow><mml:mi>O</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:mo>⋅</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>The relative boundary overlap metric (<italic>OR</italic>) was scaled such that it was zero when it was equal to the expected overlap and one when it was equal to the maximal possible overlap:<disp-formula id="equ7"><mml:math id="m7"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>O</mml:mi><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>O</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>O</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>For each pair of searchlights, we tested whether the boundary overlap was significantly different from zero across the 15 independent samples.</p></sec><sec id="s4-10"><title>Identification of functional networks</title><p>In order to identify networks of regions that contained the same neural state boundaries, we computed the boundary overlap between each pair of searchlights as described above. We used the data in which all 265 participants were averaged. Based on the boundary overlap between all searchlight pairs, functional networks were detected using a consensus partitioning algorithm (<xref ref-type="bibr" rid="bib46">Lancichinetti and Fortunato, 2012</xref>), as implemented in the Brain Connectivity Toolbox (<xref ref-type="bibr" rid="bib61">Rubinov and Sporns, 2010</xref>). The aim of the partitioning was to identify networks (groups) of searchlights with high boundary overlap between searchlights within each network and low(er) overlap between searchlights in different networks. Specifically, an initial partition into functional networks was created using the Louvain modularity algorithm (<xref ref-type="bibr" rid="bib11">Blondel et al., 2008</xref>), which was refined using a modularity fine-tuning algorithm (<xref ref-type="bibr" rid="bib70">Sun et al., 2009</xref>) to optimize the modularity. The fit of the partitioning was quantified using an asymmetric measure of modularity that assigns a lower importance to negative weights than positive weights (<xref ref-type="bibr" rid="bib62">Rubinov and Sporns, 2011</xref>).</p><p>Because the modularity maximization is stochastic, we repeated the partitioning 100 times. Subsequently, all 100 repetitions for all of the groups were combined into a consensus matrix. Each element in the consensus matrix indicates the proportion of repetitions and groups in which the corresponding two searchlights were assigned to the same network. The consensus matrix was thresholded such that values less than those expected by chance were set to zero (<xref ref-type="bibr" rid="bib7">Bassett et al., 2013</xref>). The values expected by chance were computed by randomly assigning module labels to each searchlight. This thresholded consensus matrix was used as the input for a new partitioning, using the same method described above, until the algorithm converged to a single partition (such that the final consensus matrix consisted only of ones and zeroes).</p><p>The procedure described above was applied for different values of the resolution parameter <italic>γ</italic> (varying γ between 1 and 3; <xref ref-type="bibr" rid="bib59">Reichardt and Bornholdt, 2006</xref>). Increasing the value of <italic>γ</italic> allows for the detection of smaller networks. We used the same values for <italic>γ</italic> across the initial and consensus partitioning. We selected the partition with the highest similarity to a previous whole brain network partition (<xref ref-type="bibr" rid="bib57">Power et al., 2011</xref>), as measured by aMI (<xref ref-type="bibr" rid="bib80">Xuan Vinh et al., 2010</xref>). We specifically chose the parcellation by <xref ref-type="bibr" rid="bib57">Power et al., 2011</xref> as a reference as it proved functional network labels per voxel, rather than regional of interest, making it more similar to our searchlight analyses. To compare our network labels for each searchlight to the voxelwise Power networks, we labeled each searchlight according to the Power network label that occurred most frequently in the searchlight voxels. The highest similarity was observed for gamma = 1.8 (aMI = 0.39). We named each functional network we identified in accordance with the Power network that it overlapped most with, in addition to a descriptive term about the network location (e.g., ventral, posterior) or function (early, late).</p></sec><sec id="s4-11"><title>Co-occurrence of neural state boundaries and events</title><p>On the level of functional networks, we investigated the association between neural boundary co-occurrence and event boundaries. Just like our investigation of the role of boundary strength, we investigated whether taking boundary co-occurrence into account would increase the absolute overlap with events. We did this for both boundary co-occurrence within the network that a given searchlight is part of, as well as the co-occurrence across all searchlights in the brain.</p><p>To do this, we changed the neural state time series for searchlight <italic>i</italic> (<italic>S<sub>i</sub></italic>) such that for timepoints with state transitions, it does not contain ones, but the proportion of searchlights within that searchlights’ network (or within all searchlights in the brain whole brain) that also show a neural state boundary at that timepoint. After redefining <italic>S<sub>i</sub></italic> in these ways, we recomputed the absolute overlap. This resulted in three measures of absolute overlap: the binary overlap (<inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>), the within-network co-occurrence overlap (<inline-formula><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>A</mml:mi><mml:mo>-</mml:mo><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>), and the whole-brain co-occurrence overlap (<inline-formula><mml:math id="inf5"><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>A</mml:mi><mml:mo>-</mml:mo><mml:mi>W</mml:mi><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) and investigated which brain regions showed a significant increase in overlap when we compared <inline-formula><mml:math id="inf6"><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>A</mml:mi><mml:mo>-</mml:mo><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf7"><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>A</mml:mi><mml:mo>-</mml:mo><mml:mi>W</mml:mi><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> to <inline-formula><mml:math id="inf8"><mml:msub><mml:mrow><mml:mi>O</mml:mi><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula><italic><sub>,</sub></italic> across the 15 independent samples.</p><p>To look in more detail at how boundaries that are shared vs. boundaries that are not shared are associated with the occurrence of an event boundary, we performed an additional analysis at the level pairs of searchlights. For each pair of searchlights <italic>i</italic> and <italic>j</italic>, we created three sets of neural state boundaries time series, boundaries unique to searchlights <italic>i</italic> or <italic>j</italic>: <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo>∼</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mo>∼</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and boundaries shared between searchlights <italic>i</italic> and <italic>j</italic>: <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">&amp;</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. More formally, using the binary definition of the neural state boundary time series <italic>S<sub>i</sub></italic> and <italic>S<sub>j</sub></italic>, these are defined at each timepoint <italic>t</italic> as<disp-formula id="equ8"><mml:math id="m8"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">&amp;</mml:mi><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ9"><mml:math id="m9"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo>∼</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">&amp;</mml:mi><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula><disp-formula id="equ10"><mml:math id="m10"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mo>∼</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">&amp;</mml:mi><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Then, we investigated the absolute overlap between each of these three boundary series and the event boundaries as described in the section ‘Comparison of neural state boundaries to event boundaries.’ This resulted in three estimates of absolute boundary overlap; for boundaries unique to searchlight <italic>i</italic> (<inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>O</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo>∼</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) and searchlight <italic>j</italic> (<inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>O</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mo>∼</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) and the shared boundaries (<inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>O</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">&amp;</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>). Then we tested whether the absolute overlap for the shared boundaries was larger than the absolute overlap for non-shared boundaries using the searchlight that showed the largest overlap in their unique boundaries as the baseline: <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>O</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">&amp;</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>O</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo>∼</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>O</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mo>∼</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. Because the absolute boundary overlap is scaled by the total number of neural state boundaries, it is not biased when there is a larger or smaller number of shared/non-shared states between searchlights <italic>i</italic> and <italic>j</italic>. It is only affected by the proportion of neural state boundaries that overlap with an event boundary. If that proportion is the same for shared and non-shared boundaries, the overlap is also the same.</p><p>Finally, we performed an exploratory analysis to further investigate how neural state boundaries are shared across the cortical hierarchy. To this end, we used a WSBM to identify groups of timepoints, which we will refer to as ‘communities’ (<xref ref-type="bibr" rid="bib1">Aicher et al., 2015</xref>). The advantage of WSBM is that it can identify different types of community structures, such as assortative communities (similar to modularity maximization) or core-periphery communities. As the input to the WSBM, we computed the Euclidean distance between the neural state boundary vectors of each timepoint. These neural state boundary vectors contain zeros for searchlights with no boundary and ones for searchlights with a neural state boundary at a specific timepoint. We varied the number of communities from 2 to 10, and we repeated the community detection 1000 times for each number of communities with a random initialization. The WSBM can be informed by the absence or presence of connections and by the connection weights. The alpha parameter <italic>α</italic> determines the trade-off between the two. Because we used an unthresholded Euclidean distance matrix as the input to the WSBM, we based the community detection only on the weights and not on the absence or presence of certain connections (fixing <italic>α</italic> to 1). The optimal number of communities was based on the log-likelihood for each number of communities. After identifying the communities, we ordered them based on the average number of neural states per timepoint in each cluster. The algorithm was implemented in MATLAB using code made available at the author’s personal website (<ext-link ext-link-type="uri" xlink:href="http://tuvalu.santafe.edu/waaronc/wsbm/">http://tuvalu.santafe.edu/waaronc/wsbm/</ext-link>).</p></sec><sec id="s4-12"><title>Statistical testing and data visualization</title><p>The results reported in the article are based on analyses in which data were averaged over all 265 participants (or two groups of ~127 participants for the results in <xref ref-type="fig" rid="fig1">Figure 1</xref>). To investigate the statistical significance of the associations within each searchlight, network, or network pair, we also ran separate analyses within 15 independent samples of participants. For each metric of interest, we obtained a p-value for each searchlight by testing whether this metric differed significantly from zero across all 15 independent samples using a Wilcoxon signed-rank test (<xref ref-type="bibr" rid="bib77">Wilcoxon, 1945</xref>). p-Values were corrected for multiple comparisons using FDR correction (<xref ref-type="bibr" rid="bib9">Benjamini and Hochberg, 2000</xref>). Results in which the sign of the effect in the one group analysis did not match the sign of the average effect across the 15 independent subgroups were considered non-significant.</p><p>For all searchlight-based analyses, p-values from the searchlights were projected to the voxel level and averaged across the searchlights that overlapped each voxel before they were thresholded using the FDR-corrected critical p-value (<xref ref-type="bibr" rid="bib9">Benjamini and Hochberg, 2000</xref>). When projecting the results of the analyses to the voxel level, we excluded voxels for which less than half of the searchlights that covered that voxel were included in the analysis. These excluded searchlights had too few in-brain voxels (see section ‘Whole-brain search for neural state boundaries’). Data were projected to the surface for visualization using the Caret toolbox (<xref ref-type="bibr" rid="bib73">Van Essen et al., 2001</xref>).</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Software, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Software, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Writing - review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Software, Methodology, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: This Cambridge Centre for Ageing Neuroscience study was conducted in compliance with the Helsinki Declaration, and has been approved by the local ethics committee, Cambridgeshire 2 Research Ethics Committee (now East of England - Cambridge Central; reference: 10/H0308/50). Participants gave written informed consent prior to participating in the study.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media xlink:href="elife-77430-transrepform1-v2.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The data used in this project can be requested via - <ext-link ext-link-type="uri" xlink:href="https://camcan-archive.mrc-cbu.cam.ac.uk/dataaccess/">https://camcan-archive.mrc-cbu.cam.ac.uk/dataaccess/</ext-link>. The code used to generate the results in the paper is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/lgeerligs/NestedHierarchy">https://github.com/lgeerligs/NestedHierarchy</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:a6ea5c67afa2941fc010fed0e2eabbe21df7ad8c;origin=https://github.com/lgeerligs/NestedHierarchy;visit=swh:1:snp:7dc238d0a9fc2051fbc449ea3af9ae47d435dcfd;anchor=swh:1:rev:9049f7500c6db1b90b539bcf859e59edb55f5fa6">swh:1:rev:9049f7500c6db1b90b539bcf859e59edb55f5fa6</ext-link>). The improvements to our GSBS algorithm that are presented in this paper are released in a Python package: <ext-link ext-link-type="uri" xlink:href="https://pypi.org/project/statesegmentation/">https://pypi.org/project/statesegmentation/</ext-link>.</p><p>The following previously published dataset was used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset1"><person-group person-group-type="author"><name><surname>Shafto</surname><given-names>MA</given-names></name><name><surname>Tyler</surname><given-names>LK</given-names></name><name><surname>Dixon</surname><given-names>M</given-names></name><name><surname>Taylor</surname><given-names>JR</given-names></name><name><surname>Rowe</surname><given-names>JB</given-names></name><name><surname>Cusack</surname><given-names>R</given-names></name><name><surname>Calder</surname><given-names>AJ</given-names></name><name><surname>Marslen-Wilson</surname><given-names>WD</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name><name><surname>Dalgleish</surname><given-names>T</given-names></name><name><surname>Henson</surname><given-names>RN</given-names></name><name><surname>Brayne</surname><given-names>C</given-names></name><name><surname>Matthews</surname><given-names>FE</given-names></name><collab>Cam-CAN</collab></person-group><year iso-8601-date="2014">2014</year><data-title>Data from the Cambridge Centre for Ageing and Neuroscience</data-title><source>Cam-CAN Data Portal</source><pub-id pub-id-type="accession" xlink:href="https://camcan-archive.mrc-cbu.cam.ac.uk/dataaccess/">Cam-CAN</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>LG was supported by a Vidi grant (VI.Vidi.201.150) from the Netherlands Organization for Scientific Research. KC was supported by the Natural Sciences and Engineering Research Council of Canada (grant RGPIN-2017-03804 to KC) and the Canada Research Chairs program. We thank Aya Ben-Yakov for providing data on the perceived event boundaries in the Cam-CAN movie dataset. Data collection and sharing for this project was provided by the Cambridge Centre for Ageing and Neuroscience (Cam-CAN). Cam-CAN funding was provided by the UK Biotechnology and Biological Sciences Research Council (grant number BB/H008217/1), together with support from the UK Medical Research Council and University of Cambridge, UK.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aicher</surname><given-names>C</given-names></name><name><surname>Jacobs</surname><given-names>AZ</given-names></name><name><surname>Clauset</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Learning latent block structure in weighted networks</article-title><source>Journal of Complex Networks</source><volume>3</volume><fpage>221</fpage><lpage>248</lpage><pub-id pub-id-type="doi">10.1093/comnet/cnu026</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andermane</surname><given-names>N</given-names></name><name><surname>Joensen</surname><given-names>BH</given-names></name><name><surname>Horner</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Forgetting across a hierarchy of episodic representations</article-title><source>Current Opinion in Neurobiology</source><volume>67</volume><fpage>50</fpage><lpage>57</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2020.08.004</pub-id><pub-id pub-id-type="pmid">32882596</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andrews-Hanna</surname><given-names>JR</given-names></name><name><surname>Reidler</surname><given-names>JS</given-names></name><name><surname>Sepulcre</surname><given-names>J</given-names></name><name><surname>Poulin</surname><given-names>R</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Functional-anatomic fractionation of the brain ’ S default network</article-title><source>Neuron</source><volume>65</volume><fpage>550</fpage><lpage>562</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.02.005</pub-id><pub-id pub-id-type="pmid">20188659</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baldassano</surname><given-names>C</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Zadbood</surname><given-names>A</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Discovering event structure in continuous narrative perception and memory</article-title><source>Neuron</source><volume>95</volume><fpage>709</fpage><lpage>721</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.041</pub-id><pub-id pub-id-type="pmid">28772125</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baldassano</surname><given-names>C</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Representation of real-world event schemas during narrative perception</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>9689</fpage><lpage>9699</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0251-18.2018</pub-id><pub-id pub-id-type="pmid">30249790</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baron-Cohen</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Theory of mind and autism: a review</article-title><source>International Review of Research in Mental Retardation</source><volume>23</volume><fpage>169</fpage><lpage>184</lpage><pub-id pub-id-type="doi">10.1016/S0074-7750(00)80010-5</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bassett</surname><given-names>DS</given-names></name><name><surname>Porter</surname><given-names>MA</given-names></name><name><surname>Wymbs</surname><given-names>NF</given-names></name><name><surname>Grafton</surname><given-names>ST</given-names></name><name><surname>Carlson</surname><given-names>JM</given-names></name><name><surname>Mucha</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Robust detection of dynamic community structure in networks</article-title><source>Chaos</source><volume>23</volume><elocation-id>013142</elocation-id><pub-id pub-id-type="doi">10.1063/1.4790830</pub-id><pub-id pub-id-type="pmid">23556979</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ben-Yakov</surname><given-names>A</given-names></name><name><surname>Henson</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The hippocampal film editor: sensitivity and specificity to event boundaries in continuous experience</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>10057</fpage><lpage>10068</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0524-18.2018</pub-id><pub-id pub-id-type="pmid">30301758</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benjamini</surname><given-names>Y</given-names></name><name><surname>Hochberg</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Controlling the false discovery rate: a practical and powerful approach to multiple testing</article-title><source>Journal of the Royal Statistical Society</source><volume>57</volume><fpage>289</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1111/j.2517-6161.1995.tb02031.x</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benoit</surname><given-names>RG</given-names></name><name><surname>Szpunar</surname><given-names>KK</given-names></name><name><surname>Schacter</surname><given-names>DL</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Ventromedial prefrontal cortex supports affective future simulation by integrating distributed knowledge</article-title><source>PNAS</source><volume>111</volume><fpage>16550</fpage><lpage>16555</lpage><pub-id pub-id-type="doi">10.1073/pnas.1419274111</pub-id><pub-id pub-id-type="pmid">25368170</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blondel</surname><given-names>VD</given-names></name><name><surname>Guillaume</surname><given-names>JL</given-names></name><name><surname>Lambiotte</surname><given-names>R</given-names></name><name><surname>Lefebvre</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Fast unfolding of communities in large networks</article-title><source>Journal of Statistical Mechanics</source><volume>2008</volume><elocation-id>10008</elocation-id><pub-id pub-id-type="doi">10.1088/1742-5468/2008/10/P10008</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bromis</surname><given-names>K</given-names></name><name><surname>Raykov</surname><given-names>PP</given-names></name><name><surname>Wickens</surname><given-names>L</given-names></name><name><surname>Roseboom</surname><given-names>W</given-names></name><name><surname>Bird</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>The neural representation of events is dominated by elements that are most reliably present</article-title><source>Journal of Cognitive Neuroscience</source><volume>34</volume><fpage>517</fpage><lpage>531</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01802</pub-id><pub-id pub-id-type="pmid">34942648</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buschman</surname><given-names>TJ</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Top-Down versus bottom-up control of attention in the prefrontal and posterior parietal cortices</article-title><source>Science</source><volume>315</volume><fpage>1860</fpage><lpage>1862</lpage><pub-id pub-id-type="doi">10.1126/science.1138071</pub-id><pub-id pub-id-type="pmid">17395832</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Campbell</surname><given-names>KL</given-names></name><name><surname>Grigg</surname><given-names>O</given-names></name><name><surname>Saverino</surname><given-names>C</given-names></name><name><surname>Churchill</surname><given-names>N</given-names></name><name><surname>Grady</surname><given-names>CL</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Age differences in the intrinsic functional connectivity of default network subsystems</article-title><source>Frontiers in Aging Neuroscience</source><volume>5</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.3389/fnagi.2013.00073</pub-id><pub-id pub-id-type="pmid">24294203</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Campbell</surname><given-names>KL</given-names></name><name><surname>Shafto</surname><given-names>MA</given-names></name><name><surname>Wright</surname><given-names>P</given-names></name><name><surname>Tsvetanov</surname><given-names>KA</given-names></name><name><surname>Geerligs</surname><given-names>L</given-names></name><name><surname>Cusack</surname><given-names>R</given-names></name><name><surname>Tyler</surname><given-names>LK</given-names></name><collab>Cam-CAN</collab></person-group><year iso-8601-date="2015">2015</year><article-title>Idiosyncratic responding during movie-watching predicted by age differences in attentional control</article-title><source>Neurobiology of Aging</source><volume>36</volume><fpage>3045</fpage><lpage>3055</lpage><pub-id pub-id-type="doi">10.1016/j.neurobiolaging.2015.07.028</pub-id><pub-id pub-id-type="pmid">26359527</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chien</surname><given-names>HYS</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Constructing and forgetting temporal context in the human cerebral cortex</article-title><source>Neuron</source><volume>106</volume><fpage>675</fpage><lpage>686</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.02.013</pub-id><pub-id pub-id-type="pmid">32164874</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clarke</surname><given-names>A</given-names></name><name><surname>Tyler</surname><given-names>LK</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Understanding what we see: how we derive meaning from vision</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>677</fpage><lpage>687</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.08.008</pub-id><pub-id pub-id-type="pmid">26440124</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clewett</surname><given-names>D</given-names></name><name><surname>DuBrow</surname><given-names>S</given-names></name><name><surname>Davachi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Transcending time in the brain: how event memories are constructed from experience</article-title><source>Hippocampus</source><volume>29</volume><fpage>162</fpage><lpage>183</lpage><pub-id pub-id-type="doi">10.1002/hipo.23074</pub-id><pub-id pub-id-type="pmid">30734391</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>RW</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>AFNI: software for analysis and visualization of functional magnetic resonance NeuroImages</article-title><source>Computers and Biomedical Research, an International Journal</source><volume>29</volume><fpage>162</fpage><lpage>173</lpage><pub-id pub-id-type="doi">10.1006/cbmr.1996.0014</pub-id><pub-id pub-id-type="pmid">8812068</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davis</surname><given-names>EE</given-names></name><name><surname>Chemnitz</surname><given-names>E</given-names></name><name><surname>Collins</surname><given-names>TK</given-names></name><name><surname>Geerligs</surname><given-names>L</given-names></name><name><surname>Campbell</surname><given-names>KL</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Looking the same, but remembering differently: preserved eye-movement synchrony with age during movie watching</article-title><source>Psychology and Aging</source><volume>36</volume><fpage>604</fpage><lpage>615</lpage><pub-id pub-id-type="doi">10.1037/pag0000615</pub-id><pub-id pub-id-type="pmid">34291964</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desikan</surname><given-names>RS</given-names></name><name><surname>Ségonne</surname><given-names>F</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Quinn</surname><given-names>BT</given-names></name><name><surname>Dickerson</surname><given-names>BC</given-names></name><name><surname>Blacker</surname><given-names>D</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Maguire</surname><given-names>RP</given-names></name><name><surname>Hyman</surname><given-names>BT</given-names></name><name><surname>Albert</surname><given-names>MS</given-names></name><name><surname>Killiany</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>An automated labeling system for subdividing the human cerebral cortex on MRI scans into gyral based regions of interest</article-title><source>NeuroImage</source><volume>31</volume><fpage>968</fpage><lpage>980</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.01.021</pub-id><pub-id pub-id-type="pmid">16530430</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DiCarlo</surname><given-names>JJ</given-names></name><name><surname>Cox</surname><given-names>DD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Untangling invariant object recognition</article-title><source>Trends in Cognitive Sciences</source><volume>11</volume><fpage>333</fpage><lpage>341</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2007.06.010</pub-id><pub-id pub-id-type="pmid">17631409</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duncan</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The multiple-demand (MD) system of the primate brain: mental programs for intelligent behaviour</article-title><source>Trends in Cognitive Sciences</source><volume>14</volume><fpage>172</fpage><lpage>179</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2010.01.004</pub-id><pub-id pub-id-type="pmid">20171926</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ezzyat</surname><given-names>Y</given-names></name><name><surname>Davachi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>What constitutes an episode in episodic memory?</article-title><source>Psychological Science</source><volume>22</volume><fpage>243</fpage><lpage>252</lpage><pub-id pub-id-type="doi">10.1177/0956797610393742</pub-id><pub-id pub-id-type="pmid">21178116</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Flores</surname><given-names>S</given-names></name><name><surname>Bailey</surname><given-names>HR</given-names></name><name><surname>Eisenberg</surname><given-names>ML</given-names></name><name><surname>Zacks</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Event segmentation improves event memory up to one month later</article-title><source>Journal of Experimental Psychology. Learning, Memory, and Cognition</source><volume>43</volume><fpage>1183</fpage><lpage>1202</lpage><pub-id pub-id-type="doi">10.1037/xlm0000367</pub-id><pub-id pub-id-type="pmid">28383955</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuster</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The prefrontal cortex -- an update: time is of the essence</article-title><source>Neuron</source><volume>30</volume><fpage>319</fpage><lpage>333</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(01)00285-9</pub-id><pub-id pub-id-type="pmid">11394996</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geerligs</surname><given-names>L</given-names></name><name><surname>Campbell</surname><given-names>KL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Age-Related differences in information processing during movie watching</article-title><source>Neurobiology of Aging</source><volume>72</volume><fpage>106</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.1016/j.neurobiolaging.2018.07.025</pub-id><pub-id pub-id-type="pmid">30243125</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geerligs</surname><given-names>L</given-names></name><name><surname>van Gerven</surname><given-names>M</given-names></name><name><surname>Güçlü</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Detecting neural state transitions underlying event segmentation</article-title><source>NeuroImage</source><volume>236</volume><elocation-id>118085</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.118085</pub-id><pub-id pub-id-type="pmid">33882350</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilboa</surname><given-names>A</given-names></name><name><surname>Marlatte</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neurobiology of schemas and schema-mediated memory</article-title><source>Trends in Cognitive Sciences</source><volume>21</volume><fpage>618</fpage><lpage>631</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.04.013</pub-id><pub-id pub-id-type="pmid">28551107</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gordon</surname><given-names>EM</given-names></name><name><surname>Laumann</surname><given-names>TO</given-names></name><name><surname>Marek</surname><given-names>S</given-names></name><name><surname>Raut</surname><given-names>RV</given-names></name><name><surname>Gratton</surname><given-names>C</given-names></name><name><surname>Newbold</surname><given-names>DJ</given-names></name><name><surname>Greene</surname><given-names>DJ</given-names></name><name><surname>Coalson</surname><given-names>RS</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Schlaggar</surname><given-names>BL</given-names></name><name><surname>Petersen</surname><given-names>SE</given-names></name><name><surname>Dosenbach</surname><given-names>NUF</given-names></name><name><surname>Nelson</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Default-Mode network streams for coupling to language and control systems</article-title><source>PNAS</source><volume>117</volume><fpage>17308</fpage><lpage>17319</lpage><pub-id pub-id-type="doi">10.1073/pnas.2005238117</pub-id><pub-id pub-id-type="pmid">32632019</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gregoriou</surname><given-names>GG</given-names></name><name><surname>Gotts</surname><given-names>SJ</given-names></name><name><surname>Zhou</surname><given-names>H</given-names></name><name><surname>Desimone</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>High-Frequency, long-range coupling between prefrontal and visual cortex during attention</article-title><source>Science</source><volume>324</volume><fpage>1207</fpage><lpage>1210</lpage><pub-id pub-id-type="doi">10.1126/science.1171402</pub-id><pub-id pub-id-type="pmid">19478185</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guntupalli</surname><given-names>JS</given-names></name><name><surname>Hanke</surname><given-names>M</given-names></name><name><surname>Halchenko</surname><given-names>YO</given-names></name><name><surname>Connolly</surname><given-names>AC</given-names></name><name><surname>Ramadge</surname><given-names>PJ</given-names></name><name><surname>Haxby</surname><given-names>JV</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A model of representational spaces in human cortex</article-title><source>Cerebral Cortex</source><volume>26</volume><fpage>2919</fpage><lpage>2934</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw068</pub-id><pub-id pub-id-type="pmid">26980615</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamilton</surname><given-names>LS</given-names></name><name><surname>Huth</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The revolution will not be controlled: natural stimuli in speech neuroscience</article-title><source>Language, Cognition and Neuroscience</source><volume>35</volume><fpage>573</fpage><lpage>582</lpage><pub-id pub-id-type="doi">10.1080/23273798.2018.1499946</pub-id><pub-id pub-id-type="pmid">32656294</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanke</surname><given-names>M</given-names></name><name><surname>Halchenko</surname><given-names>YO</given-names></name><name><surname>Sederberg</surname><given-names>PB</given-names></name><name><surname>Hanson</surname><given-names>SJ</given-names></name><name><surname>Haxby</surname><given-names>JV</given-names></name><name><surname>Pollmann</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>PyMVPA: a python toolbox for multivariate pattern analysis of fMRI data</article-title><source>Neuroinformatics</source><volume>7</volume><fpage>37</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1007/s12021-008-9041-y</pub-id><pub-id pub-id-type="pmid">19184561</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname><given-names>Uri</given-names></name><name><surname>Yang</surname><given-names>E</given-names></name><name><surname>Vallines</surname><given-names>I</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name><name><surname>Rubin</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A hierarchy of temporal receptive windows in human cortex</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>2539</fpage><lpage>2550</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5487-07.2008</pub-id><pub-id pub-id-type="pmid">18322098</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Avidan</surname><given-names>G</given-names></name><name><surname>Gelbard</surname><given-names>H</given-names></name><name><surname>Vallines</surname><given-names>I</given-names></name><name><surname>Harel</surname><given-names>M</given-names></name><name><surname>Minshew</surname><given-names>N</given-names></name><name><surname>Behrmann</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Shared and idiosyncratic cortical activation patterns in autism revealed under continuous real-life viewing conditions</article-title><source>Autism Research</source><volume>2</volume><fpage>220</fpage><lpage>231</lpage><pub-id pub-id-type="doi">10.1002/aur.89</pub-id><pub-id pub-id-type="pmid">19708061</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Hierarchical process memory: memory as an integral component of information processing</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>304</fpage><lpage>313</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.04.006</pub-id><pub-id pub-id-type="pmid">25980649</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holroyd</surname><given-names>CB</given-names></name><name><surname>Coles</surname><given-names>MGH</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>The neural basis of human error processing: reinforcement learning, dopamine, and the error-related negativity</article-title><source>Psychological Review</source><volume>109</volume><fpage>679</fpage><lpage>709</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.109.4.679</pub-id><pub-id pub-id-type="pmid">12374324</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Honey</surname><given-names>CJ</given-names></name><name><surname>Thesen</surname><given-names>T</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name><name><surname>Silbert</surname><given-names>LJ</given-names></name><name><surname>Carlson</surname><given-names>CE</given-names></name><name><surname>Devinsky</surname><given-names>O</given-names></name><name><surname>Doyle</surname><given-names>WK</given-names></name><name><surname>Rubin</surname><given-names>N</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Slow cortical dynamics and the accumulation of information over long timescales</article-title><source>Neuron</source><volume>76</volume><fpage>423</fpage><lpage>434</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.08.011</pub-id><pub-id pub-id-type="pmid">23083743</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krueger</surname><given-names>F</given-names></name><name><surname>Barbey</surname><given-names>AK</given-names></name><name><surname>Grafman</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The medial prefrontal cortex mediates social event knowledge</article-title><source>Trends in Cognitive Sciences</source><volume>13</volume><fpage>103</fpage><lpage>109</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2008.12.005</pub-id><pub-id pub-id-type="pmid">19223228</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kundu</surname><given-names>P</given-names></name><name><surname>Inati</surname><given-names>SJ</given-names></name><name><surname>Evans</surname><given-names>JW</given-names></name><name><surname>Luh</surname><given-names>WM</given-names></name><name><surname>Bandettini</surname><given-names>PA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Differentiating BOLD and non-BOLD signals in fMRI time series using multi-echo EPI</article-title><source>NeuroImage</source><volume>60</volume><fpage>1759</fpage><lpage>1770</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.12.028</pub-id><pub-id pub-id-type="pmid">22209809</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kundu</surname><given-names>P</given-names></name><name><surname>Brenowitz</surname><given-names>ND</given-names></name><name><surname>Voon</surname><given-names>V</given-names></name><name><surname>Worbe</surname><given-names>Y</given-names></name><name><surname>Vértes</surname><given-names>PE</given-names></name><name><surname>Inati</surname><given-names>SJ</given-names></name><name><surname>Saad</surname><given-names>ZS</given-names></name><name><surname>Bandettini</surname><given-names>PA</given-names></name><name><surname>Bullmore</surname><given-names>ET</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Integrated strategy for improving functional connectivity mapping using multiecho fMRI</article-title><source>PNAS</source><volume>110</volume><fpage>16187</fpage><lpage>16192</lpage><pub-id pub-id-type="doi">10.1073/pnas.1301725110</pub-id><pub-id pub-id-type="pmid">24038744</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kurby</surname><given-names>CA</given-names></name><name><surname>Zacks</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Segmentation in the perception and memory of events</article-title><source>Trends in Cognitive Sciences</source><volume>12</volume><fpage>72</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2007.11.004</pub-id><pub-id pub-id-type="pmid">18178125</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kurby</surname><given-names>CA</given-names></name><name><surname>Zacks</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Preserved neural event segmentation in healthy older adults</article-title><source>Psychology and Aging</source><volume>33</volume><fpage>232</fpage><lpage>245</lpage><pub-id pub-id-type="doi">10.1037/pag0000226</pub-id><pub-id pub-id-type="pmid">29446971</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name><name><surname>Sage</surname><given-names>K</given-names></name><name><surname>Jones</surname><given-names>RW</given-names></name><name><surname>Mayberry</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Coherent concepts are computed in the anterior temporal lobes</article-title><source>PNAS</source><volume>107</volume><fpage>2717</fpage><lpage>2722</lpage><pub-id pub-id-type="doi">10.1073/pnas.0907307107</pub-id><pub-id pub-id-type="pmid">20133780</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lancichinetti</surname><given-names>A</given-names></name><name><surname>Fortunato</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Consensus clustering in complex networks</article-title><source>Scientific Reports</source><volume>2</volume><elocation-id>336</elocation-id><pub-id pub-id-type="doi">10.1038/srep00336</pub-id><pub-id pub-id-type="pmid">22468223</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>H</given-names></name><name><surname>Bellana</surname><given-names>B</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>What can narratives tell us about the neural bases of human memory?</article-title><source>Current Opinion in Behavioral Sciences</source><volume>32</volume><fpage>111</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2020.02.007</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lei</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Yuan</surname><given-names>H</given-names></name><name><surname>Mantini</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neuronal oscillations and functional interactions between resting state networks</article-title><source>Human Brain Mapping</source><volume>35</volume><fpage>3517</fpage><lpage>3528</lpage><pub-id pub-id-type="doi">10.1002/hbm.22418</pub-id><pub-id pub-id-type="pmid">25050432</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lerner</surname><given-names>Y</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name><name><surname>Silbert</surname><given-names>LJ</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Topographic mapping of a hierarchy of temporal receptive windows using a narrated story</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>2906</fpage><lpage>2915</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3684-10.2011</pub-id><pub-id pub-id-type="pmid">21414912</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>W</given-names></name><name><surname>Shi</surname><given-names>Y</given-names></name><name><surname>Cousins</surname><given-names>JN</given-names></name><name><surname>Kohn</surname><given-names>N</given-names></name><name><surname>Fernández</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Hippocampal-medial prefrontal event segmentation and integration contribute to episodic memory formation</article-title><source>Cerebral Cortex</source><volume>32</volume><fpage>949</fpage><lpage>969</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhab258</pub-id><pub-id pub-id-type="pmid">34398213</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>KH</given-names></name><name><surname>Hung</surname><given-names>SC</given-names></name><name><surname>Wen</surname><given-names>H</given-names></name><name><surname>Marussich</surname><given-names>L</given-names></name><name><surname>Liu</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Influences of high-level features, gaze, and scene transitions on the reliability of BOLD responses to natural movie stimuli</article-title><source>PLOS ONE</source><volume>11</volume><elocation-id>e0161797</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0161797</pub-id><pub-id pub-id-type="pmid">27564573</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nelson</surname><given-names>MJ</given-names></name><name><surname>El Karoui</surname><given-names>I</given-names></name><name><surname>Giber</surname><given-names>K</given-names></name><name><surname>Yang</surname><given-names>X</given-names></name><name><surname>Cohen</surname><given-names>L</given-names></name><name><surname>Koopman</surname><given-names>H</given-names></name><name><surname>Cash</surname><given-names>SS</given-names></name><name><surname>Naccache</surname><given-names>L</given-names></name><name><surname>Hale</surname><given-names>JT</given-names></name><name><surname>Pallier</surname><given-names>C</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neurophysiological dynamics of phrase-structure building during sentence processing</article-title><source>PNAS</source><volume>114</volume><fpage>E3669</fpage><lpage>E3678</lpage><pub-id pub-id-type="doi">10.1073/pnas.1701590114</pub-id><pub-id pub-id-type="pmid">28416691</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newtson</surname><given-names>D</given-names></name><name><surname>Engquist</surname><given-names>GA</given-names></name><name><surname>Bois</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>The objective basis of behavior units</article-title><source>Journal of Personality and Social Psychology</source><volume>35</volume><fpage>847</fpage><lpage>862</lpage><pub-id pub-id-type="doi">10.1037/0022-3514.35.12.847</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newtson</surname><given-names>D</given-names></name><name><surname>Rindner</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Variation in behavior perception and ability Attribution</article-title><source>Journal of Personality and Social Psychology</source><volume>37</volume><fpage>1847</fpage><lpage>1858</lpage><pub-id pub-id-type="doi">10.1037/0022-3514.37.10.1847</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Northoff</surname><given-names>G</given-names></name><name><surname>Heinzel</surname><given-names>A</given-names></name><name><surname>de Greck</surname><given-names>M</given-names></name><name><surname>Bermpohl</surname><given-names>F</given-names></name><name><surname>Dobrowolny</surname><given-names>H</given-names></name><name><surname>Panksepp</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Self-referential processing in our brain -- a meta-analysis of imaging studies on the self</article-title><source>NeuroImage</source><volume>31</volume><fpage>440</fpage><lpage>457</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2005.12.002</pub-id><pub-id pub-id-type="pmid">16466680</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pettijohn</surname><given-names>KA</given-names></name><name><surname>Radvansky</surname><given-names>GA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Narrative event boundaries, reading times, and expectation</article-title><source>Memory &amp; Cognition</source><volume>44</volume><fpage>1064</fpage><lpage>1075</lpage><pub-id pub-id-type="doi">10.3758/s13421-016-0619-6</pub-id><pub-id pub-id-type="pmid">27170375</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Power</surname><given-names>JD</given-names></name><name><surname>Cohen</surname><given-names>AL</given-names></name><name><surname>Nelson</surname><given-names>SM</given-names></name><name><surname>Wig</surname><given-names>GS</given-names></name><name><surname>Barnes</surname><given-names>KA</given-names></name><name><surname>Church</surname><given-names>JA</given-names></name><name><surname>Vogel</surname><given-names>AC</given-names></name><name><surname>Laumann</surname><given-names>TO</given-names></name><name><surname>Miezin</surname><given-names>FM</given-names></name><name><surname>Schlaggar</surname><given-names>BL</given-names></name><name><surname>Petersen</surname><given-names>SE</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Functional network organization of the human brain</article-title><source>Neuron</source><volume>72</volume><fpage>665</fpage><lpage>678</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.09.006</pub-id><pub-id pub-id-type="pmid">22099467</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ranganath</surname><given-names>C</given-names></name><name><surname>Ritchey</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Two cortical systems for memory-guided behaviour</article-title><source>Nature Reviews. Neuroscience</source><volume>13</volume><fpage>713</fpage><lpage>726</lpage><pub-id pub-id-type="doi">10.1038/nrn3338</pub-id><pub-id pub-id-type="pmid">22992647</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reichardt</surname><given-names>J</given-names></name><name><surname>Bornholdt</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Statistical mechanics of community detection</article-title><source>Physical Review. E, Statistical, Nonlinear, and Soft Matter Physics</source><volume>74</volume><elocation-id>016110</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevE.74.016110</pub-id><pub-id pub-id-type="pmid">16907154</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rogers</surname><given-names>TT</given-names></name><name><surname>Lambon Ralph</surname><given-names>MA</given-names></name><name><surname>Garrard</surname><given-names>P</given-names></name><name><surname>Bozeat</surname><given-names>S</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name><name><surname>Hodges</surname><given-names>JR</given-names></name><name><surname>Patterson</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Structure and deterioration of semantic memory: a neuropsychological and computational investigation</article-title><source>Psychological Review</source><volume>111</volume><fpage>205</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.111.1.205</pub-id><pub-id pub-id-type="pmid">14756594</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubinov</surname><given-names>M</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Complex network measures of brain connectivity: uses and interpretations</article-title><source>NeuroImage</source><volume>52</volume><fpage>1059</fpage><lpage>1069</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.10.003</pub-id><pub-id pub-id-type="pmid">19819337</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rubinov</surname><given-names>M</given-names></name><name><surname>Sporns</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Weight-conserving characterization of complex functional brain networks</article-title><source>NeuroImage</source><volume>56</volume><fpage>2068</fpage><lpage>2079</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.03.069</pub-id><pub-id pub-id-type="pmid">21459148</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sargent</surname><given-names>JQ</given-names></name><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Hambrick</surname><given-names>DZ</given-names></name><name><surname>Zacks</surname><given-names>RT</given-names></name><name><surname>Kurby</surname><given-names>CA</given-names></name><name><surname>Bailey</surname><given-names>HR</given-names></name><name><surname>Eisenberg</surname><given-names>ML</given-names></name><name><surname>Beck</surname><given-names>TM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Event segmentation ability uniquely predicts event memory</article-title><source>Cognition</source><volume>129</volume><fpage>241</fpage><lpage>255</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2013.07.002</pub-id><pub-id pub-id-type="pmid">23942350</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shafto</surname><given-names>MA</given-names></name><name><surname>Tyler</surname><given-names>LK</given-names></name><name><surname>Dixon</surname><given-names>M</given-names></name><name><surname>Taylor</surname><given-names>JR</given-names></name><name><surname>Rowe</surname><given-names>JB</given-names></name><name><surname>Cusack</surname><given-names>R</given-names></name><name><surname>Calder</surname><given-names>AJ</given-names></name><name><surname>Marslen-Wilson</surname><given-names>WD</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name><name><surname>Dalgleish</surname><given-names>T</given-names></name><name><surname>Henson</surname><given-names>RN</given-names></name><name><surname>Brayne</surname><given-names>C</given-names></name><name><surname>Matthews</surname><given-names>FE</given-names></name><collab>Cam-CAN</collab></person-group><year iso-8601-date="2014">2014</year><article-title>The Cambridge centre for ageing and neuroscience (cam-CAN) study protocol: a cross-sectional, lifespan, multidisciplinary examination of healthy cognitive ageing</article-title><source>BMC Neurology</source><volume>14</volume><elocation-id>204</elocation-id><pub-id pub-id-type="doi">10.1186/s12883-014-0204-1</pub-id><pub-id pub-id-type="pmid">25412575</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shin</surname><given-names>YS</given-names></name><name><surname>DuBrow</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Structuring memory through inference-based event segmentation</article-title><source>Topics in Cognitive Science</source><volume>13</volume><fpage>106</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1111/tops.12505</pub-id><pub-id pub-id-type="pmid">32459391</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simony</surname><given-names>E</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Lositsky</surname><given-names>O</given-names></name><name><surname>Yeshurun</surname><given-names>Y</given-names></name><name><surname>Wiesel</surname><given-names>A</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Dynamic reconfiguration of the default mode network during narrative comprehension</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>12141</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms12141</pub-id><pub-id pub-id-type="pmid">27424918</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Son</surname><given-names>J</given-names></name><name><surname>Ai</surname><given-names>L</given-names></name><name><surname>Lim</surname><given-names>R</given-names></name><name><surname>Xu</surname><given-names>T</given-names></name><name><surname>Colcombe</surname><given-names>S</given-names></name><name><surname>Franco</surname><given-names>AR</given-names></name><name><surname>Cloud</surname><given-names>J</given-names></name><name><surname>LaConte</surname><given-names>S</given-names></name><name><surname>Lisinski</surname><given-names>J</given-names></name><name><surname>Klein</surname><given-names>A</given-names></name><name><surname>Craddock</surname><given-names>RC</given-names></name><name><surname>Milham</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Evaluating fmri-based estimation of eye gaze during naturalistic viewing</article-title><source>Cerebral Cortex</source><volume>30</volume><fpage>1171</fpage><lpage>1184</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhz157</pub-id><pub-id pub-id-type="pmid">31595961</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Speer</surname><given-names>NK</given-names></name><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Reynolds</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Human brain activity time-locked to narrative event boundaries</article-title><source>Psychological Science</source><volume>18</volume><fpage>449</fpage><lpage>455</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.2007.01920.x</pub-id><pub-id pub-id-type="pmid">17576286</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stephens</surname><given-names>GJ</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A place for time: the spatiotemporal structure of neural dynamics during natural audition</article-title><source>Journal of Neurophysiology</source><volume>110</volume><fpage>2019</fpage><lpage>2026</lpage><pub-id pub-id-type="doi">10.1152/jn.00268.2013</pub-id><pub-id pub-id-type="pmid">23926041</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>Y</given-names></name><name><surname>Danila</surname><given-names>B</given-names></name><name><surname>Josić</surname><given-names>K</given-names></name><name><surname>Bassler</surname><given-names>KE</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Improved community structure detection using a modified fine-tuning strategy</article-title><source>Europhysics Letters</source><volume>86</volume><elocation-id>28004</elocation-id><pub-id pub-id-type="doi">10.1209/0295-5075/86/28004</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>JR</given-names></name><name><surname>Williams</surname><given-names>N</given-names></name><name><surname>Cusack</surname><given-names>R</given-names></name><name><surname>Auer</surname><given-names>T</given-names></name><name><surname>Shafto</surname><given-names>MA</given-names></name><name><surname>Dixon</surname><given-names>M</given-names></name><name><surname>Tyler</surname><given-names>LK</given-names></name><name><surname>Henson</surname><given-names>RN</given-names></name><collab>Cam-Can</collab></person-group><year iso-8601-date="2017">2017</year><article-title>The Cambridge centre for ageing and neuroscience (cam-CAN) data Repository: structural and functional MRI, MEG, and cognitive data from a cross-sectional adult lifespan sample</article-title><source>NeuroImage</source><volume>144</volume><fpage>262</fpage><lpage>269</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.09.018</pub-id><pub-id pub-id-type="pmid">26375206</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taylor</surname><given-names>AJ</given-names></name><name><surname>Kim</surname><given-names>JH</given-names></name><name><surname>Ress</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Characterization of the hemodynamic response function across the majority of human cerebral cortex</article-title><source>NeuroImage</source><volume>173</volume><fpage>322</fpage><lpage>331</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.02.061</pub-id><pub-id pub-id-type="pmid">29501554</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Drury</surname><given-names>HA</given-names></name><name><surname>Dickson</surname><given-names>J</given-names></name><name><surname>Harwell</surname><given-names>J</given-names></name><name><surname>Hanlon</surname><given-names>D</given-names></name><name><surname>Anderson</surname><given-names>CH</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>An integrated software suite for surface-based analyses of cerebral cortex</article-title><source>Journal of the American Medical Informatics Association</source><volume>8</volume><fpage>443</fpage><lpage>459</lpage><pub-id pub-id-type="doi">10.1136/jamia.2001.0080443</pub-id><pub-id pub-id-type="pmid">11522765</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Kesteren</surname><given-names>MTR</given-names></name><name><surname>Ruiter</surname><given-names>DJ</given-names></name><name><surname>Fernández</surname><given-names>G</given-names></name><name><surname>Henson</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>How schema and novelty augment memory formation</article-title><source>Trends in Neurosciences</source><volume>35</volume><fpage>211</fpage><lpage>219</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2012.02.001</pub-id><pub-id pub-id-type="pmid">22398180</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vernet</surname><given-names>M</given-names></name><name><surname>Quentin</surname><given-names>R</given-names></name><name><surname>Chanes</surname><given-names>L</given-names></name><name><surname>Mitsumasu</surname><given-names>A</given-names></name><name><surname>Valero-Cabré</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Frontal eye field, where art thou? anatomy, function, and non-invasive manipulation of frontal regions involved in eye movements and associated cognitive operations</article-title><source>Frontiers in Integrative Neuroscience</source><volume>8</volume><elocation-id>8</elocation-id><pub-id pub-id-type="doi">10.3389/fnint.2014.00066</pub-id><pub-id pub-id-type="pmid">25202241</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wen</surname><given-names>T</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name><name><surname>Mitchell</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Hierarchical representation of multistep tasks in multiple-demand and default mode networks</article-title><source>The Journal of Neuroscience</source><volume>40</volume><fpage>7724</fpage><lpage>7738</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0594-20.2020</pub-id><pub-id pub-id-type="pmid">32868460</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilcoxon</surname><given-names>F</given-names></name></person-group><year iso-8601-date="1945">1945</year><article-title>Individual comparisons by ranking methods</article-title><source>Biometrics Bulletin</source><volume>1</volume><fpage>80</fpage><lpage>83</lpage><pub-id pub-id-type="doi">10.2307/3001968</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Willems</surname><given-names>RM</given-names></name><name><surname>Nastase</surname><given-names>SA</given-names></name><name><surname>Milivojevic</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Narratives for neuroscience</article-title><source>Trends in Neurosciences</source><volume>43</volume><fpage>271</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2020.03.003</pub-id><pub-id pub-id-type="pmid">32353331</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>GR</given-names></name><name><surname>Colenbier</surname><given-names>N</given-names></name><name><surname>Van Den Bossche</surname><given-names>S</given-names></name><name><surname>Clauw</surname><given-names>K</given-names></name><name><surname>Johri</surname><given-names>A</given-names></name><name><surname>Tandon</surname><given-names>M</given-names></name><name><surname>Marinazzo</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>RsHRF: a toolbox for resting-state HRF estimation and deconvolution</article-title><source>NeuroImage</source><volume>244</volume><elocation-id>118591</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.118591</pub-id><pub-id pub-id-type="pmid">34560269</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xuan Vinh</surname><given-names>N</given-names></name><name><surname>Epps</surname><given-names>J</given-names></name><name><surname>Bailey</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Information theoretic measures for clusterings comparison: variants, properties, normalization and correction for chance</article-title><source>Journal of Machine Learning Research: JMLR</source><volume>11</volume><fpage>2837</fpage><lpage>2854</lpage><pub-id pub-id-type="doi">10.5555/1756006.1953024</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yeo</surname><given-names>BTT</given-names></name><name><surname>Krienen</surname><given-names>FM</given-names></name><name><surname>Sepulcre</surname><given-names>J</given-names></name><name><surname>Sabuncu</surname><given-names>MR</given-names></name><name><surname>Lashkari</surname><given-names>D</given-names></name><name><surname>Hollinshead</surname><given-names>M</given-names></name><name><surname>Roffman</surname><given-names>JL</given-names></name><name><surname>Smoller</surname><given-names>JW</given-names></name><name><surname>Zöllei</surname><given-names>L</given-names></name><name><surname>Polimeni</surname><given-names>JR</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Liu</surname><given-names>H</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The organization of the human cerebral cortex estimated by intrinsic functional connectivity</article-title><source>Journal of Neurophysiology</source><volume>106</volume><fpage>1125</fpage><lpage>1165</lpage><pub-id pub-id-type="doi">10.1152/jn.00338.2011</pub-id><pub-id pub-id-type="pmid">21653723</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Braver</surname><given-names>TS</given-names></name><name><surname>Sheridan</surname><given-names>MA</given-names></name><name><surname>Donaldson</surname><given-names>DI</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Ollinger</surname><given-names>JM</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name><name><surname>Raichle</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2001">2001a</year><article-title>Human brain activity time-locked to perceptual event boundaries</article-title><source>Nature Neuroscience</source><volume>4</volume><fpage>651</fpage><lpage>655</lpage><pub-id pub-id-type="doi">10.1038/88486</pub-id><pub-id pub-id-type="pmid">11369948</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Tversky</surname><given-names>B</given-names></name><name><surname>Iyer</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2001">2001b</year><article-title>Perceiving, remembering, and communicating structure in events</article-title><source>Journal of Experimental Psychology. General</source><volume>130</volume><fpage>29</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1037/0096-3445.130.1.29</pub-id><pub-id pub-id-type="pmid">11293458</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Speer</surname><given-names>NK</given-names></name><name><surname>Vettel</surname><given-names>JM</given-names></name><name><surname>Jacoby</surname><given-names>LL</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Event understanding and memory in healthy aging and dementia of the Alzheimer type</article-title><source>Psychology and Aging</source><volume>21</volume><fpage>466</fpage><lpage>482</lpage><pub-id pub-id-type="doi">10.1037/0882-7974.21.3.466</pub-id><pub-id pub-id-type="pmid">16953710</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Speer</surname><given-names>NK</given-names></name><name><surname>Swallow</surname><given-names>KM</given-names></name><name><surname>Braver</surname><given-names>TS</given-names></name><name><surname>Reynolds</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Event perception: a mind-brain perspective</article-title><source>Psychological Bulletin</source><volume>133</volume><fpage>273</fpage><lpage>293</lpage><pub-id pub-id-type="doi">10.1037/0033-2909.133.2.273</pub-id><pub-id pub-id-type="pmid">17338600</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Speer</surname><given-names>NK</given-names></name><name><surname>Reynolds</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Segmentation in reading and film comprehension</article-title><source>Journal of Experimental Psychology. General</source><volume>138</volume><fpage>307</fpage><lpage>327</lpage><pub-id pub-id-type="doi">10.1037/a0015305</pub-id><pub-id pub-id-type="pmid">19397386</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Speer</surname><given-names>NK</given-names></name><name><surname>Swallow</surname><given-names>KM</given-names></name><name><surname>Maley</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The brain ’ S cutting-room floor: segmentation of narrative cinema</article-title><source>Frontiers in Human Neuroscience</source><volume>4</volume><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.3389/fnhum.2010.00168</pub-id><pub-id pub-id-type="pmid">20953234</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Supplementary methods</title><sec sec-type="appendix" id="s8-1"><title>Detecting states</title><p>Since the publication of our article describing the GSBS algorithm, we discovered some issues that have resulted in several improvements to the algorithm. First, we discovered that for specific brain regions the original GSBS algorithm performed suboptimally; the placement of one new boundary at a late stage in the fitting process resulted in a large increase in the t-distances (our measure of fit; see <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1A</xref>). This suggests that a strong neural state boundary (i.e., demarcating a large change in neural activity patterns) was detected only in a late iteration of the algorithm, which led to an overestimation of the number of neural states. To deal with this problem, we adapted the algorithm, such that it can place two boundaries at the same time, essentially demarcating the location of a new ‘substate’ within a previously defined state (as described in ‘Materials and methods’). In the following, we refer to this adapted version as states-GSBS. This change in the fitting procedure remedied the issues we experienced before (see <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1B</xref>) and resulted in more robust fitting behavior, which we observed across many brain regions. It also resulted in a change in the approach we used to fine-tune boundary locations; while we previously fine-tuned boundary locations based on their order of detection, the order is now determined by the strength of the boundaries (weakest – strongest).</p><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>T-distance curves and the optimal number of states for the different versions of the greedy state boundary search (GSBS) algorithm.</title><p>(<bold>A</bold>) The t-distance curve for the original GSBS implementation for an example brain region. (<bold>B</bold>) The t-distance curve for the same brain region with the new option to place two boundaries in one iteration of the algorithm. The dotted lines indicated the optimal number of states for the original GSBS algorithm (blue line) and the states-GSBS algorithm (red line).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77430-app1-fig1-v2.tif"/></fig><p>To investigate how these changes to GSBS impacted reliability, we split the data in two independent groups of participants and looked at the percentage of overlapping boundaries between the groups for each searchlight. To make sure differences in number of states between methods did not impact our results, we fixed the number of state boundaries to 18 or 19. Because the states-GSBS algorithm can place one or two boundaries at a time, we cannot fix the number of state boundaries exactly, which is why it can be either 18 or 19. We found that the number of overlapping boundaries between groups was substantially higher for states-GSBS compared to the original GSBS implementation and also compared to the GSBS implementation with altered fine-tuning (see <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2A</xref>). This was also the case when we used the optimal number of states as determined by the t-distance, instead of fixing the number of states (see <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2B</xref>). We also investigated the reliability of regional differences in states duration by computing the correlations in median state duration across all searchlights between the two independent groups. Again we observed that reliability increased substantially for states-GSBS compared to the original GSBS implementation and also compared to the GSBS implementation with altered fine-tuning (see <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2C</xref>).</p><fig id="app1fig2" position="float"><label>Appendix 1—figure 2.</label><caption><title>Comparing different implementations of the greedy state boundary search (GSBS) algorithm and different data preprocessing steps.</title><p>(<bold>A</bold>) The percentage of overlapping boundaries between two independent groups for each searchlight. The bar shows the mean across 5029 searchlights, while the error bar shows the standard error. The number of states was fixed to k = 18/19. (<bold>B</bold>) Same as (<bold>A</bold>) but now the number of states was determined by the optimal t-distance. (<bold>C</bold>) The correlation between the estimated median state lengths over all searchlights between two independent groups (correlation computed across 5029 searchlights). Bounds FTo = the original GSBS implementation; bounds FTs = the GSBS implementation with strength-ordered fine-tuning; states = the states-GSBS implementation that can place two boundaries at a time; states DC = states GSBS applied to data deconvolved with a canonical hemodynamic response function (HRF); states DE = states GSBS applied to data deconvolved with an estimated HRF.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77430-app1-fig2-v2.tif"/></fig></sec><sec sec-type="appendix" id="s8-2"><title>Deconvolution</title><p>Another issue we discovered with GSBS is that it was unable to detect short states (of one or two TRs) in some cases. Specifically, we noticed that this happens when consecutive neural states are strongly anticorrelated. We observed such anticorrelated states in many of our searchlights. To investigate this issue, we simulated data with 15, 30, or 50 neural states within 200 TRs using the same setup as our previous work (<xref ref-type="bibr" rid="bib28">Geerligs et al., 2021</xref>). However, instead of randomly generating an activity pattern per state, we used one activity pattern that we inverted when there was a state boundary. This resulted in strongly anticorrelated states (see <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3A</xref>). In this simulated setup, we found that as the number of states increased and there were more states with very short durations, the number of states was underestimated by states-GSBS. We hypothesized that this was due to the slow hemodynamic response, which obscures transitions between short states. Indeed, when we deconvolved the simulated data, the number of states was estimated correctly, even when there were 50 states (see <xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4B</xref>).</p><fig id="app1fig3" position="float"><label>Appendix 1—figure 3.</label><caption><title>Performance of states-GSBS on simulated data with anticorrelated states and (from left to right) 15, 30, or 50 states.</title><p>(<bold>A</bold>) The correlation matrices with the detected neural state boundaries in white. (<bold>B</bold>) The t-distance curves, where the black line indicates the simulated number of states. For k = 30 and k = 50, the t-distance peaks at a number of states that is below the simulated number of states, suggesting that some of the boundaries of short-lasting neural states are not detected. GSBS, greedy state boundary search.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77430-app1-fig3-v2.tif"/></fig><fig id="app1fig4" position="float"><label>Appendix 1—figure 4.</label><caption><title>Estimated hemodynamic response function (HRF) peak delays and the impact of HRF peak delay on the estimated number of states in simulated data.</title><p>(<bold>A</bold>) The estimates of the HRF peak delays for all searchlights are shown in a histogram<italic>.</italic> The values are averaged across all participants within each of the independent groups. The distribution is highly similar for both groups. (<bold>B</bold>) t-distance curves are shown for simulated data with different HRF delays that are deconvolved with a canonical HRF. There is no systematic under- or overestimation of the number of states when the HRF peak delays are in the range of the empirical data.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77430-app1-fig4-v2.tif"/></fig><p>Because we wanted to be able to identify states with both short and long durations, we chose to apply HRF deconvolution to our data before running states-GSBS using a canonical HRF. We found that deconvolution resulted in a very large improvement in the reliability of regional differences in states duration and also substantially increased the boundary overlap between independent samples (see <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>). However, it should also be noted that deconvolution may not be optimal for every study interested in neural states. It is particularly important for studies that are interested in accurately identifying the number of neural states in particular brain regions and for studies that are interested in short-lasting states. For studies that are more interested in transitions between longer-lasting states, the deconvolution may actually result in lower signal-to-noise. In particular, because we also observed that deconvolution results in reduced similarity of timepoints within the same state as well as increased similarity of timepoints between states.</p></sec><sec sec-type="appendix" id="s8-3"><title>Regional differences in HRF</title><p>One concern with deconvolution is that there are known differences between regions in the timing of the HRF (<xref ref-type="bibr" rid="bib72">Taylor et al., 2018</xref>). To investigate whether such differences might impact our results, we estimated the HRF for each participant and each searchlight using the rsHRF toolbox that is designed to estimate HRFs in resting state data (<xref ref-type="bibr" rid="bib79">Wu et al., 2021</xref>). In this case, we applied the algorithm to our fMRI data recorded during movie watching. Because HRF estimation is applied to single-subject data that contains many sources of noise, we performed some extra data denoising steps (as in <xref ref-type="bibr" rid="bib27">Geerligs and Campbell, 2018</xref>), which included regressing out signals from the CSF and white matter as well as head motion signals. This denoised data was used to run the HRF estimation for each participant and for each voxel within a searchlight. Subsequently, the HRF shape was averaged across all voxels in a searchlight and the data were deconvolved for each participant. Importantly, we used the same data as before (without the extra denoising steps) as the input for the deconvolution to make sure results were comparable. Also, we observed that data cleaning removed some of the signal of interest, resulting in slightly decreased reliability of boundaries. After deconvolution, the data were again averaged within the two independent groups of participants and then we applied the states-GSBS algorithm.</p><p><xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4A</xref> shows the estimated HRF peak delays for each brain region after averaging the estimated peaks across all participants within each of the two independent groups. The differences between searchlights in their estimated HRF delay (averaged across participants) were highly reliable across the two independent groups (<italic>r</italic> = 0.87). The peak delays varied between 4.6 and 5.4 s, which is very similar to the delay of the canonical HRF (5 s). When we deconvolved the data with the estimated HRF instead of the canonical HRF, we found that this resulted in a slight decrease in the boundary overlap between independent samples and also slightly reduced the reliability of regional differences in states duration (see <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>). Regional differences in state duration were highly similar when we compared the deconvolution with the canonical HRF and the deconvolution with the estimated HRF (<italic>r</italic> = 0.92 and <italic>r</italic> = 0.93 for the two groups at the voxel level and <italic>r</italic> = 0.73 and <italic>r</italic> = 0.76 at the level of searchlights). These results suggest that regional differences in the HRF shape did not bias the estimated regional timescales.</p><p>To investigate this in more detail, we ran additional simulations to investigate the consequences of slight deviation in the HRF shape on the recovery of the state boundaries (see <xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4B</xref>). Simulated data with HRF delays between 4.6 and 5.4 s, which were deconvolved with a canonical HRF, did not show an under- or overestimation in the number of states. Together, these results show that the regional differences we observe in the duration of neural states when we use data that is deconvolved with a canonical HRF cannot be explained by regional differences in the HRF shape. Furthermore, it is not clear that the extra step of estimating the HRF shape results in more accurate or reliable results. That is why we opted for the simpler approach of canonical HRF estimation throughout the article.</p></sec><sec sec-type="appendix" id="s8-4"><title>Sample size effects</title><p>To look at how replicable results are across samples and how this depends on the sample size, we computed the proportion of boundaries that was shared between each unique pair of participant groups. In line with our previous work, we observed that the boundary time courses were a lot more consistent between different pairs of participant groups when the data were split into two independent groups of 127/128 participants per group (63% of boundaries shared on average) than when the data were split into 15 groups of around 17/18 participants per group (49% of boundaries shared on average). That is why, throughout the article, we report the results with the largest possible sample size. To make sure there were enough unique data points to perform tests for statistical significance to show the consistency of effects across samples, all statistical analyses are performed on the data split into 15 independent groups.</p></sec></sec><sec sec-type="appendix" id="s9"><title>Supplementary results</title><sec sec-type="appendix" id="s9-1"><title>Reliability</title><p>As a first step, we determined in which searchlights neural state boundaries were sufficiently reliable for follow-up analyses when we looked at the smallest and therefore least reliable sample size (15 groups with 17/18 participants per group). Specifically, we investigated which searchlights showed a significantly positive Pearson correlation between state boundary time courses in each participant group and the average state boundary time courses across all other participant groups (similar to <xref ref-type="bibr" rid="bib28">Geerligs et al., 2021</xref>). Reliable boundary time courses were observed in 5029 out of 5061 searchlights. The 32 regions without reliable boundary time courses were not included in any of the analyses reported in the article or Appendix 1 (‘Supplementary methods’ or ‘Supplementary results’; see <xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5A</xref> for a map of these regions). In these 5029 regions, the reliability was highest for searchlights around the visual and auditory cortex and lowest around the paracentral lobule and the posterior parts of the orbitofrontal cortex (see <xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5B</xref>).</p><fig id="app1fig5" position="float"><label>Appendix 1—figure 5.</label><caption><title>Reliability of neural states boundaries across the brain and an overview of searchlights that were excluded due to poor reliability.</title><p>(<bold>A</bold>) Searchlights that were excluded due to poor reliability. (<bold>B</bold>) A map of the reliability of neural state boundaries across the cortex.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77430-app1-fig5-v2.tif"/></fig></sec><sec sec-type="appendix" id="s9-2"><title>Overlap between searchlights</title><p>To investigate whether the strong relative boundary overlap between brain regions could be caused by shared sources of noise across brain regions, we recomputed this overlap based on the data from two independent groups of participants. To make sure the resulting matrix remained symmetric, we averaged the results across the two possible orders of participant groups (i.e., comparing searchlight 1 in subgroup 1 to searchlight 2 in subgroup 2, as well as comparing searchlight 1 in subgroup 2 to searchlight 2 in subgroup 1). The results show that the relative boundary overlap computed in this way across independent datasets is highly similar to the boundary overlap within one subgroup (<italic>r</italic> = 0.69, see <xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6A and B</xref>), showing that shared noise cannot be the cause of the strong overlap we observed.</p><fig id="app1fig6" position="float"><label>Appendix 1—figure 6.</label><caption><title>Investigating the role of shared noise, ‘ regular’ functional connectivity and regional differences in state length in shaping the boundary overlap between pairs of searchlights.</title><p>(<bold>A</bold>) The relative neural state boundary overlap between each pair of searchlights. (<bold>B</bold>) Same as (<bold>A</bold>), but computed between two independent groups of participants. This ensures that the overlap cannot be caused by noise shared across brain regions. (<bold>C</bold>) The correlation matrix based on the averaged brain activity time course in each searchlight (i.e., standard measure of functional connectivity). (<bold>D</bold>) The difference between each pair of searchlights in median state length was markedly different from the relative boundary overlap (shown in <bold>A</bold>), showing that the boundary overlap between different regions was not just due to regional differences in the optimal number of states.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77430-app1-fig6-v2.tif"/></fig><p>To examine whether the relative boundary overlap is simply a proxy for ‘regular’ functional connectivity, we compared it to the correlation between mean activity time courses in each searchlight (see <xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6A and C</xref>). We found that these correlation patterns could only explain a small part of the regional differences in boundary overlap. To investigate whether the boundary overlap is simply a result of regional similarities in state length, we compared the boundary overlap to regional differences in state duration (see <xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6A and D</xref>). We found that differences in state duration cannot explain the overlap patterns we observed.</p></sec><sec sec-type="appendix" id="s9-3"><title>Effects of noise on overlap between neural states and events for shared boundaries</title><p>One concern is that identifying boundaries shared by two regions has a similar effect to averaging, which provides a better estimation of boundaries within each searchlight because it reduces noise. This noise reduction could be the cause of the increased overlap between events and neural states for shared boundaries vs. non-shared boundaries. To investigate this possibility, we examined the increase in overlap for shared vs. non-shared values in the data averaged across 265 participants as well as for each independent subgroup of 17/18 participants. If noise reduction is the cause of the increase in overlap with event boundaries, we should expect the difference between shared and non-shared boundaries to be largest in the smaller independent subgroups where there is the most to be gained from noise reduction. In contrast, if the increase in overlap with event boundaries is a real effect, not due to noise, its effect size should be larger in the data averaged across all participants, where estimates of boundary locations are more accurate. The results in <xref ref-type="fig" rid="app1fig7">Appendix 1—figure 7</xref> show that the latter interpretation is correct, making it unlikely that the observed increase in overlap between neural state and event boundaries is related to noise.</p><fig id="app1fig7" position="float"><label>Appendix 1—figure 7.</label><caption><title>Mean increase in absolute overlap for shared vs. non-shared boundaries for large and small groups of participants.</title><p>(<bold>A</bold>) Mean increase in absolute overlap for shared vs. non-shared boundaries across all pairs of searchlights and (<bold>B</bold>) for the pairs of searchlights that showed a significant increase in overlap.The effect size for the full sample of 265 participants is shown by the red line, and the effect sizes for the independent subgroups of 17/18 participants are shown in blue. The effect size is larger in the data averaged across all 265 participants, suggesting that the increase in overlap is not due to noise reduction.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77430-app1-fig7-v2.tif"/></fig></sec><sec sec-type="appendix" id="s9-4"><title>Head motion</title><p>Another quality check we performed was to investigate the association between neural state boundaries and head motion. First, we computed the average amount of head motion for each TR across all the participants in each of the 15 independent groups. Second, we computed Pearson correlations between the neural state boundary time courses and the average head motion time courses. We investigated whether there was a consistently positive or negative association between state boundaries and head motion across the 15 samples after FDR correlation for multiple comparisons. This was not the case for any of the searchlights.</p></sec><sec sec-type="appendix" id="s9-5"><title>Stability of communities of timepoints</title><p>In the main text, we identified different communities of timepoints that varied in the degree to which neural state boundaries were shared across the cortical hierarchy. To make sure that these findings are replicable, here we repeated the same analysis across two independent samples of participants (see <xref ref-type="fig" rid="app1fig8">Appendix 1—figure 8</xref>). We found that even though the two subgroups did not have the same number of communities (four in group 1, five in group 2), the pattern of results was highly similar across the two. Both groups showed communities that differed in the degree to which boundaries propagated across the cortical hierarchy and in both cases this was also associated with the occurrence of event boundaries, such that timepoints in communities with more widespread boundaries also were more likely to coincide with event boundaries.</p><fig id="app1fig8" position="float"><label>Appendix 1—figure 8.</label><caption><title>Stability of communities of timepoints across two independent groups of participants.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-77430-app1-fig8-v2.tif"/></fig><table-wrap id="app1table1" position="float"><label>Appendix 1—table 1.</label><caption><title>For each network, the table lists the network defined by <xref ref-type="bibr" rid="bib57">Power et al., 2011</xref> that showed the highest overlap and the percentage of searchlights in the network that overlapped with that particular <xref ref-type="bibr" rid="bib57">Power et al., 2011</xref> network.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Network name</th><th align="left" valign="top">Power network</th><th align="left" valign="top">Percentage of searchlights</th></tr></thead><tbody><tr><td align="left" valign="top">Motor</td><td align="left" valign="top">Sensorimotor</td><td align="char" char="." valign="top">49</td></tr><tr><td align="left" valign="top">Sensorimotor-medial</td><td align="left" valign="top">Sensorimotor</td><td align="char" char="." valign="top">45</td></tr><tr><td align="left" valign="top">Sensorimotor-lateral</td><td align="left" valign="top">Sensorimotor</td><td align="char" char="." valign="top">37</td></tr><tr><td align="left" valign="top">Auditory</td><td align="left" valign="top">Auditory</td><td align="char" char="." valign="top">24</td></tr><tr><td align="left" valign="top">Visual early</td><td align="left" valign="top">Visual</td><td align="char" char="." valign="top">58</td></tr><tr><td align="left" valign="top">Visual late</td><td align="left" valign="top">Visual</td><td align="char" char="." valign="top">20</td></tr><tr><td align="left" valign="top">Dorsal attention network</td><td align="left" valign="top">Dorsal attention network</td><td align="char" char="." valign="top">27</td></tr><tr><td align="left" valign="top">Cinglulo-opercular network</td><td align="left" valign="top">Cinglulo-opercular network</td><td align="char" char="." valign="top">23</td></tr><tr><td align="left" valign="top">Fronto-parietal control network</td><td align="left" valign="top">Fronto-parietal task control</td><td align="char" char="." valign="top">24</td></tr><tr><td align="left" valign="top">Posterior default mode network</td><td align="left" valign="top">Default mode network</td><td align="char" char="." valign="top">57</td></tr><tr><td align="left" valign="top">Superior default mode network</td><td align="left" valign="top">Default mode network</td><td align="char" char="." valign="top">24</td></tr><tr><td align="left" valign="top">Anterior default mode network</td><td align="left" valign="top">Default mode network</td><td align="char" char="." valign="top">68</td></tr></tbody></table></table-wrap><table-wrap id="app1table2" position="float"><label>Appendix 1—table 2.</label><caption><title>For the three separate default mode networks (DMNs) we identified, the table lists the overlap with the posterior and anterior DMN defined in <xref ref-type="bibr" rid="bib14">Campbell et al., 2013</xref>.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="top">Network name</th><th align="left" valign="top">Percentage of searchlights that overlap with anterior DMN</th><th align="left" valign="top">Percentage of searchlights that overlap with posterior DMN</th></tr></thead><tbody><tr><td align="left" valign="top">Posterior DMN</td><td align="char" char="." valign="top">39</td><td align="char" char="." valign="top">70</td></tr><tr><td align="left" valign="top">Superior DMN</td><td align="char" char="." valign="top">52</td><td align="char" char="." valign="top">31</td></tr><tr><td align="left" valign="top">Anterior DMN</td><td align="char" char="." valign="top">77</td><td align="char" char="." valign="top">65</td></tr></tbody></table></table-wrap></sec></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.77430.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Badre</surname><given-names>David</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>This article addresses the question of how the brain segments naturalistic events and the relationship between perceived event boundaries and neural pattern shifts. By applying an innovative analysis to a large, publicly available dataset, they observe evidence of different timescales of neural state shifts that correspond with perceived event bounds. These results will be of interest to cognitive neuroscientists investigating the relationship between neural states and event segmentation.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.77430.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Badre</surname><given-names>David</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Ranganath</surname><given-names>Charan</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05rrcem69</institution-id><institution>University of California at Davis</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>[Editors’ note: the authors submitted for reconsideration following the decision after peer review. What follows is the decision letter after the first round of review.]</p><p>Thank you for submitting your work entitled &quot;Timescales and functional organization of event segmentation in the human brain&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and a Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Charan Ranganath (Reviewer #2).</p><p>Our decision has been reached after consultation between the reviewers. Based on these discussions and the individual reviews below, we regret to inform you that this submission will not be considered further for publication in <italic>eLife</italic>.</p><p>The reviewers were in agreement that this is an important topic and that this research is both interesting and promising. However, the reviewers raised a number of significant concerns that centered around two themes. First, there were a number of points raised about the methodology itself and its validity. After some discussion, it was decided that these methodological points could be addressable through additional analysis and/or simulation, but likely require considerably more work than would be usual for an <italic>eLife</italic> revision. The second set of concerns were with regard to the clear scientific advance over prior work; there was not consensus that these findings move the field forward in a clear way. Reviewer 1 suggested that the generalizability and impact might be improved by drawing direct links to the existing literature, including analysis of a secondary dataset as in the Baldasano et al. (2017) paper. Though, there might be other ways to clarify the impact, as well. Regardless, this is a challenging concern to address in a straightforward way through revision.</p><p>As addressing these concerns would likely require more than is typically expected for an <italic>eLife</italic> revision, it was decided to reject this submission. This being said, if you were to undertake the work required to conclusively address these issues, there was sufficient enthusiasm among reviewers that they would be willing to consider this paper again, as a new submission.</p><p>I have appended the detailed reviews to this decision letter. I hope you find them constructive with this work.</p><p><italic>Reviewer #1:</italic></p><p>In this paper, Geerligs et al. focus on the alignment of event boundaries across brain regions. They examine the transitions between brain states using the method introduced by Baldassano et al. (2017), and how these state transitions are shared across nodes of large-scale brain networks. They introduce a method that enables them to map event-timescales in a broader set of regions than previously possible, and they use this method to reveal how functional networks of regions share time-aligned &quot;event transitions&quot;.</p><p>This is a well-written manuscript on a timely and important question.</p><p>My main concerns relate to the validity (and potential sources of bias) in the methodology for identifying the event-rate of each region, and I also outline a number of other areas where the conceptual and methodological framing could be improved.</p><p>p.3 &quot;This dataset, in combination with the application of hyperalignment to optimize functional alignment (Guntupalli et al., 2016), allowed us to study event segmentation across the entire cortex for the first time, because this dataset shows reliable stimulus-driven activity (i.e., significant inter-subject correlations) over nearly all cortical brain regions (Geerligs et al., 2018). &quot;</p><p>A central methodological question, which affects almost every claim in this manuscript, is whether the inference of event boundaries from the HMM model (the methods in Figure 1) is valid, and in what ways it might be biased. The validity question is simple: does it measure what it is supposed to measure? In particular, I would like the authors to justify the final step, in which they compute the difference between the correlation for real boundaries and the correlation for random boundaries. Surely, this difference computation will be affected by the noise ceiling of the individual ROI being examined? I understand why using the random condition as a &quot;reference&quot; makes some sense, but I do not understand why the final decision is made based on the simple arithmetic difference of the mean value for the random boundaries and real boundaries? I suggest that the authors justify this procedure using a simulation procedure where the ground truth about event transitions is known, and the procedure should be compared against the method applied in the original Baldassano et al. (2017) paper.</p><p>The bias question is also fairly simple: which factors influence the &quot;k&quot; that is inferred? In particular, if a region has high reliability or low reliability of its response across subjects, does this affect the number of events that will be inferred for that region using the HMM procedure? As noted above, this simulation could additionally investigate how the &quot;k&quot; value varies as function of the noise level (i.e. response reliability) of the ROI.</p><p>Additionally, although hyperalignment render a larger swathe of cortex available to analysis, but there will still be variability in the reliability of the signal across regions, and this might interact with the hyperalignment performance. In particular, the accuracy of the hyper alignment procedure (for each subject) will presumably also increase for regions whose reliability of response is higher; it is therefore very to consider whether noise (in &quot;space&quot;) introduced by the hyperalignment procedure (and varying across regions as a function of their reliability) could further bias the measurement of the event-timescale via the HMM procedure.</p><p>Finally, to better understand this method, the authors could also apply their approach to the freely available data from the Baldassano et al. (2017) paper. Does this method produce results that are at least qualitatively similar? This could help to resolve the question of why the event timescales in this paper are shorter than those observed in the Baldassano et al. paper.</p><p>p.7: Event networks: &quot;We found that event boundaries are shared within long-range networks that resemble the functional networks that are typically identified based on (resting state) timeseries correlations (see figure 3A)&quot;.</p><p>This is one of the most intriguing aspects of this paper. However, it would be much more convincing if the authors would replace their qualitative language (e.g. &quot;resemble&quot;) with quantitative metrics of overlap. The overlap could be measure between (a) networks defined based on event-timing and (b) networks defined based on functional connectivity. All of the major functional networks should be available in atlases (e.g. the Yeo lab atlases) or via data sharing repositories. Thus, the authors should be able to substantiate their broad claims of &quot;resemblance&quot; with quantitative demonstrations of how well the event-networks match the functional-connectivity-networks. All of the visual networks as well as the FPN and DMN should be quantitatively compared against standard networks defined elsewhere in the literature.</p><p>On the same point: p.13 &quot;The fractionation of the DMN into a fast and slow subnetwork closely aligns with the previously observed posterior and anterior DMN subnetworks (Andrews-Hanna et al., 2010; Campbell et al., 2013; Lei et al., 2014).&quot;</p><p>Again, please quantify the alignment when claiming spatial alignment with prior findings.</p><p>p.13 &quot;Our results show for the first time that neural events are shared across brain regions in distinct functional networks. &quot;</p><p>The authors should consider re-wording this sentence to distinguish their findings from what was already shown in Figure 4B of Baldassano et al. (2017). In particular, note the commonality of event boundaries across early visual and late visual areas (part of the visual network), as well as the commonality of events across angular gyrus and posterior medial cortex (parts of the DMN).</p><p>On a related note, in the Abstract we read: &quot;This work extends the definition of functional networks to the temporal domain&quot; – I am unclear on how novel this extension is. To the best of my understanding, the concept of dynamic functional connectivity is not new (e.g. Hutchison et al., 2013), and even second-order pattern-transition methods have been employed to study functional networks (e.g. Anzellotti and Coutanche, 2018). I would like the authors to sharpen their argument for why this result is not entirely expected in light of prior work. Shouldn't members of the same functional networks be expected to exhibit state-transitions at rates higher than chance?</p><p>p.11. I struggled to follow the logic of the analysis employed in Figure 6. Why is event duration being predicted from individual frequency bands of the PSD? There is voluminous evidence for band-specific and region-specific artifact (e.g. Birn et al., 2013; Shmueli et al., 2007). Furthermore, distinct functional networks have distinct frequency profiles and coherence patterns (e.g. Salvador et al., 2008; Baria et al., 2011; Stephens et al., 2013). Finally, the frequency bands in the PSD are non-independent (because of the temporal smoothing in the BOLD signal). Therefore, the relationship between frequency band and event duration is confounded by (i) non-independence of frequencies and (ii) frequency covariation across brain regions which arises for a multitude of reasons. The results in Figure 6A seem rather noisy to me, and I imagine that this is because the regression procedure on the PSD is influenced by many interacting and confounding variables.</p><p>Another region why this analysis produces (in my opinion) curious results is that it spans distinct sensory modalities which are already known to have opposite PSD-event relationships: along the auditory pathway, PSDs get flatter as event time-scales get longer, while in the visual pathway, PSDs in V1 are already very steep, even while the event timescales are short. It is not clear what is gained by fitting a single model to regions with obviously different relationships of PSD and event structure.</p><p>p.12. &quot;These results suggest that visual and auditory stimulation are a prerequisite for observing the temporal hierarchy we describe in this paper and that this hierarchy only partly reflects an intrinsic property of brain function that is also present in the resting state.&quot;</p><p>I do not follow the logic supporting this claim. How can we know whether the (event-based) temporal hierarchy is preserved in the resting state unless we can measure the event transitions in the resting state data? Isn't this analysis just another way of saying that the PSDs have different shapes during rest and during movie viewing?</p><p>References</p><p>Anzellotti, S., and Coutanche, M. N. (2018). Beyond functional connectivity: investigating networks of multivariate representations. Trends in cognitive sciences, 22(3), 258-269.</p><p>Baria, A. T., Baliki, M. N., Parrish, T., and Apkarian, A. V. (2011). Anatomical and Functional Assemblies of Brain BOLD Oscillations. Journal of Neuroscience, 31(21), 7910-7919. https://doi.org/10.1523/JNEUROSCI.1296-11.2011</p><p>Birn, R. M., Diamond, J. B., Smith, M. A., and Bandettini, P. A. (2006). Separating respiratory-variation-related fluctuations from neuronal-activity-related fluctuations in fMRI. Neuroimage, 31, 1536-1548. https://doi.org/10.1016/j.neuroimage.2006.02.048</p><p>Coutanche, M. N., and Thompson-Schill, S. L. (2013). Informational connectivity: identifying synchronized discriminability of multi-voxel patterns across the brain. Frontiers in human neuroscience, 7, 15.</p><p>Hutchison, R. M., Womelsdorf, T., Allen, E. A., Bandettini, P. A., Calhoun, V. D., Corbetta, M.,.… Chang, C. (2013). Dynamic functional connectivity: Promise, issues, and interpretations. NeuroImage, 80, 360-378. https://doi.org/10.1016/j.neuroimage.2013.05.079</p><p>Salvador, R., Martínez, A., Pomarol-Clotet, E., Gomar, J., Vila, F., Sarró, S.,.… Bullmore, E. (2008). A simple view of the brain through a frequency-specific functional connectivity measure. NeuroImage, 39(1), 279-289. https://doi.org/10.1016/j.neuroimage.2007.08.018</p><p>Shmueli, K., van Gelderen, P., de Zwart, J. A., Horovitz, S. G., Fukunaga, M., Jansma, J. M., and Duyn, J. H. (2007). Low-frequency fluctuations in the cardiac rate as a source of variance in the resting-state fMRI BOLD signal. Neuroimage, 38(2), 306-320.</p><p>Stephens, G. J., Honey, C. J., and Hasson, U. (2013). A place for time: The spatiotemporal structure of neural dynamics during natural audition. Journal of Neurophysiology, 110(9), 2019-2026. https://doi.org/10.1152/jn.00268.2013</p><p><italic>Reviewer #2:</italic></p><p>In this paper, Geerlings and colleagues leverage a large, publicly-available dataset in order to assess shared and distinct timescales of neural pattern shifts at event boundaries across different areas of the brain. In line with prior work, the authors report a gradient of timescales in neural event segmentation, with sensory regions comprising the fastest-shifting areas and 'default mode' nodes such as precuneus and medial prefrontal cortex comprising the slowest-shifiting areas. Importantly, the authors build on this previous research and demonstrate that canonical functional networks – such as the frontoparietal network, and the 'default mode' network – feature distinct subnetworks with corresponding faster and slower timescales of pattern shifts. Finally, a fairly novel analysis applied to these types of data examined power spectral density across regions, which could be used to predict event duration across regions (consistent with observed pattern shifts), and could partly, but not entirely, characterize resting-state fMRI data (suggesting that the audiovisual stimulus drove additional functional properties in brain networks not observed during rest).</p><p>Overall, this is an interesting and timely study. The question of how the brain segments naturalistic events is one of increasing popularity, and this manuscript approaches the question with a large sample size and fairly thorough analyses. That said, there are a number of questions and concerns, primarily regarding the analyses.</p><p>• Procedures such as hyperalignment, or the related shared response model used by Baldassano and colleagues, are typically implemented by training on one set of the data, and applying the alignment procedure to a separate, held-out dataset (i.e., training and testing sets). It is unclear whether this approach was taken in the current study, or whether the hyperalignment algorithm was trained and tested on same dataset. In the latter case, there is a degree of circularity in the way across-participant alignment was conducted, potentially leading to biased correlation measures. The movie used in the CamCAN dataset is only 8 minutes long, which is probably not enough data for obtaining separate training and test datasets. However, this is still potentially a serious issue for this manuscript, and I am not sure if the use of hyperalignment is appropriate. If I have misunderstood the methodology, it perhaps warrants some clarification in how the training and application of the hyperalignment algorithm proceeded. (I will note that I am aware you used cross-validation for deriving the number of events, but that is unfortunately a separate issue from a train-test split in the hyperalignment routine itself.)</p><p>• A key finding from the study is that the FPN and DMN fractionate into different subnetworks that have fast and slow timescales. As noted above, the present results are based on an analysis of data from a relatively short period of time. Although the sample size is very large, one wonders whether this distinction would remain solid with a longer movie. With a very short movie, one can only sample a small number of real events, and this could lead to some instability in estimates of the timescale of representations in relation to the events. This might be an issue in relation to the differentiation of fast and slow subnetworks within the FPN and DMN. For instance, Figure 3B, suggests that the fit values for the slow FPN remain more or less stable across a range of event durations (which presumably reflect k values?). The slow FPN shows an interesting bimodal distribution (as do many of the networks) with the second peak coinciding with the peak for the fast FPN. The differentiation is a bit more convincing for the fast and slow DMN, but it is still not clear whether there are enough events and enough fMRI data from each subject to ensure reliable estimates of the timescales. Just to provide some context for this point, some estimates suggest that reliable identification of resting state networks requires at least 20 minutes of fMRI data.</p><p>• Throughout the paper, fMRI results are described in reference to event processing, but the relationship is underdeveloped. Much of the paper relies on the Hidden Markov Model, which assumes that there is a pattern that remains stationary throughout an event. Baldassano's data shows a surprisingly strong correspondence in posterior medial cortex, but it is less clear whether this assumption is valid for other areas. In relation to this point, one can think of event processing as an accumulation of evidence. At the onset of an event, one might have a decent idea of what is about to happen, but as information comes in, the event model can be refined to make stronger predictions. These kinds of within-event dynamics would be lost in the Hidden Markov model. A related point is that the paper conflates timescales of neural states with psychologically meaningful conceptions of events. EST suggests that event segmentation is driven by prediction error-by one interpretation of the model, sensory information can change considerably without leading one to infer an event boundary. However, change in incoming sensory information would almost certainly lead to the detection of &quot;event boundaries&quot; across short timescales in sensory cortical areas. Figure 5 makes it fairly clear that there is a pretty strong distinction to be made between data-driven event identification based on the fMRI data and psychologically meaningful events inferred by the subjects. It would be helpful for the authors to be more clear about what the data do and do not show in relation to putative event cognition processes.</p><p>• Why were voxels with an intersubject correlation of less than r=0.35 excluded from analyses? Is this based on prior studies or preliminary analyses? It is not necessarily a bad thing if this choice was made arbitrarily, but I imagine this threshold could have important impacts on the data as presented, so it is worth clarifying.</p><p>• Was ME-ICA the only step taken to account for head motion artifacts? If so, there is some concern about whether this step was sufficient to deal with the potential confound. This is especially critical given the fairly brief time series being analyzed here. It would be more compelling to see a quantitative demonstration that head motion is not correlated with the measures of interest.</p><p>• A related issue is that of eye movements. Eye movements are related to event processing (e.g., Eisenberg et a., 2018), so one can expect neural activity related to event prediction/prediction error to be confounded with lower-level effects related to eye movements. For instance, we might expect signal artifacts in the EPI data, as well as neural activity related to the generation of eye movements, and changes in visual cortex activity resulting from eye movements. It is unlikely that this issue can be conclusively addressed with the current dataset, and it's not a deal-breaker in the sense that eye movements are intrinsically related to naturalistic event processing. However, it would be useful for the authors to discuss whether this issue is a potential limitation.</p><p>• The power spectral analyses were a bit difficult to follow, but more importantly, the motivation for the analysis was not clearly described. The main take home points from this analyses are nicely summarized at the end of p. 14, but it would be helpful to clarify the motivation for this analysis (and the need for doing it) on p.11 in the Results section. Relatedly, is Figure 6A an example spectrum from a particular voxel or region, or an average across regions?</p><p>• The take-home message appears to be that different brain networks have different timescales at which they seem to maintain event representations. Moreover, certain networks (e.g., the posterior medial/'default mode' network) do not have uniformly fast or slow timescales. The network-based analysis used here is indeed novel, but the impact of the work could be enhanced by clarifying the significance of the results in relation to what we know about event processing. The explicit demarcation of 'fast' and 'slow' subnetworks may be the key conceptual advance, as was the power spectral analysis, but it isn't clear whether these conclusions could also be ascertained from the maps shown in Baldassano et al., 2017 or other papers from the Hasson group.</p><p>This review was completed by Zach Reagh, Ph.D. in collaboration with Charan Ranganath, Ph.D. (I sign all reviews)</p><p><italic>Reviewer #3:</italic></p><p>Geerligs and colleagues conduct a thorough set of analyses aimed at identifying event segmentation timescales across the cortex in a large cohort of participants. They extend previous work by Baldassano et al. by covering the entire cortex, and nicely control for the power spectrum of different regions. In addition, they examine which regions share the same event boundaries, not just the same timescale, and relate these to functional connectivity networks. Overall, their work is impressive and rigorous, but there are a few points that make it somewhat difficult to assess the how strong the contribution is to our understanding of processing timescales:</p><p>1. The authors divide the brain into functional networks based on boundary similarity and find that this division is very similar to functional networks defined using resting-state timeseries correlations. They further find increased similarity between regions of different networks that are that are interconnected. Wouldn't the similarity between boundary vectors be strongly linked to the timeseries correlations (both between regions in the same network and across networks)? While the similarity-based functional networks aren't completely identical to those identified in rest, perhaps the same results would be obtained by correlating timeseries in this specific dataset, using the movie data (altering the interpretation of the results).</p><p>2. It seems that the power spectrum analysis is run both on the resting-state data and on the movie data, whereas the timescale segmentation is run only on the movie data. I expect this is because hyperalignment is possible only when using a shared stimulus, and the HMM is run only on the hyperaligned data. However, this may bias the correlations presented in figure 6 – the movie PSD-based timescale estimation would be expected to be more similar to the HMM timescales than the rest, simply because the same data is used. A more convincing analysis would be to run the HMM on the rest data as well, and test for correlations between the two estimations of event timescales in the rest data, although this would entail substantial additional analyses (as HMM would also have to be run on non-hyperaligned movie data for comparability). It would also help with point 1, testing whether similarity in boundary vectors arises directly from timeseries correlations. I realize this adds quite a bit of analysis, and the authors may prefer to avoid doing so, but the conclusions arising from the power spectrum analysis should be softened in the Results and Discussion, clearly mentioning this caveat.</p><p>3. It would aid clarity to better separate the current contributions from previous findings, in the Results, and mainly in the Discussion. The authors do describe what has previously been found, citing all relevant literature, but it would be helpful to have a clear division of previous findings and novel ones. For example in the first paragraph of the Discussion, and in general when discussing the interpretation of activity the different regions (currently regions that have already been found are somewhat intermixed with the new regions found).</p><p>[Editors’ note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;A partially nested cortical hierarchy of neural states underlies event segmentation in the human brain&quot; for further consideration by <italic>eLife</italic>. Your revised article has been evaluated by Michael Frank (Senior Editor) and a Reviewing Editor.</p><p>The manuscript has been improved but there are some remaining issues that need to be addressed, as outlined below:</p><p>The reviewers were positive about the revisions you made to this submission and felt that extensive work had been done to improve the paper. There were a few remaining points raised by this review that could be addressed the further strengthen the paper. The Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1. Reviewer 1 has raised some additional points for clarification in their review, as noted below. These should be clarified in a revision. Please refer to the comments below for these notes.</p><p>2. Some of the conclusions do not completely reflect the results. If additional analyses are not added, perhaps these conclusions could be rephrased, such as &quot;some of the neural boundaries are represented throughout the hierarchy.… until eventually reflected in conscious experience&quot; (p. 14) and &quot;boundaries that were represented in more brain regions at the same time were also more likely to be associated with the experience of an event boundary&quot; (p. 15).</p><p>3. Since the GSBS algorithm was fine-tuned based on the data that was later used for analysis, it would be helpful to include additional information demonstrating the choices in the optimization procedure are independent of the eventual results. For example, it isn't clear what 'important boundaries being detected late' means, whether that indicates event boundaries were being missed by the original algorithm. Combined with the fact part of the optimization was based on fixing the number of state boundaries to the number of event boundaries – could these choices have increased the chance of finding overlap between state boundaries and event boundaries?</p><p>4. Two small notes: the network defined as posterior DMN includes anterior regions, which is slightly confusing; were the regional differences in HRF assessed on the resting state data or the movie watching data?</p><p>Additional Suggestions for Revision (for the authors):</p><p>One of the reviewers had some suggestions for additional analyses that might strengthen the results. We pass them along to you here, but you should view these as optional. Only include them if you agree that they will strengthen the conclusions.</p><p>there are a few analyses that may help strengthen the conclusions - these are suggested as optional additional analyses, but the authors should feel free not to include them:</p><p>• To verify the overlap between searchlights is not due to various artifacts, it may be preferable to compare the searchlight in one region with the searchlights of other groups in the second region (following the rationale of intersubject functional connectivity vs. functional connectivity). It would also be interesting to further explore the nature of the overlap - to see whether there are specific state boundaries that drive most of the overlap or whether different pairs of regions have different overlapping boundaries. This could be used to explore the nature of the hierarchy between regions, beyond just finding that higher regions share boundaries with lower regions. For example, it could enable testing whether state shifts shared by multiple lower level regions are the ones that traverse the hierarchy.</p><p>• Further to this, it would be interesting to test whether event boundaries and non-event neural state boundaries form a similar hierarchy (though this may not be feasible with such a low number of event boundaries).</p><p>• To assess the effects of noise reduction on the overlap between neural state boundaries and event boundaries, it may be worth testing whether neural state boundaries shared across groups of participants are also more likely to be event boundaries (and specifically whether this effect is stronger in the same regions arising from the co-occurrence analysis). This analysis wouldn't provide an answer, but could help shed some light on the role of noise reduction.</p><p><italic>Reviewer #1:</italic></p><p>This work investigates timescales of neural pattern states (periods of time with a relatively stable activity pattern in a region) across the brain and identify links between state shifts and perceived boundaries events. In multiple regions, they find significant overlap between state shifts and event boundaries, and an even stronger overlap for state shifts that occur simultaneously in more than one region. The results are interesting and timely and extend previous work by Baldassano et al. that found a similar hierarchy in a specific set of brain regions (here extended to the entire cortex).</p><p>Strengths</p><p>The question of whether neural state shifts form a hierarchy such that state shifts in higher regions coincide with state shifts in sensory regions, and the question of whether event boundaries occur at conjunctions of shifts in different regions are both very interesting.</p><p>The optimized GSBS method nicely overcomes limitations of previous methods, as well as a previous version of GSBS. In general, justification is provided for the different analysis choices in the manuscript.</p><p>The current work goes beyond previous work by extending the analysis to the entire cortex, revealing that state shifts in higher regions of the cortex overlap with state shifts in lower regions of the hierarchy.</p><p>Weaknesses</p><p>One of the important conclusions of the paper is that simultaneous neural state shifts in multiple brain regions are more likely to be experienced as boundaries. This finding fits in nicely with existing literature, but the analysis supporting it is not as compelling as the rest of the analyses in the paper:</p><p>1. The methods section describing the analysis is not entirely clear. Do Oi, Oj refer to the number of neural state boundaries in searchlights I,j? Or the number of neural state boundaries in each that overlap with an event boundary? If the former (which was my initial interpretation), then how is the reference searchlight chosen – max {Oi,Oj}, as indicated by the formula, or the searchlight with the larger overlap of its unique boundaries (and is the overlap calculated in numerical value or the proportion of overlap)? Given the unclarity, it is difficult to assess whether the degree of overlap between neural state boundaries and event boundaries in each of the searchlights (and/or the number of boundaries in each) could affect the results. It would be helpful to provide verification (either mathematically or with simulations) that higher overlap in one/both searchlights does not lead to a larger difference in overlap between shared and non-shared boundaries.</p><p>2. The analysis focuses on pairs of searchlights/regions, demonstrating that in a subset of regions there is a higher chance of an overlap with event boundaries for neural state boundaries that are shared between two regions. Yet the interpretation goes beyond this, suggesting that &quot;boundaries that were represented in more brain regions at the same time were also more likely to be associated with the experience of an event boundary&quot;. Additional analyses would be needed to back this claim, demonstrating that overlap between a larger number of regions increases the chance of perceiving a boundary.</p><p>3. Could the effect be due to reduction of noise rather than event boundaries arising at neural state boundaries shared between regions? Identifying boundaries shared by two regions has a similar effect to averaging, which the authors have indeed found reduces noise and provides a better estimation of boundaries within each searchlight. This possibility should be discussed.</p><p>Recommendations for the authors:</p><p>1. As this is a revision of a previous version of the manuscript, and the authors have already conducted a great deal of work to address previous concerns, I am hesitant to suggest additional analyses. However, there are a few analyses that may help strengthen the conclusions – these are suggested as optional additional analyses, but the authors should feel free not to include them:</p><p>• To verify the overlap between searchlights is not due to various artifacts, it may be preferable to compare the searchlight in one region with the searchlights of other groups in the second region (following the rationale of intersubject functional connectivity vs. functional connectivity). It would also be interesting to further explore the nature of the overlap – to see whether there are specific state boundaries that drive most of the overlap or whether different pairs of regions have different overlapping boundaries. This could be used to explore the nature of the hierarchy between regions, beyond just finding that higher regions share boundaries with lower regions. For example, it could enable testing whether state shifts shared by multiple lower level regions are the ones that traverse the hierarchy.</p><p>• Further to this, it would be interesting to test whether event boundaries and non-event neural state boundaries form a similar hierarchy (though this may not be feasible with such a low number of event boundaries).</p><p>• To assess the effects of noise reduction on the overlap between neural state boundaries and event boundaries, it may be worth testing whether neural state boundaries shared across groups of participants are also more likely to be event boundaries (and specifically whether this effect is stronger in the same regions arising from the co-occurrence analysis). This analysis wouldn't provide an answer, but could help shed some light on the role of noise reduction</p><p>2. Some of the conclusions do not completely reflect the results. If additional analyses are not added, perhaps these conclusions could be rephrased, such as &quot;some of the neural boundaries are represented throughout the hierarchy.… until eventually reflected in conscious experience&quot; (p. 14) and &quot;boundaries that were represented in more brain regions at the same time were also more likely to be associated with the experience of an event boundary&quot; (p. 15).</p><p>3. Since the GSBS algorithm was fine-tuned based on the data that was later used for analysis, it would be helpful to include additional information demonstrating the choices in the optimization procedure are independent of the eventual results. For example, it isn't clear what 'important boundaries being detected late' means, whether that indicates event boundaries were being missed by the original algorithm. Combined with the fact part of the optimization was based on fixing the number of state boundaries to the number of event boundaries – could these choices have increased the chance of finding overlap between state boundaries and event boundaries?</p><p>4. Two small notes: the network defined as posterior DMN includes anterior regions, which is slightly confusing; were the regional differences in HRF assessed on the resting state data or the movie watching data?</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.77430.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><p>[Editors’ note: the authors resubmitted a revised version of the paper for consideration. What follows is the authors’ response to the first round of review.]</p><disp-quote content-type="editor-comment"><p>The reviewers were in agreement that this is an important topic and that this research is both interesting and promising. However, the reviewers raised a number of significant concerns that centered around two themes. First, there were a number of points raised about the methodology itself and its validity. After some discussion, it was decided that these methodological points could be addressable through additional analysis and/or simulation, but likely require considerably more work than would be usual for an eLife revision. The second set of concerns were with regard to the clear scientific advance over prior work; there was not consensus that these findings move the field forward in a clear way. Reviewer 1 suggested that the generalizability and impact might be improved by drawing direct links to the existing literature, including analysis of a secondary dataset as in the Baldasano et al. (2017) paper. Though, there might be other ways to clarify the impact, as well. Regardless, this is a challenging concern to address in a straightforward way through revision.</p><p>As addressing these concerns would likely require more than is typically expected for an eLife revision, it was decided to reject this submission. This being said, if you were to undertake the work required to conclusively address these issues, there was sufficient enthusiasm among reviewers that they would be willing to consider this paper again, as a new submission.</p><p>I have appended the detailed reviews to this decision letter. I hope you find them constructive with this work.</p><p>Reviewer #1:</p><p>In this paper, Geerligs et al. focus on the alignment of event boundaries across brain regions. They examine the transitions between brain states using the method introduced by Baldassano et al. (2017), and how these state transitions are shared across nodes of large-scale brain networks. They introduce a method that enables them to map event-timescales in a broader set of regions than previously possible, and they use this method to reveal how functional networks of regions share time-aligned &quot;event transitions&quot;.</p><p>This is a well-written manuscript on a timely and important question.</p></disp-quote><p>We thank the reviewer for their compliments about our work.</p><disp-quote content-type="editor-comment"><p>My main concerns relate to the validity (and potential sources of bias) in the methodology for identifying the event-rate of each region, and I also outline a number of other areas where the conceptual and methodological framing could be improved.</p><p>p.3 &quot;This dataset, in combination with the application of hyperalignment to optimize functional alignment (Guntupalli et al., 2016), allowed us to study event segmentation across the entire cortex for the first time, because this dataset shows reliable stimulus-driven activity (i.e., significant inter-subject correlations) over nearly all cortical brain regions (Geerligs et al., 2018). &quot;</p><p>A central methodological question, which affects almost every claim in this manuscript, is whether the inference of event boundaries from the HMM model (the methods in Figure 1) is valid, and in what ways it might be biased. The validity question is simple: does it measure what it is supposed to measure? In particular, I would like the authors to justify the final step, in which they compute the difference between the correlation for real boundaries and the correlation for random boundaries. Surely, this difference computation will be affected by the noise ceiling of the individual ROI being examined? I understand why using the random condition as a &quot;reference&quot; makes some sense, but I do not understand why the final decision is made based on the simple arithmetic difference of the mean value for the random boundaries and real boundaries? I suggest that the authors justify this procedure using a simulation procedure where the ground truth about event transitions is known, and the procedure should be compared against the method applied in the original Baldassano et al. (2017) paper.</p><p>The bias question is also fairly simple: which factors influence the &quot;k&quot; that is inferred? In particular, if a region has high reliability or low reliability of its response across subjects, does this affect the number of events that will be inferred for that region using the HMM procedure? As noted above, this simulation could additionally investigate how the &quot;k&quot; value varies as function of the noise level (i.e. response reliability) of the ROI.</p><p>Additionally, although hyperalignment render a larger swathe of cortex available to analysis, but there will still be variability in the reliability of the signal across regions, and this might interact with the hyperalignment performance. In particular, the accuracy of the hyper alignment procedure (for each subject) will presumably also increase for regions whose reliability of response is higher; it is therefore very to consider whether noise (in &quot;space&quot;) introduced by the hyperalignment procedure (and varying across regions as a function of their reliability) could further bias the measurement of the event-timescale via the HMM procedure.</p><p>Finally, to better understand this method, the authors could also apply their approach to the freely available data from the Baldassano et al. (2017) paper. Does this method produce results that are at least qualitatively similar? This could help to resolve the question of why the event timescales in this paper are shorter than those observed in the Baldassano et al. paper.</p></disp-quote><p>We thank the reviewer for these valid questions. In trying to answer them, we performed many simulations to determine the validity of our previous approach. These simulations revealed to us that the method we used before was indeed biased by the level of noise in different brain regions. While running these simulations we also discovered some problems with the HMM-approach in dealing with states of unequal length. In the end, all of these issues led us to develop a new method for detecting neural state boundaries and the optimal number of states, which does not suffer from these issues. This new method called greedy state boundary search (GSBS) was used to redo all the analyses in the paper and has now been published in Neuroimage – https://doi.org/10.1016/j.neuroimage.2021.118085<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroimage.2021.118085">.</ext-link></p><p>In the Neuroimage paper, we performed an extensive set of simulations to demonstrate the validity of GSBS. We show that state boundaries can be identified reliably when the data are averaged across groups of ~17/18 or more participants. We also observed that high levels of noise in the data lead our algorithm to over-estimate the number of states in a region. In contrast, regions such as the medial prefrontal cortex, which show relatively low levels of inter-subject synchrony, have a small number of long-lasting neural states. Therefore, we can be confident that the regional differences in the number of states we observe are not due to regional differences in noise.</p><disp-quote content-type="editor-comment"><p>p.7: Event networks: &quot;We found that event boundaries are shared within long-range networks that resemble the functional networks that are typically identified based on (resting state) timeseries correlations (see figure 3A)&quot;.</p><p>This is one of the most intriguing aspects of this paper. However, it would be much more convincing if the authors would replace their qualitative language (e.g. &quot;resemble&quot;) with quantitative metrics of overlap. The overlap could be measure between (a) networks defined based on event-timing and (b) networks defined based on functional connectivity. All of the major functional networks should be available in atlases (e.g. the Yeo lab atlases) or via data sharing repositories. Thus, the authors should be able to substantiate their broad claims of &quot;resemblance&quot; with quantitative demonstrations of how well the event-networks match the functional-connectivity-networks. All of the visual networks as well as the FPN and DMN should be quantitatively compared against standard networks defined elsewhere in the literature.</p><p>On the same point: p.13 &quot;The fractionation of the DMN into a fast and slow subnetwork closely aligns with the previously observed posterior and anterior DMN subnetworks (Andrews-Hanna et al., 2010; Campbell et al., 2013; Lei et al., 2014).&quot;</p><p>Again, please quantify the alignment when claiming spatial alignment with prior findings.</p></disp-quote><p>To address this concern, we compared the measures of boundary overlap to the functional connectivity observed with correlation of time series across all pairs of searchlights. We show that there is only a medium sized correlation between the two (r=0.39) suggesting that overlap of neural state boundaries is not simply a result of ‘regular’ functional connectivity between brain regions. In fact, we observe that regions that are negatively correlated do tend to have neural state boundaries at the same time.</p><p>To determine the correspondence to previously identified networks, we now quantify the spatial alignment between the networks we detected and the networks defined by Power et al. (2011). We also compared the DMN subnetworks to the previously detected DMN subnetwork by Campbell et al. (2013). For the newly identified superior DMN, we were not able to quantify the alignment with the data from Gordon et al. (2020) because those data were in surface space, rather than MNI space.</p><p>The new results and comparisons can be found on page 8-12 of the manuscript and tables S1 and S2.</p><disp-quote content-type="editor-comment"><p>p.13 &quot;Our results show for the first time that neural events are shared across brain regions in distinct functional networks. &quot;</p><p>The authors should consider re-wording this sentence to distinguish their findings from what was already shown in Figure 4B of Baldassano et al. (2017). In particular, note the commonality of event boundaries across early visual and late visual areas (part of the visual network), as well as the commonality of events across angular gyrus and posterior medial cortex (parts of the DMN).</p></disp-quote><p>We have rephrased this to: “In line with previous work (Baldassano et al., 2017) we found that neural state boundaries are shared across brain regions. Our results show for the first time that these boundaries are shared within distinct functional networks.”</p><disp-quote content-type="editor-comment"><p>On a related note, in the Abstract we read: &quot;This work extends the definition of functional networks to the temporal domain&quot; – I am unclear on how novel this extension is. To the best of my understanding, the concept of dynamic functional connectivity is not new (e.g. Hutchison et al., 2013), and even second-order pattern-transition methods have been employed to study functional networks (e.g. Anzellotti and Coutanche, 2018). I would like the authors to sharpen their argument for why this result is not entirely expected in light of prior work. Shouldn't members of the same functional networks be expected to exhibit state-transitions at rates higher than chance?</p></disp-quote><p>We have removed this claim from the abstract. In addition, we now show in the Results section and figure S6 that the correlations between state boundaries cannot be directly explained from the correlations between the average searchlight timeseries (i.e., regular functional connectivity). The following text has been added to the manuscript”:</p><p>“Although the networks we identified show overlap with functional networks previously identified in resting state, they clearly diverged for some networks (e.g., the visual network). Some divergence is expected because neural state boundaries are driven by shifts in voxel-activity patterns over time, rather than by the changes in mean activity that we typically use to infer functional connectivity. This divergence was supported by the overall limited similarity with the previously identified networks by Power et al. (2011; adjusted mutual information = 0.39), as well as the differences between the correlation matrix that was computed based on the mean activity time courses in each searchlight and the relative boundary overlap between each pair of searchlights (figure S6; r=0.31). Interestingly, regions with strongly negatively correlated mean activity time courses typically showed overlap that was similar to or larger than the overlap expected by chance. Indeed, the relative boundary overlap between each pair of searchlights was more similar to the absolute Pearson correlation coefficient between searchlights (r=0.39) than when the sign of the correlation coefficient was preserved (r=0.31). This suggests that pairs of regions that show negatively correlated BOLD activity still tend to show neural state boundaries at the same time.”</p><disp-quote content-type="editor-comment"><p>p.11. I struggled to follow the logic of the analysis employed in Figure 6. Why is event duration being predicted from individual frequency bands of the PSD? There is voluminous evidence for band-specific and region-specific artifact (e.g. Birn et al., 2013; Shmueli et al., 2007). Furthermore, distinct functional networks have distinct frequency profiles and coherence patterns (e.g. Salvador et al., 2008; Baria et al., 2011; Stephens et al., 2013). Finally, the frequency bands in the PSD are non-independent (because of the temporal smoothing in the BOLD signal). Therefore, the relationship between frequency band and event duration is confounded by (i) non-independence of frequencies and (ii) frequency covariation across brain regions which arises for a multitude of reasons. The results in Figure 6A seem rather noisy to me, and I imagine that this is because the regression procedure on the PSD is influenced by many interacting and confounding variables.</p><p>Another region why this analysis produces (in my opinion) curious results is that it spans distinct sensory modalities which are already known to have opposite PSD-event relationships: along the auditory pathway, PSDs get flatter as event time-scales get longer, while in the visual pathway, PSDs in V1 are already very steep, even while the event timescales are short. It is not clear what is gained by fitting a single model to regions with obviously different relationships of PSD and event structure.</p></disp-quote><p>In response to the comments of reviewers 1 and 3, we have removed the resting state analyses from the paper. We realised that using the power spectral density as a proxy for neural state timescales is suboptimal, given the variable duration of neural states within brain regions. In response to reviewer suggestions, we have shifted the focus of the manuscript to what neural states can tell us about the neural mechanisms underlying event segmentation.</p><disp-quote content-type="editor-comment"><p>p.12. &quot;These results suggest that visual and auditory stimulation are a prerequisite for observing the temporal hierarchy we describe in this paper and that this hierarchy only partly reflects an intrinsic property of brain function that is also present in the resting state.&quot;</p><p>I do not follow the logic supporting this claim. How can we know whether the (event-based) temporal hierarchy is preserved in the resting state unless we can measure the event transitions in the resting state data? Isn't this analysis just another way of saying that the PSDs have different shapes during rest and during movie viewing?</p></disp-quote><p>This claim has been removed from the paper, in relation to the previous point made by the reviewer.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>In this paper, Geerlings and colleagues leverage a large, publicly-available dataset in order to assess shared and distinct timescales of neural pattern shifts at event boundaries across different areas of the brain. In line with prior work, the authors report a gradient of timescales in neural event segmentation, with sensory regions comprising the fastest-shifting areas and 'default mode' nodes such as precuneus and medial prefrontal cortex comprising the slowest-shifiting areas. Importantly, the authors build on this previous research and demonstrate that canonical functional networks – such as the frontoparietal network, and the 'default mode' network – feature distinct subnetworks with corresponding faster and slower timescales of pattern shifts. Finally, a fairly novel analysis applied to these types of data examined power spectral density across regions, which could be used to predict event duration across regions (consistent with observed pattern shifts), and could partly, but not entirely, characterize resting-state fMRI data (suggesting that the audiovisual stimulus drove additional functional properties in brain networks not observed during rest).</p><p>Overall, this is an interesting and timely study. The question of how the brain segments naturalistic events is one of increasing popularity, and this manuscript approaches the question with a large sample size and fairly thorough analyses. That said, there are a number of questions and concerns, primarily regarding the analyses.</p></disp-quote><p>We thank the reviewer for their positive feedback.</p><disp-quote content-type="editor-comment"><p>• Procedures such as hyperalignment, or the related shared response model used by Baldassano and colleagues, are typically implemented by training on one set of the data, and applying the alignment procedure to a separate, held-out dataset (i.e., training and testing sets). It is unclear whether this approach was taken in the current study, or whether the hyperalignment algorithm was trained and tested on same dataset. In the latter case, there is a degree of circularity in the way across-participant alignment was conducted, potentially leading to biased correlation measures. The movie used in the CamCAN dataset is only 8 minutes long, which is probably not enough data for obtaining separate training and test datasets. However, this is still potentially a serious issue for this manuscript, and I am not sure if the use of hyperalignment is appropriate. If I have misunderstood the methodology, it perhaps warrants some clarification in how the training and application of the hyperalignment algorithm proceeded. (I will note that I am aware you used cross-validation for deriving the number of events, but that is unfortunately a separate issue from a train-test split in the hyperalignment routine itself.)</p></disp-quote><p>We agree with the reviewer that hyperalignment parameters are typically estimated in a separate dataset. Hyperalignment can introduce dependencies between datasets from different participants, which can result in biased statistics. To avoid this issue, we ran hyperalignment separately in each of the participant subgroups reported in the manuscript. All statistical testing was performed on independent subgroups of participants (17/18 participants per group), which were hyperaligned separately (i.e. within each group).</p><disp-quote content-type="editor-comment"><p>• A key finding from the study is that the FPN and DMN fractionate into different subnetworks that have fast and slow timescales. As noted above, the present results are based on an analysis of data from a relatively short period of time. Although the sample size is very large, one wonders whether this distinction would remain solid with a longer movie. With a very short movie, one can only sample a small number of real events, and this could lead to some instability in estimates of the timescale of representations in relation to the events. This might be an issue in relation to the differentiation of fast and slow subnetworks within the FPN and DMN. For instance, Figure 3B, suggests that the fit values for the slow FPN remain more or less stable across a range of event durations (which presumably reflect k values?). The slow FPN shows an interesting bimodal distribution (as do many of the networks) with the second peak coinciding with the peak for the fast FPN. The differentiation is a bit more convincing for the fast and slow DMN, but it is still not clear whether there are enough events and enough fMRI data from each subject to ensure reliable estimates of the timescales. Just to provide some context for this point, some estimates suggest that reliable identification of resting state networks requires at least 20 minutes of fMRI data.</p></disp-quote><p>To illustrate the reliability of our approach in identifying regional timescale differences, we now estimate the timescales separately in two independent samples of participants (see figure 1). The correlations between the results of these two groups is very high at the voxel level (r=0.85), suggesting that even in this short dataset we can reliably estimate regional differences in timescale.</p><p>Second, figure 4 shows that the timescale differences across the different DMN subnetworks are highly reliable across the searchlights in these networks. It should be noted that due to substantial improvements to our data analysis pipeline, we no longer observe two distinct FPN networks.</p><disp-quote content-type="editor-comment"><p>• Throughout the paper, fMRI results are described in reference to event processing, but the relationship is underdeveloped. Much of the paper relies on the Hidden Markov Model, which assumes that there is a pattern that remains stationary throughout an event. Baldassano's data shows a surprisingly strong correspondence in posterior medial cortex, but it is less clear whether this assumption is valid for other areas. In relation to this point, one can think of event processing as an accumulation of evidence. At the onset of an event, one might have a decent idea of what is about to happen, but as information comes in, the event model can be refined to make stronger predictions. These kinds of within-event dynamics would be lost in the Hidden Markov model. A related point is that the paper conflates timescales of neural states with psychologically meaningful conceptions of events. EST suggests that event segmentation is driven by prediction error-by one interpretation of the model, sensory information can change considerably without leading one to infer an event boundary. However, change in incoming sensory information would almost certainly lead to the detection of &quot;event boundaries&quot; across short timescales in sensory cortical areas. Figure 5 makes it fairly clear that there is a pretty strong distinction to be made between data-driven event identification based on the fMRI data and psychologically meaningful events inferred by the subjects. It would be helpful for the authors to be more clear about what the data do and do not show in relation to putative event cognition processes.</p></disp-quote><p>We strongly agree with the reviewer that it is important to distinguish between the transitions in brain activity patterns observed in the current paper and perceived event boundaries that have been described extensively in the behavioural literature. We have therefore changed the terminology in the paper and refer to ‘neural states’, rather than events when referring to the brain data. We now also discuss much more extensively what our findings can tell us about the mechanisms underlying event segmentation in both the introduction and Discussion sections.</p><disp-quote content-type="editor-comment"><p>• Why were voxels with an intersubject correlation of less than r=0.35 excluded from analyses? Is this based on prior studies or preliminary analyses? It is not necessarily a bad thing if this choice was made arbitrarily, but I imagine this threshold could have important impacts on the data as presented, so it is worth clarifying.</p></disp-quote><p>We investigated the effect of thresholding based on inter-subject correlation in a recent Neuroimage paper (Geerligs et al., 2021) and we observed that it did not result in more reliable estimates of neural state boundaries. Hence, we have removed this threshold from the analysis pipeline.</p><disp-quote content-type="editor-comment"><p>• Was ME-ICA the only step taken to account for head motion artifacts? If so, there is some concern about whether this step was sufficient to deal with the potential confound. This is especially critical given the fairly brief time series being analyzed here. It would be more compelling to see a quantitative demonstration that head motion is not correlated with the measures of interest.</p></disp-quote><p>ME-ICA denoising is currently the most effective method to deal with head motion (Power et al., 2018, PNAS). In addition, all our analyses are performed on group averaged data. This means that head motion that is not synchronized across participants cannot affect the results. To further investigate this potential confound, we computed the correlation between scan to scan head motion and state boundaries for each searchlight within each of the 15 groups of participants. Next we used a Wilcoxon signrank test to investigate if these correlations were significantly different from zero across the 15 groups. We found that none of the searchlights showed a significant association between the average head motion in each group of participants and the occurrence of neural state boundaries. These results are reported in the supplementary Results section. Together these results suggest that head motion did not confound the results reported in the current manuscript.</p><disp-quote content-type="editor-comment"><p>• A related issue is that of eye movements. Eye movements are related to event processing (e.g., Eisenberg et a., 2018), so one can expect neural activity related to event prediction/prediction error to be confounded with lower-level effects related to eye movements. For instance, we might expect signal artifacts in the EPI data, as well as neural activity related to the generation of eye movements, and changes in visual cortex activity resulting from eye movements. It is unlikely that this issue can be conclusively addressed with the current dataset, and it's not a deal-breaker in the sense that eye movements are intrinsically related to naturalistic event processing. However, it would be useful for the authors to discuss whether this issue is a potential limitation.</p></disp-quote><p>We agree with the reviewer that eye movements may affect neural data in the frontal eye fields as well as sensory cortices. However, they are indeed intrinsically related to naturalistic stimulus processing. Fixating the eyes would result in a very unnatural mode of information processing which might bias neural activity in very different ways. In response to this comment from the reviewer, we added the following section to the discussion:</p><p>“It should be noted that this more naturalistic way of investigating brain activity comes at a cost of reduced experimental control (Willems et al., 2020). For example, some of the differences in brain activity that we observe over time may be associated with eye movements. Preparation of eye movements may cause activity changes in the frontal-eye-fields (Vernet et al., 2014), while execution of eye movements may alter the input in early sensory regions (Lu et al., 2016; Son et al., 2020). However, in a related study (Davis et al., 2021), we found no age difference in eye movement synchrony while viewing the same movie, despite our previous observation of reduced synchrony with age in several areas (particularly the hippocampus, medial PFC, and FPCN; Geerligs et al., 2018), suggesting a disconnect between eye movements and neural activity in higher-order areas. In addition, reducing this potential confound by asking participants to fixate leads to an unnatural mode of information processing which could arguably bias the results in different ways by requiring participants to perform a double task (monitoring eye movements in addition to watching the movie). ”</p><disp-quote content-type="editor-comment"><p>• The power spectral analyses were a bit difficult to follow, but more importantly, the motivation for the analysis was not clearly described. The main take home points from this analyses are nicely summarized at the end of p. 14, but it would be helpful to clarify the motivation for this analysis (and the need for doing it) on p.11 in the Results section. Relatedly, is Figure 6A an example spectrum from a particular voxel or region, or an average across regions?</p></disp-quote><p>These analyses have now been removed from the paper. Based on the comments from reviewers 1 and 3, we realised that using the PSD as a proxy for neural state timescales is suboptimal, given the variable duration of neural states within brain regions.</p><disp-quote content-type="editor-comment"><p>• The take-home message appears to be that different brain networks have different timescales at which they seem to maintain event representations. Moreover, certain networks (e.g., the posterior medial/'default mode' network) do not have uniformly fast or slow timescales. The network-based analysis used here is indeed novel, but the impact of the work could be enhanced by clarifying the significance of the results in relation to what we know about event processing. The explicit demarcation of 'fast' and 'slow' subnetworks may be the key conceptual advance, as was the power spectral analysis, but it isn't clear whether these conclusions could also be ascertained from the maps shown in Baldassano et al., 2017 or other papers from the Hasson group.</p></disp-quote><p>We have completely rewritten the introduction and Discussion sections to clarify the significance of our work in relation to what we know about event processing.</p><disp-quote content-type="editor-comment"><p>This review was completed by Zach Reagh, Ph.D. in collaboration with Charan Ranganath, Ph.D. (I sign all reviews)</p><p>Reviewer #3:</p><p>Geerligs and colleagues conduct a thorough set of analyses aimed at identifying event segmentation timescales across the cortex in a large cohort of participants. They extend previous work by Baldassano et al. by covering the entire cortex, and nicely control for the power spectrum of different regions. In addition, they examine which regions share the same event boundaries, not just the same timescale, and relate these to functional connectivity networks. Overall, their work is impressive and rigorous, but there are a few points that make it somewhat difficult to assess the how strong the contribution is to our understanding of processing timescales:</p></disp-quote><p>Thank you for your enthusiasm. We address your specific concerns below.</p><disp-quote content-type="editor-comment"><p>1. The authors divide the brain into functional networks based on boundary similarity and find that this division is very similar to functional networks defined using resting-state timeseries correlations. They further find increased similarity between regions of different networks that are that are interconnected. Wouldn't the similarity between boundary vectors be strongly linked to the timeseries correlations (both between regions in the same network and across networks)? While the similarity-based functional networks aren't completely identical to those identified in rest, perhaps the same results would be obtained by correlating timeseries in this specific dataset, using the movie data (altering the interpretation of the results).</p></disp-quote><p>We now show in the Results section and figure S6 that the correlations between state boundaries cannot be directly explained from the correlations between the average searchlight timeseries (i.e., regular functional connectivity). Although there are similarities between the two, as we would expect, the correlation between them is only r=0.31, suggesting that the same results could not have been obtained using ‘regular’ functional connectivity analyses in the movie dataset. The following text has been added to the manuscript:</p><p>“Although the networks we identified show overlap with functional networks previously identified in resting state, they clearly diverged for some networks (e.g., the visual network). Some divergence is expected because neural state boundaries are driven by shifts in voxel-activity patterns over time, rather than by the changes in mean activity that we typically use to infer functional connectivity. This divergence was supported by the overall limited similarity with the previously identified networks by Power et al. (2011; adjusted mutual information = 0.39), as well as the differences between the correlation matrix that was computed based on the mean activity time courses in each searchlight and the relative boundary overlap between each pair of searchlights (figure S6; r=0.31).</p><p>Interestingly, regions with strongly negatively correlated mean activity time courses typically showed overlap that was similar to or larger than the overlap expected by chance. Indeed, the relative boundary overlap between each pair of searchlights was more similar to the absolute Pearson correlation coefficient between searchlights (r=0.39) than when the sign of the correlation coefficient was preserved (r=0.31). This suggests that pairs of regions that show negatively correlated BOLD activity still tend to show neural state boundaries at the same time.”</p><disp-quote content-type="editor-comment"><p>2. It seems that the power spectrum analysis is run both on the resting-state data and on the movie data, whereas the timescale segmentation is run only on the movie data. I expect this is because hyperalignment is possible only when using a shared stimulus, and the HMM is run only on the hyperaligned data. However, this may bias the correlations presented in figure 6 – the movie PSD-based timescale estimation would be expected to be more similar to the HMM timescales than the rest, simply because the same data is used. A more convincing analysis would be to run the HMM on the rest data as well, and test for correlations between the two estimations of event timescales in the rest data, although this would entail substantial additional analyses (as HMM would also have to be run on non-hyperaligned movie data for comparability). It would also help with point 1, testing whether similarity in boundary vectors arises directly from timeseries correlations. I realize this adds quite a bit of analysis, and the authors may prefer to avoid doing so, but the conclusions arising from the power spectrum analysis should be softened in the Results and Discussion, clearly mentioning this caveat.</p></disp-quote><p>Unfortunately, it is not possible to detect neural states in the resting state data, since detecting neural states requires data averaging across participants. Because resting-state fluctuations in brain activity are not stimulus driven, data cannot be meaningfully averaged across participants in resting state. Therefore, based in the comments from reviewers 1 and 3 and the altered focus of the paper on neural mechanisms underlying event segmentation, we have removed the analyses from the PSDbased timescale estimation from the paper.</p><disp-quote content-type="editor-comment"><p>3. It would aid clarity to better separate the current contributions from previous findings, in the Results, and mainly in the Discussion. The authors do describe what has previously been found, citing all relevant literature, but it would be helpful to have a clear division of previous findings and novel ones. For example in the first paragraph of the Discussion, and in general when discussing the interpretation of activity the different regions (currently regions that have already been found are somewhat intermixed with the new regions found).</p></disp-quote><p>We have rewritten the introduction and Discussion sections extensively to make more clear what is novel in the current study.</p><p>[Editors’ note: what follows is the authors’ response to the second round of review.]</p><disp-quote content-type="editor-comment"><p>The manuscript has been improved but there are some remaining issues that need to be addressed, as outlined below:</p><p>The reviewers were positive about the revisions you made to this submission and felt that extensive work had been done to improve the paper. There were a few remaining points raised by this review that could be addressed the further strengthen the paper. The Reviewing Editor has drafted this to help you prepare a revised submission.</p></disp-quote><p>We are very happy to hear that the reviewers were positive about the extensive work we did for the revision. We have taken care to address all remaining points. A summary of the most important changes is provided below.</p><p>First, we have described our analyses more clearly, regarding how the overlap between neural state and event boundaries is computed and how we compare this overlap for shared vs. non-shared states. This also helped us streamline our analyses more and we now use the same metric (absolute overlap) throughout the manuscript, also for investigating the effect of boundary strength. This should make the paper easier to follow for readers. Second, we have added additional analyses to more clearly demonstrate the effects of boundary sharing across (large) parts of the cortical hierarchy in relation to perceiving event boundaries. These analyses provide stronger support for the claims we made in the previous version of the manuscript. Finally, we have added some analyses to make sure that the effects we see cannot be explained by shared confounds or noise.</p><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1. Reviewer 1 has raised some additional points for clarification in their review, as noted below. These should be clarified in a revision. Please refer to the comments below for these notes.</p></disp-quote><p>We have clarified all the points that the reviewer raised. More details about these clarifications are provided in the answers to specific reviewer comments below.</p><disp-quote content-type="editor-comment"><p>2. Some of the conclusions do not completely reflect the results. If additional analyses are not added, perhaps these conclusions could be rephrased, such as &quot;some of the neural boundaries are represented throughout the hierarchy.… until eventually reflected in conscious experience&quot; (p. 14) and &quot;boundaries that were represented in more brain regions at the same time were also more likely to be associated with the experience of an event boundary&quot; (p. 15).</p></disp-quote><p>We rephrased the first sentence (originally p 14) to: “This finding suggests that some of the neural state boundaries that can be identified in early sensory regions are also consciously experienced as an event boundary. Potentially because these boundaries are propagated to regions further up in the cortical hierarchy.”</p><p>The second sentence (p. 15) is now supported more strongly by the results that we have obtained through new analyses. More details about these new results are provided in the answers to specific reviewer comments below.</p><disp-quote content-type="editor-comment"><p>3. Since the GSBS algorithm was fine-tuned based on the data that was later used for analysis, it would be helpful to include additional information demonstrating the choices in the optimization procedure are independent of the eventual results. For example, it isn't clear what 'important boundaries being detected late' means, whether that indicates event boundaries were being missed by the original algorithm. Combined with the fact part of the optimization was based on fixing the number of state boundaries to the number of event boundaries – could these choices have increased the chance of finding overlap between state boundaries and event boundaries?</p></disp-quote><p>The primary concern with the performance of the original algorithm in some brain regions, was that the placement of one new boundary resulted in a huge increase in the t-distance. This suggests there was a strong neural state boundary (i.e. large transition in brain activity patterns) that was detected in a late iteration of the algorithm. Therefore, the peak of the t-distance was at a high value of <italic>k</italic> (number of states) and the inferred optimal number of states was higher than it should have been. By placing two boundaries at the same time (i.e. inferring the location of a state, rather than the location of one boundary), the algorithm behaves much more stable and no longer shows this kind of behavior.</p><p>We have not investigated whether those boundaries that are detected late tend to overlap with event boundaries. This is because it is not the problem that the original algorithm missed boundaries, but rather that too many boundaries were added, probably including many boundaries that did not overlap with events. We have now clarified this point in the methods section:</p><p>“First, GSBS previously placed one boundary in each iteration. We found that for some brain regions, this version of the algorithm showed sub-optimal performance. A boundary corresponding to a strong state transition was placed in a relatively late iteration of the GSBS algorithm. This led to a steep increase in the t-distance in this particular iteration, resulting in a solution with more neural state boundaries than might be necessary or optimal (for more details, see the supplementary methods and figure 1A in appendix 1).”</p><p>And in the supplementary methods in appendix 1:</p><p>“First, we discovered that for specific brain regions the original GSBS algorithm performed suboptimally; the placement of one new boundary at a late stage in the fitting process resulted in a large increase in the t-distances (our measure of fit; see appendix 1 – figure 1A). This suggests that a strong neural state boundary (i.e. demarcating a large change in neural activity patterns) was detected only in a late iteration of the algorithm, which led to an overestimation of the number of neural states.”</p><p>For completeness we also reran the analyses comparing states and events without fixing the number of states to the number of events. The results of these analyses support our original conclusions and are shown in appendix 1 – figure 2. The adapted text in the supplementary methods section of appendix 1 is copied below:</p><p>“To investigate how these changes to GSBS impacted reliability, we split the data in two independent groups of participants and looked at the percentage of overlapping boundaries between the groups for each searchlight. To make sure differences in number of states between methods did not impact our results, we fixed the number of state boundaries to 18 or 19. Because the states-GSBS algorithm can place one or two boundaries at a time, we cannot fix the number of state boundaries exactly, which is why is can be either 18 or 19. We found that the number of overlapping boundaries between groups was substantially higher for states-GSBS, compared to the original GSBS implementation and also compared to the GSBS implementation with altered finetuning (see appendix 1 – figure 2A). This was also the case when we used the optimal number of states as determined by the t-distance, instead of fixing the number of states (see appendix 1 – figure 2B).”</p><disp-quote content-type="editor-comment"><p>4. Two small notes: the network defined as posterior DMN includes anterior regions, which is slightly confusing; were the regional differences in HRF assessed on the resting state data or the movie watching data?</p></disp-quote><p>We have added the following sentence to clarify the issue about network naming: “It should be noted that all three of the DMN subnetworks include some anterior, superior and posterior subregions; the names of these subnetworks indicate which aspects of the networks are most strongly represented.”</p><p>Regional differences in HRF were assessed with movie data. This has now been clarified in the methods section:</p><p>“We also investigated the effects of estimating the HRF shape based on the movie fMRI data, instead of using the canonical HRF and found that this did not have a marked impact on the results (see supplementary methods in appendix 1).”</p><p>And also in the supplementary methods in appendix 1: “To investigate whether such differences might impact our results, we estimated the HRF for each participant and each searchlight, using the rsHRF toolbox that is designed to estimate HRFs in resting state data (Wu et al., 2021). In this case we applied the algorithm to our fMRI data recorded during movie watching.”</p><disp-quote content-type="editor-comment"><p>Additional Suggestions for Revision (for the authors):</p><p>One of the reviewers had some suggestions for additional analyses that might strengthen the results. We pass them along to you here, but you should view these as optional. Only include them if you agree that they will strengthen the conclusions.</p><p>There are a few analyses that may help strengthen the conclusions - these are suggested as optional additional analyses, but the authors should feel free not to include them:</p><p>• To verify the overlap between searchlights is not due to various artifacts, it may be preferable to compare the searchlight in one region with the searchlights of other groups in the second region (following the rationale of intersubject functional connectivity vs. functional connectivity).</p></disp-quote><p>To address this point, we have repeated the overlap analyses in data with two independent groups of participants, like the reviewer suggested. The results of these analyses are described in the results section and in appendix 1 - figure 6.</p><p>“To make sure the observed relative boundary overlap between searchlights was not caused by noise shared across brain regions, we also computed the relative boundary overlap across two independent groups of participants (similar to the rationale of inter-subject functional connectivity analyses Simony et al., 2016). We observed that the relative boundary overlap computed in this way was similar to the relative overlap computed within a participant group (r=0.69; see appendix 1 - figure 6), suggesting that shared noise is not the cause of the observed regional overlap in neural state boundaries.”</p><p>And in the supplementary results section of appendix 1:</p><disp-quote content-type="editor-comment"><p>• It would also be interesting to further explore the nature of the overlap - to see whether there are specific state boundaries that drive most of the overlap or whether different pairs of regions have different overlapping boundaries. This could be used to explore the nature of the hierarchy between regions, beyond just finding that higher regions share boundaries with lower regions. For example, it could enable testing whether state shifts shared by multiple lower level regions are the ones that traverse the hierarchy.</p></disp-quote><p>To further explore the nature of the overlap we have now added an additional analysis in which we clustered time points with similar patterns of neural states. Below we copied the description from the results section:</p><p>“So far, we have focused on comparing state boundary timeseries across regions or between brain regions and events. However, that approach does not allow us to fully understand the different ways in which boundaries can be shared across parts of the cortical hierarchy at specific points in time. To investigate this, we can group timepoints together based on the similarity of their boundary profiles;</p><p>i.e. which searchlights do or do not have a neural state boundary at the same timepoint. We used a weighted stochastic block model (WSBM) to identify groups of timepoints, which we will refer to as ‘communities’. We found an optimal number of four communities (see figure 7). These communities group together timepoints that vary in the degree to their neural state boundaries are shared across the cortical hierarchy: timepoints in the first community show the most widely spread neural state boundaries across the hierarchy, while timepoints in the later communities show less widespread state transitions. We found that from community 1 to 4, the prevalence of state boundaries decreased for all networks, but most strongly for the FPCN and CON, sDMN, aDMN and auditory networks. However, the same effect was also seen in the higher visual and SMN and motor networks. This might suggest that boundaries that are observed widely across lower-level networks are more likely to traverse the cortical hierarchy. We also found a similar drop in prevalence of event boundaries across communities, supporting our previous observation that the perception of event boundaries is associated with the sharing of neural state boundaries across large parts of the cortical hierarchy. We repeated this analysis in two independent groups of participants to be able to assess the stability of this pattern of results. Although group 1 showed an optimum of four communities and group 2 an optimum of five communities, the pattern of results was highly similar across both groups (see appendix 1 - figure 8).”</p><disp-quote content-type="editor-comment"><p>• Further to this, it would be interesting to test whether event boundaries and non-event neural state boundaries form a similar hierarchy (though this may not be feasible with such a low number of event boundaries).</p></disp-quote><p>Unfortunately, this was indeed not feasible given the low number of event boundaries in our data. A longer movie would be required to answer this question.</p><disp-quote content-type="editor-comment"><p>• To assess the effects of noise reduction on the overlap between neural state boundaries and event boundaries, it may be worth testing whether neural state boundaries shared across groups of participants are also more likely to be event boundaries (and specifically whether this effect is stronger in the same regions arising from the co-occurrence analysis). This analysis wouldn't provide an answer, but could help shed some light on the role of noise reduction.</p></disp-quote><p>We have performed additional analyses to test whether these effects could indeed be due to noise reduction. These analyses have shown that noise reduction is an unlikely cause of our results. The relevant parts of the results section and supplementary results in appendix 1 are copied below:</p><p>Results section:</p><p>“Analyses shown in the supplementary results section in appendix 1 demonstrate that these increases in overlap for shared vs. non-shared boundaries cannot be attributed to effects of noise (see also appendix 1 - figure 7).”</p><p>Supplementary results in appendix 1:</p><p>“Effects of noise on overlap between neural states and events for shared boundaries</p><p>One concern is that identifying boundaries shared by two regions has a similar effect to averaging, which provides a better estimation of boundaries within each searchlight because it reduces noise. This noise reduction could be the cause of the increased overlap between events and neural states for shared boundaries vs. non-shared boundaries. To investigate this possibility we examined the increase in overlap for shared vs. non-shared values in the data averaged across 265 participants as well as for each independent subgroup of 17/18 participants. If noise reduction is the cause of the increase in overlap with event boundaries, we should expect the difference between shared and nonshared boundaries to be largest in the smaller independent subgroups where there is the most to be gained from noise reduction. In contrast, if the increase in overlap with event boundaries is a real effect, not due to noise, its effect size should be larger in the data averaged across all participants, where estimates of boundary locations are more accurate. The results in appendix 1 - figure 7 show that the latter interpretation is correct, making it unlikely that the observed increase in overlap between neural state and event boundaries is related to noise.”</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>This work investigates timescales of neural pattern states (periods of time with a relatively stable activity pattern in a region) across the brain and identify links between state shifts and perceived boundaries events. In multiple regions, they find significant overlap between state shifts and event boundaries, and an even stronger overlap for state shifts that occur simultaneously in more than one region. The results are interesting and timely and extend previous work by Baldassano et al. that found a similar hierarchy in a specific set of brain regions (here extended to the entire cortex).</p><p>Strengths</p><p>The question of whether neural state shifts form a hierarchy such that state shifts in higher regions coincide with state shifts in sensory regions, and the question of whether event boundaries occur at conjunctions of shifts in different regions are both very interesting.</p><p>The optimized GSBS method nicely overcomes limitations of previous methods, as well as a previous version of GSBS. In general, justification is provided for the different analysis choices in the manuscript.</p><p>The current work goes beyond previous work by extending the analysis to the entire cortex, revealing that state shifts in higher regions of the cortex overlap with state shifts in lower regions of the hierarchy.</p><p>Weaknesses</p><p>One of the important conclusions of the paper is that simultaneous neural state shifts in multiple brain regions are more likely to be experienced as boundaries. This finding fits in nicely with existing literature, but the analysis supporting it is not as compelling as the rest of the analyses in the paper:</p><p>1. The methods section describing the analysis is not entirely clear. Do Oi, Oj refer to the number of neural state boundaries in searchlights I,j? Or the number of neural state boundaries in each that overlap with an event boundary? If the former (which was my initial interpretation), then how is the reference searchlight chosen – max {Oi,Oj}, as indicated by the formula, or the searchlight with the larger overlap of its unique boundaries (and is the overlap calculated in numerical value or the proportion of overlap)? Given the unclarity, it is difficult to assess whether the degree of overlap between neural state boundaries and event boundaries in each of the searchlights (and/or the number of boundaries in each) could affect the results. It would be helpful to provide verification (either mathematically or with simulations) that higher overlap in one/both searchlights does not lead to a larger difference in overlap between shared and non-shared boundaries.</p></disp-quote><p>We agree that our initial description of this analysis was not sufficiently clear. We have now clarified the description of the approach we used. In the previous version of the paper, we used the relative boundary overlap to quantify the overlap for both the shared and non-shared boundaries, but after some simulations we did based on your suggestions, we realized that this metric was biased against pairs of regions with a high number of states (higher than the number of events). That is why we now use the absolute overlap in our analysis, which only depends on the proportion of neural state boundaries that overlap with events. This also led to much stronger evidence for the increased overlap between shared vs. non-shared neural state boundaries with event boundaries.</p><p>We have extensively revised our mathematical descriptions of both the overlap metrics as well as our explanations of how we computed the overlap difference between shared/non-shared pairs. These new descriptions clarify that higher overlap in one/both searchlights does not lead to a larger difference in overlap between shared and non-shared boundaries. The overlap metric only depends on the proportion of neural states that overlap with an event boundary. If that proportion is the same for shared/non-shared boundaries then the absolute overlap will also not show any difference.</p><p>The relevant sections of text are copied below:</p><p>“Comparison of neural state boundaries to event boundaries</p><p>To compare the neural state boundaries across regions to the event boundaries, we computed two overlap metrics; the absolute and relative boundary overlap. Both overlap measures were scaled with respect to the expected number of overlapping boundaries. To compute these values, we define E as the event boundary timeseries and S<sub>i</sub> as the neural state boundary timeseries for searchlight i. These timeseries contain zeros at each timepoint t when there is no change in state/event and ones at each timepoint when there is a transition to a different state/event.</p><p>The overlap between event boundaries and state boundaries in searchlight i is defined as:<disp-formula id="sa2equ1"><mml:math id="sa2m1"><mml:mrow><mml:msup><mml:mi>O</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>∙</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where n is the number of TRs.</p><p>If we assume that there is no association between the occurrence of event boundaries and state boundaries, the expected number of overlapping boundaries is defined as in Zacks et al. (2001a) as:<disp-formula id="sa2equ2"><mml:math id="sa2m2"><mml:mrow><mml:msub><mml:mtext>OE</mml:mtext><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>n</mml:mi><mml:mo>∙</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∙</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Because the number of overlapping boundaries will increase as the number of state boundaries increases, the absolute overlap (OA) was scaled such that it was zero when it was equal to the expected overlap and one when all neural state boundaries overlapped with an event boundary. The absolute overlap therefore quantifies the proportion of the neural state boundaries that overlap with an event boundary:<disp-formula id="sa2equ3"><mml:math id="sa2m3"><mml:mrow><mml:msub><mml:mtext>OA</mml:mtext><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mtext>OE</mml:mtext><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mtext>OE</mml:mtext><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Instead, the relative overlap (OR) was scaled such that is was one when all event boundaries overlapped with a neural state (or when all neural state boundaries overlapped with an event boundary if there were fewer state boundaries than event boundaries). In this way, this metric quantifies the overlap without penalizing regions that have more or fewer state boundaries than event boundaries. The relative overlap is defined as:<disp-formula id="sa2equ4"><mml:math id="sa2m4"><mml:mrow><mml:msub><mml:mtext>OR</mml:mtext><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mtext>OE</mml:mtext><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>.</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mtext>OE</mml:mtext><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>And later in the methods section:</p><p>“To look in more detail at how boundaries that are shared vs. boundaries that are not shared are associated with the occurrence of an event boundary, we performed an additional analysis at the level pairs of searchlights. For each pair of searchlights i and j, we created three sets of neural state boundaries timeseries, boundaries unique to searchlights i or j: <inline-formula><mml:math id="sa2m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo>∼</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="sa2m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mo>∼</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and boundaries shared between searchlights i and j: <inline-formula><mml:math id="sa2m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">&amp;</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. More formally, using the binary definition of the neural state boundary timeseries <italic>S</italic><sub><italic>i</italic></sub> and <italic>S</italic><sub><italic>j</italic></sub>, these are defined at each timepoint t as:<disp-formula id="sa2equ5"><mml:math id="sa2m8"><mml:mrow><mml:mtable columnalign="center center" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∙</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace linebreak="newline"/><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo>∼</mml:mo><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace linebreak="newline"/><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mo>∼</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Then, we investigated the absolute overlap between each of these three boundary series and the event boundaries as described in the section ‘Comparison of neural state boundaries to event boundaries’. This resulted in three estimates of absolute boundary overlap; for boundaries unique to searchlight <italic>i</italic> (<inline-formula><mml:math id="sa2m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>O</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo>∼</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) and searchlight <italic>j</italic> (<inline-formula><mml:math id="sa2m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>O</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mo>∼</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) and the shared boundaries (<inline-formula><mml:math id="sa2m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>O</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">&amp;</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>). Then we tested whether the absolute overlap for the shared boundaries was larger than the absolute overlap for non-shared boundaries, using the searchlight that showed the largest overlap in their unique boundaries as the baseline: <inline-formula><mml:math id="sa2m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>O</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi mathvariant="normal">&amp;</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>O</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mo>∼</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi>O</mml:mi><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mo>∼</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. Because the absolute boundary overlap is scaled by the total number of neural state boundaries, it is not biased when there is a larger or smaller number of shared/non-shared states between searchlights <italic>i</italic> and <italic>j</italic>. It is only affected by the proportion of neural state boundaries that overlap with an event boundary. If that proportion is the same for shared and non-shared boundaries, the overlap is also the same.”</p><p>In the Results section:</p><p>“To investigate the role of boundary co-occurrence across networks in more detail, we investigated for each pair of searchlights whether boundaries that are shared have a stronger association with perceived event boundaries as compared to boundaries that are unique to one of the two searchlights. We found that boundary sharing had a positive impact on overlap with perceived boundaries, particularly for pairs of searchlights within the auditory network and between the auditory network and the anterior DMN (see figure 6A and B). In addition, we saw that neural state boundaries that were shared between the auditory network and the early and late visual networks, and the superior and posterior DMN were more likely to be associated with a perceived event boundary than non-shared boundaries. The same was true for boundaries shared between the anterior DMN and the lateral and medial SMN network and the posterior DMN. Boundary sharing between the other higher-level networks (pDMN, sDMN, FPCN and CON) as well as between these higher-level networks and the SMN networks was also beneficial for overlap with event boundaries. On a regional level, the strongest effects of boundary sharing was observed in the medial prefrontal cortex, medial occipital cortex, preceuneus, middle and superior temporal gyrus and insula (see figure 6B). Analyses shown in the supplementary Results section in appendix 1 demonstrate that these increases in overlap for shared vs. non-shared boundaries cannot be attributed to effects of noise (see also appendix 1 – figure 7).”</p><disp-quote content-type="editor-comment"><p>2. The analysis focuses on pairs of searchlights/regions, demonstrating that in a subset of regions there is a higher chance of an overlap with event boundaries for neural state boundaries that are shared between two regions. Yet the interpretation goes beyond this, suggesting that &quot;boundaries that were represented in more brain regions at the same time were also more likely to be associated with the experience of an event boundary&quot;. Additional analyses would be needed to back this claim, demonstrating that overlap between a larger number of regions increases the chance of perceiving a boundary.</p></disp-quote><p>We have performed two additional analyses that provide strong support for this conclusion. First, we modified the analyses to investigate co-occurrence within networks and across the whole brain in figure 5A. Second, we added an exploratory analysis in which we identify communities of time points that also supports this claim (see figure 7). The relevant sections from the Results section are copied below:</p><p>“Shared neural state boundaries and event boundaries</p><p>Previous research on event segmentation has shown that the perception of an event boundary is more likely when multiple features of a stimulus change at the same time (Clewett et al., 2019). When multiple sensory features changes at the same time, this could be reflected in many regions within the same functional network showing a state boundary at the same time (e.g. in the visual network when many aspects of the visual environment change), or in neural state boundaries that are shared across functional networks (e.g. across the auditory and visual networks when a visual and auditory change coincide). Similarly, boundaries shared between many brain regions within or across higher-level cortical networks might reflect a more pronounced change in conceptual features of the narrative (e.g. the goals or emotional state of the character). Therefore, we expect that in a nested cortical hierarchy, neural state boundaries that are shared between many brain regions within functional networks, and particularly those shared widely across functional networks, would be more likely to be associated with the perception of an event boundary. To investigate this, we first weighted each neural state boundary in each searchlight by the proportion of searchlights within the same network that also showed a boundary at the same time. This is very similar to how we investigated the role of boundary strength above.”</p><disp-quote content-type="editor-comment"><p>Recommendations for the authors:</p><p>• It would be interesting to test whether event boundaries and non-event neural state boundaries form a similar hierarchy (though this may not be feasible with such a low number of event boundaries).</p></disp-quote><p>Unfortunately, this was indeed not feasible given the low number of event boundaries in our data. A longer movie would be required to answer this question.</p></body></sub-article></article>