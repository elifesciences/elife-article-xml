<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">63282</article-id><article-id pub-id-type="doi">10.7554/eLife.63282</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Trading mental effort for confidence in the metacognitive control of value-based decision-making</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-206570"><name><surname>Lee</surname><given-names>Douglas G</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5892-8694</contrib-id><email>DouglasGLee@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-69490"><name><surname>Daunizeau</surname><given-names>Jean</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9142-1270</contrib-id><email>jean.daunizeau@gmail.com</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Sorbonne University</institution><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff2"><label>2</label><institution>Paris Brain Institute (ICM)</institution><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff3"><label>3</label><institution>Institute of Cognitive Sciences and Technologies, National Research Council of Italy</institution><addr-line><named-content content-type="city">Rome</named-content></addr-line><country>Italy</country></aff><aff id="aff4"><label>4</label><institution>Translational Neuromodeling Unit (TNU), ETH</institution><addr-line><named-content content-type="city">Zurich</named-content></addr-line><country>Switzerland</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Donner</surname><given-names>Tobias H</given-names></name><role>Reviewing Editor</role><aff><institution>University Medical Center Hamburg-Eppendorf</institution><country>Germany</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution>Brown University</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>26</day><month>04</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e63282</elocation-id><history><date date-type="received" iso-8601-date="2020-09-20"><day>20</day><month>09</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-04-23"><day>23</day><month>04</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Lee and Daunizeau</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Lee and Daunizeau</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-63282-v2.pdf"/><abstract><p>Why do we sometimes opt for actions or items that we do not value the most? Under current neurocomputational theories, such preference reversals are typically interpreted in terms of errors that arise from the unreliable signaling of value to brain decision systems. But, an alternative explanation is that people may change their mind because they are reassessing the value of alternative options while pondering the decision. So, why do we carefully ponder some decisions, but not others? In this work, we derive a computational model of the metacognitive control of decisions or MCD. In brief, we assume that fast and automatic processes first provide initial (and largely uncertain) representations of options' values, yielding prior estimates of decision difficulty. These uncertain value representations are then refined by deploying cognitive (e.g., attentional, mnesic) resources, the allocation of which is controlled by an effort-confidence tradeoff. Importantly, the anticipated benefit of allocating resources varies in a decision-by-decision manner according to the prior estimate of decision difficulty. The ensuing MCD model predicts response time, subjective feeling of effort, choice confidence, changes of mind, as well as choice-induced preference change and certainty gain. We test these predictions in a systematic manner, using a dedicated behavioral paradigm. Our results provide a quantitative link between mental effort, choice confidence, and preference reversals, which could inform interpretations of related neuroimaging findings.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>choice</kwd><kwd>subjective value</kwd><kwd>value certainty</kwd><kwd>uncertainty</kwd><kwd>cognitive resources</kwd><kwd>expected value of control</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution>LabEx BIOPSY</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Lee</surname><given-names>Douglas G</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Intra-individual variability in choice, response time, subjective effort, confidence, and choice-induced preference change and certainty gain is explained by a cost–benefit model of cognitive resource allocation.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Why do we carefully ponder some decisions, but not others? Decisions permeate every aspect of our lives – what to eat, where to live, whom to date, etc. – but the amount of effort that we put into different decisions varies tremendously. Rather than processing all decision-relevant information, we often rely on fast habitual and/or intuitive decision policies, which can lead to irrational biases and errors (<xref ref-type="bibr" rid="bib37">Kahneman et al., 1982</xref>). For example, snap judgments about others are prone to unconscious stereotyping, which often has enduring and detrimental consequences (<xref ref-type="bibr" rid="bib27">Greenwald and Banaji, 1995</xref>). Yet we don't always follow the fast but negligent lead of habits or intuitions. So, what determines how much time and effort we invest when making decisions?</p><p>Biased and/or inaccurate decisions can be triggered by psychobiological determinants such as stress (<xref ref-type="bibr" rid="bib66">Porcelli and Delgado, 2009</xref>; <xref ref-type="bibr" rid="bib65">Porcelli et al., 2012</xref>), emotions (<xref ref-type="bibr" rid="bib29">Harlé and Sanfey, 2007</xref>; <xref ref-type="bibr" rid="bib13">De Martino et al., 2006</xref>; <xref ref-type="bibr" rid="bib76">Sokol-Hessner et al., 2013</xref>), or fatigue (<xref ref-type="bibr" rid="bib5">Blain et al., 2016</xref>). But, in fact, they also arise in the absence of such contextual factors. That is why they are sometimes viewed as the outcome of inherent neurocognitive limitations on the brain's decision processes, e.g., bounded attentional and/or mnemonic capacity (<xref ref-type="bibr" rid="bib24">Giguère and Love, 2013</xref>; <xref ref-type="bibr" rid="bib48">Lim et al., 2011</xref>; <xref ref-type="bibr" rid="bib55">Marois and Ivanoff, 2005</xref>), unreliable neural representations of decision-relevant information (<xref ref-type="bibr" rid="bib18">Drugowitsch et al., 2016</xref>; <xref ref-type="bibr" rid="bib86">Wang and Busemeyer, 2016</xref>; <xref ref-type="bibr" rid="bib90">Wyart and Koechlin, 2016</xref>), or physiologically constrained neural information transmission (<xref ref-type="bibr" rid="bib53">Louie and Glimcher, 2012</xref>; <xref ref-type="bibr" rid="bib64">Polanía et al., 2019</xref>). However, an alternative perspective is that the brain has a preference for efficiency over accuracy (<xref ref-type="bibr" rid="bib82">Thorngate, 1980</xref>). For example, when making perceptual or motor decisions, people frequently trade accuracy for speed, even when time constraints are not tight (<xref ref-type="bibr" rid="bib32">Heitz, 2014</xref>; <xref ref-type="bibr" rid="bib61">Palmer et al., 2005</xref>). Related neural and behavioral data are best explained by ‘accumulation-to-bound’ process models, in which a decision is emitted when the accumulated perceptual evidence reaches a bound (<xref ref-type="bibr" rid="bib25">Gold and Shadlen, 2007</xref>; <xref ref-type="bibr" rid="bib58">O'Connell et al., 2012</xref>; <xref ref-type="bibr" rid="bib69">Ratcliff and McKoon, 2008</xref>; <xref ref-type="bibr" rid="bib68">Ratcliff et al., 2016</xref>). Further computational work demonstrated that if the bound is properly set, these models actually implement an optimal solution to speed-accuracy tradeoff problems (<xref ref-type="bibr" rid="bib16">Ditterich, 2006</xref>; <xref ref-type="bibr" rid="bib17">Drugowitsch et al., 2012</xref>). From a theoretical standpoint, this implies that accumulation-to-bound policies can be viewed as an evolutionary adaptation, in response to selective pressure that favors efficiency (<xref ref-type="bibr" rid="bib63">Pirrone et al., 2014</xref>).</p><p>This line of reasoning, however, is not trivial to generalize to value-based decision-making, for which objective accuracy remains an elusive notion (<xref ref-type="bibr" rid="bib20">Dutilh and Rieskamp, 2016</xref>; <xref ref-type="bibr" rid="bib67">Rangel et al., 2008</xref>). This is because, in contrast to evidence-based (e.g., perceptual) decisions, there are no right or wrong value-based decisions. Nevertheless, people still make choices that deviate from subjective reports of value, with a rate that decreases with value contrast. From the perspective of accumulation-to-bound models, these preference reversals count as errors and arise from the unreliable signaling of value to decision systems in the brain (<xref ref-type="bibr" rid="bib49">Lim et al., 2013</xref>). That value-based variants of accumulation-to-bound models are able to capture the neural and behavioral effects of, e.g., overt attention (<xref ref-type="bibr" rid="bib40">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="bib48">Lim et al., 2011</xref>), external time pressure (<xref ref-type="bibr" rid="bib56">Milosavljevic et al., 2010</xref>), confidence (<xref ref-type="bibr" rid="bib14">De Martino et al., 2013</xref>), or default preferences (<xref ref-type="bibr" rid="bib52">Lopez-Persem et al., 2016</xref>) lends empirical support to this type of interpretation. Further credit also comes from theoretical studies showing that these process models, under some simplifying assumptions, optimally solve the problem of efficient value comparison (<xref ref-type="bibr" rid="bib80">Tajima et al., 2016</xref>; <xref ref-type="bibr" rid="bib81">Tajima et al., 2019</xref>). However, they do not solve the issue of adjusting the amount of effort to invest in reassessing an uncertain prior preference with yet-unprocessed value-relevant information. Here, we propose an alternative computational model of value-based decision-making that suggests that mental effort is optimally traded against choice confidence, given how value representations are modified while pondering decisions (<xref ref-type="bibr" rid="bib75">Slovic, 1995</xref>; <xref ref-type="bibr" rid="bib83">Tversky and Thaler, 1990</xref>; <xref ref-type="bibr" rid="bib87">Warren et al., 2011</xref>).</p><p>We start from the premise that the brain generates representations of options' value in a quick and automatic manner, even before attention is engaged for comparing option values (<xref ref-type="bibr" rid="bib43">Lebreton et al., 2009</xref>). The brain also encodes the certainty of such value estimates (<xref ref-type="bibr" rid="bib44">Lebreton et al., 2015</xref>), from which a priori feelings of choice difficulty and confidence could, in principle, be derived. Importantly, people are reluctant to make a choice that they are not confident about (<xref ref-type="bibr" rid="bib14">De Martino et al., 2013</xref>). Thus, when faced with a difficult decision, people should reassess option values until they reach a satisfactory level of confidence about their preference. This effortful mental deliberation would engage neurocognitive resources, such as attention and memory, in order to process value-relevant information. In line with recent proposals regarding the strategic deployment of cognitive control (<xref ref-type="bibr" rid="bib57">Musslick et al., 2015</xref>; <xref ref-type="bibr" rid="bib73">Shenhav et al., 2013</xref>), we assume that the amount of allocated resources optimizes a tradeoff between expected effort cost and confidence gain. The main issue here is that the impact of yet-unprocessed information on value representations is a priori unknown. Critically, we show how the system can anticipate the expected benefit of allocating resources before having processed value-relevant information. The ensuing <italic>metacognitive control of decisions</italic> or <italic>MCD</italic> thus adjusts mental effort on a decision-by-decision basis, according to prior decision difficulty and importance (<xref ref-type="fig" rid="fig1">Figure 1</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>The metacognitive control of decisions.</title><p>First, automatic processes provide a ‘pre-effort’ belief about option values. This belief is probabilistic, in the sense that it captures an uncertain prediction regarding the to-be-experienced value of a given option. This pre-effort belief serves to identify the anticipated impact of investing costly cognitive resources (i.e., effort) in the decision. In particular, investing effort is expected to increase decision confidence beyond its pre-effort level. But how much effort it should be worth investing depends upon the balance between expected confidence gain and effort costs. The system then allocates resources into value-relevant information processing up until the optimal effort investment is reached. At this point, a decision is triggered based on the current post-effort belief about option values (in this example, the system has changed its mind, i.e., its preference has reversed). Note: we refer to the ensuing increase in the value difference between chosen and unchosen items as the ‘spreading of alternatives’ (cf. Materials and methods section).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-fig1-v2.tif"/></fig><p>As we will see, the MCD model makes clear quantitative predictions about several key decision variables (cf. Model section below). We test these predictions by asking participants to report their judgments about each item's subjective value and their subjective certainty about their value judgments, both before and after choosing between pairs of the items. Note that we also measure choice confidence, response time, and subjective effort for each decision.</p><p>The objective of this work is to show how most non-trivial properties of value-based decision-making can be explained with a minimal (and mutually consistent) set of assumptions. The MCD model predicts response time, subjective effort, choice confidence, probability of changing one's mind, as well as choice-induced preference change and certainty gain, out of two properties of pre-choice value representations, namely value ratings and value certainty ratings. Relevant details regarding the model derivations, as well as the decision-making paradigm we designed to evaluate those predictions, can be found in the Model and Methods sections below. In the subsequent section, we present our main dual computational/behavioral results. Finally, we discuss our results in light of the existing literature on value-based decision-making.</p><sec id="s1-1"><title>The MCD model</title><p>In what follows, we derive a computational model of the metacognitive control of decisions or MCD. In brief, we assume that the amount of cognitive resources that is deployed during a decision is controlled by an effort-confidence tradeoff. Critically, this tradeoff relies on a prospective anticipation of how these resources will perturb the internal representations of subjective values. As we will see, the MCD model eventually predicts how cognitive effort expenditure depends upon prior estimates of decision difficulty, and what impact this will have on post-choice value representations.</p></sec><sec id="s1-2"><title>Deriving the expected value of decision control</title><p>Let <inline-formula><mml:math id="inf1"><mml:mi>z</mml:mi></mml:math></inline-formula> be the amount of cognitive (e.g., executive, mnemonic, or attentional) resources that serve to process value-relevant information. Allocating these resources will be associated with both a benefit <inline-formula><mml:math id="inf2"><mml:mrow><mml:mi>B</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and a cost <inline-formula><mml:math id="inf3"><mml:mrow><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. As we will see, both are increasing functions of <inline-formula><mml:math id="inf4"><mml:mi>z</mml:mi></mml:math></inline-formula>: <inline-formula><mml:math id="inf5"><mml:mrow><mml:mi>B</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> derives from the refinement of internal representations of subjective values of alternative options or actions that compose the choice set, and <inline-formula><mml:math id="inf6"><mml:mrow><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> quantifies how aversive engaging cognitive resources are (mental effort). In line with the framework of expected value of control or EVC (<xref ref-type="bibr" rid="bib57">Musslick et al., 2015</xref>; <xref ref-type="bibr" rid="bib73">Shenhav et al., 2013</xref>), we assume that the brain chooses to allocate the amount of resources <inline-formula><mml:math id="inf7"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> that optimizes the following cost–benefit trade-off:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mi>z</mml:mi></mml:munder><mml:mtext> </mml:mtext><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>B</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where the expectation accounts for predictable stochastic influences that ensue from allocating resources (this will be clarified below). Note that the benefit term <inline-formula><mml:math id="inf8"><mml:mrow><mml:mi>B</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the (weighted) choice confidence <inline-formula><mml:math id="inf9"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mi>B</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>R</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where the weight <inline-formula><mml:math id="inf10"><mml:mi>R</mml:mi></mml:math></inline-formula> is analogous to a reward and quantifies the importance of making a confident decision (see below). As we will see, <inline-formula><mml:math id="inf11"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> plays a pivotal role in the model, in that it captures the efficacy of allocating resources for processing value-relevant information. So, how do we define choice confidence?</p><p>We assume that decision makers may be unsure about how much they like/want the alternative options that compose the choice set. In other words, the internal representations of values <inline-formula><mml:math id="inf12"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> of alternative options are probabilistic. Such a probabilistic representation of value can be understood in terms of, for example, an uncertain prediction regarding the to-be-experienced value of a given option. Without loss of generality, the probabilistic representation of option value takes the form of Gaussian probability density functions, as follows:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf13"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf14"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are the mode and the variance of the probabilistic value representation, respectively (and <inline-formula><mml:math id="inf15"><mml:mi>i</mml:mi></mml:math></inline-formula> indexes alternative options in the choice set).</p><p>This allows us to define choice confidence <inline-formula><mml:math id="inf16"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mi>c</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> as the probability that the (predicted) experienced value of the (to be) chosen item is higher than that of the (to be) unchosen item:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd columnalign="left"><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">#</mml:mi><mml:mn>1</mml:mn><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">#</mml:mi><mml:mn>2</mml:mn><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mspace width="thinmathspace"/></mml:mrow><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mspace width="thinmathspace"/></mml:mrow><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mo>≈</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi>π</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:msqrt><mml:mn>3</mml:mn><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:msqrt></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf17"><mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the standard sigmoid mapping. Here the second line derives from assuming that the choice follows the sign of the preference <inline-formula><mml:math id="inf18"><mml:mrow><mml:mi>Δ</mml:mi><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, and the last line derives from a moment-matching approximation to the Gaussian cumulative density function (<xref ref-type="bibr" rid="bib11">Daunizeau, 2017a</xref>).</p><p>As stated in the Introduction section, we assume that the brain valuation system automatically generates uncertain estimates of options' value (<xref ref-type="bibr" rid="bib43">Lebreton et al., 2009</xref>; <xref ref-type="bibr" rid="bib44">Lebreton et al., 2015</xref>), before cognitive effort is invested in decision-making. In what follows, <inline-formula><mml:math id="inf19"><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf20"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> are the mode and variance of the ensuing prior value representations (we treat them as inputs to the MCD model). We also assume that these prior representations neglect existing value-relevant information that would require cognitive effort to be retrieved and processed (<xref ref-type="bibr" rid="bib52">Lopez-Persem et al., 2016</xref>).</p><p>Now, how does the system anticipate the benefit of allocating resources to the decision process? Recall that the purpose of allocating resources is to process (yet unavailable) value-relevant information. The critical issue is thus to predict how both the uncertainty <inline-formula><mml:math id="inf21"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and the modes <inline-formula><mml:math id="inf22"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> of value representations will eventually change, before having actually allocated the resources (i.e., without having processed the information). In brief, allocating resources essentially has two impacts: (i) it decreases the uncertainty <inline-formula><mml:math id="inf23"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, and (ii) it perturbs the modes <inline-formula><mml:math id="inf24"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> in a stochastic manner.</p><p>The former impact derives from assuming that the amount of information that will be processed increases with the amount of allocated resources. Here, this implies that the variance of a given probabilistic value representation decreases in proportion to the amount of allocated effort, that is:<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>≜</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf25"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> is the prior variance of the representation (before any effort has been allocated), and <inline-formula><mml:math id="inf26"><mml:mi>β</mml:mi></mml:math></inline-formula> controls the efficacy with which resources increase the precision of the value representation. Formally speaking, <xref ref-type="disp-formula" rid="equ5">Equation 5</xref> has the form of a Bayesian update of the belief's precision in a Gaussian-likelihood model, where the precision of the likelihood term is <inline-formula><mml:math id="inf27"><mml:mrow><mml:mi>β</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:math></inline-formula>. More precisely, <inline-formula><mml:math id="inf28"><mml:mi>β</mml:mi></mml:math></inline-formula> is the precision increase that follows from allocating a unitary amount of resources <inline-formula><mml:math id="inf29"><mml:mi>z</mml:mi></mml:math></inline-formula>. In what follows, we will refer to <inline-formula><mml:math id="inf30"><mml:mi>β</mml:mi></mml:math></inline-formula> as the ‘<italic>type #1 effort efficacy</italic>’.</p><p>The latter impact follows from acknowledging the fact that the system cannot know how processing more value-relevant information will affect its preference before having allocated the corresponding resources. Let <inline-formula><mml:math id="inf31"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> be the change in the position of the mode of the <italic>i</italic>th value representation, having allocated an amount <inline-formula><mml:math id="inf32"><mml:mi>z</mml:mi></mml:math></inline-formula> of resources. The direction of the mode's perturbation <inline-formula><mml:math id="inf33"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> cannot be predicted because it is tied to the information that would be processed. However, a tenable assumption is to consider that the magnitude of the perturbation increases with the amount of information that will be processed. This reduces to stating that the variance of <inline-formula><mml:math id="inf34"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> increases in proportion to <inline-formula><mml:math id="inf35"><mml:mi>z</mml:mi></mml:math></inline-formula>, that is:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf36"><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mi>i</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> is the mode of the value representation before any effort has been allocated, and <inline-formula><mml:math id="inf37"><mml:mi>γ</mml:mi></mml:math></inline-formula> controls the relationship between the amount of allocated resources and the variance of the perturbation term <inline-formula><mml:math id="inf38"><mml:mi>δ</mml:mi></mml:math></inline-formula>. The higher the parameter <inline-formula><mml:math id="inf39"><mml:mi>γ</mml:mi></mml:math></inline-formula>, the greater the expected perturbation of the mode for a given amount of allocated resources. In what follows, we will refer to <inline-formula><mml:math id="inf40"><mml:mi>γ</mml:mi></mml:math></inline-formula> as the ‘<italic>type #2 effort efficacy</italic>’. Note that <xref ref-type="disp-formula" rid="equ6">Equation 6</xref> treats the impact of future information processing as a non-specific random perturbation on the mode of the prior value representation. Our justification for this assumption is twofold: (i) it is simple, and (ii) and it captures the idea that the MCD controller does not know how the allocated resources will be used (here, by the value-based decision system downstream). We will see that, in spite of this, the MCD controller can still make quantitative predictions regarding the expected benefit of allocating resources.</p><p>Taken together, Equations 5 and 6 imply that predicting the net effect of allocating resources onto choice confidence is not trivial. On one hand, allocating effort will increase the precision of value representations (cf. <xref ref-type="disp-formula" rid="equ5">Equation 5</xref>), which mechanically increases choice confidence, all other things being equal. On the other hand, allocating effort can either increase or decrease the absolute difference <inline-formula><mml:math id="inf41"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> between the modes. This, in fact, depends upon the sign of the perturbation terms <inline-formula><mml:math id="inf42"><mml:mi>δ</mml:mi></mml:math></inline-formula>, which are not known in advance. Having said this, it is possible to derive the <italic>expected</italic> absolute difference between the modes that would follow from allocating an amount <inline-formula><mml:math id="inf43"><mml:mi>z</mml:mi></mml:math></inline-formula> of resources:<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow> <mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:msqrt><mml:mrow><mml:mfrac><mml:mrow><mml:mi>γ</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mi>π</mml:mi></mml:mfrac></mml:mrow></mml:msqrt><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>γ</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>π</mml:mi><mml:mtext> </mml:mtext><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mn>6</mml:mn><mml:mi>γ</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where we have used the expression for the first-order moment of the so-called 'folded normal distribution', and the second term in the right-hand side of <xref ref-type="disp-formula" rid="equ7">Equation 7</xref> derives from the same moment-matching approximation to the Gaussian cumulative density function as above. The expected absolute means' difference <inline-formula><mml:math id="inf44"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> depends upon both the absolute prior mean difference <inline-formula><mml:math id="inf45"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and the amount of allocated resources <inline-formula><mml:math id="inf46"><mml:mi>z</mml:mi></mml:math></inline-formula>. This is depicted in <xref ref-type="fig" rid="fig2">Figure 2</xref>.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>The expected impact of allocated resources onto value representations.</title><p>Left panel: the expected absolute mean difference <inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> (y-axis) is plotted as a function of the absolute prior mean difference <inline-formula><mml:math id="inf48"><mml:mfenced close="|" open="|" separators="|"><mml:mrow><mml:mo>∆</mml:mo><mml:msup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></inline-formula> (x-axis) for different amounts <inline-formula><mml:math id="inf49"><mml:mi>z</mml:mi></mml:math></inline-formula> of allocated resources (color code), having set type #2 effort efficacy to unity (i.e. <inline-formula><mml:math id="inf50"><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>). Right panel: Variance <inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> of the absolute mean difference; same format.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-fig2-v2.tif"/></fig><p>One can see that <inline-formula><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is always greater than 0 and increases with <inline-formula><mml:math id="inf53"><mml:mi>z</mml:mi></mml:math></inline-formula> (and if <inline-formula><mml:math id="inf54"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, then <inline-formula><mml:math id="inf55"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow> <mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>). In other words, allocating resources is expected to increase the value difference, despite the fact that the impact of the perturbation term can go either way. In addition, the expected gain in value difference afforded by allocating resources decreases with the absolute prior means' difference.</p><p>Similarly, the variance <inline-formula><mml:math id="inf56"><mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of the absolute means' difference is derived from the expression of the second-order moment of the corresponding folded normal distribution:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow> <mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>γ</mml:mi><mml:mi>z</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>−</mml:mo><mml:mi>E</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></disp-formula></p><p>One can see in <xref ref-type="fig" rid="fig2">Figure 2</xref> that <inline-formula><mml:math id="inf57"><mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> increases with the amount <inline-formula><mml:math id="inf58"><mml:mi>z</mml:mi></mml:math></inline-formula> of allocated resources (but if <inline-formula><mml:math id="inf59"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, then <inline-formula><mml:math id="inf60"><mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow> <mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>).</p><p>Knowing the moments of the distribution of <inline-formula><mml:math id="inf61"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> now enables us to derive the expected confidence level <inline-formula><mml:math id="inf62"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> that would result from allocating the amount of resource <inline-formula><mml:math id="inf63"><mml:mi>z</mml:mi></mml:math></inline-formula>:<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>≜</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi>π</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:msqrt><mml:mn>6</mml:mn><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msqrt></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>≈</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi>π</mml:mi><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:msqrt><mml:mn>6</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>V</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msqrt></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where we have assumed, for the sake of conciseness, that both prior value representations are similarly uncertain (i.e., <inline-formula><mml:math id="inf64"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mn>1</mml:mn><mml:mn>0</mml:mn></mml:msubsup><mml:mo>≈</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn><mml:mn>0</mml:mn></mml:msubsup><mml:mo>≜</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>). It turns out that the expected choice confidence <inline-formula><mml:math id="inf65"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> always increase with <inline-formula><mml:math id="inf66"><mml:mi>z</mml:mi></mml:math></inline-formula>, irrespective of the efficacy parameters, as long as <inline-formula><mml:math id="inf67"><mml:mrow><mml:mi>β</mml:mi><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf68"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. These, however, control the magnitude of the confidence gain that can be expected from allocating an amount <inline-formula><mml:math id="inf69"><mml:mi>z</mml:mi></mml:math></inline-formula> of resources. <xref ref-type="disp-formula" rid="equ9">Equation 9</xref> is important, because it quantifies the expected benefit of resource allocation, before having processed the ensuing value-relevant information. More details regarding the accuracy of <xref ref-type="disp-formula" rid="equ9">Equation 9</xref> can be found in section 1 of the Appendix. In addition, section 2 of the Appendix summarizes the dependence of MCD-optimal choice confidence on <inline-formula><mml:math id="inf70"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf71"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>.</p><p>To complete the cost–benefit model, we simply assume that the cost of allocating resources to the decision process linearly scales with the amount of resources, that is:<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf72"><mml:mi>α</mml:mi></mml:math></inline-formula> determines the effort cost of allocating a unitary amount of resources <inline-formula><mml:math id="inf73"><mml:mi>z</mml:mi></mml:math></inline-formula>. In what follows, we will refer to <inline-formula><mml:math id="inf74"><mml:mi>α</mml:mi></mml:math></inline-formula> as the ‘effort unitary cost’. We note that weak nonlinearities in the cost function (e.g., quadratic terms) would not qualitatively change the model predictions.</p><p>In brief, the MCD-optimal resource allocation <inline-formula><mml:math id="inf75"><mml:mrow><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>≜</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is simply given by:<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mspace width="1em"/><mml:mi>z</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>which does not have any closed-form analytic solution. Nevertheless, it can easily be identified numerically, having replaced <xref ref-type="disp-formula" rid="equ7 equ8 equ9">Equations 7–9</xref> into <xref ref-type="disp-formula" rid="equ11">Equation 11</xref>. We refer the readers interested in the impact of model parameters <inline-formula><mml:math id="inf76"><mml:mrow><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:mi>α</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> on the MCD-optimal control to section 2 of the Appendix.</p><p>At this point, we do not specify how <xref ref-type="disp-formula" rid="equ11">Equation 11</xref> is solved by neural networks in the brain. Many alternatives are possible, from gradient ascent (<xref ref-type="bibr" rid="bib72">Seung, 2003</xref>) to winner-take-all competition of candidate solutions (<xref ref-type="bibr" rid="bib54">Mao and Massaquoi, 2007</xref>). We will also comment on the specific issue of prospective (offline) versus reactive (online) MCD processes in the Discussion section.</p><p><italic>Note</italic>: implicit in the above model derivation is the assumption that the allocation of resources is similar for both alternative options in the choice set (i.e. <inline-formula><mml:math id="inf77"><mml:mrow><mml:msubsup><mml:mi>z</mml:mi><mml:mn>1</mml:mn><mml:mrow/></mml:msubsup><mml:mo>≈</mml:mo><mml:msubsup><mml:mi>z</mml:mi><mml:mn>2</mml:mn><mml:mrow/></mml:msubsup><mml:mo>≜</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:math></inline-formula>). This simplifying assumption is justified by eye-tracking data (cf. section 8 of the Appendix).</p></sec><sec id="s1-3"><title>Corollary predictions of the MCD model</title><p>In the previous section, we derived the MCD-optimal resource allocation <inline-formula><mml:math id="inf78"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula>, which effectively best balances the expected choice confidence with the expected effort costs, given the predictable impact of stochastic perturbations that arise from processing value-relevant information. This quantitative prediction is effectively shown in Figures 5 and 6 of the Results section below, as a function of (empirical proxies for) the prior absolute difference between modes <inline-formula><mml:math id="inf79"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and the prior certainty <inline-formula><mml:math id="inf80"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> of value representations. But, this resource allocation mechanism has a few interesting corollary implications.</p><p>To begin with, note that knowing <inline-formula><mml:math id="inf81"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> enables us to predict what confidence level the system should eventually reach. In fact, one can define the MCD-optimal confidence level as the expected confidence evaluated at the MCD-optimal amount of allocated resources, that is, <inline-formula><mml:math id="inf82"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. This is important, because it implies that the model can predict both the effort the system will invest and its associated confidence, on a decision-by-decision basis. The impact of the efficacy parameters on this quantitative prediction is detailed in section 2 of the Appendix.</p><p>Additionally, <inline-formula><mml:math id="inf83"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> determines the expected improvement in the certainty of value representations (hereafter: the ‘certainty gain’), which trivially relates to type #2 efficacy, that is: <inline-formula><mml:math id="inf84"><mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mi>β</mml:mi><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>. This also means that, under the MCD model, no choice-induced value certainty gain can be expected when <inline-formula><mml:math id="inf85"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>.</p><p>Similarly, one can predict the MCD-optimal probability of changing one's mind. Recall that the probability <inline-formula><mml:math id="inf86"><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of changing one's mind depends on the amount of allocated resources <inline-formula><mml:math id="inf87"><mml:mi>z</mml:mi></mml:math></inline-formula>, that is:<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>≜</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≠</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext>if</mml:mtext><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext>if</mml:mtext><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>≈</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>π</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:msqrt><mml:mn>6</mml:mn><mml:mi>γ</mml:mi><mml:mi>z</mml:mi></mml:msqrt></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>One can see that the MCD-optimal probability of changing one's mind <inline-formula><mml:math id="inf88"><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a simple monotonic function of the allocated effort <inline-formula><mml:math id="inf89"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula>. Importantly, <inline-formula><mml:math id="inf90"><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> when <inline-formula><mml:math id="inf91"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. This implies that MCD agents do not change their minds when effort cannot change the relative position of the modes of the options’ value representations (irrespective of type #1 effort efficacy). In retrospect, this is critical, because there should be no incentive to invest resources in deliberation if it would not be possible to change one’s pre-deliberation preference.</p><p>Lastly, we can predict the magnitude of choice-induced preference change, that is, how value representations are supposed to spread apart during the decision. Such an effect is typically measured in terms of the so-called ‘spreading of alternatives’ or SoA, which is defined as follows:<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>S</mml:mi><mml:mi>O</mml:mi><mml:mi>A</mml:mi></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>−</mml:mo><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mtext>if</mml:mtext><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext>if</mml:mtext><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext>if</mml:mtext><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mtext>if</mml:mtext><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf92"><mml:mrow><mml:mi>Δ</mml:mi><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mi>γ</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the cumulative perturbation term of the modes' difference. Taking the expectation of the right-hand term of <xref ref-type="disp-formula" rid="equ13">Equation 13</xref> under the distribution of <inline-formula><mml:math id="inf93"><mml:mrow><mml:mi>Δ</mml:mi><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and evaluating it at <inline-formula><mml:math id="inf94"><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> now yields the MCD-optimal spreading of alternatives <inline-formula><mml:math id="inf95"><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>S</mml:mi><mml:mi>O</mml:mi><mml:mi>A</mml:mi></mml:mrow><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mrow><mml:mover><mml:mrow><mml:mi>S</mml:mi><mml:mi>O</mml:mi><mml:mi>A</mml:mi></mml:mrow><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mi>O</mml:mi><mml:mi>A</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:msqrt><mml:mfrac><mml:mrow><mml:mi>γ</mml:mi><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>π</mml:mi></mml:mfrac></mml:msqrt><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>γ</mml:mi><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where the last line derives from the expression of the first-order moment of the truncated Gaussian distribution. Note that the expected preference change also increases monotonically with the allocated effort <inline-formula><mml:math id="inf96"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula>. Here again, under the MCD model, no preference change can be expected when <inline-formula><mml:math id="inf97"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>.</p><p>We note that all of these corollary predictions essentially capture choice-induced modifications of value representations. This is why we will refer to choice confidence, value certainty gain, change of mind, and spreading of alternatives as ‘decision-related’ variables.</p></sec><sec id="s1-4"><title>Correspondence between model variables and empirical measures</title><p>In summary, the MCD model predicts cognitive effort (or, more properly, the amount of allocated resources) and decision-related variables, given the prior absolute difference between modes <inline-formula><mml:math id="inf98"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and the prior certainty <inline-formula><mml:math id="inf99"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> of value representations. In other words, the inputs to the MCD model are the prior moments of value representations, whose trial-by-trial variations determine variations in model predictions. Here, we simply assume that pre-choice value and value certainty ratings provide us with an approximation of these prior moments. More precisely, we use ΔVR<sup>0</sup> and VCR<sup>0</sup> (cf. section 3.3 below) as empirical proxies for <inline-formula><mml:math id="inf100"><mml:mrow><mml:mi>Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf101"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, respectively. Accordingly, we consider post-choice value and value certainty ratings as empirical proxies for the posterior mean <inline-formula><mml:math id="inf102"><mml:mrow><mml:mi>μ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and precision <inline-formula><mml:math id="inf103"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> of value representations, at the time when the decision was triggered (i.e., after having invested the effort <inline-formula><mml:math id="inf104"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula>). Similarly, we match expected choice confidence <inline-formula><mml:math id="inf105"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (i.e., after having invested the effort <inline-formula><mml:math id="inf106"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula>) with empirical choice confidence.</p><p>Note that the MCD model does not specify <italic>what</italic> the allocated resources are. In principle, both mnesic and attentional resources may be engaged when processing value-relevant information. Nevertheless, what really matters is assessing the magnitude <inline-formula><mml:math id="inf107"><mml:mi>z</mml:mi></mml:math></inline-formula> of decision-related effort. We think of <inline-formula><mml:math id="inf108"><mml:mi>z</mml:mi></mml:math></inline-formula> as the cumulative engagement of neurocognitive resources, which varies both in terms of duration and intensity. Empirically, we relate <inline-formula><mml:math id="inf109"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> to two different ‘effort-related’ empirical measures, namely subjective feeling of effort and response time. The former relies on the subjective cost incurred when deploying neurocognitive resources, which would be signaled by experiencing mental effort. The latter makes sense if one thinks of response time in terms of effort duration. Although it is a more objective measurement than subjective rating of effort, response time only approximates <inline-formula><mml:math id="inf110"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> if effort intensity shows relatively small variations. We will comment on this in the Discussion section.</p><p>Finally, the MCD model is also agnostic about the definition of ‘decision importance’, that is, the weight <inline-formula><mml:math id="inf111"><mml:mi>R</mml:mi></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>. In this work, we simply investigate the effect of decision importance by comparing subjective effort and response time in ‘neutral’ versus ‘consequential’ decisions (cf. section 'Task conditions' below). We will also comment on this in the Discussion section.</p></sec></sec><sec id="s2" sec-type="materials|methods"><title>Materials and methods</title><sec id="s2-1"><title>Participants</title><p>Participants for our study were recruited from the RISC (<italic>Relais d’Information sur les Sciences de la Cognition</italic>) subject pool through the ICM (<italic>Institut du Cerveau et de la Moelle – Paris Brain Institute</italic>). All participants were native French speakers, with no reported history of psychiatric or neurological illness. A total of 41 people (28 female; age: mean = 28, SD = 5, min = 20, max = 40) participated in this study. The experiment lasted approximately 2 hr, and participants were paid a flat rate of 20€ as compensation for their time, plus a bonus, which was given to participants to compensate for potential financial losses in the ‘penalized’ trials (see below). More precisely, in ‘penalized’ trials, participants lost 0.20€ (out of a 5€ bonus) for each second that they took to make their choice. This resulted in an average 4€ bonus (across participants). One group of 11 participants was excluded from the cross-condition analysis only (see below) due to technical issues.</p></sec><sec id="s2-2"><title>Materials</title><p>Written instructions provided detailed information about the sequence of tasks within the experiment, the mechanics of how participants would perform the tasks, and images illustrating what a typical screen within each task section would look like. The experiment was developed using Matlab and PsychToolbox, and was conducted entirely in French. The stimuli for this experiment were 148 digital images, each representing a distinct food item (50 fruits, 50 vegetables, and 48 various snack items including nuts, meats, and cheeses). Food items were selected such that most items would be well known to most participants.</p><p>Eye gaze position and pupil size were continuously recorded throughout the duration of the experiment using The Eye Tribe eye-tracking devices. Participants’ head positions were fixed using stationary chinrests. In case of incidental movements, we corrected the pupil size data for distance to screen, separately for each eye.</p></sec><sec id="s2-3"><title>Task design</title><p>Prior to commencing the testing session of the experiment, participants underwent a brief training session. The training tasks were identical to the experimental tasks, although different stimuli were used (beverages). The experiment itself began with an initial section where all individual items were displayed in a random sequence for 1.5 s each, in order to familiarize the participants with the set of options they would later be considering and form an impression of the range of subjective value for the set. The main experiment was divided into three sections, following the classic Free-Choice Paradigm protocol (e.g., <xref ref-type="bibr" rid="bib34">Izuma and Murayama, 2013</xref>): pre-choice item ratings, choice, and post-choice item ratings. There was no time limit for the overall experiment, nor for the different sections, nor for the individual trials. The item rating and choice sections are described below (see <xref ref-type="fig" rid="fig3">Figure 3</xref>).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Experimental design.</title><p>Left: pre-choice item rating session: participants are asked to rate how much they like each food item and how certain they are about it (value certainty rating). Center: choice session: participants are asked to choose between two food items, to rate how confident they are about their choice, and to report the feeling of effort associated with the decision. Right: post-choice item rating session (same as pre-choice item rating session).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-fig3-v2.tif"/></fig><sec id="s2-3-1"><title>Item rating (same for pre-choice and post-choice sessions)</title><p>Participants were asked to rate the entire set of items in terms of how much they liked each item. The items were presented one at a time in a random sequence (pseudo-randomized across participants). At the onset of each trial, a fixation cross appeared at the center of the screen for 750 ms. Next, a solitary image of a food item appeared at the center of the screen. Participants had to respond to the question, ‘How much do you like this item?’ using a horizontal slider scale (from ‘I hate it!’ to ‘I love it!”) to indicate their value rating for the item. The middle of the scale was the point of neutrality (‘I don’t care about it.”). Hereafter, we refer to the reported value as the ‘pre-choice value rating’. Participants then had to respond to the question, ‘What degree of certainty do you have?’ (about the item’s value) by expanding a solid bar symmetrically around the cursor of the value slider scale to indicate the range of possible value ratings that would be compatible with their subjective feeling. We measured participants' certainty about value rating in terms of the percentage of the value scale that is not occupied by the reported range of compatible value ratings. We refer to this as the ‘pre-choice value certainty rating’. At that time, the next trial began.</p></sec><sec id="s2-3-2"><title>Note</title><p>In the Results section below, ΔVR<sup>0</sup> is the difference between pre-choice value ratings of items composing a choice set. Similarly, VCR<sup>0</sup> is the average pre-choice value certainty ratings across items composing a choice set. Both value and value certainty rating scales range from 0 to 1 (but participants were unaware of the quantitative units of the scales).</p></sec><sec id="s2-3-3"><title>Choice</title><p>Participants were asked to choose between pairs of items in terms of which item they preferred. The entire set of items was presented one pair at a time in a random sequence. Each item appeared in only one pair. At the onset of each trial, a fixation cross appeared at the center of the screen for 750 ms. Next, two images of snack items appeared on the screen: one toward the left and one toward the right. Participants had to respond to the question, ‘Which do you prefer?’ using the left or right arrow key. We measured response time in terms of the delay between the stimulus onset and the response. Participants then had to respond to the question, ‘Are you sure about your choice?’ using a vertical slider scale (from ‘Not at all!’ to ‘Absolutely!'). We refer to this as the report of choice confidence. Finally, participants had to respond to the question, ‘To what extent did you think about this choice?’ using a horizontal slider scale (from ‘Not at all!’ to ‘Really a lot!”). We refer to this as the report of subjective effort. At that time, the next trial began.</p></sec></sec><sec id="s2-4"><title>Task conditions</title><p>We partitioned the task trials into three conditions, which were designed to test the following two predictions of the MCD model: all else equal, effort should increase with decision importance and decrease with related costs. We aimed to check the former prediction by asking participants to make some decisions where they knew that the choice would be real, that is, they would actually have to eat the chosen food item at the end of the experiment. We refer to these trials as ‘consequential’ decisions. To check the latter prediction, we imposed a financial penalty that increased with response time. More precisely, participants were instructed that they would lose 0.20€ (out of a 5€ bonus) for each second that they would take to make their choice. The choice section of the experiment was composed of 60 ‘neutral’ trials, 7 ‘consequential’ trials, and 7 ‘penalized’ trials, which were randomly intermixed. Instructions for both ‘consequential’ and ‘penalized’ decisions were repeated at each relevant trial, immediately prior to the presentation of the choice items.</p></sec><sec id="s2-5"><title>Probabilistic model fit</title><p>The MCD model predicts trial-by-trial variations in the probability of changing one’s mind, choice confidence, spreading of alternatives, certainty gain, response time, and subjective effort ratings (MCD outputs) from trial-by-trial variations in value rating difference ΔVR<sup>0</sup> and mean value certainty rating VCR<sup>0</sup> (MCD inputs). Together, three unknown parameters control the quantitative relationship between MCD inputs and outputs: the <italic>effort unitary cost</italic> <inline-formula><mml:math id="inf112"><mml:mi>α</mml:mi></mml:math></inline-formula>, <italic>type #1 effort efficacy</italic> <inline-formula><mml:math id="inf113"><mml:mi>β</mml:mi></mml:math></inline-formula>, and <italic>type #2 effort efficacy</italic> <inline-formula><mml:math id="inf114"><mml:mi>γ</mml:mi></mml:math></inline-formula>. However, additional parameters are required to capture variations induced by experimental conditions. Recall that we expect ‘consequential’ decisions to be more important than ‘neutral’ ones, and ‘penalized’ decisions effectively include an extraneous cost-of-time term. One can model the former condition effect by making <inline-formula><mml:math id="inf115"><mml:mi>R</mml:mi></mml:math></inline-formula> (cf. <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>) sensitive to whether the decision is consequential or not. We proxy the latter condition effect by making the effort unitary cost <inline-formula><mml:math id="inf116"><mml:mi>α</mml:mi></mml:math></inline-formula> a function of whether the decision is penalized (where effort induces both intrinsic and extrinsic costs) or not (intrinsic effort cost only). This means that condition effects require one additional parameter each.</p><p>In principle, all of these parameters may vary across people, thereby capturing idiosyncrasies in people’s (meta-)cognitive apparatus. However, in addition to estimating these five parameters, fitting the MCD model to each participant’s data also requires a rescaling of the model’s output variables. This is because there is no reason to expect the empirical measure of these variables to match their theoretical scale. We thus inserted two additional nuisance parameters per output MCD variable, which operate a linear rescaling (affine transformation, with a positive constraint on slope parameters). Importantly, these nuisance parameters cannot change the relationship between MCD inputs and outputs. In other terms, the MCD model really has only five degrees of freedom.</p><p>For each subject, we fit all MCD dependent variables concurrently with a single set of MCD parameters. Within-subject probabilistic parameter estimation was performed using the variational Laplace approach (<xref ref-type="bibr" rid="bib12">Daunizeau, 2017b</xref>; <xref ref-type="bibr" rid="bib23">Friston et al., 2007</xref>), which is made available from the VBA toolbox (<xref ref-type="bibr" rid="bib10">Daunizeau et al., 2014</xref>). We refer the reader interested in the mathematical details of within-subject MCD parameter estimation to the section 3 of the Appendix (this also includes a parameter recovery analysis). In what follows, we compare empirical data to MCD-fitted dependent variables (when binned according to ΔVR<sup>0</sup> and VCR<sup>0</sup>). We refer to the latter as ‘postdictions’, in the sense that they derive from a posterior predictive density that is conditional on the corresponding data.</p><p>We also fit the MCD model on reduced subsets of dependent variables (e.g., only ‘effort-related’ variables), and report proper out-of-sample predictions of data that were not used for parameter estimation (e.g., ‘decision-related’ variables). We note that this is a strong test of the model, since it does not rely on any train/test partition of the predicted variable (see next section below).</p></sec></sec><sec id="s3" sec-type="results"><title>Results</title><p>Here, we test the predictions of the MCD model. We note that basic descriptive statistics of our data, including measures of test–retest reliability and replications of previously reported effects on confidence in value-based choices (<xref ref-type="bibr" rid="bib14">De Martino et al., 2013</xref>), are appended in sections 5–7 of the Appendix.</p><sec id="s3-1"><title>Within-subject model fit accuracy and out-of-sample predictions</title><p>To capture idiosyncrasies in participants’ metacognitive control of decisions, the MCD model was fitted to subject-specific trial-by-trial data, where all MCD outputs (namely change of mind, choice confidence, spreading of alternatives, value certainty gain, response time, and subjective effort ratings) were considered together. In the next section, we present summary statistics at the group level, which validate the predictions that can be derived from the MCD model, when fitted to all dependent variables. But can we provide even stronger evidence that the MCD model is capable of predicting all dependent variables at once? In particular, can the model make out-of-sample predictions regarding effort-related variables (i.e., RT and subjective effort ratings) given decision-related variables (i.e., choice confidence, change of mind, spreading of alternatives, and certainty gain), and <italic>vice versa</italic>?</p><p>To address this question, we performed two partial model fits: (i) with decision-related variables only, and (ii) with effort-related variables only. In both cases, out-of-sample predictions for the remaining dependent variables were obtained directly from within-subject parameter estimates. For each subject, we then estimated the cross-trial correlation between each pair of observed and predicted variables. <xref ref-type="fig" rid="fig4">Figure 4</xref> reports the ensuing group-average correlations, for each dependent variable and each model fit. In this context, the predictions derived when fitting the full dataset only serve as a reference point for evaluating the accuracy of out-of-sample predictions. For completeness, we also show chance-level prediction accuracy (i.e. the 95% percentile of group average correlations between observed and predicted variables under the null).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Accuracy of model postdictions and out-of-sample predictions.</title><p>The mean within-subject (across-trial) correlation between observed and predicted/postdicted data (y-axis) is plotted for each variable (x-axis, from left to right: choice confidence, spreading of alternatives, change of mind, certainty gain, RT and subjective effort ratings), and each fitting procedure (gray: full data fit, blue: decision-related variables only, and red: effort-related variables only). Error bars depict standard error of the mean, and the horizontal dashed black line shows chance-level prediction accuracy.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-fig4-v2.tif"/></fig><p>In what follows, we refer to model predictions on dependent variables that were actually fitted by the model as ‘postdictions’ (full data fits: all dependent variables, partial model fits: variables included in the fit). As one would expect, the accuracy of postdictions is typically higher than that of out-of-sample predictions. Slightly more interesting, perhaps, is the fact that the accuracy of model predictions/postdictions depends upon which output variable is considered. For example, choice confidence is always better predicted/postdicted than spreading of alternatives. This is most likely because the latter data has lower reliability.</p><p>But the main result of this analysis is the fact that out-of-sample predictions of dependent variables perform systematically better than chance. In fact, all across-trial correlations between observed and predicted (out-of-sample) data were statistically significant at the group-level (all p&lt;10<sup>−3</sup>). In particular, this implies that the MCD model makes accurate out-of-sample predictions regarding effort-related variables given decision-related variables, and reciprocally.</p></sec><sec id="s3-2"><title>Predicting effort-related variables</title><p>In what follows, we inspect the three-way relationships between pre-choice value and value certainty ratings and each effort-related variable: namely, RT and subjective effort rating. The former can be thought of as a proxy for the duration of resource allocation, whereas the latter is a metacognitive readout of resource allocation cost. Unless stated otherwise, we will focus on both the absolute difference between pre-choice value ratings (hereafter: |ΔVR<sup>0</sup>|) and the mean pre-choice value certainty rating across paired choice items (hereafter: VCR<sup>0</sup>). Under the MCD model, increasing |ΔVR<sup>0</sup>| and/or VCR<sup>0</sup> will decrease the demand for effort, which should result in smaller expected RT and subjective effort rating. We will now summarize the empirical data and highlight the corresponding quantitative MCD model postdictions and out-of-sample predictions (here: predictions are derived from model fits on decision-related variables only, that is, all dependent variables except RT and subjective effort rating).</p><p>First, we checked how RT relates to pre-choice value and value certainty ratings. For each subject, we regressed (log-) RT data against |ΔVR<sup>0</sup>| and VCR<sup>0</sup>, and then performed a group-level random-effect analysis on regression weights. The results of this model-free analysis provide a qualitative summary of the impact of trial-by-trial variations in pre-choice value representations on RT. We also compare RT data with both MCD model postdictions (full data fit) and out-of-sample predictions. In addition to summarizing the results of the model-free analysis, <xref ref-type="fig" rid="fig5">Figure 5</xref> shows the empirical, predicted, and postdicted RT data, when median-split (within subjects) according to both |ΔVR<sup>0</sup>| and VCR<sup>0</sup>.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Three-way relationship between RT, value, and value certainty.</title><p>Left panel: Mean standardized regression weights for |ΔVR<sup>0</sup>| and VCR<sup>0</sup> on log-RT (<italic>cst</italic> is the constant term); error bars represent s.e.m. Right panel: Mean z-scored log-RT (y-axis) is shown as a function of |ΔVR<sup>0</sup>| (x-axis) and VCR<sup>0</sup> (color code: blue = 0–50% lower quantile, green = 50–100% upper quantile); solid lines indicate empirical data (error bars represent s.e.m.), star-dotted lines show out-of-sample predictions and diamond-dashed lines represent model postdictions.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-fig5-v2.tif"/></fig><p>One can see that RT data behave as expected under the MCD model, that is, RT decreases when |ΔVR<sup>0</sup>|and/or VCR<sup>0</sup> increases. The random effect analysis shows that both variables have a significant negative effect at the group level (|ΔVR<sup>0</sup>|: mean standardized regression weight = −0.16, s.e.m. = 0.02, p&lt;10<sup>−3</sup>; VCR<sup>0</sup>: mean standardized regression weight = −0.08, s.e.m. = 0.02, p&lt;10<sup>−3</sup>; one-sided t-tests). Moreover, MCD postdictions are remarkably accurate at capturing the effect of both |ΔVR<sup>0</sup>|and VCR<sup>0</sup> variables in a quantitative manner. Although MCD out-of-sample predictions are also very accurate, they tend to slightly underestimate the quantitative effect of |ΔVR<sup>0</sup>|. This is because this effect is typically less pronounced in decision-related variables than in effort-related variables (see below), which then yield MCD parameter estimates that eventually attenuate the impact of |ΔVR<sup>0</sup>| on effort.</p><p>Second, we checked how subjective effort ratings relate to pre-choice value and value certainty ratings. We performed the same analysis as above, the results of which are summarized in <xref ref-type="fig" rid="fig6">Figure 6</xref>.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Three-way relationship between subjective effort rating, value, and value certainty.</title><p>Same format as <xref ref-type="fig" rid="fig5">Figure 5</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-fig6-v2.tif"/></fig><p>Here as well, subjective effort rating data behave as expected under the MCD model, that is, subjective effort decreases when |ΔVR<sup>0</sup>| and/or VCR<sup>0</sup> increases. The random effect analysis shows that both variables have a significant negative effect at the group level (|ΔVR<sup>0</sup>|: mean standardized regression weight = −0.21, s.e.m. = 0.03, p&lt;10<sup>−3</sup>; VCR<sup>0</sup>: mean regression weight = −0.05, s.e.m. = 0.02, p=0.027; one-sided t-tests). One can see that MCD postdictions and out-of-sample predictions accurately capture the effect of both |ΔVR<sup>0</sup>|and VCR<sup>0</sup> variables. More quantitatively, we note that MCD postdictions slightly overestimate the effect VCR<sup>0</sup>, whereas out-of-sample predictions also tend to underestimate the effect of |ΔVR<sup>0</sup>|.</p><p>At this point, we note that the MCD model makes two additional predictions regarding effort-related variables, which relate to our task conditions. In brief, all else equal, effort should increase in ‘consequential’ trials, while it should decrease in ‘penalized’ trials. To test these predictions, we modified the model-free regression analysis of RT and subjective effort ratings by including two additional subject-level regressors, encoding consequential and penalized trials, respectively. <xref ref-type="fig" rid="fig7">Figure 7</xref> shows the ensuing augmented set of standardized regression weights for both RT and subjective effort ratings.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Impact of consequential and penalized conditions on effort-related variables.</title><p>Left panel: log-RT: mean standardized regression weights (same format as <xref ref-type="fig" rid="fig4">Figure 4</xref> – left panel, <italic>cons</italic> = ‘consequential’ condition, <italic>pena</italic> = ‘penalized’ condition). Right panel: subjective effort ratings: same format as left panel.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-fig7-v2.tif"/></fig><p>First, we note that accounting for task conditions does not modify the statistical significance of the impact of |ΔVR<sup>0</sup>| and VCR<sup>0</sup> on effort-related variables, except for the effect of VCR<sup>0</sup> on subjective effort ratings (p=0.09, one-sided t-test). Second, one can see that the impact of ‘consequential’ and ‘penalized’ conditions on effort-related variables globally conforms to MCD predictions. More precisely, both RT and subjective effort ratings were significantly higher for ‘consequential’ decisions than for ‘neutral’ decisions (log-RT: mean standardized regression weight = 0.07, s.e.m. = 0.03, p=0.036; effort ratings: mean standardized regression weight = 0.12, s.e.m. = 0.03, p&lt;10<sup>−3</sup>; one-sided t-tests). In addition, response times are significantly faster for ‘penalized’ than for ‘neutral’ decisions (mean standardized regression weight = −0.26, s.e.m. = 0.03, p&lt;10<sup>−3</sup>; one-sided t-test). However, the difference in subjective effort ratings between ‘neutral’ and ‘penalized’ decisions does not reach statistical significance (mean effort difference = 0.012, s.e.m. = 0.024, p=0.66; two-sided t-test). We will comment on this in the Discussion section.</p></sec><sec id="s3-3"><title>Predicting decision-related variables</title><p>Under the MCD model, ‘decision-related’ dependent variables (i.e., choice confidence, change of mind, spreading of alternatives, and value certainty gain) are determined by the amount of resources allocated to the decision. However, their relationship to features of prior value representation is not trivial (see section 2 of the Appendix for the specific case of choice confidence). For this reason, we will recapitulate the qualitative MCD prediction that can be made about each of them, prior to summarizing the empirical data and its corresponding postdictions and out-of-sample predictions. Note that here, the latter are obtained from a model fit on effort-related variables only.</p><p>First, we checked how choice confidence relates to |ΔVR<sup>0</sup>| and VCR<sup>0</sup>. Under the MCD model, choice confidence reflects the discriminability of the options’ value representations after optimal resource allocation. Recall that more resources are allocated to the decision when either |ΔVR<sup>0</sup>| or VCR<sup>0</sup> decreases. However, under moderate effort efficacies, this does not overcompensate decision difficulty, and thus choice confidence should decrease. As with effort-related variables, we regressed trial-by-trial confidence data against |ΔVR<sup>0</sup>| and VCR<sup>0</sup>, and then performed a group-level random-effect analysis on regression weights. The results of this analysis, as well as the comparison between empirical, predicted, and postdicted confidence data are shown in <xref ref-type="fig" rid="fig8">Figure 8</xref>.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Three-way relationship between choice confidence, value, and value certainty.</title><p>Same format as <xref ref-type="fig" rid="fig5">Figure 5</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-fig8-v2.tif"/></fig><p>The results of the group-level random effect analysis confirm our qualitative predictions. In brief, both |ΔVR<sup>0</sup>| (mean standardized regression weight = 0.25, s.e.m. = 0.02, p&lt;10<sup>−3</sup>; one-sided t-test) and VCR<sup>0</sup> (mean standardized regression weight = 0.16, s.e.m. = 0.03, p&lt;10<sup>−3</sup>; one-sided t-test) have a significant positive impact on choice confidence. Here again, MCD postdictions and out-of-sample predictions are remarkably accurate at capturing the effect of both |ΔVR<sup>0</sup>|and VCR<sup>0</sup> variables (though predictions slightly underestimate the effect of |ΔVR<sup>0</sup>|).</p><p>Second, we checked how change of mind relates to |ΔVR<sup>0</sup>| and VCR<sup>0</sup>. Note that we define a change of mind according to two criteria: (i) the choice is incongruent with the prior preference inferred from the pre-choice value ratings, and (ii) the choice is congruent with the posterior preference inferred from post-choice value ratings. The latter criterion distinguishes a change of mind from a mere ‘error’, which may arise from attentional and/or motor lapses. Under the MCD model, we expect no change of mind unless type #2 efficacy <inline-formula><mml:math id="inf117"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. In addition, the rate of change of mind should decrease when either |ΔVR<sup>0</sup>| or VCR<sup>0</sup> increases. This is because increasing |ΔVR<sup>0</sup>| and/or VCR<sup>0</sup> will decrease the demand for effort, which implies that the probability of reversing the prior preference will be smaller. <xref ref-type="fig" rid="fig9">Figure 9</xref> shows the corresponding model predictions/postdictions and summarizes the corresponding empirical data.</p><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>Three-way relationship between change of mind, value, and value certainty.</title><p>Same format as <xref ref-type="fig" rid="fig5">Figure 5</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-fig9-v2.tif"/></fig><p>Note that, on average, the rate of change of mind reaches about 14.5% (s.e.m. = 0.008, p&lt;10<sup>−3</sup>, one-sided t-test), which is significantly higher than the rate of ‘error’ (mean rate difference = 2.3%, s.e.m. = 0.01, p=0.032; two-sided t-test). The results of the group-level random effect analysis confirm our qualitative MCD predictions. In brief, both |ΔVR<sup>0</sup>| (mean standardized regression weight = −0.17, s.e.m. = 0.02, p&lt;10<sup>−3</sup>; one-sided t-test) and VCR<sup>0</sup> (mean standardized regression weight = −0.08, s.e.m. = 0.03, p&lt;10<sup>−3</sup>; one-sided t-test) have a significant negative impact on the rate of change of mind. Again, MCD postdictions and out-of-sample predictions are remarkably accurate at capturing the effect of both |ΔVR<sup>0</sup>|and VCR<sup>0</sup> variables (though predictions slightly underestimate the effect of |ΔVR<sup>0</sup>|).</p><p>Third, we checked how spreading of alternatives relates to |ΔVR<sup>0</sup>| and VCR<sup>0</sup>. Recall that spreading of alternatives measures the magnitude of choice-induced preference change. Under the MCD model, the reported value of alternative options cannot spread apart unless type #2 efficacy <inline-formula><mml:math id="inf118"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. In addition, and as with change of mind, spreading of alternatives should globally follow the optimal effort allocation, that is, it should decrease when |ΔVR<sup>0</sup>| and/or VCR<sup>0</sup> increase. <xref ref-type="fig" rid="fig10">Figure 10</xref> shows the corresponding model predictions/postdictions and summarizes the corresponding empirical data.</p><fig id="fig10" position="float"><label>Figure 10.</label><caption><title>Three-way relationship between spreading of alternatives, value, and value certainty.</title><p>Same format as <xref ref-type="fig" rid="fig5">Figure 5</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-fig10-v2.tif"/></fig><p>One can see that there is a significant positive spreading of alternatives (mean = 0.04 A.U., s.e.m. = 0.004, p&lt;10<sup>−3</sup>, one-sided t-test). This is reassuring, because it dismisses the possibility that <inline-formula><mml:math id="inf119"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> (which would mean that effort does not perturb the mode of value representations). In addition, the results of the group-level random effect analysis confirm that both |ΔVR<sup>0</sup>| (mean standardized regression weight = −0.09, s.e.m. = 0.03, p=0.001; one-sided t-test) and VCR<sup>0</sup> (mean standardized regression weight = −0.04, s.e.m. = 0.02, p=0.03; one-sided t-test) have a significant negative impact on spreading of alternatives. Note that this replicates previous findings on choice-induced preference change (<xref ref-type="bibr" rid="bib45">Lee and Coricelli, 2020</xref>; <xref ref-type="bibr" rid="bib46">Lee and Daunizeau, 2020</xref>). Finally, MCD postdictions and out-of-sample predictions accurately capture the effect of both |ΔVR<sup>0</sup>| and VCR<sup>0</sup> variables in a quantitative manner (though predictions slightly underestimate the effect of |ΔVR<sup>0</sup>|).</p><p>Fourth, we checked how |ΔVR<sup>0</sup>| and VCR<sup>0</sup> impact value certainty gain. Under the MCD model, the certainty of value representations cannot improve unless type #1 efficacy <inline-formula><mml:math id="inf120"><mml:mrow><mml:mi>β</mml:mi><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. In addition, value certainty gain should globally follow the optimal effort allocation, i.e., it should decrease when |ΔVR<sup>0</sup>| and/or VCR<sup>0</sup> increase. <xref ref-type="fig" rid="fig11">Figure 11</xref> shows the corresponding model predictions/postdictions and summarizes the corresponding empirical data.</p><fig id="fig11" position="float"><label>Figure 11.</label><caption><title>Three-way relationship between value certainty gain, value, and value certainty.</title><p>Same format as <xref ref-type="fig" rid="fig5">Figure 5</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-fig11-v2.tif"/></fig><p>Importantly, there is a small but significantly positive certainty gain (mean = 0.11 A.U., s.e.m. = 0.06, p=0.027, one-sided t-test). This is reassuring, because it dismisses the possibility that <inline-formula><mml:math id="inf121"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> (which would mean that effort does not increase the precision of value representation). This time, the results of the group-level random effect analysis only partially confirm our qualitative MCD predictions. In brief, although VCR<sup>0</sup> has a very strong negative impact on certainty gain (mean standardized regression weight = −0.61, s.e.m. = 0.04, p&lt;10<sup>−3</sup>; one-sided t-test), the effect of |ΔVR<sup>0</sup>| does not reach statistical significance (mean standardized regression weight = −0.009, s.e.m. = 0.01, p=0.35; one-sided t-test). We note that a simple regression-to-the-mean artifact (<xref ref-type="bibr" rid="bib79">Stigler, 1997</xref>) likely inflates the observed negative correlation between VCR<sup>0</sup> and certainty gain, beyond what would be predicted under the MCD model. Accordingly, both MCD postdictions and out-of-sample predictions clearly underestimate the effect of VCR<sup>0</sup> (and overestimate the effect of |ΔVR<sup>0</sup>|).</p></sec></sec><sec id="s4" sec-type="discussion"><title>Discussion</title><p>In this work, we have presented a novel computational model of decision-making that explains the intricate relationships between effort-related variables (response time, subjective effort) and decision-related variables (choice confidence, change of mind, spreading of alternatives, and choice-induced value certainty gain). This model assumes that deciding between alternative options whose values are uncertain induces a demand for allocating cognitive resources to value-relevant information processing. Cognitive resource allocation then optimally trades mental effort for confidence, given the prior discriminability of the value representations.</p><p>Such metacognitive control of decisions or MCD provides an alternative theoretical framework to accumulation-to-bound models of decision-making, e.g., drift-diffusion models or DDMs (<xref ref-type="bibr" rid="bib56">Milosavljevic et al., 2010</xref>; <xref ref-type="bibr" rid="bib68">Ratcliff et al., 2016</xref>; <xref ref-type="bibr" rid="bib80">Tajima et al., 2016</xref>). Recall that DDMs assume that decisions are triggered once the noisy evidence in favor of a particular option has reached a predefined bound. Standard DDM variants make quantitative predictions regarding both response times and decision outcomes, but are agnostic about choice confidence, spreading of alternatives, value certainty gain, and/or subjective effort ratings. We note that simple DDMs are significantly less accurate than MCD at making out-of-sample predictions on dependent variables common to both models (e.g., change of mind). We refer the reader interested in the details of the MCD–DDM comparison to section 9 of the Appendix.</p><p>But how do MCD and accumulation-to-bound models really differ? For example, if the DDM can be understood as an optimal policy for value-based decision-making (<xref ref-type="bibr" rid="bib80">Tajima et al., 2016</xref>), then how can these two frameworks both be optimal? The answer lies in the distinct computational problems that they solve. The MCD solves the problem of finding the optimal amount of effort to invest under the possibility that yet-unprocessed value-relevant information might change the decision maker’s mind. In fact, this resource allocation problem would be vacuous, would it not be possible to reassess preferences during the decision process. In contrast, the DDM provides an optimal solution to the problem of efficiently comparing option values, which may be unreliably signaled, but remain nonetheless stationary. Of course, the DDM decision variable (i.e., the ‘evidence’ for a given choice option over the alternative) may fluctuate, e.g. it may first drift toward the upper bound, but then eventually reach the lower bound. This is the typical DDM’s explanation for why people change their mind over the course of deliberation (<xref ref-type="bibr" rid="bib38">Kiani et al., 2014</xref>; <xref ref-type="bibr" rid="bib70">Resulaj et al., 2009</xref>). But, critically, these fluctuations are not caused by changes in the underlying value signal (i.e., the DDM’s drift term). Rather, the fluctuations are driven by neural noise that corrupts the value signals (i.e., the DDM’s diffusion term). This is why the DDM cannot predict choice-induced preference changes, or changes in options’ values more generally. This distinction between MCD and DDM extends to other types of accumulation-to-bound models, including race models (<xref ref-type="bibr" rid="bib14">De Martino et al., 2013</xref>; <xref ref-type="bibr" rid="bib81">Tajima et al., 2019</xref>). We note that either of these models (DDM or race) could be equipped with pre-choice value priors (initial bias), and then driven with ‘true’ values (drift term) derived from post-choice ratings. But then, simulating these models would require both pre-choice and post-choice ratings, which implies that choice-induced preference changes cannot be <italic>predicted</italic> from pre-choice ratings using a DDM. In contrast, the MCD model assumes that the value representations themselves are modified during the decision process, in proportion to the effort expenditure. Now the latter is maximal when prior value difference is minimal, at least when type #2 efficacy dominates (γ-effect, see section 2 of the Appendix). In turn, the MCD model predicts that the magnitude of (choice-induced) value spreading should decrease when the prior value difference increases (cf. <xref ref-type="disp-formula" rid="equ14">Equation 14</xref>). Together with (choice-induced) value certainty gain, this quantitative prediction is unique to the MCD framework, and cannot be derived from existing variants of DDM.</p><p>As a side note, the cognitive essence of spreading of alternatives has been debated for decades. Its typical interpretation is that of ‘cognitive dissonance’ reduction: if people feel uneasy about their choice, they later convince themselves that the chosen (rejected) item was actually better (worse) than they originally thought (<xref ref-type="bibr" rid="bib3">Bem, 1967</xref>; <xref ref-type="bibr" rid="bib30">Harmon-Jones et al., 2009</xref>; <xref ref-type="bibr" rid="bib34">Izuma and Murayama, 2013</xref>). In contrast, the MCD framework would rather suggest that people tend to reassess value representations until they reach a satisfactory level of confidence prior to committing to their choice. Interestingly, recent neuroimaging studies have shown that spreading of alternatives can be predicted from brain activity measured during the decision (<xref ref-type="bibr" rid="bib9">Colosio et al., 2017</xref>; <xref ref-type="bibr" rid="bib36">Jarcho et al., 2011</xref>; <xref ref-type="bibr" rid="bib39">Kitayama et al., 2013</xref>; <xref ref-type="bibr" rid="bib84">van Veen et al., 2009</xref>, <xref ref-type="bibr" rid="bib85">Voigt et al., 2019</xref>). This is evidence against the idea that spreading of alternatives only occurs after the choice has been made. In addition, key regions of the brain’s valuation and cognitive control systems are involved, including: the right inferior frontal gyrus, the ventral striatum, the anterior insula, and the anterior cingulate cortex (ACC). This further corroborates the MCD interpretation, under the assumption that the ACC is involved in controlling the allocation of cognitive effort (<xref ref-type="bibr" rid="bib57">Musslick et al., 2015</xref>; <xref ref-type="bibr" rid="bib73">Shenhav et al., 2013</xref>). Having said this, both MCD and cognitive dissonance reduction mechanisms may contribute to spreading of alternatives, on top of its known statistical artifact component (<xref ref-type="bibr" rid="bib8">Chen and Risen, 2010</xref>). The latter is a consequence of the fact that pre-choice value ratings may be unreliable and is known to produce an apparent spreading of alternatives that decreases with pre-choice value difference (<xref ref-type="bibr" rid="bib34">Izuma and Murayama, 2013</xref>). Although this pattern is compatible with our results, the underlying statistical confound is unlikely to drive our results. The reason is twofold. First, effort-related variables yield accurate within-subject out-of-sample predictions about spreading of alternatives (cf. <xref ref-type="fig" rid="fig10">Figure 10</xref>). Second, we have already shown that the effect of pre-choice value difference on spreading of alternatives is higher here than in a control condition where the choice is made after both rating sessions (<xref ref-type="bibr" rid="bib46">Lee and Daunizeau, 2020</xref>).</p><p>A central tenet of the MCD model is that involving cognitive resources in value-related information processing is costly, which calls for an efficient resource allocation mechanism. A related notion is that information processing resources may be limited, in particular: value-encoding neurons may have a bounded firing range (<xref ref-type="bibr" rid="bib53">Louie and Glimcher, 2012</xref>). In turn, ‘efficient coding’ theory assumes that the brain has evolved adaptive neural codes that optimally account for such capacity limitations (<xref ref-type="bibr" rid="bib1">Barlow, 1961</xref>; <xref ref-type="bibr" rid="bib42">Laughlin, 1981</xref>). In our context, efficient coding implies that value-encoding neurons should optimally adapt their firing range to the prior history of experienced values (<xref ref-type="bibr" rid="bib64">Polanía et al., 2019</xref>). When augmented with a Bayesian model of neural encoding/decoding (<xref ref-type="bibr" rid="bib88">Wei and Stocker, 2015</xref>), this idea was successful in explaining the non-trivial relationship between choice consistency and the distribution of subjective value ratings. Both MCD and efficient coding frameworks assume that value representations are uncertain, which stresses the importance of metacognitive processes in decision-making control (<xref ref-type="bibr" rid="bib22">Fleming and Daw, 2017</xref>). However, they differ in how they operationalize the notion of efficiency. In efficient coding, the system is ‘efficient’ in the sense that it changes the physiological properties of value-encoding neurons to minimize the information loss that results from their limited firing range. In MCD, the system is ‘efficient’ in the sense that it allocates the amount of resources that optimally trades effort cost against choice confidence. These two perspectives may not be easy to reconcile. A possibility is to consider, for example, energy-efficient population codes (<xref ref-type="bibr" rid="bib33">Hiratani and Latham, 2020</xref>; <xref ref-type="bibr" rid="bib91">Yu et al., 2016</xref>), which would tune the amount of neural resources involved in representing value to optimally trade information loss against energetic costs.</p><p>Now, let us highlight that the MCD model offers a plausible alternative interpretation for the two main reported neuroimaging findings regarding confidence in value-based choices (<xref ref-type="bibr" rid="bib14">De Martino et al., 2013</xref>). First, the ventromedial prefrontal cortex or vmPFC was found to respond positively to both value difference (i.e., ΔVR<sup>0</sup>) and choice confidence. Second, the right rostrolateral prefrontal cortex or rRLPFC was more active during low-confidence versus high-confidence choices. These findings were originally interpreted through a so-called ‘race model’, in which a decision is triggered whenever the first of option-specific value accumulators reaches a bound. Under this model, choice confidence is defined as the final gap between the two value accumulators. We note that this scenario predicts the same three-way relationship between response time, choice outcome, and choice confidence as the MCD model (see section 7 of the Appendix). In brief, rRLPFC was thought to perform a readout of choice confidence (for the purpose of subjective metacognitive report) from the racing value accumulators hosted in the vmPFC. Under the MCD framework, the contribution of the vmPFC to value-based decision control might rather be to construct item values, and to anticipate and monitor the benefit of effort investment (i.e., confidence). This would be consistent with recent fMRI studies suggesting that vmPFC confidence computations signal the attainment of task goals (<xref ref-type="bibr" rid="bib31">Hebscher and Gilboa, 2016</xref>; <xref ref-type="bibr" rid="bib44">Lebreton et al., 2015</xref>). Now, recall that the MCD model predicts that confidence and effort should be anti-correlated. Thus, the puzzling negative correlation between choice confidence and rRLPFC activity could be simply explained under the assumption that rRLPFC provides the neurocognitive resources that are instrumental for processing value-relevant information during decisions (and/or to compare item values). This resonates with the known involvement of rRLPFC in reasoning (<xref ref-type="bibr" rid="bib15">Desrochers et al., 2015</xref>; <xref ref-type="bibr" rid="bib19">Dumontheil, 2014</xref>) or memory retrieval (<xref ref-type="bibr" rid="bib4">Benoit et al., 2012</xref>; <xref ref-type="bibr" rid="bib89">Westphal et al., 2019</xref>).</p><p>At this point, we note that the current MCD model clearly has limited predictive power. Arguably, this limitation is partly due to the imperfect reliability of the data, and to the fact that MCD does not model all decision-relevant processes. In addition, assigning variations in many effort- and/or decision-related variables to a unique mechanism with few degrees of freedom necessarily restricts the model’s expected predictive power. Nevertheless, the MCD model may also not yield a sufficiently tight approximation to the mechanism that it focuses on. In turn, it may unavoidably distort the impact of prior value representations and other decision input variables. The fact that it can only explain 81% of the variability in dependent variables that can be captured using simple linear regressions against ΔVR0 and VCR0 (see section 11 of the Appendix) supports this notion. A likely explanation here is that the MCD model includes constraints that prevent it from matching the model-free postdiction accuracy level. In turn, one may want to extend the MCD model with the aim of relaxing these constraints. For example, one may allow for deviations from the optimal resource allocation framework, e.g., by considering candidate systematic biases whose magnitudes would be controlled by specific additional parameters. Having said this, some of these constraints may be necessary, in the sense that they derive from the modeling assumptions that enable the MCD model to provide a unified explanation for all dependent variables (and thus make out-of-sample predictions). What follows is a discussion of what we perceive as the main limitations of the current MCD model, and the directions of improvement they suggest.</p><p>First, we did not specify what determines decision ‘importance’, which effectively acts as a weight for confidence against effort costs (cf. <inline-formula><mml:math id="inf122"><mml:mi>R</mml:mi></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ2">Equation 2</xref> of the Model section). We know from the comparison of ‘consequential’ and ‘neutral’ choices that increasing decision importance eventually increases effort, as predicted by the MCD model. However, decision importance may have many determinants, such as, for example, the commitment duration of the decision (e.g., life partner choices), the breadth of its repercussions (e.g., political decisions), or its instrumentality with respect to the achievement of superordinate goals (e.g., moral decisions). How these determinants are combined and/or moderated by the decision context is virtually unknown (<xref ref-type="bibr" rid="bib50">Locke and Latham, 2002</xref>; <xref ref-type="bibr" rid="bib51">Locke and Latham, 2006</xref>). In addition, decision importance may also be influenced by the prior (intuitive/emotional/habitual) appraisal of choice options. For example, we found that, all else equal, people spent more time and effort deciding between two disliked items than between two liked items (results not shown). This reproduces recent results regarding the evaluation of choice sets (<xref ref-type="bibr" rid="bib74">Shenhav and Karmarkar, 2019</xref>). One may also argue that people should care less about decisions between items that have similar values (<xref ref-type="bibr" rid="bib59">Oud et al., 2016</xref>). In other terms, decision importance would be an increasing function of the absolute difference in pre-choice value ratings. However, this would predict that people invest fewer resources when deciding between items of similar pre-choice values, which directly contradicts our results (cf. <xref ref-type="fig" rid="fig5">Figures 5</xref> and <xref ref-type="fig" rid="fig6">6</xref>). Importantly, options with similar values may still be very different from each other, when decomposed on some value-relevant feature space. For example, although two food items may be similarly liked and/or wanted, they may be very different in terms of, e.g., tastiness and healthiness, which would induce some form of decision conflict (<xref ref-type="bibr" rid="bib28">Hare et al., 2009</xref>). In such a context, making a decision effectively implies committing to a preference about feature dimensions. This may be deemed to be consequential, when contrasted with choices between items that are similar in all regards. In turn, decision importance may rather be a function of options’ feature conflict. In principle, this alternative possibility is compatible with our results, under the assumption that options’ feature conflict is approximately orthogonal to pre-choice value difference. Considering how decision importance varies with feature conflict may significantly improve the amount of explained trial-by-trial variability in the model’s dependent variables. We note that the brain’s quick/automatic assessment of option features may also be the main determinant of the prior value representations that eventually serve to compute the MCD-optimal resource allocation. Probing these computational assumptions will be the focus of forthcoming publications.</p><p>Second, our current version of the MCD model relies on a simple variant of resource costs and efficacies. One may thus wonder how sensitive model predictions are to these assumptions. For example, one may expect that type #2 efficacy saturates, i.e. that the magnitude of the perturbation <inline-formula><mml:math id="inf123"><mml:mrow><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to the modes <inline-formula><mml:math id="inf124"><mml:mrow><mml:mi>μ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of the value representations eventually reaches a plateau instead of growing linearly with <inline-formula><mml:math id="inf125"><mml:mi>z</mml:mi></mml:math></inline-formula> (cf. <xref ref-type="disp-formula" rid="equ6">Equation 6</xref>). We thus implemented and tested such a model variant. We report the results of this analysis in section 10 of the Appendix. In brief, a saturating type #2 efficacy brings no additional explanatory power for the model’s dependent variables. Similarly, rendering the cost term nonlinear (e.g., quadratic) does not change the qualitative nature of the MCD predictions. More problematic, perhaps, is the fact that we did not consider distinct types of effort, which could, in principle, be associated with different costs and/or efficacies. For example, the efficacy of allocating attention may depend upon which option is considered. In turn, the brain may dynamically refocus its attention on maximally uncertain options when prospective information gains exceed switch costs (<xref ref-type="bibr" rid="bib7">Callaway et al., 2021</xref>; <xref ref-type="bibr" rid="bib35">Jang et al., 2021</xref>). Such optimal adjustment of divided attention might eventually explain systematic decision biases and shortened response times for ‘default’ choices (<xref ref-type="bibr" rid="bib52">Lopez-Persem et al., 2016</xref>). Another possibility is that effort might be optimized along two canonical dimensions, namely duration and intensity. The former dimension essentially justifies the fact that we used RT as a proxy for the amount of allocated resources. This is because, if effort intensity stays constant, then longer RT essentially signals greater resource expenditure. In fact, as is evident from the comparison between ‘penalized’ and ‘neutral’ choices, imposing an external penalty cost on RT reduces, as expected, the ensuing effort duration. More generally, however, the dual optimization of effort dimensions might render the relationship between effort and RT more complex. For example, beyond memory span or attentional load, effort intensity could be related to processing speed. This would explain why, although ‘penalized’ choices are made much faster than ‘neutral’ choices, the associated subjective feeling of effort is not as strongly impacted as RT (cf. <xref ref-type="fig" rid="fig7">Figure 7</xref>). In any case, the relationship between effort and RT might depend upon the relative costs and/or efficacies of effort duration and intensity, which might themselves be partially driven by external availability constraints (cf. time pressure or multitasking). We note that the essential nature of the cost of mental effort in cognitive tasks (e.g., neurophysiological cost, interferences cost, or opportunity cost) is still a matter of intense debate (<xref ref-type="bibr" rid="bib41">Kurzban et al., 2013</xref>; <xref ref-type="bibr" rid="bib57">Musslick et al., 2015</xref>; <xref ref-type="bibr" rid="bib60">Ozcimder et al., 2017</xref>). Progress toward addressing this issue will be highly relevant for future extensions of the MCD model.</p><p>Third, we did not consider the issue of identifying plausible neuro-computational implementations of MCD. This issue is tightly linked to the previous one, in that distinct cost types would likely impose different constraints on candidate neural network architectures (<xref ref-type="bibr" rid="bib21">Feng et al., 2014</xref>; <xref ref-type="bibr" rid="bib62">Petri et al., 2017</xref>). For example, underlying brain circuits are likely to operate MCD in a more reactive manner, eventually adjusting resource allocation from the continuous monitoring of relevant decision variables (e.g., experienced costs and benefits). Such a reactive process contrasts with our current, prospective-only variant of MCD, which sets resource allocation based on anticipated costs and benefits. We already checked that simple reactive scenarios, where the decision is triggered whenever the online monitoring of effort or confidence reaches the optimal threshold, make predictions qualitatively similar to those we have presented here. We tend to think, however, that such reactive processes should be based on a dynamic programming perspective on MCD, as was already done for the problem of optimal efficient value comparison (<xref ref-type="bibr" rid="bib80">Tajima et al., 2016</xref>; <xref ref-type="bibr" rid="bib81">Tajima et al., 2019</xref>). We will pursue this and related neuro-computational issues in subsequent publications.</p><sec id="s4-1"><title>Code availability</title><p>The computer code and algorithms that support the findings of this study will soon be made available from the open academic freeware VBA (<ext-link ext-link-type="uri" xlink:href="http://mbb-team.github.io/VBA-toolbox/">http://mbb-team.github.io/VBA-toolbox/</ext-link>). Until then, they are available from the corresponding author upon reasonable request.</p></sec><sec id="s4-2"><title>Ethical compliance</title><p>This study complies with all relevant ethical regulations and received formal approval from the INSERM Ethics Committee (CEEI-IRB00003888, decision no 16–333). In particular, in accordance with the Helsinki declaration, all participants gave written informed consent prior to commencing the experiment, which included consent to disseminate the results of the study via publication.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>DL was supported by a grant from the Laboratory of Excellence of Biology for Psychiatry (LabEx BIO-PSY, Paris, France).</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Software, Formal analysis, Supervision, Funding acquisition, Validation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: This study complies with all relevant ethical regulations and received formal approval from the INSERM Ethics Committee (CEEI-IRB00003888, decision no 16-333). In particular, in accordance with the Helsinki declaration, all participants gave written informed consent prior to commencing the experiment, which included consent to disseminate the results of the study via publication.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="sdata1"><label>Source data 1.</label><caption><title>Behavioral data.</title></caption><media mime-subtype="octet-stream" mimetype="application" xlink:href="elife-63282-data1-v2.mat"/></supplementary-material><supplementary-material id="scode1"><label>Source code 1.</label><caption><title>Analysis code.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-63282-code1-v2.zip"/></supplementary-material><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-63282-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Empirical data as well as model fitting code have been uploaded as part of this submission. Also, it is now publicly available at Dryad: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/dryad.7h44j0zsg">https://doi.org/10.5061/dryad.7h44j0zsg</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>D</given-names></name><name><surname>Daunizeau</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Lee and Daunizeau choice data from: Trading mental effort for confidence in the metacognitive control of value-based decision-making</data-title><source>Dryad Digital Repository</source><pub-id assigning-authority="Dryad" pub-id-type="doi">10.5061/dryad.7h44j0zsg</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Barlow</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="1961">1961</year><chapter-title>Possible principles underlying the transformations of sensory messages</chapter-title><person-group person-group-type="editor"><name><surname>Rosenblith</surname> <given-names>W. A</given-names></name></person-group><source>Sensory Communication</source><publisher-name>MIT Press</publisher-name><fpage>217</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.7551/mitpress/9780262518420.003.0013</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Beal</surname> <given-names>MJ</given-names></name></person-group><year iso-8601-date="2003">2003</year><source>Variational Algorithms for Approximate Bayesian Inference (Doctoral Dissertation</source><publisher-name>UCL (University College London)</publisher-name></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bem</surname> <given-names>DJ</given-names></name></person-group><year iso-8601-date="1967">1967</year><article-title>Self-perception: an alternative interpretation of cognitive dissonance phenomena</article-title><source>Psychological Review</source><volume>74</volume><fpage>183</fpage><lpage>200</lpage><pub-id pub-id-type="doi">10.1037/h0024835</pub-id><pub-id pub-id-type="pmid">5342882</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benoit</surname> <given-names>RG</given-names></name><name><surname>Gilbert</surname> <given-names>SJ</given-names></name><name><surname>Frith</surname> <given-names>CD</given-names></name><name><surname>Burgess</surname> <given-names>PW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Rostral prefrontal cortex and the focus of attention in prospective memory</article-title><source>Cerebral Cortex</source><volume>22</volume><fpage>1876</fpage><lpage>1886</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhr264</pub-id><pub-id pub-id-type="pmid">21976356</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blain</surname> <given-names>B</given-names></name><name><surname>Hollard</surname> <given-names>G</given-names></name><name><surname>Pessiglione</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural mechanisms underlying the impact of daylong cognitive work on economic decisions</article-title><source>PNAS</source><volume>113</volume><fpage>6967</fpage><lpage>6972</lpage><pub-id pub-id-type="doi">10.1073/pnas.1520527113</pub-id><pub-id pub-id-type="pmid">27274075</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogacz</surname> <given-names>R</given-names></name><name><surname>Brown</surname> <given-names>E</given-names></name><name><surname>Moehlis</surname> <given-names>J</given-names></name><name><surname>Holmes</surname> <given-names>P</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The physics of optimal decision making: a formal analysis of models of performance in two-alternative forced-choice tasks</article-title><source>Psychological Review</source><volume>113</volume><fpage>700</fpage><lpage>765</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.113.4.700</pub-id><pub-id pub-id-type="pmid">17014301</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Callaway</surname> <given-names>F</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name><name><surname>Griffiths</surname> <given-names>TL</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Fixation patterns in simple choice reflect optimal information sampling</article-title><source>PLOS Computational Biology</source><volume>17</volume><elocation-id>e1008863</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008863</pub-id><pub-id pub-id-type="pmid">33770069</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>MK</given-names></name><name><surname>Risen</surname> <given-names>JL</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>How choice affects and reflects preferences: revisiting the free-choice paradigm</article-title><source>Journal of Personality and Social Psychology</source><volume>99</volume><fpage>573</fpage><lpage>594</lpage><pub-id pub-id-type="doi">10.1037/a0020217</pub-id><pub-id pub-id-type="pmid">20658837</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Colosio</surname> <given-names>M</given-names></name><name><surname>Shestakova</surname> <given-names>A</given-names></name><name><surname>Nikulin</surname> <given-names>VV</given-names></name><name><surname>Blagovechtchenski</surname> <given-names>E</given-names></name><name><surname>Klucharev</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neural mechanisms of cognitive dissonance (Revised): An EEG study</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>5074</fpage><lpage>5083</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3209-16.2017</pub-id><pub-id pub-id-type="pmid">28438968</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daunizeau</surname> <given-names>J</given-names></name><name><surname>Adam</surname> <given-names>V</given-names></name><name><surname>Rigoux</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>VBA: a probabilistic treatment of nonlinear models for neurobiological and behavioural data</article-title><source>PLOS Computational Biology</source><volume>10</volume><elocation-id>e1003441</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003441</pub-id><pub-id pub-id-type="pmid">24465198</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Daunizeau</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017a</year><article-title>Semi-analytical approximations to statistical moments of sigmoid and softmax mappings of normal variables</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1703.00091">https://arxiv.org/abs/1703.00091</ext-link></element-citation></ref><ref id="bib12"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Daunizeau</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017b</year><article-title>The variational laplace approach to approximate bayesian inference</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1703.02089">https://arxiv.org/abs/1703.02089</ext-link></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Martino</surname> <given-names>B</given-names></name><name><surname>Kumaran</surname> <given-names>D</given-names></name><name><surname>Seymour</surname> <given-names>B</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Frames, biases, and rational decision-making in the human brain</article-title><source>Science</source><volume>313</volume><fpage>684</fpage><lpage>687</lpage><pub-id pub-id-type="doi">10.1126/science.1128356</pub-id><pub-id pub-id-type="pmid">16888142</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Martino</surname> <given-names>B</given-names></name><name><surname>Fleming</surname> <given-names>SM</given-names></name><name><surname>Garrett</surname> <given-names>N</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Confidence in value-based choice</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>105</fpage><lpage>110</lpage><pub-id pub-id-type="doi">10.1038/nn.3279</pub-id><pub-id pub-id-type="pmid">23222911</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Desrochers</surname> <given-names>TM</given-names></name><name><surname>Chatham</surname> <given-names>CH</given-names></name><name><surname>Badre</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The necessity of rostrolateral prefrontal cortex for Higher-Level sequential behavior</article-title><source>Neuron</source><volume>87</volume><fpage>1357</fpage><lpage>1368</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.08.026</pub-id><pub-id pub-id-type="pmid">26402612</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ditterich</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Evidence for time-variant decision making</article-title><source>European Journal of Neuroscience</source><volume>24</volume><fpage>3628</fpage><lpage>3641</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2006.05221.x</pub-id><pub-id pub-id-type="pmid">17229111</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drugowitsch</surname> <given-names>J</given-names></name><name><surname>Moreno-Bote</surname> <given-names>R</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name><name><surname>Shadlen</surname> <given-names>MN</given-names></name><name><surname>Pouget</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The cost of accumulating evidence in perceptual decision making</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>3612</fpage><lpage>3628</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4010-11.2012</pub-id><pub-id pub-id-type="pmid">22423085</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drugowitsch</surname> <given-names>J</given-names></name><name><surname>Wyart</surname> <given-names>V</given-names></name><name><surname>Devauchelle</surname> <given-names>AD</given-names></name><name><surname>Koechlin</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Computational precision of mental inference as critical source of human choice suboptimality</article-title><source>Neuron</source><volume>92</volume><fpage>1398</fpage><lpage>1411</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.11.005</pub-id><pub-id pub-id-type="pmid">27916454</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dumontheil</surname> <given-names>I</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Development of abstract thinking during childhood and adolescence: the role of rostrolateral prefrontal cortex</article-title><source>Developmental Cognitive Neuroscience</source><volume>10</volume><fpage>57</fpage><lpage>76</lpage><pub-id pub-id-type="doi">10.1016/j.dcn.2014.07.009</pub-id><pub-id pub-id-type="pmid">25173960</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dutilh</surname> <given-names>G</given-names></name><name><surname>Rieskamp</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Comparing perceptual and preferential decision making</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>23</volume><fpage>723</fpage><lpage>737</lpage><pub-id pub-id-type="doi">10.3758/s13423-015-0941-1</pub-id><pub-id pub-id-type="pmid">26432714</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feng</surname> <given-names>SF</given-names></name><name><surname>Schwemmer</surname> <given-names>M</given-names></name><name><surname>Gershman</surname> <given-names>SJ</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Multitasking versus multiplexing: toward a normative account of limitations in the simultaneous execution of control-demanding behaviors</article-title><source>Cognitive, Affective, &amp; Behavioral Neuroscience</source><volume>14</volume><fpage>129</fpage><lpage>146</lpage><pub-id pub-id-type="doi">10.3758/s13415-013-0236-9</pub-id><pub-id pub-id-type="pmid">24481850</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fleming</surname> <given-names>SM</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Self-evaluation of decision-making: a general bayesian framework for metacognitive computation</article-title><source>Psychological Review</source><volume>124</volume><fpage>91</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1037/rev0000045</pub-id><pub-id pub-id-type="pmid">28004960</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friston</surname> <given-names>K</given-names></name><name><surname>Mattout</surname> <given-names>J</given-names></name><name><surname>Trujillo-Barreto</surname> <given-names>N</given-names></name><name><surname>Ashburner</surname> <given-names>J</given-names></name><name><surname>Penny</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Variational free energy and the Laplace approximation</article-title><source>NeuroImage</source><volume>34</volume><fpage>220</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2006.08.035</pub-id><pub-id pub-id-type="pmid">17055746</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giguère</surname> <given-names>G</given-names></name><name><surname>Love</surname> <given-names>BC</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Limits in decision making arise from limits in memory retrieval</article-title><source>PNAS</source><volume>110</volume><fpage>7613</fpage><lpage>7618</lpage><pub-id pub-id-type="doi">10.1073/pnas.1219674110</pub-id><pub-id pub-id-type="pmid">23610402</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname> <given-names>JI</given-names></name><name><surname>Shadlen</surname> <given-names>MN</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The neural basis of decision making</article-title><source>Annual Review of Neuroscience</source><volume>30</volume><fpage>535</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.29.051605.113038</pub-id><pub-id pub-id-type="pmid">17600525</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gould</surname> <given-names>N</given-names></name><name><surname>Ortner</surname> <given-names>C</given-names></name><name><surname>Packwood</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A dimer-type saddle search algorithm with preconditioning and linesearch</article-title><source>Mathematics of Computation</source><volume>85</volume><fpage>2939</fpage><lpage>2966</lpage><pub-id pub-id-type="doi">10.1090/mcom/3096</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greenwald</surname> <given-names>AG</given-names></name><name><surname>Banaji</surname> <given-names>MR</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Implicit social cognition: attitudes, self-esteem, and stereotypes</article-title><source>Psychological Review</source><volume>102</volume><fpage>4</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.102.1.4</pub-id><pub-id pub-id-type="pmid">7878162</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hare</surname> <given-names>TA</given-names></name><name><surname>Camerer</surname> <given-names>CF</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Self-control in decision-making involves modulation of the vmPFC valuation system</article-title><source>Science</source><volume>324</volume><fpage>646</fpage><lpage>648</lpage><pub-id pub-id-type="doi">10.1126/science.1168450</pub-id><pub-id pub-id-type="pmid">19407204</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harlé</surname> <given-names>KM</given-names></name><name><surname>Sanfey</surname> <given-names>AG</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Incidental sadness biases social economic decisions in the ultimatum game</article-title><source>Emotion</source><volume>7</volume><fpage>876</fpage><lpage>881</lpage><pub-id pub-id-type="doi">10.1037/1528-3542.7.4.876</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harmon-Jones</surname> <given-names>E</given-names></name><name><surname>Amodio</surname> <given-names>DM</given-names></name><name><surname>Harmon-Jones</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Action-based model of dissonance: a review, integration, and expansion of conceptions of cognitive conflict</article-title><source>Advances in Experimental Social Psychology</source><volume>41</volume><fpage>119</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1016/S0065-2601(08)00403-6</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hebscher</surname> <given-names>M</given-names></name><name><surname>Gilboa</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A boost of confidence: the role of the ventromedial prefrontal cortex in memory, decision-making, and schemas</article-title><source>Neuropsychologia</source><volume>90</volume><fpage>46</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2016.05.003</pub-id><pub-id pub-id-type="pmid">27150705</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Heitz</surname> <given-names>RP</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The speed-accuracy tradeoff: history, physiology, methodology, and behavior</article-title><source>Frontiers in Neuroscience</source><volume>8</volume><elocation-id>150</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2014.00150</pub-id><pub-id pub-id-type="pmid">24966810</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Hiratani</surname> <given-names>N</given-names></name><name><surname>Latham</surname> <given-names>PE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Developmental and evolutionary constraints on olfactory circuit selection</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.12.22.423799</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Izuma</surname> <given-names>K</given-names></name><name><surname>Murayama</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Choice-induced preference change in the free-choice paradigm: a critical methodological review</article-title><source>Frontiers in Psychology</source><volume>4</volume><elocation-id>41</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2013.00041</pub-id><pub-id pub-id-type="pmid">23404185</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jang</surname> <given-names>AI</given-names></name><name><surname>Sharma</surname> <given-names>R</given-names></name><name><surname>Drugowitsch</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Optimal policy for attention-modulated decisions explains human fixation behavior</article-title><source>eLife</source><volume>10</volume><elocation-id>e63436</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.63436</pub-id><pub-id pub-id-type="pmid">33769284</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jarcho</surname> <given-names>JM</given-names></name><name><surname>Berkman</surname> <given-names>ET</given-names></name><name><surname>Lieberman</surname> <given-names>MD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The neural basis of rationalization: cognitive dissonance reduction during decision-making</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>6</volume><fpage>460</fpage><lpage>467</lpage><pub-id pub-id-type="doi">10.1093/scan/nsq054</pub-id><pub-id pub-id-type="pmid">20621961</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kahneman</surname> <given-names>D</given-names></name><name><surname>Slovic</surname> <given-names>P</given-names></name><name><surname>Tversky</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1982">1982</year><source>Judgment Under Uncertainty: Heuristics and Biases</source><publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1007/978-94-010-1834-0_8</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiani</surname> <given-names>R</given-names></name><name><surname>Cueva</surname> <given-names>CJ</given-names></name><name><surname>Reppas</surname> <given-names>JB</given-names></name><name><surname>Newsome</surname> <given-names>WT</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dynamics of neural population responses in prefrontal cortex indicate changes of mind on single trials</article-title><source>Current Biology</source><volume>24</volume><fpage>1542</fpage><lpage>1547</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2014.05.049</pub-id><pub-id pub-id-type="pmid">24954050</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kitayama</surname> <given-names>S</given-names></name><name><surname>Chua</surname> <given-names>HF</given-names></name><name><surname>Tompson</surname> <given-names>S</given-names></name><name><surname>Han</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neural mechanisms of dissonance: an fMRI investigation of choice justification</article-title><source>NeuroImage</source><volume>69</volume><fpage>206</fpage><lpage>212</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.11.034</pub-id><pub-id pub-id-type="pmid">23238432</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krajbich</surname> <given-names>I</given-names></name><name><surname>Armel</surname> <given-names>C</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Visual fixations and the computation and comparison of value in simple choice</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1292</fpage><lpage>1298</lpage><pub-id pub-id-type="doi">10.1038/nn.2635</pub-id><pub-id pub-id-type="pmid">20835253</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kurzban</surname> <given-names>R</given-names></name><name><surname>Duckworth</surname> <given-names>A</given-names></name><name><surname>Kable</surname> <given-names>JW</given-names></name><name><surname>Myers</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>An opportunity cost model of subjective effort and task performance</article-title><source>Behavioral and Brain Sciences</source><volume>36</volume><fpage>661</fpage><lpage>679</lpage><pub-id pub-id-type="doi">10.1017/S0140525X12003196</pub-id><pub-id pub-id-type="pmid">24304775</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laughlin</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>A simple coding procedure enhances a neuron's Information Capacity</article-title><source>Zeitschrift Für Naturforschung C</source><volume>36</volume><fpage>910</fpage><lpage>912</lpage><pub-id pub-id-type="doi">10.1515/znc-1981-9-1040</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lebreton</surname> <given-names>M</given-names></name><name><surname>Jorge</surname> <given-names>S</given-names></name><name><surname>Michel</surname> <given-names>V</given-names></name><name><surname>Thirion</surname> <given-names>B</given-names></name><name><surname>Pessiglione</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>An automatic valuation system in the human brain: evidence from functional neuroimaging</article-title><source>Neuron</source><volume>64</volume><fpage>431</fpage><lpage>439</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.09.040</pub-id><pub-id pub-id-type="pmid">19914190</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lebreton</surname> <given-names>M</given-names></name><name><surname>Abitbol</surname> <given-names>R</given-names></name><name><surname>Daunizeau</surname> <given-names>J</given-names></name><name><surname>Pessiglione</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Automatic integration of confidence in the brain valuation signal</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1159</fpage><lpage>1167</lpage><pub-id pub-id-type="doi">10.1038/nn.4064</pub-id><pub-id pub-id-type="pmid">26192748</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>D</given-names></name><name><surname>Coricelli</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>An empirical test of the role of value certainty in decision making</article-title><source>Frontiers in Psychology</source><volume>11</volume><elocation-id>574473</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2020.574473</pub-id><pub-id pub-id-type="pmid">33192874</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>D</given-names></name><name><surname>Daunizeau</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Choosing what we like vs liking what we choose: how choice-induced preference change might actually be instrumental to decision-making</article-title><source>PLOS ONE</source><volume>15</volume><elocation-id>e0231081</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0231081</pub-id><pub-id pub-id-type="pmid">32421699</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>D</given-names></name><name><surname>Usher</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Value certainty in Drift-Diffusion models of preferential choice</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.08.22.262725</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname> <given-names>SL</given-names></name><name><surname>O'Doherty</surname> <given-names>JP</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The decision value computations in the vmPFC and striatum use a relative value code that is guided by visual attention</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>13214</fpage><lpage>13223</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1246-11.2011</pub-id><pub-id pub-id-type="pmid">21917804</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname> <given-names>SL</given-names></name><name><surname>O'Doherty</surname> <given-names>JP</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Stimulus value signals in ventromedial PFC reflect the integration of attribute value signals computed in Fusiform gyrus and posterior superior temporal gyrus</article-title><source>Journal of Neuroscience</source><volume>33</volume><fpage>8729</fpage><lpage>8741</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4809-12.2013</pub-id><pub-id pub-id-type="pmid">23678116</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Locke</surname> <given-names>EA</given-names></name><name><surname>Latham</surname> <given-names>GP</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Building a practically useful theory of goal setting and task motivation. A 35-year odyssey</article-title><source>American Psychologist</source><volume>57</volume><fpage>705</fpage><lpage>717</lpage><pub-id pub-id-type="doi">10.1037/0003-066X.57.9.705</pub-id><pub-id pub-id-type="pmid">12237980</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Locke</surname> <given-names>EA</given-names></name><name><surname>Latham</surname> <given-names>GP</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>New directions in Goal-Setting theory</article-title><source>Current Directions in Psychological Science</source><volume>15</volume><fpage>265</fpage><lpage>268</lpage><pub-id pub-id-type="doi">10.1111/j.1467-8721.2006.00449.x</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lopez-Persem</surname> <given-names>A</given-names></name><name><surname>Domenech</surname> <given-names>P</given-names></name><name><surname>Pessiglione</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>How prior preferences determine decision-making frames and biases in the human brain</article-title><source>eLife</source><volume>5</volume><elocation-id>e20317</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.20317</pub-id><pub-id pub-id-type="pmid">27864918</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Louie</surname> <given-names>K</given-names></name><name><surname>Glimcher</surname> <given-names>PW</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Efficient coding and the neural representation of value</article-title><source>Annals of the New York Academy of Sciences</source><volume>1251</volume><fpage>13</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1111/j.1749-6632.2012.06496.x</pub-id><pub-id pub-id-type="pmid">22694213</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mao</surname> <given-names>ZH</given-names></name><name><surname>Massaquoi</surname> <given-names>SG</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Dynamics of winner-take-all competition in recurrent neural networks with lateral inhibition</article-title><source>IEEE Transactions on Neural Networks</source><volume>18</volume><fpage>55</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1109/TNN.2006.883724</pub-id><pub-id pub-id-type="pmid">17278461</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marois</surname> <given-names>R</given-names></name><name><surname>Ivanoff</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Capacity limits of information processing in the brain</article-title><source>Trends in Cognitive Sciences</source><volume>9</volume><fpage>296</fpage><lpage>305</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2005.04.010</pub-id><pub-id pub-id-type="pmid">15925809</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Milosavljevic</surname> <given-names>M</given-names></name><name><surname>Malmaud</surname> <given-names>J</given-names></name><name><surname>Huth</surname> <given-names>A</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name><name><surname>Rangel</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The drift diffusion model can account for value-based choice response times under high and low time pressure</article-title><source>Judgment and Decision Making</source><volume>5</volume><fpage>437</fpage><lpage>449</lpage></element-citation></ref><ref id="bib57"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Musslick</surname> <given-names>S</given-names></name><name><surname>Shenhav</surname> <given-names>A</given-names></name><name><surname>Botvinick</surname> <given-names>M</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A computational model of control allocation based on the expected value of control</article-title><conf-name>Reinforcement Learning and Decision Making Conference</conf-name></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Connell</surname> <given-names>RG</given-names></name><name><surname>Dockree</surname> <given-names>PM</given-names></name><name><surname>Kelly</surname> <given-names>SP</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A supramodal accumulation-to-bound signal that determines perceptual decisions in humans</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1729</fpage><lpage>1735</lpage><pub-id pub-id-type="doi">10.1038/nn.3248</pub-id><pub-id pub-id-type="pmid">23103963</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oud</surname> <given-names>B</given-names></name><name><surname>Krajbich</surname> <given-names>I</given-names></name><name><surname>Miller</surname> <given-names>K</given-names></name><name><surname>Cheong</surname> <given-names>JH</given-names></name><name><surname>Botvinick</surname> <given-names>M</given-names></name><name><surname>Fehr</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Irrational time allocation in decision-making</article-title><source>Proceedings of the Royal Society B: Biological Sciences</source><volume>283</volume><elocation-id>20151439</elocation-id><pub-id pub-id-type="doi">10.1098/rspb.2015.1439</pub-id><pub-id pub-id-type="pmid">26763695</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Ozcimder</surname> <given-names>K</given-names></name><name><surname>Dey</surname> <given-names>B</given-names></name><name><surname>Musslick</surname> <given-names>S</given-names></name><name><surname>Petri</surname> <given-names>G</given-names></name><name><surname>Ahmed</surname> <given-names>NK</given-names></name><name><surname>Willke</surname> <given-names>TL</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A formal approach to modeling the cost of cognitive control</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1706.00085">https://arxiv.org/abs/1706.00085</ext-link></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palmer</surname> <given-names>J</given-names></name><name><surname>Huk</surname> <given-names>AC</given-names></name><name><surname>Shadlen</surname> <given-names>MN</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The effect of stimulus strength on the speed and accuracy of a perceptual decision</article-title><source>Journal of Vision</source><volume>5</volume><fpage>376</fpage><lpage>404</lpage><pub-id pub-id-type="doi">10.1167/5.5.1</pub-id><pub-id pub-id-type="pmid">16097871</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Petri</surname> <given-names>G</given-names></name><name><surname>Musslick</surname> <given-names>S</given-names></name><name><surname>Dey</surname> <given-names>B</given-names></name><name><surname>Ozcimder</surname> <given-names>K</given-names></name><name><surname>Ahmed</surname> <given-names>NK</given-names></name><name><surname>Willke</surname> <given-names>T</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Universal limits to parallel processing capability of network architectures</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1708.03263">https://arxiv.org/abs/1708.03263</ext-link></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pirrone</surname> <given-names>A</given-names></name><name><surname>Stafford</surname> <given-names>T</given-names></name><name><surname>Marshall</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>When natural selection should optimize speed-accuracy trade-offs</article-title><source>Frontiers in Neuroscience</source><volume>8</volume><elocation-id>73</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2014.00073</pub-id><pub-id pub-id-type="pmid">24782703</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Polanía</surname> <given-names>R</given-names></name><name><surname>Woodford</surname> <given-names>M</given-names></name><name><surname>Ruff</surname> <given-names>CC</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Efficient coding of subjective value</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>134</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0292-0</pub-id><pub-id pub-id-type="pmid">30559477</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Porcelli</surname> <given-names>AJ</given-names></name><name><surname>Lewis</surname> <given-names>AH</given-names></name><name><surname>Delgado</surname> <given-names>MR</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Acute stress influences neural circuits of reward processing</article-title><source>Frontiers in Neuroscience</source><volume>6</volume><elocation-id>157</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2012.00157</pub-id><pub-id pub-id-type="pmid">23125822</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Porcelli</surname> <given-names>AJ</given-names></name><name><surname>Delgado</surname> <given-names>MR</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Acute stress modulates risk taking in financial decision making</article-title><source>Psychological Science</source><volume>20</volume><fpage>278</fpage><lpage>283</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.2009.02288.x</pub-id><pub-id pub-id-type="pmid">19207694</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rangel</surname> <given-names>A</given-names></name><name><surname>Camerer</surname> <given-names>C</given-names></name><name><surname>Montague</surname> <given-names>PR</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A framework for studying the neurobiology of value-based decision making</article-title><source>Nature Reviews Neuroscience</source><volume>9</volume><fpage>545</fpage><lpage>556</lpage><pub-id pub-id-type="doi">10.1038/nrn2357</pub-id><pub-id pub-id-type="pmid">18545266</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname> <given-names>R</given-names></name><name><surname>Smith</surname> <given-names>PL</given-names></name><name><surname>Brown</surname> <given-names>SD</given-names></name><name><surname>McKoon</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Diffusion decision model: current issues and history</article-title><source>Trends in Cognitive Sciences</source><volume>20</volume><fpage>260</fpage><lpage>281</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2016.01.007</pub-id><pub-id pub-id-type="pmid">26952739</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname> <given-names>R</given-names></name><name><surname>McKoon</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The diffusion decision model: theory and data for two-choice decision tasks</article-title><source>Neural Computation</source><volume>20</volume><fpage>873</fpage><lpage>922</lpage><pub-id pub-id-type="doi">10.1162/neco.2008.12-06-420</pub-id><pub-id pub-id-type="pmid">18085991</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Resulaj</surname> <given-names>A</given-names></name><name><surname>Kiani</surname> <given-names>R</given-names></name><name><surname>Wolpert</surname> <given-names>DM</given-names></name><name><surname>Shadlen</surname> <given-names>MN</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Changes of mind in decision-making</article-title><source>Nature</source><volume>461</volume><fpage>263</fpage><lpage>266</lpage><pub-id pub-id-type="doi">10.1038/nature08275</pub-id><pub-id pub-id-type="pmid">19693010</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigoux</surname> <given-names>L</given-names></name><name><surname>Stephan</surname> <given-names>KE</given-names></name><name><surname>Friston</surname> <given-names>KJ</given-names></name><name><surname>Daunizeau</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Bayesian model selection for group studies - revisited</article-title><source>NeuroImage</source><volume>84</volume><fpage>971</fpage><lpage>985</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.08.065</pub-id><pub-id pub-id-type="pmid">24018303</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seung</surname> <given-names>HS</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Learning in spiking neural networks by reinforcement of stochastic synaptic transmission</article-title><source>Neuron</source><volume>40</volume><fpage>1063</fpage><lpage>1073</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(03)00761-X</pub-id><pub-id pub-id-type="pmid">14687542</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shenhav</surname> <given-names>A</given-names></name><name><surname>Botvinick</surname> <given-names>MM</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The expected value of control: an integrative theory of anterior cingulate cortex function</article-title><source>Neuron</source><volume>79</volume><fpage>217</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.07.007</pub-id><pub-id pub-id-type="pmid">23889930</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shenhav</surname> <given-names>A</given-names></name><name><surname>Karmarkar</surname> <given-names>UR</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Dissociable components of the reward circuit are involved in appraisal versus choice</article-title><source>Scientific Reports</source><volume>9</volume><elocation-id>1958</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-019-38927-7</pub-id><pub-id pub-id-type="pmid">30760824</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Slovic</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>The construction of preference</article-title><source>American Psychologist</source><volume>50</volume><fpage>364</fpage><lpage>371</lpage><pub-id pub-id-type="doi">10.1037/0003-066X.50.5.364</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sokol-Hessner</surname> <given-names>P</given-names></name><name><surname>Camerer</surname> <given-names>CF</given-names></name><name><surname>Phelps</surname> <given-names>EA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Emotion regulation reduces loss aversion and decreases amygdala responses to losses</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>8</volume><fpage>341</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1093/scan/nss002</pub-id><pub-id pub-id-type="pmid">22275168</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srivastava</surname> <given-names>V</given-names></name><name><surname>Holmes</surname> <given-names>P</given-names></name><name><surname>Simen</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Explicit moments of decision times for single- and double-threshold drift-diffusion processes</article-title><source>Journal of Mathematical Psychology</source><volume>75</volume><fpage>96</fpage><lpage>109</lpage><pub-id pub-id-type="doi">10.1016/j.jmp.2016.03.005</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stephan</surname> <given-names>KE</given-names></name><name><surname>Penny</surname> <given-names>WD</given-names></name><name><surname>Daunizeau</surname> <given-names>J</given-names></name><name><surname>Moran</surname> <given-names>RJ</given-names></name><name><surname>Friston</surname> <given-names>KJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Bayesian model selection for group studies</article-title><source>NeuroImage</source><volume>46</volume><fpage>1004</fpage><lpage>1017</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.03.025</pub-id><pub-id pub-id-type="pmid">19306932</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stigler</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Regression towards the mean, historically considered</article-title><source>Statistical Methods in Medical Research</source><volume>6</volume><fpage>103</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1177/096228029700600202</pub-id><pub-id pub-id-type="pmid">9261910</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tajima</surname> <given-names>S</given-names></name><name><surname>Drugowitsch</surname> <given-names>J</given-names></name><name><surname>Pouget</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Optimal policy for value-based decision-making</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>12400</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms12400</pub-id><pub-id pub-id-type="pmid">27535638</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tajima</surname> <given-names>S</given-names></name><name><surname>Drugowitsch</surname> <given-names>J</given-names></name><name><surname>Patel</surname> <given-names>N</given-names></name><name><surname>Pouget</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Optimal policy for multi-alternative decisions</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1503</fpage><lpage>1511</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0453-9</pub-id><pub-id pub-id-type="pmid">31384015</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thorngate</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Efficient decision heuristics</article-title><source>Behavioral Science</source><volume>25</volume><fpage>219</fpage><lpage>225</lpage><pub-id pub-id-type="doi">10.1002/bs.3830250306</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tversky</surname> <given-names>A</given-names></name><name><surname>Thaler</surname> <given-names>RH</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Anomalies: preference reversals</article-title><source>Journal of Economic Perspectives</source><volume>4</volume><fpage>201</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.1257/jep.4.2.201</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Veen</surname> <given-names>V</given-names></name><name><surname>Krug</surname> <given-names>MK</given-names></name><name><surname>Schooler</surname> <given-names>JW</given-names></name><name><surname>Carter</surname> <given-names>CS</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Neural activity predicts attitude change in cognitive dissonance</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1469</fpage><lpage>1474</lpage><pub-id pub-id-type="doi">10.1038/nn.2413</pub-id><pub-id pub-id-type="pmid">19759538</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voigt</surname> <given-names>K</given-names></name><name><surname>Murawski</surname> <given-names>C</given-names></name><name><surname>Speer</surname> <given-names>S</given-names></name><name><surname>Bode</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Hard decisions shape the neural coding of preferences</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>718</fpage><lpage>726</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1681-18.2018</pub-id><pub-id pub-id-type="pmid">30530856</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>Z</given-names></name><name><surname>Busemeyer</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Interference effects of categorization on decision making</article-title><source>Cognition</source><volume>150</volume><fpage>133</fpage><lpage>149</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2016.01.019</pub-id><pub-id pub-id-type="pmid">26896726</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warren</surname> <given-names>C</given-names></name><name><surname>McGraw</surname> <given-names>AP</given-names></name><name><surname>Van Boven</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Values and preferences: defining preference construction</article-title><source>Wiley Interdisciplinary Reviews: Cognitive Science</source><volume>2</volume><fpage>193</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1002/wcs.98</pub-id><pub-id pub-id-type="pmid">26302010</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname> <given-names>XX</given-names></name><name><surname>Stocker</surname> <given-names>AA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A bayesian observer model constrained by efficient coding can explain 'anti-Bayesian' percepts</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1509</fpage><lpage>1517</lpage><pub-id pub-id-type="doi">10.1038/nn.4105</pub-id><pub-id pub-id-type="pmid">26343249</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Westphal</surname> <given-names>AJ</given-names></name><name><surname>Chow</surname> <given-names>TE</given-names></name><name><surname>Ngoy</surname> <given-names>C</given-names></name><name><surname>Zuo</surname> <given-names>X</given-names></name><name><surname>Liao</surname> <given-names>V</given-names></name><name><surname>Storozuk</surname> <given-names>LA</given-names></name><name><surname>Peters</surname> <given-names>MAK</given-names></name><name><surname>Wu</surname> <given-names>AD</given-names></name><name><surname>Rissman</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Anodal transcranial direct current stimulation to the left rostrolateral prefrontal cortex selectively improves source memory retrieval</article-title><source>Journal of Cognitive Neuroscience</source><volume>31</volume><fpage>1380</fpage><lpage>1391</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01421</pub-id><pub-id pub-id-type="pmid">31059351</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wyart</surname> <given-names>V</given-names></name><name><surname>Koechlin</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Choice variability and suboptimality in uncertain environments</article-title><source>Current Opinion in Behavioral Sciences</source><volume>11</volume><fpage>109</fpage><lpage>115</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2016.07.003</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname> <given-names>L</given-names></name><name><surname>Zhang</surname> <given-names>C</given-names></name><name><surname>Liu</surname> <given-names>L</given-names></name><name><surname>Yu</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Energy-efficient population coding constrains network size of a neuronal array system</article-title><source>Scientific Reports</source><volume>6</volume><elocation-id>19369</elocation-id><pub-id pub-id-type="doi">10.1038/srep19369</pub-id><pub-id pub-id-type="pmid">26781354</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><boxed-text><sec id="s8" sec-type="appendix"><title>1. On the approximation accuracy of the expected confidence gain</title><p>The MCD model relies on the system's ability to anticipate the benefit of allocating resources to the decision process. Given the mathematical expression of choice confidence (<xref ref-type="disp-formula" rid="equ4">Equation 4</xref> in the main text), this reduces to finding an analytical approximation to the following expression:<disp-formula id="equ15"><label>(A1)</label><mml:math id="m15"><mml:mrow><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mrow><mml:mo>|</mml:mo> <mml:mi>x</mml:mi> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf126"><mml:mrow><mml:mi>x</mml:mi><mml:mo>→</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi mathvariant="normal">e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the sigmoid mapping, <inline-formula><mml:math id="inf127"><mml:mi>λ</mml:mi></mml:math></inline-formula> is an arbitrary constant, and the expectation is taken under the Gaussian distribution of <inline-formula><mml:math id="inf128"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, whose mean and variance are µ and <inline-formula><mml:math id="inf129"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>, respectively.</p><p>Note that the absolute value mapping <inline-formula><mml:math id="inf130"><mml:mrow><mml:mi>x</mml:mi><mml:mo>→</mml:mo><mml:mrow><mml:mo>|</mml:mo> <mml:mi>x</mml:mi> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> follows a folded normal distribution, whose first two moments <inline-formula><mml:math id="inf131"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mi>x</mml:mi> <mml:mo>|</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf132"><mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mi>x</mml:mi> <mml:mo>|</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> have known expressions:<disp-formula id="equ16"><label>(A2)</label><mml:math id="m16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd/><mml:mtd><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:msqrt><mml:mfrac><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mfrac></mml:msqrt><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>μ</mml:mi><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>μ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>×</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi>π</mml:mi><mml:mtext> </mml:mtext><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>σ</mml:mi><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mspace width="negativethinmathspace"/><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>V</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mi>E</mml:mi><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>x</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where the first line relies on a moment-matching approximation to the cumulative normal distribution function (<xref ref-type="bibr" rid="bib11">Daunizeau, 2017a</xref>). This allows us to derive the following analytical approximation to <xref ref-type="disp-formula" rid="equ15">Equation A1</xref>:<disp-formula id="equ17"><label>(A3)</label><mml:math id="m17"><mml:mrow><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mo>≈</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mi>x</mml:mi> <mml:mo>|</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msqrt><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msup><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>a</mml:mi><mml:mi>V</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mi>x</mml:mi> <mml:mo>|</mml:mo></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where setting <inline-formula><mml:math id="inf133"><mml:mrow><mml:mi>a</mml:mi><mml:mo>≈</mml:mo><mml:mrow><mml:mn>3</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:msup><mml:mi>π</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> makes this approximation tight (<xref ref-type="bibr" rid="bib11">Daunizeau, 2017a</xref>).</p><p>The quality of this approximation can be evaluated by drawing samples of <inline-formula><mml:math id="inf134"><mml:mrow><mml:mi>x</mml:mi><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, and comparing the Monte-Carlo average of <inline-formula><mml:math id="inf135"><mml:mrow><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mrow><mml:mo>|</mml:mo> <mml:mi>x</mml:mi> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> with the expression given in <xref ref-type="disp-formula" rid="equ17">Equation A3</xref>. This is summarized in <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>, where the range of variation for the moments of <inline-formula><mml:math id="inf136"><mml:mi>x</mml:mi></mml:math></inline-formula> was set as follows: <inline-formula><mml:math id="inf137"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mo>−</mml:mo><mml:mn>4</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf138"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Quality of the analytical approximation to <inline-formula><mml:math id="inf139"><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:mover></mml:math></inline-formula>.</title><p>Upper left panel: the Monte-Carlo estimate of <inline-formula><mml:math id="inf140"><mml:mover accent="true"><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:mover></mml:math></inline-formula> (color-coded) is shown as a function of both the mean <inline-formula><mml:math id="inf141"><mml:mi>μ</mml:mi><mml:mo>∈</mml:mo><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mo>-</mml:mo><mml:mn>4,4</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula> (y-axis) and the variance <inline-formula><mml:math id="inf142"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mn>0,4</mml:mn></mml:mrow></mml:mfenced></mml:math></inline-formula> (x-axis) of the parent process <inline-formula><mml:math id="inf143"><mml:mi>x</mml:mi><mml:mo>~</mml:mo><mml:mi>N</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></inline-formula>. Upper right panel: analytic approximation to <inline-formula><mml:math id="inf144"><mml:mover accent="true"><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:mover></mml:math></inline-formula> as given by <xref ref-type="disp-formula" rid="equ17">Equation A3</xref> (same format). Lower left panel: the error, that is, the difference between the Monte-Carlo and the analytic approximation (same format). Lower right panel: the analytic approximation (y-axis) is plotted as a function of the Monte-Carlo estimate (x-axis) for each pair of moments <inline-formula><mml:math id="inf145"><mml:mfenced close="}" open="{" separators="|"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></inline-formula> of the parent distribution.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-app1-fig1-v2.tif"/></fig><p>One can see that the error rarely exceeds 5%, across the whole range of moments <inline-formula><mml:math id="inf146"><mml:mrow><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of the parent distribution. This is how tight the analytic approximation of the expected confidence gain (<xref ref-type="disp-formula" rid="equ9">Equation 9</xref> in the main text) is.</p></sec><sec id="s9" sec-type="appendix"><title>2. On the impact of model parameters for the MCD model</title><p>To begin with, note that the properties of the metacognitive control of decisions (in terms of effort allocation and/or confidence) actually depend on the demand for resources, which is itself determined by prior value representations (or, more properly, by the prior uncertainty <inline-formula><mml:math id="inf147"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> and the absolute means' difference <inline-formula><mml:math id="inf148"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>). Now, the way the MCD-optimal control responds to the resource demand is determined by effort efficacy and unitary cost parameters. In addition, MCD-optimal confidence may not trivially follow resource allocation, because it may be overcompensated by choice difficulty.</p><p>First, recall that the amount <inline-formula><mml:math id="inf149"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> of allocated resources maximizes the EVC:<disp-formula id="equ18"><label>(A4)</label><mml:math id="m18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mspace width="1em"/><mml:mi>z</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>α</mml:mi><mml:mi>z</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf150"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is given in <xref ref-type="disp-formula" rid="equ9">Equation 9</xref> in the main text. According to the implicit function theorem, the derivatives of <inline-formula><mml:math id="inf151"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> w.r.t. <inline-formula><mml:math id="inf152"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf153"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are given by <xref ref-type="bibr" rid="bib26">Gould et al., 2016</xref>:<disp-formula id="equ19"><label>(A5)</label><mml:math id="m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mrow><mml:mo fence="true" stretchy="true" symmetric="true"/><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mo fence="true" stretchy="true" symmetric="true"/><mml:mfrac><mml:mrow><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:mfrac></mml:mstyle></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mrow><mml:mo fence="true" stretchy="true" symmetric="true"/><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:mfrac></mml:mstyle><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mo fence="true" stretchy="true" symmetric="true"/><mml:mfrac><mml:mrow><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>02</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The double derivatives in <xref ref-type="disp-formula" rid="equ19">Equations A5</xref> are not trivial to obtain.</p><p>First, the gradient <inline-formula><mml:math id="inf154"><mml:mrow><mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> of choice confidence w.r.t. <inline-formula><mml:math id="inf155"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> writes:<disp-formula id="equ20"><label>(A6)</label><mml:math id="m20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>V</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>V</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mn>3</mml:mn><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi>γ</mml:mi><mml:mi>z</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf156"><mml:mrow><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> is given by:<disp-formula id="equ21"><label>(A7)</label><mml:math id="m21"><mml:mrow><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>π</mml:mi><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>6</mml:mn><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>3</mml:mn><mml:mi>V</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mstyle scriptlevel="+1"><mml:mfrac><mml:mn>3</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mstyle></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>Note that the gradient <inline-formula><mml:math id="inf157"><mml:mrow><mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ20">Equation A6</xref> can be obtained analytically from <xref ref-type="disp-formula" rid="equ7">Equation 7</xref> in the main text. However, we refrain from doing this, because it is clear that deriving the right-hand term of <xref ref-type="disp-formula" rid="equ20">Equation A6</xref> w.r.t. both <inline-formula><mml:math id="inf158"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf159"><mml:mi>z</mml:mi></mml:math></inline-formula> will not bring any simple insight regarding the impact of <inline-formula><mml:math id="inf160"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> onto <inline-formula><mml:math id="inf161"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula>.</p><p>Also, although the gradient <inline-formula><mml:math id="inf162"><mml:mrow><mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> of choice confidence wr.t. <inline-formula><mml:math id="inf163"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> takes a much more concise form:<disp-formula id="equ22"><label>(A8)</label><mml:math id="m22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>3</mml:mn><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi>z</mml:mi><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>it still remains tedious to derive its expression with respect to both <inline-formula><mml:math id="inf164"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf165"><mml:mi>z</mml:mi></mml:math></inline-formula>. This is why we opt for separating the respective effects of type #1 and type #2 efficacies.</p><p>First, let us ask what would be the MCD-optimal effort <inline-formula><mml:math id="inf166"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> and confidence <inline-formula><mml:math id="inf167"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> when <inline-formula><mml:math id="inf168"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, that is, if the only effect of allocating resources is to increase the precision of value representations. We call this the 'β-effect'. In this case, <inline-formula><mml:math id="inf169"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow> <mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf170"><mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mi>z</mml:mi></mml:mrow> <mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> irrespective of <inline-formula><mml:math id="inf171"><mml:mi>z</mml:mi></mml:math></inline-formula>. This greatly simplifies <xref ref-type="disp-formula" rid="equ20 equ21 equ22">Equations A6–A8</xref>:<disp-formula id="equ23"><label>(A9)</label><mml:math id="m23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mn>6</mml:mn><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>3</mml:mn><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi>z</mml:mi><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>π</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>6</mml:mn><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mfrac><mml:mn>3</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Inserting <xref ref-type="disp-formula" rid="equ23">Equation A9</xref> back into <xref ref-type="disp-formula" rid="equ19">Equation A5</xref> now yields:<disp-formula id="equ24"><label>(A10)</label><mml:math id="m24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>β</mml:mi><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mstyle></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>β</mml:mi><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>β</mml:mi><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:mstyle></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Now the sign of the gradients of <inline-formula><mml:math id="inf172"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> w.r.t. <inline-formula><mml:math id="inf173"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf174"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are driven by the numerators of <xref ref-type="disp-formula" rid="equ24">Equation A10</xref> because all partial derivatives of <inline-formula><mml:math id="inf175"><mml:mrow><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> have unambiguous signs:<disp-formula id="equ25"><label>(A11)</label><mml:math id="m25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>6</mml:mn><mml:mi>π</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>6</mml:mn><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup></mml:mfrac><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mi>π</mml:mi><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mi>z</mml:mi><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>6</mml:mn><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mfrac><mml:mn>3</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>6</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>σ</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>β</mml:mi><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>4</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>6</mml:mn><mml:mi>π</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>6</mml:mn><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mfrac><mml:mn>3</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Replacing the expression for <inline-formula><mml:math id="inf176"><mml:mrow><mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mi>z</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ25">Equation A11</xref> into <xref ref-type="disp-formula" rid="equ24">Equation A10</xref> now yields:<disp-formula id="equ26"><label>(A12)</label><mml:math id="m26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>∝</mml:mo><mml:mn>3</mml:mn><mml:mi>β</mml:mi><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>4</mml:mn></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>6</mml:mn><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mfrac><mml:mn>3</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>∝</mml:mo><mml:mi>β</mml:mi><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>4</mml:mn></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>π</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:msqrt><mml:mn>6</mml:mn><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>At the limit <inline-formula><mml:math id="inf177"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow><mml:mo>→</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, then: <inline-formula><mml:math id="inf178"><mml:mrow><mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf179"><mml:mrow><mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. However, one can see from <xref ref-type="disp-formula" rid="equ26">Equation A12</xref> that there may be a critical value for <inline-formula><mml:math id="inf180"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, above which the gradient <inline-formula><mml:math id="inf181"><mml:mrow><mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mo>∂</mml:mo><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> will eventually become negative. This means that the amount of allocated resources will behave as a bell-shaped function of <inline-formula><mml:math id="inf182"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mn>0</mml:mn></mml:msup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. This may not be the case along the <inline-formula><mml:math id="inf183"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> direction though, because <inline-formula><mml:math id="inf184"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup><mml:mo>≥</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and the last term in the brackets shrinks as <inline-formula><mml:math id="inf185"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> increases.</p><p>Similar derivations eventually yield expressions for the gradients of MCD-optimal confidence:<disp-formula id="equ27"><label>(A13)</label><mml:math id="m27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>3</mml:mn><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mrow><mml:mover><mml:mi>P</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>6</mml:mn><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mi>σ</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p><xref ref-type="disp-formula" rid="equ27">Equation A13</xref> implies that, under moderate type #1 efficacy (<inline-formula><mml:math id="inf186"><mml:mrow><mml:mi>β</mml:mi><mml:mo>≈</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>), MCD-optimal confidence decreases when <inline-formula><mml:math id="inf187"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> decreases and/or when <inline-formula><mml:math id="inf188"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> increases, irrespective of the amount <inline-formula><mml:math id="inf189"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> of allocated resources. In other terms, variations in choice confidence are dominated by variations in the discriminability of prior value representations.</p><p>This analysis is exemplified in <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>, which summarizes the β-effect, in terms of how MCD-optimal resource allocation and choice confidence depend upon <inline-formula><mml:math id="inf190"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf191"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>.</p><fig id="app1fig2" position="float"><label>Appendix 1—figure 2.</label><caption><title>The β-effect: MCD-optimal effort and confidence when effort has no impact on the value difference.</title><p>MCD-optimal effort (left) and confidence (right) are shown as a function of the absolute prior mean difference <inline-formula><mml:math id="inf192"><mml:mfenced close="|" open="|" separators="|"><mml:mrow><mml:mo>∆</mml:mo><mml:msup><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:math></inline-formula> (x-axis) and prior variance <inline-formula><mml:math id="inf193"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> (y-axis).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-app1-fig2-v2.tif"/></fig><p>One can see that, overall, increasing the prior variance <inline-formula><mml:math id="inf194"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> increases the resource demand, which eventually increases the MCD-optimal allocated effort <inline-formula><mml:math id="inf195"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula>. This, however, does not overcompensate for the loss of confidence incurred when increasing the prior variance. This is why the MCD-optimal confidence <inline-formula><mml:math id="inf196"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> decreases with the prior variance <inline-formula><mml:math id="inf197"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>. Note that, for the same reason, the MCD-optimal confidence increases with the absolute prior means' difference <inline-formula><mml:math id="inf198"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>Now the impact of the absolute prior means' difference <inline-formula><mml:math id="inf199"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> on <inline-formula><mml:math id="inf200"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> is less trivial. In brief, when <inline-formula><mml:math id="inf201"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is high, the MCD-optimal allocated effort <inline-formula><mml:math id="inf202"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> decreases when <inline-formula><mml:math id="inf203"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> increases. This is due to the fact that the resource demand decreases with <inline-formula><mml:math id="inf204"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. However, there is a critical value for <inline-formula><mml:math id="inf205"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, below which the MCD-optimal allocated effort <inline-formula><mml:math id="inf206"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula><italic>increases</italic> with <inline-formula><mml:math id="inf207"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. This is because, although the resource demand still increases when <inline-formula><mml:math id="inf208"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> decreases, the cost of allocating resources overcompensates the gain in confidence. For such difficult decisions, the system does not follow the demand anymore, and progressively de-motivates the allocation of resources as <inline-formula><mml:math id="inf209"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> continues to decrease. In brief, the amount <inline-formula><mml:math id="inf210"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> of allocated resources decreases away from a 'sweet spot', which is the absolute prior means' difference that yields the maximal confidence gain per effort unit. Critically, the position of this sweet spot along the <inline-formula><mml:math id="inf211"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> dimension decreases with <inline-formula><mml:math id="inf212"><mml:mi>β</mml:mi></mml:math></inline-formula> and increases with <inline-formula><mml:math id="inf213"><mml:mi>α</mml:mi></mml:math></inline-formula>. This is because confidence gain increases, by definition, with effort efficacy, whereas it becomes more costly when <inline-formula><mml:math id="inf214"><mml:mi>α</mml:mi></mml:math></inline-formula> increases.</p><p>Second, let us ask what would be the MCD-optimal effort <inline-formula><mml:math id="inf215"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> and confidence <inline-formula><mml:math id="inf216"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> when <inline-formula><mml:math id="inf217"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, that is, if the only effect of allocating resources is to perturb the value difference. The ensuing 'γ -effect' is depicted in <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3</xref>.</p><fig id="app1fig3" position="float"><label>Appendix 1—figure 3.</label><caption><title>The γ-effect: MCD-optimal effort and confidence when effort has no impact on value precision.</title><p>Same format as <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-app1-fig3-v2.tif"/></fig><p>In brief, the overall picture is reversed, with a few minor differences. One can see that increasing the absolute prior means' difference <inline-formula><mml:math id="inf218"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> decreases the resource demand, which eventually decreases the MCD-optimal allocated effort <inline-formula><mml:math id="inf219"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula>. This can decrease confidence, if <inline-formula><mml:math id="inf220"><mml:mi>γ</mml:mi></mml:math></inline-formula> is high enough to overcompensate the effect of variations in <inline-formula><mml:math id="inf221"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. When no effort is allocated, however, confidence is driven by <inline-formula><mml:math id="inf222"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, that is, it becomes an increasing function of <inline-formula><mml:math id="inf223"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. In contrast, variations in the prior variance <inline-formula><mml:math id="inf224"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> always overcompensate the ensuing changes in effort, which is why confidence always decreases with <inline-formula><mml:math id="inf225"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>. In addition, the amount <inline-formula><mml:math id="inf226"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> of allocated resources decreases away from a sweet prior variance spot, which is the prior variance <inline-formula><mml:math id="inf227"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> that yields the maximal confidence gain per effort unit. Critically, the position of this sweet spot increases with <inline-formula><mml:math id="inf228"><mml:mi>γ</mml:mi></mml:math></inline-formula> and decreases with <inline-formula><mml:math id="inf229"><mml:mi>α</mml:mi></mml:math></inline-formula>, for reasons similar to the β-effect.</p><p>Now one can ask what happens in the presence of both the β-effect and the γ-effect. If the effort unitary cost <inline-formula><mml:math id="inf230"><mml:mi>α</mml:mi></mml:math></inline-formula> is high enough, the MCD-optimal effort allocation is essentially the superposition of both effects. This means that there are two 'sweet spots': one around some value of <inline-formula><mml:math id="inf231"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> at high <inline-formula><mml:math id="inf232"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> (β-effect) and one around some value of <inline-formula><mml:math id="inf233"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> at high <inline-formula><mml:math id="inf234"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (γ-effect). If the effort unitary cost <inline-formula><mml:math id="inf235"><mml:mi>α</mml:mi></mml:math></inline-formula> decreases, then the position of the β-sweet spot increases and that of the β-sweet spot decreases, until they effectively merge together. This is exemplified in <xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4</xref>.</p><fig id="app1fig4" position="float"><label>Appendix 1—figure 4.</label><caption><title>MCD-optimal effort and confidence when both types of effort efficacy are operant.</title><p>Same format as <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-app1-fig4-v2.tif"/></fig><p>One can see that, somewhat paradoxically, the effort response is now much simpler. In brief, the MCD-optimal effort allocation <inline-formula><mml:math id="inf236"><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> increases with the prior variance <inline-formula><mml:math id="inf237"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> and decreases with the absolute prior means' difference <inline-formula><mml:math id="inf238"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The landscape of the ensuing MCD-optimal confidence level <inline-formula><mml:math id="inf239"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>P</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is slightly less trivial, but globally, it can be thought of as increasing with <inline-formula><mml:math id="inf240"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and decreasing with <inline-formula><mml:math id="inf241"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>. Here again, this is because variations in <inline-formula><mml:math id="inf242"><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and/or <inline-formula><mml:math id="inf243"><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> almost always overcompensate the ensuing effects of changes in allocated effort.</p></sec><sec id="s10" sec-type="appendix"><title>3. On MCD parameter estimation</title><p>Let <inline-formula><mml:math id="inf244"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> be a 6 × 1 vector composed of measured choice confidence, spreading of alternatives, value certainty gain, change of mind, response time, and subjective effort rating on trial <inline-formula><mml:math id="inf245"><mml:mi>t</mml:mi></mml:math></inline-formula>. Let <inline-formula><mml:math id="inf246"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> be a 4 × 1 vector, whose two first entries are composed of pre-choice value difference (ΔVR<sup>0</sup>) and average value certainty (VCR<sup>0</sup>) ratings, and whose two last entries encode consequential and penalized trials. Finally, let <inline-formula><mml:math id="inf247"><mml:mi>φ</mml:mi></mml:math></inline-formula> be the set of unknown MCD parameters (i.e., intrinsic effort cost <inline-formula><mml:math id="inf248"><mml:mi>α</mml:mi></mml:math></inline-formula> and effort efficacies <inline-formula><mml:math id="inf249"><mml:mi>β</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf250"><mml:mi>γ</mml:mi></mml:math></inline-formula>), augmented with condition-effect parameters and affine transform parameters (see below). From a statistical perspective, the MCD model then reduces to the following observation equation:<disp-formula id="equ28"><label>(A14)</label><mml:math id="m28"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>ε</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf251"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula> denotes data that have been z-scored across trials, <inline-formula><mml:math id="inf252"><mml:mrow><mml:msub><mml:mi>ε</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are model residuals, and the observation mapping <inline-formula><mml:math id="inf253"><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is given by:<disp-formula id="equ29"><label>(A15)</label><mml:math id="m29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnalign="center center" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi>π</mml:mi><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:msqrt><mml:mn>3</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>2</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mi>V</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>μ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msqrt></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:mi>γ</mml:mi><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mi>π</mml:mi></mml:mfrac></mml:msqrt><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mi>γ</mml:mi><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mi>s</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi>π</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:msqrt><mml:mn>6</mml:mn><mml:mi>γ</mml:mi><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mi>β</mml:mi><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>6</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mn>6</mml:mn></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:mrow><mml:mover><mml:mi>z</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf254"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf255"><mml:mrow><mml:mi>V</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>Δ</mml:mi><mml:mi>μ</mml:mi></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> depend upon <inline-formula><mml:math id="inf256"><mml:mi>γ</mml:mi></mml:math></inline-formula> (see <xref ref-type="disp-formula" rid="equ7 equ8">Equations 7 and 8</xref> in the main text). In <xref ref-type="disp-formula" rid="equ29">Equation A15</xref>, <inline-formula><mml:math id="inf257"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf258"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> are the unknown offset and slope parameters of the (nuisance) affine transform on MCD outputs. Note that when fitting the MCD model to empirical data, theoretical pre-choice value difference and value certainty ratings are replaced by their empirical proxies, that is, <inline-formula><mml:math id="inf259"><mml:mrow><mml:mi>Δ</mml:mi><mml:msup><mml:mi>μ</mml:mi><mml:mn>0</mml:mn></mml:msup><mml:mo>≈</mml:mo><mml:mi>Δ</mml:mi><mml:msup><mml:mrow><mml:mtext>VR</mml:mtext></mml:mrow><mml:mn>0</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf260"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow/><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:mrow><mml:mo>≈</mml:mo><mml:msup><mml:mrow><mml:mtext>VCR</mml:mtext></mml:mrow><mml:mn>0</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula>. In turn, given MCD parameters, <xref ref-type="disp-formula" rid="equ28 equ29">Equations A14 and A15</xref> predict trial-by-trial variations in choice confidence, spreading of alternatives, value certainty gain, change of mind, response time, and subjective effort rating from variations in prior moments of value representations. We note that <xref ref-type="disp-formula" rid="equ29">Equation A15</xref> does not yet include condition-specific effects. As we will see, it will be easier to complete the definition of model parameters <inline-formula><mml:math id="inf261"><mml:mi>φ</mml:mi></mml:math></inline-formula> once we have explained the variational Laplace scheme for parameter estimation.</p><p>Recall that the variational Laplace scheme is an iterative algorithm that indirectly optimizes an approximation to both the model evidence <inline-formula><mml:math id="inf262"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and the posterior density <inline-formula><mml:math id="inf263"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf264"><mml:mi>m</mml:mi></mml:math></inline-formula> is the so-called generative model (i.e., the set of assumptions that are required for inference). The key trick is to decompose the log model evidence into:<disp-formula id="equ30"><mml:math id="m30"><mml:mrow><mml:mi>ln</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>;</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf265"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is any arbitrary density over the model parameters, <inline-formula><mml:math id="inf266"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>K</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the Kullback-Leibler divergence and the so-called <italic>free energy</italic> <inline-formula><mml:math id="inf267"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, defined as:<disp-formula id="equ31"><mml:math id="m31"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>⟨</mml:mo> <mml:mrow><mml:mi>ln</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>ln</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow></mml:mrow><mml:mi>q</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>S</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf268"><mml:mrow><mml:mi>S</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the Shannon entropy of <inline-formula><mml:math id="inf269"><mml:mi>q</mml:mi></mml:math></inline-formula> and the expectation <inline-formula><mml:math id="inf270"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mo>⟨</mml:mo> <mml:mo>·</mml:mo> <mml:mo>⟩</mml:mo></mml:mrow></mml:mrow><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is taken under <inline-formula><mml:math id="inf271"><mml:mi>q</mml:mi></mml:math></inline-formula>.</p><p>From <xref ref-type="disp-formula" rid="equ30">Equation A16</xref>, maximizing the functional <inline-formula><mml:math id="inf272"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> w.r.t. <inline-formula><mml:math id="inf273"><mml:mi>q</mml:mi></mml:math></inline-formula> indirectly minimizes the Kullback-Leibler divergence between <inline-formula><mml:math id="inf274"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and the exact posterior <inline-formula><mml:math id="inf275"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. This decomposition is complete in the sense that if <inline-formula><mml:math id="inf276"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, then <inline-formula><mml:math id="inf277"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>ln</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>The variational Laplace algorithm iteratively maximizes the free energy <inline-formula><mml:math id="inf278"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> under simplifying assumptions (see below) about the functional form of <inline-formula><mml:math id="inf279"><mml:mi>q</mml:mi></mml:math></inline-formula>, rendering <inline-formula><mml:math id="inf280"><mml:mi>q</mml:mi></mml:math></inline-formula> an approximate posterior density over model parameters and <inline-formula><mml:math id="inf281"><mml:mrow><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> an approximate log model evidence (<xref ref-type="bibr" rid="bib11">Daunizeau, 2017a</xref>; <xref ref-type="bibr" rid="bib23">Friston et al., 2007</xref>). The free energy optimization is then made with respect to the sufficient statistics of <inline-formula><mml:math id="inf282"><mml:mi>q</mml:mi></mml:math></inline-formula>, which makes the algorithm generic, quick, and efficient.</p><p>Under normal i.i.d. model residuals (i.e., <inline-formula><mml:math id="inf283"><mml:mrow><mml:msub><mml:mi>ε</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>), the likelihood function writes:<disp-formula id="equ32"><label>(A18)</label><mml:math id="m32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:munder><mml:mo>∏</mml:mo><mml:mi>t</mml:mi></mml:munder><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:munder><mml:mo>∏</mml:mo><mml:mi>t</mml:mi></mml:munder><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>λ</mml:mi></mml:mfrac><mml:mi>I</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf284"><mml:mi>λ</mml:mi></mml:math></inline-formula> is the residuals' precision or inverse variance hyperparameter and the observation mapping <inline-formula><mml:math id="inf285"><mml:mrow><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is given in <xref ref-type="disp-formula" rid="equ29">Equation A15</xref>.</p><p>We also use Gaussian priors <inline-formula><mml:math id="inf286"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>Σ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for model parameters and gamma priors for precision hyperparameters <inline-formula><mml:math id="inf287"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>G</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>ϖ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>κ</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>In what follows, we derive the variational Laplace algorithm under a 'mean-field' separability assumption between parameters and hyperparameters, that is: <inline-formula><mml:math id="inf288"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. We will see that this eventually yields a Gaussian posterior density <inline-formula><mml:math id="inf289"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>η</mml:mi><mml:mo>,</mml:mo><mml:mi>Σ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> on model parameters, and a Gamma posterior density <inline-formula><mml:math id="inf290"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>G</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ϖ</mml:mi><mml:mo>,</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> on the precision hyperparameter.</p><p>First, let us note that, under the Laplace approximation, the free energy bound on the log-model evidence can be written as:<disp-formula id="equ33"><label>(A19)</label><mml:math id="m33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>⟨</mml:mo><mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>⟩</mml:mo></mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>S</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>S</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>≈</mml:mo><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>η</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>φ</mml:mi></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mo>+</mml:mo><mml:mi>ϖ</mml:mi><mml:mo>−</mml:mo><mml:mi>l</mml:mi><mml:mi>n</mml:mi><mml:mi>κ</mml:mi><mml:mo>+</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi mathvariant="normal">Γ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>ϖ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>ϖ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>ϖ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf291"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>φ</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the number of parameters, <inline-formula><mml:math id="inf292"><mml:mrow><mml:mi>Γ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the gamma function, <inline-formula><mml:math id="inf293"><mml:mrow><mml:mi>ψ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mo>·</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the digamma function, and <inline-formula><mml:math id="inf294"><mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is defined as:<disp-formula id="equ34"><label>(A20)</label><mml:math id="m34"><mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mrow><mml:mo>⟨</mml:mo> <mml:mrow><mml:mi>log</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>log</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>log</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow> <mml:mo>⟩</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>Given the Gamma posterior <inline-formula><mml:math id="inf295"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> on the precision hyperparameter, <inline-formula><mml:math id="inf296"><mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> can be simply expressed as follows:<disp-formula id="equ35"><label>(A21)</label><mml:math id="m35"><mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:msub><mml:mi>Σ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:msup><mml:mrow/><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>η</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>λ</mml:mi> <mml:mo>⟩</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mstyle displaystyle="true"><mml:munder><mml:mo>∑</mml:mo><mml:mi>t</mml:mi></mml:munder><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula>where we have ignored the terms that do not depend upon <inline-formula><mml:math id="inf297"><mml:mi>φ</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf298"><mml:mrow><mml:mrow><mml:mo>⟨</mml:mo> <mml:mi>λ</mml:mi> <mml:mo>⟩</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>λ</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:mrow> <mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>ϖ</mml:mi><mml:mo>/</mml:mo><mml:mi>κ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is the posterior mean of the data precision hyperparameter <inline-formula><mml:math id="inf299"><mml:mi>λ</mml:mi></mml:math></inline-formula>.</p><p>The variational Laplace update rule for the approximate posterior density <inline-formula><mml:math id="inf300"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> on model parameters now simply reduces to an update rule for its sufficient statistics:<disp-formula id="equ36"><label>(A22)</label><mml:math id="m36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≈</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>η</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Σ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>:</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>η</mml:mi><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mtext> </mml:mtext><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mspace width="1em"/><mml:mi>φ</mml:mi></mml:mrow></mml:munder><mml:mtext> </mml:mtext><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msup><mml:mi>φ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>η</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>In <xref ref-type="disp-formula" rid="equ36">Equation A22</xref>, the first-order moment <inline-formula><mml:math id="inf301"><mml:mi>η</mml:mi></mml:math></inline-formula> of <inline-formula><mml:math id="inf302"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is obtained from the following Gauss-Newton iterative gradient ascent scheme:<disp-formula id="equ37"><label>(A23)</label><mml:math id="m37"><mml:mrow><mml:mi>η</mml:mi><mml:mo>←</mml:mo><mml:mi>η</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mo>∂</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:msup><mml:mi>φ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mi>η</mml:mi></mml:msub></mml:mrow> <mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mo>∂</mml:mo><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mo>∂</mml:mo><mml:mi>φ</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mi>η</mml:mi></mml:msub></mml:mrow></mml:math></disp-formula>where the gradient and Hessians of <inline-formula><mml:math id="inf303"><mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are given by:<disp-formula id="equ38"><label>(A24)</label><mml:math id="m38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>φ</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msubsup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>φ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:mi>λ</mml:mi><mml:mo>⟩</mml:mo></mml:mrow><mml:msup><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>φ</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:munder><mml:mo>∑</mml:mo><mml:mi>t</mml:mi></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>φ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msup><mml:mi>φ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>≈</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:mi>λ</mml:mi><mml:mo>⟩</mml:mo></mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mi>t</mml:mi></mml:munder><mml:msup><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>φ</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>φ</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>At convergence of the above gradient ascent, the approximate posterior density <inline-formula><mml:math id="inf304"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> on the precision hyperparameter is updated as follows:<disp-formula id="equ39"><label>(A25)</label><mml:math id="m39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>λ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>G</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>ϖ</mml:mi><mml:mo>,</mml:mo><mml:mi>κ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>:</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>ϖ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>ϖ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>3</mml:mn><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>κ</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mi>t</mml:mi></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>η</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>η</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>φ</mml:mi></mml:mrow></mml:mfrac><mml:msubsup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>η</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>g</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>φ</mml:mi></mml:mrow></mml:mfrac><mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi>η</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf305"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the number of trials.</p><p>The variational Laplace scheme alternates between <xref ref-type="disp-formula" rid="equ36 equ39">Equations A22 and A25</xref> iteratively until convergence of the free energy.</p><p>Now, let us complete the definition of the model parameter vector <inline-formula><mml:math id="inf306"><mml:mrow><mml:mi>φ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mn>17</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>.</p><p>First, note that effort efficiency parameters are necessarily positive. Enforcing this constraint can be done using the following simple change of variable in <xref ref-type="disp-formula" rid="equ29">Equation A15</xref>: <inline-formula><mml:math id="inf307"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf308"><mml:mrow><mml:mi>γ</mml:mi><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. In other words, <inline-formula><mml:math id="inf309"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> effectively measure efficiency parameters in log-space. Second, recall that we want to insert condition-specific effects in the model. More precisely, we expect ‘consequential’ decisions to be more important than ‘neutral’ ones, and ‘penalized’ decisions effectively include an extraneous cost-of-time term. One can model the former condition effect by making <inline-formula><mml:math id="inf310"><mml:mi>R</mml:mi></mml:math></inline-formula> (<xref ref-type="disp-formula" rid="equ2">Equation 2</xref> in the main text) sensitive to whether the decision is consequential (<inline-formula><mml:math id="inf311"><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mrow/><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) or not (<inline-formula><mml:math id="inf312"><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mrow/><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>), that is: <inline-formula><mml:math id="inf313"><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf314"><mml:mi>t</mml:mi></mml:math></inline-formula> indexes trials, and <inline-formula><mml:math id="inf315"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is the unknown weight of consequential choices on decision importance. This parameterization makes decision importance necessarily positive, and forces non-consequential trials to act as reference choices (in the sense that their decision importance is set to 1). We proxy the latter condition effect by making the effort unitary cost a function of whether the decision is penalized (<inline-formula><mml:math id="inf316"><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mrow/><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) or not (<inline-formula><mml:math id="inf317"><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mrow/><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>), that is: <inline-formula><mml:math id="inf318"><mml:mrow><mml:msub><mml:mi>α</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mn>4</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mn>5</mml:mn></mml:msub><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf319"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mn>4</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is the unknown intrinsic effort cost (in log-space), and <inline-formula><mml:math id="inf320"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mn>5</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is the unknown weight of penalized choices on effort cost. The remaining parameters <inline-formula><mml:math id="inf321"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mn>6</mml:mn><mml:mo>:</mml:mo><mml:mn>17</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> lump the offsets (<inline-formula><mml:math id="inf322"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>) and log-slopes (<inline-formula><mml:math id="inf323"><mml:mrow><mml:mi>log</mml:mi><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>: this enforces a positivity constraint on slope parameters) of the affine transform.</p><p>Finally, we set the prior probability density functions on model parameters and hyperparameters as follows:</p><list list-type="bullet"><list-item><p><inline-formula><mml:math id="inf324"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>|</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>∀</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula>, that is, the prior mean of model parameters is <inline-formula><mml:math id="inf325"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and their prior variance is <inline-formula><mml:math id="inf326"><mml:mrow><mml:msub><mml:mi>Σ</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>×</mml:mo><mml:mi>I</mml:mi></mml:mrow></mml:math></inline-formula>.</p></list-item><list-item><p><inline-formula><mml:math id="inf327"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>G</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Since the data has been z-scored prior to model inversion, this ensures that the prior and likelihood components of <inline-formula><mml:math id="inf328"><mml:mrow><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are balanced when the variational Laplace algorithm starts.</p></list-item></list><p>This completes the description of the variational Laplace approach to MCD inversion. For more details, we refer the interested reader to the existing literature on variational approaches to approximate Bayesian inference (<xref ref-type="bibr" rid="bib2">Beal, 2003</xref>; <xref ref-type="bibr" rid="bib12">Daunizeau, 2017b</xref>; <xref ref-type="bibr" rid="bib23">Friston et al., 2007</xref>). We note that the above variational Laplace approach is implemented in the opensource VBA toolbox (<xref ref-type="bibr" rid="bib10">Daunizeau et al., 2014</xref>).</p><p>In what follows, we use Monte-Carlo numerical simulations to evaluate the ability of this approach to recover MCD parameters. Our parameter recovery analyses proceed as follows. First, we sample a set of model parameters <inline-formula><mml:math id="inf329"><mml:mi>φ</mml:mi></mml:math></inline-formula> under a standard i.i.d. normal distribution. Here, we refer to <inline-formula><mml:math id="inf330"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> as <italic>i</italic><sup>th</sup> element of <inline-formula><mml:math id="inf331"><mml:mi>φ</mml:mi></mml:math></inline-formula> at the <italic>j</italic><sup>th</sup> Monte-Carlo simulation. Second, for each of these parameter set <inline-formula><mml:math id="inf332"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mo>·</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, we simulate a series of N=100 decision trials according to <xref ref-type="disp-formula" rid="equ28 equ29">Equation A14 and A15</xref> above (under random prior moments of value representations). Note that we set the variance of model residuals (<inline-formula><mml:math id="inf333"><mml:mi>ε</mml:mi></mml:math></inline-formula> in <xref ref-type="disp-formula" rid="equ28">Equation A14</xref>) to match the average correlation between MCD predictions and empirical data (about 20%, see <xref ref-type="fig" rid="fig4">Figure 4</xref> in the main text). We also used the same rate of neutral, consequential, and penalized choices as in our experiment. Third, we fit the model to the resulting simulated data (after z-scoring) and extract parameter estimates <inline-formula><mml:math id="inf334"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mrow><mml:mo>·</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> (at convergence of the variational Laplace approach). We repeat these three steps 1000 times, yielding a series of 1000 simulated parameter sets, and their corresponding 1000 estimated parameters sets. Should <inline-formula><mml:math id="inf335"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mrow><mml:mo>·</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>≈</mml:mo><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mo>·</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo>∀</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula>, then parameter recovery would be perfect. <xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5</xref> compares simulated and estimated parameters to each other across Monte-Carlo simulations. Note that we only report recovery results for <inline-formula><mml:math id="inf336"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>:</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, since we do not care about nuisance affine transform parameters.</p><p>We also quantify pairwise non-identifiability issues, which arise when the estimation method confuses two parameters with each other. We do this using the so-called ‘recovery matrices’, which summarize whether variations (across the 1000 Monte-Carlo simulations) in estimated parameters faithfully capture variations in simulated parameters. We first z-score simulated and estimated parameters across Monte-Carlo simulations. We then regress each estimated parameter against all simulated parameters through the following multiple linear regression model:<disp-formula id="equ40"><label>(A26)</label><mml:math id="m40"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>'</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>5</mml:mn></mml:munderover><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi><mml:mo>'</mml:mo></mml:mrow><mml:mrow/></mml:msubsup><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>'</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle><mml:mo>+</mml:mo><mml:msubsup><mml:mi>ς</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow/></mml:msubsup></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf337"><mml:msubsup><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi><mml:mi>'</mml:mi></mml:mrow><mml:mrow/></mml:msubsup></mml:math></inline-formula> are regression weights, and <inline-formula><mml:math id="inf338"><mml:mrow><mml:msubsup><mml:mi>ς</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mrow/></mml:msubsup></mml:mrow></mml:math></inline-formula> are regression residuals. Here, regression weights are partial correlation coefficients between simulated and estimated parameters (across Monte-Carlo simulations). More precisely, <inline-formula><mml:math id="inf339"><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi><mml:mo>'</mml:mo></mml:mrow><mml:mrow/></mml:msubsup></mml:mrow></mml:math></inline-formula> quantifies the impact that variations of the simulated parameter <inline-formula><mml:math id="inf340"><mml:mrow><mml:msubsup><mml:mi>φ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>'</mml:mo><mml:mo>·</mml:mo></mml:mrow><mml:mrow/></mml:msubsup></mml:mrow></mml:math></inline-formula> have on variations of the estimated parameter <inline-formula><mml:math id="inf341"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>·</mml:mo></mml:mrow><mml:mrow/></mml:msubsup></mml:mrow></mml:math></inline-formula>, conditional on all other simulated parameters. Would parameters be perfectly identifiable, then <inline-formula><mml:math id="inf342"><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>≈</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf343"><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi><mml:mo>'</mml:mo></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>≈</mml:mo><mml:mn>0</mml:mn><mml:mtext> </mml:mtext><mml:mo>∀</mml:mo><mml:mi>i</mml:mi><mml:mo>'</mml:mo><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula>. Pairwise non-identifiability issues arise when <inline-formula><mml:math id="inf344"><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi><mml:mo>'</mml:mo></mml:mrow><mml:mrow/></mml:msubsup><mml:mo>≠</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. In other words, the regression model in <xref ref-type="disp-formula" rid="equ40">Equation A26</xref> effectively decomposes the observed variability in the series of estimated parameter <inline-formula><mml:math id="inf345"><mml:mrow><mml:msubsup><mml:mi>η</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>·</mml:mo></mml:mrow><mml:mrow/></mml:msubsup></mml:mrow></mml:math></inline-formula> into 'correct variations' that are induced by variations in the corresponding simulated parameter <inline-formula><mml:math id="inf346"><mml:mrow><mml:msubsup><mml:mi>φ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>·</mml:mo></mml:mrow><mml:mrow/></mml:msubsup></mml:mrow></mml:math></inline-formula>, and 'incorrect variations' that are induced by the remaining simulated parameters <inline-formula><mml:math id="inf347"><mml:mrow><mml:msubsup><mml:mi>φ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>'</mml:mo><mml:mo>·</mml:mo></mml:mrow><mml:mrow/></mml:msubsup></mml:mrow></mml:math></inline-formula> (with <inline-formula><mml:math id="inf348"><mml:mrow><mml:mi>i</mml:mi><mml:mo>'</mml:mo><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:math></inline-formula>). This analysis is then summarized in terms of 'recovery matrices', which simply report the squared regression weights <inline-formula><mml:math id="inf349"><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi><mml:mo>'</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> for each simulated parameter (see right panel of <xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5</xref>).</p><fig id="app1fig5" position="float"><label>Appendix 1—figure 5.</label><caption><title>Comparison of simulated and estimated MCD parameters.</title><p>Left panel: estimated parameters (y-axis) are plotted against simulated parameters (x-axis). Each dot is a Monte-Carlo simulation and different colors indicate distinct parameters (blue: efficacy type #1, red: efficacy type #2, yellow: unknown weight of consequential choices on decision importance, violet: intrinsic cost of effort, green: unknown weight of penalized choices on effort cost). The black dotted line indicates the identity line (perfect estimation). Right panel: Parameter recovery matrix: each line shows the squared partial correlation coefficient between a given estimated parameter and each simulated parameter (across 1000 Monte-Carlo simulations). Diagonal elements of the recovery matrix measure ‘correct estimation variability’, i.e. variations in the estimated parameters that are due to variations in the corresponding simulated parameter. In contrast, non-diagonal elements of the recovery matrix measure ‘incorrect estimation variability’, that is, variations in the estimated parameters that are due to variations in other parameters. Perfect recovery would thus exhibit a diagonal structure, where variations in each estimated parameter are only due to variations in the corresponding simulated parameter. In contrast, strong non-diagonal elements in recovery matrices signal pairwise non-identifiability issues.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-app1-fig5-v2.tif"/></fig><p>One can see that parameter recovery is far from perfect. This is in fact expected, given the high amount of simulation noise. However, no parameter estimate exhibits any noticeable estimation bias, that is, estimation error is non-systematic and directly results from limited data reliability. Recovery matrices provide further quantitative insight regarding the accuracy of parameter estimation.</p><p>First, variability in all parameter estimates is mostly driven by variability in the corresponding simulated parameter (amount of 'correct variability': <inline-formula><mml:math id="inf350"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>: 5.3%, <inline-formula><mml:math id="inf351"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>: 17.4%, <inline-formula><mml:math id="inf352"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mn>4</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>: 22.1%, <inline-formula><mml:math id="inf353"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mn>5</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>: 22.7%, to be compared with 'incorrect variability' – see below), except for type #1 efficacy (<inline-formula><mml:math id="inf354"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>: 0.3%). The latter estimate is thus comparatively much less efficient than other MCD parameters. This is because <inline-formula><mml:math id="inf355"><mml:mrow><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> only has a limited impact on MCD outputs. Second, there are no strong non-identifiability issues (total amount of 'incorrect invariability' is always below 2.7%, even when including nuisance affine transform parameters <inline-formula><mml:math id="inf356"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mrow><mml:mn>6</mml:mn><mml:mo>:</mml:mo><mml:mn>17</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>), except for type #2 effort efficacy. In particular, the latter estimate may be partly confused with intrinsic effort cost (amount of “incorrect variability” driven by <inline-formula><mml:math id="inf357"><mml:mrow><mml:msub><mml:mi>φ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>: 1.6%).</p><p>Having said this, the reliability of MCD parameter recovery is globally much weaker than in the ideal case, where data is not polluted with simulation noise (the amount of ‘correct variability’ in this case is higher than 95% for all parameters – results not shown). This means that acquiring data of higher quality and/or quantity may significantly improve inference on MCD parameters.</p><p>We note that the weak identifiability of type #1 effort efficacy (β) does not imply that some dependent variables will be less well predicted/postdicted than others. Recall that β indirectly influences all dependent variables, through its impact on the optimal amount of allocated resources. Therefore, all dependent variables provide information about β. Importantly, some dependent variables are more useful than others for estimating β. If empirical measures of these variables become unreliable (e.g., because they are very noisy), then β will not be identifiable. However, the reverse is not true. In fact, in our recovery analysis, we found no difference in postdiction accuracy across dependent variables. Now, the question of whether weak β identifiability may explain (out-of-sample) prediction errors regarding the impact of MCD input variables (such as ΔVR0) on dependent variables is more subtle. This is because, by construction, MCD parameters control the way MCD input variables eventually influence dependent variables. As one can see from the analytical derivations in section 2 of this Appendix, the impact of input variables on MCD dependent variables (in particular, the optimal amount of allocated resources) depends upon whether β dominates effort efficacy (cf. ‘β-effect’) or not (cf. ‘γ-effect’). For example, if β dominates, then the relationship between ΔVR<sup>0</sup> and effort is bell-shaped (cf. Figure S6), whereas it is monotonic if β = 0 (cf. Figure S7). This means that estimation errors on β may confuse the predicted relationship between input variables and MCD dependent variables.</p></sec><sec id="s11" sec-type="appendix"><title>4. Data descriptive statistics and sanity checks</title><p>Recall that we collect value ratings and value certainty ratings both before and after the choice session. We did this for the purpose of validating specific predictions of the MCD model (in particular: choice-induced preference changes: see <xref ref-type="fig" rid="fig10">Figure 10</xref> in the main text). It turns out this also enables us to assess the test–retest reliability of both value and value certainty ratings. We found that both ratings were significantly reproducible (value: mean correlation = 0.88, s.e.m. = 0.01, p&lt;0.001, value certainty: mean correlation = 0.37, s.e.m. = 0.04, p&lt;0.001).</p><p>We also checked whether choices were consistent with pre-choice ratings. For each participant, we thus performed a logistic regression of choices against the difference in value ratings. We found that the balanced prediction accuracy was beyond chance level (mean accuracy=0.68, s.e.m.=0.01, p&lt;0.001).</p></sec><sec id="s12" sec-type="appendix"><title>5. Does choice confidence moderate the relationship between choice and pre-choice value ratings?</title><p>Previous studies regarding confidence in value-base choices showed that choice confidence moderates choice prediction accuracy (<xref ref-type="bibr" rid="bib14">De Martino et al., 2013</xref>). We thus split our logistic regression of choices into high- and low-confidence trials, and tested whether higher confidence was consistently associated with increased choice accuracy. A random effect analysis showed that the regression slopes were significantly higher for high- than for low-confidence trials (mean slope difference = 0.14, s.e.m. = 0.03, p&lt;0.001). For the sake of completeness, the impact of choice confidence on the slope of the logistic regression (of choice onto the difference in pre-choice value ratings) is shown in <xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref>.</p><fig id="app1fig6" position="float"><label>Appendix 1—figure 6.</label><caption><title>Relationship between choices, pre-choice value ratings, and choice confidence.</title><p>Left panel: the probability of choosing the item on the right (y-axis) is shown as a function of the pre-choice value difference (x-axis), for high- (blue) versus low- (red) confidence trials. The plain lines show the logistic prediction that would follow from group-averages of the corresponding slope estimates. Right panel: the corresponding logistic regression slope (y-axis) is shown for both high- (blue) and low- (red) confidence trials (group means ± s.e.m.).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-app1-fig6-v2.tif"/></fig><p>These results clearly replicate the findings of <xref ref-type="bibr" rid="bib14">De Martino et al., 2013</xref>, which were interpreted with a race model variant of the accumulation-to-bound principle. We note, however, that this effect is also predicted by the MCD model. Here, variations in both (i) the prediction accuracy of choice from pre-choice value ratings and (ii) choice confidence are driven by variations in resource allocation. In brief, the expected magnitude of the perturbation of value representations increases with the amount of allocated resources. This eventually increases the probability of a change of mind. However, although more resources are allocated to the decision, this does not overcompensate for decision difficulty, and thus choice confidence decreases. Thus, low-confidence choices will be those choices that are more likely to be associated with a change of mind. We note that the anti-correlation between choice confidence and change of mind can be seen by comparing <xref ref-type="fig" rid="fig7">Figures 7</xref> and <xref ref-type="fig" rid="fig8">8</xref> in the main text.</p></sec><sec id="s13" sec-type="appendix"><title>6. How do choice confidence, difference in pre-choice value ratings, and response time relate to each other?</title><p>In the main text, we show that trial-by-trial variation in choice confidence is concurrently explained by both pre-choice value and value certainty ratings. Here, we reproduce previous findings relating choice confidence to both absolute value difference ΔVR<sup>0</sup> and response time (<xref ref-type="bibr" rid="bib14">De Martino et al., 2013</xref>). First, for each participant, we regressed response time concurrently against both |ΔVR<sup>0</sup>| and choice confidence. A random effect analysis showed that both have a significant main effect on response time (ΔVR<sup>0</sup>: mean GLM beta = −0.016, s.e.m. = 0.003, p&lt;0.001; choice confidence: mean GLM beta = −0.014, s.e.m. = 0.002; p&lt;0.001), without any two-way interaction (p=0.133). This analysis is summarized in <xref ref-type="fig" rid="app1fig7">Appendix 1—figure 7</xref>, together with the full three-way relationship between |ΔVR<sup>0</sup>|, confidence, and response time.</p><fig id="app1fig7" position="float"><label>Appendix 1—figure 7.</label><caption><title>Relationship between pre-choice value ratings, choice confidence, and response times.</title><p>Left panel: response times (y-axis) are plotted as a function of low- and high- |ΔVR<sup>0</sup>| (x-axis) for both low- (red) and high- (blue) confidence trials. Error bars represent s.e.m. Right panel: A heatmap of mean z-scored confidence is shown as a function of both response time (x-axis) and |ΔVR<sup>0</sup>| (y-axis).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-app1-fig7-v2.tif"/></fig><p>In brief, confidence increases with the absolute value difference and decreases with response time. This effect is also predicted by the MCD model, for reasons identical to the explanation of the relationship between confidence and choice accuracy (see above). Recall that, overall, an increase in choice difficulty is expected to yield an increase in response time and a decrease in choice confidence. This would produce the same data pattern as <xref ref-type="fig" rid="app1fig7">Appendix 1—figure 7</xref>, although the causal relationships implicit in this data representation is partially incongruent with the computational mechanisms underlying MCD.</p></sec><sec id="s14" sec-type="appendix"><title>7. Do post-choice ratings better predict choice and choice confidence than pre-choice ratings?</title><p>The MCD model assumes that value representations are modified during the decision process, until the MCD-optimal amount of resources is met. This eventually triggers the decision, whose properties (i.e., which alternative option is eventually preferred, and with which confidence level) then reflect the modified value representations. If post-choice ratings are reports of modified value representations at the time when the choice is triggered, then choice and its associated confidence level should be better predicted with post-choice ratings than with pre-choice ratings. In what follows, we test this prediction.</p><p>In Section 4 of this Appendix, we report the result of a logistic regression of choice against pre-choice value ratings (see also <xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref>). We performed the same regression analysis, but this time against post-choice value ratings. For each subject, we then measured the ensuing predictive power (here, in terms of balanced accuracy or BA) for both pre-choice and post-choice ratings. The main text also features the result of a multiple linear regression of choice confidence ratings onto |ΔVR<sup>0</sup>| and VCR<sup>0</sup> (<xref ref-type="fig" rid="fig8">Figure 8</xref> in the main text). Again, we performed the same regression, this time against post-choice ratings. For each subject, we then measured the ensuing predictive power (here, in terms of percentage of explained variance or R<sup>2</sup>) for both pre-choice and post-choice ratings.</p><p>A simple random effect analysis shows that the predictive power of post-choice ratings is significantly higher than that of pre-choice ratings, both for choice (mean difference in BA=7%, s.e.m.=0.01, p&lt;0.001) and choice confidence (mean difference in R<sup>2</sup>=3%, s.e.m.=0.01, p=0.004).</p></sec><sec id="s15" sec-type="appendix"><title>8. Analysis of eye-tracking data</title><p>We first checked whether pupil dilation positively correlates with participants' subjective effort ratings. We epoched the pupil size data into trial-by-trial time series, and temporally co-registered the epochs either at stimulus onset (starting 1.5 s before the stimulus onset and lasting 5 s) or at choice response (starting 3.5 s before the choice response and lasting 5 s). Data was baseline-corrected at stimulus onset. For each participant, we then regressed, at each time point during the decision, pupil size onto effort ratings (across trials). Time series of regression coefficients were then reported at the group level, and tested for statistical significance (correction for multiple comparison was performed using random field theory 1D-RFT). <xref ref-type="fig" rid="app1fig8">Appendix 1—figure 8</xref> summarizes this analysis, in terms of the baseline-corrected time series of regression coefficients.</p><fig id="app1fig8" position="float"><label>Appendix 1—figure 8.</label><caption><title>Correlation between pupil size and subjective effort ratings during decision time.</title><p>Left panel: Mean (± s.e.m.) correlation between pupil size and subjective effort (y-axis) is plotted as a function of peristimulus time (x-axis). Here, epochs are co-registered w.r.t. stimulus onset (the green line indicates stimulus onset and the red dotted line indicates the average choice response). Right panel: Same, but for epochs co-registered w.r.t. choice response (the green line indicates choice response and the red dotted line indicates the average stimulus onset).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-app1-fig8-v2.tif"/></fig><p>We found that the correlation between subjective effort ratings and pupil dilation became significant from 500 ms after stimulus onset onwards. Note that, using the same approach, we found a negative correlation between pupil dilation and pre-choice absolute value difference |ΔVR<sup>0</sup>|. However, this relationship disappeared when we entered both |ΔVR<sup>0</sup>| and effort into the same regression model.</p><p>Our eye-tracking data also allowed us to ascertain which item was being gazed at for each point in peristimulus time (during decisions). Using the choice responses, we classified each time point as a gaze at the (to be) chosen item or at the (to be) rejected item. We then derived, for each decision, the ratio of time spent gazing at chosen/rejected items versus the total duration of the decision (between stimulus onset and choice response). The difference between these two gaze ratios measures the overt attentional bias toward the chosen item. We refer to this as the gaze bias. Consistent with previous studies, we found that chosen items were gazed at more than rejected items (mean gaze bias = 0.02, s.e.m. = 0.01, p=0.067). However, we also found that this effect was in fact limited to low effort choices. <xref ref-type="fig" rid="app1fig9">Appendix 1—figure 9</xref> shows the gaze bias for low- and high-effort trials, based on a median-split of subjective effort.</p><fig id="app1fig9" position="float"><label>Appendix 1—figure 9.</label><caption><title>Gaze bias for low- and high-effort trials.</title><p>Mean (± s.e.m.) gaze bias is plotted for both low- (left) and high- (right) effort trials.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-app1-fig9-v2.tif"/></fig><p>We found that there was a significant gaze bias for low effort choices (mean gaze ratio difference = 0.033, s.e.m. = 0.013, p=0.009), but not for high effort choices (mean gaze ratio difference = 0.002, s.e.m. = 0.014, p=0.453). A potential trivial explanation for the fact that the gaze bias is large for low effort trials is that these are the trials where participants immediately recognize their favorite option, which attracts their attention. More interesting is the fact that the gaze bias is null for high effort trials. This may be taken as evidence for the fact that, on average, people allocate the same amount of (attentional) resources to both options. This is important, because we use this simplifying assumption in our MCD model derivations.</p></sec><sec id="s16" sec-type="appendix"><title>9. Comparison with evidence-accumulation (DDM) models</title><p>In the main text, we evaluate the accuracy of the MCD model predictions, without considering alternative computational scenarios. Here, we report results of a model-based data analysis that relies on the standard drift-diffusion decision or DDM model for value-based decision-making (<xref ref-type="bibr" rid="bib14">De Martino et al., 2013</xref>; <xref ref-type="bibr" rid="bib52">Lopez-Persem et al., 2016</xref>; <xref ref-type="bibr" rid="bib56">Milosavljevic et al., 2010</xref>; <xref ref-type="bibr" rid="bib68">Ratcliff et al., 2016</xref>; <xref ref-type="bibr" rid="bib80">Tajima et al., 2016</xref>).</p><p>In brief, DDMs tie together decision outcomes and response times by assuming that decisions are triggered once the accumulated evidence in favor of a particular option has reached a predefined threshold or bound (<xref ref-type="bibr" rid="bib69">Ratcliff and McKoon, 2008</xref>; <xref ref-type="bibr" rid="bib68">Ratcliff et al., 2016</xref>). Importantly here, evidence accumulation has two components: a drift term that quantifies the strength of evidence and a random diffusion term that captures some form of neural perturbation of evidence accumulation. The latter term allows choice outcomes to deviate from otherwise deterministic, evidence-driven, decisions.</p><p>Importantly, standard DDMs do not predict choice confidence, spreading of alternatives, value certainty gain, or subjective effort ratings. This is because these concepts have no straightforward definition under the standard DDM. However, DDMs can be used to make out-of-sample trial-by-trial predictions of, for example, decision outcomes, from parameter estimates obtained with response times alone. This enables a straightforward comparison of MCD and DDM frameworks, in terms of the accuracy of RT ‘postdictions’ and change of mind out-of-sample prediction. Here, we also make sure both models rely on the same inputs: namely, pre-choice value (ΔVR<sup>0</sup>) and value certainty (VCR<sup>0</sup>) ratings as well as information about task conditions.</p><p>The simplest DDM variant includes the following set of five unknown parameters: the drift rate <inline-formula><mml:math id="inf358"><mml:mi>v</mml:mi></mml:math></inline-formula>, the bound's height <inline-formula><mml:math id="inf359"><mml:mi>b</mml:mi></mml:math></inline-formula>, the standard deviation of the diffusion term <inline-formula><mml:math id="inf360"><mml:mi>σ</mml:mi></mml:math></inline-formula>, the initial decision bias <inline-formula><mml:math id="inf361"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, and the non-decision time <inline-formula><mml:math id="inf362"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. Given these model parameters, the expected response time (conditional on the decision outcome) is given by <xref ref-type="bibr" rid="bib77">Srivastava et al., 2016</xref>:<disp-formula id="equ41"><label>(A27)</label><mml:math id="m41"><mml:mrow><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>R</mml:mi><mml:mi>T</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mi>o</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mi>b</mml:mi><mml:mi>v</mml:mi></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mi>coth</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>v</mml:mi><mml:mtext> </mml:mtext><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>o</mml:mi><mml:mfrac><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mi>b</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>coth</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>o</mml:mi><mml:mfrac><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow><mml:mi>b</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mi>v</mml:mi><mml:mtext> </mml:mtext><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf363"><mml:mrow><mml:mi>o</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>{</mml:mo> <mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow> <mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the decision outcome. One can then evaluate Equation A27 at each trial, given its corresponding set of DDM parameters. In particular, if one knows how, for example, drift rates vary over trials, then one can predict the ensuing expected RT variations. In typical applications to value-based decision-making, drift rates are set proportional to the difference ΔVR<sup>0</sup> in value ratings (<xref ref-type="bibr" rid="bib14">De Martino et al., 2013</xref>; <xref ref-type="bibr" rid="bib40">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="bib52">Lopez-Persem et al., 2016</xref>; <xref ref-type="bibr" rid="bib56">Milosavljevic et al., 2010</xref>). One can then define a likelihood function for observed response times from the following observation equation: <inline-formula><mml:math id="inf364"><mml:mrow><mml:mi>R</mml:mi><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mi>E</mml:mi><mml:mrow><mml:mo>[</mml:mo> <mml:mrow><mml:mi>R</mml:mi><mml:mi>T</mml:mi><mml:mrow><mml:mo>|</mml:mo><mml:mi>o</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow> <mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>ε</mml:mi></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf365"><mml:mi>ε</mml:mi></mml:math></inline-formula> are trial-by-trial DDM residuals. The variational Laplace treatment of the ensuing generative model then yields estimates of the remaining DDM parameters.</p><p>Out-of-sample predictions of change of mind (i.e., decision errors) can then be derived from DDM parameter estimates (<xref ref-type="bibr" rid="bib6">Bogacz et al., 2006</xref>):<disp-formula id="equ42"><label>(A28)</label><mml:math id="m42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>D</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mi>P</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>o</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>≠</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>v</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>v</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>v</mml:mi><mml:mtext> </mml:mtext><mml:mi>b</mml:mi></mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>v</mml:mi><mml:mtext> </mml:mtext><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>v</mml:mi><mml:mtext> </mml:mtext><mml:mi>b</mml:mi></mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>v</mml:mi><mml:mtext> </mml:mtext><mml:mi>b</mml:mi></mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf366"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mi>D</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the DDM equivalent to the probability <inline-formula><mml:math id="inf367"><mml:mrow><mml:mi>Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>z</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of a change of mind under the MCD model (see <xref ref-type="disp-formula" rid="equ14">Equation 14</xref> in the main text).</p><p>Here, we use two modified variants of the standard DDM for value-based decisions. In all of these variants, we allow the DDM system to change its speed-accuracy tradeoff according to whether the decision is consequential (<inline-formula><mml:math id="inf368"><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mrow/><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) or not (<inline-formula><mml:math id="inf369"><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mrow/><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>), and/or ‘penalized’ (<inline-formula><mml:math id="inf370"><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mrow/><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) or not (<inline-formula><mml:math id="inf371"><mml:mrow><mml:msubsup><mml:mi>u</mml:mi><mml:mrow/><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>). This is done by enabling the decision bound to vary over trials, i.e., <inline-formula><mml:math id="inf372"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>≡</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mtext> </mml:mtext><mml:msubsup><mml:mi>u</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf373"><mml:mi>t</mml:mi></mml:math></inline-formula> indexes trials. Here, <inline-formula><mml:math id="inf374"><mml:mrow><mml:msup><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf375"><mml:mrow><mml:msup><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf376"><mml:mrow><mml:msup><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> are unknown parameters that quantify the bound's height of ‘neutral’ decisions, and the strength of ‘consequential’ and ‘penalized’ condition effects, respectively. The exponential mapping is used for imposing a positivity constraint on the resulting bound (see section 8 above). One might then expect that <inline-formula><mml:math id="inf377"><mml:mrow><mml:msup><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>c</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf378"><mml:mrow><mml:msup><mml:mi>b</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, that is, ‘consequential’ decisions demand more evidence than ‘neutral’ ones, whereas ‘penalized’ decisions favor speed over accuracy.</p><p>The two DDM variants then differ in terms of how pre-choice value certainty is taken into account (<xref ref-type="bibr" rid="bib47">Lee and Usher, 2020</xref>):</p><list list-type="bullet"><list-item><p>DDM1: at each trial, the drift rate is set to the affine-transformed certainty-weighted value difference, that is, <inline-formula><mml:math id="inf379"><mml:mrow><mml:msub><mml:mi>ν</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>≡</mml:mo><mml:msup><mml:mi>ν</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>ν</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>×</mml:mo><mml:mi>V</mml:mi><mml:mi>C</mml:mi><mml:msubsup><mml:mi>R</mml:mi><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msubsup><mml:mo>×</mml:mo><mml:mi>Δ</mml:mi><mml:mi>V</mml:mi><mml:msubsup><mml:mi>R</mml:mi><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf380"><mml:mrow><mml:msup><mml:mi>ν</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf381"><mml:mrow><mml:msup><mml:mi>ν</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> are unknown parameters that control the offset and slope of the affine transform, respectively. Here, the strength of evidence in favor of a given alternative option is measured in terms of a signal-to-noise ratio on value. Note that the diffusion standard deviation <inline-formula><mml:math id="inf382"><mml:mi>σ</mml:mi></mml:math></inline-formula> is kept fixed across trials.</p></list-item><list-item><p>DDM2: at each trial, the drift rate is set to the affine-transformed value difference, that is, <inline-formula><mml:math id="inf383"><mml:mrow><mml:msub><mml:mi>ν</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>≡</mml:mo><mml:msup><mml:mi>ν</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>ν</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>s</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>×</mml:mo><mml:mi>Δ</mml:mi><mml:mi>V</mml:mi><mml:msubsup><mml:mi>R</mml:mi><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, and the diffusion standard deviation is allowed to vary over trials with value certainty ratings: <inline-formula><mml:math id="inf384"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>≡</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>×</mml:mo><mml:mi>V</mml:mi><mml:mi>C</mml:mi><mml:msubsup><mml:mi>R</mml:mi><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Here, <inline-formula><mml:math id="inf385"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf386"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> are unknown parameters that quantify the fixed and varying components of the diffusion standard deviation, respectively. In this parameterization, value representations that are more certain will be signaled more reliably. Note that the statistical complexity of DDM2 is higher than that of DDM1 (one additional unknown parameter).</p></list-item></list><p>For each subject and each DDM variant, we estimate unknown parameters from RT data alone using <xref ref-type="disp-formula" rid="equ41">Equation A27</xref>, and derive out-of-sample predictions for changes of mind using <xref ref-type="disp-formula" rid="equ42">Equation A28</xref>. We then measure the accuracy of trial-by-trial RT postdictions and out-of-sample change of mind predictions, in terms of the correlation between observed and predicted/postdicted variables. We also perform the exact same analysis under the MCD model (this is slightly different from the analysis reported in the main text, because only RT data is included in model fitting here).</p><p>To begin with, we compare the accuracy of RT postdictions, which is summarized in <xref ref-type="fig" rid="app1fig10">Appendix 1—figure 10</xref>.</p><fig id="app1fig10" position="float"><label>Appendix 1—figure 10.</label><caption><title>Accuracy of RT postdictions.</title><p>Left panel: The mean within-subject (across-trial) correlation between observed and postdicted RT data (y-axis) is plotted for each model (gray: MCD, blue: DDM1 and DDM2); error bars depict s.e.m. Right panel: Mean z-scored log-RT (y-axis) is shown as a function of |ΔVR<sup>0</sup>| (x-axis) and VCR<sup>0</sup> (color code: blue = 0–50% lower quantile, green = 50–100% upper quantile); solid lines indicate empirical data (error bars represent s.e.m.), diamond-dashed lines represent DDM1 postdictions and star-dotted lines show DDM2 postdictions.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-app1-fig10-v2.tif"/></fig><p>One can see that the RT postdiction accuracy of both DDMs is higher than that of the MCD model. In fact, one-sample paired t-tests on the difference between DDM and MCD within-subject accuracy scores show that this comparison is statistically significant (DDM1: mean accuracy difference = 12.3%, s.e.m. = 2.6%, p&lt;10<sup>−3</sup>; DDM2: mean accuracy difference = 10.5%, s.e.m. = 2.6%, p&lt;10<sup>−3</sup>; two-sided t-tests). In addition, one can see that DDM1 accurately captures variations in RT data that are induced by ΔVR<sup>0</sup> and VCR<sup>0</sup>. However, DDM2 is unable to reproduce the impact of VCR<sup>0</sup> (cf. wrong effect direction). This is because, in DDM2, as value certainty ratings increase and the diffusion standard deviation decreases, the probability that DDM bounds are hit sooner decreases (hence prolonging RT on average). These results reproduce recent investigations of the impact of value certainty ratings on DDM predictions (<xref ref-type="bibr" rid="bib47">Lee and Usher, 2020</xref>).</p><p>Now, <xref ref-type="fig" rid="app1fig11">Appendix 1—figure 11</xref> summarizes the accuracy of out-of-sample change of mind predictions.</p><fig id="app1fig11" position="float"><label>Appendix 1—figure 11.</label><caption><title>Accuracy of out-of-sample change of mind postdictions.</title><p>Same format as <xref ref-type="fig" rid="app1fig10">Appendix 1—figure 10</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-app1-fig11-v2.tif"/></fig><p>It turns out that the MCD model exhibits the highest accuracy of out-of-sample change of mind predictions. One-sample paired t-tests on the difference between DDM and MCD within-subject accuracy scores show that this comparison reaches statistical significance for both DDM1 (mean accuracy difference=-5%, s.e.m. = 2.4%, p=0.046; two-sided t-test) and DDM2 (mean accuracy difference = −9.9%, s.e.m. = 3.4%, p=0.006; two-sided t-test). One can also see that neither DDM variant accurately predicts the effects of ΔVR<sup>0</sup> and VCR<sup>0</sup>.</p><p>In brief, the DDM framework might be better than the MCD model at capturing trial-by-trial variations in RT data. This may not be surprising, given the longstanding success of the DDM on this issue (<xref ref-type="bibr" rid="bib68">Ratcliff et al., 2016</xref>). The result of this comparison, however, depends upon how the DDM is parameterized (cf. wrong effect direction of VCR<sup>0</sup> for DDM2). More importantly, in our context, DDMs make poor out-of-sample predictions on decision outcomes, at least when compared to the MCD model. For the purpose of predicting decision-related variables from effort-related variables, one would thus favor the MCD framework.</p></sec><sec id="s17" sec-type="appendix"><title>10. Accounting for saturating γ-effect</title><p>When deriving the MCD model, we considered a linear γ-effect, that is, we assumed that the variance of the perturbation <inline-formula><mml:math id="inf387"><mml:mrow><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of value representation modes increases linearly with the amount <inline-formula><mml:math id="inf388"><mml:mi>z</mml:mi></mml:math></inline-formula> of allocated resources (<xref ref-type="disp-formula" rid="equ6">Equation 6</xref> in the main text). However, one might argue that the marginal impact of effort on the variance of <inline-formula><mml:math id="inf389"><mml:mrow><mml:mi>δ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> may decrease as further resources are allocated to the decision. In other terms, the magnitude of the perturbation (per unit of resources) that one might expect when no resources have yet been allocated may be much higher than when most resources have already been allocated. In turn, <xref ref-type="disp-formula" rid="equ6">Equation 6</xref> would be replaced by:<disp-formula id="equ43"><label>(A29)</label><mml:math id="m43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mtable columnalign="right left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>=</mml:mo><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mstyle></mml:math></disp-formula>where the variance <inline-formula><mml:math id="inf390"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> of the modes' perturbations would be a saturating function of <inline-formula><mml:math id="inf391"><mml:mi>z</mml:mi></mml:math></inline-formula>, e.g:<disp-formula id="equ44"><label>(A30)</label><mml:math id="m44"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mtext> </mml:mtext><mml:mi>z</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula><mml:math id="inf392"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is the maximum or plateau variance that perturbations can exhibit and <inline-formula><mml:math id="inf393"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is the decay rate toward the plateau variance.</p><p>It turns out that this does not change the mathematical derivations of the MCD model, that is, model predictions still follow <xref ref-type="disp-formula" rid="equ9 equ10 equ11 equ12 equ13 equ14">Equations 9–14</xref> in the main text, having replaced <inline-formula><mml:math id="inf394"><mml:mrow><mml:mi>γ</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="inf395"><mml:mrow><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>z</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> everywhere.</p><p>Model simulations with this modified MCD model show no qualitative difference from its simpler variant (linear γ-effect), across a wide range of <inline-formula><mml:math id="inf396"><mml:mrow><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> parameters. Having said this, the modified MCD model is in principle more flexible than its simpler variant, and may thus exhibit additional explanatory power. We thus performed a formal statistical model comparison to evaluate the potential advantage of considering saturating γ-effects. In brief, we performed the same within-subject analysis as with the simpler MCD variant (see main text). We then measured the accuracy of model postdictions on each dependent variable and performed a random-effect group-level Bayesian model comparison (<xref ref-type="bibr" rid="bib71">Rigoux et al., 2014</xref>; <xref ref-type="bibr" rid="bib78">Stephan et al., 2009</xref>). The results of this comparison are summarized in <xref ref-type="fig" rid="app1fig12">Appendix 1—figure 12</xref>.</p><fig id="app1fig12" position="float"><label>Appendix 1—figure 12.</label><caption><title>Comparisons of MCD model with linear and saturating γ-effects.</title><p>Left panel: The mean within-subject (across-trial) correlation between observed and postdicted data (y-axis) is plotted for dependent variable (x-axis, from left to right: choice confidence, spreading of alternatives, change of mind, certainty gain, RT and subjective effort ratings) and each model (gray: MCD with linear efficacy, blue: MCD with saturating efficacy); error bars depict s.e.m. Right panel: Estimated model frequencies from the random-effect group-level Bayesian model comparison; error bars depict posterior standard deviations.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-app1-fig12-v2.tif"/></fig><p>First, one can see that considering saturating γ-effects does not provide any meaningful advantage in terms of MCD postdiction accuracy. Second, Bayesian model section clearly favors the simpler (linear γ-effect) MCD variant (linear efficacy: estimated model frequency = 84.4 ± 5.5%, exceedance probability = 1, protected exceedance probability = 0.89). We note that other variants of the MCD model may be proposed, with similar modifications (e.g., nonlinear effort costs, non-Gaussian – skewed – value representations). Preliminary simulations seem to confirm that such modifications would not change the qualitative nature of MCD predictions. In other terms, the MCD model may be quite robust to these kinds of assumptions. Note that these modifications would necessarily increase the statistical complexity of the model (by inserting additional unknown parameters). Therefore, the limited reliability of behavioral data (such as we report here) may not afford subtle deviations to the simple MCD model variant we evaluate here.</p></sec><sec id="s18" sec-type="appendix"><title>11. Comparing MCD and model-free postdiction accuracy</title><p>The MCD model provides quantitative predictions for both effort-related and decision-related variables, from estimates of three native parameters (effort unitary cost and two types of effort efficacy), which control all dependent variables. However, the model prediction accuracy is not perfect, and one may wonder what is the added value of MCD compared to model-free analyses.</p><p>To begin with, recall that one cannot make out-of-sample predictions in a model-free manner (e.g., there is nothing one can learn about effort-related variables from regressions of decision-related variables on ΔVR<sup>0</sup> and VCR<sup>0</sup>). In contrast, a remarkable feature of model-based analyses is that training the model on some subset of variables is enough to make out-of-sample predictions on other (yet unseen) variables. In this context, MCD-based analyses show that variations in response times, subjective effort ratings, changes of mind, spreading of alternatives, choice confidence, and precision gain can be predicted from each other under a small subset of modeling assumptions.</p><p>Having said this, model-free analyses can be used to provide a reference for the accuracy of MCD postdictions. For example, one may regress each dependent variable onto ΔVR<sup>0</sup>, VCR<sup>0</sup>, and indicator variables of experimental conditions (whether or not the choice is ‘consequential’ and/or ‘penalized’), and measure the correlation between observed and postdicted variables. This provides a benchmark against which MCD postdiction accuracy can be evaluated. To enable a fair statistical comparison, we re-performed MCD model fits, this time fitting each dependent variable one by one (leaving the others out). In what follows, we refer to this as ‘MCD 1-variable fits’. The results of this analysis are summarized in <xref ref-type="fig" rid="app1fig13">Appendix 1—figure 13</xref>:</p><fig id="app1fig13" position="float"><label>Appendix 1—figure 13.</label><caption><title>Comparisons of MCD and model-free postdiction accuracies.</title><p>The mean within-subject (across-trial) correlation between observed and postdicted data (y-axis) is plotted for each variable (x-axis, from left to right: choice confidence, spreading of alternatives, change of mind, certainty gain, RT, and subjective effort ratings), and each fitting procedure (gray: MCD full data fit, white: MCD 1-variable fit, and black: linear regression). Error bars depict standard error of the mean.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-63282-app1-fig13-v2.tif"/></fig><p>As expected, MCD 1-variable fits have better postdiction accuracy than the MCD 'full-data' fit. This is because the latter approach attempts to explain all dependent variables with the same parameter set, which requires finding a compromise between all dependent variables.</p><p>Now, model-free regressions seem to show globally better postdiction accuracy than MCD 1-variable fits: on average, the MCD model captures about 81% of the variance explained using linear regressions. However, the postdiction accuracy difference is only significant for effort-related variables (RT: p=0.0002, subjective effort rating: p=0.0007), but not for decision-related variables (choice confidence: p=0.06, spreading of alternatives: p=0.28, change of mind: p=0.24) except certainty gain (p&lt;10<sup>−4</sup>).</p><p>A likely explanation here is that the MCD model includes constraints that prevent one-variable fits from matching the model-free postdiction accuracy level. In turn, one may want to extend the MCD model with the aim of relaxing these constraints. Having said this, these constraints necessarily derive from the modeling assumptions that enable the MCD model to make out-of-sample predictions. We comment on this and related issues in the Discussion section of the main text.</p></sec></boxed-text></app></app-group></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.63282.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Donner</surname><given-names>Tobias H</given-names></name><role>Reviewing Editor</role><aff><institution>University Medical Center Hamburg-Eppendorf</institution><country>Germany</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Westbrook</surname><given-names>Andrew</given-names> </name><role>Reviewer</role><aff><institution/><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>This work addresses a timely and heavily debated subject: the role of mental effort in value-based decision-making. Plenty of models attempt to explain value-based choice behavior, and there is a growing number of computational accounts concerning the allocation of mental effort therein. Yet, little theoretical work has been done to relate the two literatures. The current paper contributes a novel and inspiring step in this direction.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Trading Mental Effort for Confidence in the Metacognitive Control of Value-Based Decision-Making&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, and the evaluation has been overseen by Tobias Donner as the Reviewing Editor and Michael Frank as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Andrew Westbrook (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>As the editors have judged that your manuscript is of interest, but as described below that additional experiments are required before it is published, we would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). First, because many researchers have temporarily lost access to the labs, we will give authors as much time as they need to submit revised manuscripts. We are also offering, if you choose, to post the manuscript to bioRxiv (if it is not already there) along with this decision letter and a formal designation that the manuscript is &quot;in revision at <italic>eLife</italic>&quot;. Please let us know if you would like to pursue this option.</p><p>Summary:</p><p>This manuscript addresses a timely subject: the role of cognitive control (or mental effort) in value-based decision making. While there are plenty of models explaining value-based choice, and there is a growing number of computational accounts concerning effort-allocation, little theoretical work has been done to relate the two literatures. This manuscript contributes a novel and interesting step in this direction, by introducing a computational account of meta-control in value-based decision making. According to this account, meta-control can be described as a cost-benefit analysis that weighs the benefits of allocating mental effort against associated costs. The benefits of mental effort pertain to the integration of value-relevant information to form posterior beliefs about option values. Given a small set of parameters, as well as pre-choice value ratings and pre-choice uncertainty ratings as inputs to the model, it can predict relevant decision variables as outputs, such as choice accuracy, choice confidence, choice induced preference changes, response time and subjective effort ratings. The study fits the model to data from a behavioral experiment involving value-based decisions between food items. The resulting behavioral fits reproduce a number of predictions derived from the model. Finally, the article describes how the model relates to established accumulator models of decision-making.</p><p>The (relatively simple) model is impressive in its apparent ability to reproduce qualitative patterns across diverse data including choices, RTs, choice confidence ratings, subjective effort, and choice-induced changes in relative preferences successfully. The model also appears well-motivated, well-reasoned, and well-formulated. While all reviewers agreed that the manuscript is of potential interest, they also all felt that a stronger case needs to be made for the explanatory power of the model, and that the model should be embedded more thoroughly in the existing literature on this topic.</p><p>Essential revisions:</p><p>1. Evaluation of the (explanatory power of) the model.</p><p>1a. Parameter recoverability: Please include an analysis of parameter recoverability: How well can the fitting procedure recover model parameters from data generated by the model?</p><p>1b. Fitting procedure: Rather than fitting the model to all dependent variables at once, it would be more compelling to fit the model to a subset of established decision-related variables (e.g. accuracy, choice confidence, choice induced preference changes) and then evaluate if, and how well, the fitted model can predict out-of-sample variables related to effort allocation (e.g. response time and subjective effort ratings). The latter would be a more stringent test of the model, and may serve to highlight its value for linking variables related to value-based decision making to variables related to meta-control.</p><p>1c. Model complexity: Assess (through model comparison) how many degrees of freedom are needed to account for the data (e.g. by fixing some of the crucial parameters and evaluating the fit). Currently, the authors show that their model explains more variance in dependent variables when fit to real data than random data. Almost any model which systematically relates independent variables to dependent variables would explain more variance when fit to real data than to data. It would be more useful to know whether (and if so, how much) the model explains data better, than, e.g. a model with where effort only affects precision (β efficacy), or a model in which effort only impacts value mode (γ efficacy).</p><p>1d. Single-subject data.</p><p>The model appears to do fairly well in predicting aggregate, group-level data, but does it predict subject-level data? Or, does it sometimes make unrealistic predictions when fitting to individual subjects? The Authors should provide evidence of whether it can or cannot describe subject level choices, confidence ratings, subjective effort, etc.</p><p>2. Qualify central assumptions underlying the model.</p><p>2a. The model assumes that it is &quot;rewarding&quot; to choose the correct (highest-value) option (B = R*P). Is this realistic? If the two options have approx the same value, then R should be small (it doesn't matter which one you choose); if the options have different value, it is important to choose the correct one. Of course, the probability P<sub>c</sub> continuously differentiates between the two options, but that is not the same as the reward. Can the predictions generalise toward a more general R that depends on value difference?</p><p>2b. Is it reasonable to assume that variance would increase as a linear function of resource allocation? It seems to me that variance might increase initially, but then each increment of resources would add diminishing variance to the mode since, e.g., new mnesic evidence should tend to follow old evidence. How sensitive are model predictions to this assumption? What about if each increment of resources added to variance in an exponentially decreasing fashion? What about anchoring biases? Because anchoring biases suggest that we estimate things with reference to other value cues, should we always expect that additional resources increase the expected value difference, or might additional effort actually yield smaller value differences over time? If we relax this assumption, how does this impact model predictions?</p><p>3. Address relationship to other accounts.</p><p>3a. Does the current model predict the diverse dependent variables better than a standard accumulator models of decision-making?</p><p>3b. The model could also situate itself better in the broader existing literature on the topic. For instance, how does the model compares to existing computational work on this matter, e.g. the models described in Izuma and Murayama (2013) or the efficient coding account of Polanía, Woodford, and Ruff (2019)? We understand that the presented model can account for some phenomena that the other models cannot account for, at least without auxiliary assumptions (e.g. subjective effort ratings), but the interested reader might want to know how well the presented model can explain established decision-related variables, such as decision confidence, choice accuracy or choice-induced preference changes compared to existing models, by having them contrasted in a formal manner. Finally, it would seem fair to relate the presented account to emerging, more mechanistically explicit accounts of meta-control in value-based decision making (e.g. Callaway, Rangel and Griffiths, 2020; Jang, Sharma, and Drugowitsch, 2020). Ideally, some of the above would be addressed in the form of formal model comparisons, but we realise that this may be difficult to achieve in practice within a reasonable time frame. At the least, the manuscript should discuss in detail how the above-mentioned models differ from the presented model here.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.63282.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1. Evaluation of the (explanatory power of) the model.</p><p>1a. Parameter recoverability: Please include an analysis of parameter recoverability: How well can the fitting procedure recover model parameters from data generated by the model?</p></disp-quote><p>We have now included a parameter recovery analysis of the MCD model. It is now included as part of the new section 3 of the revised Appendix. Importantly, our parameter recovery was performed under simulated data with similar SNR as our empirical data. In brief, the reliability of MCD parameter recovery does not suffer from any strong non-identifiability issue. However, its reliability is much weaker than in the ideal case, where data is not polluted with simulation noise.</p><disp-quote content-type="editor-comment"><p>1b. Fitting procedure: Rather than fitting the model to all dependent variables at once, it would be more compelling to fit the model to a subset of established decision-related variables (e.g. accuracy, choice confidence, choice induced preference changes) and then evaluate if, and how well, the fitted model can predict out-of-sample variables related to effort allocation (e.g. response time and subjective effort ratings). The latter would be a more stringent test of the model, and may serve to highlight its value for linking variables related to value-based decision making to variables related to meta-control.</p></disp-quote><p>This is an excellent suggestion. In fact, we have decided to generalize it, in the aim of providing a strong test of the model’s ability to explain all dependent variables at once. We thus performed three distinct model fits: (i) with all dependent variables, (ii) with effort-related variables only (leaving “decision-related” variables out), and (iii) with decision-related variables only (leaving effort-related variables out). We did this for each subject, each time estimating a single (within-subject) set of model parameters. We then quantified, for each dependent variable, the model’s prediction accuracy. This allows to distinguish between the accuracy of “postdictions” (i.e., the trial-by-trial correlation between data and predictions on variables that were used for fitting the model), and the accuracy of proper out-of-sample predictions (i.e., the trial-by-trial correlation between data and predictions on variables that were not used for fitting the model). Note: the latter are formally derived from parameter estimates obtained when leaving the corresponding data out. The accuracy of postdictions and out-of-sample predictions is summarized on Figure 4 of the revised Results section. In our opinion, this analysis also addresses the point 1.d below, which relates to single-subject fit accuracy (see our response below). Note that we also report group-level summaries of out-of-sample predictions for each dependent variable, when plotted against pre-choice value ratings and value certainty ratings (along with experimental data and model postdictions, see Figures 5 to 11 of the revised Results section).</p><disp-quote content-type="editor-comment"><p>1c. Model complexity: Assess (through model comparison) how many degrees of freedom are needed to account for the data (e.g. by fixing some of the crucial parameters and evaluating the fit). Currently, the authors show that their model explains more variance in dependent variables when fit to real data than random data. Almost any model which systematically relates independent variables to dependent variables would explain more variance when fit to real data than to data. It would be more useful to know whether (and if so, how much) the model explains data better, than, e.g. a model with where effort only affects precision (β efficacy), or a model in which effort only impacts value mode (γ efficacy).</p></disp-quote><p>We agree with you that we did not highlight explicit evidence for the existence of β and/or γ effects in the previous version of our manuscript. We have now revised our Results section to provide evidence for this. In fact, β and γ effects can be tested directly against empirical data. More precisely, under the MCD model, non-zero type #1 efficacy trivially implies that the precision of post-choice value representations should be higher than the precision of pre-choice value representations. Similarly, under the MCD model, non-zero type #2 efficacy implies the existence of spreading of alternatives. In our modified manuscript, we highlight and assess these predictions using simple significance testing on our data (see Figures 10 and 11 in the revised Results section). We note that we find this procedure more robust than model comparison in this case, given the limited reliability of parameter recovery.</p><disp-quote content-type="editor-comment"><p>1d. Single-subject data.</p><p>The model appears to do fairly well in predicting aggregate, group-level data, but does it predict subject-level data? Or, does it sometimes make unrealistic predictions when fitting to individual subjects? The Authors should provide evidence of whether it can or cannot describe subject level choices, confidence ratings, subjective effort, etc.</p></disp-quote><p>We entirely agree with you. In the previous version of our manuscript, we had reported the accuracy of within-subject “postdictions” in the Appendix (former Figure S3). In the revised manuscript, we now report the accuracy of within-subject postdictions and out-of-sample predictions. In particular, we test for the significance of out-of-sample predictions, which provide direct evidence for the model’s ability to guess within-subject trial-by-trial variations in each dependent variable. These results are reported in the section 4.1 of the revised Results section (see Figure 4).</p><disp-quote content-type="editor-comment"><p>2. Qualify central assumptions underlying the model.</p><p>2a. The model assumes that it is &quot;rewarding&quot; to choose the correct (highest-value) option (B = R*P). Is this realistic? If the two options have approx the same value, then R should be small (it doesn't matter which one you choose); if the options have different value, it is important to choose the correct one. Of course, the probability P<sub>c</sub> continuously differentiates between the two options, but that is not the same as the reward. Can the predictions generalise toward a more general R that depends on value difference?</p></disp-quote><p>If you mean that people do not care about the decision when the pre-choice values are similar, then we disagree with you. In brief, we have shown that both response time and subjective effort ratings decrease when the difference in pre-choice value increases (NB: this result has been reproduced many times for RT). In other words, effort is maximal when pre-choice values are similar. This is direct evidence against the idea that decision importance (i.e., <italic><bold>R</bold></italic> in the MCD model) should tend to zero for such “iso-value” decisions.</p><p>Of course, decision importance is a critical component of the MCD model. This is why we had included an empirical way of manipulating it, by contrasting trials where subjects had to consume the item they chose (so-called “consequential” decisions) with trials where it was not the case (“neutral” decisions). The MCD model then predicts that people should allocate more resources (spend more time and report higher subjective effort) for “consequential” than for “neutral” decisions. In our revised manuscript, we highlight this qualitative prediction and its corresponding empirical test (cf. Figure 7 in section 4.2 of the revised Results section).</p><p>Having said this, we acknowledge that decision importance falls short of a complete and concise computational definition. In the previous version of our manuscript, we had discussed possible cognitive determinants of decision importance that would be independent of option values. Now, whether and how decision importance depends upon the prior assessment of choice options is virtually unknown. We have now modified the paragraph of the related Discussion as follows (new lines 783-815):</p><p>“First, we did not specify what determines decision “importance”, which effectively acts as a weight for confidence against effort costs (cf. in Equation 2 of the Model section). […] Probing these computational assumptions will be the focus of forthcoming publications.”</p><disp-quote content-type="editor-comment"><p>2b. Is it reasonable to assume that variance would increase as a linear function of resource allocation? It seems to me that variance might increase initially, but then each increment of resources would add diminishing variance to the mode since, e.g., new mnesic evidence should tend to follow old evidence. How sensitive are model predictions to this assumption? What about if each increment of resources added to variance in an exponentially decreasing fashion? What about anchoring biases? Because anchoring biases suggest that we estimate things with reference to other value cues, should we always expect that additional resources increase the expected value difference, or might additional effort actually yield smaller value differences over time? If we relax this assumption, how does this impact model predictions?</p></disp-quote><p>This is an intriguing suggestion. We recognize that, under some simple Bayesian algorithm for value estimation, one would expect some form of saturating type #2 efficacy. In other terms, the magnitude of the perturbation (per unit of resources) that one might expect when no resources have yet been allocated may be much higher than when most resources have already been allocated. We thus implemented and tested such a model. We report the results of this analysis in the section 10 of our revised Appendix. In brief, a saturating type #2 efficacy brings no additional explanatory power for the model’s dependent variables.</p><disp-quote content-type="editor-comment"><p>3. Address relationship to other accounts.</p><p>3a. Does the current model predict the diverse dependent variables better than a standard accumulator models of decision-making?</p></disp-quote><p>This is a fair point, to which we wholeheartedly concur. We have thus implemented two simple variants of a drift-diffusion model (DDM) which can, in principle, exploit the same information as the MCD model (namely: pre-choice value difference, pre-choice value certainty, and encodings of “consequential”/”penalized”/”neutral” task conditions). We have then compared these models with MCD, w.r.t. their ability to predict out-of-sample data. The results of this comparison are reported in section 9 of our revised Appendix. In brief, standard DDM variants make quantitative predictions regarding both response times and decision outcomes, but are agnostic about choice confidence, spreading of alternatives, value certainty gain, and/or subjective effort ratings. In addition, simple DDM variants are less accurate than MCD at making out-of-sample predictions on dependent variables common to both models (e.g., change of mind).</p><disp-quote content-type="editor-comment"><p>3b. The model could also situate itself better in the broader existing literature on the topic. For instance, how does the model compares to existing computational work on this matter, e.g. the models described in Izuma and Murayama (2013) or the efficient coding account of Polanía, Woodford, and Ruff (2019)? We understand that the presented model can account for some phenomena that the other models cannot account for, at least without auxiliary assumptions (e.g. subjective effort ratings), but the interested reader might want to know how well the presented model can explain established decision-related variables, such as decision confidence, choice accuracy or choice-induced preference changes compared to existing models, by having them contrasted in a formal manner. Finally, it would seem fair to relate the presented account to emerging, more mechanistically explicit accounts of meta-control in value-based decision making (e.g. Callaway, Rangel and Griffiths, 2020; Jang, Sharma, and Drugowitsch, 2020). Ideally, some of the above would be addressed in the form of formal model comparisons, but we realise that this may be difficult to achieve in practice within a reasonable time frame. At the least, the manuscript should discuss in detail how the above-mentioned models differ from the presented model here.</p></disp-quote><p>This is a fair point, which we have addressed by augmenting the revised Discussion section with topic-specific paragraphs.</p><p>First, the model described in Izuma and Murayama (2013) is describing a well-known statistical artifact of measured spreading of alternatives. We have now included the following paragraph in the revised Discussion section (new lines 714-738):</p><p>“As a side note, the cognitive essence of spreading of alternatives has been debated for decades. […] Second, we have already shown that the effect of pre-choice value difference on spreading of alternatives is higher here than in a control condition where the choice is made after both rating sessions (Lee and Daunizeau, 2020).”</p><p>Second, the model by Polania and Ruff (2019) describes how limited neural coding resources shapes the transmission of information about subjective value. We comment on the relationship between this model and the MCD framework in the following paragraph of the revised Discussion section (new lines 739-759):</p><p>“A central tenet of the MCD model is that involving cognitive resources in value-related information processing is costly, which calls for an efficient resource allocation mechanism. […] A possibility is to consider, for example, energy-efficient population codes (Hiratani and Latham, 2020; Yu et al., 2016), which would tune the amount of neural resources involved in representing value to optimally trade information loss against energetic costs.”</p><p>Third, the models of Callaway et al. (2020) and Jang et al. (2020) effectively consider optimal policies for dividing attention between items in the choice set. They are very similar to each other, although the work by Jang et al. (2020) has a more solid theoretical grounding. We thank you for pointing us to these papers, which we were not aware of. We now refer to these work in the following modified paragraph of the Discussion section (new lines 824-830):</p><p>“More problematic, perhaps, is the fact that we did not consider distinct types of effort, which could, in principle, be associated with different costs and/or efficacies. […] Such optimal adjustment of divided attention might eventually explain systematic decision biases and shortened response times for “default” choices (Lopez-Persem et al., 2016).”</p></body></sub-article></article>