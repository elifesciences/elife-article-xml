<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">62922</article-id><article-id pub-id-type="doi">10.7554/eLife.62922</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Ecology</subject></subj-group></article-categories><title-group><article-title>A remote sensing derived data set of 100 million individual tree crowns for the National Ecological Observatory Network</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-206136"><name><surname>Weinstein</surname><given-names>Ben G</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2176-7935</contrib-id><email>ben.weinstein@weecology.org</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-207395"><name><surname>Marconi</surname><given-names>Sergio</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-207396"><name><surname>Bohlman</surname><given-names>Stephanie A</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-207397"><name><surname>Zare</surname><given-names>Alina</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4847-7604</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-207398"><name><surname>Singh</surname><given-names>Aditya</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-207399"><name><surname>Graves</surname><given-names>Sarah J</given-names></name><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-207400"><name><surname>White</surname><given-names>Ethan P</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6728-7745</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Department of Wildlife Ecology and Conservation, University of Florida</institution><addr-line><named-content content-type="city">Gainesville</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>School of Forest Resources and Conservation, University of Florida</institution><addr-line><named-content content-type="city">Gainesville</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution>Department of Electrical and Computer Engineering, University of Florida</institution><addr-line><named-content content-type="city">Gainesville</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution>Department of Agricultural &amp; Biological Engineering, University of Florida</institution><addr-line><named-content content-type="city">Gainesville</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution>Nelson Institute for Environmental Studies, University of Wisconsin-Madison</institution><addr-line><named-content content-type="city">Madison</named-content></addr-line><country>United States</country></aff><aff id="aff6"><label>6</label><institution>Informatics Institute, University of Florida</institution><addr-line><named-content content-type="city">Gainesville</named-content></addr-line><country>United States</country></aff><aff id="aff7"><label>7</label><institution>Biodiversity Institute, University of Florida</institution><addr-line><named-content content-type="city">Gainesville</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Schmid</surname><given-names>Bernhard</given-names></name><role>Reviewing Editor</role><aff><institution>University of Zurich</institution><country>Switzerland</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Schuman</surname><given-names>Meredith C</given-names></name><role>Senior Editor</role><aff><institution>University of Zurich</institution><country>Switzerland</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>19</day><month>02</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e62922</elocation-id><history><date date-type="received" iso-8601-date="2020-09-09"><day>09</day><month>09</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-02-15"><day>15</day><month>02</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Weinstein et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Weinstein et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-62922-v2.pdf"/><abstract><p>Forests provide biodiversity, ecosystem, and economic services. Information on individual trees is important for understanding forest ecosystems but obtaining individual-level data at broad scales is challenging due to the costs and logistics of data collection. While advances in remote sensing techniques allow surveys of individual trees at unprecedented extents, there remain technical challenges in turning sensor data into tangible information. Using deep learning methods, we produced an open-source data set of individual-level crown estimates for 100 million trees at 37 sites across the United States surveyed by the National Ecological Observatory Network’s Airborne Observation Platform. Each canopy tree crown is represented by a rectangular bounding box and includes information on the height, crown area, and spatial location of the tree. These data have the potential to drive significant expansion of individual-level research on trees by facilitating both regional analyses and cross-region comparisons encompassing forest types from most of the United States.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>trees</kwd><kwd>NEON</kwd><kwd>remote sensing</kwd><kwd>object detection</kwd><kwd>deep learning</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Other</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000936</institution-id><institution>Gordon and Betty Moore Foundation</institution></institution-wrap></funding-source><award-id>GBMF4563</award-id><principal-award-recipient><name><surname>White</surname><given-names>Ethan P</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>1926542</award-id><principal-award-recipient><name><surname>Bohlman</surname><given-names>Stephanie A</given-names></name><name><surname>Zare</surname><given-names>Alina</given-names></name><name><surname>Singh</surname><given-names>Aditya</given-names></name><name><surname>White</surname><given-names>Ethan P</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100005825</institution-id><institution>National Institute of Food and Agriculture</institution></institution-wrap></funding-source><award-id>McIntire Stennis projects #1007080</award-id><principal-award-recipient><name><surname>Bohlman</surname><given-names>Stephanie A</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A first continental data set of tree crown predictions is derived across the United States for the National Ecological Observatory Network.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Trees are central organisms in maintaining the ecological function, biodiversity, and the health of the planet. There are estimated to be over three trillion individual trees on earth (<xref ref-type="bibr" rid="bib10">Crowther et al., 2015</xref>) covering a broad range of environments and geography (<xref ref-type="bibr" rid="bib24">Hansen et al., 2013</xref>). Counting and measuring trees are central to understanding key environmental and economic issues and has implications for global climate, land management, and wood production. Field-based surveys of trees are generally conducted at local scales (~0.1–100 ha) with measurements of attributes for individual trees within plots collected manually. Connecting these local scale measurements at the plot level to broad scale patterns is challenging because of spatial heterogeneity in forests. Many of the central processes in forests, including change in forest structure and function in response to disturbances such as hurricanes and pest outbreaks, and human modification through forest management and fire, occur at scales beyond those feasible for direct field measurement.</p><p>Satellite data with continuous global coverage have been used to quantify important patterns in forest ecology and management such as global tree cover dynamics and disturbances in temperate forests (e.g., <xref ref-type="bibr" rid="bib3">Bastin et al., 2018</xref>). However, the spatial resolution of satellite data makes it difficult to detect and monitor individual trees that underlie large scale patterns. Individual level data is important for forest ecology, ecosystem services, and forestry applications because it connects sets of remote sensing pixels to a fundamental ecological, evolutionary, and economic unit used in analysis. Without grouping to the crown level, it becomes difficult to compare remotely sensed and field-based measurements on individual trees, since field surveys have no corresponding concept of pixels. In addition, characteristics such as species identity, structural traits, growth, and carbon storage potential are properties of individuals rather than pixels. Delineation of crowns also serves as a first step in species classification (<xref ref-type="bibr" rid="bib17">Fassnacht et al., 2016</xref>), foliar trait mapping (<xref ref-type="bibr" rid="bib45">Zheng et al., 2021</xref>), and analyses of tree mortality (<xref ref-type="bibr" rid="bib37">Stovall et al., 2019</xref>).</p><p>High-resolution data from airborne sensors have become increasingly accessible, but converting the data into information on individual trees requires significant technical expertise and access to high-performance computing environments (<xref ref-type="bibr" rid="bib1">Aubry-Kientz et al., 2019</xref>; <xref ref-type="bibr" rid="bib31">Puliti et al., 2020</xref>). This prevents most ecologists, foresters, and managers from engaging with large scale data on individual trees, despite the availability of the underlying data products and broad importance for forest ecology and management. In response to the growing need for publicly available and standardized airborne remote sensing data over forested ecosystems, the National Ecological Observatory Network (NEON) is collecting multi-sensor data for more than 40 sites across the United States. We combine NEON sensor data with a semi-supervised deep learning approach (<xref ref-type="bibr" rid="bib39">Weinstein et al., 2019</xref>; <xref ref-type="bibr" rid="bib41">Weinstein et al., 2020b</xref>) to produce a data set on the location, height, and crown area of over 100 million individual canopy trees at 37 sites distributed across the United States. To make these data readily accessible, we are releasing easy to access data files to spur biological analyses and to facilitate model development for tasks that rely on individual tree prediction. We describe the components of this open-source data set, compare predicted crowns with hand-labeled crowns for a range of forest types, and discuss how this data set can be used in forest research.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>The NEON crowns data set</title><p>The NEON Crowns data set contains tree crowns for all canopy trees (those visible from airborne remote sensing) at 37 NEON sites. Since subcanopy trees are not visible from above, they are not included in this data set. We operationally define ‘trees’ as plants over 3 m tall. The 37 NEON sites represent all NEON sites containing trees with co-registered RGB and LiDAR data from 2018 or 2019 (see <xref ref-type="fig" rid="fig1">Figure 1</xref> and Appendix 1 for a list of sites and their locations). Predictions were made using the most recent year for which images were available for each site.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Locations of 37 NEON sites included in the NEON crowns data set and examples of tree predictions shown with RGB imagery for six sites.</title><p>Clockwise from bottom right: (1) OSBS: Ordway-Swisher Biological Station, Florida (2) DELA: Dead Lake, Alabama, (3) SJER: San Joaquin Experimental Range, California, (4) WREF: Wind River Experimental Forest, Washington, (5) BONA: Caribou Creek, Alaska and (6) BART: Bartlett Experimental Forest, New Hampshire. Each predicted crown is associated with the spatial position, crown area, maximum height estimates from co-registered LiDAR data, and a predicted confidence score.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62922-fig1-v2.tif"/></fig><p>The data set includes a total of 104,675,304 crowns. Each predicted crown includes data on the spatial position of the crown bounding box, the area of the bounding box (an approximation of crown area), the 99th quantile of the height of LiDAR returns within the bounding box above ground level (an estimate of tree height), the year of sampling, the site where the tree is located, and a confidence score indicating the model confidence that the box represents a tree. The confidence score can vary from 0 to 1, but based on the results from <xref ref-type="bibr" rid="bib41">Weinstein et al., 2020b</xref>, boxes with less than 0.15 confidence were not included in the data set.</p><p>The data set is provided in two formats: (1) as 11,000 individual files each covering a single 1 km<sup>2</sup> tile (geospatial ‘shapefiles’ in standard ESRI format); and (2) as 37 csv files, each covering an entire NEON site. Geospatial tiles have embedded spatial projection information and can be read in commonly available GIS software (e.g., ArcGIS, QGIS) and geospatial packages for most common programming languages used in data analysis (e.g., R, Python). All data are publicly available, openly licensed (CC-BY), and permanently archived on Zenodo (<ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/3765872">https://zenodo.org/record/3765872</ext-link>) (<xref ref-type="bibr" rid="bib40">Weinstein et al., 2020a</xref>; <xref ref-type="bibr" rid="bib42">Weinstein et al., 2020c</xref>; <xref ref-type="bibr" rid="bib41">Weinstein et al., 2020b</xref>).</p><p>To support the visualization of the data set, we developed a web visualization tool using the ViSUS WebViewer (<ext-link ext-link-type="uri" xlink:href="https://visus.org//">https://visus.org//</ext-link>) to allow users to view all of the trees at the full site scale with the ability to zoom and pan to examine individual groups of trees down to a scale of 20 m (see <ext-link ext-link-type="uri" xlink:href="http://visualize.idtrees.org">http://visualize.idtrees.org</ext-link>, <xref ref-type="fig" rid="fig2">Figure 2</xref>). This tool will allow the ecological community to assist in identifying areas in need of further refinement within the large area covered by the 37 sites.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>The Neon crowns data set provides individual-level tree predictions at broad scales.</title><p>An example from Bartlett Forest, NH shows the ability to continuously zoom from landscape level to stand level views. A single 1 km tile is shown. NEON sites tend to have between 100 and 400 tiles in the full airborne footprint.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62922-fig2-v2.tif"/></fig></sec></sec><sec id="s3" sec-type="materials|methods"><title>Materials and methods</title><sec id="s3-1"><title>Crown delineation</title><p>The location of individual tree crowns was estimated using a semi-supervised deep learning workflow (<xref ref-type="fig" rid="fig3">Figure 3</xref>) developed by <xref ref-type="bibr" rid="bib41">Weinstein et al., 2020b</xref>, <xref ref-type="bibr" rid="bib39">Weinstein et al., 2019</xref>, which is implemented in the ‘DeepForest’ Python package (<xref ref-type="bibr" rid="bib42">Weinstein et al., 2020c</xref>). We extend the workflow by filtering trees using the LiDAR-derived canopy height model (CHM) to remove objects identified by the model with heights of &lt;3 m (Supplementary material). The deep learning model uses a one-shot object detector with a convolutional neural network backbone to predict tree crowns in RGB imagery. The model was pre-trained first on ImageNet (<xref ref-type="bibr" rid="bib11">Deng et al., 2009</xref>) and then using weak labels generated from a previous published LiDAR tree detection algorithm using NEON data from 30 sites (<xref ref-type="bibr" rid="bib36">Silva et al., 2016</xref>). The model was then trained on 10,000 hand-annotated crowns from seven NEON sites (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Hand-annotations included any vegetation over 3 m in height, including standing dead trees. The LiDAR derived 3 m threshold is important in sparsely vegetated landscapes, such as oak savannah and deserts, where it was difficult for the model to distinguish between trees and low shrubs in the RGB imagery. We chose this approach because it is flexible enough to allow the data set to be updated and improved by integrating new data and modeling approaches and because it can be effectively applied at large scales with the remote sensing data available from NEON. This required a flexible method that: (1) avoided hand-tuned parameterizations for each site or ecosystem (<xref ref-type="bibr" rid="bib41">Weinstein et al., 2020b</xref>), (2) accounted for the highly variable data spanning more than 10,000 tiles that included RGB artifacts and sparse LiDAR point densities, and (3) did not rely on site-specific or species information for allometric constraints on crown size (<xref ref-type="bibr" rid="bib14">Duncanson et al., 2015</xref>; <xref ref-type="bibr" rid="bib20">Fischer et al., 2020</xref>). For details of the underlying algorithms, see <xref ref-type="bibr" rid="bib39">Weinstein et al., 2019</xref>, <xref ref-type="bibr" rid="bib41">Weinstein et al., 2020b</xref>. Relaxing each of these constraints opens areas of future improvement, especially once species information is available for each label (<xref ref-type="bibr" rid="bib30">Maschler et al., 2018</xref>). For example, <xref ref-type="bibr" rid="bib15">Duncanson and Dubayah, 2018</xref> showed that site-specific allometric functions can be effective at Teakettle Canyon (TEAK) in predicting tree location and measuring growth over time.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Workflow diagram adapted from <xref ref-type="bibr" rid="bib42">Weinstein et al., 2020c</xref>.</title><p>The workflow for model training and development are identical to <xref ref-type="bibr" rid="bib42">Weinstein et al., 2020c</xref> with the exception of extracting heights from the canopy height model for each bounding box prediction.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62922-fig3-v2.tif"/></fig></sec><sec id="s3-2"><title>Evaluation and validation</title><p>The DeepForest method has been compared with leading tree crown detection tools that use an array of sensor data and algorithmic approaches. <xref ref-type="bibr" rid="bib41">Weinstein et al., 2020b</xref> compared the approach to three commonly used LiDAR algorithms (<xref ref-type="bibr" rid="bib9">Coomes et al., 2017</xref>; <xref ref-type="bibr" rid="bib27">Li et al., 2012</xref>; <xref ref-type="bibr" rid="bib36">Silva et al., 2016</xref>) in the lidR package (<xref ref-type="bibr" rid="bib32">Roussel et al., 2020</xref>) and showed that DeepForest generalized better across forest types with higher precision and recall. <xref ref-type="bibr" rid="bib42">Weinstein et al., 2020c</xref> evaluated DeepForest using the data from a recent crown delineation comparison from a tropical forest in French Guiana (<xref ref-type="bibr" rid="bib1">Aubry-Kientz et al., 2019</xref>). The original paper competed five leading methods (e.g., <xref ref-type="bibr" rid="bib19">Ferraz et al., 2016</xref>; <xref ref-type="bibr" rid="bib23">Hamraz et al., 2016</xref>; <xref ref-type="bibr" rid="bib44">Williams et al., 2020b</xref>) with the authors submitting data to an evaluation data set kept private by the evaluation team. We repeated this setup and found that DeepForest marginally outperformed all previously tested algorithms, despite the fact that the crown evaluation data used convex polygons and DeepForest used bounding boxes to delineate tree crowns.</p><p>In this paper, we further improved the delineation method by incorporating a 3 m height filter using the NEON LiDAR-derived canopy model (NEON ID: DP3.30015.001). To validate this addition, we compare predictions to the same set of image-annotated bounding boxes used in <xref ref-type="bibr" rid="bib41">Weinstein et al., 2020b</xref> (21 NEON sites, 207 images, 6926 trees). Annotations were filtered to 3 m in height by comparing bounding boxes. In rare cases, there were obvious trees that were missed by the height threshold. We choose to maintain these rare occurrences as a measure of cross-sensor error when defining ‘tree’ based on an arbitrary lidar-derived height measure. We defined a true positive crown as a predicted bounding box with greater than 50% intersection-over-union (the area of box intersection divided the area of box union of the two boxes) between the predicted and ground truth (image-annotated) bounding box. From the true positives and the total number of samples we calculated crown recall and precision. Crown recall is the proportion of image-annotated crowns matched to a crown prediction and crown precision is the proportion of predictions that match image-annotated crowns. The workflow yielded a bounding box recall of 79.1% with a precision of 72.6%. Tests indicate that the model generalizes well across geographic sites and forest conditions (<xref ref-type="fig" rid="fig4">Figure 4</xref>; <xref ref-type="bibr" rid="bib42">Weinstein et al., 2020c</xref>; <xref ref-type="bibr" rid="bib41">Weinstein et al., 2020b</xref>). There is a general bias toward undersegmenting trees in dense stands where multiple individual trees with similar optical characteristics are grouped into a single delineation. Adding the LiDAR threshold in this implementation resulted in predictions that were 7.0% more precise, but 0.2% less accurate on average (<xref ref-type="fig" rid="fig4">Figure 4</xref>). The decrease in recall is due to sparse LiDAR coverage in the CHM model where trees in the evaluation data were clearly taller than 3 m were missed in the evaluation data set.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Precision and recall scores for the algorithm used to create the NEON crowns data set (red points), as well as the DeepForest model from <xref ref-type="bibr" rid="bib40">Weinstein et al., 2020a</xref> (blue points).</title><p>Evaluation is performed on 207 image-annotated images (6926 trees) in the NEONTreeEvaluation data set (<ext-link ext-link-type="uri" xlink:href="https://github.com/weecology/NeonTreeEvaluation">https://github.com/weecology/NeonTreeEvaluation</ext-link>). The small drop in recall in the LiDAR thresholding is due to the sparse nature of the LiDAR cloud which can occasionally miss valid trees over 3 m. Overlapping points show areas without change between the methods.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62922-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Illustration of the LiDAR threshold for minimum predicted tree height.</title><p>To utilize LiDAR information in the post-processing step we decided on a single 3 m threshold to eliminate erroneous predictions of shrubs and bare ground as trees. This occurred in open sites, especially at the edges of marshy habitat, where the test of bare ground can appear similar to tree crowns due to low lying vegetation with sharp boundaries against water features. The figure demonstrates the LiDAR threshold for minimum predicted tree height using NEON plot ID OSBS_023 from Ordway Swisher Biological Station, Florida. Using the DeepForest algorithm (<xref ref-type="bibr" rid="bib42">Weinstein et al., 2020c</xref>), in blue, several boxes were removed based on no LiDAR returns above 3 m (dotted orange). This step was key in open-ground areas in which the algorithm can confuse short vegetation with standing trees.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62922-fig4-figsupp1-v2.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Illustration and discussion of attempts to incorporate LiDAR into DeepForest algorithm.</title><p>During the training of the DeepForest model, we experimented with many approaches to include multiple sources of RGB and LiDAR information on tree presence and crown shape. LiDAR data provides information on canopy height and is therefore commonly used as the primary data source for crown delineation. We attempted to incorporate LiDAR directly into DeepForest by using NEON’s canopy height model (CHM) as raster image alongside the three band RGB image to create a four-band stack. While this seems straightforward it changes the model weights so that they are no longer related to the three band pretraining using the ImageNet data set. This means that the neural network must be instantiated with random weights. This requires the network to learn basic feature representations of colors, shapes, and lines rather than inheriting this kind of information from the pretrained model. Given the paucity of labeled data, this leads to overfitting of the network. For example, when tested on the 18 hand annotated plots for the TEAK NEON site, the RGB-only mAP score was 0.529, whereas the combined RGB + CHM score was 0.389. Informal testing on flat-topped canopies in forests such as MLBS and LENO showed a disconnect between the LiDAR prediction and RGB predictions. In general, the CHM + RGB stack did not offer meaningful improvements in predictions and is therefore not currently included in the model. This may be due in part to the point densities of much of NEON’s LiDAR data. Most LiDAR based methods are evaluated on LiDAR data from a single forest type with point densities ranging from ~15 pts/m (e.g., <xref ref-type="bibr" rid="bib15">Duncanson and Dubayah, 2018</xref>) to over 100 pts/m (e.g., <xref ref-type="bibr" rid="bib1">Aubry-Kientz et al., 2019</xref>). In contrast, NEON’s current continental airborne LiDAR program produces ~6 pts/m and these densities can be highly variable, with large areas containing less than 4 pts/m. This tradeoff is needed to cover the much larger areas than previous studies.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62922-fig4-figsupp2-v2.tif"/></fig></fig-group><p>We also compared crowns delineated by the algorithm to field-collected stems from NEON’s Woody Vegetation Structure data set. This data product contains a single point for each tree with a stem diameter ≥10 cm. We filtered the raw data to only include live trees likely to be visible in the canopy (see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). These overstory tree field data help us analyze the performance of our workflow in matching crown predictions to individual trees by scoring the proportion of field stems that fall within a prediction. Field stems can only be applied to one prediction, so if two predictions overlap over a field stem, only one is considered a positive match. This test produces an overall stem recall rate at 69.4%, which is similar to the bounding box recall rate from the image-annotated data (<xref ref-type="fig" rid="fig5">Figure 5</xref>). The analysis of stem recall rate is conservative due to the challenge of aligning the field-collected spatial data with the remote sensing data (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). We found several examples of good predictions that were counted as false positives due to errors in the position of the ground samples within the imagery. The two outliers in OSBS are trees whose most recent field data (2015–2017) are labeled ‘Live’ but have little discernable crowns during leaf-on flights in 2019. It is possible that these trees have since died. In the case of two of the 12 missed trees, they are labeled ‘disease damaged’ and are not recorded in subsequent surveys. Capturing mortality events remains an area of further work, as RGB-based detection requires visible crowns.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Overstory stem recall rate for NEON sites with available field data.</title><p>Each data point is the recall rate for a field-collected plot. NEON plots are either 40m × 40 m ‘tower’ plots with two 20 × 20 m subplots, or a single 20 m × 20 m ‘distributed’ plot. See NEON sampling protocols for details. For site abbreviations see Appendix 1 for complete table.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62922-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Description of workflow for filtering data to only include live trees likely to be visible in the canopy.</title><p>Raw NEON tree stem data was processed from the NEON data portal to provide a data set to compare image derived heights to field measured heights. The following filters were applied to the raw NEON field data (ID: DP1.10098.001) after download. A reference tree must have (1) valid spatial coordinates, (2) a unique height measurement per sampling period; individuals double recorded but with different heights were discarded, (3) height measurements in more than 1 year to verify height measurement, (4) changes in between-year field heights of less than 6 m, (5) a classification as alive, (6) a minimum height of 3 m to match the threshold in the remote sensing workflow, and (7) be at least within 5 m of the canopy as measured by the LiDAR height model extracted at the stem location. This was used to prevent matching with understory trees in the event that overstory trees were eliminated due to failing in one of the above conditions, or not sampled by NEON. To match trees in the field and the NEON Crowns data set, we took the closest height when two predictions and field stems overlapped. We also dropped CLBJ since only three points met these criteria. All other NEON sites did not have any data that met these criteria. In this figure we show stem recall for evaluation plot JERC_048 from Jones Ecological Resource Center, Georgia. Predicted tree bounding boxes in black. Filtered NEON field stems (see above for filtering criteria) in red. The green arrow shows the simplest scenario, a single prediction unambiguously overlaps a single collected stem. The black arrow shows a moderately challenging scenario in which a visually unambiguous crown only barely matches the field collected stem. This could occur due to (1) the stem growing at an angle leading to a spatial mismatch between crown and stem, (2) spatial error in measuring the crown location, and (3) spatial error in the georeferencing of the RGB image. The blue arrow shows a stem point that does not overlap with a prediction crown. We have written the stem recall evaluation to be conservative, allowing no tolerance for points outside of the prediction box. Therefore, the stem recall for this image was 4/6 = 66.66%, which we believe is a conservative representation of the performance of the algorithm given the uncertainty in the field data and matching process.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62922-fig5-figsupp1-v2.tif"/></fig></fig-group><p>To assess the utility of our approach for mapping forest structure, we compared remotely sensed predictions of maximum tree height to field measurements of tree height of overstory trees using NEON’s Woody Plant Vegetation Structure Data. We used the same workflow described in <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> for determining overstory status for both the stem recall and height verification analysis. Predicted heights showed good correspondence with field-measured heights of reference trees. Using a linear-mixed model with a site-level random effect, the predicted crown height had a root mean squared error (RMSE) of 1.73 m (<xref ref-type="fig" rid="fig6">Figure 6</xref>). The relationship is stronger in forests with more open canopies (SJER, OSBS) and predictably more prone to error in forests with denser canopies (BART, MLBS). There is a persistent trend of taller predictions from the remote sensing data as compared with field measured heights. This results in part from tree growth since field measurement due to the temporal gap between field data collection and remote sensing acquisition. For example, 73.8% of the field data for Bartlett Forest (BART; RMSE = 1.68 m) came from 2015 to 2017, but the remote sensing data is from 2019. In addition, previous work to compare field heights to remote sensing data usually first identify trees that are visible from an overhead perspective canopy (e.g., <xref ref-type="bibr" rid="bib31">Puliti et al., 2020</xref>), whereas all the trees above 10 cm are sampled in NEON plots. This makes it necessary to infer which crowns are visible (for details for implementation see <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). This process can lead to overestimation of heights if the tree identified in the field data is overtopped by a larger tree, leading to a higher predicted than measured field height. Given the data available, an average RMSE of 1.73 m suggests that overstory height measures are reasonably accurate across the data set.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Comparison of field and remote sensing measurements of tree heights for 11 sites in the National Ecological Observatory Network.</title><p>Each point is an individual tree. See text and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> for selection criteria and matching scheme for the field data. The root mean squared error (RMSE) of a mixed-effects model with a site level random effect is 1.73 m.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62922-fig6-v2.tif"/></fig></sec></sec><sec id="s4" sec-type="discussion"><title>Discussion</title><sec id="s4-1"><title>Using the NEON crowns data set for individual, landscape, and biogeographic scale applications</title><p>This data set supports individual-level cross-scale ecological research that has not been previously possible. It provides the unique combination of information spanning the entire United States, with sites ranging from Puerto Rico to Alaska, with continuous individual-level data within sites at scales hundreds of times larger than what is possible using field-based survey methods. At the individual level, high-resolution airborne imagery can inform analysis of critical forest properties, such as tree growth and mortality (<xref ref-type="bibr" rid="bib8">Clark et al., 2004</xref>; <xref ref-type="bibr" rid="bib37">Stovall et al., 2019</xref>), foliar biochemistry (<xref ref-type="bibr" rid="bib7">Chadwick and Asner, 2016</xref>; <xref ref-type="bibr" rid="bib38">Wang et al., 2020</xref>), and landscape-scale carbon storage (<xref ref-type="bibr" rid="bib22">Graves et al., 2018b</xref>). Because field data on these properties are measured on individual trees, individual level tree detection allows connecting field data directly to image data. In addition, growth, mortality, and changes in carbon storage occur on the scale of individual trees such that detection of individual crowns allows direct tracking of these properties across space and time. This allows researchers to understand questions like how individual level attributes relate to mortality in response to disturbance and pests and how the spatial configuration of individual trees within a landscape influences resilience. As a result, this individual level data may be useful for promoting fire resistance landscapes and combating large scale pest outbreaks. While it is possible to aggregate information solely at the stand level, we believe that individual level data opens new possibilities in large scale forest monitoring and provides richer insights into the underlying mechanisms that drive these patterns.</p><p>At landscape scales, research is often focused on the effect of environmental and anthropogenic factors on forest structure and biodiversity (<xref ref-type="bibr" rid="bib12">Denslow, 1995</xref>). For example, understanding why tree biomass and traits vary across landscapes has direct applications to numerous ecological questions and economic implications (e.g., <xref ref-type="bibr" rid="bib26">Laubhann et al., 2009</xref>). Often this requires sampling at a number of disparate locations and either extrapolation to continuous patterns at landscape scales, or assumptions that the range of possible states of the system are captured by the samples. Using the individual level data from this data set, we can now produce continuous high-resolution maps across entire NEON sites for enabling landscape scale studies of multiple ecological phenomena (<xref ref-type="fig" rid="fig7">Figure 7</xref>). For example, previous work has found that functional and species diversity at local scales promotes biomass and tree growth (<xref ref-type="bibr" rid="bib2">Barrufol et al., 2013</xref>; <xref ref-type="bibr" rid="bib28">Liang et al., 2016</xref>). Similar findings have been reported for phylogenetic diversity at local scales (<xref ref-type="bibr" rid="bib33">Satdichanh et al., 2019</xref>). Especially when combining with species data, using the crown data to investigate the scale and strength of these effects will inform the mechanisms of community assembly, ecological stability, and forest productivity. These landscape scale responses can then be combined with high resolution data on natural and anthropogenic drivers (e.g., topography, soils, and fire management) to model forest dynamics at broad scales.</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Tree density maps for Teakettle Canyon, California (left) and Ordway Swisher Biological Station, Florida (right).</title><p>For each 100 m<sup>2</sup> pixel, the total number of predicted crowns were counted.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62922-fig7-v2.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>Illustrations of data quality challenges in remote sensing data.</title><p>With over 7000 1 km<sup>2</sup> tiles, it is not possible to do a systematic check of data and predicted crowns. However, there are several general issues that we have encountered that are worth noting. Data quality errors include incomplete site coverage, image artifacts due to georectification, errors in orthomosaic stitching, and lighting changes among data collection events. (Top left) Patchy coverage at the site level can prevent broad scale analysis with large gaps in RGB data availability (NEON site GRSM). (Top right) RGB artifacts at the edge of images stem from the challenge of georectification of the RGB and LiDAR tiles leading to swirling in the RGB pixels (NEON site OSBS). (Bottom left) Seams in the flight-lines in the RGB images lead to gaps in local predictions (NEON site DELA). (Bottom right) Changes in illumination among data acquisition collections lead to stark changes in pixel values.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62922-fig7-figsupp1-v2.tif"/></fig></fig-group><p>By focusing on detecting individual trees, this approach to landscape scale forest analysis does not require assumptions about spatial similarity, sufficiently extensive sampling, or consistent responses of the ecosystem to drivers across spatial gradients. This is important because the heterogeneity of forest landscapes makes it difficult to use field plot data on quantities such as tree density and biomass to extrapolate inference to broad scales (<xref ref-type="bibr" rid="bib29">Marvin et al., 2014</xref>). To illustrate this challenge, we compared field-measured tree densities of NEON field plots to estimated densities of 10,000 remotely sensed plots of the same size placed randomly throughout the landscapes across footprints of the airborne data. We attempted to change the Woody Vegetation data as little as possible (i.e., compared with the more refined filtered data in previous analyses) in order to obtain estimates of tree cover in a plot from the field data. To be included in this analysis, trees needed to have valid spatial coordinates and a minimum height of 3 m. Some older data lacked height estimates, in which case we used a minimum DBH threshold of 15 cm. In each simulated plot, we then counted the total number of predicted tree crowns to create a distribution of tree densities at the site level (<xref ref-type="fig" rid="fig8">Figure 8</xref>). Comparing the field plot tree densities with the distribution from the full site shows deviations for most sites, with NEON field plots exhibiting higher tree densities than encountered on average in the airborne data for some sites (e.g., Teakettle Canyon, CA) and lower tree densities than from remote sensing in others (e.g., Ordway-Swisher Biological Station). While this kind of comparison is inherently difficult due to differing thresholds and filters for data inclusion in field versus remotely sensed data, it highlights that even well stratified sampling of large landscapes as was done with NEON plots (see NEON technical documents for NEON.DP1.10098) can produce differing tree attribute estimates than continuous sampling from remote sensing data. Combining representative field sampling with remote sensing to produce data products like the NEON Crowns data set provides an approach to addressing this challenge to improve estimations of the abundance, biomass, and size distributions across large geographic areas.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Comparison of tree counts between the field-collected NEON plots and the predicted plots from the data set.</title><p>For the remote sensing data, 10,000 simulated 40 m<sup>2</sup> plots were calculated for each site for the full AOP footprint for each year. To mimic NEON sampling, two quadrants were randomly sampled in each simulated plot. No plots on water, bare ground, or herbaceous land classes were included in the comparison. We selected three sites from three NEON domains to show a sample of sites across the continental United States. Both distributed and tower NEON plots were used for these analyses.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62922-fig8-v2.tif"/></fig><p>The NEON Crowns data set supports the assessment of cross-site patterns to help understand the influence of large-scale processes on forest structure at biogeographic scales. For example, ecologists are interested in how and why forest characteristics such as abundance, biomass, and allometric relationships vary among forest types (e.g., <xref ref-type="bibr" rid="bib25">Jucker et al., 2017</xref>) and how these patterns covary across environmental gradients (<xref ref-type="bibr" rid="bib18">Feldpausch et al., 2011</xref>). Understanding these relationships is important for inferring controls over forest stand structure, understanding individual tree biology, and assessing stand productivity. For example, are local patterns of density and structural biomass primarily the result of historical mechanisms, such as dispersal and adaptation, or local mechanisms such as nutrient availability? By providing standardized data that span near-continental scales, this data set can help inform the fundamental mechanisms that shape forest structure and dynamics. For example, we can calculate tree allometries (e.g., the ratio of tree height to crown area) on a large number of individual trees across NEON sites and explore how allometry varies with stand density and vegetation type (<xref ref-type="fig" rid="fig9">Figure 9</xref>). This analysis shows a continental-scale relationship, with denser forests exhibiting trees with narrower crowns for the same tree height compared with less dense forests, but also clustering and variation in the relationship within vegetation types. For example, subalpine forests illustrate relationships between tree density and allometry that are distinct from other forest types. By defining both general biogeographic patterns, and deviations therein, this data set will allow the investigation of factors shaping forest structure at macroecological scales.</p><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>Individual crown attributes for predictions made at each NEON site.</title><p>For site abbreviations see Appendix 1. Crown area is calculated by multiplying the width and height of the predicted crown bounding box. Crown height is the 99th quantile of the LiDAR returns that fall inside the predicted crown bounding box. Sites are colored by the dominant forest type to illustrate the general macroecological relationship among sites in similar biomes.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-62922-fig9-v2.tif"/></fig><p>In addition to these ecological applications, the NEON Crowns data set can also act as a foundation for other machine learning and computer vision applications in forest informatics, such as tree health assessments, species classification, or foliar trait estimation both within NEON sites (<xref ref-type="bibr" rid="bib38">Wang et al., 2020</xref>) and outside of NEON sites (<xref ref-type="bibr" rid="bib34">Schneider et al., 2020</xref>). In each of these tasks, individual tree delineation is the first step to associate sensor data with ground measurements. However, delineation requires a distinct set of technical background and computational approaches and thus many ecological applications skip an explicit delineation step entirely (<xref ref-type="bibr" rid="bib43">Williams et al., 2020a</xref>). In addition, the growing availability of continental scale data sets of high resolution remote sensing imagery opens up the possibility for broad scale forest monitoring of individual trees (<xref ref-type="bibr" rid="bib5">Brandt et al., 2020</xref>; <xref ref-type="bibr" rid="bib34">Schneider et al., 2020</xref>) that can be supported by this data set. Just as we used weak annotations generated from unsupervised LiDAR algorithms, future developers can use this data set to train in the multiple data types provided by the NEON Airborne Observation Platform across a broad range of forest types. While our crown annotations are not perfect, they are specifically tailored to one of the largest data sets that allows pairing individual tree detections with information on species identity, tree health, and leaf traits through NEONs field sampling, and we believe they are sufficiently robust to serve as the basis for broad scale analysis.</p></sec><sec id="s4-2"><title>Limitations and further technical developments</title><p>An important limitation for this data set is that it only provides information on sun-exposed tree crowns. It is therefore not appropriate for ecological analyses that depend on accurate characterization of subcanopy trees and the three-dimensional structure of forest stands. Fortunately, a number of the major questions and applications in ecology are primarily influenced by large individuals (<xref ref-type="bibr" rid="bib16">Enquist et al., 2020</xref>). For example, biomass estimation is largely driven by the canopy in most ecosystems, rather than mid or understory trees that are likely to be missed by aerial surveys. Similarly, habitat classification and species abundance curves can depend on the dominant forest structure that can be inferred from coarse resolution airborne data (<xref ref-type="bibr" rid="bib35">Shirley et al., 2013</xref>) and could be improved using this data set. It may be possible to establish relationships between understory and canopy measures using field data that could allow this data set to be used as part of a broader analysis (<xref ref-type="bibr" rid="bib4">Bohlman, 2015</xref>; <xref ref-type="bibr" rid="bib13">Duncanson et al., 2014</xref>; <xref ref-type="bibr" rid="bib20">Fischer et al., 2020</xref>). However, this would require significant additional research to validate the potential for this type of approach at continental scales.</p><p>We experimented with avenues to combine RGB information and a LiDAR CHM to create a jointly learned input and found that no combination of data fusion outperformed the current pipeline (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). The lack of improvement when directly incorporating LiDAR data into the CNN is likely due to a combination of geographic variation in tree shape and LiDAR coverage, sparse LiDAR point densities (~6 pts/m at many NEON sites), and a lack of joint RGB and LiDAR data for initial pretraining. Most LiDAR based methods are evaluated on data from a single forest type with point densities ranging from ~15 pts/m (e.g., <xref ref-type="bibr" rid="bib15">Duncanson and Dubayah, 2018</xref>) to over 100 pts/m (e.g., <xref ref-type="bibr" rid="bib1">Aubry-Kientz et al., 2019</xref>). As instrumentation improves to support collecting higher density LiDAR consistently at larger scales and algorithms are improved to allow generalization across forest types, we anticipate updating the data set with improved delineation of the sunlit canopy and begin to add subcanopy trees.</p><p>An additional limitation is the uncertainty inherent in the algorithmic detection of crowns. While we found good correspondence between image-based crown annotations and those produced by the model for many sites, there remained substantial uncertainty across all sites and reasonable levels of error in some sites. It is important to consider how this uncertainty will influence the inference from research using this and similar data sets. The model is biased toward undersegmentation, meaning that multiple trees are prone to being grouped as a single crown. It is also somewhat conservative in estimating crown extent wherein it tends to ignore small extensions of branches from the main crown. These biases could impact studies of tree allometry and biomass if the analysis is particularly sensitive to crown area. When making predictions for ecosystem features such as biomass, it will be important to propagate the uncertainty in individual crowns into downstream analyses. While confidence scores for individual detections are provided to aid uncertainty propagation, the use of additional ground truth data may also be necessary to infer reliability.</p><p>One aspect of individual crown uncertainty that we have not addressed is the uncertainty related to image-based crown annotations and measurement of trees in the field (<xref ref-type="bibr" rid="bib21">Graves et al., 2018a</xref>). To allow training and evaluating the model across a broad range of forest types, we used image-based crown annotations. This approach assumes that crowns identifiable in remotely sensed imagery accurately reflect trees on the ground. This will not always be the case, as what appears to be a single crown from above may constitute multiple neighboring trees, and conversely, what appears to be two distinct crowns in an image may be two branches of a single large tree (<xref ref-type="bibr" rid="bib21">Graves et al., 2018a</xref>). Distinguishing individual trees, especially when considering species with multi-bole stems, can be subjective, even during field surveys. Targeted field surveys will be always needed to validate these predictions and community annotation efforts will allow for assessment of this component of uncertainty. In particular, combining terrestrial LiDAR sampling with airborne sensors is a promising route to both validate the number of stems and establish subcanopy diversity (<xref ref-type="bibr" rid="bib6">Calders et al., 2020</xref>). In addition, when co-registered hyperspectral data are available, it may help to separate neighboring trees in diverse forests, provided it does not cause lumping of neighboring trees of the same species. Weighing these tradeoffs across a range of forest types remains an open area of exploration.</p><p>The machine learning workflow used to generate this data set also has several areas that could be improved for greater accuracy, transferability, and robustness. The current model contains a single class ‘Tree’ with an associated confidence score. This representation prevents the model from differentiating between objects that are not trees and objects for which sufficient training information is not available. For example, the model has been trained to ignore buildings and other vertical structures that may look like trees. However, when confronted by objects data that has never been encountered, it often produces unintuitive results. Examples of objects that did not appear in the training data, and as a result were erroneously predicted as trees, include weather stations, floating buoys, and oil wells. Designing models that can identify outliers, anomalies, and ‘unknown’ objects is an active area of research in machine learning and will be useful in increasing accuracy in novel environments. In addition, NEON data can sometimes be afflicted by imaging artifacts due to co-registration issues with LiDAR and raw RGB imagery (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). This effect can lead to distorted imagery that appears fuzzy and swirled and lead to poor segmentation. An ideal model would detect these areas of poor quality and label them as ‘unknown’ rather than attempting to detect trees in these regions.</p><p>Given these limitations, we view this version of the data set as the first step in an iterative process to improve cross-scale individual level data on trees. Ongoing assessment of these predictions using both our visualization tool and field-based surveys will be crucial to continually identify areas for improvements in both training data and modeling approaches. While iterative improvements are important, the accuracy of the current predictions illustrates that this data set is sufficiently precise for addressing many cross-scale questions related to forest structure. By providing broad scale crown data we hope to highlight the promising integration between deep learning, remote sensing, and forest informatics, and provide access to the results of this next key step in ecological research to the broad range of stakeholders who can benefit from these data.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We would like to thank NEON staff and in particular Tristan Goulden and Courtney Meier for their assistance and support. This research was supported by the Gordon and Betty Moore Foundation’s Data-Driven Discovery Initiative (GBMF4563) to EP White and by the National Science Foundation (1926542) to EP White, SA Bohlman, A Zare, DZ Wang, and A Singh and USDA National Institute of Food and Agriculture McIntire Stennis projects #1007080 to SA Bohlman. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Investigation, Visualization, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Data curation, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Funding acquisition, Investigation, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Supervision, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Software, Methodology, Writing - original draft</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Data curation, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con7"><p>Conceptualization, Data curation, Supervision, Writing - original draft, Writing - review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-62922-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>The dataset is available at <ext-link ext-link-type="uri" xlink:href="https://zenodo.org/record/3765872#.X2J1zZNKjOQ">https://zenodo.org/record/3765872#.X2J1zZNKjOQ</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Weinstein</surname><given-names>BG</given-names></name><name><surname>Marconi</surname><given-names>S</given-names></name><name><surname>Zare</surname><given-names>A</given-names></name><name><surname>Bohlman</surname><given-names>SA</given-names></name><name><surname>Graves</surname><given-names>SJ</given-names></name><name><surname>Singh</surname><given-names>A</given-names></name><name><surname>White</surname><given-names>EP</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>NEON Tree Crowns Dataset</data-title><source>Zenodo</source><pub-id assigning-authority="Zenodo" pub-id-type="doi">10.5281/zenodo.3765872</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aubry-Kientz</surname> <given-names>M</given-names></name><name><surname>Dutrieux</surname> <given-names>R</given-names></name><name><surname>Ferraz</surname> <given-names>A</given-names></name><name><surname>Saatchi</surname> <given-names>S</given-names></name><name><surname>Hamraz</surname> <given-names>H</given-names></name><name><surname>Williams</surname> <given-names>J</given-names></name><name><surname>Coomes</surname> <given-names>D</given-names></name><name><surname>Piboule</surname> <given-names>A</given-names></name><name><surname>Vincent</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A comparative assessment of the performance of individual tree crowns delineation algorithms from ALS data in tropical forests</article-title><source>Remote Sensing</source><volume>11</volume><elocation-id>1086</elocation-id><pub-id pub-id-type="doi">10.3390/rs11091086</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barrufol</surname> <given-names>M</given-names></name><name><surname>Schmid</surname> <given-names>B</given-names></name><name><surname>Bruelheide</surname> <given-names>H</given-names></name><name><surname>Chi</surname> <given-names>X</given-names></name><name><surname>Hector</surname> <given-names>A</given-names></name><name><surname>Ma</surname> <given-names>K</given-names></name><name><surname>Michalski</surname> <given-names>S</given-names></name><name><surname>Tang</surname> <given-names>Z</given-names></name><name><surname>Niklaus</surname> <given-names>PA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Biodiversity promotes tree growth during succession in subtropical forest</article-title><source>PLOS ONE</source><volume>8</volume><elocation-id>e81246</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0081246</pub-id><pub-id pub-id-type="pmid">24303037</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bastin</surname> <given-names>J-F</given-names></name><name><surname>Rutishauser</surname> <given-names>E</given-names></name><name><surname>Kellner</surname> <given-names>JR</given-names></name><name><surname>Saatchi</surname> <given-names>S</given-names></name><name><surname>Pélissier</surname> <given-names>R</given-names></name><name><surname>Hérault</surname> <given-names>B</given-names></name><name><surname>Slik</surname> <given-names>F</given-names></name><name><surname>Bogaert</surname> <given-names>J</given-names></name><name><surname>De Cannière</surname> <given-names>C</given-names></name><name><surname>Marshall</surname> <given-names>AR</given-names></name><name><surname>Poulsen</surname> <given-names>J</given-names></name><name><surname>Alvarez-Loyayza</surname> <given-names>P</given-names></name><name><surname>Andrade</surname> <given-names>A</given-names></name><name><surname>Angbonga-Basia</surname> <given-names>A</given-names></name><name><surname>Araujo-Murakami</surname> <given-names>A</given-names></name><name><surname>Arroyo</surname> <given-names>L</given-names></name><name><surname>Ayyappan</surname> <given-names>N</given-names></name><name><surname>de Azevedo</surname> <given-names>CP</given-names></name><name><surname>Banki</surname> <given-names>O</given-names></name><name><surname>Barbier</surname> <given-names>N</given-names></name><name><surname>Barroso</surname> <given-names>JG</given-names></name><name><surname>Beeckman</surname> <given-names>H</given-names></name><name><surname>Bitariho</surname> <given-names>R</given-names></name><name><surname>Boeckx</surname> <given-names>P</given-names></name><name><surname>Boehning-Gaese</surname> <given-names>K</given-names></name><name><surname>Brandão</surname> <given-names>H</given-names></name><name><surname>Brearley</surname> <given-names>FQ</given-names></name><name><surname>Breuer Ndoundou Hockemba</surname> <given-names>M</given-names></name><name><surname>Brienen</surname> <given-names>R</given-names></name><name><surname>Camargo</surname> <given-names>JLC</given-names></name><name><surname>Campos-Arceiz</surname> <given-names>A</given-names></name><name><surname>Cassart</surname> <given-names>B</given-names></name><name><surname>Chave</surname> <given-names>J</given-names></name><name><surname>Chazdon</surname> <given-names>R</given-names></name><name><surname>Chuyong</surname> <given-names>G</given-names></name><name><surname>Clark</surname> <given-names>DB</given-names></name><name><surname>Clark</surname> <given-names>CJ</given-names></name><name><surname>Condit</surname> <given-names>R</given-names></name><name><surname>Honorio Coronado</surname> <given-names>EN</given-names></name><name><surname>Davidar</surname> <given-names>P</given-names></name><name><surname>de Haulleville</surname> <given-names>T</given-names></name><name><surname>Descroix</surname> <given-names>L</given-names></name><name><surname>Doucet</surname> <given-names>J-L</given-names></name><name><surname>Dourdain</surname> <given-names>A</given-names></name><name><surname>Droissart</surname> <given-names>V</given-names></name><name><surname>Duncan</surname> <given-names>T</given-names></name><name><surname>Silva Espejo</surname> <given-names>J</given-names></name><name><surname>Espinosa</surname> <given-names>S</given-names></name><name><surname>Farwig</surname> <given-names>N</given-names></name><name><surname>Fayolle</surname> <given-names>A</given-names></name><name><surname>Feldpausch</surname> <given-names>TR</given-names></name><name><surname>Ferraz</surname> <given-names>A</given-names></name><name><surname>Fletcher</surname> <given-names>C</given-names></name><name><surname>Gajapersad</surname> <given-names>K</given-names></name><name><surname>Gillet</surname> <given-names>J-F</given-names></name><name><surname>Amaral</surname> <given-names>ILdo</given-names></name><name><surname>Gonmadje</surname> <given-names>C</given-names></name><name><surname>Grogan</surname> <given-names>J</given-names></name><name><surname>Harris</surname> <given-names>D</given-names></name><name><surname>Herzog</surname> <given-names>SK</given-names></name><name><surname>Homeier</surname> <given-names>J</given-names></name><name><surname>Hubau</surname> <given-names>W</given-names></name><name><surname>Hubbell</surname> <given-names>SP</given-names></name><name><surname>Hufkens</surname> <given-names>K</given-names></name><name><surname>Hurtado</surname> <given-names>J</given-names></name><name><surname>Kamdem</surname> <given-names>NG</given-names></name><name><surname>Kearsley</surname> <given-names>E</given-names></name><name><surname>Kenfack</surname> <given-names>D</given-names></name><name><surname>Kessler</surname> <given-names>M</given-names></name><name><surname>Labrière</surname> <given-names>N</given-names></name><name><surname>Laumonier</surname> <given-names>Y</given-names></name><name><surname>Laurance</surname> <given-names>S</given-names></name><name><surname>Laurance</surname> <given-names>WF</given-names></name><name><surname>Lewis</surname> <given-names>SL</given-names></name><name><surname>Libalah</surname> <given-names>MB</given-names></name><name><surname>Ligot</surname> <given-names>G</given-names></name><name><surname>Lloyd</surname> <given-names>J</given-names></name><name><surname>Lovejoy</surname> <given-names>TE</given-names></name><name><surname>Malhi</surname> <given-names>Y</given-names></name><name><surname>Marimon</surname> <given-names>BS</given-names></name><name><surname>Marimon Junior</surname> <given-names>BH</given-names></name><name><surname>Martin</surname> <given-names>EH</given-names></name><name><surname>Matius</surname> <given-names>P</given-names></name><name><surname>Meyer</surname> <given-names>V</given-names></name><name><surname>Mendoza Bautista</surname> <given-names>C</given-names></name><name><surname>Monteagudo-Mendoza</surname> <given-names>A</given-names></name><name><surname>Mtui</surname> <given-names>A</given-names></name><name><surname>Neill</surname> <given-names>D</given-names></name><name><surname>Parada Gutierrez</surname> <given-names>GA</given-names></name><name><surname>Pardo</surname> <given-names>G</given-names></name><name><surname>Parren</surname> <given-names>M</given-names></name><name><surname>Parthasarathy</surname> <given-names>N</given-names></name><name><surname>Phillips</surname> <given-names>OL</given-names></name><name><surname>Pitman</surname> <given-names>NCA</given-names></name><name><surname>Ploton</surname> <given-names>P</given-names></name><name><surname>Ponette</surname> <given-names>Q</given-names></name><name><surname>Ramesh</surname> <given-names>BR</given-names></name><name><surname>Razafimahaimodison</surname> <given-names>J-C</given-names></name><name><surname>Réjou-Méchain</surname> <given-names>M</given-names></name><name><surname>Rolim</surname> <given-names>SG</given-names></name><name><surname>Saltos</surname> <given-names>HR</given-names></name><name><surname>Rossi</surname> <given-names>LMB</given-names></name><name><surname>Spironello</surname> <given-names>WR</given-names></name><name><surname>Rovero</surname> <given-names>F</given-names></name><name><surname>Saner</surname> <given-names>P</given-names></name><name><surname>Sasaki</surname> <given-names>D</given-names></name><name><surname>Schulze</surname> <given-names>M</given-names></name><name><surname>Silveira</surname> <given-names>M</given-names></name><name><surname>Singh</surname> <given-names>J</given-names></name><name><surname>Sist</surname> <given-names>P</given-names></name><name><surname>Sonke</surname> <given-names>B</given-names></name><name><surname>Soto</surname> <given-names>JD</given-names></name><name><surname>de Souza</surname> <given-names>CR</given-names></name><name><surname>Stropp</surname> <given-names>J</given-names></name><name><surname>Sullivan</surname> <given-names>MJP</given-names></name><name><surname>Swanepoel</surname> <given-names>B</given-names></name><name><surname>Steege</surname> <given-names>Hter</given-names></name><name><surname>Terborgh</surname> <given-names>J</given-names></name><name><surname>Texier</surname> <given-names>N</given-names></name><name><surname>Toma</surname> <given-names>T</given-names></name><name><surname>Valencia</surname> <given-names>R</given-names></name><name><surname>Valenzuela</surname> <given-names>L</given-names></name><name><surname>Ferreira</surname> <given-names>LV</given-names></name><name><surname>Valverde</surname> <given-names>FC</given-names></name><name><surname>Van Andel</surname> <given-names>TR</given-names></name><name><surname>Vasque</surname> <given-names>R</given-names></name><name><surname>Verbeeck</surname> <given-names>H</given-names></name><name><surname>Vivek</surname> <given-names>P</given-names></name><name><surname>Vleminckx</surname> <given-names>J</given-names></name><name><surname>Vos</surname> <given-names>VA</given-names></name><name><surname>Wagner</surname> <given-names>FH</given-names></name><name><surname>Warsudi</surname> <given-names>PP</given-names></name><name><surname>Wortel</surname> <given-names>V</given-names></name><name><surname>Zagt</surname> <given-names>RJ</given-names></name><name><surname>Zebaze</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Pan-tropical prediction of forest structure from the largest trees</article-title><source>Global Ecology and Biogeography</source><volume>27</volume><fpage>1366</fpage><lpage>1383</lpage><pub-id pub-id-type="doi">10.1111/geb.12803</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bohlman</surname> <given-names>SA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Species diversity of canopy versus understory trees in a neotropical forest: implications for forest structure, function and monitoring</article-title><source>Ecosystems</source><volume>18</volume><fpage>658</fpage><lpage>670</lpage><pub-id pub-id-type="doi">10.1007/s10021-015-9854-0</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brandt</surname> <given-names>M</given-names></name><name><surname>Tucker</surname> <given-names>CJ</given-names></name><name><surname>Kariryaa</surname> <given-names>A</given-names></name><name><surname>Rasmussen</surname> <given-names>K</given-names></name><name><surname>Abel</surname> <given-names>C</given-names></name><name><surname>Small</surname> <given-names>J</given-names></name><name><surname>Chave</surname> <given-names>J</given-names></name><name><surname>Rasmussen</surname> <given-names>LV</given-names></name><name><surname>Hiernaux</surname> <given-names>P</given-names></name><name><surname>Diouf</surname> <given-names>AA</given-names></name><name><surname>Kergoat</surname> <given-names>L</given-names></name><name><surname>Mertz</surname> <given-names>O</given-names></name><name><surname>Igel</surname> <given-names>C</given-names></name><name><surname>Gieseke</surname> <given-names>F</given-names></name><name><surname>Schöning</surname> <given-names>J</given-names></name><name><surname>Li</surname> <given-names>S</given-names></name><name><surname>Melocik</surname> <given-names>K</given-names></name><name><surname>Meyer</surname> <given-names>J</given-names></name><name><surname>Sinno</surname> <given-names>S</given-names></name><name><surname>Romero</surname> <given-names>E</given-names></name><name><surname>Glennie</surname> <given-names>E</given-names></name><name><surname>Montagu</surname> <given-names>A</given-names></name><name><surname>Dendoncker</surname> <given-names>M</given-names></name><name><surname>Fensholt</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>An unexpectedly large count of trees in the west african sahara and sahel</article-title><source>Nature</source><volume>587</volume><fpage>78</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-2824-5</pub-id><pub-id pub-id-type="pmid">33057199</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Calders</surname> <given-names>K</given-names></name><name><surname>Adams</surname> <given-names>J</given-names></name><name><surname>Armston</surname> <given-names>J</given-names></name><name><surname>Bartholomeus</surname> <given-names>H</given-names></name><name><surname>Bauwens</surname> <given-names>S</given-names></name><name><surname>Bentley</surname> <given-names>LP</given-names></name><name><surname>Chave</surname> <given-names>J</given-names></name><name><surname>Danson</surname> <given-names>FM</given-names></name><name><surname>Demol</surname> <given-names>M</given-names></name><name><surname>Disney</surname> <given-names>M</given-names></name><name><surname>Gaulton</surname> <given-names>R</given-names></name><name><surname>Krishna Moorthy</surname> <given-names>SM</given-names></name><name><surname>Levick</surname> <given-names>SR</given-names></name><name><surname>Saarinen</surname> <given-names>N</given-names></name><name><surname>Schaaf</surname> <given-names>C</given-names></name><name><surname>Stovall</surname> <given-names>A</given-names></name><name><surname>Terryn</surname> <given-names>L</given-names></name><name><surname>Wilkes</surname> <given-names>P</given-names></name><name><surname>Verbeeck</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Terrestrial laser scanning in forest ecology: expanding the horizon</article-title><source>Remote Sensing of Environment</source><volume>251</volume><elocation-id>112102</elocation-id><pub-id pub-id-type="doi">10.1016/j.rse.2020.112102</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chadwick</surname> <given-names>K</given-names></name><name><surname>Asner</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Organismic-Scale remote sensing of canopy foliar traits in lowland tropical forests</article-title><source>Remote Sensing</source><volume>8</volume><elocation-id>87</elocation-id><pub-id pub-id-type="doi">10.3390/rs8020087</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clark</surname> <given-names>DB</given-names></name><name><surname>Castro</surname> <given-names>CS</given-names></name><name><surname>Alvarado</surname> <given-names>LDA</given-names></name><name><surname>Read</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Quantifying mortality of tropical rain forest trees using high-spatial-resolution satellite data</article-title><source>Ecology Letters</source><volume>7</volume><fpage>52</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1046/j.1461-0248.2003.00547.x</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coomes</surname> <given-names>DA</given-names></name><name><surname>Dalponte</surname> <given-names>M</given-names></name><name><surname>Jucker</surname> <given-names>T</given-names></name><name><surname>Asner</surname> <given-names>GP</given-names></name><name><surname>Banin</surname> <given-names>LF</given-names></name><name><surname>Burslem</surname> <given-names>DFRP</given-names></name><name><surname>Lewis</surname> <given-names>SL</given-names></name><name><surname>Nilus</surname> <given-names>R</given-names></name><name><surname>Phillips</surname> <given-names>OL</given-names></name><name><surname>Phua</surname> <given-names>M-H</given-names></name><name><surname>Qie</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Area-based vs tree-centric approaches to mapping forest carbon in southeast asian forests from airborne laser scanning data</article-title><source>Remote Sensing of Environment</source><volume>194</volume><fpage>77</fpage><lpage>88</lpage><pub-id pub-id-type="doi">10.1016/j.rse.2017.03.017</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crowther</surname> <given-names>TW</given-names></name><name><surname>Glick</surname> <given-names>HB</given-names></name><name><surname>Covey</surname> <given-names>KR</given-names></name><name><surname>Bettigole</surname> <given-names>C</given-names></name><name><surname>Maynard</surname> <given-names>DS</given-names></name><name><surname>Thomas</surname> <given-names>SM</given-names></name><name><surname>Smith</surname> <given-names>JR</given-names></name><name><surname>Hintler</surname> <given-names>G</given-names></name><name><surname>Duguid</surname> <given-names>MC</given-names></name><name><surname>Amatulli</surname> <given-names>G</given-names></name><name><surname>Tuanmu</surname> <given-names>MN</given-names></name><name><surname>Jetz</surname> <given-names>W</given-names></name><name><surname>Salas</surname> <given-names>C</given-names></name><name><surname>Stam</surname> <given-names>C</given-names></name><name><surname>Piotto</surname> <given-names>D</given-names></name><name><surname>Tavani</surname> <given-names>R</given-names></name><name><surname>Green</surname> <given-names>S</given-names></name><name><surname>Bruce</surname> <given-names>G</given-names></name><name><surname>Williams</surname> <given-names>SJ</given-names></name><name><surname>Wiser</surname> <given-names>SK</given-names></name><name><surname>Huber</surname> <given-names>MO</given-names></name><name><surname>Hengeveld</surname> <given-names>GM</given-names></name><name><surname>Nabuurs</surname> <given-names>GJ</given-names></name><name><surname>Tikhonova</surname> <given-names>E</given-names></name><name><surname>Borchardt</surname> <given-names>P</given-names></name><name><surname>Li</surname> <given-names>CF</given-names></name><name><surname>Powrie</surname> <given-names>LW</given-names></name><name><surname>Fischer</surname> <given-names>M</given-names></name><name><surname>Hemp</surname> <given-names>A</given-names></name><name><surname>Homeier</surname> <given-names>J</given-names></name><name><surname>Cho</surname> <given-names>P</given-names></name><name><surname>Vibrans</surname> <given-names>AC</given-names></name><name><surname>Umunay</surname> <given-names>PM</given-names></name><name><surname>Piao</surname> <given-names>SL</given-names></name><name><surname>Rowe</surname> <given-names>CW</given-names></name><name><surname>Ashton</surname> <given-names>MS</given-names></name><name><surname>Crane</surname> <given-names>PR</given-names></name><name><surname>Bradford</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Mapping tree density at a global scale</article-title><source>Nature</source><volume>525</volume><fpage>201</fpage><lpage>205</lpage><pub-id pub-id-type="doi">10.1038/nature14967</pub-id><pub-id pub-id-type="pmid">26331545</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Deng</surname> <given-names>J</given-names></name><name><surname>Dong</surname> <given-names>W</given-names></name><name><surname>Socher</surname> <given-names>R</given-names></name><name><surname>Li</surname> <given-names>L</given-names></name><name><surname>Kai Li</surname> <given-names>LF-F</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>ImageNet: a large-scale hierarchical image database2009 IEEE conference on computer vision and pattern recognition</article-title><conf-name>Presented at the 2009 IEEE Conference on Computer Vision and Pattern Recognition</conf-name><fpage>248</fpage><lpage>255</lpage><pub-id pub-id-type="doi">10.1109/CVPR.2009.5206848</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Denslow</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Disturbance and diversity in tropical rain forests: the density effect</article-title><source>Ecological Applications</source><volume>5</volume><fpage>962</fpage><lpage>968</lpage><pub-id pub-id-type="doi">10.2307/2269347</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duncanson</surname> <given-names>LI</given-names></name><name><surname>Cook</surname> <given-names>BD</given-names></name><name><surname>Hurtt</surname> <given-names>GC</given-names></name><name><surname>Dubayah</surname> <given-names>RO</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>An efficient, multi-layered crown delineation algorithm for mapping individual tree structure across multiple ecosystems</article-title><source>Remote Sensing of Environment</source><volume>154</volume><fpage>378</fpage><lpage>386</lpage><pub-id pub-id-type="doi">10.1016/j.rse.2013.07.044</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duncanson</surname> <given-names>L</given-names></name><name><surname>Rourke</surname> <given-names>O</given-names></name><name><surname>Dubayah</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Small sample sizes yield biased allometric equations in temperate forests</article-title><source>Scientific Reports</source><volume>5</volume><elocation-id>17153</elocation-id><pub-id pub-id-type="doi">10.1038/srep17153</pub-id><pub-id pub-id-type="pmid">26598233</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duncanson</surname> <given-names>L</given-names></name><name><surname>Dubayah</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Monitoring individual tree-based change with airborne lidar</article-title><source>Ecology and Evolution</source><volume>8</volume><fpage>5079</fpage><lpage>5089</lpage><pub-id pub-id-type="doi">10.1002/ece3.4075</pub-id><pub-id pub-id-type="pmid">29876083</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Enquist</surname> <given-names>BJ</given-names></name><name><surname>Abraham</surname> <given-names>AJ</given-names></name><name><surname>Harfoot</surname> <given-names>MBJ</given-names></name><name><surname>Malhi</surname> <given-names>Y</given-names></name><name><surname>Doughty</surname> <given-names>CE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The megabiota are disproportionately important for biosphere functioning</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>14369-y</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-14369-y</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fassnacht</surname> <given-names>FE</given-names></name><name><surname>Latifi</surname> <given-names>H</given-names></name><name><surname>Stereńczak</surname> <given-names>K</given-names></name><name><surname>Modzelewska</surname> <given-names>A</given-names></name><name><surname>Lefsky</surname> <given-names>M</given-names></name><name><surname>Waser</surname> <given-names>LT</given-names></name><name><surname>Straub</surname> <given-names>C</given-names></name><name><surname>Ghosh</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Review of studies on tree species classification from remotely sensed data</article-title><source>Remote Sensing of Environment</source><volume>186</volume><fpage>64</fpage><lpage>87</lpage><pub-id pub-id-type="doi">10.1016/j.rse.2016.08.013</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feldpausch</surname> <given-names>TR</given-names></name><name><surname>Banin</surname> <given-names>L</given-names></name><name><surname>Phillips</surname> <given-names>OL</given-names></name><name><surname>Baker</surname> <given-names>TR</given-names></name><name><surname>Lewis</surname> <given-names>SL</given-names></name><name><surname>Quesada</surname> <given-names>CA</given-names></name><name><surname>Affum-Baffoe</surname> <given-names>K</given-names></name><name><surname>Arets</surname> <given-names>EJMM</given-names></name><name><surname>Berry</surname> <given-names>NJ</given-names></name><name><surname>Bird</surname> <given-names>M</given-names></name><name><surname>Brondizio</surname> <given-names>ES</given-names></name><name><surname>de Camargo</surname> <given-names>P</given-names></name><name><surname>Chave</surname> <given-names>J</given-names></name><name><surname>Djagbletey</surname> <given-names>G</given-names></name><name><surname>Domingues</surname> <given-names>TF</given-names></name><name><surname>Drescher</surname> <given-names>M</given-names></name><name><surname>Fearnside</surname> <given-names>PM</given-names></name><name><surname>França</surname> <given-names>MB</given-names></name><name><surname>Fyllas</surname> <given-names>NM</given-names></name><name><surname>Lopez-Gonzalez</surname> <given-names>G</given-names></name><name><surname>Hladik</surname> <given-names>A</given-names></name><name><surname>Higuchi</surname> <given-names>N</given-names></name><name><surname>Hunter</surname> <given-names>MO</given-names></name><name><surname>Iida</surname> <given-names>Y</given-names></name><name><surname>Salim</surname> <given-names>KA</given-names></name><name><surname>Kassim</surname> <given-names>AR</given-names></name><name><surname>Keller</surname> <given-names>M</given-names></name><name><surname>Kemp</surname> <given-names>J</given-names></name><name><surname>King</surname> <given-names>DA</given-names></name><name><surname>Lovett</surname> <given-names>JC</given-names></name><name><surname>Marimon</surname> <given-names>BS</given-names></name><name><surname>Marimon-Junior</surname> <given-names>BH</given-names></name><name><surname>Lenza</surname> <given-names>E</given-names></name><name><surname>Marshall</surname> <given-names>AR</given-names></name><name><surname>Metcalfe</surname> <given-names>DJ</given-names></name><name><surname>Mitchard</surname> <given-names>ETA</given-names></name><name><surname>Moran</surname> <given-names>EF</given-names></name><name><surname>Nelson</surname> <given-names>BW</given-names></name><name><surname>Nilus</surname> <given-names>R</given-names></name><name><surname>Nogueira</surname> <given-names>EM</given-names></name><name><surname>Palace</surname> <given-names>M</given-names></name><name><surname>Patiño</surname> <given-names>S</given-names></name><name><surname>Peh</surname> <given-names>KS-H</given-names></name><name><surname>Raventos</surname> <given-names>MT</given-names></name><name><surname>Reitsma</surname> <given-names>JM</given-names></name><name><surname>Saiz</surname> <given-names>G</given-names></name><name><surname>Schrodt</surname> <given-names>F</given-names></name><name><surname>Sonké</surname> <given-names>B</given-names></name><name><surname>Taedoumg</surname> <given-names>HE</given-names></name><name><surname>Tan</surname> <given-names>S</given-names></name><name><surname>White</surname> <given-names>L</given-names></name><name><surname>Wöll</surname> <given-names>H</given-names></name><name><surname>Lloyd</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Height-diameter allometry of tropical forest trees</article-title><source>Biogeosciences</source><volume>8</volume><fpage>1081</fpage><lpage>1106</lpage><pub-id pub-id-type="doi">10.5194/bg-8-1081-2011</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferraz</surname> <given-names>A</given-names></name><name><surname>Saatchi</surname> <given-names>S</given-names></name><name><surname>Mallet</surname> <given-names>C</given-names></name><name><surname>Meyer</surname> <given-names>V</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Lidar detection of individual tree size in tropical forests</article-title><source>Remote Sensing of Environment</source><volume>183</volume><fpage>318</fpage><lpage>333</lpage><pub-id pub-id-type="doi">10.1016/j.rse.2016.05.028</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischer</surname> <given-names>FJ</given-names></name><name><surname>Labrière</surname> <given-names>N</given-names></name><name><surname>Vincent</surname> <given-names>G</given-names></name><name><surname>Hérault</surname> <given-names>B</given-names></name><name><surname>Alonso</surname> <given-names>A</given-names></name><name><surname>Memiaghe</surname> <given-names>H</given-names></name><name><surname>Bissiengou</surname> <given-names>P</given-names></name><name><surname>Kenfack</surname> <given-names>D</given-names></name><name><surname>Saatchi</surname> <given-names>S</given-names></name><name><surname>Chave</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A simulation method to infer tree allometry and forest structure from airborne laser scanning and forest inventories</article-title><source>Remote Sensing of Environment</source><volume>251</volume><elocation-id>112056</elocation-id><pub-id pub-id-type="doi">10.1016/j.rse.2020.112056</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graves</surname> <given-names>S</given-names></name><name><surname>Gearhart</surname> <given-names>J</given-names></name><name><surname>Caughlin</surname> <given-names>TT</given-names></name><name><surname>Bohlman</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018a</year><article-title>A digital mapping method for linking high-resolution remote sensing images to individual tree crowns</article-title><source>PeerJ</source><volume>6</volume><elocation-id>e27182v1</elocation-id><pub-id pub-id-type="doi">10.7287/peerj.preprints.27182v1</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graves</surname> <given-names>SJ</given-names></name><name><surname>Caughlin</surname> <given-names>TT</given-names></name><name><surname>Asner</surname> <given-names>GP</given-names></name><name><surname>Bohlman</surname> <given-names>SA</given-names></name></person-group><year iso-8601-date="2018">2018b</year><article-title>A tree-based approach to biomass estimation from remote sensing data in a tropical agricultural landscape</article-title><source>Remote Sensing of Environment</source><volume>218</volume><fpage>32</fpage><lpage>43</lpage><pub-id pub-id-type="doi">10.1016/j.rse.2018.09.009</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamraz</surname> <given-names>H</given-names></name><name><surname>Contreras</surname> <given-names>MA</given-names></name><name><surname>Zhang</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A robust approach for tree segmentation in deciduous forests using small-footprint airborne LiDAR data</article-title><source>International Journal of Applied Earth Observation and Geoinformation</source><volume>52</volume><fpage>532</fpage><lpage>541</lpage><pub-id pub-id-type="doi">10.1016/j.jag.2016.07.006</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hansen</surname> <given-names>MC</given-names></name><name><surname>Potapov</surname> <given-names>PV</given-names></name><name><surname>Moore</surname> <given-names>R</given-names></name><name><surname>Hancher</surname> <given-names>M</given-names></name><name><surname>Turubanova</surname> <given-names>SA</given-names></name><name><surname>Tyukavina</surname> <given-names>A</given-names></name><name><surname>Thau</surname> <given-names>D</given-names></name><name><surname>Stehman</surname> <given-names>SV</given-names></name><name><surname>Goetz</surname> <given-names>SJ</given-names></name><name><surname>Loveland</surname> <given-names>TR</given-names></name><name><surname>Kommareddy</surname> <given-names>A</given-names></name><name><surname>Egorov</surname> <given-names>A</given-names></name><name><surname>Chini</surname> <given-names>L</given-names></name><name><surname>Justice</surname> <given-names>CO</given-names></name><name><surname>Townshend</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>High-resolution global maps of 21st-century forest cover change</article-title><source>Science</source><volume>342</volume><fpage>850</fpage><lpage>853</lpage><pub-id pub-id-type="doi">10.1126/science.1244693</pub-id><pub-id pub-id-type="pmid">24233722</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jucker</surname> <given-names>T</given-names></name><name><surname>Caspersen</surname> <given-names>J</given-names></name><name><surname>Chave</surname> <given-names>J</given-names></name><name><surname>Antin</surname> <given-names>C</given-names></name><name><surname>Barbier</surname> <given-names>N</given-names></name><name><surname>Bongers</surname> <given-names>F</given-names></name><name><surname>Dalponte</surname> <given-names>M</given-names></name><name><surname>van Ewijk</surname> <given-names>KY</given-names></name><name><surname>Forrester</surname> <given-names>DI</given-names></name><name><surname>Haeni</surname> <given-names>M</given-names></name><name><surname>Higgins</surname> <given-names>SI</given-names></name><name><surname>Holdaway</surname> <given-names>RJ</given-names></name><name><surname>Iida</surname> <given-names>Y</given-names></name><name><surname>Lorimer</surname> <given-names>C</given-names></name><name><surname>Marshall</surname> <given-names>PL</given-names></name><name><surname>Momo</surname> <given-names>S</given-names></name><name><surname>Moncrieff</surname> <given-names>GR</given-names></name><name><surname>Ploton</surname> <given-names>P</given-names></name><name><surname>Poorter</surname> <given-names>L</given-names></name><name><surname>Rahman</surname> <given-names>KA</given-names></name><name><surname>Schlund</surname> <given-names>M</given-names></name><name><surname>Sonké</surname> <given-names>B</given-names></name><name><surname>Sterck</surname> <given-names>FJ</given-names></name><name><surname>Trugman</surname> <given-names>AT</given-names></name><name><surname>Usoltsev</surname> <given-names>VA</given-names></name><name><surname>Vanderwel</surname> <given-names>MC</given-names></name><name><surname>Waldner</surname> <given-names>P</given-names></name><name><surname>Wedeux</surname> <given-names>BM</given-names></name><name><surname>Wirth</surname> <given-names>C</given-names></name><name><surname>Wöll</surname> <given-names>H</given-names></name><name><surname>Woods</surname> <given-names>M</given-names></name><name><surname>Xiang</surname> <given-names>W</given-names></name><name><surname>Zimmermann</surname> <given-names>NE</given-names></name><name><surname>Coomes</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Allometric equations for integrating remote sensing imagery into forest monitoring programmes</article-title><source>Global Change Biology</source><volume>23</volume><fpage>177</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1111/gcb.13388</pub-id><pub-id pub-id-type="pmid">27381364</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laubhann</surname> <given-names>D</given-names></name><name><surname>Sterba</surname> <given-names>H</given-names></name><name><surname>Reinds</surname> <given-names>GJ</given-names></name><name><surname>De Vries</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The impact of atmospheric deposition and climate on forest growth in european monitoring plots: an individual tree growth model</article-title><source>Forest Ecology and Management</source><volume>258</volume><fpage>1751</fpage><lpage>1761</lpage><pub-id pub-id-type="doi">10.1016/j.foreco.2008.09.050</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>W</given-names></name><name><surname>Guo</surname> <given-names>Q</given-names></name><name><surname>Jakubowski</surname> <given-names>MK</given-names></name><name><surname>Kelly</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A new method for segmenting individual trees from the lidar point cloud</article-title><source>Photogrammetric Engineering &amp; Remote Sensing</source><volume>78</volume><fpage>75</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.14358/PERS.78.1.75</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liang</surname> <given-names>J</given-names></name><name><surname>Crowther</surname> <given-names>TW</given-names></name><name><surname>Picard</surname> <given-names>N</given-names></name><name><surname>Wiser</surname> <given-names>S</given-names></name><name><surname>Zhou</surname> <given-names>M</given-names></name><name><surname>Alberti</surname> <given-names>G</given-names></name><name><surname>Schulze</surname> <given-names>ED</given-names></name><name><surname>McGuire</surname> <given-names>AD</given-names></name><name><surname>Bozzato</surname> <given-names>F</given-names></name><name><surname>Pretzsch</surname> <given-names>H</given-names></name><name><surname>de-Miguel</surname> <given-names>S</given-names></name><name><surname>Paquette</surname> <given-names>A</given-names></name><name><surname>Hérault</surname> <given-names>B</given-names></name><name><surname>Scherer-Lorenzen</surname> <given-names>M</given-names></name><name><surname>Barrett</surname> <given-names>CB</given-names></name><name><surname>Glick</surname> <given-names>HB</given-names></name><name><surname>Hengeveld</surname> <given-names>GM</given-names></name><name><surname>Nabuurs</surname> <given-names>GJ</given-names></name><name><surname>Pfautsch</surname> <given-names>S</given-names></name><name><surname>Viana</surname> <given-names>H</given-names></name><name><surname>Vibrans</surname> <given-names>AC</given-names></name><name><surname>Ammer</surname> <given-names>C</given-names></name><name><surname>Schall</surname> <given-names>P</given-names></name><name><surname>Verbyla</surname> <given-names>D</given-names></name><name><surname>Tchebakova</surname> <given-names>N</given-names></name><name><surname>Fischer</surname> <given-names>M</given-names></name><name><surname>Watson</surname> <given-names>JV</given-names></name><name><surname>Chen</surname> <given-names>HY</given-names></name><name><surname>Lei</surname> <given-names>X</given-names></name><name><surname>Schelhaas</surname> <given-names>MJ</given-names></name><name><surname>Lu</surname> <given-names>H</given-names></name><name><surname>Gianelle</surname> <given-names>D</given-names></name><name><surname>Parfenova</surname> <given-names>EI</given-names></name><name><surname>Salas</surname> <given-names>C</given-names></name><name><surname>Lee</surname> <given-names>E</given-names></name><name><surname>Lee</surname> <given-names>B</given-names></name><name><surname>Kim</surname> <given-names>HS</given-names></name><name><surname>Bruelheide</surname> <given-names>H</given-names></name><name><surname>Coomes</surname> <given-names>DA</given-names></name><name><surname>Piotto</surname> <given-names>D</given-names></name><name><surname>Sunderland</surname> <given-names>T</given-names></name><name><surname>Schmid</surname> <given-names>B</given-names></name><name><surname>Gourlet-Fleury</surname> <given-names>S</given-names></name><name><surname>Sonké</surname> <given-names>B</given-names></name><name><surname>Tavani</surname> <given-names>R</given-names></name><name><surname>Zhu</surname> <given-names>J</given-names></name><name><surname>Brandl</surname> <given-names>S</given-names></name><name><surname>Vayreda</surname> <given-names>J</given-names></name><name><surname>Kitahara</surname> <given-names>F</given-names></name><name><surname>Searle</surname> <given-names>EB</given-names></name><name><surname>Neldner</surname> <given-names>VJ</given-names></name><name><surname>Ngugi</surname> <given-names>MR</given-names></name><name><surname>Baraloto</surname> <given-names>C</given-names></name><name><surname>Frizzera</surname> <given-names>L</given-names></name><name><surname>Bałazy</surname> <given-names>R</given-names></name><name><surname>Oleksyn</surname> <given-names>J</given-names></name><name><surname>Zawiła-Niedźwiecki</surname> <given-names>T</given-names></name><name><surname>Bouriaud</surname> <given-names>O</given-names></name><name><surname>Bussotti</surname> <given-names>F</given-names></name><name><surname>Finér</surname> <given-names>L</given-names></name><name><surname>Jaroszewicz</surname> <given-names>B</given-names></name><name><surname>Jucker</surname> <given-names>T</given-names></name><name><surname>Valladares</surname> <given-names>F</given-names></name><name><surname>Jagodzinski</surname> <given-names>AM</given-names></name><name><surname>Peri</surname> <given-names>PL</given-names></name><name><surname>Gonmadje</surname> <given-names>C</given-names></name><name><surname>Marthy</surname> <given-names>W</given-names></name><name><surname>O'Brien</surname> <given-names>T</given-names></name><name><surname>Martin</surname> <given-names>EH</given-names></name><name><surname>Marshall</surname> <given-names>AR</given-names></name><name><surname>Rovero</surname> <given-names>F</given-names></name><name><surname>Bitariho</surname> <given-names>R</given-names></name><name><surname>Niklaus</surname> <given-names>PA</given-names></name><name><surname>Alvarez-Loayza</surname> <given-names>P</given-names></name><name><surname>Chamuya</surname> <given-names>N</given-names></name><name><surname>Valencia</surname> <given-names>R</given-names></name><name><surname>Mortier</surname> <given-names>F</given-names></name><name><surname>Wortel</surname> <given-names>V</given-names></name><name><surname>Engone-Obiang</surname> <given-names>NL</given-names></name><name><surname>Ferreira</surname> <given-names>LV</given-names></name><name><surname>Odeke</surname> <given-names>DE</given-names></name><name><surname>Vasquez</surname> <given-names>RM</given-names></name><name><surname>Lewis</surname> <given-names>SL</given-names></name><name><surname>Reich</surname> <given-names>PB</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Positive biodiversity-productivity relationship predominant in global forests</article-title><source>Science</source><volume>354</volume><elocation-id>aaf8957</elocation-id><pub-id pub-id-type="doi">10.1126/science.aaf8957</pub-id><pub-id pub-id-type="pmid">27738143</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marvin</surname> <given-names>DC</given-names></name><name><surname>Asner</surname> <given-names>GP</given-names></name><name><surname>Knapp</surname> <given-names>DE</given-names></name><name><surname>Anderson</surname> <given-names>CB</given-names></name><name><surname>Martin</surname> <given-names>RE</given-names></name><name><surname>Sinca</surname> <given-names>F</given-names></name><name><surname>Tupayachi</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Amazonian landscapes and the Bias in field studies of forest structure and biomass</article-title><source>PNAS</source><volume>111</volume><fpage>E5224</fpage><lpage>E5232</lpage><pub-id pub-id-type="doi">10.1073/pnas.1412999111</pub-id><pub-id pub-id-type="pmid">25422434</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maschler</surname> <given-names>J</given-names></name><name><surname>Atzberger</surname> <given-names>C</given-names></name><name><surname>Immitzer</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Individual tree crown segmentation and classification of 13 tree species using airborne hyperspectral data</article-title><source>Remote Sensing</source><volume>10</volume><elocation-id>1218</elocation-id><pub-id pub-id-type="doi">10.3390/rs10081218</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Puliti</surname> <given-names>S</given-names></name><name><surname>Breidenbach</surname> <given-names>J</given-names></name><name><surname>Astrup</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Estimation of forest growing stock volume with UAV laser scanning data: can it be done without field data?</article-title><source>Remote Sensing</source><volume>12</volume><elocation-id>1245</elocation-id><pub-id pub-id-type="doi">10.3390/rs12081245</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roussel</surname> <given-names>J-R</given-names></name><name><surname>Auty</surname> <given-names>D</given-names></name><name><surname>Coops</surname> <given-names>NC</given-names></name><name><surname>Tompalski</surname> <given-names>P</given-names></name><name><surname>Goodbody</surname> <given-names>TRH</given-names></name><name><surname>Meador</surname> <given-names>AS</given-names></name><name><surname>Bourdon</surname> <given-names>J-F</given-names></name><name><surname>de Boissieu</surname> <given-names>F</given-names></name><name><surname>Achim</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>lidR: an R package for analysis of airborne laser scanning (ALS) data</article-title><source>Remote Sensing of Environment</source><volume>251</volume><elocation-id>112061</elocation-id><pub-id pub-id-type="doi">10.1016/j.rse.2020.112061</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Satdichanh</surname> <given-names>M</given-names></name><name><surname>Ma</surname> <given-names>H</given-names></name><name><surname>Yan</surname> <given-names>K</given-names></name><name><surname>Dossa</surname> <given-names>GGO</given-names></name><name><surname>Winowiecki</surname> <given-names>L</given-names></name><name><surname>Vågen</surname> <given-names>T‐G</given-names></name><name><surname>Gassner</surname> <given-names>A</given-names></name><name><surname>Xu</surname> <given-names>J</given-names></name><name><surname>Harrison</surname> <given-names>RD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Phylogenetic diversity correlated with above‐ground biomass production during forest succession: evidence from tropical forests in southeast asia</article-title><source>Journal of Ecology</source><volume>107</volume><fpage>1419</fpage><lpage>1432</lpage><pub-id pub-id-type="doi">10.1111/1365-2745.13112</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname> <given-names>FD</given-names></name><name><surname>Ferraz</surname> <given-names>A</given-names></name><name><surname>Hancock</surname> <given-names>S</given-names></name><name><surname>Duncanson</surname> <given-names>LI</given-names></name><name><surname>Dubayah</surname> <given-names>RO</given-names></name><name><surname>Pavlick</surname> <given-names>RP</given-names></name><name><surname>Schimel</surname> <given-names>DS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Towards mapping the diversity of canopy structure from space with GEDI</article-title><source>Environmental Research Letters</source><volume>15</volume><elocation-id>115006</elocation-id><pub-id pub-id-type="doi">10.1088/1748-9326/ab9e99</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shirley</surname> <given-names>SM</given-names></name><name><surname>Yang</surname> <given-names>Z</given-names></name><name><surname>Hutchinson</surname> <given-names>RA</given-names></name><name><surname>Alexander</surname> <given-names>JD</given-names></name><name><surname>McGarigal</surname> <given-names>K</given-names></name><name><surname>Betts</surname> <given-names>MG</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Species distribution modelling for the people: unclassified landsat TM imagery predicts bird occurrence at fine resolutions</article-title><source>Diversity and Distributions</source><volume>19</volume><fpage>855</fpage><lpage>866</lpage><pub-id pub-id-type="doi">10.1111/ddi.12093</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silva</surname> <given-names>CA</given-names></name><name><surname>Hudak</surname> <given-names>AT</given-names></name><name><surname>Vierling</surname> <given-names>LA</given-names></name><name><surname>Loudermilk</surname> <given-names>EL</given-names></name><name><surname>O’Brien</surname> <given-names>JJ</given-names></name><name><surname>Hiers</surname> <given-names>JK</given-names></name><name><surname>Jack</surname> <given-names>SB</given-names></name><name><surname>Gonzalez-Benecke</surname> <given-names>C</given-names></name><name><surname>Lee</surname> <given-names>H</given-names></name><name><surname>Falkowski</surname> <given-names>MJ</given-names></name><name><surname>Khosravipour</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Imputation of Individual Longleaf Pine ( <italic>Pinus palustris</italic> Mill.) Tree Attributes from Field and LiDAR Data</article-title><source>Canadian Journal of Remote Sensing</source><volume>42</volume><fpage>554</fpage><lpage>573</lpage><pub-id pub-id-type="doi">10.1080/07038992.2016.1196582</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stovall</surname> <given-names>AEL</given-names></name><name><surname>Shugart</surname> <given-names>H</given-names></name><name><surname>Yang</surname> <given-names>X</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Tree height explains mortality risk during an intense drought</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>4385</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-12380-6</pub-id><pub-id pub-id-type="pmid">31558795</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>Z</given-names></name><name><surname>Chlus</surname> <given-names>A</given-names></name><name><surname>Geygan</surname> <given-names>R</given-names></name><name><surname>Ye</surname> <given-names>Z</given-names></name><name><surname>Zheng</surname> <given-names>T</given-names></name><name><surname>Singh</surname> <given-names>A</given-names></name><name><surname>Couture</surname> <given-names>JJ</given-names></name><name><surname>Cavender‐Bares</surname> <given-names>J</given-names></name><name><surname>Kruger</surname> <given-names>EL</given-names></name><name><surname>Townsend</surname> <given-names>PA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Foliar functional traits from imaging spectroscopy across biomes in eastern north america</article-title><source>New Phytologist</source><volume>228</volume><fpage>494</fpage><lpage>511</lpage><pub-id pub-id-type="doi">10.1111/nph.16711</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weinstein</surname> <given-names>BG</given-names></name><name><surname>Marconi</surname> <given-names>S</given-names></name><name><surname>Bohlman</surname> <given-names>S</given-names></name><name><surname>Zare</surname> <given-names>A</given-names></name><name><surname>White</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Individual Tree-Crown detection in RGB imagery using Semi-Supervised deep learning neural networks</article-title><source>Remote Sensing</source><volume>11</volume><elocation-id>1309</elocation-id><pub-id pub-id-type="doi">10.3390/rs11111309</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Weinstein</surname> <given-names>B</given-names></name><name><surname>Marconi</surname> <given-names>S</given-names></name><name><surname>Zare</surname> <given-names>AA</given-names></name><name><surname>Bohlman</surname> <given-names>S</given-names></name><name><surname>Graves</surname> <given-names>S</given-names></name><name><surname>Singh</surname> <given-names>A</given-names></name><name><surname>White</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2020">2020a</year><data-title>NEON tree crowns dataset</data-title><source>Zenodo</source><version designator="0.0.1">0.0.1</version><ext-link ext-link-type="uri" xlink:href="http://doi.org/10.5281/zenodo.3765872">http://doi.org/10.5281/zenodo.3765872</ext-link></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weinstein</surname> <given-names>BG</given-names></name><name><surname>Marconi</surname> <given-names>S</given-names></name><name><surname>Bohlman</surname> <given-names>SA</given-names></name><name><surname>Zare</surname> <given-names>A</given-names></name><name><surname>White</surname> <given-names>EP</given-names></name></person-group><year iso-8601-date="2020">2020b</year><article-title>Cross-site learning in deep learning RGB tree crown detection</article-title><source>Ecological Informatics</source><volume>56</volume><elocation-id>101061</elocation-id><pub-id pub-id-type="doi">10.1016/j.ecoinf.2020.101061</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weinstein</surname> <given-names>BG</given-names></name><name><surname>Marconi</surname> <given-names>S</given-names></name><name><surname>Aubry-Kientz</surname> <given-names>MM</given-names></name><name><surname>Vincent</surname> <given-names>G</given-names></name><name><surname>Senyondo</surname> <given-names>H</given-names></name><name><surname>White</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2020">2020c</year><article-title>DeepForest: a Python package for RGB deep learning tree crown delineation</article-title><source>Methods in Ecology and Evolution</source><volume>11</volume><fpage>1743</fpage><lpage>1751</lpage><pub-id pub-id-type="doi">10.1111/2041-210X.13472</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Williams</surname> <given-names>J</given-names></name><name><surname>Schönlieb</surname> <given-names>C-B</given-names></name><name><surname>Swinfield</surname> <given-names>T</given-names></name><name><surname>Irawan</surname> <given-names>B</given-names></name><name><surname>Achmad</surname> <given-names>E</given-names></name><name><surname>Zudhi</surname> <given-names>M</given-names></name><name><surname>Habibi</surname> <given-names>GE</given-names></name><name><surname>Coomes</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2020">2020a</year><article-title>SLIC-UAV: a method for monitoring recovery in tropical restoration projects through identification of signature species using UAVs</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2006.06624">https://arxiv.org/abs/2006.06624</ext-link></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname> <given-names>J</given-names></name><name><surname>Schonlieb</surname> <given-names>C-B</given-names></name><name><surname>Swinfield</surname> <given-names>T</given-names></name><name><surname>Lee</surname> <given-names>J</given-names></name><name><surname>Cai</surname> <given-names>X</given-names></name><name><surname>Qie</surname> <given-names>L</given-names></name><name><surname>Coomes</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2020">2020b</year><article-title>3d segmentation of trees through a flexible multiclass graph cut algorithm</article-title><source>IEEE Transactions on Geoscience and Remote Sensing</source><volume>58</volume><fpage>754</fpage><lpage>776</lpage><pub-id pub-id-type="doi">10.1109/TGRS.2019.2940146</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname> <given-names>Z</given-names></name><name><surname>Zeng</surname> <given-names>Y</given-names></name><name><surname>Schneider</surname> <given-names>FD</given-names></name><name><surname>Zhao</surname> <given-names>Y</given-names></name><name><surname>Zhao</surname> <given-names>D</given-names></name><name><surname>Schmid</surname> <given-names>B</given-names></name><name><surname>Schaepman</surname> <given-names>ME</given-names></name><name><surname>Morsdorf</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Mapping functional diversity using individual tree-based morphological and physiological traits in a subtropical forest</article-title><source>Remote Sensing of Environment</source><volume>252</volume><elocation-id>112170</elocation-id><pub-id pub-id-type="doi">10.1016/j.rse.2020.112170</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec id="s8" sec-type="appendix"><title>NEON site abbreviations</title><boxed-text><table-wrap id="inlinetable1" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th valign="top">Site name</th><th valign="top">Site ID</th><th valign="top">Domain number</th><th valign="top">State</th><th valign="top">Latitude</th><th valign="top">Longitude</th></tr></thead><tbody><tr><td valign="top">Abby Road</td><td valign="top">ABBY</td><td valign="top">D16</td><td valign="top">WA</td><td valign="top">45.76243</td><td valign="top">−122.33033</td></tr><tr><td valign="top">Bartlett Experimental Forest</td><td valign="top">BART</td><td valign="top">D01</td><td valign="top">NH</td><td valign="top">44.06388</td><td valign="top">−71.28731</td></tr><tr><td valign="top">Blandy Experimental Farm</td><td valign="top">BLAN</td><td valign="top">D02</td><td valign="top">VA</td><td valign="top">39.06026</td><td valign="top">−78.07164</td></tr><tr><td valign="top">Caribou-Poker Creeks Research Watershed</td><td valign="top">BONA</td><td valign="top">D19</td><td valign="top">AK</td><td valign="top">65.15401</td><td valign="top">−147.50258</td></tr><tr><td valign="top">LBJ National Grassland</td><td valign="top">CLBJ</td><td valign="top">D11</td><td valign="top">TX</td><td valign="top">33.40123</td><td valign="top">−97.57</td></tr><tr><td valign="top">Rio Cupeyes</td><td valign="top">CUPE</td><td valign="top">D04</td><td valign="top">PR</td><td valign="top">18.11352</td><td valign="top">−66.98676</td></tr><tr><td valign="top">Delta Junction</td><td valign="top">DEJU</td><td valign="top">D19</td><td valign="top">AK</td><td valign="top">63.88112</td><td valign="top">−145.75136</td></tr><tr><td valign="top">Dead Lake</td><td valign="top">DELA</td><td valign="top">D08</td><td valign="top">AL</td><td valign="top">32.54172</td><td valign="top">−87.80389</td></tr><tr><td valign="top">Disney Wilderness Preserve</td><td valign="top">DSNY</td><td valign="top">D03</td><td valign="top">FL</td><td valign="top">28.12504</td><td valign="top">−81.4362</td></tr><tr><td valign="top">Guanica Forest</td><td valign="top">GUAN</td><td valign="top">D04</td><td valign="top">PR</td><td valign="top">17.96955</td><td valign="top">−66.8687</td></tr><tr><td valign="top">Harvard Forest</td><td valign="top">HARV</td><td valign="top">D01</td><td valign="top">MA</td><td valign="top">42.5369</td><td valign="top">−72.17266</td></tr><tr><td valign="top">Healy</td><td valign="top">HEAL</td><td valign="top">D19</td><td valign="top">AK</td><td valign="top">63.87569</td><td valign="top">−149.21334</td></tr><tr><td valign="top">Lower Hop Brook</td><td valign="top">HOPB</td><td valign="top">D01</td><td valign="top">MA</td><td valign="top">42.47179</td><td valign="top">−72.32963</td></tr><tr><td valign="top">Jones Ecological Research Center</td><td valign="top">JERC</td><td valign="top">D03</td><td valign="top">GA</td><td valign="top">31.19484</td><td valign="top">−84.46861</td></tr><tr><td valign="top">Jornada LTER</td><td valign="top">JORN</td><td valign="top">D14</td><td valign="top">NM</td><td valign="top">32.59068</td><td valign="top">−106.84254</td></tr><tr><td valign="top">Konza Prairie Biological Station</td><td valign="top">KONZ</td><td valign="top">D06</td><td valign="top">KS</td><td valign="top">39.10077</td><td valign="top">−96.56309</td></tr><tr><td valign="top">Lajas Experimental Station</td><td valign="top">LAJA</td><td valign="top">D04</td><td valign="top">PR</td><td valign="top">18.02125</td><td valign="top">−67.0769</td></tr><tr><td valign="top">Lenoir Landing</td><td valign="top">LENO</td><td valign="top">D08</td><td valign="top">AL</td><td valign="top">31.85388</td><td valign="top">−88.16122</td></tr><tr><td valign="top">Mountain Lake Biological Station</td><td valign="top">MLBS</td><td valign="top">D07</td><td valign="top">VA</td><td valign="top">37.37828</td><td valign="top">−80.52484</td></tr><tr><td valign="top">Moab</td><td valign="top">MOAB</td><td valign="top">D13</td><td valign="top">UT</td><td valign="top">38.24833</td><td valign="top">−109.38827</td></tr><tr><td valign="top">Niwot Ridge Mountain Research Station</td><td valign="top">NIWO</td><td valign="top">D13</td><td valign="top">CO</td><td valign="top">40.05425</td><td valign="top">−105.58237</td></tr><tr><td valign="top">Northern Great Plains Research Laboratory</td><td valign="top">NOGP</td><td valign="top">D09</td><td valign="top">ND</td><td valign="top">46.76972</td><td valign="top">−100.91535</td></tr><tr><td valign="top">Klemme Range Research Station</td><td valign="top">OAES</td><td valign="top">D11</td><td valign="top">OK</td><td valign="top">35.41059</td><td valign="top">−99.05879</td></tr><tr><td valign="top">Ordway-Swisher Biological Station</td><td valign="top">OSBS</td><td valign="top">D03</td><td valign="top">FL</td><td valign="top">29.68927</td><td valign="top">−81.99343</td></tr><tr><td valign="top">Red Butte Creek</td><td valign="top">REDB</td><td valign="top">D15</td><td valign="top">UT</td><td valign="top">40.78374</td><td valign="top">−111.79765</td></tr><tr><td valign="top">Rocky Mountain National Park, CASTNET</td><td valign="top">RMNP</td><td valign="top">D10</td><td valign="top">CO</td><td valign="top">40.27591</td><td valign="top">−105.54592</td></tr><tr><td valign="top">Smithsonian Conservation Biology Institute</td><td valign="top">SCBI</td><td valign="top">D02</td><td valign="top">VA</td><td valign="top">38.89292</td><td valign="top">−78.1395</td></tr><tr><td valign="top">Smithsonian Environmental Research Center</td><td valign="top">SERC</td><td valign="top">D02</td><td valign="top">MD</td><td valign="top">38.89008</td><td valign="top">−76.56001</td></tr><tr><td valign="top">San Joaquin Experimental Range</td><td valign="top">SJER</td><td valign="top">D17</td><td valign="top">CA</td><td valign="top">37.10878</td><td valign="top">−119.73228</td></tr><tr><td valign="top">Soaproot Saddle</td><td valign="top">SOAP</td><td valign="top">D17</td><td valign="top">CA</td><td valign="top">37.03337</td><td valign="top">−119.26219</td></tr><tr><td valign="top">Santa Rita Experimental Range</td><td valign="top">SRER</td><td valign="top">D14</td><td valign="top">AZ</td><td valign="top">31.91068</td><td valign="top">−110.83549</td></tr><tr><td valign="top">Talladega National Forest</td><td valign="top">TALL</td><td valign="top">D08</td><td valign="top">AL</td><td valign="top">32.95046</td><td valign="top">−87.39327</td></tr><tr><td valign="top">Lower Teakettle</td><td valign="top">TEAK</td><td valign="top">D17</td><td valign="top">CA</td><td valign="top">37.00583</td><td valign="top">−119.00602</td></tr><tr><td valign="top">West St Louis Creek</td><td valign="top">WLOU</td><td valign="top">D13</td><td valign="top">CO</td><td valign="top">39.89137</td><td valign="top">−105.9154</td></tr><tr><td valign="top">Woodworth</td><td valign="top">WOOD</td><td valign="top">D09</td><td valign="top">ND</td><td valign="top">47.12823</td><td valign="top">−99.24136</td></tr><tr><td valign="top">Wind River Experimental Forest</td><td valign="top">WREF</td><td valign="top">D16</td><td valign="top">WA</td><td valign="top">45.82049</td><td valign="top">−121.95191</td></tr><tr><td valign="top">Yellowstone Northern Range (Frog Rock)</td><td valign="top">YELL</td><td valign="top">D12</td><td valign="top">WY</td><td valign="top">44.95348</td><td valign="top">−110.53914</td></tr></tbody></table></table-wrap></boxed-text></sec></app></app-group></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.62922.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Schmid</surname><given-names>Bernhard</given-names></name><role>Reviewing Editor</role><aff><institution>University of Zurich</institution><country>Switzerland</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Schmid</surname><given-names>Bernhard</given-names> </name><role>Reviewer</role><aff><institution>University of Zurich</institution><country>Switzerland</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>This paper presents a large data set of tree positions, heights and crown areas from 37 NEON sites across North America. Data obtained by remote sensing techniques about individual trees offer a large step forward from pixel-level data for ecologists interested in forest structure, size-density-diversity relationships and how these affect ecosystem functioning, arguably the most important topic in current forest research.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;NEON Crowns: a remote sensing derived dataset of 100 million individual tree crowns&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, including Bernhard Schmid as the Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Meredith Schuman as the Senior Editor.</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>As the editors have judged that your manuscript is of interest, but as described below that additional work is required before it is published, we would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). First, because many researchers have temporarily lost access to the labs, we will give authors as much time as they need to submit revised manuscripts. We are also offering, if you choose, to post the manuscript to bioRxiv (if it is not already there) along with this decision letter and a formal designation that the manuscript is &quot;in revision at <italic>eLife</italic>&quot;. Please let us know if you would like to pursue this option. (If your work is more suitable for medRxiv, you will need to post the preprint yourself, as the mechanisms for us to do so are still in development.)</p><p>Summary:</p><p>This paper presents a large data set of tree positions, heights and crown areas from 37 NEON sites across North America. The authors used airborne RGB data and a previously published Python software tool to delineate crowns of individual canopy trees. They then compared a subset of these crowns with crowns identified by visual inspection of the airborne pictures and with field-measured stem positions and height and crown data. The accuracy of the automatic detection was about 70 %. Lidar measurements were used to exclude trees or objects less than 3 m tall and to estimate the height of the trees with an accuracy of roughly 2 m RMSE.</p><p>The authors discuss some possible uses of the individual-level tree data, but clearly these potential uses could be much extended if the data set could be updated and improved as further information becomes available, which the authors point out. It is difficult to judge to which extent this would be possible with the particular approach used in the paper. The authors would have to provide at least a summary of the algorithms implemented in their software tool (e.g. as supplement), because even the previously published paper in Methods in Ecology and Evolution does not provide this information, nor could I find it on the website of the tool.</p><p>Essential revisions:</p><p>The major issue that should be solved is that the LiDAR data should be included to improve the crown detection efficiency:</p><p>i) The reviewers are very surprised that you do not to use the LiDAR data in the segmentation of the single tree crowns. There exists a large body of different LiDAR-based individual tree crown (ITC) approaches, a number of benchmarking studies and open-source benchmarking datasets for comparing new methods with older ones.</p><p>ii) If you use LiDAR based ITC methods, you could remedy some of the error sources of your current approach, i.e. shaded crowns and sub-dominant trees. The references to such approaches are missing, even in contexts directly related to some of the potential applications of the dataset, i.e., the ITC-related papers of Duncanson et al., working on two of the NEON sites and, for the first time, showing the potential of LiDAR ITC-based allometries.</p><p>iii) Why not use height as a fourth dimension besides RGB? For example, two neighboring trees with similar optical properties could be separated by height. Also in general, does this approach allow to add more bands as from multi- or hyperspectral sensors?</p><p>iv) Besides the important measures of stem density and crown size distributions, the dataset could also be used as a starting point to refine other individual tree crown detection methods, for example using lidar point cloud segmentation in 3D space.</p><p>v) Finally, it's worth mentioning the various efforts for individual tree detection from airborne laser scanning data. It would be good to compare your results to point-cloud based segmentation, or also to test the use of this dataset for more extensive 3D segmentation algorithms, e.g. by using the tree locations as seed points for 3D segmentation of the point cloud.</p><p>Here is a list of references on ITC from LIDAR/RGB Imagery:</p><p>[1] Y. Wang, J. Hyyppa, X. Liang, H. Kaartinen, X. Yu, E. Lindberg, J. Holmgren, Y. Qin, C. Mallet, A. Ferraz, H. Torabzadeh, F. Morsdorf, L. Zhu, J. Liu, and P. Alho, &quot;International benchmarking of the individual tree detection methods for modeling 3-d canopy structure for silviculture and forest ecology using airborne laser scanning,&quot; IEEE Transactions on Geoscience and Remote Sensing, vol. 54, no. 9, pp. 5011-5027, 2016.</p><p>[2] M. Parkan and D. Tuia, &quot;Individual tree segmentation in deciduous forests using geodesic voting,&quot; in 2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS), pp. 637-640, July 2015.</p><p>[3] L. Duncanson, O. Rourke, and R. Dubayah, &quot;Small sample sizes yield biased allometric equations in temperate forests,&quot; Scientific Reports, vol. 5, no. 1, p. 17153, 2015.</p><p>[4] L. Duncanson, R. Dubayah, B. Cook, J. Rosette, and G. Parker, &quot;The importance of spatial detail: Assessing the utility of individual crown information and scaling approaches for lidar-based biomass density estimation,&quot; Remote Sensing of Environment, vol. 168, pp. 102 – 112, 2015.</p><p>[5] L. Eysn, M. Hollaus, E. Lindberg, F. Berger, J.-M. Monnet, M. Dalponte, M. Kobal, M. Pellegrini, E. Lingua, D. Mongus, and N. Pfeifer, &quot;A benchmark of lidar-based single tree detection methods using heterogeneous forest data from the alpine space,&quot; Forests, vol. 6, no. 5, p. 1721, 2015.</p><p>[6] L. Duncanson, B. Cook, G. Hurtt, and R. Dubayah, &quot;An efficient, multi-layered crown delineation algorithm for mapping individual tree structure across multiple ecosystems,&quot; Remote Sensing of Environment, vol. 154, pp. 378 – 386, 2014.</p><p>[7] A. Ferraz, F. Bretar, S. Jacquemoud, G. Gon?alves, L. Pereira, M. Tom?, and P. Soares, &quot;3-d mapping of a multi-layered mediterranean forest using als data,&quot; Remote Sensing of Environment, vol. 121, pp. 210-223, June 2012.</p><p>[8] H. Kaartinen, J. Hyypp ̈a, X. Yu, M. Vastaranta, H. Hyypp ̈a, A. Kukko, M. Holopainen, C. Heipke, M. Hirschmugl, F. Morsdorf, E. Næsset, J. Pitk ̈anen, S. Popescu, S. Solberg, B. M. Wolf, and J.-C. Wu, &quot;An international comparison of individual tree detection and extraction using airborne laser scanning,&quot; Remote Sensing, vol. 4, pp. 950-974, 2012.</p><p>[9] J. Vauhkonen, L. Ene, S. Gupta, J. Heinzel, J. Holmgren, J. Pitk ̈anen, S. Solberg, Y. Wang, H. Weinacker, K. M. Hauglin, V. Lien, P. Packal ́en, T. Gobakken, B. Koch, E. Næsset, T. Tokola, and M. Maltamo, &quot;Comparative testing of single-tree detection algorithms under different types of forest,&quot; Forestry, vol. 85, no. 1, pp. 27-40, 2012.</p><p>[10] H. O. Orka, E. Næsset, and O. M. Bollandsas, &quot;Classifying species of individual trees by intensity and structure features derived from airborne laser scanner data,&quot; Remote Sensing of Environment, vol. 113, no. 6, pp. 1163 – 1174, 2009.</p><p>[11] J. Reitberger, P. Krzystek, and U. Stilla, &quot;Analysis of full waveform lidar data for the classification of deciduous and coniferous trees,&quot; International Journal of Remote Sensing, vol. 29, no. 5, pp. 1407-1431, 2008.[12] Y. Wang, H. Weinacker, and B. Koch, &quot;A lidar point cloud based procedure for vertical canopy structure analysis and 3d single tree modelling in forest,&quot; Sensors, vol. 8, no. 6, pp. 3938-3951, 2008.</p><p>[13] S. Solberg, E. Naesset, and O. Bollandsas, &quot;Single tree segmentation using airborne laser scanner data in a structurally heterogeneous spruce forest,&quot; Photogrammetric Engineering and Remote Sensing, vol. 72, no. 12, pp. 1369-1378, 2006.</p><p>[14] D. G. Leckie, F. A. Gougeon, S. Tinis, T. Nelson, C. N. Burnett, and D. Paradine, &quot;Automated tree recognition in old growth conifer stands with high resolution digital imagery,&quot; Remote Sensing of Environment, vol. 94, no. 3, pp. 311-326, 2004.</p><p>[15] F. Morsdorf, E. Meier, B. K ̈otz, K. I. Itten, M. Dobbertin, and B. Allg ̈ower, &quot;Lidar-based geometric reconstruction of boreal type forest stands at single tree level for forest and wildland fire management,&quot; Remote Sensing of Environment, vol. 92, no. 3, pp. 353 – 362, 2004. Forest Fire Prevention and Assessment.</p><p>[16] T. Brandtberg, T. A. Warner, R. E. Landenberger, and J. B. McGraw, &quot;Detection and analysis of individual leaf-off tree crowns in small footprint, high sampling density lidar data from the eastern deciduous forest in north america,&quot; Remote Sens. Environ., vol. 85, no. 3, pp. 290-303, 2003.</p><p>[17] H.-E. Andersen, S. E. Reutebuch, and G. F. Schreuder, &quot;Automated individual tree measurement through morphological analysis of a lidar-based canopy surface model,&quot; 2001.</p><p>[18] J. Hyypp ̈a, O. Kelle, M. Lehikoinen, and M. Inkinen, &quot;A segmentation-based method to retrieve stem volume estimates from 3-d tree height models produced by laser scanners,&quot; IEEE Transactions on Geoscience and Remote Sensing, vol. 39, pp. 969-975, 2001.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;A remote sensing derived dataset of 100 million individual tree crowns for the National Ecological Observatory Network&quot; for further consideration by <italic>eLife</italic>. Your revised article has been evaluated by Meredith Schuman (Senior Editor) and Bernhard Schmid (Reviewing Editor).</p><p>Your revisions are convincing. However, we find:</p><p>1) you could still make it clearer why LiDAR currently could not further improve the detection of individual crowns (because of low resolution and inconsistencies across multiple sites in available LiDAR data) and what would be needed and hopefully will become available to include LiDAR more fully for future improvements of the data set (higher resolution data consistently available across all sites plus methods development).</p><p>2) Although this is essentially a data paper, it would be good if you could add more concrete suggestions what could be done with the data. You do mention the value of individual data as opposed to pixel data in very general terms. But for example, even though you show a figure with densities, in the corresponding paragraph it is not really discussed why density is so extremely important in forest ecology (see e.g. Barrufol et al. cited in the previous review for just one example). Individuals are also important for estimating biodiversity once you can assign traits or even species identities to them, and biodiversity is probably the most important variable you eventually would like to assess with such a data set (see e.g. J. Liang et al., 2016 and Huang et al., Science 362, 80-83 (2018), DOI: 10.1126/science.aat6405).</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.62922.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>This paper presents a large data set of tree positions, heights and crown areas from 37 NEON sites across North America. The authors used airborne RGB data and a previously published Python software tool to delineate crowns of individual canopy trees. They then compared a subset of these crowns with crowns identified by visual inspection of the airborne pictures and with field-measured stem positions and height and crown data. The accuracy of the automatic detection was about 70 %. Lidar measurements were used to exclude trees or objects less than 3 m tall and to estimate the height of the trees with an accuracy of roughly 2 m RMSE.</p><p>The authors discuss some possible uses of the individual-level tree data, but clearly these potential uses could be much extended if the data set could be updated and improved as further information becomes available, which the authors point out. It is difficult to judge to which extent this would be possible with the particular approach used in the paper. The authors would have to provide at least a summary of the algorithms implemented in their software tool (e.g. as supplement), because even the previously published paper in Methods in Ecology and Evolution does not provide this information, nor could I find it on the website of the tool.</p></disp-quote><p>The main description of the algorithm is in Weinstein et al. (2019, 2020b). We have expanded the summary of the algorithms in the Crown Delineation section of the manuscript so that readers don’t need to read the underlying methods papers to understand the general approach. In addition to expanding the summary of the methods we have also improved our communication of the previous comparisons of these methods to other approaches (including LiDAR-based methods). We have summarized the methods and previous comparisons in</p><p>Weinstein BG, Marconi S, Bohlman S, Zare A, White E. Individual Tree-Crown Detection in RGB Imagery Using Semi-Supervised Deep Learning Neural Networks. Remote Sensing. 2019;11: 1309. doi:10.3390/rs11111309</p><p>Weinstein BG, Marconi S, Bohlman SA, Zare A, White EP. Cross-site learning in deep learning RGB tree crown detection. Ecological Informatics. 2020b;56: 101061. doi:10.1016/j.ecoinf.2020.101061</p><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>The major issue that should be solved is that the LiDAR data should be included to improve the crown detection efficiency:</p><p>i) The reviewers are very surprised that you do not to use the LiDAR data in the segmentation of the single tree crowns.</p></disp-quote><p>We agree that LiDAR data has an important role to play in crown detection. Based on this recognition our method already uses LiDAR data twice: first to identify millions of crowns for pretraining the CNN (Weinstein et al., 2019, 2020b) and then to filter detections that do not correspond to sufficiently high canopy heights (this paper). Both of these integrations of LiDAR provided significant improvements in model performance.</p><p>In addition we have previously attempted to actively integrate LiDAR data into the CNN itself as suggested here and by reviewer 1. However, so far, this addition has failed to improve the predictions from the model. The lack of improvement when directly incorporating LiDAR data into the CNN is likely due in part to the density of the LiDAR data generally available at NEON sites. Most LiDAR based methods are evaluated on LiDAR data with point densities ranging from ~15 pts/m (e.g., Duncanson et al., 2018) to over 100 pts/m (e.g., Aubry-Kientz et al., 2019). In contrast, NEON’s current continental airborne LiDAR program produces only ~6 pts/m and these densities can be highly variable, with large areas containing &lt; 4 pts/m. While a handful of sites do have higher density data, the value of this dataset is the standardized set of predictions for the entire NEON network.</p><p>Given that this is a dataset paper the key question is whether the predictions are sufficiently accurate to produce a useful dataset. We have compared the accuracy of delineations from our method to 8 different LiDAR based segmentation methods and found it to perform equivalently to the most accurate of these methods (Weinstein et al., 2019, 2020a, 2020b). This does not mean that there isn’t room for improvement, but it does mean that the method used to generate this dataset is producing results that are as good as those that would be produced with current LiDAR based approaches.</p><p>We recognize that questions about why LiDAR data is not used in the CNN phase of our algorithm will be common and have therefore added discussion of the points made above in the Crown Delineation section of the manuscript and in a new supplement.</p><disp-quote content-type="editor-comment"><p>There exists a large body of different LiDAR-based individual tree crown (ITC) approaches, a number of benchmarking studies and open-source benchmarking datasets for comparing new methods with older ones.</p></disp-quote><p>We are definitely aware of the large amount of high quality research in this area. As described above we have compared our method to eight of these algorithms, including the cutting edge methods evaluated in Aubry-Kientz et al. (2019). In Weinstein et al. (2020b) we compared DeepForest to methods made available in (Roussel et al., 2020) derived from (Dalponte et al., 2018; Li et al., 2012; Silva et al., 2016). In Weinstein et al. (2020a) we compared DeepForest to the scores computed in (Aubry-Kientz et al., 2019) which competed methods from algorithms published in (Ferraz et al., 2016; Hamraz et al., 2017; Williams et al., 2020). We have clarified the discussion of these comparisons in the Evaluation and Validation section and added additional citations to the specific LiDAR based methods that DeepForest was compared to.</p><p>While there are some benchmarking studies and datasets, it is worth noting that very few allow comparisons across sensor types. For example, the most commonly used ITC benchmark is the NewFor benchmark (https://publik.tuwien.ac.at/files/PubDat_230620.pdf) which does not include co-registered RGB data. We are not aware of any publicly available RGB + LiDAR remote sensing dataset that has co-registered crown data, which is why we currently have a multi-sensor benchmark dataset paper in review. We have attached a copy of this manuscript and the data is available on GitHub (https://github.com/weecology/NeonTreeEvaluation). The manuscript is currently in review as PLOS Computational Biology and a preprint is on biorxiv. https://www.biorxiv.org/content/10.1101/2020.11.16.385088v1</p><disp-quote content-type="editor-comment"><p>ii) If you use LiDAR based ITC methods, you could remedy some of the error sources of your current approach, i.e. shaded crowns and sub-dominant trees.</p></disp-quote><p>Given the density of the LiDAR in the NEON data, we do not believe we can accurately delineate shaded or sub-dominant trees at most NEON sites. We are aware of methods for individual sites, but validating them at broad scales with low point densities remains an area of further work. Therefore, we believe that it is important to not overstate what is possible with this dataset at this time. We certainly hope that future work will lead to effective understory detection across NEON sites and we plan to incorporate these approaches as they become available and update the dataset accordingly.</p><disp-quote content-type="editor-comment"><p>The references to such approaches are missing, even in contexts directly related to some of the potential applications of the dataset, i.e., the ITC-related papers of Duncanson et al., working on two of the NEON sites and, for the first time, showing the potential of LiDAR ITC-based allometries.</p></disp-quote><p>We have added references to the Duncanson et al. paper and added several citations for greater background information.</p><disp-quote content-type="editor-comment"><p>iii) Why not use height as a fourth dimension besides RGB? For example, two neighboring trees with similar optical properties could be separated by height. Also in general, does this approach allow to add more bands as from multi- or hyperspectral sensors?</p></disp-quote><p>We have previously attempted to include canopy height models (CHM) as a fourth dimension input into the deep learning model and found no improvement. We used the CHM because combining point cloud data with 2 dimensional sensor output is non-trivial given the unordered nature of point clouds in three dimensions. We conducted extensive testing of the addition of the canopy height model as a 4th layer, and were surprised to find that this actually decreased performance relative to using RGB data alone. This is likely due to a combination of the low point density available for many sites (see above) and because adding a fourth dimension eliminates the ability to pretrain the network on the three dimension Imagenet RGB dataset. We have added a brief appendix to alert readers to this (S4).</p><p>In a few NEON sites, like the conifer forests studied in Duncanson et al. 2018, the LiDAR canopy height model was helpful. However, in sites with a fully connected flat canopy, like at Mountain Lake Biological Station, Virginia, or with very flat topped trees, such as CLBJ Grasslands, Texas the CHM component of the model becomes difficult to parameterize in a way that both avoids splitting wide branching oaks or clumping small trees. There have been useful recent attempts to parametrize these kinds of models using allometric functions (such as in Fischer et al., (2020); Gomes et al., (2018)), but these focus on individual sites. At the continental scale it is not yet clear how to apply these approaches in a way that captures the large variation in tree shape both within and between species, without having the species label.</p><p>We are very interested in multi-instrument fusion to address both crown delineation and species identification, but this requires new methodological development. The goal of the current paper is to provide a useful dataset of tree crowns based on an algorithm that has high prediction accuracy (matching or exceeding the values from other available methods). We want to emphasize that we do not view the publication of this dataset as an end point that precludes the improvement of the method and updating of the data in the future. There is active work by multiple groups (including ours) in integrating not only multiple sensors but also multi-temporal features to improve crown delineations. We view the current dataset as a useful starting point, to be iteratively improved on as the methods and data underlying crown delineation improve.</p><disp-quote content-type="editor-comment"><p>iv) Besides the important measures of stem density and crown size distributions, the dataset could also be used as a starting point to refine other individual tree crown detection methods, for example using lidar point cloud segmentation in 3D space.</p></disp-quote><p>Agreed. We see this dataset as a useful starting point and companion to a variety of studies, including as weakly-labeled data for training with a variety of data types. We have mentioned this in the text.</p><disp-quote content-type="editor-comment"><p>v) Finally, it's worth mentioning the various efforts for individual tree detection from airborne laser scanning data. It would be good to compare your results to point-cloud based segmentation, or also to test the use of this dataset for more extensive 3D segmentation algorithms, e.g. by using the tree locations as seed points for 3D segmentation of the point cloud.</p></disp-quote><p>As described above we have already compared our methods to point-cloud based segmentation approaches. Specifically we have compared them to AMS3D, itcSegment, a graph-cut point cloud approach (Weinstein et al., 2020b). The performance of our method is as good as the best of these methods even in the ideal case where the LiDAR point density is 50-100 pts/m rather than the 6 pt/m available for the NEON data.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Your revisions are convincing. However, we find:</p><p>1) you could still make it clearer why LiDAR currently could not further improve the detection of individual crowns (because of low resolution and inconsistencies across multiple sites in available LiDAR data) and what would be needed and hopefully will become available to include LiDAR more fully for future improvements of the data set (higher resolution data consistently available across all sites plus methods development).</p></disp-quote><p>We added an additional paragraph to the Discussion on LiDAR integration and extended the discussion in the associated Figure 4—figure supplement 2.</p><disp-quote content-type="editor-comment"><p>2) Although this is essentially a data paper, it would be good if you could add more concrete suggestions what could be done with the data. You do mention the value of individual data as opposed to pixel data in very general terms. But for example, even though you show a figure with densities, in the corresponding paragraph it is not really discussed why density is so extremely important in forest ecology (see e.g. Barrufol et al. cited in the previous review for just one example). Individuals are also important for estimating biodiversity once you can assign traits or even species identities to them, and biodiversity is probably the most important variable you eventually would like to assess with such a data set (see e.g. J. Liang et al., 2016 and Huang et al., Science 362, 80-83 (2018), DOI: 10.1126/science.aat6405).</p></disp-quote><p>We added additional examples for each scale of analysis, individual, landscape and macroecology. Added reference to Liang et al., 206 and Barrufol et al., 2013, with the note that species labels remain a work in progress and not yet released for the dataset.</p></body></sub-article></article>