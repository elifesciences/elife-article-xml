<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">79045</article-id><article-id pub-id-type="doi">10.7554/eLife.79045</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Neural representations of naturalistic events are updated as our understanding of the past changes</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-274930"><name><surname>Zadbood</surname><given-names>Asieh</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9098-0510</contrib-id><email>az2604@columbia.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-229055"><name><surname>Nastase</surname><given-names>Samuel</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7013-5275</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-91451"><name><surname>Chen</surname><given-names>Janice</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-76997"><name><surname>Norman</surname><given-names>Kenneth A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5887-9682</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-16326"><name><surname>Hasson</surname><given-names>Uri</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hj8s172</institution-id><institution>Department of Psychology, Columbia University</institution></institution-wrap><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hx57361</institution-id><institution>Princeton Neuroscience Institute and Department of Psychology, Princeton University</institution></institution-wrap><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00za53h95</institution-id><institution>Department of Psychological and Brain Sciences, Johns Hopkins University</institution></institution-wrap><addr-line><named-content content-type="city">Baltimore</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Peelen</surname><given-names>Marius V</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/016xsfp80</institution-id><institution>Radboud University</institution></institution-wrap><country>Netherlands</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>de Lange</surname><given-names>Floris P</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/016xsfp80</institution-id><institution>Radboud University</institution></institution-wrap><country>Netherlands</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>15</day><month>12</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e79045</elocation-id><history><date date-type="received" iso-8601-date="2022-03-28"><day>28</day><month>03</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2022-12-01"><day>01</day><month>12</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2021-09-30"><day>30</day><month>09</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.09.28.462068"/></event></pub-history><permissions><copyright-statement>© 2022, Zadbood et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Zadbood et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-79045-v2.pdf"/><abstract><p>The brain actively reshapes our understanding of past events in light of new incoming information. In the current study, we ask how the brain supports this updating process during the encoding and recall of naturalistic stimuli. One group of participants watched a movie (‘The Sixth Sense’) with a cinematic ‘twist’ at the end that dramatically changed the interpretation of previous events. Next, participants were asked to verbally recall the movie events, taking into account the new ‘twist’ information. Most participants updated their recall to incorporate the twist. Two additional groups recalled the movie without having to update their memories during recall: one group never saw the twist; another group was exposed to the twist prior to the beginning of the movie, and thus the twist information was incorporated both during encoding and recall. We found that providing participants with information about the twist beforehand altered neural response patterns during movie-viewing in the default mode network (DMN). Moreover, presenting participants with the twist at the end of the movie changed the neural representation of the previously-encoded information during recall in a subset of DMN regions. Further evidence for this transformation was obtained by comparing the neural activation patterns during encoding and recall and correlating them with behavioral signatures of memory updating. Our results demonstrate that neural representations of past events encoded in the DMN are dynamically integrated with new information that reshapes our understanding in natural contexts.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>memory updating</kwd><kwd>neural representations</kwd><kwd>episodic memory</kwd><kwd>naturalistic paradigm</kwd><kwd>default mode network</kwd><kwd>event processing</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000025</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>R01 MH12357</award-id><principal-award-recipient><name><surname>Norman</surname><given-names>Kenneth A</given-names></name><name><surname>Hasson</surname><given-names>Uri</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>DP1 HD091948</award-id><principal-award-recipient><name><surname>Hasson</surname><given-names>Uri</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Changes in the interpretation of specific scenes in a narrative trigger corresponding updates in the neural patterns evoked by those scenes in the default mode network.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>In a constantly changing world, it is critical to update prior beliefs and memories in light of new circumstances. As new information arrives, we often need to update previously encoded information in the brain retrospectively. Imagine discovering that a longtime friend has lied to you about something important. You might automatically start looking back and reinterpreting their behavior, perhaps finding different motives for their past actions. This updated understanding of the past will assist you in your future interactions with that friend. Importantly, updating representations of real-world events does not necessarily involve rewriting or erasing the content of the previous memory for the event – it can also include adding new information that alters one’s overall interpretation of what happened. In this paper, we use the term ‘memory updating’ to refer to this process of updating representations of past events based on new information. To effectively support ‘memory updating’, the episodic memory system must be capable of modifying stored representations in light of new incoming information. Under this framework, memories are dynamic entities that can be reorganized or reconstructed even after encoding takes place (<xref ref-type="bibr" rid="bib5">Bartlett and Burt, 1933</xref>; <xref ref-type="bibr" rid="bib14">Conway and Pleydell-Pearce, 2000</xref>; <xref ref-type="bibr" rid="bib27">Hassabis and Maguire, 2007</xref>; <xref ref-type="bibr" rid="bib58">Schacter et al., 1998</xref>; <xref ref-type="bibr" rid="bib60">Schacter, 2012</xref>).</p><p>Research in the last few decades suggests that memories are malleable to modification when they are reactivated (<xref ref-type="bibr" rid="bib49">Przybyslawski and Sara, 1997</xref>), and relevant new information is presented (<xref ref-type="bibr" rid="bib7">Besnard et al., 2012</xref>; <xref ref-type="bibr" rid="bib33">Hupbach et al., 2015</xref>; <xref ref-type="bibr" rid="bib43">Nader and Einarsson, 2010</xref>; <xref ref-type="bibr" rid="bib65">Sinclair and Barense, 2019</xref>). Behavioral paradigms using a retroactive interference design have been widely used to study post-encoding changes in human memory (e.g. <xref ref-type="bibr" rid="bib38">Lee et al., 2017</xref>; <xref ref-type="bibr" rid="bib33">Hupbach et al., 2015</xref>; <xref ref-type="bibr" rid="bib56">Samide and Ritchey, 2020</xref>; <xref ref-type="bibr" rid="bib64">Scully et al., 2017</xref>). Only a subset of studies, however, have investigated changes in the <italic>content</italic> of memory, as opposed to the weakening or strengthening of old memories (<xref ref-type="bibr" rid="bib16">Dongaonkar et al., 2013</xref>; <xref ref-type="bibr" rid="bib32">Hupbach et al., 2007</xref>). At the neural level, changes in the functional connectivity of mPFC and amygdala circuitry have been associated with post-retrieval fear extinction (<xref ref-type="bibr" rid="bib19">Feng et al., 2016</xref>; <xref ref-type="bibr" rid="bib62">Schiller et al., 2013</xref>). These experimental studies have clinical significance and provide valuable insight into the behavioral and neural substrates of memory updating in humans. However, it is unclear how findings obtained using tightly controlled paradigms and isolated stimuli generalize to memory updating in everyday life (<xref ref-type="bibr" rid="bib45">Nastase et al., 2020</xref>). In the present work, we introduce a naturalistic interference-based design that resembles our real-world experiences where new information obtained post-encoding is not compatible with previously encoded events. Using an audiovisual movie and verbal recall, we aim to utilize recent advances in naturalistic neuroimaging to study how memories are reshaped to incorporate new incoming information.</p><p>The brain’s default mode network (DMN)—comprising the posterior medial cortex, medial prefrontal cortex, temporoparietal junction, and parts of anterior temporal cortex—was originally described as an intrinsic or ‘task-negative’ network, activated when participants are not engaged with external stimuli (<xref ref-type="bibr" rid="bib50">Raichle et al., 2001</xref>; <xref ref-type="bibr" rid="bib10">Buckner et al., 2008</xref>). This observation led to a large body of work showing that the DMN is an important hub for supporting internally driven tasks such as memory retrieval, imagination, future planning, theory of mind, and creating and updating situation models (<xref ref-type="bibr" rid="bib68">Svoboda et al., 2006</xref>; <xref ref-type="bibr" rid="bib1">Addis et al., 2007</xref>; <xref ref-type="bibr" rid="bib27">Hassabis and Maguire, 2007</xref>; <xref ref-type="bibr" rid="bib28">Hassabis and Maguire, 2009</xref>; <xref ref-type="bibr" rid="bib59">Schacter and Addis, 2007</xref>; <xref ref-type="bibr" rid="bib69">Szpunar et al., 2007</xref>; <xref ref-type="bibr" rid="bib66">Spreng et al., 2009</xref>; <xref ref-type="bibr" rid="bib36">Koster-Hale and Saxe, 2013</xref>; <xref ref-type="bibr" rid="bib51">Ranganath and Ritchey, 2012</xref>). However, it is not fully understood how this network contributes to these varying functions, and in particular—the focus of the present study—memory processes. Activation of this network during ‘offline’ periods has been proposed to play a role in the consolidation of memories through replay (<xref ref-type="bibr" rid="bib35">Kaefer et al., 2022</xref>). Interestingly, prior work has also shown that the DMN is reliably engaged during ‘online’ processing (encoding) of continuous rich dynamic stimuli such as movies and audio stories (<xref ref-type="bibr" rid="bib67">Stephens et al., 2013</xref>; <xref ref-type="bibr" rid="bib29">Hasson et al., 2008</xref>). Regions in this network have been shown to have long ‘temporal receptive windows’ (<xref ref-type="bibr" rid="bib29">Hasson et al., 2008</xref>; <xref ref-type="bibr" rid="bib39">Lerner et al., 2011</xref>; <xref ref-type="bibr" rid="bib11">Chang et al., 2022</xref>), meaning that they integrate and retain high-level information that accumulates over the course of extended timescales (e.g. scenes in movies, paragraphs in text) to support comprehension. This combination of processing characteristics suggests that the DMN integrates past and new knowledge, as regions in this network have access to incoming sensory input, recent active memories, and remote long-term memories or semantic knowledge (<xref ref-type="bibr" rid="bib77">Yeshurun et al., 2021</xref>; <xref ref-type="bibr" rid="bib30">Hasson et al., 2015</xref>). These integration processes feature in many of the ‘constructive’ processes attributed to DMN such as imagination, future planning, mentalizing, and updating situation models (<xref ref-type="bibr" rid="bib59">Schacter and Addis, 2007</xref>; <xref ref-type="bibr" rid="bib51">Ranganath and Ritchey, 2012</xref>). Notably, constructive processes are highly relevant to real-world memory updating, which involves selecting and combining the relevant parts of old and new memories. Recent work has shown that neural patterns during encoding and recall of naturalistic stimuli (movies) are reliably similar across participants in this network (<xref ref-type="bibr" rid="bib13">Chen et al., 2017</xref>; <xref ref-type="bibr" rid="bib46">Oedekoven et al., 2017</xref>; <xref ref-type="bibr" rid="bib78">Zadbood et al., 2017</xref>; see <xref ref-type="bibr" rid="bib8">Bird, 2020</xref> for a review of recent naturalistic studies on memory), and the DMN displays distinct neural activity when listening to the same story with different perspectives (<xref ref-type="bibr" rid="bib76">Yeshurun et al., 2017</xref>). Building on this foundation of prior work on the DMN, we asked whether we could find neural evidence for the retroactive influence of new knowledge on past memories.</p><p>In the current work, using a novel naturalistic paradigm intended to simulate a real-life situation of adaptive memory updating, we asked how new information changes the neural representations in the DMN during the recall of prior events. To answer this question, we used a popular Hollywood-style film titled ‘The Sixth Sense’ (M. Night Shyamalan, 1999), which contains a dramatic twist in the final scene. [Spoiler alert!] The movie depicts the story of a clinical psychologist treating a child who claims to see ghosts. In the final scene, it is revealed that the doctor was in fact, a ghost himself throughout the movie. Therefore, there are two coherent interpretations of the movie: the <italic>Doctor</italic> (or <italic>naive</italic>) interpretation (labeled D in <xref ref-type="fig" rid="fig1">Figure 1</xref>), which is typically held by viewers up until they encounter the ‘twist ending’; and the <italic>Ghost</italic> (or <italic>spoiled</italic>) interpretation (labeled G in <xref ref-type="fig" rid="fig1">Figure 1</xref>), which is held by viewers after they learn about the twist. In this setting, memory updating is operationalized as the transition from the <italic>Doctor</italic> (D) interpretation to the <italic>Ghost</italic> (G) interpretation.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Experimental design.</title><p>(<bold>A</bold>) Participants watched edited versions of the movie and performed a scene-by-scene cued verbal recall task in the scanner. (<bold>B</bold>) Experimental groups. Red boxes refer to the <italic>Ghost</italic> interpretation, and blue boxes refer to the <italic>Doctor</italic> interpretation. The ‘twist’ group (middle row) is the main experimental group that encodes the movie with <italic>Doctor</italic> interpretation (left blue box) but recalls it with <italic>Ghost</italic> interpretation (right red box)—essentially following the narrative as intended by the filmmaker. The two additional groups keep the same interpretation across the encoding and recall: the ‘spoiled’ group receives a spoiler at the beginning, thus encoding the movie and performing the recall task with the red <italic>Ghost</italic> interpretation, whereas the ‘no-twist’ group never receives the twist and therefore encodes the movie and performs the recall task under the blue <italic>Doctor</italic> interpretation.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79045-fig1-v2.tif"/></fig><p>Our study design hinges on the hypothesis that participants who received the twist and are aware that the doctor is a ghost might have distinct neural representations of the events from those who encoded the movie while ignorant of the twist. Importantly, we predicted that encountering the twist after encoding the movie would initiate a retrospective update in the interpretation of the encoded movie and that this update would be reflected in both verbal recall and patterns of brain activity during remembering. In contrast, the neural representations of the events in the movie will remain unchanged during recall in subjects who do not need to update their memories during recall (i.e. in subjects in the ‘no-twist’ condition who are only aware of the D interpretation, or subjects in the ‘spoiler’ condition who knew all along about the G interpretation).</p><p>In a large set of regions in the DMN, we found that context changed how the movie was encoded into memory. In other words, the neural representations for each event in the movie were different for viewers who believed the doctor was alive versus viewers who believed the doctor was a ghost. Furthermore, in several DMN regions, we found that neural representations were updated during recall for viewers who learned that the doctor was a ghost after watching the movie. Together these results suggest that areas in the default mode network are actively updating the neural representations as they integrate incoming information with prior knowledge.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>Three distinct experimental groups watched concise versions of a popular Hollywood-style film titled “The Sixth Sense” (M. Night Shyamalan, 1999) in the fMRI scanner (<xref ref-type="fig" rid="fig1">Figure 1B</xref>, left column). Following the movie viewing all three groups were asked to freely recall the movie in the scanner (<xref ref-type="fig" rid="fig1">Figure 1B</xref>, left column). Participants in the main group (the ‘twist’ condition, <xref ref-type="fig" rid="fig1">Figure 1B</xref>, middle row), watched the movie with the twist scene <italic>at the end</italic>. Therefore, they watched the movie naive to the true nature of the doctor (<italic>Movie-Doctor</italic> or M<sub>D</sub>). During their recall, however, they were aware of the twist information and could use it to update their memory (<italic>Recall-Ghost</italic> or R<sub>G</sub>). In order to identify interpretation-specific neural patterns, we needed two comparison conditions: the <italic>Movie-Ghost</italic> (M<sub>G</sub>) condition during viewing, and the <italic>Recall-Doctor</italic> (R<sub>D</sub>) condition during recall. Therefore, we introduced two other groups to the study: participants in one group (the ‘spoiled’ condition; <xref ref-type="fig" rid="fig1">Figure 1B</xref>, top row) were exposed to the twist at the beginning of the movie. This group watched and recalled the movie knowing that the doctor was a ghost (M<sub>G</sub> and R<sub>G</sub>). The other group (the ‘no-twist’ condition; <xref ref-type="fig" rid="fig1">Figure 1B</xref>, bottom row) never received the twist information throughout encoding and remained naive to the true nature of the doctor in both their encoding and recall (M<sub>D</sub> and R<sub>D</sub>). This design allowed us to compare the behavioral and neural patterns of response in participants across the two interpretations. We compared the patterns of neural responses in the ‘twist’ group with the patterns in the ‘spoiled’ and ‘no-twist’ groups during encoding and recall. We predicted that the ‘twist’ group would be more similar to the ‘no-twist’ group during encoding (both having the <italic>Doctor</italic> interpretation) but more similar to the ‘spoiled’ group during recall (both having the <italic>Ghost</italic> interpretation). Moreover, we asked whether the memory updating would make the recall of the ‘twist’ group more similar to the encoding of the ‘spoiled’ group (see the ‘prediction legends’ in Figures 2 and 3).</p><p>We used intersubject pattern similarity analysis (intersubject pattern correlation: pISC, see Methods) to compare the neural event representations between groups. This analytic approach is motivated by prior work showing that slowly-evolving activity patterns in DMN represent event-level information (<xref ref-type="bibr" rid="bib4">Baldassano et al., 2018</xref>) and that pISC captures scene-specific pattern similarity between groups who watched the same movie, groups who verbally recalled the same story (in their own words), and across viewing and recall of the same scenes (<xref ref-type="bibr" rid="bib13">Chen et al., 2017</xref>; <xref ref-type="bibr" rid="bib78">Zadbood et al., 2017</xref>). In this analysis, scene-specific neural patterns during encoding of the movie were obtained by averaging data across time within each scene in each subject (<xref ref-type="bibr" rid="bib13">Chen et al., 2017</xref>; <xref ref-type="bibr" rid="bib78">Zadbood et al., 2017</xref>). For the cued recall data, we ran a GLM analysis (<xref ref-type="bibr" rid="bib41">Mumford et al., 2012</xref>) to capture responses corresponding to the recall of single events. fMRI responses averaged across time points within an event (or estimated from the GLM) for each ROI served as the <italic>spatial response patterns</italic> (i.e. neural event representations) that were then compared across groups using pISC. We then compared pairs of pattern similarity correlations based on our hypotheses. For example, we hypothesized that the updated recall in the ‘twist’ group would be more similar to the recall of the ‘spoiled’ group (as both groups have the <italic>Ghost</italic> interpretation during the recall) than of the ‘no-twist’ group (who have the <italic>Doctor</italic> interpretation). To test this hypothesis, in each ROI, we measured pISC once between ‘twist’ and ‘spoiled’ groups and once between ‘twist’ and ‘no-twist’ groups. We then compared these two sets of pattern similarity values to quantify which two groups’ neural event representations were more similar. We focused our analyses on a predetermined selection of movie scenes (i.e. 7 ‘critical scenes’ out of 18 total scenes) in which the <italic>Doctor</italic> or <italic>Ghost</italic> interpretation of the main character in the movie would dramatically change the overall interpretation of those scenes. Selection of these scenes was based on ratings from five raters asked to quantify the influence of the twist on the interpretation of each scene (see Methods).</p><p>After watching the movie, participants performed a cued-recall task in which they watched a few seconds of the beginning of all movie scenes (18 scenes) and were asked to describe what happened next in that scene. The recall task was identical across the three experimental conditions. Participants were highly accurate in recognizing the corresponding scenes from the movie cues (94% accuracy in the ‘twist’ group, 93% in the ‘spoiled’ group, and 97% in the ‘no-twist’group). Only the scenes that were correctly recalled were included in the neural analyses. The content of recall was evaluated using two separate measures assigned by human raters. <italic>Memory score</italic> assessed the quality and detail of memory. <italic>Twist score</italic> assessed whether the twist information was incorporated into the recall and ranged from 1 (the recall purely reflected the <italic>Doctor</italic> interpretation) to 5 (the recall purely reflected the <italic>Ghost</italic> interpretation). Memory score and twist score were expected to capture different aspects of the recall behavior; for example a detailed recall of the original scene about the doctor treating the child (high memory score) may not include information about the doctor being a ghost (low twist score). Indeed, there was no significant correlation between memory scores and twist scores across participants (<italic>r</italic>=0.07, p=0.56). If participants were unaware of the twist or did not incorporate it into their recall at all, we would expect the average twist score of the critical scenes to be approximately equal to 1 (‘purely reflects the <italic>Doctor</italic> interpretation’). In the main experimental group (‘twist’ group), 14 out of 19 participants scored above 2 (median score = 3.25) on the twist score, indicating that they incorporated the new interpretation into their recall. Importantly, the ‘twist’ group (twist score: M=3.16, SD = 1.03) exhibited a significantly higher twist score (t(37) = 6.37, p&lt;0.001) than the ‘no-twist’ group (twist score: M=1.65, SD = 0.22). Note that these two groups had no knowledge of the twist when they encoded the movie. Therefore, this result confirms that participants in the ‘twist group’ updated their memories of the movie to incorporate the twist. No significant difference (t(35) = 1.46, p=0.15) was observed between the twist score of the ‘twist’ group and the ‘spoiled’ group (twist score: M=2.72, SD = 0.74). This finding suggests that the ‘twist’ group recalled the movie more similarly to the group that knew the twist while watching the movie.</p><sec id="s2-1"><title>Memory update in recall behavior</title><p>A surprising observation during the analysis of the behavioral recall in the ‘twist’ condition was that most participants talked about <italic>both</italic> interpretations of the movie scenes in many of the recalled scenes (this pattern was observed in the recall of the ‘spoiled’ group as well). Thus, it appeared that participants kept both interpretations in mind during the recall, instead of overwriting the <italic>Doctor</italic> representation with the <italic>Ghost</italic> representation. These recalls were typically structured as, “Initially I thought that… but now I know that…”. Interestingly, some instances of this recall behavior were also observed in the ‘spoiled’ group, who had watched the movie knowing the doctor is a ghost (e.g. “You could think that… but I knew that…”). This suggests that the neural representations supporting recall in the ‘twist’ and ‘spoiled’ groups included <italic>both</italic> the original (<italic>Doctor</italic>) and updated (<italic>Ghost</italic>) interpretations, which could make differentiating these representations in the neural analysis more challenging (see Discussion).</p></sec><sec id="s2-2"><title>Neural representation of the twist information during movie-viewing</title><p>First, we set out to test how contextual knowledge about the twist modifies the neural patterns in the DMN during the encoding of the movie into memory. As encoding conditions are directly compared, we refer to this analysis as encoding-encoding throughout the paper. We compared the spatially distributed neural activity patterns elicited during movie-viewing (encoding) in the ‘twist’ group (M<sub>D</sub>) to the activity patterns obtained during encoding in the ‘no-twist’ group (M<sub>D</sub>) and the ‘spoiled’ group (M<sub>G</sub>). We hypothesized that within the regions of the brain that are sensitive to different interpretations, the pattern similarity between the ‘twist’ group (M<sub>D</sub>) and the ‘no-twist’ group (M<sub>D</sub>) should be higher than the similarity between the ‘twist’ group (M<sub>D</sub>) and the ‘spoiled’ group (M<sub>G</sub>) (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, prediction legends).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Brain regions coding for story interpretation at encoding and recall.</title><p>‘Prediction legends’ depict the predicted pattern of correlations between groups based on our hypotheses. (<bold>A</bold>) Areas with significantly greater intersubject pattern correlation between groups who encoded the movie with the same interpretation (<italic>Doctor</italic>). (<bold>B</bold>) Areas with significantly greater intersubject pattern correlation between groups who recalled the movie with the same interpretation (<italic>Ghost</italic>). (<bold>C</bold>) Areas with a significant interaction effect, indicating a change in interpretation between encoding and recall (see ‘Intersubject pattern correlation (pISC) analysis’ in Methods). Statistical significance was assessed using a nonparametric randomization test, FDR corrected p&lt;0.05.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79045-fig2-v2.tif"/></fig><p>Indeed, there was significantly greater intersubject pattern correlation in parts of the DMN between the ‘twist’ and ‘no-twist’ experimental groups (who had a similar M<sub>D</sub> interpretation of the movie during encoding) than across experimental groups with opposing interpretations (M<sub>D</sub> versus M<sub>G</sub>). These areas included the dorsal and lateral PFC, left precuneus, left retrosplenial cortex, left angular gyrus, middle temporal cortex, left superior temporal cortex, and left temporal pole (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). These results fit with previous findings demonstrating that the timecourse of brain responses in DMN regions reflects different perspectives when listening to a spoken narrative (<xref ref-type="bibr" rid="bib76">Yeshurun et al., 2017</xref>). Our results extend these findings by showing that different interpretations are discriminable in <italic>spatial</italic> response patterns measured while viewing audiovisual movie stimuli.</p></sec><sec id="s2-3"><title>Neural representation of the twist information during cued recall</title><p>Results from the encoding phase suggest that regions in DMN exhibit different patterns of neural response to <italic>Ghost</italic> vs. <italic>Doctor</italic> interpretations. In the next step, we sought to measure memory updating, which we define as a shift during recall from the neural patterns associated with the <italic>Doctor</italic> interpretation to incorporate information associated with <italic>Ghost</italic> interpretation. Since recall conditions are directly compared, we refer to this analysis as recall-recall. As described earlier, the analysis of recall behavior suggests that participants in the ‘twist’ condition utilized the twist information to update their recall of the movie. Hence, we ask whether the neural patterns observed during recall would reflect these changes. We predicted that the ‘no-twist’ group and the ‘spoiled’ group would keep the same interpretation of the movie during encoding and recall (M<sub>D</sub> to R<sub>D</sub> in the ‘no-twist’ group and M<sub>G</sub> to R<sub>G</sub> in the ‘spoiled’ group). However, in the ‘twist’ group, we expected to observe an update during recall to accommodate the twist information (M<sub>D</sub> to R<sub>G</sub>). Therefore, we hypothesized that, during recall, the neural patterns for the ‘twist’ group might shift from being more similar to the ‘no-twist’ group as observed during encoding to be more similar to the neural patterns in the ‘spoiled’ group during recall (<xref ref-type="fig" rid="fig2">Figure 2B</xref> – prediction legends).</p><p>Indeed, as subjects recalled the movie in the scanner, there was significantly greater intersubject pattern correlation in parts of the DMN between the ‘twist’ and ‘spoiled’ experimental groups (who believed that the doctor is a ghost: R<sub>G</sub>) than across the ‘twist’ and ‘no-twist’ groups (who had opposing interpretations: R<sub>G</sub> versus R<sub>D</sub>). These areas included the ventromedial prefrontal cortex (vmPFC), right precuneus, and right superior temporal cortex (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). In addition, we ran an interaction analysis to further emphasize the reversal of neural similarity during encoding and recall (see Methods). This analysis highlights a large set of DMN regions, including medial, dorsal, and lateral PFC, precuneus, left retrosplenial cortex, angular gyrus, right superior and middle temporal cortex, and left temporal pole, where neural patterns in the ‘twist’ group were relatively more similar to the <italic>Ghost</italic> (vs. <italic>Doctor</italic>) interpretation at recall than at encoding (<xref ref-type="fig" rid="fig2">Figure 2C</xref>).</p><p>To test whether our reported results were mainly driven by the similarities and differences in multivariate spatial patterns of neural representations, as opposed to by univariate regional-average response magnitudes, we ran a univariate analysis in each ROI. This analysis revealed no significant effect of group (‘spoiled’, ‘twist’, ‘no-twist’) or interaction between group and condition (movie, recall) (<xref ref-type="table" rid="app1table1">Appendix 1—table 1</xref>, see Methods for details).</p></sec><sec id="s2-4"><title>Relationship between the neural representations during encoding and recall</title><p>To provide further neural evidence for the shift from <italic>Doctor</italic> interpretation during encoding to <italic>Ghost</italic> interpretation during recall in the ‘twist’ group, we directly compared the brain responses elicited during encoding and recall (encoding-recall analyses). <xref ref-type="bibr" rid="bib13">Chen et al., 2017</xref> have demonstrated that, across free recall of a movie, neural patterns are reinstated in DMN. In addition, these scene-specific neural patterns changed between encoding and recall in a systematic manner across individuals (<xref ref-type="bibr" rid="bib13">Chen et al., 2017</xref>). We hypothesized that updating one’s interpretation to incorporate twist information might alter the neural representations during recall, such that they become more similar to the neural patterns elicited during encoding of the spoiled movie.</p><p>We tested this hypothesis in two ways. First, we predicted that (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, prediction legend) the neural pattern similarity between recall in the ‘twist’ group and encoding in the ‘spoiled’ group (R<sub>G</sub> to M<sub>G</sub>) would be higher than the pattern similarity between recall in the ‘no-twist’ group and encoding of the ‘spoiled’ group (R<sub>D</sub> to M<sub>G</sub>). Our analysis confirmed this prediction in the left angular gyrus, left dorsomedial PFC, and right middle temporal cortex (<xref ref-type="fig" rid="fig3">Figure 3A</xref>).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Encoding-retrieval similarity analyses to test our memory updating predictions.</title><p>“Prediction legends” depict the predicted pattern of correlations between groups based on our hypotheses. (<bold>A</bold>) Areas where intersubject pattern correlations were significantly greater when comparing updated recall (R<sub>G</sub>) to spoiled encoding (M<sub>G</sub>) than when comparing naive recalls (R<sub>D</sub>) to spoiled encoding (M<sub>G</sub>). (<bold>B</bold>) Areas where intersubject pattern correlations between updated recall (R<sub>G</sub>) and spoiled encoding (M<sub>G</sub>) were greater than between updated recall (R<sub>G</sub>) and naive encoding (M<sub>D</sub>); note that these results were not significant after correction for multiple tests.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79045-fig3-v2.tif"/></fig><p>Second, if participants in the ‘twist’ group were to <italic>fully</italic> update their interpretation at recall from <italic>Doctor</italic> to <italic>Ghost</italic>, we would expect activity patterns during recall in the ‘twist’ group to be more similar to encoding in the ‘spoiled’ group (R<sub>G</sub> to M<sub>G</sub>) compared to encoding in their own (‘twist’) group (R<sub>G</sub> to M<sub>D</sub>) (<xref ref-type="fig" rid="fig3">Figure 3B</xref>, prediction legends). When we looked for regions showing this effect, we found weak effects in the predicted direction in the left angular gyrus, left frontal pole, and right anterior temporal ROIs (note that all of these comparisons were performed across participants; see Methods for details); however, these effects did not survive correction for multiple comparisons at an FDR-corrected p&lt;0.05 (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). The most straightforward interpretation of these weak effects is, in general, ‘twist’ group participants did <italic>not</italic> fully update their interpretations; that is, there may have been some lingering memory of the <italic>Doctor</italic> interpretation in the ‘twist’ group in some participants even after they were exposed to <italic>Ghost</italic> interpretation and updated their memory.</p><p>To test this hypothesis, we ran an exploratory analysis where we correlated neural pattern change (i.e. the degree to which the neural pattern at recall matched the <italic>Doctor</italic> or <italic>Ghost</italic> encoding pattern) with behavioral twist scores (i.e. how much each subject discussed the twist during recall) across participants in the ‘twist’ group, in each DMN ROI (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>). If weak neural pattern change effects are due to incomplete memory updating, we would expect to see a positive correlation between these measures. We observed a positive correlation between the neural and behavioral indices of memory update in posterior regions of the DMN, including precuneus and angular gyrus. The right precuneus ROI exhibited a notable relationship (<italic>r</italic>=0.62); however, this did not survive FDR correction across ROIs.</p></sec><sec id="s2-5"><title>The role of scene content</title><p>In the prior analyses, we focused on ‘critical scenes’, selected based on ratings from five raters who quantified the influence of the twist on the interpretation of each scene (see Methods). An independent post-experiment analysis of the verbal recall behavior of the fMRI participants yielded ‘twist scores’ that were also highest for these scenes; that is, the expected and perceived effect of twist information on recall behavior were found to match. In our next analysis, we asked whether the neural event representations reflect these differences in the twist-related content of the scenes. In other words, are the ‘critical scenes’ with highly twist-dependent interpretations truly <italic>critical</italic> for our observed effects?</p><p>To answer this question, we re-ran our main encoding-encoding and recall-recall pISC analysis in each DMN ROI (<xref ref-type="fig" rid="fig2">Figures 2</xref>–<xref ref-type="fig" rid="fig3">3</xref>). We calculated interaction indices (<xref ref-type="fig" rid="fig2">Figure 2C</xref>) first by including all scenes, and second by including only the 11 non-critical scenes. To better compare the effect of including different subsets of scenes to our original results, in <xref ref-type="fig" rid="fig4">Figure 4</xref> we show the results in 15 ROIs that exhibited meaningful effects in our main analyses (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). <xref ref-type="fig" rid="fig4">Figure 4A</xref> demonstrates that ‘critical scenes’ yielded higher interaction indices compared to all scenes or non-critical scenes across all ROIs. The interaction score across all DMN ROIs was significantly higher in ‘critical scenes’ than all scenes (t(23) = 7.19, p=2.53 x 10<sup>–7</sup>) and non-critical scenes (t(23) = 7.3, p=1.95 x 10<sup>–7</sup>). These results show that critical scenes are indeed responsible for the observed pISC differences across groups.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Scence content analyses.</title><p>Interaction indices for 15 regions with meaningful results in the original interaction analysis (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). Note that the analyses were performed in all 24 DMN regions and this set is selected for visualization, to facilitate comparison with the prior analysis. (<bold>A</bold>) Interaction indices were computed separately for ‘critical scenes’ (blue dots), ‘non-critical scenes’ (red dots), or all scenes (yellow dots). Error bars depict standard error of mean (N = 19). (<bold>B</bold>) Light magenta distributions depict interaction values calculated after shuffling critical scene labels 1000 times. Blue dots indicate the actual (non-shuffled) interaction index; blue dots marked with black borders are statistically significant based on the null distribution (FDR controlled at q&lt;0.05).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79045-fig4-v2.tif"/></fig><p>Next, to determine whether scene-specific neural event representations—as opposed to coarser differences in general mental state across all scenes with similar interpretations—drive our observed pISC differences, we shuffled the labels of critical scenes within each group before calculating and comparing pISC across groups. By repeating this procedure 1000 times and recalculating the interaction index at each iteration, we constructed a null distribution of interaction indices for shuffled critical scenes (light magenta distributions in <xref ref-type="fig" rid="fig4">Figure 4B</xref>). In 12 out of 24 DMN regions, interaction indices were statistically significant based on the shuffled-scene distribution (p&lt;0.025, FDR controlled at q&lt;.05). All of these 12 regions were among the ROIs that showed meaningful effects in our original analysis (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). Regions with significant scene-specific interaction effects are marked as blue dots with black borders in <xref ref-type="fig" rid="fig4">Figure 4B</xref>. Overall, the findings from this analysis confirm that our results are driven by changes to scene-specific representations.</p><p>To further evaluate the relationship between scene-specific twist information in the brain and behavior, we ran an exploratory analysis which was focused on the changes in the neural event representations during recall of the ‘twist’ group and their corresponding recall behavior. We ran the same pISC procedure described in <xref ref-type="fig" rid="fig2">Figures 2B</xref> and <xref ref-type="fig" rid="fig3">3B</xref>. However, we did not average the pISC differences across scenes. In the recall-recall analysis, this procedure yielded 18 values (one for each scene, averaged across participants) indicating whether the neural event representations during updated recall were more similar to the spoiled recall or the naïve recall for a given scene. We then correlated these values with the twist score data (based on ratings of verbal recall) for each scene averaged across participants (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4A</xref>). None of these correlations were significant after correction for multiple tests; however, the four ROIs with significant effects in the main recall-recall analysis (<xref ref-type="fig" rid="fig2">Figure 2B</xref>) all showed positive correlations, particularly left mPFC. We repeated the same procedure to compute the relationship between scene-level neural event representations and behavioral twist scores in the encoding-recall analysis (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). In the original analysis (<xref ref-type="fig" rid="fig3">Figure 3B</xref>), we evaluated whether the neural representations of updated recall in the ‘twist’ group were more similar to encoding in the ‘spoiled’ group than their own naïve encoding. Here, we followed the same procedure of correlating scene-level outputs with scene-level twist scores (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4B</xref>). Again, none of these correlations were significant after correcting for multiple tests, but the three regions with (uncorrected) effects in the original analysis (<xref ref-type="fig" rid="fig3">Figure 3B</xref>) all displayed positive correlations with twist score. As we did not find strong results in this exploratory set of analyses, we refrain from overinterpreting them. However, they appear to match the direction of our main analyses; with greater statistical power analyses of this sort may provide insights into how neural event representations are updated in a scene-specific manner.</p></sec><sec id="s2-6"><title>Changes in neural representations beyond the DMN</title><p>We focused our core analyses on regions of the default mode network. Prior work has shown that multimodal neural representations of naturalistic events (e.g. movie scenes) are similar across encoding (movie-watching or story-listening) and verbal recall of the same events in the DMN (<xref ref-type="bibr" rid="bib13">Chen et al., 2017</xref>; <xref ref-type="bibr" rid="bib78">Zadbood et al., 2017</xref>). Therefore, in the current work we hypothesized that retrospective changes in the neural representations of events as the narrative interpretation shifts would be observed in the DMN. We did not, for example, expect to observe such effects in lower-level sensory regions, where neural activity differs dramatically for movie-viewing and verbal recall. To be thorough, we ran the same set of analyses we performed in the DMN (<xref ref-type="fig" rid="fig2">Figures 2</xref>–<xref ref-type="fig" rid="fig3">3</xref>) in regions of the visual and somatomotor networks extracted from the same atlas parcellation (<xref ref-type="bibr" rid="bib61">Schaefer et al., 2018</xref>). Our results revealed larger overall differences in DMN than in visual and somatosensory networks for the key comparisons discussed previously (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>). In particular, the only regions showing significant differences in pISC in recall-recall and encoding-recall comparisons (p&lt;0.01, uncorrected) were located in the DMN. We did not observe a notable difference between DMN and the two other networks when comparing recall ‘twist’ to movie ‘spoiled’ and recall ‘twist’ to movie ‘twist’ (R<sub>G</sub> – M<sub>G</sub> &gt;R<sub>G</sub> – M<sub>D</sub>) which is consistent with the weak effect in the original comparison (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). In the encoding-encoding comparison, several ROIs from the visual and somatomotor networks showed relatively strong effects as well (see Discussion).</p><p>In addition, we qualitatively reproduced our results by performing an ROI-based whole brain analysis (<xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3</xref>, p&lt;0.01 uncorrected). This analysis confirmed the importance of DMN regions for updating neural event representations. However, strong differences in pISC in the hypothesized direction were also observed in a handful of other non-DMN regions, including ROIs partly overlapping with anterior cingulate cortex and dorsolateral prefrontal cortex (see Discussion).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Using a novel naturalistic paradigm that prompted participants to update their previously-encoded memories, we studied how new information can retrospectively change the event representations in the default mode network. At encoding, a widespread network of frontal, parietal, and temporal regions exhibited significantly higher pattern similarity between groups in which participants had the same interpretation of the movie (naive to the twist; see <xref ref-type="fig" rid="fig2">Figure 2A</xref>). This result demonstrates how a belief about the identity of the doctor (which can broadly be construed as the context or the state of mind of the observer) can shape the encoding processes of new information (the same movie) into memory. But information is not only shaped by context during encoding, as stored representations must also be amenable to change as the context changes at a later stage. Indeed, our unique paradigm allows us to see how the patterns of stored representations change, as we learn about the twist in the movie. In particular, the neural patterns during recall changed in the twist condition to better match the neural patterns in the spoiled condition observed during recall in the ventromedial PFC, right precuneus, and temporal cortex (see <xref ref-type="fig" rid="fig2">Figure 2B</xref>). Furthermore, numerous areas throughout the DMN showed a significant interaction whereby neural patterns in the ‘twist’ group became relatively more similar to patterns from the ‘spoiled’ <italic>Ghost</italic> group (compared to the ‘no-twist’ <italic>Doctor</italic> group) at recall (compared to encoding; <xref ref-type="fig" rid="fig2">Figure 2C</xref>).</p><p>We also found evidence for memory updating by directly comparing patterns from encoding and retrieval. In the left angular gyrus, left dorsomedial PFC, and right middle temporal cortex, viewing the twist at the end of the movie (vs. not viewing the twist) resulted in neural patterns at recall becoming more similar to the ‘spoiled’ <italic>Ghost</italic> encoding patterns (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). In some regions, this updating effect led to ‘twist’ recall patterns being numerically more similar to the ‘spoiled’ encoding patterns than to encoding patterns from the ‘twist’ condition, but this effect did not survive multiple comparisons correction (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). We suggested that the weakness of this effect may be attributable to some participants not fully discarding the <italic>Doctor</italic> interpretation when they update their interpretation; in line with this, an exploratory analysis showed that—in some DMN ROIs—the degree of neural change was nominally correlated (across participants) with behavioral ‘twist scores’ capturing how strongly a participant’s recall was influenced by the twist (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>; these exploratory correlations did not survive multiple comparisons correction). Taken together, our results provide further evidence for the involvement of DMN regions in integrating new information with prior knowledge to form distinct high-level event representations. In particular, we suggest a subset of core DMN regions are implicated in representing changes in event interpretations during memory updating.</p><p>The default mode network, traditionally known to support internally oriented processes, is now considered a major hub for actively processing incoming external information and integrating it with prior knowledge in the social world (<xref ref-type="bibr" rid="bib77">Yeshurun et al., 2021</xref>). Our experimental design targets naturalistic event representations unfolding over seconds to minutes. There have been many studies to date corroborating the discovery of a cortical hierarchy of increasing temporal receptive windows where high-level event representations are encoded at the top of the hierarchy—in the DMN (<xref ref-type="bibr" rid="bib29">Hasson et al., 2008</xref>; <xref ref-type="bibr" rid="bib39">Lerner et al., 2011</xref>; <xref ref-type="bibr" rid="bib30">Hasson et al., 2015</xref>; <xref ref-type="bibr" rid="bib4">Baldassano et al., 2018</xref>; etc). This network is involved in episodic encoding and retrieval (<xref ref-type="bibr" rid="bib55">Rugg and Vilberg, 2013</xref>) and constructive memory-related tasks such as imagining fictitious scenes and future events (<xref ref-type="bibr" rid="bib1">Addis et al., 2007</xref>; <xref ref-type="bibr" rid="bib27">Hassabis and Maguire, 2007</xref>; <xref ref-type="bibr" rid="bib27">Hassabis and Maguire, 2007</xref>; <xref ref-type="bibr" rid="bib55">Rugg and Vilberg, 2013</xref>; <xref ref-type="bibr" rid="bib59">Schacter and Addis, 2007</xref>; <xref ref-type="bibr" rid="bib59">Schacter and Addis, 2007</xref>). Our design relies on an event-level correspondence between the encoding (viewing) and verbal recall of movie scenes. Previous research has localized modality-independent representations of movie scenes (<xref ref-type="bibr" rid="bib78">Zadbood et al., 2017</xref>) and their similarity during encoding and recall (<xref ref-type="bibr" rid="bib13">Chen et al., 2017</xref>) to the DMN. These characteristics make this network a good candidate to contribute to memory updating—a constructive process in which new information is integrated into past event memories in service of better guiding behavior. Our findings support this idea by showing the shift in neural representations during updated recall in a subset of regions in this network.</p><p>At encoding, a widespread set of areas including dorsal and lateral PFC, left precuneus, left retrosplenial cortex, and left angular gyrus had differentiable neural patterns across the two interpretations of the movie. These results are consistent with previous work that showed the time course of brain responses in DMN distinguishes between groups when participants are prompted to take two different perspectives before listening to an audio story (<xref ref-type="bibr" rid="bib76">Yeshurun et al., 2017</xref>). We extend these results to an audiovisual movie, and provide evidence that interpretative perspective is also encoded in spatially distributed neural response patterns for narrative events, averaged across minutes-long scenes. Interestingly, the difference in neural responses measured by Yeshurun and colleagues was not significant between the two perspectives of the story in the ventral portion of mPFC. Similarly, vmPFC ROIs did not exhibit a significant difference between the <italic>Doctor</italic> and <italic>Ghost</italic> representations during the encoding phase in our experiment. Previous research has implicated mPFC in processing schematic information and integration of new information into prior knowledge (<xref ref-type="bibr" rid="bib23">Gilboa and Marlatte, 2017</xref>; <xref ref-type="bibr" rid="bib63">Schlichting and Preston, 2017</xref>; <xref ref-type="bibr" rid="bib74">van Kesteren et al., 2012</xref>). Using naturalistic clips as schematic events, it has been shown that response patterns in mPFC are particularly dependent on intact and predictable schemas (<xref ref-type="bibr" rid="bib4">Baldassano et al., 2018</xref>). Together, these results suggest that our manipulation (<italic>Doctor</italic> and <italic>Ghost</italic> interpretations) may not have substantially altered the schemas that participants were using during movie-viewing (e.g. during a restaurant scene, participants will need to use their ‘restaurant’ schema to interpret it, regardless of whether the doctor is alive or a ghost)—although we interpret these null results with caution.</p><p>Even though groups had different knowledge/perspectives during encoding, we found higher pattern similarity across groups if they had similar twist knowledge during recall in vmPFC, right precuneus, and parts of temporal cortex. Previous findings suggest mPFC is involved in not just encoding but retrieval of memories in relation to prior knowledge (<xref ref-type="bibr" rid="bib9">Brod et al., 2015</xref>; <xref ref-type="bibr" rid="bib73">van Kesteren et al., 2010</xref>) and retrieval of overlapping representations to support integration and organization of related memories (<xref ref-type="bibr" rid="bib70">Tompary and Davachi, 2017</xref>). Our observations during recall fit with these findings and suggest that shifting toward a more similar perspective during recall leads to higher neural similarity in mPFC. However, during encoding, we did not observe a significant pattern correlation between groups that held the same interpretation of the movie. Furthermore, vmPFC was significant in our interaction analysis (<xref ref-type="fig" rid="fig2">Figure 2C</xref>), indicating that the similarity structure of vmPFC patterns across conditions was significantly different at encoding versus retrieval. Together, these results suggest vmPFC is differently implicated in encoding and recall of story-specific representations during processing of naturalistic events. In addition to mPFC, right precuneus and parts of temporal cortex exhibited significantly higher pattern similarity in the ‘twist’ and ‘spoiled’ groups who recalled the movie with the same interpretation. Precuneus is a core region in the posterior medial network, which is hypothesized to be involved in constructing and applying situation models (<xref ref-type="bibr" rid="bib51">Ranganath and Ritchey, 2012</xref>). Our findings support a role for precuneus in deploying interpretation-specific situation models when retrieving event memories. In particular, we suggest that the posterior medial network may encode a shift in the situation model of the ‘twist’ group in order to accommodate the new <italic>Ghost</italic> interpretation.</p><p>We performed two targeted analyses to look for evidence of memory updating across encoding and recall: the interaction analysis (<xref ref-type="fig" rid="fig2">Figure 2C</xref>) and the encoding-recall analysis (<xref ref-type="fig" rid="fig3">Figure 3</xref>). We hypothesized that a shift in direction of pISC difference would occur when neural representations during recall in the ‘twist’ group start to reflect the <italic>Ghost</italic> interpretation. The interaction analysis probed this shift indirectly by taking into account the effects of both encoding-encoding and recall-recall analyses. Unlike the interaction analysis, in the encoding-recall analysis, we <italic>directly</italic> compared neural event representations during encoding and recall. Interestingly, all regions exhibiting an effect across the two encoding-recall analyses, excluding left anterior temporal cortex, were present in the interaction results. Among these regions, the left angular gyrus/TPJ exhibited an effect across all three analyses. As a core hub in the mentalizing network, temporo-parietal cortex has been implicated in theory of mind through perspective-taking, rationalizing the mental state of someone else, and modeling the attentional state of others (<xref ref-type="bibr" rid="bib22">Frith and Frith, 2006</xref>; <xref ref-type="bibr" rid="bib26">Guterstam et al., 2021</xref>; <xref ref-type="bibr" rid="bib57">Saxe and Kanwisher, 2003</xref>). The motivations behind some actions of the main character in the movie heavily depend on whether the viewer perceives them as a Doctor or a Ghost, and participants may focus on this during both encoding and recall. We speculate that neural event representations in AG/TPJ in the current experiment may be related to mentalizing about the main character’s actions. Under this interpretation, the updated event representations during recall following the twist would be more closely aligned to the ‘spoiled’ encoding representations, as a consequence of memory updating in the ‘twist’ group.</p><p>Our findings are consistent with the view that DMN synthesizes incoming information with one’s prior beliefs and memories (<xref ref-type="bibr" rid="bib77">Yeshurun et al., 2021</xref>). We add to this framework by providing evidence for the involvement of DMN regions in updating prior beliefs in light of new knowledge. Across our different encoding and recall analyses, we observe memory updating effects in a varied subset of DMN regions that do not cleanly map onto a specific subsystem of DMN (<xref ref-type="bibr" rid="bib54">Robin and Moscovitch, 2017</xref>; <xref ref-type="bibr" rid="bib51">Ranganath and Ritchey, 2012</xref>; <xref ref-type="bibr" rid="bib52">Ritchey and Cooper, 2020</xref>). Rather than being divergent, these results might be reflecting inherent differences between the processes of encoding and recall of naturalistic events. It has been proposed that neural representations corresponding to encoding of events are systematically transformed during recall of those events (<xref ref-type="bibr" rid="bib13">Chen et al., 2017</xref>; <xref ref-type="bibr" rid="bib18">Favila et al., 2020</xref>; <xref ref-type="bibr" rid="bib42">Musz and Chen, 2022</xref>). While we provide evidence for reinstatement of memories in DMN, our findings also support a transformation of neural representation during recall, as encoding-recall results were weaker in some areas than recall-recall findings. This transformation could affect how different regions and sub-systems of DMN represent memories, and suggests that the concerted activity of multiple subsystems and neural mechanisms might be at play during encoding, recall and successful updating of naturalistic event memories.</p><p>While our main goal in this paper was to examine how neural representations of naturalistic events change in the DMN, we also examined visual and somatosensory networks. Aside from the encoding-encoding analysis in which some visual and somatosensory regions showed stronger similarity between two groups with the same interpretation of the movie, we did not find any regions with significant effects in these two networks in the other analyses. Unlike the recall phase where each participant has their unique utterance with their own choice of words and concepts to describe the movie, the encoding (move-watching) stimulus is identical across all groups. Therefore, the effects observed during encoding-encoding analysis in sensory regions could reflect similarity in perception of the movie guided by similar attentional state while watching scenes with the same interpretation (e.g. similarity in gaze location, paying attention to certain dialogues, or small body movements while watching the movie with the same Doctor or Ghost interpretations). In our whole brain analysis, these regions did not have significant interaction effects, which suggests that the effects were isolated to encoding. In the whole-brain analysis, we also observed a significant encoding-encoding and interaction effects in anterior cingulate cortex, as well as recall-recall and interaction effects in dlPFC. These results suggest that both the ‘spoiled’ manipulation and the ‘twist’ may recruit top-down control and conflict monitoring processes during naturalistic viewing and recall.</p><p>Our findings provide further insight into the functional role of the DMN. However, these results have been obtained using only one movie. While naturalistic paradigms better capture the complexity of real life and provide greater ecological generalizability than highly-controlled experimental stimuli and tasks (<xref ref-type="bibr" rid="bib45">Nastase et al., 2020</xref>), they are still limited by the properties of the particular naturalistic stimulus used. For example, this movie—including the twist itself—hinges on suspension of disbelief about the existence of ghosts. Future work is needed to extend our findings about updating event memories to a broader class of naturalistic stimuli: for example, movies with different kinds of (non-supernatural) plot twists, spoken stories with twist endings, or using autobiographical real-life situations where new information (e.g. discovering a longtime friend has lied about something important) triggers re-evaluation of the past (e.g. reinterpreting their friend’s previous actions). Moreover, our current method relies on averaging spatially coarse activity patterns across subjects (and time points within an event). Future extensions of this work may benefit from using functional alignment methods (<xref ref-type="bibr" rid="bib31">Haxby et al., 2020</xref>; <xref ref-type="bibr" rid="bib12">Chen et al., 2015</xref>) to capture more fine-grained event representations which are shared across participants.</p><p>During recall, many participants recounted both the old and new interpretations (<italic>Ghost</italic> and <italic>Doctor</italic>) of movie scenes. This behavior indicated that they maintained both representations in parallel (possibly competing), rather than overwriting the old representation with new information. The simultaneous presence of these representations poses an interesting theoretical question for future studies: When does updating the memory cause us to lose traces of the old interpretation, and when do the old and new interpretations end up co-existing in memory? Previous studies have shown that old and new memory traces are simultaneously reactivated in the brain, leading to competition (e.g. <xref ref-type="bibr" rid="bib37">Kuhl et al., 2012</xref>), and this competition can trigger learning processes that resolve the competition; for example, by weakening one of the memories or by restructuring the memories so they can coexist (<xref ref-type="bibr" rid="bib53">Ritvo et al., 2019</xref>). Understanding how competition between interpretations plays out over time is an important topic for future work; existing research on memory revaluation suggests that updating may be a temporally-extended process driven by successive replays of the new information, rather than taking place all at once (see, e.g., <xref ref-type="bibr" rid="bib40">Momennejad et al., 2018</xref>). In clinical settings, methods inspired by reconsolidation and memory updating are extensively used to treat maladaptive memories (<xref ref-type="bibr" rid="bib47">Phelps and Hofmann, 2019</xref>). In these clinical contexts, it will be especially important to understand the factors that influence the ‘end state’ of this competition between interpretations (in terms of our study: who ends up fully adopting the <italic>Ghost</italic> interpretation and who ends up with lingering traces of the <italic>Doctor</italic> interpretation).</p><p>In summary, our findings show that in a movie with a dramatic twist ending, the new information introduced by the twist causes a new (<italic>Ghost</italic>) interpretation of past events to take root in participants’ brains. Overall, these results highlight the importance of DMN regions in updating naturalistic memories and suggest new approaches to studying real-world memory modification in both experimental and clinical treatment settings.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Stimuli</title><p>The stimuli consisted of three edited versions of ‘The Sixth Sense’ (M. Night Shyamalan, 1999) movie. The movie depicts the story of a child psychologist treating a young boy who claims he can see and speak with dead people. In the film’s ending scene, however, it is revealed that the psychologist died prior to the events of the movie and has actually been one of the ghosts the boy was seeing all along. Three different edited versions of the movie were created for the experiment. The first version was a~60 min shortened movie including the final scene with the big reveal followed by a text on the screen describing the twist to ensure all participants in the ‘twist’ group fully understood the twist information. The second version was identical to the first version, but a spoiler was presented as text on screen early in the movie (the ‘spoiled’ group). In the third version, the final scene was cut out and the movie ended at a point where it appeared that the doctor successfully completed the treatment and therefore did not raise any suspicion about the twist in participants who watched this version (‘no-twist’ group). Eighteen scenes were selected to be included in the cued recall task (see the section on timestamping and scene selection below). For each of these scenes, a short clip from the beginning of that scene (lasting from 5 to 36 s. Mean = 12.9 s) was used as a retrieval cue for the scene during the recall task.</p></sec><sec id="s4-2"><title>Participants</title><p>Sixty-six right-handed, native English speakers (ages 18–24, average = 20, 21 males) were scanned in the experiment. Our sample size was decided based on our previous work in which we captured scene-specific pattern similarity across encoding, recall, and listening (18 subjects per group in <xref ref-type="bibr" rid="bib78">Zadbood et al., 2017</xref>, 17 subjects in <xref ref-type="bibr" rid="bib13">Chen et al., 2017</xref>) and differences in brain response while listening to the same story with different perspectives (20 subjects per group in <xref ref-type="bibr" rid="bib76">Yeshurun et al., 2017</xref>). None of the participants had previously seen The Sixth Sense in full or in part, which was confirmed through an online questionnaire before the session. However, because the movie is well-known and frequently referenced in popular culture, participants with some knowledge about the twist (e.g. knowing that this is a movie about ghosts and the main character is actually dead) were admitted to the ‘spoiled’ group (see <italic>Experimental design</italic>) in order to facilitate data collection. In the post-scan questionnaire, two participants reported guessing the twist while watching the movie and their data were excluded. One participant did not understand the twist after watching the final scene and receiving the text explanation, so their data were omitted as well. Six participants were excluded due to large head motion (spikes of framewise displacement &gt;4 mm). The data of the remaining fifty-seven participants were used in the analyses. All participants provided written informed consent prior to the experiment and received information about the conditions of the experiment and their rights. The experiment protocol and the consent forms were approved by the Institutional Review Board of Princeton University.</p></sec><sec id="s4-3"><title>Experimental design</title><p>Participants were pseudo-randomly divided into three groups: the ‘twist’ group (N=19) watched a 60 min audio-visual edition of The Sixth Sense movie, including the twist at the end while undergoing fMRI scanning. The ‘spoiled’ group (N=18) watched a spoiled version of the movie (see Stimuli). The ‘no-twist’ group (N=20) watched a 55 min version of the movie with no twist scene (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). Participants were instructed to watch the movie naturally and attentively, as there will be a task related to the movie content after watching. However, no specific information about the upcoming recall task was revealed. After the movie, participants performed a verbal cued recall task. During the cued recall task, participants watched short clips from 18 scenes of the movie. After each clip, they were asked to freely describe the events of that particular scene and to provide the most accurate interpretation of the scene given all the information they have gathered throughout watching. The instructions were identical for all three groups. The movie cue and recall were separated by 14 s, which ended as a countdown on the screen. The recall task was self-paced and participants pressed a button to continue to the next scene after each recall. After scanning, participants filled out a questionnaire about their experience in the scanner, including information about the movie and recall tasks and whether they guessed the twist in the middle of the movie (and if yes in which scene). All participants rated the movie as engaging. Participants in the ‘no-twist’ group were debriefed about the real ending of the movie before leaving the facility.</p></sec><sec id="s4-4"><title>Scanning procedure</title><p>The scanning session began with an anatomical scan. Participants watched the movie and read the instructions through a mirror mounted to the head coil which reflected a rear screen. The main screen was located at the back of the magnet bore and the movie was projected on the screen via an LCD projector. MR-safe, in-ear headphones were used for the movie audio. Eye-tracking was set up to monitor participants during the scans in real-time and ensure they stayed awake and attentive during the experiment. The movie and recall stimuli were presented using the Psychophysics Toolbox in MATLAB (Mathworks), which enabled coordinating the onset of the stimuli (movie and recall cues) with data acquisition. The volume level of the movie was adjusted separately for each participant using a sample clip to assure a clear and comfortable audio signal. Recall speech was recorded during the fMRI scan using a customized MR-compatible recording system (FOMRI II; Optoacoustics Ltd). The MR recording system used two orthogonally-oriented optical microphones. The reference microphone captures the background noise, and the source microphone captures both background noise and the speaker’s speech (signal). A dual-adaptive filter subtracted the reference input from the source channel using a least mean square approach. To achieve an optimal subtraction, the reference signal was adaptively filtered so the filter gains are learned continuously from the residual signal and the reference input. To prevent divergence of the filter when speech was present, a voice activity detector was integrated into the algorithm. A speech enhancement spectral filtering algorithm further preprocessed the speech output to achieve a real-time speech enhancement. Audio recordings were further cleaned using noise removal software (Adobe Audition). The output recall recordings were fully comprehensible. A response box was used to collect the participants’ manual button-presses during the recall task. Participants were instructed to press a button when they finished the recall of a scene to proceed with the task. In five participants, the recall scans were stopped due to problems in pressing the buttons (or just by mistake) and were resumed after they received feedback and further instructions. In these cases, the recalls were resumed starting with the next scene. In three participants the recall scan was stopped after the first scene and in one participant before the last two scenes. In one participant the scan stopped and resumed in the middle of the recall task.</p></sec><sec id="s4-5"><title>MRI acquisition</title><p>MRI data were collected on a 3T full-body scanner (Siemens Prisma) with a 64-channel head coil. Functional images were acquired using an interleaved multiband EPI sequence (TR = 1500ms, TE 33ms, flip angle 80 degrees, whole-brain coverage, 2 mm slice thickness, FOV 192 mm<sup>2</sup>, SMS = 4). Anatomical images were acquired using a T1-weighted magnetization-prepared rapid-acquisition gradient echo (MPRAGE) pulse sequence (1 mm<sup>3</sup> resolution). Anatomical images were acquired in a 6-min scan before the functional scans with no stimulus on the screen. Field maps were collected for B0 correction at the end of the recall run.</p></sec><sec id="s4-6"><title>Preprocessing</title><p>Preprocessing was performed using fMRIPrep, version stable 1.0.11 (<xref ref-type="bibr" rid="bib17">Esteban et al., 2019</xref>, RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_016216">SCR_016216</ext-link>), a Nipype (<xref ref-type="bibr" rid="bib24">Gorgolewski et al., 2011</xref>, RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_002502">SCR_002502</ext-link>) based tool. Each T1w (T1-weighted) volume was corrected for INU (intensity non-uniformity) using N4BiasFieldCorrection v2.1.0 (<xref ref-type="bibr" rid="bib72">Tustison et al., 2010</xref>) and skull-stripped using antsBrainExtraction.sh v2.1.0 (using the OASIS template). Spatial normalization to the ICBM 152 Nonlinear Asymmetrical template version 2009c (<xref ref-type="bibr" rid="bib21">Fonov et al., 2009</xref>, RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_008796">SCR_008796</ext-link>) was performed through nonlinear registration with the antsRegistration tool of ANTs v2.1.0 (<xref ref-type="bibr" rid="bib3">Avants et al., 2008</xref>, RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_004757">SCR_004757</ext-link>), using brain-extracted versions of both T1w volume and template.</p><p>Functional data were motion corrected using mcflirt (FSL v5.0.9, <xref ref-type="bibr" rid="bib34">Jenkinson et al., 2002</xref>). &quot;Fieldmap-less&quot; distortion correction was performed by co-registering the functional image to the same-subject T1w image with intensity inverted (<xref ref-type="bibr" rid="bib75">Wang et al., 2017</xref>) constrained with an average fieldmap template (<xref ref-type="bibr" rid="bib71">Treiber et al., 2016</xref>), implemented with antsRegistration (ANTs). This was followed by co-registration to the corresponding T1w using boundary-based registration (<xref ref-type="bibr" rid="bib25">Greve and Fischl, 2009</xref>) with six degrees of freedom, using flirt (FSL). Motion correcting transformations, field distortion correcting warp, BOLD-to-T1w transformation and T1w-to-template (MNI) warp were concatenated and applied in a single step using antsApplyTransforms (ANTs v2.1.0) using Lanczos interpolation.Frame-wise displacement (<xref ref-type="bibr" rid="bib48">Power et al., 2014</xref>) was calculated for each functional run using the implementation of Nipype.</p><p>Then, the datasets were adaptively smoothed using AFNI’s 3dBlurToFWHM to reach 7 mm global smoothness (<xref ref-type="bibr" rid="bib15">Cox, 1996</xref>). Note that the 7 mm reported smoothness is the <italic>global smoothness</italic>, which is the ‘final’ smoothness of the images given their original, intrinsic smoothness and the applied smoothing. In other words, we did not apply an additional 7 mm smoothing kernel to the data; rather, we iteratively smoothed the data until a 7 mm global smoothness was attained (using AFNI’s <ext-link ext-link-type="uri" xlink:href="https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dBlurToFWHM.html">3dBlurToFWHM</ext-link>). If the initial smoothness of the raw data was roughly 2 mm, this would be similar to applying a 5 mm smoothing kernel. This amount of smoothing is comparable to previous papers using similar intersubject pattern similarity methods to compare event-level representations during encoding and recall (<xref ref-type="bibr" rid="bib13">Chen et al., 2017</xref>; <xref ref-type="bibr" rid="bib78">Zadbood et al., 2017</xref>). AFNI’s 3dTproject was used to regress out confound variables comprising head motion (6 motion parameters and their temporal derivatives), second-order polynomial detrending variables, and high-pass filtering (140 s cutoff). De-spiking and subsequent analyses were conducted using custom MATLAB scripts (see Code Accessibility). The movie data were acquired in a single run and the time series were z-scored across the entire run prior to further analysis. Inspection of the recall data revealed a dramatic difference in mean signal intensity between the audiovisual movie cues and the verbal recall sections during the cued-recall task. To account for this, we used the least-squares-separate (LSS) method (<xref ref-type="bibr" rid="bib41">Mumford et al., 2012</xref>) implemented by AFNI’s 3dLSS to model the recall data. In this method each verbal recall section was modeled independently of both the other recall scenes and the preceding movie cue. Regression coefficients (beta values) obtained by this method (one beta value per scene) were used in the main analyses. In four participants where the recall scan was split due to button-press issues, the smaller section of the recall only included 1–2 scenes. These scans were too short to be modeled using LSS and the data for these scenes were ignored. All analyses were performed in volume space. The results were projected onto the surface for visualization using <ext-link ext-link-type="uri" xlink:href="https://www.humanconnectome.org/software/connectome-workbench">Connectome Workbench</ext-link>.</p></sec><sec id="s4-7"><title>Atlas and ROI definitions</title><p>Whole brain ROI analysis was performed on a set of 100 ROIs grouped into seven networks based on functional connectivity during rest (<xref ref-type="bibr" rid="bib61">Schaefer et al., 2018</xref>). Twenty-four of these ROIs labeled as ‘DMN’ were used in the main analysis.</p></sec><sec id="s4-8"><title>Timestamping and scene selection</title><p>The movie was time-stamped by an independent rater naive to the purpose and design of the experiment to identify the main scenes of the movie. All of the movie scenes with clear scene boundaries (N=18) were selected to be used in the cued-recall task. Prior to running the fMRI experiment, our evaluation of movie scenes suggested that, in some scenes, knowing the twist information would more dramatically change the interpretation of the scenes (we called them ‘critical scenes’). However, we also thought it was possible that the twist would affect recall of other scenes in the movie; for this reason, we decided to include all 18 movie scenes in the cued-recall task, rather than limiting ourselves to the critical scenes. Very short snippets from the beginning of these scenes were used as cues in the recall task. To determine the exact number of ‘critical scenes’, a group of five raters (AZ from the authors and four independent raters naïve to the purpose of the experiment) watched the movie and rated all 18 scenes in terms of how much the twist information might change the interpretation of these scenes (‘twist influence’). They were instructed to rate each scene on a scale of 1–5 (1=Interpretation does not change at all, 2=Interpretation is mildly changed, 3=Interpretation is moderately changed, 4=Interpretation is strongly changed, 5=Interpretation is very strongly changed). Six scenes scored 4 or higher (‘Interpretation is strongly changed’)—these critical scenes were selected for the main neural analyses. There was 100% agreement between the top 6 scenes scored by the rater from our group and the top 6 scenes selected using the average of ratings of our four independent raters. In the independent analysis of the recall behavior data, this same set of 6 scenes scored highest in twist score (described in the next section) which indicates a match between expected and perceived effect of twist information on recall behavior. Scene number one, in which the doctor and child meet for the first time was scored ~3 (Interpretation is moderately changed) but showed a high twist score in the behavioral recall analysis. This scene was the first time participants recalled the doctor after the main reveal (watching the twist) and given its high twist score, the recall and possibly the corresponding neural patterns appeared to be more strongly affected by the twist information. Therefore, we added this scene as a seventh critical scene to be used in the main neural analyses.</p></sec><sec id="s4-9"><title>Behavioral analysis</title><p>The recall data were transcribed from speech to text and subject numbers (and group information) were removed. The same four independent raters who watched the movie and rated the ‘twist influence’ in the previous section read the recall data scene by scene. They rated each scene for all subjects, while the order of scenes across subjects was shuffled and there was no information indicating to which experimental group the scene belonged. They were asked to report a score for each scene based on the ‘ghostness’ or ‘doctorness’ of the depiction of the main character in that scene. The scores were from 1 to 5 (1=Purely reflects the <italic>Doctor</italic> interpretation, 2=More strongly reflects the <italic>Doctor</italic> interpretation, 3=Balanced between <italic>Doctor</italic> and <italic>Ghost</italic> interpretation, 4=More strongly reflects the <italic>Ghost</italic> interpretation, 5=Purely reflects the <italic>Ghost</italic> interpretation). Raters showed strong agreement on their scoring (pairwise correlations between raters’ scores ranged from <italic>r</italic>=0.84, p=6.6 × 10<sup>–18</sup> to <italic>r</italic>=0.97, p=7.5 × 10<sup>–42</sup>). Scores for each scene were averaged across 4 raters and were used as the twist score in the main analyses. Two separate raters scored the recall data based on the details and accuracy of recall irrespective of the twist information. Scores provided by these raters were averaged and used as the ‘memory score’.</p><p>The average length of scenes in the 55-min movie was 2 min and 10 s (sd = 1:59, median = 1:56, min = 00:26, max = 5:56). For the recalls, in the ‘spoiled’ group the average recall time per scene was 39.4 s (sd = 13.2 s, min = 14 s, max = 67 s) for a total average of 713 s of recall time. In the ‘twist’ group, the average recall time per scene was 38.5 s (sd = 13 s, min = 17 s, max = 69 s) for a total average of 698 s of recall time. In the ‘no-twist’ group, the average recall time per scene was 37.75 s (sd = 19.8 s, min = 8 s, max = 73 s) for a total average of 642 s of recall time. No significant differences were observed between average recall time per scene or overall recall time across any two groups (according to t-tests).</p></sec><sec id="s4-10"><title>Intersubject pattern correlation (pISC) analysis</title><p>The multivariate analysis of the data was performed by measuring the similarity between the spatial patterns of brain response in each ROI. To obtain this measure, first the time series of brain responses to the movie in each subject/ROI was averaged within each of the seven critical scenes. This method has been used to study scene-specific patterns of brain activity in previous studies (<xref ref-type="bibr" rid="bib13">Chen et al., 2017</xref>; <xref ref-type="bibr" rid="bib78">Zadbood et al., 2017</xref>). Averaging the time series within each scene resulted in seven spatially distributed patterns of brain activity in each ROI. For the recall phase, the beta values extracted via LSS modeling were used, similarly providing 7 activity patterns in each ROI. All pattern similarity analyses were performed between subjects to capitalize on the between-group design of the experiment (<xref ref-type="bibr" rid="bib44">Nastase et al., 2019</xref>). For the encoding phase, the patterns of brain activity in each subject from the ‘twist’ group were correlated (Pearson correlation) with the average of activity patterns for the ‘spoiled’ group in corresponding scenes and averaged across scenes. The same procedure was performed to compare the ‘twist’ and ‘no-twist’ groups which resulted in two correlation values assigned to each subject in the ‘twist’ group. All correlation values were Fisher transformed prior to further analysis (<xref ref-type="bibr" rid="bib20">Fisher, 1915</xref>). In each ROI, the difference between these two comparisons was calculated and averaged across participants (difference r values depicted on each map). To determine statistical significance, we compared these two sets of values using a non-parametric paired t-test by shuffling the sign of difference values across subjects 1000 times and calculating a p-value for the observed difference based on this null distribution (one-tailed). p Values were corrected for multiple comparisons across DMN ROIs by controlling the false discovery rate (FDR) at p&lt;0.05 (<xref ref-type="bibr" rid="bib6">Benjamini and Hochberg, 1995</xref>). The same procedure was performed in the recall and encoding-recall analysis except for two differences in the encoding-recall analysis: during the analysis to compare ‘twist’ and ‘no-twist’ recall with ‘spoiled’ encoding (<xref ref-type="fig" rid="fig3">Figure 3A</xref>), an independent sample non-parametric t test was performed by shuffling the group labels 1000 times and calculating the difference between the two permuted groups at each iteration to create the null distribution. To compare the ‘twist’ recall with the ‘twist’ encoding (<xref ref-type="fig" rid="fig3">Figure 3B</xref>), each subject’s recall was compared to the average of the rest of the group’s encoding to ensure all comparisons were made across subjects. To match the number of subjects in the encoding groups, one subject was randomly dropped from the encoding set in each iteration when comparing ‘twist’ recall to ‘spoiled’ encoding.</p><p>The interaction analysis assessed whether neural patterns in the ‘wist’ group were relatively more similar to the ‘spoiled’ (vs. ‘no-twist’) group at recall (vs. encoding), and was computed as follows:<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold">i</mml:mi><mml:mi mathvariant="bold">n</mml:mi><mml:mi mathvariant="bold">t</mml:mi><mml:mi mathvariant="bold">e</mml:mi><mml:mi mathvariant="bold">r</mml:mi><mml:mi mathvariant="bold">a</mml:mi><mml:mi mathvariant="bold">c</mml:mi><mml:mi mathvariant="bold">t</mml:mi><mml:mi mathvariant="bold">i</mml:mi><mml:mi mathvariant="bold">o</mml:mi><mml:mi mathvariant="bold">n</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="bold">i</mml:mi><mml:mi mathvariant="bold">n</mml:mi><mml:mi mathvariant="bold">d</mml:mi><mml:mi mathvariant="bold">e</mml:mi><mml:mi mathvariant="bold">x</mml:mi><mml:mtext> </mml:mtext><mml:mo mathvariant="bold" stretchy="false">(</mml:mo><mml:mi mathvariant="bold">r</mml:mi><mml:mo mathvariant="bold" stretchy="false">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi><mml:mtext>-</mml:mtext><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mtext>-</mml:mtext><mml:mi>t</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mspace width="thinmathspace"/><mml:mrow><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mrow><mml:mtext> </mml:mtext><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi><mml:mtext>-</mml:mtext><mml:mi>t</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>−</mml:mo><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">(</mml:mo><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi><mml:mtext>-</mml:mtext><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mspace width="thinmathspace"/><mml:mrow><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi><mml:mtext>-</mml:mtext><mml:mi>t</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>−</mml:mo><mml:mspace width="thinmathspace"/></mml:mstyle><mml:mspace linebreak="newline"/><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mtext>-</mml:mtext><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mtext>-</mml:mtext><mml:mi>t</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mspace width="thinmathspace"/><mml:mrow><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mtext>-</mml:mtext><mml:mi>t</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>−</mml:mo><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mtext>-</mml:mtext><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mrow><mml:mrow><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mtext>-</mml:mtext><mml:mi>t</mml:mi><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The same pISC procedures were performed in the regions of the visual and somatosensory cortices (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>), as well as across the whole brain (<xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3</xref>). All regions were extracted from the 100-parcel Shaeffer where each region is assigned to one of seven resting-state networks (<xref ref-type="bibr" rid="bib61">Schaefer et al., 2018</xref>).</p><p>In the scene content analyses (<xref ref-type="fig" rid="fig4">Figure 4</xref>), interaction index was calculated using different subsets of scenes including <italic>critical scenes</italic> (N=7), <italic>non-critical scenes</italic> (N=11) and <italic>all scenes</italic> (N=18) in all regions within the DMN. Other than the scene selection, the rest of the procedure was identical to the pISC analysis described above and used in the main analyses (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Interaction indices across ROIs from the ‘critical scene’ condition were compared with the ones from all scene and non-critical scenes using a paired t-test. To examine scene specificity, scene labels were shuffled within each subject and the pISC analysis was repeated 1000 times on the new scene orders to create the distribution depicted as ‘shuffled scenes’ on <xref ref-type="fig" rid="fig4">Figure 4</xref>. For each ROI, the number of interaction indices in this pool of null values that were larger than the original interaction indices were used to calculate p-values. p-Values were corrected for multiple tests (across DMN regions) by controlling the false discovery rate (FDR) at q&lt;0.05.</p><p>To ensure our results (<xref ref-type="fig" rid="fig2">Figures 2</xref>–<xref ref-type="fig" rid="fig3">3</xref>) were not driven by overall activation differences across the groups (‘spoiled’, ‘twist’, ‘no-twist’), we performed a univariate analysis in each ROI. For each participant in the movie group, we calculated the regional-average response magnitude in each ROI. The same procedure was done for beta values obtained using the GLM during recall. This yielded a two conditions by three groups table of univariate activity magnitudes per ROI. We performed an ANOVA with condition as a within-subject factor and group as a between-subject factor. This analysis yielded no significant effect of group or interaction of group and condition in any ROIs. Two ROIs exhibited a significant effect of group and one ROI showed a significant interaction prior to correction for multiple tests, but these values did not survive correction (<xref ref-type="table" rid="app1table1">Appendix 1—table 1</xref>).</p><p>To ensure that our results were not biased due to any systematic differences in the noise level of neural activity patterns between the groups (<italic>spoiled</italic>, <italic>twist</italic>, <italic>no-twist</italic>), we calculated the pISC within each group by correlating each subject’s pattern with the average pattern from the rest of the subjects in that group. We performed this procedure for the movie and recall conditions separately in each of the 15 ROIs that showed any significant effect in any of the reported analyses. We then submitted all the correlation values across subjects to an ANOVA including all groups, conditions, and ROIs. As expected, we did not find any main effect of group or an interaction of group with condition or ROI.</p><p>In the analysis to identify the relationship between the neural and behavioral signature of memory update (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>), the neural data were obtained by computing (r<italic>ecall-twist</italic> vs. <italic>movie-spoiled</italic>) – (r<italic>ecall-twist</italic> vs. <italic>movie-twist</italic>), as mentioned above and described in the results section. However, the difference values were not averaged and were correlated with the twist score across participants.</p><p>In the analysis to compare the behavioral and neural responses across scenes (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4</xref>), we performed the same pISC procedure as in the recall-recall analysis (<xref ref-type="fig" rid="fig2">Figure 2B</xref>) and encoding-recall analysis (<xref ref-type="fig" rid="fig3">Figure 3B</xref>) on all scenes. However, this time we did not average the scene responses. Instead, we averaged the pISC difference value for each scene across participants. Similarly, we averaged participants’ behavioral twist scores for each scene. We then computed the Pearson correlation between the vectors of pISC differences and behavioral twist scores (18 values in each vector, equal to the number of scenes). We repeated this procedure in each DMN region and plotted the strength of these correlations on the brain (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4</xref>, left panels). To better understand the role of ‘critical scenes’ in this relationship, those scenes were marked as blue on the scatter plots (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4</xref>, left panels).</p></sec><sec id="s4-11"><title>Code and data accessibility</title><p>Code available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/azadbood/sixthsense">https://github.com/azadbood/sixthsense</ext-link>, (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:0ff25d23d2a50134cab3846a399dfffbb71c673c;origin=https://github.com/azadbood/sixthsense;visit=swh:1:snp:2894b33de48b2cd67078a59210580c01047f86fd;anchor=swh:1:rev:889b89f8201d7a28b9dc2b44dda211f05a218c0d">swh:1:rev:889b89f8201d7a28b9dc2b44dda211f05a218c0d</ext-link>; <xref ref-type="bibr" rid="bib2">Asieh, 2022</xref>). Data available at: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.18112/openneuro.ds004359.v1.0.0">https://doi.org/10.18112/openneuro.ds004359.v1.0.0</ext-link>.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Software, Formal analysis, Investigation, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Supervision, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Supervision, Funding acquisition, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Supervision, Funding acquisition, Methodology, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: All participants provided written informed consent prior to the experiment and received information about the conditions of the experiment and their rights. The experiment protocol and the consent forms were approved by the Institutional Review Board of Princeton University (protocol number 7883).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-79045-mdarchecklist1-v2.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Code available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/azadbood/sixthsense">https://github.com/azadbood/sixthsense</ext-link>, (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:7f0444cb2867810520afa3a060e1c9683964b8aa;origin=https://github.com/azadbood/sixthsense;visit=swh:1:snp:1a323a91bc3f2153abac45a071620e2ddeaef0e1;anchor=swh:1:rev:113b3203722573033b5cc4535f6523c1fca5c1d7">swh:1:rev:113b3203722573033b5cc4535f6523c1fca5c1d7</ext-link>) Data available at: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.18112/openneuro.ds004359.v1.0.0">https://doi.org/10.18112/openneuro.ds004359.v1.0.0</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Zadbood</surname><given-names>A</given-names></name><name><surname>Nastase</surname><given-names>SA</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><source>OpenNeuro</source><year iso-8601-date="2022">2022</year><data-title>SixthSense</data-title><pub-id pub-id-type="doi">10.18112/openneuro.ds004359.v1.0.0</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported by the National Institutes of Health (NIMH R01 MH12357 awarded to UH and KAN and DP1 HD091948 awarded to UH). We thank Savannah Born for help in analyzing the behavioral data, Christopher Honey for helpful comments on data analysis, and Liat Hasenfratz for help with execution of the study.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Addis</surname><given-names>DR</given-names></name><name><surname>Wong</surname><given-names>AT</given-names></name><name><surname>Schacter</surname><given-names>DL</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Remembering the past and imagining the future: common and distinct neural substrates during event construction and elaboration</article-title><source>Neuropsychologia</source><volume>45</volume><fpage>1363</fpage><lpage>1377</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2006.10.016</pub-id><pub-id pub-id-type="pmid">17126370</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Asieh</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>SixthSense</data-title><version designator="swh:1:rev:113b3203722573033b5cc4535f6523c1fca5c1d7">swh:1:rev:113b3203722573033b5cc4535f6523c1fca5c1d7</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:7f0444cb2867810520afa3a060e1c9683964b8aa;origin=https://github.com/azadbood/sixthsense;visit=swh:1:snp:1a323a91bc3f2153abac45a071620e2ddeaef0e1;anchor=swh:1:rev:113b3203722573033b5cc4535f6523c1fca5c1d7">https://archive.softwareheritage.org/swh:1:dir:7f0444cb2867810520afa3a060e1c9683964b8aa;origin=https://github.com/azadbood/sixthsense;visit=swh:1:snp:1a323a91bc3f2153abac45a071620e2ddeaef0e1;anchor=swh:1:rev:113b3203722573033b5cc4535f6523c1fca5c1d7</ext-link></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Avants</surname><given-names>BB</given-names></name><name><surname>Epstein</surname><given-names>CL</given-names></name><name><surname>Grossman</surname><given-names>M</given-names></name><name><surname>Gee</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Symmetric diffeomorphic image registration with cross-correlation: evaluating automated labeling of elderly and neurodegenerative brain</article-title><source>Medical Image Analysis</source><volume>12</volume><fpage>26</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1016/j.media.2007.06.004</pub-id><pub-id pub-id-type="pmid">17659998</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baldassano</surname><given-names>C</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Representation of real-world event schemas during narrative perception</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>9689</fpage><lpage>9699</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0251-18.2018</pub-id><pub-id pub-id-type="pmid">30249790</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bartlett</surname><given-names>FC</given-names></name><name><surname>Burt</surname><given-names>C</given-names></name></person-group><year iso-8601-date="1933">1933</year><article-title>Remembering: a study in experimental and social psychology</article-title><source>British Journal of Educational Psychology</source><volume>3</volume><fpage>187</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1111/j.2044-8279.1933.tb02913.x</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benjamini</surname><given-names>Y</given-names></name><name><surname>Hochberg</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Controlling the false discovery rate: a practical and powerful approach to multiple testing</article-title><source>Journal of the Royal Statistical Society</source><volume>57</volume><fpage>289</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1111/j.2517-6161.1995.tb02031.x</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Besnard</surname><given-names>A</given-names></name><name><surname>Caboche</surname><given-names>J</given-names></name><name><surname>Laroche</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Reconsolidation of memory: a decade of debate</article-title><source>Progress in Neurobiology</source><volume>99</volume><fpage>61</fpage><lpage>80</lpage><pub-id pub-id-type="doi">10.1016/j.pneurobio.2012.07.002</pub-id><pub-id pub-id-type="pmid">22877586</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bird</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>How do we remember events?</article-title><source>Current Opinion in Behavioral Sciences</source><volume>32</volume><fpage>120</fpage><lpage>125</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2020.01.020</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brod</surname><given-names>G</given-names></name><name><surname>Lindenberger</surname><given-names>U</given-names></name><name><surname>Werkle-Bergner</surname><given-names>M</given-names></name><name><surname>Shing</surname><given-names>YL</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Differences in the neural signature of remembering schema-congruent and schema-incongruent events</article-title><source>NeuroImage</source><volume>117</volume><fpage>358</fpage><lpage>366</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.05.086</pub-id><pub-id pub-id-type="pmid">26048620</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buckner</surname><given-names>RL</given-names></name><name><surname>Andrews-Hanna</surname><given-names>JR</given-names></name><name><surname>Schacter</surname><given-names>DL</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The brain’s default network: anatomy, function, and relevance to disease</article-title><source>Annals of the New York Academy of Sciences</source><volume>1124</volume><fpage>1</fpage><lpage>38</lpage><pub-id pub-id-type="doi">10.1196/annals.1440.011</pub-id><pub-id pub-id-type="pmid">18400922</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>CHC</given-names></name><name><surname>Nastase</surname><given-names>SA</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Information Flow across the Cortical Timescales Hierarchy during Narrative Construction</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.12.01.470825</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>PH</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Yeshurun</surname><given-names>Y</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Haxby</surname><given-names>J</given-names></name><name><surname>Ramadge</surname><given-names>PJ</given-names></name></person-group><article-title>A Reduced-Dimension fMRI Shared Response Model</article-title><conf-name>Advances in Neural Information Processing Systems 28</conf-name><year iso-8601-date="2015">2015</year><ext-link ext-link-type="uri" xlink:href="https://papers.nips.cc/paper/2015/hash/b3967a0e938dc2a6340e258630febd5a-Abstract.html">https://papers.nips.cc/paper/2015/hash/b3967a0e938dc2a6340e258630febd5a-Abstract.html</ext-link></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Leong</surname><given-names>YC</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name><name><surname>Yong</surname><given-names>CH</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Shared memories reveal shared structure in neural activity across individuals</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>115</fpage><lpage>125</lpage><pub-id pub-id-type="doi">10.1038/nn.4450</pub-id><pub-id pub-id-type="pmid">27918531</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Conway</surname><given-names>M</given-names></name><name><surname>Pleydell-Pearce</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>The construction of autobiographical memories in the self-memory system</article-title><source>Psychological Review</source><volume>107</volume><fpage>261</fpage><lpage>288</lpage><pub-id pub-id-type="doi">10.1037/0033-295x.107.2.261</pub-id><pub-id pub-id-type="pmid">10789197</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>RW</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>AFNI: software for analysis and visualization of functional magnetic resonance neuroimages</article-title><source>Computers and Biomedical Research, an International Journal</source><volume>29</volume><fpage>162</fpage><lpage>173</lpage><pub-id pub-id-type="doi">10.1006/cbmr.1996.0014</pub-id><pub-id pub-id-type="pmid">8812068</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dongaonkar</surname><given-names>B</given-names></name><name><surname>Hupbach</surname><given-names>A</given-names></name><name><surname>Gomez</surname><given-names>R</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Effects of psychosocial stress on episodic memory updating</article-title><source>Psychopharmacology</source><volume>226</volume><fpage>769</fpage><lpage>779</lpage><pub-id pub-id-type="doi">10.1007/s00213-013-2998-8</pub-id><pub-id pub-id-type="pmid">23404063</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Esteban</surname><given-names>O</given-names></name><name><surname>Markiewicz</surname><given-names>CJ</given-names></name><name><surname>Blair</surname><given-names>RW</given-names></name><name><surname>Moodie</surname><given-names>CA</given-names></name><name><surname>Isik</surname><given-names>AI</given-names></name><name><surname>Erramuzpe</surname><given-names>A</given-names></name><name><surname>Kent</surname><given-names>JD</given-names></name><name><surname>Goncalves</surname><given-names>M</given-names></name><name><surname>DuPre</surname><given-names>E</given-names></name><name><surname>Snyder</surname><given-names>M</given-names></name><name><surname>Oya</surname><given-names>H</given-names></name><name><surname>Ghosh</surname><given-names>SS</given-names></name><name><surname>Wright</surname><given-names>J</given-names></name><name><surname>Durnez</surname><given-names>J</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name><name><surname>Gorgolewski</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>FMRIPrep: a robust preprocessing pipeline for functional MRI</article-title><source>Nature Methods</source><volume>16</volume><fpage>111</fpage><lpage>116</lpage><pub-id pub-id-type="doi">10.1038/s41592-018-0235-4</pub-id><pub-id pub-id-type="pmid">30532080</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Favila</surname><given-names>SE</given-names></name><name><surname>Lee</surname><given-names>H</given-names></name><name><surname>Kuhl</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Transforming the concept of memory reactivation</article-title><source>Trends in Neurosciences</source><volume>43</volume><fpage>939</fpage><lpage>950</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2020.09.006</pub-id><pub-id pub-id-type="pmid">33041061</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feng</surname><given-names>P</given-names></name><name><surname>Zheng</surname><given-names>Y</given-names></name><name><surname>Feng</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Resting-state functional connectivity between amygdala and the ventromedial prefrontal cortex following fear reminder predicts fear extinction</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>11</volume><fpage>991</fpage><lpage>1001</lpage><pub-id pub-id-type="doi">10.1093/scan/nsw031</pub-id><pub-id pub-id-type="pmid">27013104</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fisher</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="1915">1915</year><article-title>Frequency distribution of the values of the correlation coefficient in samples from an indefinitely large population</article-title><source>Biometrika</source><volume>10</volume><elocation-id>507</elocation-id><pub-id pub-id-type="doi">10.2307/2331838</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fonov</surname><given-names>V</given-names></name><name><surname>Evans</surname><given-names>A</given-names></name><name><surname>McKinstry</surname><given-names>R</given-names></name><name><surname>Almli</surname><given-names>C</given-names></name><name><surname>Collins</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Unbiased nonlinear average age-appropriate brain templates from birth to adulthood</article-title><source>NeuroImage</source><volume>47</volume><elocation-id>S102</elocation-id><pub-id pub-id-type="doi">10.1016/S1053-8119(09)70884-5</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frith</surname><given-names>CD</given-names></name><name><surname>Frith</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The neural basis of mentalizing</article-title><source>Neuron</source><volume>50</volume><fpage>531</fpage><lpage>534</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.05.001</pub-id><pub-id pub-id-type="pmid">16701204</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilboa</surname><given-names>A</given-names></name><name><surname>Marlatte</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neurobiology of schemas and schema-mediated memory</article-title><source>Trends in Cognitive Sciences</source><volume>21</volume><fpage>618</fpage><lpage>631</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.04.013</pub-id><pub-id pub-id-type="pmid">28551107</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorgolewski</surname><given-names>K</given-names></name><name><surname>Burns</surname><given-names>CD</given-names></name><name><surname>Madison</surname><given-names>C</given-names></name><name><surname>Clark</surname><given-names>D</given-names></name><name><surname>Halchenko</surname><given-names>YO</given-names></name><name><surname>Waskom</surname><given-names>ML</given-names></name><name><surname>Ghosh</surname><given-names>SS</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in python</article-title><source>Frontiers in Neuroinformatics</source><volume>5</volume><elocation-id>13</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2011.00013</pub-id><pub-id pub-id-type="pmid">21897815</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greve</surname><given-names>DN</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Accurate and robust brain image alignment using boundary-based registration</article-title><source>NeuroImage</source><volume>48</volume><fpage>63</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.06.060</pub-id><pub-id pub-id-type="pmid">19573611</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guterstam</surname><given-names>A</given-names></name><name><surname>Bio</surname><given-names>BJ</given-names></name><name><surname>Wilterson</surname><given-names>AI</given-names></name><name><surname>Graziano</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Temporo-parietal cortex involved in modeling one’s own and others’ attention</article-title><source>eLife</source><volume>10</volume><elocation-id>e63551</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.63551</pub-id><pub-id pub-id-type="pmid">33587038</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Deconstructing episodic memory with construction</article-title><source>Trends in Cognitive Sciences</source><volume>11</volume><fpage>299</fpage><lpage>306</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2007.05.001</pub-id><pub-id pub-id-type="pmid">17548229</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Maguire</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The construction system of the brain</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>364</volume><fpage>1263</fpage><lpage>1271</lpage><pub-id pub-id-type="doi">10.1098/rstb.2008.0296</pub-id><pub-id pub-id-type="pmid">19528007</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Yang</surname><given-names>E</given-names></name><name><surname>Vallines</surname><given-names>I</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name><name><surname>Rubin</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>A hierarchy of temporal receptive windows in human cortex</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>2539</fpage><lpage>2550</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5487-07.2008</pub-id><pub-id pub-id-type="pmid">18322098</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Hierarchical process memory: memory as an integral component of information processing</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>304</fpage><lpage>313</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.04.006</pub-id><pub-id pub-id-type="pmid">25980649</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haxby</surname><given-names>JV</given-names></name><name><surname>Guntupalli</surname><given-names>JS</given-names></name><name><surname>Nastase</surname><given-names>SA</given-names></name><name><surname>Feilong</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Hyperalignment: modeling shared information encoded in idiosyncratic cortical topographies</article-title><source>eLife</source><volume>9</volume><elocation-id>e56601</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.56601</pub-id><pub-id pub-id-type="pmid">32484439</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hupbach</surname><given-names>A</given-names></name><name><surname>Gomez</surname><given-names>R</given-names></name><name><surname>Hardt</surname><given-names>O</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Reconsolidation of episodic memories: a subtle reminder triggers integration of new information</article-title><source>Learning &amp; Memory</source><volume>14</volume><fpage>47</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1101/lm.365707</pub-id><pub-id pub-id-type="pmid">17202429</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hupbach</surname><given-names>A</given-names></name><name><surname>Gomez</surname><given-names>R</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2015">2015</year><chapter-title>Memory reconsolidation</chapter-title><person-group person-group-type="editor"><name><surname>Hupbach</surname><given-names>A</given-names></name></person-group><source>The Wiley Handbook on the Cognitive Neuroscience of Memory</source><publisher-name>John Wiley &amp; Sons, Ltd</publisher-name><fpage>244</fpage><lpage>264</lpage><pub-id pub-id-type="doi">10.1002/9781118332634.ch12</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Bannister</surname><given-names>P</given-names></name><name><surname>Brady</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Improved optimization for the robust and accurate linear registration and motion correction of brain images</article-title><source>NeuroImage</source><volume>17</volume><fpage>825</fpage><lpage>841</lpage><pub-id pub-id-type="doi">10.1016/s1053-8119(02)91132-8</pub-id><pub-id pub-id-type="pmid">12377157</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaefer</surname><given-names>K</given-names></name><name><surname>Stella</surname><given-names>F</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Battaglia</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Replay, the default mode network and the cascaded memory systems model</article-title><source>Nature Reviews. Neuroscience</source><volume>23</volume><fpage>628</fpage><lpage>640</lpage><pub-id pub-id-type="doi">10.1038/s41583-022-00620-6</pub-id><pub-id pub-id-type="pmid">35970912</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koster-Hale</surname><given-names>J</given-names></name><name><surname>Saxe</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Theory of mind: A neural prediction problem</article-title><source>Neuron</source><volume>79</volume><fpage>836</fpage><lpage>848</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.08.020</pub-id><pub-id pub-id-type="pmid">24012000</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuhl</surname><given-names>BA</given-names></name><name><surname>Bainbridge</surname><given-names>WA</given-names></name><name><surname>Chun</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural reactivation reveals mechanisms for updating memory</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>3453</fpage><lpage>3461</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5846-11.2012</pub-id><pub-id pub-id-type="pmid">22399768</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>JLC</given-names></name><name><surname>Nader</surname><given-names>K</given-names></name><name><surname>Schiller</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>An update on memory reconsolidation updating</article-title><source>Trends in Cognitive Sciences</source><volume>21</volume><fpage>531</fpage><lpage>545</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.04.006</pub-id><pub-id pub-id-type="pmid">28495311</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lerner</surname><given-names>Y</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name><name><surname>Silbert</surname><given-names>LJ</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Topographic mapping of a hierarchy of temporal receptive windows using a narrated story</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>2906</fpage><lpage>2915</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3684-10.2011</pub-id><pub-id pub-id-type="pmid">21414912</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Momennejad</surname><given-names>I</given-names></name><name><surname>Otto</surname><given-names>AR</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Offline replay supports planning in human reinforcement learning</article-title><source>eLife</source><volume>7</volume><elocation-id>e32548</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.32548</pub-id><pub-id pub-id-type="pmid">30547886</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mumford</surname><given-names>JA</given-names></name><name><surname>Turner</surname><given-names>BO</given-names></name><name><surname>Ashby</surname><given-names>FG</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Deconvolving BOLD activation in event-related designs for multivoxel pattern classification analyses</article-title><source>NeuroImage</source><volume>59</volume><fpage>2636</fpage><lpage>2643</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.08.076</pub-id><pub-id pub-id-type="pmid">21924359</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Musz</surname><given-names>E</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Neural signatures associated with temporal compression in the verbal retelling of past events</article-title><source>Communications Biology</source><volume>5</volume><elocation-id>489</elocation-id><pub-id pub-id-type="doi">10.1038/s42003-022-03418-5</pub-id><pub-id pub-id-type="pmid">35606497</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nader</surname><given-names>K</given-names></name><name><surname>Einarsson</surname><given-names>EO</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Memory reconsolidation: an update</article-title><source>Annals of the New York Academy of Sciences</source><volume>1191</volume><fpage>27</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1111/j.1749-6632.2010.05443.x</pub-id><pub-id pub-id-type="pmid">20392274</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nastase</surname><given-names>SA</given-names></name><name><surname>Gazzola</surname><given-names>V</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Keysers</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Measuring shared responses across subjects using intersubject correlation</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>14</volume><fpage>667</fpage><lpage>685</lpage><pub-id pub-id-type="doi">10.1093/scan/nsz037</pub-id><pub-id pub-id-type="pmid">31099394</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nastase</surname><given-names>SA</given-names></name><name><surname>Goldstein</surname><given-names>A</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Keep it real: rethinking the primacy of experimental control in cognitive neuroscience</article-title><source>NeuroImage</source><volume>222</volume><elocation-id>117254</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117254</pub-id><pub-id pub-id-type="pmid">32800992</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oedekoven</surname><given-names>CSH</given-names></name><name><surname>Keidel</surname><given-names>JL</given-names></name><name><surname>Berens</surname><given-names>SC</given-names></name><name><surname>Bird</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Reinstatement of memory representations for lifelike events over the course of a week</article-title><source>Scientific Reports</source><volume>7</volume><elocation-id>14305</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-017-13938-4</pub-id><pub-id pub-id-type="pmid">29084981</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Phelps</surname><given-names>EA</given-names></name><name><surname>Hofmann</surname><given-names>SG</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Memory editing from science fiction to clinical practice</article-title><source>Nature</source><volume>572</volume><fpage>43</fpage><lpage>50</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1433-7</pub-id><pub-id pub-id-type="pmid">31367027</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Power</surname><given-names>JD</given-names></name><name><surname>Mitra</surname><given-names>A</given-names></name><name><surname>Laumann</surname><given-names>TO</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Schlaggar</surname><given-names>BL</given-names></name><name><surname>Petersen</surname><given-names>SE</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Methods to detect, characterize, and remove motion artifact in resting state fmri</article-title><source>NeuroImage</source><volume>84</volume><fpage>320</fpage><lpage>341</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.08.048</pub-id><pub-id pub-id-type="pmid">23994314</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Przybyslawski</surname><given-names>J</given-names></name><name><surname>Sara</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Reconsolidation of memory after its reactivation</article-title><source>Behavioural Brain Research</source><volume>84</volume><fpage>241</fpage><lpage>246</lpage><pub-id pub-id-type="doi">10.1016/s0166-4328(96)00153-2</pub-id><pub-id pub-id-type="pmid">9079788</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raichle</surname><given-names>ME</given-names></name><name><surname>MacLeod</surname><given-names>AM</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Powers</surname><given-names>WJ</given-names></name><name><surname>Gusnard</surname><given-names>DA</given-names></name><name><surname>Shulman</surname><given-names>GL</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A default mode of brain function</article-title><source>PNAS</source><volume>98</volume><fpage>676</fpage><lpage>682</lpage><pub-id pub-id-type="doi">10.1073/pnas.98.2.676</pub-id><pub-id pub-id-type="pmid">11209064</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ranganath</surname><given-names>C</given-names></name><name><surname>Ritchey</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Two cortical systems for memory-guided behaviour</article-title><source>Nature Reviews. Neuroscience</source><volume>13</volume><fpage>713</fpage><lpage>726</lpage><pub-id pub-id-type="doi">10.1038/nrn3338</pub-id><pub-id pub-id-type="pmid">22992647</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritchey</surname><given-names>M</given-names></name><name><surname>Cooper</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Deconstructing the posterior medial episodic network</article-title><source>Trends in Cognitive Sciences</source><volume>24</volume><fpage>451</fpage><lpage>465</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2020.03.006</pub-id><pub-id pub-id-type="pmid">32340798</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritvo</surname><given-names>VJH</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Nonmonotonic plasticity: how memory retrieval drives learning</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>726</fpage><lpage>742</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.06.007</pub-id><pub-id pub-id-type="pmid">31358438</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robin</surname><given-names>J</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Details, GIST and schema: hippocampal–neocortical interactions underlying recent and remote episodic and spatial memory</article-title><source>Current Opinion in Behavioral Sciences</source><volume>17</volume><fpage>114</fpage><lpage>123</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2017.07.016</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rugg</surname><given-names>MD</given-names></name><name><surname>Vilberg</surname><given-names>KL</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Brain networks underlying episodic memory retrieval</article-title><source>Current Opinion in Neurobiology</source><volume>23</volume><fpage>255</fpage><lpage>260</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2012.11.005</pub-id><pub-id pub-id-type="pmid">23206590</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samide</surname><given-names>R</given-names></name><name><surname>Ritchey</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Reframing the past: role of memory processes in emotion regulation</article-title><source>Cognitive Therapy and Research</source><volume>45</volume><fpage>848</fpage><lpage>857</lpage><pub-id pub-id-type="doi">10.1007/s10608-020-10166-5</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saxe</surname><given-names>R</given-names></name><name><surname>Kanwisher</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>People thinking about thinking people. The role of the temporo-parietal junction in “theory of mind”</article-title><source>NeuroImage</source><volume>19</volume><fpage>1835</fpage><lpage>1842</lpage><pub-id pub-id-type="doi">10.1016/s1053-8119(03)00230-1</pub-id><pub-id pub-id-type="pmid">12948738</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schacter</surname><given-names>DL</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Koutstaal</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>The cognitive neuroscience of constructive memory</article-title><source>Annual Review of Psychology</source><volume>49</volume><fpage>289</fpage><lpage>318</lpage><pub-id pub-id-type="doi">10.1146/annurev.psych.49.1.289</pub-id><pub-id pub-id-type="pmid">9496626</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schacter</surname><given-names>DL</given-names></name><name><surname>Addis</surname><given-names>DR</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The cognitive neuroscience of constructive memory: remembering the past and imagining the future</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>362</volume><fpage>773</fpage><lpage>786</lpage><pub-id pub-id-type="doi">10.1098/rstb.2007.2087</pub-id><pub-id pub-id-type="pmid">17395575</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schacter</surname><given-names>DL</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Constructive memory: past and future</article-title><source>Dialogues in Clinical Neuroscience</source><volume>14</volume><fpage>7</fpage><lpage>18</lpage><pub-id pub-id-type="doi">10.31887/DCNS.2012.14.1/dschacter</pub-id><pub-id pub-id-type="pmid">22577300</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaefer</surname><given-names>A</given-names></name><name><surname>Kong</surname><given-names>R</given-names></name><name><surname>Gordon</surname><given-names>EM</given-names></name><name><surname>Laumann</surname><given-names>TO</given-names></name><name><surname>Zuo</surname><given-names>XN</given-names></name><name><surname>Holmes</surname><given-names>AJ</given-names></name><name><surname>Eickhoff</surname><given-names>SB</given-names></name><name><surname>Yeo</surname><given-names>BTT</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Local-global parcellation of the human cerebral cortex from intrinsic functional connectivity MRI</article-title><source>Cerebral Cortex</source><volume>28</volume><fpage>3095</fpage><lpage>3114</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhx179</pub-id><pub-id pub-id-type="pmid">28981612</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schiller</surname><given-names>D</given-names></name><name><surname>Kanen</surname><given-names>JW</given-names></name><name><surname>LeDoux</surname><given-names>JE</given-names></name><name><surname>Monfils</surname><given-names>MH</given-names></name><name><surname>Phelps</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Extinction during reconsolidation of threat memory diminishes prefrontal cortex involvement</article-title><source>PNAS</source><volume>110</volume><fpage>20040</fpage><lpage>20045</lpage><pub-id pub-id-type="doi">10.1073/pnas.1320322110</pub-id><pub-id pub-id-type="pmid">24277809</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Schlichting</surname><given-names>ML</given-names></name><name><surname>Preston</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2017">2017</year><chapter-title>The hippocampus and memory integration: building knowledge to navigate future decisions</chapter-title><person-group person-group-type="editor"><name><surname>Hannula</surname><given-names>DE</given-names></name><name><surname>Duff</surname><given-names>MC</given-names></name></person-group><source>The Hippocampus from Cells to Systems: Structure, Connectivity, and Functional Contributions to Memory and Flexible Cognition</source><publisher-name>Springer International Publishing</publisher-name><fpage>405</fpage><lpage>437</lpage><pub-id pub-id-type="doi">10.1007/978-3-319-50406-3_13</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scully</surname><given-names>ID</given-names></name><name><surname>Napper</surname><given-names>LE</given-names></name><name><surname>Hupbach</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Does reactivation trigger episodic memory change? A meta-analysis</article-title><source>Neurobiology of Learning and Memory</source><volume>142</volume><fpage>99</fpage><lpage>107</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2016.12.012</pub-id><pub-id pub-id-type="pmid">28025069</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sinclair</surname><given-names>AH</given-names></name><name><surname>Barense</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Prediction error and memory reactivation: how incomplete reminders drive reconsolidation</article-title><source>Trends in Neurosciences</source><volume>42</volume><fpage>727</fpage><lpage>739</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2019.08.007</pub-id><pub-id pub-id-type="pmid">31506189</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spreng</surname><given-names>RN</given-names></name><name><surname>Mar</surname><given-names>RA</given-names></name><name><surname>Kim</surname><given-names>ASN</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The common neural basis of autobiographical memory, prospection, navigation, theory of mind, and the default mode: a quantitative meta-analysis</article-title><source>Journal of Cognitive Neuroscience</source><volume>21</volume><fpage>489</fpage><lpage>510</lpage><pub-id pub-id-type="doi">10.1162/jocn.2008.21029</pub-id><pub-id pub-id-type="pmid">18510452</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stephens</surname><given-names>GJ</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A place for time: the spatiotemporal structure of neural dynamics during natural audition</article-title><source>Journal of Neurophysiology</source><volume>110</volume><fpage>2019</fpage><lpage>2026</lpage><pub-id pub-id-type="doi">10.1152/jn.00268.2013</pub-id><pub-id pub-id-type="pmid">23926041</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Svoboda</surname><given-names>E</given-names></name><name><surname>McKinnon</surname><given-names>MC</given-names></name><name><surname>Levine</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The functional neuroanatomy of autobiographical memory: a meta-analysis</article-title><source>Neuropsychologia</source><volume>44</volume><fpage>2189</fpage><lpage>2208</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2006.05.023</pub-id><pub-id pub-id-type="pmid">16806314</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szpunar</surname><given-names>KK</given-names></name><name><surname>Watson</surname><given-names>JM</given-names></name><name><surname>McDermott</surname><given-names>KB</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Neural substrates of envisioning the future</article-title><source>PNAS</source><volume>104</volume><fpage>642</fpage><lpage>647</lpage><pub-id pub-id-type="doi">10.1073/pnas.0610082104</pub-id><pub-id pub-id-type="pmid">17202254</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tompary</surname><given-names>A</given-names></name><name><surname>Davachi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Consolidation promotes the emergence of representational overlap in the hippocampus and medial prefrontal cortex</article-title><source>Neuron</source><volume>96</volume><fpage>228</fpage><lpage>241</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.09.005</pub-id><pub-id pub-id-type="pmid">28957671</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treiber</surname><given-names>JM</given-names></name><name><surname>White</surname><given-names>NS</given-names></name><name><surname>Steed</surname><given-names>TC</given-names></name><name><surname>Bartsch</surname><given-names>H</given-names></name><name><surname>Holland</surname><given-names>D</given-names></name><name><surname>Farid</surname><given-names>N</given-names></name><name><surname>McDonald</surname><given-names>CR</given-names></name><name><surname>Carter</surname><given-names>BS</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Chen</surname><given-names>CC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Characterization and correction of geometric distortions in 814 diffusion weighted images</article-title><source>PLOS ONE</source><volume>11</volume><elocation-id>e0152472</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0152472</pub-id><pub-id pub-id-type="pmid">27027775</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tustison</surname><given-names>NJ</given-names></name><name><surname>Avants</surname><given-names>BB</given-names></name><name><surname>Cook</surname><given-names>PA</given-names></name><name><surname>Zheng</surname><given-names>Y</given-names></name><name><surname>Egan</surname><given-names>A</given-names></name><name><surname>Yushkevich</surname><given-names>PA</given-names></name><name><surname>Gee</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>N4ITK: improved N3 bias correction</article-title><source>IEEE Transactions on Medical Imaging</source><volume>29</volume><fpage>1310</fpage><lpage>1320</lpage><pub-id pub-id-type="doi">10.1109/TMI.2010.2046908</pub-id><pub-id pub-id-type="pmid">20378467</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Kesteren</surname><given-names>MTR</given-names></name><name><surname>Rijpkema</surname><given-names>M</given-names></name><name><surname>Ruiter</surname><given-names>DJ</given-names></name><name><surname>Fernandez</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Retrieval of associative information congruent with prior knowledge is related to increased medial prefrontal activity and connectivity</article-title><source>Journal of Neuroscience</source><volume>30</volume><fpage>15888</fpage><lpage>15894</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2674-10.2010</pub-id><pub-id pub-id-type="pmid">21106827</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Kesteren</surname><given-names>MTR</given-names></name><name><surname>Ruiter</surname><given-names>DJ</given-names></name><name><surname>Fernández</surname><given-names>G</given-names></name><name><surname>Henson</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>How schema and novelty augment memory formation</article-title><source>Trends in Neurosciences</source><volume>35</volume><fpage>211</fpage><lpage>219</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2012.02.001</pub-id><pub-id pub-id-type="pmid">22398180</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Peterson</surname><given-names>DJ</given-names></name><name><surname>Gatenby</surname><given-names>JC</given-names></name><name><surname>Li</surname><given-names>W</given-names></name><name><surname>Grabowski</surname><given-names>TJ</given-names></name><name><surname>Madhyastha</surname><given-names>TM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Evaluation of field map and nonlinear registration methods for correction of susceptibility artifacts in diffusion MRI</article-title><source>Frontiers in Neuroinformatics</source><volume>11</volume><elocation-id>17</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2017.00017</pub-id><pub-id pub-id-type="pmid">28270762</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yeshurun</surname><given-names>Y</given-names></name><name><surname>Swanson</surname><given-names>S</given-names></name><name><surname>Simony</surname><given-names>E</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Lazaridi</surname><given-names>C</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Same story, different story: the neural representation of interpretive frameworks</article-title><source>Psychological Science</source><volume>28</volume><fpage>307</fpage><lpage>319</lpage><pub-id pub-id-type="doi">10.1177/0956797616682029</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yeshurun</surname><given-names>Y</given-names></name><name><surname>Nguyen</surname><given-names>M</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The default mode network: where the idiosyncratic self meets the shared social world</article-title><source>Nature Reviews. Neuroscience</source><volume>22</volume><fpage>181</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1038/s41583-020-00420-w</pub-id><pub-id pub-id-type="pmid">33483717</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zadbood</surname><given-names>A</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Leong</surname><given-names>YC</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>How we transmit memories to other brains: constructing shared neural representations via communication</article-title><source>Cerebral Cortex</source><volume>27</volume><fpage>4988</fpage><lpage>5000</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhx202</pub-id><pub-id pub-id-type="pmid">28922834</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>The relationship between the behavioral (twist score) and neural (recall ‘twist’ to movie ‘spoiled’&gt;recall ‘twist’ to movie ‘twist’) measures of memory update in each DMN ROI.</title><p>The panel on the right depicts the correlation in the precuneus. Each dot is a participant in the ‘twist’ group (N=19). Note that the example at right was selected post-hoc for high correlation and is not significant after correction for multiple tests.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79045-app1-fig1-v2.tif"/></fig><fig id="app1fig2" position="float"><label>Appendix 1—figure 2.</label><caption><title>Depiction of pattern similarity differences calculated in the main analyses (<xref ref-type="fig" rid="fig2">Figures 2</xref>–<xref ref-type="fig" rid="fig3">3</xref>) in three resting state networks.</title><p>Blue graphs depict the results in the default mode network. Light red represents the visual network, and yellow shows the somatosensory network. Each dot on the violin graphs shows the effect size in one of the regions on interest in the corresponding network. White dots depict median values. Significance levels have been calculated for each ROI separately (the same as the main analysis). Bold dots depict ROIs with p&lt;0.01 (uncorrected). Labels on x axis: D subscript denotes <italic>Doctor</italic> interpretation and G subscript denotes <italic>Ghost</italic> interpretation. M<sub>D</sub>–M<sub>D</sub> &gt;M<sub>D</sub>–M<sub>G</sub> denotes greater pISC when comparing naive encoding in ‘twist’ group (M<sub>D</sub>) to naive encoding in ‘no-twist’ group (M<sub>D</sub>) than when comparing naive encoding in ‘twist’ group (M<sub>D</sub>) to spoiled encoding in ‘spoiled’ group (M<sub>G</sub>) (similar comparison as in <xref ref-type="fig" rid="fig2">Figure 2A</xref> and <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3A</xref>). R<sub>G</sub>–R<sub>G</sub> &gt;R<sub>G</sub>–R<sub>D</sub> denotes greater pISC when comparing recall in ‘twist’ group (R<sub>G</sub>) to recall in ‘spoiled’ group (R<sub>G</sub>) than when comparing recall in ‘twist’ group (R<sub>G</sub>) to naive recall in ‘no-twist’ group (R<sub>D</sub>) (similar comparison as in <xref ref-type="fig" rid="fig2">Figure 2B</xref> and <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3B</xref>). Interaction corresponds to the same analysis in <xref ref-type="fig" rid="fig2">Figure 2C</xref> and Figure <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3C</xref>. R<sub>G</sub>–M<sub>G</sub> &gt;R<sub>D</sub>–M<sub>G</sub> denotes greater pISC when comparing updated recall in ‘twist’ group (R<sub>G</sub>) to spoiled encoding in ‘spoiled’ group (M<sub>G</sub>) than when comparing naive recalls in ‘no-twist’ group (R<sub>D</sub>) to spoiled encoding in ‘spoiled’ group (M<sub>G</sub>) (similar comparison as in <xref ref-type="fig" rid="fig3">Figure 3A</xref> and <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3D</xref>). R<sub>G</sub>–M<sub>G</sub> &gt;R<sub>G</sub>–M<sub>D</sub> denotes greater pISC when comparing updated recall in ‘twist’ group (R<sub>G</sub>) and spoiled encoding in <italic>spoiled</italic> group (M<sub>G</sub>) than when comparing updated recall in ‘twist’ group (R<sub>G</sub>) and naive encoding in ‘twist’ group (M<sub>D</sub>) (similar comparison as in <xref ref-type="fig" rid="fig3">Figure 3B</xref> and <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3E</xref>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79045-app1-fig2-v2.tif"/></fig><fig id="app1fig3" position="float"><label>Appendix 1—figure 3.</label><caption><title>Depiction of the same set of results as in <xref ref-type="fig" rid="fig2">Figure 2</xref> (upper row) and <xref ref-type="fig" rid="fig3">Figure 3</xref> (lower row) in the whole brain (not restricted to DMN).</title><p>The maps show ROIs with p&lt;0.01 calculated by nonparametric randomization test without correction (areas missing on these maps compared to the original maps had p values greater than 0.01). (<bold>A</bold>) Areas with significantly greater intersubject pattern correlation between groups who encoded the movie with the same interpretation (<italic>Doctor</italic>). (<bold>B</bold>) Areas with significantly greater intersubject pattern correlation between groups who recalled the movie with the same interpretation (<italic>Ghost</italic>). (<bold>C</bold>) Areas with a significant interaction effect, indicating a change in interpretation between encoding and recall (see ‘Pattern similarity analysis’ in Methods). (<bold>D</bold>) Areas where intersubject pattern correlations are significantly greater when comparing updated recall (R<sub>G</sub>) to spoiled encoding (M<sub>G</sub>) than when comparing naive recalls (R<sub>D</sub>) to spoiled encoding (M<sub>G</sub>). (<bold>E</bold>) Areas where intersubject pattern correlations between updated recall (R<sub>G</sub>) and spoiled encoding (M<sub>G</sub>) are greater than between updated recall (R<sub>G</sub>) and naive encoding (M<sub>D</sub>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79045-app1-fig3-v2.tif"/></fig><fig id="app1fig4" position="float"><label>Appendix 1—figure 4.</label><caption><title>Relationship across scenes between our behavioral measure of memory updating (twist score) and neural measures of memory updating (pISC difference).</title><p>(<bold>A</bold>) shows the results when we operationalize memory updating based on the difference between pISC for recall ‘twist’ to recall ‘spoiled’ and pISC for recall ‘twist’ to recall ‘no-twist’. Correlation values for each DMN region are shown as colors on the map. Red shade indicates higher correlation. Circled areas highlight the regions that showed significant effects in the main recall-recall analysis across subjects (<xref ref-type="fig" rid="fig2">Figure 2B</xref>), where pISC for recall ‘twist’ to recall ‘spoiled’ was greater than pISC for recall ‘twist’ to recall ‘no-twist’. The area with the highest correlation among these areas (which is the highest correlation in the entire map as well) is highlighted with a black continuous-line circle. The scatter plot on the left depicts the correlation in this area. ‘Critical scenes’ that were used in the main analyses (<xref ref-type="fig" rid="fig2">Figures 2</xref>–<xref ref-type="fig" rid="fig3">3</xref>) are shown in blue on the scatter plot. The rest of the scenes are shown in red. Correlation was calculated across all 18 scenes. (<bold>B</bold>) shows the results when we operationalize memory updating based on the difference between pISC for recall ‘twist’ to movie ‘spoiled’ and pISC for recall ‘twist’ to movie ‘twist’. Circled areas highlight the regions that showed significant effects in the encoding-recall analysis across subjects (<xref ref-type="fig" rid="fig3">Figure 3B</xref>), where pISC for recall ‘twist’ to movie ‘spoiled’ was greater than pISC for recall ‘twist’ to movie ‘twist’. The area with the highest correlation among these areas (which is the highest correlation in the entire map as well) is highlighted with a black continuous-line circle. The scatter plot on the left depicts the correlation in this area. ‘Critical scenes’ that were used in the main analyses (<xref ref-type="fig" rid="fig2">Figures 2</xref>–<xref ref-type="fig" rid="fig3">3</xref>) are shown in blue on the scatter plot. The rest of the scenes are shown in red. Correlation was calculated across all 18 scenes.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-79045-app1-fig4-v2.tif"/></fig><table-wrap id="app1table1" position="float"><label>Appendix 1—table 1.</label><caption><title>The output of condition x group ANOVA in each ROI (each row).</title><p>‘Condition’ columns showthe average of the univariate response in each ROI for a given condition. Statistics corresponding to eacheffect are shown in the five right columns. p Values marked as significant (*) did not pass correction formultiple comparison.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom" rowspan="2"/><th align="left" valign="bottom"><italic>condition:</italic></th><th align="left" valign="bottom" colspan="2">movie</th><th align="left" valign="bottom"><italic>condition:</italic></th><th align="left" valign="bottom">recall</th><th align="left" valign="bottom" rowspan="2">no-twist</th><th align="left" valign="bottom" rowspan="2">DFn</th><th align="left" valign="bottom" rowspan="2">DFd</th><th align="left" valign="bottom" rowspan="2">F</th><th align="left" valign="bottom" rowspan="2">p</th><th align="left" valign="bottom" rowspan="2">effect</th></tr><tr><th align="left" valign="bottom">spoiled</th><th align="left" valign="bottom">twist</th><th align="left" valign="bottom">no-twist</th><th align="left" valign="bottom">spoiled</th><th align="left" valign="bottom">twist</th></tr></thead><tbody><tr><td align="left" valign="bottom"><bold>LH_Default_Temp_1</bold></td><td align="char" char="." valign="bottom">–0.02</td><td align="char" char="." valign="bottom">–0.025</td><td align="char" char="." valign="bottom">–0.038</td><td align="char" char="." valign="bottom">0.188</td><td align="char" char="." valign="bottom">0.106</td><td align="char" char="." valign="bottom">0.117</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">1.237</td><td align="char" char="." valign="bottom">0.298</td><td align="left" valign="bottom"><italic>group</italic></td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">0.628</td><td align="char" char="." valign="bottom">0.537</td><td align="left" valign="bottom"><italic>group x condition</italic></td></tr><tr><td align="left" valign="bottom"><bold>LH_Default_Temp_4</bold></td><td align="char" char="." valign="bottom">–0.002</td><td align="char" char="." valign="bottom">–0.033</td><td align="char" char="." valign="bottom">–0.024</td><td align="char" char="." valign="bottom">0.131</td><td align="char" char="." valign="bottom">0.148</td><td align="char" char="." valign="bottom">–0.034</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">3.649</td><td align="char" char="." valign="bottom">0.033 *</td><td align="left" valign="bottom"><italic>group</italic></td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">3.279</td><td align="char" char="." valign="bottom">0.045 *</td><td align="left" valign="bottom"><italic>group x condition</italic></td></tr><tr><td align="left" valign="bottom"><bold>LH_Default_PFC_1</bold></td><td align="char" char="." valign="bottom">–0.005</td><td align="char" char="." valign="bottom">–0.005</td><td align="char" char="." valign="bottom">–0.024</td><td align="char" char="." valign="bottom">0.106</td><td align="char" char="." valign="bottom">0.067</td><td align="char" char="." valign="bottom">0.054</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">0.434</td><td align="char" char="." valign="bottom">0.65</td><td align="left" valign="bottom"><italic>group</italic></td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">0.125</td><td align="char" char="." valign="bottom">0.883</td><td align="left" valign="bottom"><italic>group x condition</italic></td></tr><tr><td align="left" valign="bottom"><bold>LH_Default_PFC_2</bold></td><td align="char" char="." valign="bottom">–0.027</td><td align="char" char="." valign="bottom">–0.043</td><td align="char" char="." valign="bottom">–0.053</td><td align="char" char="." valign="bottom">0.088</td><td align="char" char="." valign="bottom">0.006</td><td align="char" char="." valign="bottom">0.006</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">1.432</td><td align="char" char="." valign="bottom">0.248</td><td align="left" valign="bottom"><italic>group</italic></td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">0.526</td><td align="char" char="." valign="bottom">0.594</td><td align="left" valign="bottom"><italic>group x condition</italic></td></tr><tr><td align="left" valign="bottom"><bold>LH_Default_PFC_3</bold></td><td align="char" char="." valign="bottom">0.002</td><td align="char" char="." valign="bottom">–0.005</td><td align="char" char="." valign="bottom">–0.014</td><td align="char" char="." valign="bottom">0.088</td><td align="char" char="." valign="bottom">0.116</td><td align="char" char="." valign="bottom">0.055</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">0.5</td><td align="char" char="." valign="bottom">0.609</td><td align="left" valign="bottom"><italic>group</italic></td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">0.237</td><td align="char" char="." valign="bottom">0.789</td><td align="left" valign="bottom"><italic>group x condition</italic></td></tr><tr><td align="left" valign="bottom"><bold>LH_Default_PFC_4</bold></td><td align="char" char="." valign="bottom">0.002</td><td align="char" char="." valign="bottom">–0.02</td><td align="char" char="." valign="bottom">–0.02</td><td align="char" char="." valign="bottom">0.031</td><td align="char" char="." valign="bottom">0.034</td><td align="char" char="." valign="bottom">–0.008</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">0.611</td><td align="char" char="." valign="bottom">0.546</td><td align="left" valign="bottom"><italic>group</italic></td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">0.281</td><td align="char" char="." valign="bottom">0.755</td><td align="left" valign="bottom"><italic>group x condition</italic></td></tr><tr><td align="left" valign="bottom"><bold>LH_Default_PFC_5</bold></td><td align="char" char="." valign="bottom">–0.011</td><td align="char" char="." valign="bottom">–0.03</td><td align="char" char="." valign="bottom">–0.033</td><td align="char" char="." valign="bottom">0.138</td><td align="char" char="." valign="bottom">0.09</td><td align="char" char="." valign="bottom">0.056</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">0.97</td><td align="char" char="." valign="bottom">0.385</td><td align="left" valign="bottom"><italic>group</italic></td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">0.318</td><td align="char" char="." valign="bottom">0.728</td><td align="left" valign="bottom"><italic>group x condition</italic></td></tr><tr><td align="left" valign="bottom"><bold>LH_Default_PCC_1</bold></td><td align="char" char="." valign="bottom">0.018</td><td align="char" char="." valign="bottom">0.015</td><td align="char" char="." valign="bottom">0.013</td><td align="char" char="." valign="bottom">0.21</td><td align="char" char="." valign="bottom">0.201</td><td align="char" char="." valign="bottom">0.153</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">0.381</td><td align="char" char="." valign="bottom">0.684</td><td align="left" valign="bottom"><italic>group</italic></td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">0.26</td><td align="char" char="." valign="bottom">0.771</td><td align="left" valign="bottom"><italic>group x condition</italic></td></tr><tr><td align="left" valign="bottom"><bold>LH_Default_PCC_2</bold></td><td align="char" char="." valign="bottom">0.008</td><td align="char" char="." valign="bottom">–0.017</td><td align="char" char="." valign="bottom">–0.005</td><td align="char" char="." valign="bottom">0.178</td><td align="char" char="." valign="bottom">0.163</td><td align="char" char="." valign="bottom">0.023</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">2.231</td><td align="char" char="." valign="bottom">0.117</td><td align="left" valign="bottom"><italic>group</italic></td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">2.013</td><td align="char" char="." valign="bottom">0.143</td><td align="left" valign="bottom"><italic>group x condition</italic></td></tr><tr><td align="left" valign="bottom"><bold>RH_Default_Par_1</bold></td><td align="char" char="." valign="bottom">0.037</td><td align="char" char="." valign="bottom">0.025</td><td align="char" char="." valign="bottom">0.013</td><td align="char" char="." valign="bottom">0.172</td><td align="char" char="." valign="bottom">0.252</td><td align="char" char="." valign="bottom">0.043</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">3.151</td><td align="left" valign="bottom">0.0507~</td><td align="left" valign="bottom"><italic>group</italic></td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">2.373</td><td align="char" char="." valign="bottom">0.102</td><td align="left" valign="bottom"><italic>group x condition</italic></td></tr><tr><td align="left" valign="bottom"><bold>RH_Default_Temp_1</bold></td><td align="char" char="." valign="bottom">–0.001</td><td align="char" char="." valign="bottom">–0.024</td><td align="char" char="." valign="bottom">–0.025</td><td align="char" char="." valign="bottom">0.135</td><td align="char" char="." valign="bottom">0.13</td><td align="char" char="." valign="bottom">0.078</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">0.76</td><td align="char" char="." valign="bottom">0.472</td><td align="left" valign="bottom"><italic>group</italic></td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">0.249</td><td align="char" char="." valign="bottom">0.78</td><td align="left" valign="bottom"><italic>group x condition</italic></td></tr><tr><td align="left" valign="bottom"><bold>RH_Default_Temp_3</bold></td><td align="char" char="." valign="bottom">–0.014</td><td align="char" char="." valign="bottom">–0.024</td><td align="char" char="." valign="bottom">–0.026</td><td align="char" char="." valign="bottom">0.242</td><td align="char" char="." valign="bottom">0.239</td><td align="char" char="." valign="bottom">0.188</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">0.374</td><td align="char" char="." valign="bottom">0.689</td><td align="left" valign="bottom"><italic>group</italic></td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">0.184</td><td align="char" char="." valign="bottom">0.831</td><td align="left" valign="bottom"><italic>group x condition</italic></td></tr><tr><td align="left" valign="bottom"><bold>RH_Default_PFCm_1</bold></td><td align="char" char="." valign="bottom">0.006</td><td align="char" char="." valign="bottom">0.003</td><td align="char" char="." valign="bottom">–0.005</td><td align="char" char="." valign="bottom">0.102</td><td align="char" char="." valign="bottom">0.126</td><td align="char" char="." valign="bottom">0.067</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">0.437</td><td align="char" char="." valign="bottom">0.648</td><td align="left" valign="bottom"><italic>group</italic></td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">0.214</td><td align="char" char="." valign="bottom">0.807</td><td align="left" valign="bottom"><italic>group x condition</italic></td></tr><tr><td align="left" valign="bottom"><bold>RH_Default_PFCm_2</bold></td><td align="char" char="." valign="bottom">0.009</td><td align="char" char="." valign="bottom">–0.004</td><td align="char" char="." valign="bottom">–0.014</td><td align="char" char="." valign="bottom">0.138</td><td align="char" char="." valign="bottom">0.12</td><td align="char" char="." valign="bottom">0.074</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">0.693</td><td align="char" char="." valign="bottom">0.504</td><td align="left" valign="bottom"><italic>group</italic></td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">0.169</td><td align="char" char="." valign="bottom">0.844</td><td align="left" valign="bottom"><italic>group x condition</italic></td></tr><tr><td align="left" valign="bottom"><bold>RH_Default_PCC_2</bold></td><td align="char" char="." valign="bottom">0.031</td><td align="char" char="." valign="bottom">0.005</td><td align="char" char="." valign="bottom">0.005</td><td align="char" char="." valign="bottom">0.219</td><td align="char" char="." valign="bottom">0.214</td><td align="char" char="." valign="bottom">0.073</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">2.41</td><td align="char" char="." valign="bottom">0.099</td><td align="left" valign="bottom"><italic>group</italic></td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">54</td><td align="char" char="." valign="bottom">1.579</td><td align="char" char="." valign="bottom">0.215</td><td align="left" valign="bottom"><italic>group x condition</italic></td></tr></tbody></table></table-wrap></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.79045.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Peelen</surname><given-names>Marius V</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/016xsfp80</institution-id><institution>Radboud University</institution></institution-wrap><country>Netherlands</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2021.09.28.462068" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2021.09.28.462068"/></front-stub><body><p>This study presents an important extension of recent work investigating the encoding and recall of narratives in the default mode network. The design is clever, allowing the authors to conduct multiple targeted analyses. The results are compelling and will be of interest to cognitive neuroscientists working on memory and naturalistic paradigms.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.79045.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Peelen</surname><given-names>Marius V</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/016xsfp80</institution-id><institution>Radboud University</institution></institution-wrap><country>Netherlands</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Reagh</surname><given-names>Zachariah M</given-names></name><role>Reviewer</role></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2021.09.28.462068">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.09.28.462068v2">the preprint</ext-link> for the benefit of readers; ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Here's the twist: How the brain updates the representations of naturalistic events as our understanding of the past changes&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Floris de Lange as the Senior Editor. The following individual involved in the review of your submission has agreed to reveal their identity: Zachariah M. Reagh (Reviewer #3).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1) Better introduce the method and specific hypotheses, including the focus on the DMN.</p><p>2) Include additional analyses to provide more insight into the processes/mechanisms leading to the observed results, such as whether these reflect overall (univariate) activity differences, are scene-specific, are specific to critical (vs non-critical) scenes, regional (DMN) specificity, etc. (see suggestions by R1 and R3)</p><p>3) Present results when including all 18 scenes (note that this also allows you to address some of the concerns listed under #2 above).</p><p>4) More in-depth discussion about the possible role(s) of DMN regions in memory updating, including the distinct roles of individual regions, taking into account the partly divergent results across analyses.</p><p><italic>Reviewer #1 (Public Review):</italic></p><p>This fMRI study investigated how memories are updated after reinterpreting past events. Participants watched a movie and subsequently recalled individual scenes from that movie. Importantly, the movie ends with a twist that changes the interpretation of earlier scenes in the movie. One group of participants watched the movie with the twist at the end, one group did not get to see the twist, and a third group was already informed about this twist before watching the movie. Analyses compared the similarity of activity patterns to (encoded or recalled) events across participants within regions of the default mode network (DMN). The design allowed for multiple relevant comparisons, confirming the prediction that activity patterns in DMN regions reflect the (re)interpretation of the movie (during movie viewing and/or during recall).</p><p>The study is well-designed and executed. The inclusion of multiple analyses involving distinct comparisons strengthens the evidence for the role of the DMN in memory updating.</p><p>The following points may be relevant to consider:</p><p>1. The cross-participant pattern analysis method used here is not standard, with such analyses typically done within participants (or across participants, but after aligning representational spaces). Considering individual variability in functional organization, the method is likely only sensitive to coarse-scale patterns (e.g., anterior vs posterior parts of an ROI). This is not necessarily a weakness but is relevant when interpreting the results.</p><p>2. Unlike previous work, analyses are not testing for scene-specific information. Rather, each scene is treated separately to establish between-group differences, and results are averaged across scenes. This raises the question of whether the patterns reflect scene-specific information or generic group differences. For example, knowing the twist may increase overall engagement, both when viewing the movie (spoiled group) and when recalling it (spoiled group + twist group). The DMN may be particularly sensitive to such differences in overall engagement.</p><p>3. The study does not reveal what the DMN represents about the movie, such that its activity changes after knowing the twist. The Discussion briefly mentions that it may reflect the state of the observer, related to the belief about the identity of the doctor. This suggests a link to the theory of mind/mentalizing, but this is not made explicit. Alternatively, the DMN may be involved in the conflict (or switching) between the two interpretations.</p><p>4. The design has many naturalistic aspects, but it is also different from real life in that the critical twist involves a ghost. Furthermore, all results are based on one movie with a specific plot twist. It is thus not clear whether similar results would be obtained with other and more naturalistic plot twists.</p><p>5. Only 7 scenes (out of 18) were included in the analysis. It is not clear if/how the results depend on the selection of these 7 scenes.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>1. The interpretation of the results critically relies on a good understanding of the method. Therefore, please introduce and explain the method more explicitly (either in the Introduction or the Results), making clear how it differs from related methods (including the temporal correlation method used in previous papers of this group) and what it may (and may not) be sensitive to. Also, please discuss the results in the context of what this method can reveal, i.e., what kind of representation can be revealed at this spatial scale.</p><p>2. This point could be addressed in additional analyses (e.g., by testing whether similar results are found when randomly pairing scenes in the analyses). Alternatively, this would be relevant to discuss and/or exclude in other ways.</p><p>3. Please include additional discussion about the putative role of the DMN in relation to the twist manipulation.</p><p>4. This could be discussed as a limitation of the study.</p><p>5. The scene selection procedure would need to be described in the Results section, following the behavioral results (as it was based on those results). It would be relevant to know how and when this was decided, particularly whether this was decided before or after analyses were conducted (and results inspected), and why 18 scenes were originally included. Also, the current scene selection appears somewhat arbitrary. For example, scene #1 was included because it showed a high twist score, but it is not clear what this twist score is or whether there were scenes with a similarly high twist score. Ideally, the authors would also present the results when including all 18 scenes (e.g., as Supplementary file).</p><p>Additional comments:</p><p>The Introduction does not sufficiently make clear why the DMN is the main focus of the study. Readers may be unfamiliar with the DMN, so it would be relevant to briefly introduce the DMN (e.g., which regions are part of it, how it is defined, what it does, etc.). This could then lead to a more focused motivation for why these regions were specifically relevant for the current study.</p><p>Considering the coarse spatial scale, results may similarly come out of simpler univariate analyses. If so, this would inform (and simplify) the interpretation of the results. For example, rather than using correlation as a measure of similarity, you could take the absolute activation difference (e.g., between Participant 1 of Group 1 and the average of Group 2), averaged across the voxels of the ROI (or at the voxel level, in a whole-brain analysis). Please include such analyses, or describe why they would not be informative.</p><p>If possible, please include the interaction analysis of Figure 2c also in the whole brain analysis (Supp figure 1). It may be easiest, for comparison, to include two Supp figures corresponding to the two main results figures (same layout, etc).</p><p>If I understand the analysis correctly, it is done separately for each of the 7 scenes and results were then averaged. To get more insight into the results, it may be informative to know which scenes showed the strongest correlation difference (e.g., within the ROIs showing an overall effect). This analysis may be most powerful when including all 18 scenes, correlating the effect of interest with the twist score from the behavioral data (i.e., correlate across scenes rather than participants, as in Supp Figure 2). This would more directly relate the results to the twist manipulation.</p><p>Please motivate how you determined the sample size.</p><p>What was the duration of the 18 scenes? How long did participants take to recall them? Did this differ across conditions?</p><p><italic>Reviewer #2 (Public Review):</italic></p><p>In this manuscript titled &quot;Here's the twist: How the brain updates the representations of naturalistic events as our understanding of the past changes&quot;, the authors reported a study that examined how new information (manipulated as a twist at the end of a movie) changes the neural representations in the default mode network (DMN) during the recall of prior knowledge. Three groups of participants were compared - one group experienced the twist at the end, one group never experienced the twist, and one group received a spoiler at the beginning. At retrieval, participants received snippets of 18 scenes of the movie as cues and were asked to freely describe the events of each scene and to provide the most accurate interpretation of the scene, given the information they gathered throughout watching.</p><p>All three groups were highly accurate in the recall of content. The groups that experienced the twist at the end as well as at the beginning as a spoiler showed a higher twist score (the extent to which twist information was incorporated into the recall), while seemingly also keeping the interpretation without the twist (&quot;Doctor representation&quot;) intact. Neurally, several regions in the DMN showed significant interaction effects in their neural similarity patterns (based on intersubject pattern correlation), indicating a change in interpretation between encoding and recall in the twist group uniquely, presumably reflecting memory updating.</p><p>Several points that I think should be addressed to strengthen the manuscript:</p><p>1) The results from encoding-retrieval similarity analysis (particularly the one depicted in Figure 3B) don't match the results from encoding/retrieval interaction (particularly those shown in Figure 2C). While they were certainly based on different comparisons, I would think that both analyses were set up to test for memory updating. Can the authors comment on this divergence in results?</p><p>2) The recall task was self-paced. Can reaction time information be provided on how long participants needed to recall? Did this differ across groups? Presumably in the twist group and spoiled group participants might have needed a longer time to incorporate both the original and twist interpretation. How was the length difference across events taken into consideration in the beta estimates? Also, is there an order effect, such that one type of interpretation tended to be recalled first?</p><p>3) The correlation analysis between neural pattern change and behavioral twist score is based on a small sample size and does not seem to be well suited to test the postulation of the authors, namely that some participants may hold both interpretations in their memory. Interestingly, the twist score of the spoiled group was similar to the twist group, indicating participants in this group might have held both interpretations as well. Could this observation be leveraged, for example by combining both groups (hence better powered with larger sample size), in order to relate individual differences in neural similarity patterns and behavioral tendency to hold both interpretations?</p><p>4) Several regions within the DMN were significant across the analysis steps, specifically the angular gyrus, middle temporal cortex, and medial PFC. Can the authors provide more insights on how these widely distributed regions may act together to enable memory updating? The discussion on the main findings is largely at a rather superficial level about DMN, or focuses specifically on vmPFC, but neglects the distributed regions that presumably function interactively.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>The prediction legends in Figures 2 and 3 are very helpful to follow the contrasts involved and the predictions made. My only suggestion is to increase the word font, as in the current version it is somewhat difficult to read.</p><p><italic>Reviewer #3 (Public Review):</italic></p><p>Zadbood and colleagues investigated the way key information used to update interpretations of events alter patterns of activity in the brain. This was cleverly done by the use of &quot;The Sixth Sense,&quot; a film featuring a famous &quot;twist ending,&quot; which fundamentally alters the way the events in the film are understood. Participants were assigned to three groups: (1) a Spoiled group, in which the twist was revealed at the outset, (2) a Twist group, who experienced the film as normal, and (3) a No-Twist group, in which the twist was removed. Participants were scanned while watching the movie and while performing cued recall of specific scenes. Verbal recall was scored based on recall success, and evidence for descriptive bias toward two ways of understanding the events (specifically, whether a particular character was or was not a ghost). Importantly, this allowed the authors to show that the Twist group updated their interpretation. The authors focused on regions of the Default Mode Network (DMN) based on prior studies showing responsiveness to naturalistic memory paradigms in these areas and analyzed the fMRI data using intersubject pattern similarity analysis. Regions of the DMN carried patterns indicative of story interpretation. That is, encoding similarity was greater between the Twist and No-Twist groups than in the Spoiled group, and retrieval similarity was greater between the Twist and Spoiled groups than in the No-Twist group. The Spoiled group also showed greater pattern similarity with the Twist group's recall than the No-Twist group's recall. The authors also report a weaker effect of greater pattern similarity between the Spoiled group's encoding and the Twist group's recall than between the Twist group's own encoding and recall. Together, the data all converge on the point that one's interpretation of an event is an important determinant of the way it is represented in the brain.</p><p>This is a really nice experiment, with straightforward predictions and analyses that support the claims being made. The results build directly on a prior study by this research group showing how interpretational differences in a narrative drive distinct neural representations (Yeshurun et al., 2017), but extend an understanding of how these interpretational differences might work retrospectively. I do not have any serious concerns or problems with the manuscript, the data, or the analyses. However I have a few points to raise that, if addressed, would make for a stronger paper in my opinion.</p><p>1) My most substantive comment is that I did not find the interpretive framework to be very clear with respect to the brain regions involved. The basic effects the authors report strongly support their claims, but the particular contributions to the field might be stronger if the interpretations could be made more strongly or more specifically. In other words: the DMN is involved in updating interpretations, but how should we now think about the role of the DMN and its constituent regions as a result of this study? There are a number of ideas briefly presented about what the DMN might be doing, but it just did not feel very coherent at times. I will break this down into a few more specific points:</p><p>While many of us would agree that the DMN is likely to be involved in the phenomena at hand, I did not find that the paper communicated the logic for singularly focusing on this subset of regions very compellingly. The authors note a few studies whose main results are found in DMN regions, but I think that this could stand to be unpacked in a more theoretically interesting way in the Introduction.</p><p>Relatedly, I found the summary/description of regional effects in the Discussion to be a bit unsatisfying. The various pattern similarity comparisons yielded results that were actually quite nonoverlapping among DMN regions, which was not really unpacked. To be clear, it is not a 'problem' that the regional effects varied from comparison to comparison, but I do think that a more theoretical exploration of what this could mean would strengthen the paper. To the authors' credit, they describe mPFC effects through the lens of schemas, but this stands in contrast to many other regions which do not receive much consideration.</p><p>Finally, although there is evidence that regions of the DMN act in a coordinated way under some circumstances, there is also ample evidence for distinct regional contributions to cognitive processes, memory being just one of them (e.g., Cooper &amp; Ritchey, 2020; Robin &amp; Moscovitch, 2017; Ranganath &amp; Ritchey, 2012). The authors themselves introduce the idea of temporal receptive windows in a cortical hierarchy, and while DMN regions do appear to show slower temporal drift than sensory areas, those studies show regional differences in pattern stability across time even within DMN regions. Simply put, it is worth considering whether it is ideal to treat the DMN as a singular unit.</p><p>2) I think that some direct comparison to regions outside the DMN would speak to whether the DMN is truly unique in carrying the key representations being discussed here. I was reluctant to suggest this because I think that the authors are justified in expecting that DMN regions would show the effects in question. However, there really is no &quot;null&quot; comparison here wherein a set of regions not expected to show these effects (e.g., a somatosensory network, or the frontoparietal network) in fact do not show them. There are not really controls or key differences being hypothesized across different conditions or regions. Rather, we have a set of regions that may or may not show pattern similarity differences to varying degrees, which feels very exploratory. The inclusion of some principled control comparisons, etc. would bolster these findings. The authors do include a whole-brain analysis in Supplementary Figure 1, which indeed produced many DMN regions. However, notably, regions outside the DMN such as the primary visual cortex and mid-cingulate cortex appear to show significant effects (which, based on the color bar, might actually be stronger than effects seen in the DMN). Given the specificity of the language in the paper in terms of the DMN, I think that some direct regional or network-level comparison is needed.</p><p>3) If I understand correctly, the main analyses of the fMRI data were limited to across-group comparisons of &quot;critical scenes&quot; that were maximally affected by the twist at the end of the movie. In other words, the analyses focused on the scenes whose interpretation hinged on the &quot;doctor&quot; versus &quot;ghost&quot; interpretation. I would be interested in seeing a comparison of &quot;critical&quot; scenes directly against scenes where the interpretation did not change with the twist. This &quot;critical&quot; versus &quot;non-critical&quot; contrast would be a strong confirmatory analysis that could further bolster the authors' claims, but on the other hand, it would be interesting to know whether the overall story interpretation led to any differences in neural patterns assigned to scenes that would not be expected to depend on differences in interpretation. (As a final note, such a comparison might provide additional analytical leverage for exploring the effect described in Figure 3B, which did not survive correction for multiple comparisons.)</p><p>4) I appreciate the code being made available and that the neuroimaging data will be made available soon. I would also appreciate it if the authors made the movie stimulus and behavioral data available. The movie stimulus itself is of interest because it was edited down, and it would be nice for readers to be able to see which scenes were included.</p><p>To sum up, I think that this is a great experiment with a lot of strengths. The design is fairly clean (especially for a movie stimulus), the analyses are well reasoned, and the data are clear. The only weaknesses I would suggest addressing are with regards to how the DMN is being described and evaluated, and the communication of how this work informs the field on a theoretical level.</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>I want to emphasize that I am a big fan of the study and the approach overall. It is very well done, the results are clear and interesting, and the paper is overall well constructed. Below, I will expand on some of the points I raised in the public review, and provide some suggestions for how they might be addressed.</p><p>1) My first point dealt with asking for a somewhat stronger explanation for a focus on the DMN, and the question of how the reader should update their model of the DMN on the basis of these results. The updating phenomenon is certainly interesting, and as I noted in the public review, a focus on the DMN is sensible. However, I think this focus could be more clearly justified. The results themselves were a bit inconsistent in terms of which specific DMN regions showed pattern similarity effects, and I found myself wondering what this might mean. A bit more unpacking of this could be helpful. Beyond these points, however, there are theoretical frameworks arguing pretty compellingly that subsystems of the DMN may uniquely contribute to cognition (e.g., Maureen Ritchey's and Morris Moscovitch's ideas). This is a bit at odds with treating the DMN as a single unit. While I want to be clear that I do not think it is necessarily wrong to do so in this case, it does warrant some consideration.</p><p>2) As I noted in the public review, I hesitated to bring this up. However, some direct comparison of DMN vs. non-DMN would really bolster the results and the claims in my opinion. This would also go a long way in addressing my points above.</p><p>3) I was not sure when writing this comment whether this &quot;critical&quot; versus &quot;non-critical&quot; analysis was tried, but in my view, it could serve to bolster the findings being presented in the paper currently. And as I noted in the public review, on the other hand, it would be interesting to know if the effects of the twist on neural patterns reached beyond the &quot;critical&quot; scenes into a general interpretation of the story.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.79045.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) Better introduce the method and specific hypotheses, including the focus on the DMN.</p></disp-quote><p>We addressed this by adding the following paragraphs to Introduction and the beginning of the Results section.</p><p>Paragraph added to Introduction:</p><p>“The brain’s default mode network (DMN)—comprising the posterior medial cortex, medial prefrontal cortex, temporoparietal junction, and parts of anterior temporal cortex—was originally described as an intrinsic or “task-negative” network, activated when participants are not engaged with external stimuli (Raichle et al. 2001, Buckner et al. 2008). […] Building on this foundation of prior work on the DMN, we asked whether we could find neural evidence for the retroactive influence of new knowledge on past memories.”</p><p>Paragraph added to the beginning of Results section:</p><p>“We used intersubject pattern similarity analysis (intersubject pattern correlation: pISC, see Methods) to compare the neural event representations between groups. […] We focused our analyses on a predetermined selection of movie scenes (i.e., 7 “critical scenes” out of 18 total scenes) in which the <italic>Doctor</italic> or <italic>Ghost</italic> interpretation of the main character in the movie would dramatically change the overall interpretation of those scenes. Selection of these scenes was based on ratings from four raters asked to quantify the influence of the twist on the interpretation of each scene (see Methods).”</p><disp-quote content-type="editor-comment"><p>2) Include additional analyses to provide more insight into the processes/mechanisms leading to the observed results, such as whether these reflect overall (univariate) activity differences, are scene-specific, are specific to critical (vs non-critical) scenes, regional (DMN) specificity, etc. (see suggestions by R1 and R3)</p></disp-quote><p>Thank you for summarizing the reviewers’ suggestions. We added new analyses for each of these suggestions.</p><p>A univariate analysis was performed and reported in the Results section (end of Neural representation of the twist information during cued recall):</p><p>“To test whether our reported results were mainly driven by the similarities and differences in multivariate spatial patterns of neural representations, as opposed to by univariate regional-average response magnitudes, we ran a univariate analysis in each ROI. This analysis revealed no significant effect of group (“spoiled”, “twist”, “no-twist”) or interaction between group and condition (movie, recall) (Table 1, see Methods for details).”</p><p>Scene-related analyses (critical vs. non-critical scenes analysis and scene specificity analysis) are reported in a new Results section entitled “The role of scene content”:</p><p>“The role of scene content</p><p>In the prior analyses, we focused on “critical scenes”, selected based on ratings from four raters who quantified the influence of the twist on the interpretation of each scene (see Methods). […] However, they appear to match the direction of our main analyses; with greater statistical power, analyses of this sort may provide insights into how neural event representations are updated in a scene-specific manner.”</p><p>DMN specificity is further evaluated in a new Results section entitled “The changes in neural representations beyond DMN”:</p><p>“Changes in neural representations beyond the DMN</p><p>We focused our core analyses on regions of the default mode network. Prior work has shown that multimodal neural representations of naturalistic events (e.g. movie scenes) are similar across encoding (movie-watching or story-listening) and verbal recall of the same events in the DMN (Chen et al., 2017; Zadbood et al., 2017). […] In the encoding-encoding comparison, several ROIs from the visual and somatomotor networks showed relatively strong effects as well (see Discussion).”</p><p>The whole brain analysis figure was modified to add the interaction analysis (asked by reviewer 1) and adding text for further discussion of anterior cingulate cortex and dorsolateral prefrontal cortex regions:</p><p>“In addition, we qualitatively reproduced our results by performing an ROI-based whole brain analysis (Appendix-Figure 3, p &lt; 0.01 uncorrected). This analysis confirmed the importance of DMN regions for updating neural event representations. However, strong differences in pISC in the hypothesized direction were also observed in a handful of other non-DMN regions, including ROIs partly overlapping with anterior cingulate cortex and dorsolateral prefrontal cortex (see Discussion).”</p><p>Sections added to the Methods corresponding to the new analyses:</p><p>“The same pISC procedures were performed in the regions of the visual and somatosensory cortices (Appendix-Figure 2), as well as across the whole brain (Appendix-Figure 3). All regions were extracted from the 100-parcel Shaeffer where each region is assigned to one of seven resting-state networks (Shaeffer et al. 2018). […] To better understand the role of “critical scenes” in this relationship, those scenes were marked as blue on the scatter plots (Appendix-Figure 4, left panels).”</p><disp-quote content-type="editor-comment"><p>3) Present results when including all 18 scenes (note that this also allows you to address some of the concerns listed under #2 above).</p></disp-quote><p>This analysis was added in the “The role of scene content” section and Figure 4-A, described above.</p><disp-quote content-type="editor-comment"><p>4) More in-depth discussion about the possible role(s) of DMN regions in memory updating, including the distinct roles of individual regions, taking into account the partly divergent results across analyses.</p></disp-quote><p>The following paragraphs were added to the Discussion to address these points:</p><p>“In addition to mPFC, right precuneus and parts of temporal cortex exhibited significantly higher pattern similarity in the “twist” and “spoiled” groups who recalled the movie with the same interpretation. […] Future extensions of this work may benefit from using functional alignment methods (Haxby et al. 2020, Chen et al. 2015) to capture more fine-grained event representations which are shared across participants.”</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Public Review):</p><p>This fMRI study investigated how memories are updated after reinterpreting past events. Participants watched a movie and subsequently recalled individual scenes from that movie. Importantly, the movie ends with a twist that changes the interpretation of earlier scenes in the movie. One group of participants watched the movie with the twist at the end, one group did not get to see the twist, and a third group was already informed about this twist before watching the movie. Analyses compared the similarity of activity patterns to (encoded or recalled) events across participants within regions of the default mode network (DMN). The design allowed for multiple relevant comparisons, confirming the prediction that activity patterns in DMN regions reflect the (re)interpretation of the movie (during movie viewing and/or during recall).</p><p>The study is well-designed and executed. The inclusion of multiple analyses involving distinct comparisons strengthens the evidence for the role of the DMN in memory updating.</p><p>The following points may be relevant to consider:</p><p>1. The cross-participant pattern analysis method used here is not standard, with such analyses typically done within participants (or across participants, but after aligning representational spaces). Considering individual variability in functional organization, the method is likely only sensitive to coarse-scale patterns (e.g., anterior vs posterior parts of an ROI). This is not necessarily a weakness but is relevant when interpreting the results.</p></disp-quote><p>We agree with the reviewer that functional misalignment might have played against us here. We designed this study as a natural successor of our previous work in which we captured reliable and multimodal scene-specific cross-participant pattern similarity during encoding and recall in standard space. In this revised version, we provide further evidence on how scene content is captured and influences our results. Nonetheless, we agree with your comment and add the following section to the discussion to encourage considering this point while interpreting the results.</p><p>“Moreover, our current method relies on averaging spatially-coarse activity patterns across subjects (and time points within an event). Future extensions of this work may benefit from using functional alignment methods (Haxby et al 2020, Chen et al 2015) to capture more fine-grained event representations which are shared across participants.”</p><disp-quote content-type="editor-comment"><p>2. Unlike previous work, analyses are not testing for scene-specific information. Rather, each scene is treated separately to establish between-group differences, and results are averaged across scenes. This raises the question of whether the patterns reflect scene-specific information or generic group differences. For example, knowing the twist may increase overall engagement, both when viewing the movie (spoiled group) and when recalling it (spoiled group + twist group). The DMN may be particularly sensitive to such differences in overall engagement.</p></disp-quote><p>You have brought up great points. We addressed them in two ways: (1) We ran a univariate analysis in each DMN ROI to look at the role of overall regional-average response magnitude in our results. We did not observe a significant effect of group or an interaction between group and condition. (2) We ran a scene-specificity analysis in a new Results section entitled “The role of scene content” (Figure 4). This section is focused on comparing interaction index (Figure 2C), as an indicator of memory updating, under different manipulations. Interaction index reflects the reversal of neural similarity during encoding and recall. Our results suggest that we don’t see the same effects if we shuffle the scene labels and recompute the pattern similarity analyses. Please see added text below:</p><p>“To test whether our reported results were mainly driven by the similarities and differences in multivariate spatial patterns of neural representations, as opposed to by univariate regional-average response magnitudes, we ran a univariate analysis in each ROI. This analysis revealed no significant effect of group (“spoiled”, “twist”, “no-twist”) or interaction between group and condition (movie, recall) (Table 1, see Methods for details) […] Next, to determine whether scene-specific neural event representations—as opposed to coarser differences in general mental state across all scenes with similar interpretations—drive our observed pISC differences, we shuffled the labels of critical scenes within each group before calculating and comparing pISC across groups. By repeating this procedure 1000 times and recalculating the interaction index at each iteration, we constructed a null distribution of interaction indices for shuffled critical scenes (light magenta distributions in Figure 4B). In 12 out of 24 DMN regions, interaction indices were statistically significant based on the shuffled-scene distribution (p &lt; .025, FDR controlled at q &lt; .05). All of these 12 regions were among the ROIs that showed meaningful effects in our original analysis (Figure 2C). Regions with significant scene-specific interaction effects are marked as blue dots with black borders in Figure 4B. Overall, the findings from this analysis confirm that our results are driven by changes to scene-specific representations.”</p><disp-quote content-type="editor-comment"><p>3. The study does not reveal what the DMN represents about the movie, such that its activity changes after knowing the twist. The Discussion briefly mentions that it may reflect the state of the observer, related to the belief about the identity of the doctor. This suggests a link to the theory of mind/mentalizing, but this is not made explicit. Alternatively, the DMN may be involved in the conflict (or switching) between the two interpretations.</p></disp-quote><p>Great points. We added to the discussion about the role of mentalizing network and in the particular temporo-parietal cortex. About your last point, we think our whole brain findings outside DMN (ACC and dlPFC) might relate to that point. We discussed these further in the paper.</p><p>“We performed two targeted analyses to look for evidence of memory updating across encoding and recall: the interaction analysis (Figure 2C) and the encoding-recall analysis (Figure 3). […] These results suggest that both the &quot;spoiled&quot; manipulation and the &quot;twist&quot; may recruit top-down control and conflict monitoring processes during naturalistic viewing and recall.</p><disp-quote content-type="editor-comment"><p>4. The design has many naturalistic aspects, but it is also different from real life in that the critical twist involves a ghost. Furthermore, all results are based on one movie with a specific plot twist. It is thus not clear whether similar results would be obtained with other and more naturalistic plot twists.</p></disp-quote><p>We added this as a limitation of the study.</p><p>“Our findings provide further insight into the functional role of the DMN. However, these results have been obtained using only one movie. While naturalistic paradigms better capture the complexity of real life and provide greater ecological generalizability than highly-controlled experimental stimuli and tasks (Nastase et al., 2020), they are still limited by the properties of the particular naturalistic stimulus used. For example, this movie—including the twist itself—hinges on suspension of disbelief about the existence of ghosts. Future work is needed to extend our findings about updating event memories to a broader class of naturalistic stimuli: for example, movies with different kinds of (non-supernatural) plot twists, spoken stories with twist endings, or using autobiographical real-life situations where new information (e.g. discovering a longtime friend has lied about something important) triggers re-evaluation of the past (e.g. reinterpreting their friend’s previous actions).”</p><disp-quote content-type="editor-comment"><p>5. Only 7 scenes (out of 18) were included in the analysis. It is not clear if/how the results depend on the selection of these 7 scenes.</p></disp-quote><p>Thank you for bringing this up. These scenes were pre-selected for the analyses, as they are the only scenes that are rated high by our independent raters (not study participants) on “twist influence”, meaning that knowing the twist could dramatically change their interpretation. So, we had a priori reasons to hypothesize that the effect will be strong in these scenes. To address your point, we report results by including all 18 scenes in a new Results section entitled “The role of scene content” and in Figure 4A. While the effect was weaker for all scenes it was still apparent in this conservative analysis. As expected, however, including 7 critical scenes produces stronger results than including all scenes or the uncritical scenes (all minus critical scenes). Please see the “The role of scene content” in Results and in Figure 4 for more detailed information.</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>1. The interpretation of the results critically relies on a good understanding of the method. Therefore, please introduce and explain the method more explicitly (either in the Introduction or the Results), making clear how it differs from related methods (including the temporal correlation method used in previous papers of this group) and what it may (and may not) be sensitive to. Also, please discuss the results in the context of what this method can reveal, i.e., what kind of representation can be revealed at this spatial scale.</p></disp-quote><p>Thank you for bringing this up. We added text to the beginning of results to address this:</p><p>“We used intersubject pattern similarity analysis (intersubject pattern correlation: pISC, see Methods) to compare the neural event representations between groups. […] Selection of these scenes was based on ratings from four raters asked to quantify the influence of the twist on the interpretation of each scene (see Methods).”</p><disp-quote content-type="editor-comment"><p>2. This point could be addressed in additional analyses (e.g., by testing whether similar results are found when randomly pairing scenes in the analyses). Alternatively, this would be relevant to discuss and/or exclude in other ways.</p></disp-quote><p>Thank you. We ran an additional analysis for this as stated in our response in the public section.</p><disp-quote content-type="editor-comment"><p>3. Please include additional discussion about the putative role of the DMN in relation to the twist manipulation.</p></disp-quote><p>We added these paragraphs to the discussion.</p><p>“In addition to mPFC, right precuneus and parts of temporal cortex exhibited significantly higher pattern similarity in the “twist” and “spoiled” groups who recalled the movie with the same interpretation. […] This transformation could affect how different regions and sub-systems of DMN represent memories, and suggests that the concerted activity of multiple subsystems and neural mechanisms might be at play during encoding, recall and successful updating of naturalistic event memories.”</p><disp-quote content-type="editor-comment"><p>4. This could be discussed as a limitation of the study.</p></disp-quote><p>We discussed this as a limitation of the study as you suggested.</p><p>“Our findings provide further insight into the functional role of the DMN. However, these results have been obtained using only one movie. While naturalistic paradigms better capture the complexity of real life and provide greater ecological generalizability than highly-controlled experimental stimuli and tasks (Nastase et al., 2020), they are still limited by the properties of the particular naturalistic stimulus used. For example, this movie—including the twist itself—hinges on suspension of disbelief about the existence of ghosts. Future work is needed to extend our findings about updating event memories to a broader class of naturalistic stimuli: for example, movies with different kinds of (non-supernatural) plot twists, spoken stories with twist endings, or using autobiographical real-life situations where new information (e.g. discovering a longtime friend has lied about something important) triggers re-evaluation of the past (e.g. reinterpreting their friend’s previous actions).”</p><disp-quote content-type="editor-comment"><p>5. The scene selection procedure would need to be described in the Results section, following the behavioral results (as it was based on those results). It would be relevant to know how and when this was decided, particularly whether this was decided before or after analyses were conducted (and results inspected), and why 18 scenes were originally included. Also, the current scene selection appears somewhat arbitrary. For example, scene #1 was included because it showed a high twist score, but it is not clear what this twist score is or whether there were scenes with a similarly high twist score. Ideally, the authors would also present the results when including all 18 scenes (e.g., as Supplementary file).</p></disp-quote><p>Thank you for your comment. We tried to make the scene selection procedure more clear at the end of the Results section opening and also the beginning of the new Results section (The role of scene content). We also made some edits in the related Methods section. To your points, our scene selection procedure was separate from subjects’ behavioral twist score. But interestingly, it did match it. Before running the study and based on our internal rating of the content of the scenes (by AZ from the authors), we knew those selected scenes were perhaps the most critical ones for our questions. Ratings from three independent raters confirmed this selection. However, as the doctor was present in most of the other scenes of the movie and we were not sure how the twist would be reflected in subjects’ behavioral recall of unrelated scenes, we included all 18 scenes of the movie in the study. Behavioral recall “twist scores” confirmed that those originally hypothesized scenes contained the highest behavioral reflection of the twist information. We made this procedure more clear by adding text to the beginning of the new Results section (The role of scene content) and the Methods section (Timestamping and scene selection). About scene 1, its twist score is the highest after the main 6 scenes and equals to 1 other scene. As stated in the text, we included this scene as it was the first time subjects saw the doctor after watching the twist and needed to retrieve him in this new context (<italic>Ghost</italic> instead of <italic>Doctor</italic>). So, we hypothesized it might be an important scene to keep and subjects’ twist scores confirmed it.</p><p>To summarize, we had pre-selected a set of scenes that we thought would be particularly relevant before we ran the study. But we also had the post-encoding twist scores from participants’ recall in hand (which perfectly matched our prior movie-based selection) at the time of analysis. Results with all scenes are also presented in the revision of the paper. The following snippets show the related edits in the paper:</p><p>“We focused our analyses on a predetermined selection of movie scenes (i.e., 7 “critical scenes” out of 18 total scenes) in which the <italic>Doctor</italic> or <italic>Ghost</italic> interpretation of the main character in the movie would dramatically change the overall interpretation of those scenes. Selection of these scenes was based on ratings from four raters asked to quantify the influence of the twist on the interpretation of each scene (see Methods).”</p><p>“In the prior analyses, we focused on “critical scenes”, selected based on ratings from four raters who quantified the influence of the twist on the interpretation of each scene (see Methods). An independent post-experiment analysis of the verbal recall behavior of the fMRI participants yielded “twist scores” that were also highest for these scenes; that is, the expected and perceived effect of twist information on recall behavior were found to match. Next, we asked whether the neural event representations reflect these differences in the twist-related content of the scenes. In other words, are the “critical scenes” with highly twist-dependent interpretations truly <italic>critical</italic> for our observed effects?”</p><p>“Edited method:</p><p>Timestamping and scene selection</p><p>The movie was time-stamped by an independent rater naive to the purpose and design of the experiment to identify the main scenes of the movie. All of the movie scenes with clear scene boundaries (N = 18) were selected to be used in the cued-recall task. […] Therefore, we added this scene as a seventh <italic>critical scene</italic> to be used in the main neural analyses.”</p><disp-quote content-type="editor-comment"><p>Additional comments:</p><p>The Introduction does not sufficiently make clear why the DMN is the main focus of the study. Readers may be unfamiliar with the DMN, so it would be relevant to briefly introduce the DMN (e.g., which regions are part of it, how it is defined, what it does, etc.). This could then lead to a more focused motivation for why these regions were specifically relevant for the current study.</p></disp-quote><p>This paragraph was added to the introduction:</p><p>“The brain’s default mode network (DMN)—comprising the posterior medial cortex, medial prefrontal cortex, temporoparietal junction, and parts of anterior temporal cortex—was originally described as an intrinsic or “task-negative” network, activated when participants are not engaged with external stimuli (Raichle et al. 2001, Buckner et al. 2008). […] Building on this foundation of prior work on the DMN, we asked whether we could find neural evidence for the retroactive influence of new knowledge on past memories.”</p><disp-quote content-type="editor-comment"><p>Considering the coarse spatial scale, results may similarly come out of simpler univariate analyses. If so, this would inform (and simplify) the interpretation of the results. For example, rather than using correlation as a measure of similarity, you could take the absolute activation difference (e.g., between Participant 1 of Group 1 and the average of Group 2), averaged across the voxels of the ROI (or at the voxel level, in a whole-brain analysis). Please include such analyses, or describe why they would not be informative.</p></disp-quote><p>We included a univariate analysis by looking at differences in absolute activation values across groups and conditions in each ROI. Running an ANOVA in each ROI revealed no significant effect of group or interaction between group and condition. We found a significant effect of group in two ROIs that didn’t pass correction for multiple comparisons. As you suggested, univariate activation values in some ROIs were more similar in conditions that were associated with the same interpretation (average values are reported in Table 1). But based on our results here and also the results of other analyses in the manuscript (in particular, our new “scene-specificity” analysis, where we showed that our results go away when we permute scene labels within group, without altering mean univariate activation), group differences in mean univariate activation alone do not seem to explain our results.</p><disp-quote content-type="editor-comment"><p>If possible, please include the interaction analysis of Figure 2c also in the whole brain analysis (Supp figure 1). It may be easiest, for comparison, to include two Supp figures corresponding to the two main results figures (same layout, etc).</p></disp-quote><p>Thanks for pointing this out. It was added to Appendix-Figure 2.</p><disp-quote content-type="editor-comment"><p>If I understand the analysis correctly, it is done separately for each of the 7 scenes and results were then averaged. To get more insight into the results, it may be informative to know which scenes showed the strongest correlation difference (e.g., within the ROIs showing an overall effect). This analysis may be most powerful when including all 18 scenes, correlating the effect of interest with the twist score from the behavioral data (i.e., correlate across scenes rather than participants, as in Supp Figure 2). This would more directly relate the results to the twist manipulation.</p></disp-quote><p>Thank you for this interesting suggestion. We explored this further and you can find the results at the end of the Results section on the role of scene content and in Appendix-Figure 4. We did not see strong results but the direction of findings were interesting and complement our main analysis so we included this as a supplemental analysis/appendix figure.</p><p>“To further evaluate the relationship between scene-specific twist information in the brain and behavior, we ran an exploratory analysis which was focused on the changes in the neural event representations during recall of the “twist” group and their corresponding recall behavior. […] However, they appear to match the direction of our main analyses; with greater statistical power, analyses of this sort may provide insights into how neural event representations are updated in a scene-specific manner.”</p><disp-quote content-type="editor-comment"><p>Please motivate how you determined the sample size.</p></disp-quote><p>Our sample size was decided based on our previous work in which we captured scene-specific pattern similarity across encoding, recall, and listening (18 subjects per group in Zadbood et al. 2017, 17 subjects in Chen et al. 2016) and differences in brain response while listening to the same story with different perspectives (20 subjects per group in Yeshurun et al. 2017). We added this information to the Methods section now. We originally collected 21 participants in each group but we had to remove participants for head motions and other reasons mentioned in the Methods. So, we ended up with 18, 19, and 20 participants per group.</p><disp-quote content-type="editor-comment"><p>What was the duration of the 18 scenes? How long did participants take to recall them? Did this differ across conditions?</p></disp-quote><p>We added this information to the methods section (end of <italic>Behavioral analysis</italic>). No significant difference between overall recall time or average recall time per scene was observed across groups. Section added to Methods:</p><p>“The average length of scenes in the 55 minute movie was 2 minutes and 10 seconds (sd = 1:59, median = 1:56, min = 00:26, max = 5:56). For the recalls, in the “spoiled” group the average recall time per scene was 39.4 seconds (sd = 13.2 s, min = 14 s, max = 67 s) for a total average of 713 seconds of recall time. In the “twist” group, the average recall time per scene was 38.5 seconds (sd = 13 s, min= 17 s, max = 69 s) for a total average of 698 seconds of recall time. In the “no-twist” group, the average recall time per scene was 37.75 seconds (sd = 19.8 s, min = 8 s, max = 73 s) for a total average of 642 seconds of recall time. No significant differences were observed between average recall time per scene or overall recall time across any two groups (according to t-tests).”</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Public Review):</p><p>In this manuscript titled &quot;Here's the twist: How the brain updates the representations of naturalistic events as our understanding of the past changes&quot;, the authors reported a study that examined how new information (manipulated as a twist at the end of a movie) changes the neural representations in the default mode network (DMN) during the recall of prior knowledge. Three groups of participants were compared - one group experienced the twist at the end, one group never experienced the twist, and one group received a spoiler at the beginning. At retrieval, participants received snippets of 18 scenes of the movie as cues and were asked to freely describe the events of each scene and to provide the most accurate interpretation of the scene, given the information they gathered throughout watching.</p><p>All three groups were highly accurate in the recall of content. The groups that experienced the twist at the end as well as at the beginning as a spoiler showed a higher twist score (the extent to which twist information was incorporated into the recall), while seemingly also keeping the interpretation without the twist (&quot;Doctor representation&quot;) intact. Neurally, several regions in the DMN showed significant interaction effects in their neural similarity patterns (based on intersubject pattern correlation), indicating a change in interpretation between encoding and recall in the twist group uniquely, presumably reflecting memory updating.</p><p>Several points that I think should be addressed to strengthen the manuscript:</p><p>1) The results from encoding-retrieval similarity analysis (particularly the one depicted in Figure 3B) don't match the results from encoding/retrieval interaction (particularly those shown in Figure 2C). While they were certainly based on different comparisons, I would think that both analyses were set up to test for memory updating. Can the authors comment on this divergence in results?</p></disp-quote><p>Thank you for your comment. Except for one ROI, the other two regions in Figure 2C are present in the interaction analysis. The ROI at the frontal pole might be hard to see from this angle but in fact it holds a high effect size in interaction analysis. So we do not see a big divergence between these two results. But taking into account the recall-recall results, we agree that there seems to be inhomogeneity. We discussed these further in the discussion.</p><p>“We performed two targeted analyses to look for evidence of memory updating across encoding and recall: the interaction analysis (Figure 2C) and the encoding-recall analysis (Figure 3). […] This transformation could affect how different regions and sub-systems of DMN represent memories, and suggests that the concerted activity of multiple subsystems and neural mechanisms might be at play during encoding, recall and successful updating of naturalistic event memories.”</p><disp-quote content-type="editor-comment"><p>2) The recall task was self-paced. Can reaction time information be provided on how long participants needed to recall? Did this differ across groups? Presumably in the twist group and spoiled group participants might have needed a longer time to incorporate both the original and twist interpretation.</p></disp-quote><p>This is an interesting idea. Unfortunately, we could not measure this accurately because our recall cues were snippets from the beginning of each scene with different length (selected based on content). And updating could begin from the beginning of those snippets (but we wouldn’t know when). We will consider this point in the future related designs.</p><disp-quote content-type="editor-comment"><p>How was the length difference across events taken into consideration in the beta estimates?</p></disp-quote><p>They were used as event durations in the GLM model.</p><disp-quote content-type="editor-comment"><p>Also, is there an order effect, such that one type of interpretation tended to be recalled first?</p></disp-quote><p>This is indeed hard to measure as you mentioned. We will provide the transcripts when sharing the data and hopefully this will facilitate future text-analysis work on this dataset to answer interesting questions like this.</p><disp-quote content-type="editor-comment"><p>3) The correlation analysis between neural pattern change and behavioral twist score is based on a small sample size and does not seem to be well suited to test the postulation of the authors, namely that some participants may hold both interpretations in their memory. Interestingly, the twist score of the spoiled group was similar to the twist group, indicating participants in this group might have held both interpretations as well. Could this observation be leveraged, for example by combining both groups (hence better powered with larger sample size), in order to relate individual differences in neural similarity patterns and behavioral tendency to hold both interpretations?</p></disp-quote><p>Even though both groups showed signs of holding both interpretations in mind, the process happening in their brain during the recall is different. In particular, we do not expect to see any updating effect in the spoiled group. So it wouldn’t seem accurate to combine these groups to test the effect of incomplete updating.</p><disp-quote content-type="editor-comment"><p>4) Several regions within the DMN were significant across the analysis steps, specifically the angular gyrus, middle temporal cortex, and medial PFC. Can the authors provide more insights on how these widely distributed regions may act together to enable memory updating? The discussion on the main findings is largely at a rather superficial level about DMN, or focuses specifically on vmPFC, but neglects the distributed regions that presumably function interactively.</p></disp-quote><p>Thanks for bringing this up. We added text to discussion to respond to this very valid point. Please see the added text in our response to your first point. One more snippet added to the discussion about this:</p><p>“In addition to mPFC, right precuneus and parts of temporal cortex exhibited significantly higher pattern similarity in the “twist” and “spoiled” groups who recalled the movie with the same interpretation. […] This transformation could affect how different regions and sub-systems of DMN represent memories, and suggests that the concerted activity of multiple subsystems and neural mechanisms might be at play during encoding, recall and successful updating of naturalistic event memories.”</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>The prediction legends in Figures 2 and 3 are very helpful to follow the contrasts involved and the predictions made. My only suggestion is to increase the word font, as in the current version it is somewhat difficult to read.</p></disp-quote><p>We did it. Thank you for bringing it up.</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Public Review):</p><p>Zadbood and colleagues investigated the way key information used to update interpretations of events alter patterns of activity in the brain. This was cleverly done by the use of &quot;The Sixth Sense,&quot; a film featuring a famous &quot;twist ending,&quot; which fundamentally alters the way the events in the film are understood. Participants were assigned to three groups: (1) a Spoiled group, in which the twist was revealed at the outset, (2) a Twist group, who experienced the film as normal, and (3) a No-Twist group, in which the twist was removed. Participants were scanned while watching the movie and while performing cued recall of specific scenes. Verbal recall was scored based on recall success, and evidence for descriptive bias toward two ways of understanding the events (specifically, whether a particular character was or was not a ghost). Importantly, this allowed the authors to show that the Twist group updated their interpretation. The authors focused on regions of the Default Mode Network (DMN) based on prior studies showing responsiveness to naturalistic memory paradigms in these areas and analyzed the fMRI data using intersubject pattern similarity analysis. Regions of the DMN carried patterns indicative of story interpretation. That is, encoding similarity was greater between the Twist and No-Twist groups than in the Spoiled group, and retrieval similarity was greater between the Twist and Spoiled groups than in the No-Twist group. The Spoiled group also showed greater pattern similarity with the Twist group's recall than the No-Twist group's recall. The authors also report a weaker effect of greater pattern similarity between the Spoiled group's encoding and the Twist group's recall than between the Twist group's own encoding and recall. Together, the data all converge on the point that one's interpretation of an event is an important determinant of the way it is represented in the brain.</p><p>This is a really nice experiment, with straightforward predictions and analyses that support the claims being made. The results build directly on a prior study by this research group showing how interpretational differences in a narrative drive distinct neural representations (Yeshurun et al., 2017), but extend an understanding of how these interpretational differences might work retrospectively. I do not have any serious concerns or problems with the manuscript, the data, or the analyses. However I have a few points to raise that, if addressed, would make for a stronger paper in my opinion.</p><p>1) My most substantive comment is that I did not find the interpretive framework to be very clear with respect to the brain regions involved. The basic effects the authors report strongly support their claims, but the particular contributions to the field might be stronger if the interpretations could be made more strongly or more specifically. In other words: the DMN is involved in updating interpretations, but how should we now think about the role of the DMN and its constituent regions as a result of this study? There are a number of ideas briefly presented about what the DMN might be doing, but it just did not feel very coherent at times. I will break this down into a few more specific points:</p><p>While many of us would agree that the DMN is likely to be involved in the phenomena at hand, I did not find that the paper communicated the logic for singularly focusing on this subset of regions very compellingly. The authors note a few studies whose main results are found in DMN regions, but I think that this could stand to be unpacked in a more theoretically interesting way in the Introduction.</p><p>Relatedly, I found the summary/description of regional effects in the Discussion to be a bit unsatisfying. The various pattern similarity comparisons yielded results that were actually quite nonoverlapping among DMN regions, which was not really unpacked. To be clear, it is not a 'problem' that the regional effects varied from comparison to comparison, but I do think that a more theoretical exploration of what this could mean would strengthen the paper. To the authors' credit, they describe mPFC effects through the lens of schemas, but this stands in contrast to many other regions which do not receive much consideration.</p><p>Finally, although there is evidence that regions of the DMN act in a coordinated way under some circumstances, there is also ample evidence for distinct regional contributions to cognitive processes, memory being just one of them (e.g., Cooper &amp; Ritchey, 2020; Robin &amp; Moscovitch, 2017; Ranganath &amp; Ritchey, 2012). The authors themselves introduce the idea of temporal receptive windows in a cortical hierarchy, and while DMN regions do appear to show slower temporal drift than sensory areas, those studies show regional differences in pattern stability across time even within DMN regions. Simply put, it is worth considering whether it is ideal to treat the DMN as a singular unit.</p></disp-quote><p>Thank you for your helpful comments. We added text to the introduction and discussion to address your point:</p><disp-quote content-type="editor-comment"><p>Introduction:</p></disp-quote><p>“The brain’s default mode network (DMN)—comprising the posterior medial cortex, medial prefrontal cortex, temporoparietal junction, and parts of anterior temporal cortex—was originally described as an intrinsic or “task-negative” network, activated when participants are not engaged with external stimuli (Raichle et al. 2001, Buckner et al 2008). […] Building on this foundation of prior work on the DMN, we asked whether we could find neural evidence for the retroactive influence of new knowledge on past memories.”</p><disp-quote content-type="editor-comment"><p>Discussion :</p></disp-quote><p>“In addition to mPFC, right precuneus and parts of temporal cortex exhibited significantly higher pattern similarity in the “twist” and “spoiled” groups who recalled the movie with the same interpretation. […] This transformation could affect how different regions and sub-systems of DMN represent memories, and suggests that the concerted activity of multiple subsystems and neural mechanisms might be at play during encoding, recall and successful updating of naturalistic event memories.”</p><disp-quote content-type="editor-comment"><p>2) I think that some direct comparison to regions outside the DMN would speak to whether the DMN is truly unique in carrying the key representations being discussed here. I was reluctant to suggest this because I think that the authors are justified in expecting that DMN regions would show the effects in question. However, there really is no &quot;null&quot; comparison here wherein a set of regions not expected to show these effects (e.g., a somatosensory network, or the frontoparietal network) in fact do not show them. There are not really controls or key differences being hypothesized across different conditions or regions. Rather, we have a set of regions that may or may not show pattern similarity differences to varying degrees, which feels very exploratory. The inclusion of some principled control comparisons, etc. would bolster these findings. The authors do include a whole-brain analysis in Supplementary Figure 1, which indeed produced many DMN regions. However, notably, regions outside the DMN such as the primary visual cortex and mid-cingulate cortex appear to show significant effects (which, based on the color bar, might actually be stronger than effects seen in the DMN). Given the specificity of the language in the paper in terms of the DMN, I think that some direct regional or network-level comparison is needed.</p></disp-quote><p>In the original submission, we included additional analyses for visual and somatosensory networks, which we hypothesized would serve as control networks. Following your comment, in the revision, we added a separate section (included below) more thoroughly examining these analyses. We also added text to the results and discussion to explain our interpretation of these findings.</p><p>Changes in neural representations beyond DMN</p><p>“We focused our core analyses on regions of the default mode network. Prior work has shown that multimodal neural representations of naturalistic events (e.g. movie scenes) are similar across encoding (movie-watching or story-listening) and verbal recall of the same events in the DMN (Chen et al., 2017; Zadbood et al., 2017). […] In the encoding-encoding comparison, several ROIs from the visual and somatomotor networks showed relatively strong effects as well (see Discussion).</p><p>In addition, we qualitatively reproduced our results by performing an ROI-based whole brain analysis (Appendix-Figure 3, p &lt; 0.01 uncorrected). This analysis confirmed the importance of DMN regions for updating neural event representations. However, strong differences in pISC in the hypothesized direction were also observed in a handful of other non-DMN regions, including ROIs partly overlapping with anterior cingulate cortex and dorsolateral prefrontal cortex (see Discussion).”</p><p>Discussion:</p><p>“While our main goal in this paper was to examine how neural representations of naturalistic events change in the DMN, we also examined visual and somatosensory networks. […] These results suggest that both the &quot;spoiled&quot; manipulation and the &quot;twist&quot; may recruit top-down control and conflict monitoring processes during naturalistic viewing and recall.”</p><disp-quote content-type="editor-comment"><p>3) If I understand correctly, the main analyses of the fMRI data were limited to across-group comparisons of &quot;critical scenes&quot; that were maximally affected by the twist at the end of the movie. In other words, the analyses focused on the scenes whose interpretation hinged on the &quot;doctor&quot; versus &quot;ghost&quot; interpretation. I would be interested in seeing a comparison of &quot;critical&quot; scenes directly against scenes where the interpretation did not change with the twist. This &quot;critical&quot; versus &quot;non-critical&quot; contrast would be a strong confirmatory analysis that could further bolster the authors' claims, but on the other hand, it would be interesting to know whether the overall story interpretation led to any differences in neural patterns assigned to scenes that would not be expected to depend on differences in interpretation. (As a final note, such a comparison might provide additional analytical leverage for exploring the effect described in Figure 3B, which did not survive correction for multiple comparisons.)</p></disp-quote><p>This is a helpful suggestion, and we’ve added an analysis addressing your comment. We found that the interaction index capturing the difference between the three groups was stronger for the critical scenes than for the non-critical scenes for almost all DMN ROIs.</p><p>The role of scene content</p><p>“In the prior analyses, we focused on “critical scenes”, selected based on ratings from four raters who quantified the influence of the twist on the interpretation of each scene (see Methods). […] The interaction score across all DMN ROIs was significantly higher in “critical scenes” than all scenes (t(23) = 7.19, p = 2.53 x 10<sup>-7</sup>) and non-critical scenes (t(23) = 7.3, p = 1.95 x 10<sup>-7</sup>). These results show that critical scenes are indeed responsible for the observed pISC differences across groups.”</p><disp-quote content-type="editor-comment"><p>4) I appreciate the code being made available and that the neuroimaging data will be made available soon. I would also appreciate it if the authors made the movie stimulus and behavioral data available. The movie stimulus itself is of interest because it was edited down, and it would be nice for readers to be able to see which scenes were included.</p></disp-quote><p>Unfortunately due to copyright, we cannot share the movie stimulus outright. However, we will share the timing of the cuts used, as well as the time-stamped transcripts of verbal recall.</p><disp-quote content-type="editor-comment"><p>To sum up, I think that this is a great experiment with a lot of strengths. The design is fairly clean (especially for a movie stimulus), the analyses are well reasoned, and the data are clear. The only weaknesses I would suggest addressing are with regards to how the DMN is being described and evaluated, and the communication of how this work informs the field on a theoretical level.</p><p>Reviewer #3 (Recommendations for the authors):</p><p>I want to emphasize that I am a big fan of the study and the approach overall. It is very well done, the results are clear and interesting, and the paper is overall well constructed. Below, I will expand on some of the points I raised in the public review, and provide some suggestions for how they might be addressed.</p><p>1) My first point dealt with asking for a somewhat stronger explanation for a focus on the DMN, and the question of how the reader should update their model of the DMN on the basis of these results. The updating phenomenon is certainly interesting, and as I noted in the public review, a focus on the DMN is sensible. However, I think this focus could be more clearly justified. The results themselves were a bit inconsistent in terms of which specific DMN regions showed pattern similarity effects, and I found myself wondering what this might mean. A bit more unpacking of this could be helpful. Beyond these points, however, there are theoretical frameworks arguing pretty compellingly that subsystems of the DMN may uniquely contribute to cognition (e.g., Maureen Ritchey's and Morris Moscovitch's ideas). This is a bit at odds with treating the DMN as a single unit. While I want to be clear that I do not think it is necessarily wrong to do so in this case, it does warrant some consideration.</p></disp-quote><p>Thank you for clarifying your points. We hope our added text in discussion addresses your concern.</p><disp-quote content-type="editor-comment"><p>2) As I noted in the public review, I hesitated to bring this up. However, some direct comparison of DMN vs. non-DMN would really bolster the results and the claims in my opinion. This would also go a long way in addressing my points above.</p></disp-quote><p>It was done.</p><disp-quote content-type="editor-comment"><p>3) I was not sure when writing this comment whether this &quot;critical&quot; versus &quot;non-critical&quot; analysis was tried, but in my view, it could serve to bolster the findings being presented in the paper currently. And as I noted in the public review, on the other hand, it would be interesting to know if the effects of the twist on neural patterns reached beyond the &quot;critical&quot; scenes into a general interpretation of the story.</p></disp-quote><p>This was a great suggestion and provided interesting results that we now include in the paper.</p></body></sub-article></article>