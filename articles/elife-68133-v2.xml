<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">68133</article-id><article-id pub-id-type="doi">10.7554/eLife.68133</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Coding of chromatic spatial contrast by macaque V1 neurons</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-162674"><name><surname>De</surname><given-names>Abhishek</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2978-473X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-93886"><name><surname>Horwitz</surname><given-names>Gregory D</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5130-5259</contrib-id><email>ghorwitz@uw.edu</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00cvxb145</institution-id><institution>Graduate Program in Neuroscience, University of Washington</institution></institution-wrap><addr-line><named-content content-type="city">Seattle</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00cvxb145</institution-id><institution>Department of Physiology and Biophysics, Washington National Primate Research Center, University of Washington</institution></institution-wrap><addr-line><named-content content-type="city">Seattle</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Pasternak</surname><given-names>Tatiana</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01s5ya894</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Moore</surname><given-names>Tirin</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00f54p054</institution-id><institution>Stanford University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>11</day><month>02</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e68133</elocation-id><history><date date-type="received" iso-8601-date="2021-03-05"><day>05</day><month>03</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2022-02-01"><day>01</day><month>02</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2021-02-14"><day>14</day><month>02</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.02.12.430975"/></event></pub-history><permissions><copyright-statement>© 2022, De and Horwitz</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>De and Horwitz</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-68133-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-68133-figures-v2.pdf"/><abstract><p>Color perception relies on comparisons between adjacent lights, but how the brain performs these comparisons is poorly understood. To elucidate the underlying mechanisms, we recorded spiking responses of individual V1 neurons in macaque monkeys to pairs of stimuli within the classical receptive field (RF). We estimated the spatial-chromatic RF of each neuron and then presented customized colored edges using a closed-loop technique. We found that many double-opponent (DO) cells, which have spatially and chromatically opponent RFs, responded to chromatic contrast as a weighted sum, akin to how other V1 neurons responded to luminance contrast. Yet other neurons integrated chromatic signals nonlinearly, confirming that linear signal integration is not an obligate property of V1 neurons. The functional similarity of cone-opponent DO cells and cone non-opponent simple cells suggests that these two groups may share a common underlying circuitry, promotes the construction of image-computable models for full-color image representation, and sheds new light on V1 complex cells.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>color</kwd><kwd>double-opponent</kwd><kwd>simple cell</kwd><kwd>V1</kwd><kwd>macaque</kwd><kwd>linearity</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000053</institution-id><institution>National Eye Institute</institution></institution-wrap></funding-source><award-id>EY018849</award-id><principal-award-recipient><name><surname>Horwitz</surname><given-names>Gregory D</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000052</institution-id><institution>Office of the Director</institution></institution-wrap></funding-source><award-id>OD010425</award-id><principal-award-recipient><name><surname>Horwitz</surname><given-names>Gregory D</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000053</institution-id><institution>National Eye Institute</institution></institution-wrap></funding-source><award-id>EY01730</award-id><principal-award-recipient><name><surname>Horwitz</surname><given-names>Gregory D</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000026</institution-id><institution>National Institute on Drug Abuse</institution></institution-wrap></funding-source><award-id>DA033461</award-id><principal-award-recipient><name><surname>De</surname><given-names>Abhishek</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Many V1 double-opponent cells integrate light information across their receptive fields as linearly as simple cells do.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Color depends on the spectral composition and spatial organization of lights (<xref ref-type="bibr" rid="bib10">Brown and MacLeod, 1997</xref>; <xref ref-type="bibr" rid="bib51">Kraft and Brainard, 1999</xref>; <xref ref-type="bibr" rid="bib59">Monnier and Shevell, 2003</xref>; <xref ref-type="bibr" rid="bib71">Shevell and Monnier, 2005</xref>; <xref ref-type="bibr" rid="bib86">Xian and Shevell, 2004</xref>). The joint spectral and spatial statistics of lights in natural scenes are critical for object recognition, visual memory, and scene segmentation (<xref ref-type="bibr" rid="bib31">Fine et al., 2003</xref>; <xref ref-type="bibr" rid="bib74">Spence et al., 2006</xref>; <xref ref-type="bibr" rid="bib85">Wurm et al., 1993</xref>). Despite its importance for these critical functions, however, the spatial integration of spectral signals by neurons in the visual system is poorly understood.</p><p>Some V1 neurons combine signals from all cone photoreceptor types (from which they receive any input at all) with the same sign. Many of these cone non-opponent neurons have receptive fields (RFs) consisting of side-by-side ON and OFF subfields, rendering them sensitive to luminance contrast of a particular orientation at a particular location in their RFs. Other V1 neurons combine signals from multiple cone types with opposite sign and are therefore cone-opponent. A subset of V1 cone-opponent neurons, called double-opponent (DO) cells, are both cone-opponent and spatially opponent, rendering them sensitive to chromatic edges of particular orientations at particular locations in their RFs (<xref ref-type="bibr" rid="bib19">Conway, 2001</xref>; <xref ref-type="bibr" rid="bib23">De and Horwitz, 2021a</xref>; <xref ref-type="bibr" rid="bib48">Johnson et al., 2008</xref>). V1 is the first stage of the primate visual system at which DO cells exist (<xref ref-type="bibr" rid="bib45">Hubel and Wiesel, 1968</xref>; <xref ref-type="bibr" rid="bib53">Livingstone and Hubel, 1984</xref>).</p><p>V1 is also the first stage of the primate visual system that contains simple cells (<xref ref-type="bibr" rid="bib45">Hubel and Wiesel, 1968</xref>). These cells, by definition, respond to a drifting achromatic sinusoidal grating of appropriate spatial- and temporal-frequency with spike rate modulation that exceeds the unmodulated response (<xref ref-type="bibr" rid="bib73">Skottun et al., 1991</xref>). Applied to macaque V1 neurons, this definition likely includes many DO cells (simple cells were originally characterized in cat, an animal with few if any cone-opponent V1 neurons). We use the term ‘simple cell’ in this report to refer to phase-sensitive, orientation-tuned macaque V1 neurons that are <italic>not cone-opponent</italic>, so as to distinguish them from DO cells. Cone non-opponent simple cells have much in common with DO cells (<xref ref-type="bibr" rid="bib23">De and Horwitz, 2021a</xref>). A major goal of the current study was to determine whether these two cell types integrate visual information across their RFs similarly.</p><p>Classically defined simple cells combine light information across their RFs approximately as a weighted sum (<xref ref-type="bibr" rid="bib13">Carandini et al., 1997</xref>; <xref ref-type="bibr" rid="bib25">DeAngelis et al., 1993</xref>; <xref ref-type="bibr" rid="bib43">Hubel and Wiesel, 1959</xref>; <xref ref-type="bibr" rid="bib62">Movshon et al., 1978b</xref>). These neurons can therefore be thought of as linear filters that operate on the retinal image. This insight propelled scientific progress in at least three ways. First, it facilitated the construction of image-computable models of achromatic image representation (<xref ref-type="bibr" rid="bib2">Adelson and Bergen, 1991</xref>; <xref ref-type="bibr" rid="bib55">Marr and Hildreth, 1980</xref>; <xref ref-type="bibr" rid="bib57">Mehrotra et al., 1992</xref>). Second, it shed light on cortical circuitry: simple cells receive excitation (push) and inhibition (pull) with opposite spatial tuning, and this appears to be a critical step for establishing linearity in the face of nonlinear input from the lateral geniculate nucleus (LGN) (<xref ref-type="bibr" rid="bib28">Ferster, 1988</xref>; <xref ref-type="bibr" rid="bib30">Ferster and Miller, 2000</xref>; <xref ref-type="bibr" rid="bib38">Hirsch et al., 1998</xref>; <xref ref-type="bibr" rid="bib56">McLaughlin, 2000</xref>). Third, it provided an essential building block for quantitative models of V1 complex cells (<xref ref-type="bibr" rid="bib1">Adelson and Bergen, 1985</xref>; <xref ref-type="bibr" rid="bib61">Movshon et al., 1978a</xref>), neurons in higher-order cortical areas (<xref ref-type="bibr" rid="bib12">Cadieu et al., 2007</xref>; <xref ref-type="bibr" rid="bib33">Freeman et al., 2013</xref>; <xref ref-type="bibr" rid="bib64">Okazawa et al., 2015</xref>; <xref ref-type="bibr" rid="bib69">Rust et al., 2006</xref>; <xref ref-type="bibr" rid="bib72">Simoncelli and Heeger, 1998</xref>; <xref ref-type="bibr" rid="bib82">Willmore et al., 2010</xref>), and a variety of psychophysical phenomena (<xref ref-type="bibr" rid="bib1">Adelson and Bergen, 1985</xref>; <xref ref-type="bibr" rid="bib6">Beaudot and Mullen, 2006</xref>; <xref ref-type="bibr" rid="bib35">Graham, 2011</xref>; <xref ref-type="bibr" rid="bib54">Malik and Perona, 1990</xref>; <xref ref-type="bibr" rid="bib60">Moreland and Boynton, 2017</xref>; <xref ref-type="bibr" rid="bib83">Wilson et al., 1997</xref>). Currently, all of these advances have been restricted to the achromatic domain. A similar quantitative understanding of image representation in the chromatic domain is lacking and is necessary to extend these advances to natural, full-color images.</p><p>The nature of the spatial antagonism implemented by DO cells has important implications for their contributions to vision. For example, consider a hypothetical DO cell that compares cone-opponent signals between the left and right halves of its RF (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). If the cell integrates signals linearly and with equal weight, then it is well suited for extracting vertical chromatic edges (<xref ref-type="fig" rid="fig1">Figure 1B–D</xref>). In this case, the excitation produced by a preferred light in one half of the RF can be canceled by the same light in the neighboring half. On the other hand, if the cell integrates signals nonlinearly, for example, by weighting contrast increments more heavily than contrast decrements, it would encode both edges and surfaces (<xref ref-type="fig" rid="fig1">Figure 1E and F</xref>). In this case, a light in one half of the RF would fail to cancel the same light appearing in the neighboring half.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Linear and nonlinear image filtering.</title><p>(<bold>A</bold>) A hypothetical V1 DO cell that is excited by a red light on one side of its receptive field (RF) and a green light on the other. S1 and S2 represent stimulation of the two subfields of the RF. (<bold>B</bold>) An example natural image. (<bold>C</bold>) A linear spatial filter that sums the drive from each subfield and generates a response via a spiking nonlinearity. Note that the drive from each subfield is combined linearly before being transformed by the spiking nonlinearity. (<bold>D</bold>) Linearly filtered image using filter in (<bold>C). (E</bold>) A nonlinear spatial filter that partially rectifies S1 and S2 prior to summation. (<bold>F</bold>) Nonlinearly filtered image using filter in (<bold>E</bold>). DO, double-opponent.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68133-fig1-v2.tif"/></fig><p>In this study, we measured the spatial integration of visual signals by individual V1 neurons in awake, fixating monkeys. Neurons can combine signals in many ways, but we focus on linear combinations because of their theoretical significance. Linearity is a mathematical ideal that is never fully realized by neurons, so we do not ask whether neurons integrate visual information across their RFs linearly but instead quantify how well a linear model describes spatial integration relative to a more flexible model. Models were fit to data collected using a closed-loop stimulus generation technique (<xref ref-type="bibr" rid="bib7">Bölinger and Gollisch, 2012</xref>; <xref ref-type="bibr" rid="bib42">Horwitz and Hass, 2012</xref>). The closed-loop technique involved the real-time construction of optimally oriented and positioned edges that varied in color but drove identical spike count responses. An advantage of this approach is that it is robust to static output nonlinearities.</p><p>Using this technique, we found that many DO cells responded linearly to differences in cone-opponent signals across their RFs, in quantitive similarity to how other V1 neurons responded to spatial differences in luminance. Nevertheless, a significant proportion of spatially opponent neurons combined signals across their RFs nonlinearly and in ways that could neither be attributed to a static output nonlinearity nor to a nonlinear combination of signals from linear subfields. These results contribute to our understanding of cone signal combination in V1 and reveal a population of DO cells that combine signals linearly across their RFs. We speculate that the linear DO cells provide input to complex cells, a proposal that explains several previous results and provides new insight into the functional role of color-sensitive V1 complex cells.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We analyzed the spiking responses of 98 V1 neurons from two awake, fixating male macaque monkeys (69 from Monkey 1, 29 from Monkey 2). Each neuron was visually stimulated with pixel white noise: a 10×10 grid of square, 0.2° pixels, each of which changed randomly and independently on every screen refresh. Data were analyzed by spike-triggered averaging to identify a pair of functionally distinct subfields within the classical RF. Visual stimulation was then targeted to these subfields to characterize their individual and joint contributions to the neuron’s firing rate.</p><sec id="s2-1"><title>RF characterization</title><p>Spike-triggered averages (STAs) of some neurons resembled uniform blobs, indicating invariant spectral sensitivity across the RF. Other STAs were spatially structured, for example, consisting of a set of yellow pixels adjacent to a set of blue pixels (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). These structured STAs are a signature of neurons that compare spectral information across space. If an STA did not reveal at least two distinct subfields, the neuron was passed over for data collection.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>White noise analysis of RF structure and spatial integration.</title><p>(<bold>A</bold>) Pixel white noise stimulus (left), spike-triggered average (STA; right). Two sets of contiguous pixels were yoked to create two hyperpixels, each of which stimulated one RF subfield (white outlines). (<bold>B</bold>) Hyperpixel white noise stimulus (left) and STA at the peak frame (middle). Red, green, and blue curves (right) represent the average red, green, and blue phosphor intensities, relative to background, as a function of time before a spike. (<bold>C</bold>) A firing rate map for the example DO cell. The probability of spiking (grayscale) is plotted as a function of projection magnitudes of the hyperpixel stimulus onto the right and left halves of the STA (the 45° and 135° directions, respectively). Solid and dashed white lines are contours of constant spiking probability from GLM and GQM fits to the data, respectively. The firing rate map is binned to facilitate visualization, but models were fit to unbinned data. (<bold>D</bold>) Histogram of white noise NLIs for DO cells. The NLI of the example neuron is marked with a tick, and the median is marked with a triangle. (<bold>E</bold>) Same as (<bold>D</bold>) but for simple cells. (<bold>F</bold>) Same as (<bold>D</bold>) but for the other spatially opponent cells. DO, double-opponent; GLM, generalized linear model; GQM, generalized quadratic model; NLI, nonlinearity index; RF, receptive field.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68133-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Comparison of the effective stimulus contrast across the three phases of the experiment.</title><p>(<bold>A</bold>) Stimuli from <italic>Phase 1</italic> (black) and <italic>Phase 2</italic> (red) were projected onto the spatial–temporal–chromatic STA shown in <xref ref-type="fig" rid="fig2">Figure 2B</xref>. Projection magnitudes of both stimuli occupy only a small region of the display gamut (dashed gray rectangle). (<bold>B</bold>) Two-dimensional histogram of the <italic>Phase 1</italic> projections shown in (<bold>A, C</bold>). Same as (<bold>B</bold>) but for the <italic>Phase 2</italic> stimuli. (<bold>D</bold>) The probability of spiking (the ratio of spike triggering to total stimuli) as a function of hyperpixel stimulus projections onto the two halves of the STA. Projection magnitudes are shown from the 5th to the 95th percentile. Within this range, the probability of a spike increases approximately as a linear combination of the stimulus projections, but this range is a small fraction of what can be achieved on the display. STA, spike-triggered average.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68133-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Comparison of firing rates across the three phases of the experiment.</title><p>(<bold>A</bold>) Scatterplot of the firing rates (mean ± sem) in response to pixel and hyperpixel white noise for DO cells (red), simple cells (black), and OSO cells (gray). (<bold>B</bold>) Same as (<bold>A</bold>) but comparing responses to <italic>Phase 3</italic> stimuli and hyperpixel white noise. DO, double-opponent; OSO, other spatially opponent.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68133-fig2-figsupp2-v2.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>Cone weights for DO cells (<bold>A</bold>) and simple cells (<bold>B</bold>) derived from each hyperpixel STA.</title><p>Each neuron is represented by a line joining two circles. Circle position indicates normalized cone weights and fill indicates the sign of the S-cone weight (filled = positive, unfilled = negative). DO, double-opponent; STA, spike-triggered average.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68133-fig2-figsupp3-v2.tif"/></fig><fig id="fig2s4" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 4.</label><caption><title>Overview of hyperpixel white noise nonlinearity index calculation.</title><p>(<bold>A</bold>) Probability of spiking was predicted as a function of projection magnitudes onto the two halves of the hyperpixel STA (Proj 1 and Proj 2) using a generalized linear model (GLM) and a generalized quadratic model (GQM). (<bold>B</bold>) An ROC analysis was used to assess the ability of the GLM and GQM to classify stimuli into those that preceded a spike by a response latency (inset, black) and those that did not (inset, gray). The identity line is shown for reference (dashed line). ROC, receiver operating characteristic.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68133-fig2-figsupp4-v2.tif"/></fig><fig id="fig2s5" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 5.</label><caption><title>Relationship between white noise NLI and the eigenvalue corresponding to the largest principal component (PC1) for two simulated neurons.</title><p>(<bold>A</bold>) Histogram of eigenvalues obtained by randomizing time shifts between hyperpixel white noise stimuli and evoked spikes. Eigenvalue from the unrandomized data is shown as a gray triangle. In this simulation, the spiking response was given by the product of two half-wave rectified linear subfields. This nonlinearity tightens the distribution of excitatory stimuli and therefore does not manifest in the PC1. (<bold>B</bold>) A firing rate map for the simulated neuron in (<bold>A</bold>) in the same format as <xref ref-type="fig" rid="fig2">Figure 2C</xref>. Contours of constant spiking probability (white lines) are curved, and white noise NLI (0.028) is large, indicative of nonlinear spatial integration. (<bold>C, D</bold>). Same as (<bold>A, B</bold>) but for a simulated neuron with a half-wave rectified response to modulations of one color channel and a full-wave rectified response to another. This neuron has a large PC1 due to the full-wave rectification but a small white noise NLI (0.00) because the nonlinearity is hidden once the stimuli are projected onto the STA, which is the first step in the calculation of the white noise NLI. NLI, non-linearity index; STA, spike-triggered average.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68133-fig2-figsupp5-v2.tif"/></fig></fig-group><p>A major goal of these experiments was to characterize spatial integration within the RFs of DO cells. The pixel white noise stimulus is ill-suited for achieving this goal because it modulates V1 neurons weakly, and nonlinear spatial integration might appear linear in response to small perturbations. To drive the neurons more effectively, we customized the stimulus for each neuron studied. From the pixel white noise STA, we identified two contiguous groups of pixels, each covering an RF subfield, and yoked each group into a ‘hyperpixel’ (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). White noise modulation of the two hyperpixels stimulated the two subfields strongly and independently (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>), driving a wide range of firing rates (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>).</p><p>On the basis of responses to the hyperpixel white noise stimulus, neurons with spatially opponent RFs were classified into three categories. The largest category consisted of neurons with a significant excitatory stimulus feature that was distinct from the STA (n=35, see Material and methods). Some of these neurons may have been complex cells, a classification that is inconsistent with the classical definitions of simple cells and DO cells. These neurons were therefore given the designation ‘other spatially opponent‘ (OSO). For the 63 cells not classified as OSO by this criterion, cone weights were computed and analyzed. An additional 12 neurons with cone weights insufficient for a decisive cone-opponent or non-opponent classification were also classified as OSO. The remaining 51 neurons were divided into DO cells and simple cells on their basis of cone-opponency. Altogether, 26 neurons were classified as simple cells, 25 were classified as DO cells, and 47 were classified as OSO cells.</p><p>The two sides of the hyperpixel STAs from simple cells and DO cells were complementary, or nearly so. This complementarity was evident via a comparison between the background-subtracted red, green, and blue phosphor intensities at the two hyperpixels (Pearson’s r=–0.94±0.11 (mean ± SD) for simple cells and –0.76±0.23 for DO cells), and between cone weights derived from these RGB values (<xref ref-type="fig" rid="fig2s3">Figure 2—figure supplement 3</xref>). The results of these analyses are color space-dependent, but the fact that similar results were obtained in the physiologically relevant space of cone contrast and the device-specific space in which sampling errors are independent across color channels, attests to the spatial opponency of simple cells and DO cells in our data set.</p></sec><sec id="s2-2"><title>Measuring spatial integration using hyperpixel white noise</title><p>We quantified interactions between RF subfields using an approach similar to one used previously to study interactions between stimulus features that trigger spikes in complex cells (<xref ref-type="bibr" rid="bib68">Rust et al., 2005</xref>; <xref ref-type="bibr" rid="bib79">Touryan et al., 2002</xref>). In these previous studies, white noise stimuli were projected onto the plane spanned by the first and second principal components of the spike-triggering stimuli. Similarly, we projected the hyperpixel white noise stimuli onto the two halves of the STA (see Materials and methods: Hyperpixel white noise analysis of signal combination across subfields). These two projection values reveal how similar the stimulus was to the two halves of the hyperpixel STA: the larger the projection, the more of the STA is present in the stimulus. We visualized a firing rate map by binning stimulus projections and calculating the proportion within each bin that drove a spike (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). The probability of spiking increased with the stimulus projection onto individual RF subfields, and it rose more steeply when both projections increased together.</p><p>To analyze spatial integration between RF subfields, we fit the (unbinned) data with a generalized linear model (GLM) and a generalized quadratic model (GQM) (see Materials and methods: Hyperpixel white noise analysis of signal combination across subfields; <xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4A</xref>). We quantified the ability of the two models to classify stimuli as spike-triggering or not using receiver operating characteristic (ROC) analysis (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4B</xref>; <xref ref-type="bibr" rid="bib36">Green and Swets, 1966</xref>). Spike-triggering stimuli were defined as 15-frame-long segments of the white noise movie for which a spike occurred on the final frame.</p><p>Classification error rates of the GLM and GQM were summarized with a white noise nonlinearity index (NLI) (see Materials and methods: White noise nonlinearity index). A white noise NLI&lt;0 indicates that the GLM provides more accurate predictions than the GQM. An NLI&gt;0 indicates that the GQM provides more accurate predictions than the GLM. An NLI of 0 occurs if the GLM and GQM make identical predictions, which can occur because the GLM is a special case of the GQM with three parameters set to zero. Because of these extra parameters, the GQM always fits the training data as well or better than the GLM. To compare the two models fairly, we tested the model on data that had been held out from the fitting using tenfold cross-validation (<xref ref-type="bibr" rid="bib11">Browne, 2000</xref>).</p><p>NLIs differed across the three cell types (median white noise NLI for DO cells=0.0005, simple cells=0.0009, OSO cells=0.0034; p=0.02, Kruskal-Wallis test; <xref ref-type="fig" rid="fig2">Figure 2D–F</xref>). Comparison between simple and DO cells revealed no significant difference between them (p=0.99, Mann-Whitney U-test). To the contrary, NLIs of simple and DO cells were both lower than those of the OSO cells (p&lt;0.05, Mann-Whitney U-test). This latter result is not entirely surprising given that any neuron that had a significant excitatory stimulus feature distinct from the STA was classified as OSO (see Materials and methods: Spike-triggered covariance). However, this criterion does not force the result (<xref ref-type="fig" rid="fig2s5">Figure 2—figure supplement 5</xref>). In short, neurons that we classified as simple or DO combined signals across space with a similar degree of linearity and more linearly than other V1 neurons that also had spatially structured STAs.</p><p>In interpreting these data, it is important to note that a lack of evidence for a difference between simple and DO cells is not evidence that a difference does not exist. This experiment probed neurons with low-contrast, rapidly modulated stimuli (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). The possibility remains that differences between simple and DO cells become evident when they are tested with stimuli of higher contrast or longer duration. We tested this possibility in <italic>Phase 3</italic> of our experimental protocol, as described below.</p></sec><sec id="s2-3"><title>Measuring spatial integration using the isoresponse method</title><p>For each neuron, we found a collection of stimuli that evoked the same response. Each stimulus was spatially identical to the hyperpixel STA, but the contrast of the two hyperpixels was adjusted according to the algorithm described in Materials and methods: Contrast staircase procedure. Negative contrasts were allowed.</p><p>To appreciate the necessity of this technique, consider a classical alternative. A classic test of linearity is to present one stimulus at the RF of a recorded neuron, then another, and then both together. If the response to the combined stimulus does not equal the sum of responses to the two components, the neuron is not linear. However, this test is sensitive to nonlinearities that are logically distinct from the linearity of spatial summation and are present in otherwise linear neurons (e.g., spike firing thresholds and saturating contrast-response functions). An alternative approach is to find a collection of stimuli that evoke the same response from an isolated neuron and analyze these stimuli to identify the features they share. This approach has been used previously to study signal integration in the salamander retina and locust auditory receptor cells (<xref ref-type="bibr" rid="bib7">Bölinger and Gollisch, 2012</xref>; <xref ref-type="bibr" rid="bib34">Gollisch et al., 2002</xref>). It has also been used previously to analyze the linearity of signal integration across cone types by individual macaque V1 neurons (<xref ref-type="bibr" rid="bib42">Horwitz and Hass, 2012</xref>), but it has not been used previously to analyze the linearity of signal integration across a V1 RF.</p><p>If a neuron combines cone-contrast signals linearly across its RF, then stimuli that drive the same response will lie on lines when represented in the stimulus space shown in <xref ref-type="fig" rid="fig2">Figure 2C</xref> or any other stimulus space that is a linear transformation away from it (e.g., cone excitation difference or opponent modulation spaces [<xref ref-type="bibr" rid="bib8">Brainard, 1996</xref>]). If the stimuli lie on a curve instead of a line, the hypothesis of linear spatial summation can be rejected. This approach makes no assumptions about static nonlinearities downstream of spatial integration whereas the GLM and GQM assumed a logistic function. It also does not assume linearity of cone signal integration within individual RF subfields. This assumption was used in the GLM and GQM analyses to reduce RGB values from 15-frame-long stimulus movie fragments to two stimulus projections.</p><p>In <xref ref-type="fig" rid="fig3">Figure 3A</xref>, each point represents a stimulus, distance from the origin represents contrast relative to the background, and angle represents contrast between the two sides of the stimulus. Within this plane, a search was performed to find physically distinct stimuli that evoked the same neuronal response. Angles were selected pseudo-randomly, and distances were titrated by a staircase procedure until a target firing rate was achieved (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). To mitigate the impact of spontaneous activity on the staircase procedure, the target firing rate for each neuron exceeded the 90th percentile of the baseline firing rate distribution, and for 95/98 neurons, the target firing rate exceeded the 95th percentile (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). Target firing rates did not differ across cell types (p=0.63, Kruskal-Wallis test).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Analysis of isoresponse contours.</title><p>(<bold>A</bold>) Data from the example DO cell shown in <xref ref-type="fig" rid="fig2">Figure 2A–C</xref>. Dots indicate staircase terminations (target firing rate=30 ips) and gray dashed lines indicate staircases that exceeded the monitor gamut. Linear (green) and nonlinear (orange) fits to the data are similar. Pixel STA (to the right of the hyperpixel STA) and cone weights derived from the color weighting functions (bar plot) are also shown. (<bold>B</bold>) Same as (<bold>A</bold>) but for a simple cell (target firing rate=50 ips). L+M spectral sensitivity manifests as bright green (ON) or dark purple (OFF) when probed with RGB white noise (<xref ref-type="bibr" rid="bib18">Chichilnisky and Kalmar, 2002</xref>). (<bold>C</bold>) Same as (<bold>A</bold>) for a cell that was spatially opponent but neither simple nor DO (target firing rate=20 ips). (<bold>D</bold>) Histogram of isoresponse NLIs. NLIs of example neurons are marked with ticks, and medians are marked with triangles. (<bold>E</bold>) Scatter plot of isoresponse NLIs and white noise NLIs. Example neurons are marked with yellow asterisks. Error bars were obtained via a jackknife procedure (see Materials and methods). DO, double-opponent; NLI, non-linearity index; STA, spike-triggered average.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68133-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>An example staircase from the closed-loop procedure used to study the DO cell in <xref ref-type="fig" rid="fig2">Figure 2A</xref>.</title><p>Neuronal response (in impulses per second, ips) is plotted as a function of trial number (intervening stimuli skipped). The target firing rate was 30 ips (dashed line). (<bold>B</bold>) The projection magnitude as a function of trial number for the same staircase. The staircase termination point is defined as the projection magnitude of the stimulus presented in the final (17th) trial. DO, double-opponent.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68133-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Distribution of baseline and target firing rates during <italic>Phase 3</italic> for DO (red), simple (black), and OSO (gray) cells.</title><p>Dots indicate the target firing rates and vertical lines span the 5th to the 95th percentiles of the basline firing rate distribution. On average, the target firing rate was 15.65 standard deviations above the mean baseline firing rate. DO, double-opponent; OSO, other spatially opponent.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68133-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Zoomed-in isoresponse contours and staircase terminations from <xref ref-type="fig" rid="fig3">Figure 3A–B</xref>.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68133-fig3-figsupp3-v2.tif"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 4.</label><caption><title>Cross-validated errors from linear (absicca) and nonlinear (ordinate) fits to data from <italic>Phase 3</italic> for DO cells (red), simple cells (black), and OSO cells (gray).</title><p>Example neurons from <xref ref-type="fig" rid="fig3">Figure 3</xref> are marked with yellow asterisks. DO, double-opponent; OSO, other spatially opponent.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68133-fig3-figsupp4-v2.tif"/></fig><fig id="fig3s5" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 5.</label><caption><title>White noise and isoresponse NLIs from neurons reclassified using alternative cone weight criteria.</title><p>A luminance tuning index was calculated for each cell by weighting and summing normalized cone weights (0.83 L+0.55 M+0.03 S). This index ranges from 0 to 1. Cells were classified as DO if their index value was &lt;0.33 and they had an insignificant PC1. Cells were classified as simple if their index value was &gt;0.67 and they had an insignificant PC1. Remaining cells were classified as OSO. Histograms of white noise NLIs for DO (<bold>A</bold>), simple (<bold>B</bold>), and OSO (<bold>C</bold>) cells classified this way. White noise NLIs of DO and simple cells were similar (p=0.78, Mann-Whitney U-test) and lower than those of OSO neurons (p=0.004, Mann-Whitney U-test). (<bold>D–F</bold>) Identical to (<bold>A–C</bold>) but showing isoresponse NLIs. Isoresponse NLIs for DO and simple cells were lower than for OSO neurons (p=0.06, Mann-Whitney U-test). DO, double-opponent; NLI, nonlinearity index; OSO, other spatially opponent.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68133-fig3-figsupp5-v2.tif"/></fig></fig-group><p>For some neurons, staircase termination points lay close to a line when plotted in the stimulus space (<xref ref-type="fig" rid="fig3">Figure 3A–B</xref> &amp; <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>). This result shows that the excitation produced by a preferred light in one part of the RF can be canceled by an anti-preferred light in a neighboring part with a fixed constant of proportionality over the entire gamut of our video display. This cancelation is consistent with linearity of spatial integration (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) and not with differential sensitivity to contrast increments and decrements (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). However, not all neurons behaved this way. For some neurons, staircase termination points lay on a curve (<xref ref-type="fig" rid="fig3">Figure 3C</xref>), consistent with nonlinear spatial integration.</p><p>To determine quantitatively whether a line or a curve provided the better description of the staircase termination points, we compared linear and quadratic models fits for each neuron (see Materials and methods: Evaluating model fits to staircase termination points; <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>). We defined an isoresponse nonlinearity index (isoresponse NLI) similarly to the white noise NLI defined previously (see Materials and methods: Evaluating model fits to staircase termination points). An isoresponse NLI of 0 indicates that the linear and quadratic models made equally accurate response predictions, NLI&lt;0 indicates that the linear model predicted responses more accurately than the quadratic model, and NLI&gt;0 indicates that the quadratic model predicted responses more accurately than the linear model. Cross-validation ensured that the quadratic model did not achieve greater prediction accuracy simply by virtue of having more parameters.</p><p>Isoresponse NLIs of DO cells and simple cells were close to zero and did not differ significantly (median isoresponse NLI for DO cells=0.1007, median isoresponse NLI for simple cells=–0.0097; p=0.14, Mann-Whitney U-test; <xref ref-type="fig" rid="fig3">Figure 3D</xref>). In contrast, NLIs were greater for OSO neurons (median isoresponse NLI=0.2822, p=0.02, Kruskal-Wallis test). We conclude that neurons that we classified as simple cells and DO cells are similarly linear over the range that we were able to test given the limits of our display and that they are more linear than other neurons in V1.</p><p>Isoresponse NLIs (from <italic>Phase 3</italic> of the experiment) were positively correlated with white noise NLIs (from <italic>Phase 2</italic> of the experiment) (r=0.30, p=0.001, Spearman’s correlation; <xref ref-type="fig" rid="fig3">Figure 3E</xref>). This correlation was driven primarily by OSO cells (r=0.41, p=0.004,) and not by DO (r=0.01, p=0.95,) or simple cells (r=–0.19, p=0.34). Even for the OSO cells, however, this correlation was far from perfect. Many neurons had white noise NLIs near 0 but isoresponse NLIs&gt;&gt;0. The reason for this discrepancy is unclear but is consistent with the higher contrasts used in <italic>Phase 3</italic> engaging nonlinear mechanisms that were not engaged in <italic>Phase 2</italic>. However, we cannot rule out the possibility that isoresponse NLIs were inflated by nonstationarity in firing rate combined with the sequential measurement procedure used in <italic>Phase 3</italic>, or by other differences in the data collection or analysis procedures.</p></sec><sec id="s2-4"><title>Measuring signal integration within individual subfields</title><p>An appreciable fraction of neurons in our data set, principally those in the OSO category, were poorly described by the linear model. We asked whether the nonlinear model shown in <xref ref-type="fig" rid="fig1">Figure 1E</xref> described these neurons more accurately. Under this model, signals from the three types of cone photoreceptors combine linearly within each RF subfield and are then transformed nonlinearly prior to spatial integration.</p><p>We tested the assumption of linear combination within a subfield by regressing spikes recorded during <italic>Phase 2</italic> onto linear and nonlinear combinations of the three display primaries within each subfield. If signals from multiple cone types combine linearly within each RF subfield, the influence of that subfield on the spiking response can be summarized by a weighted sum of red, green, and blue primary intensities.</p><p>In this analysis, we treat the influence of each subfield as additive noise on the signal produced by the other. This approach is justified by the facts that the two hyperpixels in <italic>Phase 2</italic> modulated independently, and under the model, each subfield makes an additive contribution to the firing rate (<xref ref-type="fig" rid="fig4">Figure 4A</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Two models of nonlinear spatial integration.</title><p>(<bold>A</bold>) A model in which signals from the three types of cone photoreceptor are integrated linearly within a subfield. The combined cone signals within each of the subunits are transformed nonlinearly and then summed to generate a response, f(S1,S2). (<bold>B</bold>) A model in which cone signals are nonlinearly transformed within a subfield prior to linear combination. (<bold>C</bold>) An isoresponse surface of firing probability is plotted as a function of cone contrasts for stimulation of a single subfield. (<bold>D</bold>) Same as (<bold>C</bold>) but for nonlinear integration model in (<bold>B</bold>). The isoresponse surface is curved in (<bold>D</bold>) and planar in (<bold>C</bold>) because signal combination within subfields is nonlinear in (<bold>B</bold>) and linear in (<bold>A</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68133-fig4-v2.tif"/></fig><p>For each neuron, we fit four models (two models × two hyperpixels) to the hyperpixel white noise data: a GLM and a GQM that predicted spiking responses as a function of the background-subtracted RGBs at each hyperpixel (<xref ref-type="fig" rid="fig4">Figure 4</xref>). We computed model performance using ROC analysis and quantified the difference in performance of the GLM and GQM with an NLI (see Materials and methods: Hyperpixel white noise analysis of signal combination within subfields). Model performance was averaged across hyperpixels to provide a single ‘within-subfield’ NLI per neuron.</p><p>Within-subfield NLIs differed across the three cell types (p&lt;0.0001, Kruskal-Wallis test; <xref ref-type="fig" rid="fig5">Figure 5</xref>). On average, within-subfield NLIs were higher for OSO cells than for simple or DO cells (median within-subfield NLI for simple cells=–0.0016, for DO cells=–0.0003, for OSO cells=0.0047, p&lt;0.0001, Kruskal-Wallis test). This result extends to individual RF subfields the observation that simple cells and DO cells combine signals with a similar degree of linearity and shows that the nonlinear signal integration exhibited by many OSO cells is poorly described as resulting from a nonlinear combination of two linear RF subfields.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Within-subunit nonlinearity indices (NLIs) were calculated from GLMs and GQMs that predicted spikes on the basis of the RGB components of individual hyperpixels.</title><p>NLIs of example neurons in <xref ref-type="fig" rid="fig3">Figure 3</xref> are marked with ticks, and medians are marked with triangles. GLM, generalized linear model; GQM, generalized quadratic model.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68133-fig5-v2.tif"/></fig></sec><sec id="s2-5"><title>Relationship between S-cone input and signal integration across and within subfields</title><p>Many V1 neurons that are driven strongly by modulations of the S-cones are poorly described by a linear model (<xref ref-type="bibr" rid="bib40">Horwitz et al., 2005</xref>). Consistent with this observation, we found that the absolute value of the normalized S-cone weight derived from the hyperpixel STA was correlated with isoresponse NLI (r=0.23, p=0.02, Spearman’s correlation; <xref ref-type="fig" rid="fig6">Figure 6</xref>). However, S-cone weight did not correlate significantly with the other two NLIs (white noise and within-subfield, both r&lt;0.2, p&gt;0.05).</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Relationship between S-cone input and signal integration across subfields.</title><p>Scatterplot of normalized S-cone weight magnitude and isoresponse NLI. Data from example neurons are marked with yellow asterisks Note that the cone weights for OSO neurons are added for the sake of completeness but must be interpreted with caution as many of the these neurons combine cone signals nonlinearly. Cone-weights are meaningful only for linear neurons. NLI, nonlinearity index; OSO, other spatially opponent.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68133-fig6-v2.tif"/></fig></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>A fundamental goal of visual neuroscience is to characterize the transformation from lights to the spiking responses of individual neurons. In this study, we characterized the spatial integration of light by neurons in area V1 of macaques with two types of visual white noise stimulation, closed-loop isoresponse measurements, and statistical model comparisons. We found that some DO cells integrate signals across their RFs linearly, like cone non-opponent simple cells do and in contrast to other V1 neurons. We did not find strong evidence for V1 neurons that pool information linearly across cone photoreceptor types within a subfield and then nonlinearly across subfields.</p><p>Below, we compare our results to those from previous studies and discuss how our results are affected by cell classification criteria and the monkeys’ eye movements. We then discuss the implications of our results for the circuitry that underlies DO and simple cells and how these two cell types may contribute to downstream image processing. We conclude with speculations on parallels between the processing of color and other stimulus features in V1 by complex cells.</p><sec id="s3-1"><title>Relationship to previous work</title><p>Linearity in the visual system is ‘a rare and (apparently) prized commodity in neural signal processing’ (<xref ref-type="bibr" rid="bib70">Shapley, 2009</xref>). The linearity of V1 simple cells is not an accident of random convergence of LGN afferents but rather the product of specialized excitatory and inhibitory circuitry (<xref ref-type="bibr" rid="bib28">Ferster, 1988</xref>; <xref ref-type="bibr" rid="bib38">Hirsch et al., 1998</xref>; <xref ref-type="bibr" rid="bib78">Tolhurst and Dean, 1990</xref>). The discovery that V1 simple cells combine signals linearly across their RFs contributed to scientific progress in many ways. It provided a bridge between neurophysiology and the fields of psychophysics and computer vision. It provided guidance for how to characterize neuronal stimulus tuning efficiently. It served as a basis for more elaborate models; all V1 neurons exhibit some degree of nonlinearity, but the linear model remains a cornerstone of even nonlinear V1 models (<xref ref-type="bibr" rid="bib15">Carandini, 2006</xref>; <xref ref-type="bibr" rid="bib14">Carandini et al., 2005</xref>).</p><p>Nearly all quantitative studies of V1 spatial RF properties have used achromatic stimuli (but see <xref ref-type="bibr" rid="bib19">Conway, 2001</xref>; <xref ref-type="bibr" rid="bib20">Conway et al., 2002</xref>; <xref ref-type="bibr" rid="bib21">Conway and Livingstone, 2006</xref>; <xref ref-type="bibr" rid="bib46">Johnson et al., 2001</xref>; <xref ref-type="bibr" rid="bib48">Johnson et al., 2008</xref>). Extending quantitative RF mapping to color is complicated by the curse of dimensionality. As the dimensionality of the color space increases from 1-D (achromatic) to 3-D (full color), the number of possible spatial combinations grows exponentially. Classic workarounds include the use of gratings, which have a highly constrained spatial structure and/or cone isolating stimuli, which are most useful for analyzing neurons that combine signals linearly across cone type. Our solution was to map the RF of each neuron with 3-D (full color) white noise and then customize spatial patterns on the basis of these maps.</p><p>Three previous studies investigated spatial integration by DO cells. Using the 2-bar interaction technique, <xref ref-type="bibr" rid="bib19">Conway, 2001</xref> found that most color-sensitive V1 neurons responded maximally when a pair of bars that modulated different cone types appeared side-by-side within the RF. This maximal response exceeded the response to either bar in isolation, consistent with linearity of spatial summation as well other models (e.g., those that include an expansive nonlinearity after linear spatial summation). At least one cell was found to integrate signals nonlinearly (<xref ref-type="bibr" rid="bib19">Conway, 2001</xref>). <xref ref-type="bibr" rid="bib21">Conway and Livingstone, 2006</xref> measured the responses of DO cells to cone-isolating stimuli at individual RF locations. Most of the DO cells they studied showed clear signs of push-pull inhibition, which is correlated with linearity in V1 (<xref ref-type="bibr" rid="bib29">Ferster, 1994</xref>; <xref ref-type="bibr" rid="bib30">Ferster and Miller, 2000</xref>; <xref ref-type="bibr" rid="bib38">Hirsch et al., 1998</xref>; <xref ref-type="bibr" rid="bib78">Tolhurst and Dean, 1990</xref>). Our findings extend these results by demonstrating the linearity of spatial integration directly through simultaneous stimulation of functionally distinct RF subfields.</p><p>Most other recent studies of DO cells used cone-isolating stimuli and limited mixtures of those stimuli, which cannot completely reveal interactions among cone types (<xref ref-type="bibr" rid="bib19">Conway, 2001</xref>; <xref ref-type="bibr" rid="bib46">Johnson et al., 2001</xref>, <xref ref-type="bibr" rid="bib47">Johnson et al., 2004</xref>; <xref ref-type="bibr" rid="bib21">Conway and Livingstone, 2006</xref>; <xref ref-type="bibr" rid="bib48">Johnson et al., 2008</xref>). In contrast, we used a stimulus set that modulated all three cone types together in a variety of proportions. In further distinction from other studies, we stimulated DO cells with colored edges to confirm the spatial and spectral sensitivity inferred from the STAs.</p></sec><sec id="s3-2"><title>Cell categorization criteria</title><p>We classified neurons as OSO (other spatially opponent) if their hyperpixel STAs indicated spatial opponency and the first principal component (PC1) of hyperpixel white noise stimuli preceding spikes (PC1) was larger than expected by chance. This latter criterion was necessary to satisfy the assumptions underlying the conversion of the STA to cone weights, and it ensured that the neurons surviving this filter did not exhibit full-wave rectified responses, which would be inconsistent with the classical definitions of simple cells and DO cells.</p><p>The PC1 criterion was based on the outcome of a statistical hypothesis test and not the bimodality of a distribution (no evidence of bimodality was observed). Indeed, we suspect that DO cells and at least some OSO cells lie on a continuum. Neurons in both categories compare cone-opponent (and possibly non-opponent) signals across space and may comprise multiple distinct subtypes. We further note that some OSO cells had small NLIs, which is consistent with linear spatial integration, and some DO cells had large NLIs, consistent with nonlinear integration. This lack of a clear distinction between these cell types could be related to the fact that the PC1 and NLI are sensitive to overlapping but distinct types of nonlinearity, these measures depend on the number of spikes in different ways (the PC1 criterion was based on a statistical test, and the NLI was not), and nonlinearities that are clear with high-contrast, long-duration stimuli are not always detectable with white noise (<xref ref-type="bibr" rid="bib77">Tanabe and Cumming, 2008</xref>).</p><p>Some cells that we classified as OSO would likely have been classified as DO in other studies (e.g., <xref ref-type="bibr" rid="bib21">Conway and Livingstone, 2006</xref>; <xref ref-type="bibr" rid="bib48">Johnson et al., 2008</xref>). In our study, as in a previous one, neurons were found with STAs consistent with a DO classification but PC1s consistent with a complex cell classification (<xref ref-type="bibr" rid="bib41">Horwitz et al., 2007</xref>). Whether these neurons are more usefully classified as nonlinear DO cells, partially rectified complex cells, or something else entirely is an important question that is partly physiological and partly semantic. In any case, a major finding of this study is that a population of DO cells combines cone-opponent signals across their RFs approximately as linearly as simple cells combine non-opponent signals, a result that stands despite the existence of other V1 cells that integrate signals nonlinearly.</p><p>The cone weight criteria for inclusion into the simple cell and DO cell categories were asymmetric because the variability in estimated L- and M-cone weights is greater for non-opponent cells than for opponent cells (<xref ref-type="bibr" rid="bib41">Horwitz et al., 2007</xref>). Reclassifying DO, simple, and OSO cells with different cone weight criteria did not change the main results of this study (<xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref>).</p></sec><sec id="s3-3"><title>Eye movements</title><p>The monkeys, although rewarded for fixating, made small eye movements that moved the stimuli relative to the RF. These eye movements blurred STAs and inflated PC1s (for cells with spatially opponent RFs), but these effects were modest because the eye movements were small relative to the stimulus elements. Across experiments, the average standard deviation of horizontal and vertical eye positions (including measurement error) was 0.13°, and the largest standard deviation across all experiments was 0.18° (for reference, the size of each pixel in <italic>Phase 1</italic> was 0.2°). Neurons with RF subfields too small to produce a spatially opponent STA were passed over for data collection. Importantly for the conclusions of this study, neither the horizontal (H) nor vertical (V) standard deviation varied significantly across cell category (Kruskal-Wallis tests, p&lt;0.1) or correlated with isoresponse NLI (Spearman rank correlation coefficients, r=–0.03 (H), –0.18 (V), p&gt;0.05). The fact that we were able, for many neurons, to cancel the effect of an increase in preferred color on one side of the RF with a decrease in preferred color on the other side during <italic>Phase</italic> 3 of the experimental protocol attests to the stability of the image on the retina relative to the sizes of the RFs we studied. We conclude that eye movements affected the measurements but are unlikely to have contributed substantively to the main conclusions of this study.</p></sec><sec id="s3-4"><title>Neural circuitry underlying DO and simple cells</title><p>The spectral sensitivity of a V1 neuron is determined by the spectral sensitivity of its excitatory and inhibitory afferents. A cell that is excited by L-ON and M-ON afferents in one part of its RF, and by L-OFF and M-OFF afferents in another, is spatially opponent but not cone-opponent. Spatial linearity in such a cell could be implemented via spectrally matched push-pull inhibition: L-OFF and M-OFF inhibition from the ON subfield and L-ON and M-ON inhibition from the OFF subfield. Pooling the same afferent signals to produce cone-opponency (e.g., pairing L-OFF with M-ON and L-ON with M-OFF) with otherwise identical circuitry would produce a linear L-M DO cell.</p><p>S-cone signals, which are prevalent in DO cells and, to a lesser degree in simple cells, defy this simple explanation. S-cone ON and OFF pathways in the retina and LGN are highly asymmetric with regard to the L- and M-cone signals they carry (<xref ref-type="bibr" rid="bib76">Tailby et al., 2008</xref>; <xref ref-type="bibr" rid="bib84">Wool et al., 2019</xref>). One possibility is that these asymmetries contribute to the nonlinearity of S-cone-dominated V1 neurons.</p></sec><sec id="s3-5"><title>Contributions to downstream processing</title><p>Simple cells are thought to provide the dominant input to complex cells (<xref ref-type="bibr" rid="bib3">Alonso and Martinez, 1998</xref>; <xref ref-type="bibr" rid="bib44">Hubel and Wiesel, 1962</xref>). Under a standard model, complex cells pool signals from simple cells with overlapping RFs and shared preferred orientation (<xref ref-type="fig" rid="fig7">Figure 7A</xref>). One possibility is that some complex cells also receive input from DO cells (<xref ref-type="fig" rid="fig7">Figure 7B</xref>). We speculate that complex cells receiving (cone non-opponent) simple cell input only are luminance-sensitive (<xref ref-type="fig" rid="fig7">Figure 7C</xref>) whereas those that receive input from simple and DO cells are both color- and luminance-sensitive (<xref ref-type="fig" rid="fig7">Figure 7D</xref>). This conjecture is consistent with the observation that the preferred orientation of color-sensitive complex cells is maintained across color directions (<xref ref-type="bibr" rid="bib46">Johnson et al., 2001</xref>). It is also consistent with the observation that color-sensitive complex cells have multiple preferred color directions by STC analysis (<xref ref-type="bibr" rid="bib41">Horwitz et al., 2007</xref>) and no null directions in cone-contrast space (<xref ref-type="bibr" rid="bib42">Horwitz and Hass, 2012</xref>). Complex cells that are insensitive to chromatic modulation abound (e.g., <xref ref-type="fig" rid="fig7">Figure 7C</xref>), whereas those that are insensitive to luminance modulation are exceedingly rare, if present (<xref ref-type="bibr" rid="bib41">Horwitz et al., 2007</xref>).</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Proposed signal convergence of simple cells and DO cells onto complex cells.</title><p>(<bold>A</bold>) A hypothetical complex cell receiving input from simple cells with overlapping odd- and even-symmetric receptive fields. (<bold>B</bold>) A hypothetical color-sensitive complex cell receiving input from simple and DO cells. (<bold>C</bold>) Response of a complex cell to a drifting sinusoidal grating that modulated L- and M-cones at 3 Hz with identical contrast in phase (top) and in anti-phase (bottom). (<bold>D</bold>) Same as (<bold>C</bold>) but for a color-sensitive complex cell. Gray overlays indicate stimulus duration. Both of these neurons were recorded before the hyperpixel white noise was developed and probably would have been passed over for data collection in this study because of their phase insensitivity. DO, double-opponent.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68133-fig7-v2.tif"/></fig><p>Alternatively, the chromatic sensitivity of color-sensitive complex cells could arise entirely from DO cell inputs (<xref ref-type="bibr" rid="bib58">Michael, 1978</xref>), which have been reported to be similarly responsive to chromatic and luminance contrast (<xref ref-type="bibr" rid="bib46">Johnson et al., 2001</xref>; <xref ref-type="bibr" rid="bib47">Johnson et al., 2004</xref>; <xref ref-type="bibr" rid="bib48">Johnson et al., 2008</xref>). Yet another possibility is that it arises directly from LGN inputs. This explanation is consistent with the direct koniocellular projections to the cytochrome oxidase blobs in area V1 (<xref ref-type="bibr" rid="bib87">Xiao, 2014</xref>), but is difficult to reconcile with the sharp orientation tuning and spatial phase-invariance of some color-sensitive complex cells across color directions. These visual tuning properties would seem to require a phase- and orientation-selective upstream intermediate or else elaborate dendritic computations.</p></sec><sec id="s3-6"><title>Analogous neural coding of color and stereopsis</title><p>The stereotyped microcircuitry of area V1 contributes to vision for form, color, depth, and motion. These distinct visual modalities have distinct computational demands, but V1 circuits may contribute to each via a small set of operations that process different signals in similar ways. Parallels in the processing of binocular disparity and motion direction in V1 are well established (<xref ref-type="bibr" rid="bib2">Adelson and Bergen, 1991</xref>). We speculate that color and stereopsis have heretofore unappreciated parallels and that models of binocular disparity tuning may provide a useful guide for the study of cone-opponent and non-opponent signal combinations in V1.</p><p>A fundamental component of binocular V1 models are simple cells that linearly sum signals from the two eyes (<xref ref-type="bibr" rid="bib4">Anzai et al., 1999</xref>; <xref ref-type="bibr" rid="bib63">Ohzawa and Freeman, 1986</xref>; <xref ref-type="bibr" rid="bib67">Read and Cumming, 2003</xref>). Analogous building blocks in the color domain are simple cells and DO cells that sum cone non-opponent and cone-opponent signals with a similar degree of linearity. Binocular simple cells are thought to provide input to binocular complex cells that implement a binocular energy calculation (<xref ref-type="bibr" rid="bib67">Read and Cumming, 2003</xref>). An analogous convergence of simple cell and DO cell outputs would implement a color energy calculation (<xref ref-type="bibr" rid="bib5">Barnett et al., 2021</xref>; <xref ref-type="bibr" rid="bib42">Horwitz and Hass, 2012</xref>).</p><p>The binocular energy model, while extremely successful in describing complex cell responses, fails to account for the attenuation of responses to anti-correlated signals between the two eyes (<xref ref-type="bibr" rid="bib22">Cumming and Parker, 1997</xref>). This specialization of real V1 cells is thought to reflect the statistics of natural inputs to the visual system (<xref ref-type="bibr" rid="bib37">Haefner and Cumming, 2008</xref>). Under natural viewing conditions, binocularly correlated patterns are more common than anti-correlated patterns, and V1 neurons are specialized to encode them.</p><p>A parallel phenomenon may exist in the domain of color. Under natural viewing conditions, luminance and chromatic spatial gradients tend to be aligned, and their alignment (or misalignment) carries important information regarding the physical sources of the gradients. Edges between different materials under fixed illumination produce in-phase luminance and chromatic modulations, whereas uncorrelated variations in illumination and pigmentation, such as produced by curved three-dimensional objects of non-uniform reflectance, produce out-of-phase modulations (<xref ref-type="bibr" rid="bib16">Cavanagh, 1991</xref>; <xref ref-type="bibr" rid="bib49">Kingdom, 2003</xref>; <xref ref-type="bibr" rid="bib52">Kunsberg et al., 2018</xref>). The energy model produces phase-invariant responses and so does not account for these specializations. Whether real V1 neurons respond in accordance with the energy model or show enhanced responses to natural alignments between chromatic and luminance modulations is an important and unanswered question.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Reagent type (species) or resource</th><th align="left" valign="bottom">Designation</th><th align="left" valign="bottom">Source or reference</th><th align="left" valign="bottom">Identifiers</th><th align="left" valign="bottom">Additional information</th></tr></thead><tbody><tr><td align="left" valign="bottom">Strain, strain background (<italic>Macaca mulatta</italic>, male)</td><td align="left" valign="bottom">Monkey</td><td align="left" valign="bottom">WashingtonNational PrimateResearchCenter</td><td align="left" valign="bottom"> </td><td align="left" valign="bottom">Rhesus monkey</td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">Matlab</td><td align="left" valign="bottom">Mathworks</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://www.mathworks">https://www.mathworks</ext-link><ext-link ext-link-type="uri" xlink:href="https://www.mathworks">.com/products/matlab.</ext-link>html RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_001622">SCR_001622</ext-link></td><td align="left" valign="bottom"> </td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">Sort Client</td><td align="left" valign="bottom">Plexon</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="http://www.plexon.com">http://www.plexon.com</ext-link>RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_003170">SCR_003170</ext-link></td><td align="left" valign="bottom"> </td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">Offline Sorter</td><td align="left" valign="bottom">Plexon</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="http://www.plexon.com">http://www.plexon.com</ext-link>RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_000012">SCR_000012</ext-link></td><td align="left" valign="bottom"> </td></tr></tbody></table></table-wrap><sec id="s4-1"><title>Contact for resource sharing</title><p>Further information and requests for resources should be directed to and will be fulfilled by the Lead Contact, Gregory D. Horwitz (<ext-link ext-link-type="uri" xlink:href="https://dlmp.uw.edu/faculty/horwitz">ghorwitz@u.washington.edu</ext-link>). Data and analysis code are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/horwitzlab/Chromatic_spatial_contrast">https://github.com/horwitzlab/Chromatic_spatial_contrast</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:acecbbaeedd2a4a3c87d1144318daf0b48253a1c;origin=https://github.com/horwitzlab/Chromatic_spatial_contrast;visit=swh:1:snp:96e3b7ea8274702a72e3d11c40164c8dd46f55bd;anchor=swh:1:rev:fe8d51dc732fdc0336532ecc47cb7b18c01dc8cf">swh:1:rev:fe8d51dc732fdc0336532ecc47cb7b18c01dc8cf</ext-link>, <xref ref-type="bibr" rid="bib24">De and Horwitz, 2021b</xref>).</p></sec><sec id="s4-2"><title>General</title><p>All protocols conformed to the guidelines provided by the US National Institutes of Health and the University of Washington Animal Care and Use Committee. Data were collected from two adult male rhesus macaques (<italic>Macaca mulatta</italic>). Each monkey was surgically implanted with a titanium headpost and a recording chamber (Crist Instruments) over area V1. Eye position was monitored continuously using either an implanted monocular scleral search coil or a digital eye-tracking system (SMI iView X Hi-Speed Primate, SensoMotoric Instruments).</p></sec><sec id="s4-3"><title>Task</title><p>The monkeys sat in a primate chair 1 m from a cathode ray tube (CRT) monitor (Dell Trinitron Ultrascan P991) in a dark room during the experiments. In a subset of sessions, the distance was reduced to 0.7 m and the pixel size was changed accordingly to preserve angular subtense. During white noise presentation, the monkeys fixated a centrally located dot measuring 0.2°×0.2° and maintained their gaze within a 1.6°×1.6° fixation window. During the closed-loop isoresponse measurements, the monkeys maintained their gaze within a 0.8°×0.8° window. Successful fixation was rewarded with apple juice, and fixation breaks aborted trials.</p></sec><sec id="s4-4"><title>Monitor calibration</title><p>Monitor calibration routines were adapted from those included in Matlab Psychophysics toolbox (<xref ref-type="bibr" rid="bib9">Brainard, 1997</xref>; <xref ref-type="bibr" rid="bib50">Kleiner et al., 2007</xref>; <xref ref-type="bibr" rid="bib66">Pelli, 1997</xref>). The emission spectrum and voltage-intensity relationship of each monitor phosphor were measured with a spectroradiometer (PR650, PhotoResearch Inc). Stimuli were gamma-corrected in software to compensate for the nonlinearity of voltage-intensity relationships. The color resolution of each channel was increased from 8 to 14 bits using a Bits++ video signal processor (Cambridge Research Systems, Ltd). The monitor refreshed at 75 Hz and background was uniform gray (x=0.3, y=0.3, Y=55–75 cd/m<sup>2</sup>). Tabulated primary emission spectra and gamma-corrected background RGB levels are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/horwitzlab/Chromatic_spatial_contrast">https://github.com/horwitzlab/Chromatic_spatial_contrast</ext-link> (<xref ref-type="bibr" rid="bib24">De and Horwitz, 2021b</xref>).</p></sec><sec id="s4-5"><title>Electrophysiological recordings</title><p>We recorded from well-isolated V1 neurons (RF eccentricity: 1.3°–5.9°, median=3.6°) using extracellular tungsten microelectrodes (Frederick Haer, Inc) lowered through the dura mater via hydraulic microdrive (Stoelting Co). Electrical signals were amplified, digitized at 40 kHz, and recorded using Sort Client software (Plexon, Inc). Action potentials were identified offline using Offline Sorter software.</p></sec><sec id="s4-6"><title>Experimental protocol</title><p>Each experiment consisted of three phases. During the first phase, spatiochromatic tuning was probed with a white noise pixel stimulus and data were analyzed online by spike-triggered averaging. During the second phase, the white noise stimulus was customized to the RF of each neuron. During the third phase, high-contrast images with the same spatial structure as the <italic>Phase 2</italic> stimulus were presented for relatively long durations (300 ms). Each of these phases is detailed below.</p><sec id="s4-6-1"><title>Phase 1: pixel white noise</title><p>Each pixel white noise frame consisted of a 10×10 grid of pixels each of which subtended 0.2°×0.2° (<xref ref-type="fig" rid="fig2">Figure 2A</xref>; <xref ref-type="bibr" rid="bib41">Horwitz et al., 2007</xref>). The stimulus changed every 13.33 ms. The intensity of each phosphor at each pixel was modulated independently according to a truncated Gaussian distribution with a standard deviation that was 15% of the physically achievable range. The space-time averaged intensity of each phosphor was equal to its contribution to the background.</p><p>Neuronal responses to the pixel white noise stimulus were analyzed by spike-triggered averaging (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). In this analysis, the 15 frames preceding each spike were collected and averaged across spikes. From these 15 STA frames, we selected online the one that differed most from the background on the basis of the sum of squared elements (p&lt;0.0001, χ<sup>2</sup> test) and identified pixels that differed significantly from the background (p&lt;0.05, z-tests performed on each phosphor separately). These data were used to customize the white noise stimulus to the RF in <italic>Phase 2</italic> of the experimental protocol (see below). We selected for additional study only cells whose RFs consisted of at least two subfields with distinct chromatic preferences (<xref ref-type="fig" rid="fig2">Figure 2A</xref>).</p><p>The pixel white noise stimulus modulated neurons weakly for three reasons. First, individual stimulus pixels were small relative to V1 RFs. This was necessary to distinguish one RF subfield from another but resulted in each subfield being stimulated by independent pixel modulations that tended to cancel. Second, the pixels modulated rapidly, so multiple frames were effectively averaged together in the early visual system, prior to V1. Longer frame durations might have been preferable because spatial, not temporal, aspects of the response were of primary interest. Third, phosphor intensities were drawn from Gaussian distributions. Most of the probability mass of a Gaussian distribution is near the mean, which was identical to the background, so high-contrast pixels were improbable (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A, B</xref>). Non-Gaussian distributions complicate spike-triggered covariance analysis (<xref ref-type="bibr" rid="bib65">Paninski, 2003</xref>).</p></sec><sec id="s4-6-2"><title>Phase 2: hyperpixel white noise</title><p>For each neuron with an STA containing at least two spatially distinct subregions (with distinct chromatic preferences), we created a custom ‘hyperpixel’ white noise stimulus by yoking the pixels within each of the two subfields (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Phosphor intensities at the two yoked collections of pixels (the two hyperpixels) were modulated according to the same Gaussian distributions used in <italic>Phase 1</italic>. Pixels outside of the RF were not modulated.</p><p>Cone weights were calculated from <italic>Phase 2</italic> of the experimental protocol. For each cell, we identified the STA frame that differed maximally from the background and computed a weighted average of this frame and the two flanking frames. The weight of each frame was proportional to the sum of squared red, green, and blue intensities relative to the background. We converted these weighted STAs to cone weights that are assumed to act on cone contrast signals (<xref ref-type="bibr" rid="bib81">Weller and Horwitz, 2018</xref>). This procedure provided a pair of cone weights for each neuron, one set for each hyperpixel.</p><p>To compute a single set of cone weights for each neuron, we decomposed the weighted STA into a color weighting function and a spatial weighting function, defined as the first left- and right-singular vectors from a singular value decomposition (<xref ref-type="bibr" rid="bib24">De and Horwitz, 2021b</xref>; <xref ref-type="bibr" rid="bib39">Horwitz and Albright, 2005</xref>). This decomposition has the feature that the outer product of the color weighting function and the spatial weighting function (multiplied by the first singular value) is the rank-1 matrix that best approximates the weighted STA (<xref ref-type="bibr" rid="bib26">Eckart and Young, 1936</xref>). Taken together, the color and spatial weighting functions captured 96.7±5.0% (mean ± SD) of the variance in the weighted STAs. The color weighting function was converted to cone weights as described above. Every spatial weighting function consisted of one positive and one negative weight, because only neurons with spatially opponent RFs were analyzed.</p><p>To examine how signals were combined across the two targeted subfields, we computed the 15-frame hyperpixel STA and convolved it with the reconstructed hyperpixel stimulus movie. This operation provides two numbers for each frame that represent how strongly each short, overlapping segment of the stimulus movie drove the two RF subfields. We visualized a firing rate map from these pairs of values by binning them and then computing the proportion of stimuli within each bin that preceded a spike (<xref ref-type="bibr" rid="bib17">Chichilnisky, 2001</xref>). We also fit these data with linear and nonlinear models to examine integration across RF subfields quantitatively (see Hyperpixel white noise analysis of signal combination across subfields).</p></sec><sec id="s4-6-3"><title>Phase 3: isoresponse measurement</title><p>We selected the hyperpixel STA frame that differed most from the background and separated it into its two components, each of which stimulated one RF subfield with its preferred light (represented along the 45° and 135° directions in <xref ref-type="fig" rid="fig3">Figure 3A</xref>). We then linearly combined these two images in different proportions to create a family of stimuli that can be represented in the same plane used to construct the firing rate map in <italic>Phase 2</italic> (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). The origin of the coordinate system represents the gray background of the display. Direction represents the contrast between the two halves of the stimulus, and distance from the origin represents stimulus contrast relative to the background.</p><p>Contrast was quantified as follows. Each half of the hyperpixel STA was represented as a three-element unit vector. For example, if the STA indicated maximal sensitivity to increments of the red primary, half as much sensitivity to decrements of the green primary, and zero sensitivity to the blue primary, this vector would be [0.89 –0.46 0]. If the background was [0.5 0.5 0.5] (where ‘0’ means completely off and ‘1’ means maximum intensity), then possible stimuli included [0.589 0.454 0.5] (positive contrast), [0.411 0.546 0.5] (negative contrast), and [0.5 0.5 0.5] (zero contrast). To reduce RGB triplets to single numbers, we subtracted the background and then projected onto the unit vector: (e.g., [0.589 0.454 0.5]-[0.5 0.5 0.5]*[0.89 –0.46 0]<sup>T</sup>=0.1). This calculation provides one of the two coordinates needed to represent the stimulus as a point on a plane. The other coordinate was calculated identically, using the other half of the STA. Note that this stimulus space is different for each neuron because the axes are derived from each neuron’s hyperpixel STA.</p></sec></sec><sec id="s4-7"><title>Contrast staircase procedure</title><p>To examine interactions between subfields, we identified collections of stimuli described above that each evoked the same number of spikes using the following procedure. On each trial, the computer presented a stimulus and counted spikes from the response latency, defined as the peak frame of the hyperpixel STA from <italic>Phase 2,</italic> until the end of the stimulus presentation. This spike count was compared to an experimenter-defined target response (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1A</xref>). If the spike count was lower than the target response, the contrast of the image was increased by a factor of 1.35. If the spike count exceeded the target response, the contrast was decreased by a factor of 0.65. This process continued until a reversal occurred. A reversal is a response that exceeded the target response after having fallen below it on the previous stimulus presentation or a response that fell below the target having exceeded it on the previous stimulus presentation. After each reversal, the change in contrast per trial decreased by 25% (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1B</xref>). The staircase halted after seven reversals or whenever the contrast exceeded the physical limitations of the display. Staircase termination points were taken as estimates of the contrast that evoked the target response. Presentations of stimuli in pairs of directions in the stimulus space were randomly interleaved to mitigate non-stationarity due to adaptation. Each stimulus was presented for 300 ms and was separated from the preceding and subsequent stimuli by more than 1 s.</p></sec><sec id="s4-8"><title>Cell screening</title><p>We recorded from 232 well-isolated V1 neurons and made isoresponse measurements from 98 of them. These 98 neurons were selected on the basis that they were well-isolated throughout all the three phases of the experimental protocol and had STAs with clear spatial structure. Neurons were classified as ‘simple’, ‘double-opponent,’ or ‘other spatially opponent’ on the basis of responses to hyperpixel white noise as described below.</p></sec><sec id="s4-9"><title>Spike-triggered covariance analysis</title><p>We distinguished simple cells from DO cells on the basis of cone weights, and cone weights are interpretable only under a linear model of signal combination across cone types (<xref ref-type="bibr" rid="bib81">Weller and Horwitz, 2018</xref>). To identify neurons that are poorly described by a linear model, we computed the first principal component (PC1) of the spike-triggering stimuli orthogonal to the hyperpixel STA (<xref ref-type="bibr" rid="bib40">Horwitz et al., 2005</xref>; <xref ref-type="bibr" rid="bib68">Rust et al., 2005</xref>; <xref ref-type="bibr" rid="bib79">Touryan et al., 2002</xref>). A PC1 that is larger than expected by chance reveals a nonlinear component of the cell’s response to the white noise stimulus that cannot be captured by an output nonlinearity. We assessed the significance of the PC1 by randomly shifting spike trains in time relative to the <italic>Phase 2</italic> stimulus movie, recalculating the PC1, and obtaining its eigenvalue (<xref ref-type="bibr" rid="bib68">Rust et al., 2005</xref>). This procedure was repeated 1000 times. If the largest eigenvalue from the unrandomized data exceeded 95% of the largest eigenvalues from the randomized data sets, we concluded that the PC1 was significant at the 0.05 level. Thirty-five neurons with a significant PC1 were classified as OSO on this basis.</p><p>Neurons lacking a significant PC1 were classified as simple if their L- and M-cone weights had the same sign, accounted for 80% of the total cone weight, and individually accounted for at least 10%. None of the simple cells we studied showed evidence of opponent input from the S-cones. Twenty-six cells in our data set were categorized as simple. A cell was classified as DO if it lacked a significant PC1 and had a pair of cone weights of opposite sign. Cone weights of small absolute value were ignored; to be classified as DO, a neuron either had to have (1) an S-cone weight that accounted for at least 20% of the total in addition to a pair of opponent weights, or (2) L- and M-cone weights that accounted for at least 80% jointly and 20% individually. Using these criteria, we classified 1 S−M+L, 3 S+M−L, and 2 S−M−L cells as DO by the first criterion and 19 L−M cells as DO by the second criterion. Twenty-five cells were categorized as DO. The 12 neurons that did not meet the cone weight criteria for the DO or simple cell categories were classified as OSO, leading to a total of 47 in this category.</p></sec><sec id="s4-10"><title>Luminance tuning index</title><p>To test the robustness of the results to the cone weight classification criteria, we segregated simple cells from DO cells using an alternative approach. For each neuron, we calculated a luminance tuning index (<xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref>) by projecting the normalized cone weights of each cell onto a set of cone weights derived from the photopic luminous efficiency function. The luminance cone weights were estimated by regressing the <xref ref-type="bibr" rid="bib80">Vos, 1978</xref> 2° photopic luminosity function onto the Stockman-Macleod-Johnson 2° cone fundamentals to find the best-fitting coefficients (0.83L+0.55M+0.03S) (<xref ref-type="bibr" rid="bib75">Stockman et al., 1993</xref>; <xref ref-type="bibr" rid="bib80">Vos, 1978</xref>). The luminance tuning index ranged from 0 to 1. Cells were classified as DO if their index value was &lt;0.33 and if they lacked a significant PC1 (n=22). Cells were classified as simple if their index value was &gt;0.67 and if they lacked a significant PC1 (n=27). The remaining 49 neurons were classified as OSO.</p></sec><sec id="s4-11"><title>Hyperpixel white noise analysis of signal combination across subfields</title><p>We fit the data from <italic>Phase 2</italic> of the experimental protocol with a GLM and a GQM.</p><p>The GLM had the form:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf1"><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>p</mml:mi></mml:math></inline-formula> is the predicted response of the neuron and <inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> are the projection magnitudes of the 15-frame-long segments of the stimulus movie onto the two halves of the temporo-chromatic hyperpixel STA. <inline-formula><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> , <inline-formula><mml:math id="inf5"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> , and <inline-formula><mml:math id="inf6"><mml:mi>c</mml:mi></mml:math></inline-formula> were fit using the Matlab routine <italic>fitglm</italic> to maximize the binomial likelihood of a spike. <italic>Predresp</italic> is constrained to be ≤1 because it represents a spiking probability, and the constant term, <inline-formula><mml:math id="inf7"><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> , captures the overall responsivity of the cell.</p><p>The GQM had the form:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-12"><title>Evaluating the performance of generalized linear and quadratic models</title><p>We quantified the ability of the fitted models to predict whether or not each stimulus segment evoked a spike using ROC analysis (<xref ref-type="bibr" rid="bib36">Green and Swets, 1966</xref>). Classification error was defined as one minus the area under the ROC curve (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2B</xref>). To avoid overfitting, the model was fit with 90% of the data and tested on the remaining 10%. The white noise nonlinearity index (white noise NLI) for each cell was defined as:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mi>W</mml:mi><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mtext> </mml:mtext><mml:mi>N</mml:mi><mml:mi>L</mml:mi><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi>C</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mtext> </mml:mtext><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>L</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mtext> </mml:mtext><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>Q</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where the median is taken is taken across 10 cross-validation data partitions.</p></sec><sec id="s4-13"><title>Error estimates of NLIs</title><p>The reliability of the NLIs was assessed using a jackknife resampling procedure. As described above, a GLM and GQM classification error was computed from multiple data partitions. An NLI was calculated from each pair of classification errors, and the spread of NLIs was quantified using the standard jackknife formula (<xref ref-type="bibr" rid="bib27">Efron and Tibshirani, 1994</xref>).</p></sec><sec id="s4-14"><title>Model fits to isoresponse staircase termination points</title><p>To assess the linearity of signal integration across the gamut of our video display, we fit the staircase termination points from <italic>Phase 3</italic> with linear and quadratic models. Fitting was performed using a standard inbuilt Matlab routine for function minimization (<italic>fmincon</italic>) to minimize the Tukey-bisquare objective function (<xref ref-type="bibr" rid="bib32">Fox, 2002</xref>).</p><p>Searches for stimuli that produced the target response were conducted in multiple directions of the stimulus space (e.g., <xref ref-type="fig" rid="fig3">Figure 3A–C</xref>), but angles were fixed. We therefore fit the data with a model that assumes radial error. The linear model can be written as:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mi>A</mml:mi><mml:mtext> </mml:mtext><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>θ</mml:mi><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:mtext> </mml:mtext><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></disp-formula><disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:msup><mml:mi>n</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mfrac><mml:mi>y</mml:mi><mml:mi>x</mml:mi></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>Where <inline-formula><mml:math id="inf8"><mml:mi>x</mml:mi></mml:math></inline-formula> represents the projection of each image onto one hyperpixel of the STA and <inline-formula><mml:math id="inf9"><mml:mi>y</mml:mi></mml:math></inline-formula> represents the projection onto the other hyperpixel (see <italic>Phase 3: Isoresponse measurement</italic>). <inline-formula><mml:math id="inf10"><mml:mi>A</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf11"><mml:mi>B</mml:mi></mml:math></inline-formula> are fitted parameters. Fitting was performed on <italic>log(r</italic>), not <italic>r</italic>, because contrast was adjusted multiplicatively, not additively, during the staircase procedure.</p><p>The quadratic model can be written as:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mi>A</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>B</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mtext> </mml:mtext><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>C</mml:mi><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>θ</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>θ</mml:mi><mml:mo>+</mml:mo><mml:mi>D</mml:mi><mml:mi>r</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>θ</mml:mi><mml:mo>+</mml:mo><mml:mi>E</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf12"><mml:mi>A</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf13"><mml:mi>B</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf14"><mml:mi>C</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf15"><mml:mi>D</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf16"><mml:mi>E</mml:mi></mml:math></inline-formula> are fitted parameters.</p></sec><sec id="s4-15"><title>Evaluating model fits to staircase termination points</title><p>We evaluated the quality of model fits by calculating the sum of Tukey-bisquared errors between the data and the model predictions. To avoid overfitting, we used leave-one-out cross-validation. The isoresponse nonlinearity index (isoresponse NLI) was defined as the median of the ratio of cross-validated linear model errors and quadratic model errors in logarithmic units.<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:mi>I</mml:mi><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mtext> </mml:mtext><mml:mi>N</mml:mi><mml:mi>L</mml:mi><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mi>C</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mtext> </mml:mtext><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>L</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>v</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mtext> </mml:mtext><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>Q</mml:mi><mml:mi>u</mml:mi><mml:mi>a</mml:mi><mml:mi>d</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>NLI reliability was quantitated with the jackknife procedure described above.</p></sec><sec id="s4-16"><title>Hyperpixel white noise analysis of signal combination within subfields</title><p>To test the nonlinear model in <xref ref-type="fig" rid="fig1">Figure 1C</xref>, we fit the data collected during <italic>Phase 2</italic> of the experiment with GLMs and GQMs that predicted spikes on the basis of RGB values at individual hyperpixels. The models classified the RGB triplet on each frame as belonging to the spike-triggering or non-spike-triggering ensemble (<xref ref-type="fig" rid="fig2s4">Figure 2—figure supplement 4</xref>).</p><p>The latency of the response, which was needed to associate stimulus frames with spikes, was based on the time of the hyperpixel STA peak. Unlike the ‘across-subfield’ analysis, we only selected a single frame for ‘within-subfield’ analysis. Basing the within-subfield analysis on individual frames bypassed the assumption of linear temporal integration required to reduce multi-frame segments to single average RGB values and allowed us to focus on the integration of RGB values within a single subfield.</p><p>The GLM had the form:<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>G</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mi>B</mml:mi><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf17"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> , <inline-formula><mml:math id="inf18"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> , <inline-formula><mml:math id="inf19"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> , and <inline-formula><mml:math id="inf20"><mml:mi>c</mml:mi></mml:math></inline-formula> are fitted parameters. The output of the model is the probability of spiking given a triplet of background-subtracted red, green, and blue phosphor intensities (<inline-formula><mml:math id="inf21"><mml:mi>R</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf22"><mml:mi>G</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf23"><mml:mi>B</mml:mi></mml:math></inline-formula>).</p><p>The GQM had the form:<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:mi>R</mml:mi><mml:mi>G</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msub><mml:mi>G</mml:mi><mml:mi>B</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>6</mml:mn></mml:mrow></mml:msub><mml:mi>R</mml:mi><mml:mi>B</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>7</mml:mn></mml:mrow></mml:msub><mml:mi>R</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>8</mml:mn></mml:mrow></mml:msub><mml:mi>G</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mn>9</mml:mn></mml:mrow></mml:msub><mml:mi>B</mml:mi><mml:mo>+</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>We used tenfold cross-validation to avoid overfitting and quantified the ability of the models to predict whether a stimulus frame preceded a spike or not using an ROC as described above. In total, 40 models were fit per neuron (one GLM and one GQM at each hyperpixel with tenfold cross-validation for each). To report a single value for each neuron, we averaged classification error rates across subfields and computed the median across cross-validation folds using the formula:<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:mi>W</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mtext> </mml:mtext><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>b</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi><mml:mtext> </mml:mtext><mml:mi>N</mml:mi><mml:mi>L</mml:mi><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>b</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:mi>C</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mtext> </mml:mtext><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>L</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>b</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:mi>C</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mtext> </mml:mtext><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>G</mml:mi><mml:mi>Q</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-17"><title>Drifting gratings</title><p>Two neurons were stimulated with drifting, sinusoidal gratings (two cycles per degree, 3 Hz, 1° diameter circular aperture) that modulated L- and M-cones with identical contrasts either in phase (L+M) or in anti-phase (L−M) (<xref ref-type="fig" rid="fig7">Figure 7</xref>). These neurons were not tested with the standard protocol.</p></sec></sec></body><back><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Formal analysis, Investigation, Methodology, Software, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Methodology, Writing – original draft, Writing – review and editing, Funding acquisition, Supervision</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>This study was performed in strict accordance with the recommendations in the Guide for the Care and Use of Laboratory Animals of the National Institutes of Health. All of the animals were handled according to approved institutional animal care and use committee (IACUC) protocol (#4167-01) of the University of Washington. All surgery was performed under sevoflurane anesthesia, and every effort was made to minimize suffering.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-68133-transrepform1-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All data associated with this study are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/horwitzlab/Chromatic_spatial_contrast">https://github.com/horwitzlab/Chromatic_spatial_contrast</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:acecbbaeedd2a4a3c87d1144318daf0b48253a1c;origin=https://github.com/horwitzlab/Chromatic_spatial_contrast;visit=swh:1:snp:96e3b7ea8274702a72e3d11c40164c8dd46f55bd;anchor=swh:1:rev:fe8d51dc732fdc0336532ecc47cb7b18c01dc8cf">swh:1:rev:fe8d51dc732fdc0336532ecc47cb7b18c01dc8cf</ext-link>).</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><collab>De and Horwitz</collab></person-group><year iso-8601-date="2021">2021</year><data-title>Chromatic spatial contrast</data-title><source>Github</source><pub-id pub-id-type="accession" xlink:href="https://github.com/horwitzlab/Chromatic_spatial_contrast">fe8d51d</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>The authors thank Yasmine El-Shamayleh, Fred Rieke, Greg Field, and Jacob Yates for comments on the manuscript. This work was funded by NIH EY018849 to Gregory D Horwitz, NIH/ORIP Grant P51OD010425, and NEI Center Core Grant for Vision Research P30 EY01730 to the University of Washington and R90 DA033461 (Training Program in Neural Computation and Engineering) to Abhishek De.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adelson</surname><given-names>EH</given-names></name><name><surname>Bergen</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Spatiotemporal energy models for the perception of motion</article-title><source>Journal of the Optical Society of America. A, Optics and Image Science</source><volume>2</volume><fpage>284</fpage><lpage>299</lpage><pub-id pub-id-type="doi">10.1364/josaa.2.000284</pub-id><pub-id pub-id-type="pmid">3973762</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Adelson</surname><given-names>EH</given-names></name><name><surname>Bergen</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="1991">1991</year><chapter-title>The Plenoptic Function and the Elements of Early Vision</chapter-title><person-group person-group-type="editor"><name><surname>Landy</surname><given-names>MS</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><source>Computational Models of Visual Processing</source><publisher-name>The MIT Press</publisher-name><fpage>3</fpage><lpage>20</lpage></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alonso</surname><given-names>JM</given-names></name><name><surname>Martinez</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Functional connectivity between simple cells and complex cells in cat striate cortex</article-title><source>Nature Neuroscience</source><volume>1</volume><fpage>395</fpage><lpage>403</lpage><pub-id pub-id-type="doi">10.1038/1609</pub-id><pub-id pub-id-type="pmid">10196530</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anzai</surname><given-names>A</given-names></name><name><surname>Ohzawa</surname><given-names>I</given-names></name><name><surname>Freeman</surname><given-names>RD</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Neural mechanisms for processing binocular information I. Simple cells</article-title><source>Journal of Neurophysiology</source><volume>82</volume><fpage>891</fpage><lpage>908</lpage><pub-id pub-id-type="doi">10.1152/jn.1999.82.2.891</pub-id><pub-id pub-id-type="pmid">10444685</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barnett</surname><given-names>MA</given-names></name><name><surname>Aguirre</surname><given-names>GK</given-names></name><name><surname>Brainard</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A quadratic model captures the human V1 response to variations in chromatic direction and contrast</article-title><source>eLife</source><volume>10</volume><elocation-id>e65590</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.65590</pub-id><pub-id pub-id-type="pmid">34342580</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beaudot</surname><given-names>WHA</given-names></name><name><surname>Mullen</surname><given-names>KT</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Orientation discrimination in human vision: psychophysics and modeling</article-title><source>Vision Research</source><volume>46</volume><fpage>26</fpage><lpage>46</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2005.10.016</pub-id><pub-id pub-id-type="pmid">16325222</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bölinger</surname><given-names>D</given-names></name><name><surname>Gollisch</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Closed-loop measurements of iso-response stimuli reveal dynamic nonlinear stimulus integration in the retina</article-title><source>Neuron</source><volume>73</volume><fpage>333</fpage><lpage>346</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.10.039</pub-id><pub-id pub-id-type="pmid">22284187</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Brainard</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1996">1996</year><chapter-title>Cone contrast and opponent modulation color spaces</chapter-title><person-group person-group-type="editor"><name><surname>Kaiser</surname><given-names>PK</given-names></name><name><surname>Boynton</surname><given-names>RM</given-names></name></person-group><source>Human Color Vision</source><publisher-loc>Washington, DC</publisher-loc><publisher-name>Optical Society of America</publisher-name><fpage>563</fpage><lpage>578</lpage></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The Psychophysics Toolbox</article-title><source>Spatial Vision</source><volume>10</volume><fpage>433</fpage><lpage>436</lpage><pub-id pub-id-type="pmid">9176952</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>RO</given-names></name><name><surname>MacLeod</surname><given-names>DI</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Color appearance depends on the variance of surround colors</article-title><source>Current Biology</source><volume>7</volume><fpage>844</fpage><lpage>849</lpage><pub-id pub-id-type="doi">10.1016/s0960-9822(06)00372-1</pub-id><pub-id pub-id-type="pmid">9382808</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Browne</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Cross-validation methods</article-title><source>Journal of Mathematical Psychology</source><volume>44</volume><fpage>108</fpage><lpage>132</lpage><pub-id pub-id-type="doi">10.1006/jmps.1999.1279</pub-id><pub-id pub-id-type="pmid">10733860</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cadieu</surname><given-names>C</given-names></name><name><surname>Kouh</surname><given-names>M</given-names></name><name><surname>Pasupathy</surname><given-names>A</given-names></name><name><surname>Connor</surname><given-names>CE</given-names></name><name><surname>Riesenhuber</surname><given-names>M</given-names></name><name><surname>Poggio</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A model of V4 shape selectivity and invariance</article-title><source>Journal of Neurophysiology</source><volume>98</volume><fpage>1733</fpage><lpage>1750</lpage><pub-id pub-id-type="doi">10.1152/jn.01265.2006</pub-id><pub-id pub-id-type="pmid">17596412</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Linearity and normalization in simple cells of the macaque primary visual cortex</article-title><source>The Journal of Neuroscience</source><volume>17</volume><fpage>8621</fpage><lpage>8644</lpage><pub-id pub-id-type="pmid">9334433</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Demb</surname><given-names>JB</given-names></name><name><surname>Mante</surname><given-names>V</given-names></name><name><surname>Tolhurst</surname><given-names>DJ</given-names></name><name><surname>Dan</surname><given-names>Y</given-names></name><name><surname>Olshausen</surname><given-names>BA</given-names></name><name><surname>Gallant</surname><given-names>JL</given-names></name><name><surname>Rust</surname><given-names>NC</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Do we know what the early visual system does?</article-title><source>The Journal of Neuroscience</source><volume>25</volume><fpage>10577</fpage><lpage>10597</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3726-05.2005</pub-id><pub-id pub-id-type="pmid">16291931</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>What simple and complex cells compute</article-title><source>The Journal of Physiology</source><volume>577</volume><fpage>463</fpage><lpage>466</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.2006.118976</pub-id><pub-id pub-id-type="pmid">16973710</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cavanagh</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1991">1991</year><chapter-title>Vision at Equiluminance</chapter-title><person-group person-group-type="editor"><name><surname>Kulikowski</surname><given-names>JJ</given-names></name><name><surname>Murray</surname><given-names>IJ</given-names></name><name><surname>Walsh</surname><given-names>V</given-names></name></person-group><source>ViIision and Visual Dysfunction: Limits of Vision</source><volume>Vol. 5</volume><publisher-loc>Boca Raton, FL</publisher-loc><publisher-name>CLC Press</publisher-name><fpage>234</fpage><lpage>250</lpage></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chichilnisky</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A simple white noise analysis of neuronal light responses</article-title><source>Network (Bristol, England)</source><volume>12</volume><fpage>199</fpage><lpage>213</lpage><pub-id pub-id-type="pmid">11405422</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chichilnisky</surname><given-names>EJ</given-names></name><name><surname>Kalmar</surname><given-names>RS</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Functional asymmetries in ON and OFF ganglion cells of primate retina</article-title><source>The Journal of Neuroscience</source><volume>22</volume><fpage>2737</fpage><lpage>2747</lpage></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Conway</surname><given-names>BR</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Spatial structure of cone inputs to color cells in alert macaque primary visual cortex (V-1)</article-title><source>The Journal of Neuroscience</source><volume>21</volume><fpage>2768</fpage><lpage>2783</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.21-08-02768.2001</pub-id><pub-id pub-id-type="pmid">11306629</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Conway</surname><given-names>BR</given-names></name><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Livingstone</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Color contrast in macaque V1</article-title><source>Cerebral Cortex</source><volume>12</volume><fpage>915</fpage><lpage>925</lpage><pub-id pub-id-type="doi">10.1093/cercor/12.9.915</pub-id><pub-id pub-id-type="pmid">12183391</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Conway</surname><given-names>BR</given-names></name><name><surname>Livingstone</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Spatial and temporal properties of cone signals in alert macaque primary visual cortex</article-title><source>The Journal of Neuroscience</source><volume>26</volume><fpage>10826</fpage><lpage>10846</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2091-06.2006</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cumming</surname><given-names>BG</given-names></name><name><surname>Parker</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Responses of primary visual cortical neurons to binocular disparity without depth perception</article-title><source>Nature</source><volume>389</volume><fpage>280</fpage><lpage>283</lpage><pub-id pub-id-type="doi">10.1038/38487</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De</surname><given-names>A</given-names></name><name><surname>Horwitz</surname><given-names>GD</given-names></name></person-group><year iso-8601-date="2021">2021a</year><article-title>Spatial receptive field structure of double-opponent cells in macaque V1</article-title><source>Journal of Neurophysiology</source><volume>125</volume><fpage>843</fpage><lpage>857</lpage><pub-id pub-id-type="doi">10.1152/jn.00547.2020</pub-id><pub-id pub-id-type="pmid">33405995</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>De</surname><given-names>A</given-names></name><name><surname>Horwitz</surname><given-names>GD</given-names></name></person-group><year iso-8601-date="2021">2021b</year><data-title>Chromatic spatial contrast</data-title><version designator="swh:1:rev:fe8d51dc732fdc0336532ecc47cb7b18c01dc8cf">swh:1:rev:fe8d51dc732fdc0336532ecc47cb7b18c01dc8cf</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:acecbbaeedd2a4a3c87d1144318daf0b48253a1c;origin=https://github.com/horwitzlab/Chromatic_spatial_contrast;visit=swh:1:snp:96e3b7ea8274702a72e3d11c40164c8dd46f55bd;anchor=swh:1:rev:fe8d51dc732fdc0336532ecc47cb7b18c01dc8cf">https://archive.softwareheritage.org/swh:1:dir:acecbbaeedd2a4a3c87d1144318daf0b48253a1c;origin=https://github.com/horwitzlab/Chromatic_spatial_contrast;visit=swh:1:snp:96e3b7ea8274702a72e3d11c40164c8dd46f55bd;anchor=swh:1:rev:fe8d51dc732fdc0336532ecc47cb7b18c01dc8cf</ext-link></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Ohzawa</surname><given-names>I</given-names></name><name><surname>Freeman</surname><given-names>RD</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Spatiotemporal organization of simple-cell receptive fields in the cat’s striate cortex. II. Linearity of temporal and spatial summation</article-title><source>Journal of Neurophysiology</source><volume>69</volume><fpage>1118</fpage><lpage>1135</lpage><pub-id pub-id-type="doi">10.1152/jn.1993.69.4.1118</pub-id><pub-id pub-id-type="pmid">8492152</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eckart</surname><given-names>C</given-names></name><name><surname>Young</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1936">1936</year><article-title>The approximation of one matrix by another of lower rank</article-title><source>Psychometrika</source><volume>1</volume><fpage>211</fpage><lpage>218</lpage><pub-id pub-id-type="doi">10.1007/BF02288367</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Efron</surname><given-names>B</given-names></name><name><surname>Tibshirani</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1994">1994</year><source>An Introduction to the Bootstrap</source><publisher-name>CRC Press</publisher-name><publisher-loc>Boca Raton</publisher-loc><pub-id pub-id-type="doi">10.1201/9780429246593</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferster</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Spatially opponent excitation and inhibition in simple cells of the cat visual cortex</article-title><source>The Journal of Neuroscience</source><volume>8</volume><fpage>1172</fpage><lpage>1180</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.08-04-01172.1988</pub-id><pub-id pub-id-type="pmid">3357015</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferster</surname><given-names>D</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Linearity of synaptic interactions in the assembly of receptive fields in cat visual cortex</article-title><source>Current Opinion in Neurobiology</source><volume>4</volume><fpage>563</fpage><lpage>568</lpage><pub-id pub-id-type="doi">10.1016/0959-4388(94)90058-2</pub-id><pub-id pub-id-type="pmid">7812146</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferster</surname><given-names>D</given-names></name><name><surname>Miller</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Neural mechanisms of orientation selectivity in the visual cortex</article-title><source>Annual Review of Neuroscience</source><volume>23</volume><fpage>441</fpage><lpage>471</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.23.1.441</pub-id><pub-id pub-id-type="pmid">10845071</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fine</surname><given-names>I</given-names></name><name><surname>MacLeod</surname><given-names>DIA</given-names></name><name><surname>Boynton</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Surface segmentation based on the luminance and color statistics of natural scenes</article-title><source>Journal of the Optical Society of America. A, Optics, Image Science, and Vision</source><volume>20</volume><fpage>1283</fpage><lpage>1291</lpage><pub-id pub-id-type="doi">10.1364/josaa.20.001283</pub-id><pub-id pub-id-type="pmid">12868634</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fox</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2002">2002</year><source>Robust Regression: An R and S-Plus Companion to Applied Regression</source><publisher-loc>Thousand Oaks, CA</publisher-loc><publisher-name>Sage Publications</publisher-name></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freeman</surname><given-names>J</given-names></name><name><surname>Ziemba</surname><given-names>CM</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A functional and perceptual signature of the second visual area in primates</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>974</fpage><lpage>981</lpage><pub-id pub-id-type="doi">10.1038/nn.3402</pub-id><pub-id pub-id-type="pmid">23685719</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gollisch</surname><given-names>T</given-names></name><name><surname>Schütze</surname><given-names>H</given-names></name><name><surname>Benda</surname><given-names>J</given-names></name><name><surname>Herz</surname><given-names>AVM</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Energy integration describes sound-intensity coding in an insect auditory system</article-title><source>The Journal of Neuroscience</source><volume>22</volume><fpage>10434</fpage><lpage>10448</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.22-23-10434.2002</pub-id><pub-id pub-id-type="pmid">12451143</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graham</surname><given-names>NV</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Beyond multiple pattern analyzers modeled as linear filters (as classical V1 simple cells): useful additions of the last 25 years</article-title><source>Vision Research</source><volume>51</volume><fpage>1397</fpage><lpage>1430</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2011.02.007</pub-id><pub-id pub-id-type="pmid">21329718</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Green</surname><given-names>DM</given-names></name><name><surname>Swets</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1966">1966</year><source>Signal Detection Theory and Psychophysics.</source><publisher-loc>New York</publisher-loc><publisher-name>Wiley</publisher-name></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haefner</surname><given-names>RM</given-names></name><name><surname>Cumming</surname><given-names>BG</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Adaptation to natural binocular disparities in primate V1 explained by a generalized energy model</article-title><source>Neuron</source><volume>57</volume><fpage>147</fpage><lpage>158</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.10.042</pub-id><pub-id pub-id-type="pmid">18184571</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hirsch</surname><given-names>JA</given-names></name><name><surname>Alonso</surname><given-names>JM</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name><name><surname>Martinez</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Synaptic integration in striate cortical simple cells</article-title><source>The Journal of Neuroscience</source><volume>18</volume><fpage>9517</fpage><lpage>9528</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.18-22-09517.1998</pub-id><pub-id pub-id-type="pmid">9801388</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horwitz</surname><given-names>GD</given-names></name><name><surname>Albright</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Paucity of chromatic linear motion detectors in macaque V1</article-title><source>Journal of Vision</source><volume>5</volume><fpage>525</fpage><lpage>533</lpage><pub-id pub-id-type="doi">10.1167/5.6.4</pub-id><pub-id pub-id-type="pmid">16097865</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horwitz</surname><given-names>GD</given-names></name><name><surname>Chichilnisky</surname><given-names>EJ</given-names></name><name><surname>Albright</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Blue-yellow signals are enhanced by spatiotemporal luminance contrast in macaque V1</article-title><source>Journal of Neurophysiology</source><volume>93</volume><fpage>2263</fpage><lpage>2278</lpage><pub-id pub-id-type="doi">10.1152/jn.00743.2004</pub-id><pub-id pub-id-type="pmid">15496484</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horwitz</surname><given-names>GD</given-names></name><name><surname>Chichilnisky</surname><given-names>EJ</given-names></name><name><surname>Albright</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Cone inputs to simple and complex cells in V1 of awake macaque</article-title><source>Journal of Neurophysiology</source><volume>97</volume><fpage>3070</fpage><lpage>3081</lpage><pub-id pub-id-type="doi">10.1152/jn.00965.2006</pub-id><pub-id pub-id-type="pmid">17303812</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horwitz</surname><given-names>GD</given-names></name><name><surname>Hass</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Nonlinear analysis of macaque V1 color tuning reveals cardinal directions for cortical color processing</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>913</fpage><lpage>919</lpage><pub-id pub-id-type="doi">10.1038/nn.3105</pub-id><pub-id pub-id-type="pmid">22581184</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><year iso-8601-date="1959">1959</year><article-title>Receptive fields of single neurones in the cat’s striate cortex</article-title><source>The Journal of Physiology</source><volume>148</volume><fpage>574</fpage><lpage>591</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1959.sp006308</pub-id><pub-id pub-id-type="pmid">14403679</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><year iso-8601-date="1962">1962</year><article-title>Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex</article-title><source>The Journal of Physiology</source><volume>160</volume><fpage>106</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1962.sp006837</pub-id><pub-id pub-id-type="pmid">14449617</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><year iso-8601-date="1968">1968</year><article-title>Receptive fields and functional architecture of monkey striate cortex</article-title><source>The Journal of Physiology</source><volume>195</volume><fpage>215</fpage><lpage>243</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1968.sp008455</pub-id><pub-id pub-id-type="pmid">4966457</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>EN</given-names></name><name><surname>Hawken</surname><given-names>MJ</given-names></name><name><surname>Shapley</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The spatial transformation of color in the primary visual cortex of the macaque monkey</article-title><source>Nature Neuroscience</source><volume>4</volume><fpage>409</fpage><lpage>416</lpage><pub-id pub-id-type="doi">10.1038/86061</pub-id><pub-id pub-id-type="pmid">11276232</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>EN</given-names></name><name><surname>Hawken</surname><given-names>MJ</given-names></name><name><surname>Shapley</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Cone inputs in macaque primary visual cortex</article-title><source>Journal of Neurophysiology</source><volume>91</volume><fpage>2501</fpage><lpage>2514</lpage><pub-id pub-id-type="doi">10.1152/jn.01043.2003</pub-id><pub-id pub-id-type="pmid">14749310</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>EN</given-names></name><name><surname>Hawken</surname><given-names>MJ</given-names></name><name><surname>Shapley</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The orientation selectivity of color-responsive neurons in macaque V1</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>8096</fpage><lpage>8106</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1404-08.2008</pub-id><pub-id pub-id-type="pmid">18685034</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kingdom</surname><given-names>FAA</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Color brings relief to human vision</article-title><source>Nature Neuroscience</source><volume>6</volume><fpage>641</fpage><lpage>644</lpage><pub-id pub-id-type="doi">10.1038/nn1060</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Kleiner</surname><given-names>M</given-names></name><name><surname>Brainard</surname><given-names>DH</given-names></name><name><surname>Pelli</surname><given-names>DG</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>What’s new in Psychtoolbox-3?</article-title><conf-name>Perception 36 ECVP Abstract Supplement</conf-name></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kraft</surname><given-names>JM</given-names></name><name><surname>Brainard</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Mechanisms of color constancy under nearly natural viewing</article-title><source>PNAS</source><volume>96</volume><fpage>307</fpage><lpage>312</lpage><pub-id pub-id-type="doi">10.1073/pnas.96.1.307</pub-id><pub-id pub-id-type="pmid">9874814</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kunsberg</surname><given-names>B</given-names></name><name><surname>Holtmann-Rice</surname><given-names>D</given-names></name><name><surname>Alexander</surname><given-names>E</given-names></name><name><surname>Cholewiak</surname><given-names>S</given-names></name><name><surname>Fleming</surname><given-names>R</given-names></name><name><surname>Zucker</surname><given-names>SW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Colour, contours, shading and shape: flow interactions reveal anchor neighbourhoods</article-title><source>Interface Focus</source><volume>8</volume><elocation-id>20180019</elocation-id><pub-id pub-id-type="doi">10.1098/rsfs.2018.0019</pub-id><pub-id pub-id-type="pmid">29951196</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Livingstone</surname><given-names>MS</given-names></name><name><surname>Hubel</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>Anatomy and physiology of a color system in the primate visual cortex</article-title><source>The Journal of Neuroscience</source><volume>4</volume><fpage>309</fpage><lpage>356</lpage><pub-id pub-id-type="pmid">6198495</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Malik</surname><given-names>J</given-names></name><name><surname>Perona</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Preattentive texture discrimination with early vision mechanisms</article-title><source>Journal of the Optical Society of America. A, Optics and Image Science</source><volume>7</volume><fpage>923</fpage><lpage>932</lpage><pub-id pub-id-type="doi">10.1364/josaa.7.000923</pub-id><pub-id pub-id-type="pmid">2338600</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marr</surname><given-names>D</given-names></name><name><surname>Hildreth</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>Theory of edge detection</article-title><source>PNAS</source><volume>207</volume><fpage>187</fpage><lpage>217</lpage><pub-id pub-id-type="doi">10.1098/rspb.1980.0020</pub-id><pub-id pub-id-type="pmid">6102765</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McLaughlin</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>A neuronal network model of sharpening and dynamics of orientation tuning in an input layer of macaque primary visual cortex</article-title><source>PNAS</source><volume>97</volume><fpage>8087</fpage><lpage>8092</lpage></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mehrotra</surname><given-names>R</given-names></name><name><surname>Namuduri</surname><given-names>KR</given-names></name><name><surname>Ranganathan</surname><given-names>N</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Gabor filter-based edge detection</article-title><source>Pattern Recognition</source><volume>25</volume><fpage>1479</fpage><lpage>1494</lpage><pub-id pub-id-type="doi">10.1016/0031-3203(92)90121-X</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michael</surname><given-names>CR</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Color vision mechanisms in monkey striate cortex: dual-opponent cells with concentric receptive fields</article-title><source>Journal of Neurophysiology</source><volume>41</volume><fpage>572</fpage><lpage>588</lpage><pub-id pub-id-type="doi">10.1152/jn.1978.41.3.572</pub-id><pub-id pub-id-type="pmid">96222</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Monnier</surname><given-names>P</given-names></name><name><surname>Shevell</surname><given-names>SK</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Large shifts in color appearance from patterned chromatic backgrounds</article-title><source>Nature Neuroscience</source><volume>6</volume><fpage>801</fpage><lpage>802</lpage><pub-id pub-id-type="doi">10.1038/nn1099</pub-id><pub-id pub-id-type="pmid">12872129</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moreland</surname><given-names>JC</given-names></name><name><surname>Boynton</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A neurophysiological explanation for biases in visual localization</article-title><source>Attention, Perception, &amp; Psychophysics</source><volume>79</volume><fpage>553</fpage><lpage>562</lpage><pub-id pub-id-type="doi">10.3758/s13414-016-1251-z</pub-id><pub-id pub-id-type="pmid">27909979</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Movshon</surname><given-names>JA</given-names></name><name><surname>Thompson</surname><given-names>ID</given-names></name><name><surname>Tolhurst</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="1978">1978a</year><article-title>Receptive field organization of complex cells in the cat’s striate cortex</article-title><source>The Journal of Physiology</source><volume>283</volume><fpage>79</fpage><lpage>99</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1978.sp012489</pub-id><pub-id pub-id-type="pmid">722592</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Movshon</surname><given-names>JA</given-names></name><name><surname>Thompson</surname><given-names>ID</given-names></name><name><surname>Tolhurst</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="1978">1978b</year><article-title>Spatial summation in the receptive fields of simple cells in the cat’s striate cortex</article-title><source>The Journal of Physiology</source><volume>283</volume><fpage>53</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1978.sp012488</pub-id><pub-id pub-id-type="pmid">722589</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ohzawa</surname><given-names>I</given-names></name><name><surname>Freeman</surname><given-names>RD</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>The binocular organization of simple cells in the cat’s visual cortex</article-title><source>Journal of Neurophysiology</source><volume>56</volume><fpage>221</fpage><lpage>242</lpage><pub-id pub-id-type="doi">10.1152/jn.1986.56.1.221</pub-id><pub-id pub-id-type="pmid">3746398</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Okazawa</surname><given-names>G</given-names></name><name><surname>Tajima</surname><given-names>S</given-names></name><name><surname>Komatsu</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Image statistics underlying natural texture selectivity of neurons in macaque V4</article-title><source>PNAS</source><volume>112</volume><fpage>E351</fpage><lpage>E360</lpage><pub-id pub-id-type="doi">10.1073/pnas.1415146112</pub-id><pub-id pub-id-type="pmid">25535362</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Paninski</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Convergence properties of some spike-triggered analysis techniques</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><conf-loc>Cambridge, MA</conf-loc><fpage>189</fpage><lpage>196</lpage></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pelli</surname><given-names>DG</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The VideoToolbox software for visual psychophysics: transforming numbers into movies</article-title><source>Spatial Vision</source><volume>10</volume><fpage>437</fpage><lpage>442</lpage><pub-id pub-id-type="pmid">9176953</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Read</surname><given-names>JCA</given-names></name><name><surname>Cumming</surname><given-names>BG</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Testing quantitative models of binocular disparity selectivity in primary visual cortex</article-title><source>Journal of Neurophysiology</source><volume>90</volume><fpage>2795</fpage><lpage>2817</lpage><pub-id pub-id-type="doi">10.1152/jn.01110.2002</pub-id><pub-id pub-id-type="pmid">12867533</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rust</surname><given-names>NC</given-names></name><name><surname>Schwartz</surname><given-names>O</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Spatiotemporal elements of macaque v1 receptive fields</article-title><source>Neuron</source><volume>46</volume><fpage>945</fpage><lpage>956</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.05.021</pub-id><pub-id pub-id-type="pmid">15953422</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rust</surname><given-names>NC</given-names></name><name><surname>Mante</surname><given-names>V</given-names></name><name><surname>Simoncelli</surname><given-names>EP</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>How MT cells analyze the motion of visual patterns</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>1421</fpage><lpage>1431</lpage><pub-id pub-id-type="doi">10.1038/nn1786</pub-id><pub-id pub-id-type="pmid">17041595</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shapley</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Linear and nonlinear systems analysis of the visual system: why does it seem so linear?: A review dedicated to the memory of Henk Spekreijse</article-title><source>Vision Research</source><volume>49</volume><fpage>907</fpage><lpage>921</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2008.09.026</pub-id><pub-id pub-id-type="pmid">18940193</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shevell</surname><given-names>SK</given-names></name><name><surname>Monnier</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Color shifts from S-cone patterned backgrounds: contrast sensitivity and spatial frequency selectivity</article-title><source>Vision Research</source><volume>45</volume><fpage>1147</fpage><lpage>1154</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2004.11.013</pub-id><pub-id pub-id-type="pmid">15707923</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simoncelli</surname><given-names>EP</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>A model of neuronal responses in visual area MT</article-title><source>Vision Research</source><volume>38</volume><fpage>743</fpage><lpage>761</lpage><pub-id pub-id-type="doi">10.1016/s0042-6989(97)00183-1</pub-id><pub-id pub-id-type="pmid">9604103</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skottun</surname><given-names>BC</given-names></name><name><surname>De Valois</surname><given-names>RL</given-names></name><name><surname>Grosof</surname><given-names>DH</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name><name><surname>Albrecht</surname><given-names>DG</given-names></name><name><surname>Bonds</surname><given-names>AB</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Classifying simple and complex cells on the basis of response modulation</article-title><source>Vision Research</source><volume>31</volume><fpage>1079</fpage><lpage>1086</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(91)90033-2</pub-id><pub-id pub-id-type="pmid">1909826</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spence</surname><given-names>I</given-names></name><name><surname>Wong</surname><given-names>P</given-names></name><name><surname>Rusan</surname><given-names>M</given-names></name><name><surname>Rastegar</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>How color enhances visual memory for natural scenes</article-title><source>Psychological Science</source><volume>17</volume><fpage>1</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.2005.01656.x</pub-id><pub-id pub-id-type="pmid">16371136</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stockman</surname><given-names>A</given-names></name><name><surname>MacLeod</surname><given-names>DI</given-names></name><name><surname>Johnson</surname><given-names>NE</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Spectral sensitivities of the human cones</article-title><source>Journal of the Optical Society of America. A, Optics, Image Science, and Vision</source><volume>10</volume><fpage>2491</fpage><lpage>2521</lpage><pub-id pub-id-type="doi">10.1364/josaa.10.002491</pub-id><pub-id pub-id-type="pmid">8301403</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tailby</surname><given-names>C</given-names></name><name><surname>Solomon</surname><given-names>SG</given-names></name><name><surname>Lennie</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Functional asymmetries in visual pathways carrying S-cone signals in macaque</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>4078</fpage><lpage>4087</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5338-07.2008</pub-id><pub-id pub-id-type="pmid">18400907</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanabe</surname><given-names>S</given-names></name><name><surname>Cumming</surname><given-names>BG</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Mechanisms underlying the transformation of disparity signals from V1 to V2 in the macaque</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>11304</fpage><lpage>11314</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3477-08.2008</pub-id><pub-id pub-id-type="pmid">18971472</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tolhurst</surname><given-names>DJ</given-names></name><name><surname>Dean</surname><given-names>AF</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>The effects of contrast on the linearity of spatial summation of simple cells in the cat’s striate cortex</article-title><source>Experimental Brain Research</source><volume>79</volume><fpage>582</fpage><lpage>588</lpage><pub-id pub-id-type="doi">10.1007/BF00229326</pub-id><pub-id pub-id-type="pmid">2340875</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Touryan</surname><given-names>J</given-names></name><name><surname>Lau</surname><given-names>B</given-names></name><name><surname>Dan</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Isolation of relevant visual features from random stimuli for cortical complex cells</article-title><source>The Journal of Neuroscience</source><volume>22</volume><fpage>10811</fpage><lpage>10818</lpage><pub-id pub-id-type="pmid">12486174</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vos</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Colorimetric and photometric properties of a 2° fundamental observer</article-title><source>Color Research &amp; Application</source><volume>3</volume><fpage>125</fpage><lpage>128</lpage><pub-id pub-id-type="doi">10.1002/col.5080030309</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weller</surname><given-names>JP</given-names></name><name><surname>Horwitz</surname><given-names>GD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Measurements of neuronal color tuning: procedures, pitfalls, and alternatives</article-title><source>Vision Research</source><volume>151</volume><fpage>53</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2017.08.005</pub-id><pub-id pub-id-type="pmid">29133032</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Willmore</surname><given-names>BDB</given-names></name><name><surname>Prenger</surname><given-names>RJ</given-names></name><name><surname>Gallant</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Neural representation of natural images in visual area V2</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>2102</fpage><lpage>2114</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4099-09.2010</pub-id><pub-id pub-id-type="pmid">20147538</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>HR</given-names></name><name><surname>Wilkinson</surname><given-names>F</given-names></name><name><surname>Asaad</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Concentric orientation summation in human form vision</article-title><source>Vision Research</source><volume>37</volume><fpage>2325</fpage><lpage>2330</lpage><pub-id pub-id-type="doi">10.1016/s0042-6989(97)00104-1</pub-id><pub-id pub-id-type="pmid">9381668</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wool</surname><given-names>LE</given-names></name><name><surname>Packer</surname><given-names>OS</given-names></name><name><surname>Zaidi</surname><given-names>Q</given-names></name><name><surname>Dacey</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Connectomic identification and three-dimensional color tuning of S-OFF midget ganglion cells in the primate retina</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>7893</fpage><lpage>7909</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0778-19.2019</pub-id><pub-id pub-id-type="pmid">31405926</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wurm</surname><given-names>LH</given-names></name><name><surname>Legge</surname><given-names>GE</given-names></name><name><surname>Isenberg</surname><given-names>LM</given-names></name><name><surname>Luebker</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Color improves object recognition in normal and low vision</article-title><source>Journal of Experimental Psychology: Human Perception and Performance</source><volume>19</volume><fpage>899</fpage><lpage>911</lpage><pub-id pub-id-type="doi">10.1037//0096-1523.19.4.899</pub-id><pub-id pub-id-type="pmid">8409865</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xian</surname><given-names>SX</given-names></name><name><surname>Shevell</surname><given-names>SK</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Changes in color appearance caused by perceptual grouping</article-title><source>Visual Neuroscience</source><volume>21</volume><fpage>383</fpage><lpage>388</lpage><pub-id pub-id-type="doi">10.1017/s0952523804213062</pub-id><pub-id pub-id-type="pmid">15518218</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiao</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Processing of the S-cone signals in the early visual cortex of primates</article-title><source>Visual Neuroscience</source><volume>31</volume><fpage>189</fpage><lpage>195</lpage><pub-id pub-id-type="doi">10.1017/S0952523813000278</pub-id><pub-id pub-id-type="pmid">23941664</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.68133.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Pasternak</surname><given-names>Tatiana</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01s5ya894</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><related-object id="sa0ro1" link-type="continued-by" object-id="10.1101/2021.02.12.430975" object-id-type="id" xlink:href="https://sciety.org/articles/activity/10.1101/2021.02.12.430975"/></front-stub><body><p>There was a strong agreement that the work fills an important gap in the understanding of spatial integration of color signals in primate visual cortex and that the use of novel stimulus paradigms to study color responses in alert macaque provided important new information. There was also strong support for the analytical approaches used to categorize simple and double opponent neurons as well as appreciation for the quality of the discussion of the results.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.68133.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Pasternak</surname><given-names>Tatiana</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01s5ya894</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Conway</surname><given-names>Bevil R</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03wkg3b53</institution-id><institution>National Eye Institute</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Brainard</surname><given-names>David</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00b30xv10</institution-id><institution>University of Pennsylvania</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2021.02.12.430975">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.02.12.430975v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Coding of chromatic spatial contrast by macaque V1 neurons&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Tirin Moore as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Bevil R Conway (Reviewer #1); David Brainard (Reviewer #2).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Your manuscript was well received by the reviewers. They felt that your work fills a major gap in the understanding of cortical processing of color signals and is likely to be of broad interest. They also felt that the experiments are well executed and paper well-written. However, they raised a number of concerns which need to be addressed for the work to be publishable in <italic>eLife</italic>. Below are the topics that will require substantial revision.</p><p>1. The extent to which the results are affected by the cell classification criteria. The reviewers raise several related points and provide some possible ways of addressing the issue (which will potentially require further analysis).</p><p>2. The implications of the results for models, including the issue of how stimuli were defined and the implications of the stimulus space that was used. It will be essential that enough information is provided in the paper that others could convert the display RGB data into device-independent stimulus spaces such as cone-contrast space.</p><p>3. The color properties of the subfields.</p><p>4. The impact of eye movements on the results.</p><p>5. Potential implications of your choice of stimulus space</p><p>6. Provide information about your display's RGB data that would allow their conversion into a cone contrast space</p><p>In addition to the main concerns listed above, the two reviews contain detailed comments and suggestions which you are likely to find useful, as you revise the manuscript.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>Many studies of the chromatic spatial response properties of V1 cells have used heterochromatic gratings where the colors of the grating are fixed by some assumed theory (typically cone opponency through, e.g., DKL color space). I am aware of only three studies that have addressed how V1 cells sum responses across receptive field subunits: one showed responses for only two cells, one clearly linear and one clearly non-linear (Conway, 2001); a second study focused on the integration of color signals in time, rather than in space (Conway et al., 2002); and a third measured responses to pairs of cone-isolating spots and found that L-M cells were linear while S-dominated cells were often non-linear (Conway and Livingstone, 2006). The approach in the present report, combining the white-noise analysis and the &quot;hyperpixel&quot; contrast approach are very powerful (and clever), overcoming the limited set of colors used in the previous reports and adding substantially more quantitative resolution. But the analysis of the results do not seem to fully explore the richness of the data, and leave us with an unsurprising conclusion that confirms what we already know-double-opponent cells include a population of linear neurons. As the authors point out, previously published spatial mapping studies of cone-opponent neurons have recovered spatial structure, and the technique used in those studies only reveal spatial structure if the neurons show some degree of linearity. It is well established that the majority of V1 cells in primates are non-linear (complex) and the minority of simple cells in primate are linear (by definition). So it is not surprising that double-opponent cells in the present work are more likely to be linear compared to the somewhat random sample of non-DO/non-simple cells, which were, by definition, classified as nonlinear (discussion, last paragraph, pg. 14).</p><p>The value of the present study would seem to rest on the distinction between simple and DO cells and the selection criteria for the NSNDO population. I appreciate that there is some arbitrariness in how cells are categorized, and the authors have attempted to show that the main conclusion is maintained if category assignments are made using two different criteria. But I wonder if a simpler approach, which I think cleaves nature more naturally along the joints, would be to define cells based on significance of S cone input, and then on whether the L and M inputs have the same sign or different sign. This approach would leave the categorization of &quot;simple&quot; and &quot;double opponent&quot; to the discussion, and it would preclude an objection of the results/conclusions on the grounds of miss-categorization. The anatomy suggests that neurons carrying S cone signals are distinct, and probably have different patterns of wiring; and cells that respond with the same sign to L increments and M increments (without responding to S cone stimuli) would seem to be functionally different from neurons that respond in an L-vs-M opponent fashion. Moreover, there is considerable data (from at least two groups, Horwitz and Conway), that V1 cells with strong S-cone input show striking nonlinearities. (Are the greater number of NLI cells in the DO population and the simple cell population those with stronger S cone responses?) The physiological responses documented in the present report would be more valuable, in my opinion, if they provided clues that link with the anatomy, rather than being constrained by categorization based on potentially arbitrary physiological criteria (such as &quot;simple&quot; vs. &quot;double opponent&quot;). Of course, this is only a suggestion, and the authors should be free to analyze and present their data as they see best.</p><p>The analysis side-steps the important temporal dynamics of the cell responses. As with simple cells and double-opponent cells, responses are often push-pull in space and in time. It would seem important to test the extent to which the assigned linearity score of a neuron in space is predictive of its linearity score in time.</p><p>The hyperpixel paradigm involves presenting the stimuli at a fixed spatial location while the monkeys maintain fixation. The validity of the approach depends on the extent to which a given receptive field subregion is stimulated reliability and exclusively despite small eye movements. Some assurance (ideally with data) that this is the case would be helpful. My worry is that the interpretability of the results (given the eye movements) depends on the neurons being linear.</p><p>Finally, the paper does not explore the color tuning of the subunits, except to state that &quot;the colors on the two sides of the hyperpixel STA were complementary or nearly so&quot;. The Pearson's r analysis is insufficient: it tells us nothing about the color tuning, and high correlation values can be obtained for trivial reasons. The paradigm illustrated in Figure 2B provides a terrific chance to determine, directly, what the color tuning is of the separate subunits, and the extent to which the color tuning of one subunit of a given cell can predict the color tuning of the other subunits. This is important because color tuning inferred from cone weights suggests a bias (M+S vs L) that the paper is poised to directly test. Such an analysis could also help tease apart the distinction between simple and DO cells.</p><p>Other comments</p><p>Methods. The procedure by which different proportions of the two images were combined to create the family of stimuli is not entirely clear to me. The proportionality needs to be done by quantifying the stimuli in some way. The authors state that this was done by defining the 45 degree direction as the projection of the RGB values onto one half of the STA. But here's where I get tripped up: the goal of defining the family of stimuli is to then assess whether the neuron responses map on a line in the space or on a curve. If the space is arbitrarily defined, then a given neural response can be captured either by a line or a space depending on how the space is defined. I need some way out of this (apparent) circularity.</p><p>Intro. Given the relevance to simple cells, it might be useful to have a reference to the experimental evidence of simple cells in NHPs (there was a time, not too long ago, when dogma was that NHPs did not have simple cells).</p><p>Results. Given the validity of the results hinges on the distinction between simple, double-opponent, and NSNDO cells, I think it would be helpful to present the categorization criteria in the Results section, rather than relegating this information to the methods.</p><p>Results, pg. 6. The &quot;hyperpixel&quot; approach is analogous to the two-bar approach used in earlier studies. Except that in the earlier study the pair of bars were presented across the RF, which allowed quantification of more than two subunits. In the present work, did the stimulus always comprise just two halves? What if the cell had more than two subunits, as is not uncommon for simple and DO cells (and appears to be true for the example cell in Figure 2A)?</p><p>Results, pg. 6. I was a bit tripped up by the flow of the results: the STA analysis (2A) is what is used to recover the NLI histograms (2D-2F); the panels in 2B and 2C show a separate experiment. Perhaps regrouping the figures accordingly would help avoid the confusion that Figure 2D-2F quantify what is shown in Figure 2C (which is what would be logically assumed given the current sequence of panels and how they are described in the text).</p><p>Results, pg. 7. Is it not true that the extra parameters of the nonlinear model will also make it more likely that cross-validated data will be better fit by it? In other words, using cross validation doesn't get over the unfairness of comparing the GQM and GLM models, does it?</p><p>Results, pg. 8. The Kruskal-Wallis test outcome is driven entirely by the NSNDO population, which likely includes complex cells. It is well established that complex cells and simple cells differ in linearity, so it's not clear to me what this NLI analysis recovers. As the authors point out, the reverse-correlation mapping studies published previously only recover spatial structure if the cells have a linear component. So we already know that DO cells are more linear than the average V1 cell.</p><p>Results, pg. 10. The discussion of the necessity of the technique is helpful. Is this is the same logic underlying the use of responses to L-decrements to measure suppression by L (for green-ON cells) and M-decrements to measure suppression by M (for red-ON cells) by others?</p><p>Results, pg. 10. It would be helpful to state what conclusion (curved or linear) the authors interpret Figure 2C as showing. I'm assuming curved because the pattern of gray shading forms an arc around the 0,0 point. But then what are the dashed white lines? If they are intended to show model fits of stimuli that elicit the same firing rate, then I think something is wrong with that algorithm because the data do not, to my eye, align with the dashed lines. If they are intended to show theoretically which stimuli would have the same firing rate if the neuron were linear, then I'm confused why the lines are tilted.</p><p>Results, pg. 10. It seems odd to set the target firing rate to be lower than significantly (substantially) above baseline firing rate for any cells (even three). It would be useful to know the range, mean, and confidence limits around the mean, for the target firing rates (in terms of % above background firing rate).</p><p>Discussion, pg. 12. I appreciate the point the authors are trying to make, but as framed here, it seems weak (&quot;we used a visual stimulation paradigm that only works if the cells are linear to test if the cells are linear&quot;).</p><p>Discussion, pg. 13. The prior study discussed by the authors concluded that the responses to pairs of bars was linear. Another earlier study (Conway, 2001) showed two-bar interaction maps for two cells, one of which was clearly non-linear (and the non-linear cell was the one with strong S-cone input).</p><p>Discussion, pg. 13. The authors state that the prior work made an assumption that excitatory responses to an increment were the same size but opposite sign to suppression of a contrast decrement. It's not clear to me that this was an assumption rather than a test. The reverse-correlation procedure used in the earlier work used as a baseline the responses to stimuli presented well outside the receptive field, which allows the assumption to be directly tested.</p><p>Discussion, pg. 16 &quot;In either case, DO cells are a likely basis for the chromatic sensitivity of color-sensitive complex cells (Michael, 1978).&quot; This isn't clear to me. It seems equally plausible (arguably more plausible) that color-sensitive complex cells could derive color tuning by direct sampling of geniculate inputs.</p><p>Figure 3. It would be helpful to show the STA for each of the example cells. The distribution of data points in Figure 3A is stated in the results as being linear, but it looks curved to me (the two outliers at the far left notwithstanding). None of the example cells in Figure 3 are L-vs.-M cells, which is odd since the majority of &quot;classical&quot; double-opponent cells are defined by L-vs.-M opponency. By contrast, all the cells in Figure 3A could plausibly be simple cells. I'm a bit confused how meaningful the responses of a cell are if they fall on a line that goes through the origin. Responses at the origin are to a null stimulus (blank gray), which indicates that the target firing rate is nota much different from baseline.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>General. I think this paper would benefit from a sharpening of terminology and usage throughout. For example, always being explicit about what sort of non-linearity is being considered in any given sentence, and about which of the two types of white noise experiments is being referred to in each place where a reference is made. I could almost always figure out it what was intended from context, but that was extra work and left some uncertainty, as well distracted from following the flow of ideas. Specific examples given in some of the comments below.</p><p>Starting on page 3 and throughout. A key to understanding this paper is to understand the taxonomy the authors have applied to the neurons they recorded from. I struggled with the simple cell terminology, though. The criteria the authors use are different from more conventional ways used distinguish simple and complex cells. I think that if one applied F1/F0 criteria using luminance grating stimulation, one might well call at least some of the DO cells simple, as well as possibly some of the cells not studied. The criteria here are that the hyperpixel white noise analysis shows that cone contrast inputs are combined linearly and that the RFs are not cone opponent. I would have an easier time if the term simple cell were not used, to avoid confusion with the conventional taxonomy. Perhaps single opponent cells, or spatially-opponent non-cone-opponent cells. Thesse suggestion don't capture the linearity aspect of the criteria, but nor does the term double opponent and the authors are content with that. Maybe both terms should more clearly denote the linearity criteria. With a different choice of terminology, the relation to the conventional simple/complex taxonomy could be handled entirely in the discussion, with some care devoted to treating possible differences in classification. Avoiding the simple cell terminology might also allow ease exposition on the possible relation between NSNDO cells in the current study and chromatically sensitive complex cells, where I think more elaboration would be helpful.</p><p>Page 3. Introduction: &quot;The first stage of the primate visual system at which spatial comparison of spectral signals is implemented by individual neurons is area V1.&quot; – This statement is mysterious to me. Spatial comparisons are made at the first synapse, as signals from cones interact with signals from horizontal cells, and these interactions can involve spectral differences as signals from different classes of cones participate. Perhaps the authors mean something very specific when the qualify with &quot;by individual neurons&quot; but it is not clear what this is.</p><p>Page 4. I think more should be said about the 134 neurons that were recorded from and not studied further. These don't have a name in the current study and it is not entirely clear to me what caused them to be excluded. Perhaps only that they did not show any spatial opponency in the initial pixel white noise analysis (page 6), but I'm not sure that's the only reason so more detail on the exclusion criteria would be helpful.</p><p>Page 5. I agree with the authors that equating stimulus contrast across chromatic directions is a difficult and subtle matter, and that whenever possible it is useful to look for ways to frame questions that are robust to such equation. I diverge in that I don't see that their method avoids this difficulty. Just as one example, the frame selection criteria (pp. 21-22) are based on deciding which STA frame differs most from the background. That calculation is using some metric across color directions. Similarly with the criterion used to decide that the chromatic preferences of the two subfields of a DO neuron differ from each other.</p><p>Page 12. While we're on this point, the authors have used device primary RGB as their metric. The justify the reasonableness of this choice by writing &quot;The fact that DO cells and simple cells combined light intensities across space approximately linearly in this representation shows that it is a reasonable one for analyzing V1 neurons.&quot; This seems odd, first because it assumes the answer to the question being studied in this paper. Second, because if the combination is revealed to be linear in one choice of color representation, it will also be linear in another choice that is a linear transformation of the first. (Indeed, the authors themselves say this in the sentence after the one quoted.) So I don't see how the linearity of the result tells us much about whether the representational choice was good. If nothing else, I would ask that the authors provide enough information about their device so that others can transform their data into a device independent representation such as LMS contrast with respect to a well-defined choice of cone fundamentals.</p><p>Page 6. Figure 2B. I assumed the noise is independent across color channels in RGB, but would be good to say so explicitly.</p><p>Page 8. Figure 3. What should we make of the high indices for some DO cells, and the low indices for many NSNDO cells? Both distributions suggest at least that possibility that neither group is a homogeneous population with respect to non-linear spatial summation. More discussion of this seems worthwhile.</p><p>Page 10. How were the target firing rates chosen?</p><p>Page 13. &quot;Nearly all quantitative studies of V1 RFs have used achromatic stimuli&quot;. Perhaps worth listing the studies of this sort that have used chromatic stimuli. Also, I think that by &quot;V1 RFs&quot; the authors mean &quot;V1 spatial RF properties&quot; and this might be worth spelling out.</p><p>Page 13. &quot;This maximal response exceeded the response to either bar in isolation, consistent with linearity as well as with other models.&quot; Might make explicit that the linearity in this sentence is the linearity of spatial summation, as well as that the reason the result could be consistent with summation linearity is that there could be a response non-linearity after spatial summation.</p><p>Page 14. &quot;Reclassifying cells …. &quot; There's a lot of cell classification in this paper; perhaps sharpen here to emphasize that it is the simple/DO dichotomy classification being referred to here.</p><p>Page 14. &quot;Most other recent studies of DO cells used cone-isolating stimuli, which cannot reveal interactions among cone types (Conway, 2001; Johnson et al., 2001, 2004; Conway and Livingstone, 2006; Johnson et al., 2008).&quot; Johnson et al., used mixtures in some of their reported measurements.</p><p>Page 14. &quot;We classified neurons with nonlinear responses to white noise as NSNDO. This criterion was necessary to satisfy the assumptions underlying the conversion of the STA to cone weights.&quot; (A) In the first sentence, &quot;nonlinear&quot; seems too general since the paper believes it worthwhile to check for a specific type of nonlinearity in the simple and DO cells. (B) I don't understand this because the authors go on to apply the conversion of the STA to cone weights with the NSNDO cells, in that such conversion is used for the test in Phase 2, as shown in Figure 3F. (C) Here is an other places, it would be helpful to say &quot;hyperpixel white noise&quot; rather than just &quot;white noise&quot;</p><p>Page 15. &quot;Pooling LGN afferents with the same sign (ON or OFF) creates non-opponent spectral sensitivity.&quot; I'm not following what is meant here, need more detail on what is being assumed about chromatic properties of the afferents as well as exactly what is being pooled.</p><p>Page 17 and Figure 4. If the authors are going to show this data can they say anything about how the results for the experiments that are the focus of the current paper would come out for these two cells? That would connect these preliminary data better to the rest of the paper. And, did the authors find any cells like the one shown in 4C, but with the responses to luminance and chromatic gratings flipped?</p><p>Page 22. Please provide criteria used to decide whether the two subfields had distinct chromatic preferences, and how this related to cell classification. On page 7, correlations (computed how?) between the two halves of the STA are given, and it sounds like this is result obtained before selecting or classifying cells. One page 24 a percent variance explained number is given, again independent of cell classification. But I'm not entirely sure that this property wasn't required for cells to be included for further study.</p><p>Page 22. The authors note that using small pixels and a fast frame rate in the white noise experiments leads to the neurons being weakly driven. They might comment/think about whether the choices they made for these parameters are optimal – if they were to do the work again, could they consider using larger white noise pixels and a slower refresh rate to obtain better responses? That is, small/fast is at one end of a continuum, and maybe some other choice would be better for future work of this sort. Similarly, any requirement for use of the Gaussian distribution on the noise? Maybe a uniform or some other distribution would produce larger drive.</p><p>Page 22, last paragraph and into p. 23. The paragraph starts off talking about frames as six-dimensional vectors, but by the end it sounds like two separate 3-dimensional projections are done, yielding the two scalars one for each subfield. Would be clearer, I think, if only one of the two ways of talking about it is used here. Also might remind reader that this is the hyperpixel white noise STA, not the pixel white noise STA.</p><p>Page 23. We visualized a firing rate map from these projections by computing the ratio of spike-triggered stimuli to the total stimuli.&quot; I don't understand what metric of stimuli is being used in the ratio, which visualization in the paper this refers to, nor how the ratio of stimuli as described provides a map of firing rate.</p><p>Page 23. &quot;Direction represents the overall contrast between …&quot; Worth noting that what these axes represent in stimulus space is cell-specific, in that the axes for each cell are derived from that cell's hyperpixel STA. Also, although this is a matter of convention and up to the authors, I would find it more intuitive if the STA axes were the x and y axes of the plot, not the 45 and 135 directions.</p><p>Page 24. 232 neurons were recorded from. 98 are reported on here. What can we say about the rest, and why they were not included here. The one clear exclusion criterion is that some neurons had only a single spatial region revealed by the pixel white noise STA. Was that the only reason? On this point, I don't think NSNDO is the best term for the set of neurons out of the 98 that were not classified as simple or DO, because of all the other neurons that were not included and that also weren't classified as simple or DO.</p><p>Page 24. Is it a theorem that if you take the first row singular vector and the first column singular vector, that this is the optimal color-space separable accounting of the STA? Or could a joint analysis do better?</p><p>Page 24-25. On page 25, the classification of cells into simple, DO, and NSNDO is described. Because the term &quot;white noise&quot; is used to describe the protocol used for the classification and because this applies to both Phase 1 (pixel white noise) and Phase 2 (hyperpixel white noise) of the experiment, it would be good to remind the reader that it is (I think) the hyperpixel white noise that's relevant here. Indeed, I would try to be explicit each time in the paper the term white noise or STA is used, which of the two it refers to. Also, why is a substantial S cone input a requirement to be a DO cell? This seems like it would exclude cells with perfectly good spatially opponent L-M inputs. And, I'm not clear what happens to such cells, if there were any. I think from the next sentence that like neurons with a significant PC1, they get called NSNDO. But because the flow of this section had me thinking at the start that it was just those neurons with signifiant PC1 that were NSNDO, I'm also not clear on this. If they are NSNDO, then it is worth being explicit elsewhere that heterogeneous criteria were used to place neurons in this category, and perhaps looking at NLI separately for cells that arrived as NSNDO viat different paths.</p><p>Page 26. I'm surprised that Equation 1 doesn't include an amplitude parameter that captures the overall responsivity of the cell.</p><p>Figure 2 —figure supplement 1. I am not sure what is in panel D. Are these from Phase 2? And how does the 5th and 95th percentile information mentioned in the caption show up in the figure? More generally, I think the point of this figure is to provide a sense of how much harder the Phase 3 stimuli drive the cells than the Phase 1 and 2 stimuli, but I am not seeing this in the figure itself. Where are the Phase 3 data?</p><p>Figure 2 —figure supplement 2. Can you clarify the temporal parameters that go into this analysis?</p><p>Figure 3 —figure supplement 3. The staircase shown suggests that using the last stimulus presented does not give as good an estimate of stimulus that produces the criterion firing rate as would an analysis of the whole staircase. Do I understand that the last stimulus magnitude is what was used? If so, please elaborate why. If not, please clarify.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.68133.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>Many studies of the chromatic spatial response properties of V1 cells have used heterochromatic gratings where the colors of the grating are fixed by some assumed theory (typically cone opponency through, e.g., DKL color space). I am aware of only three studies that have addressed how V1 cells sum responses across receptive field subunits: one showed responses for only two cells, one clearly linear and one clearly non-linear (Conway, 2001); a second study focused on the integration of color signals in time, rather than in space (Conway et al., 2002); and a third measured responses to pairs of cone-isolating spots and found that L-M cells were linear while S-dominated cells were often non-linear (Conway and Livingstone, 2006). The approach in the present report, combining the white-noise analysis and the &quot;hyperpixel&quot; contrast approach are very powerful (and clever), overcoming the limited set of colors used in the previous reports and adding substantially more quantitative resolution. But the analysis of the results do not seem to fully explore the richness of the data, and leave us with an unsurprising conclusion that confirms what we already know-double-opponent cells include a population of linear neurons. As the authors point out, previously published spatial mapping studies of cone-opponent neurons have recovered spatial structure, and the technique used in those studies only reveal spatial structure if the neurons show some degree of linearity. It is well established that the majority of V1 cells in primates are non-linear (complex) and the minority of simple cells in primate are linear (by definition). So it is not surprising that double-opponent cells in the present work are more likely to be linear compared to the somewhat random sample of non-DO/non-simple cells, which were, by definition, classified as nonlinear (discussion, last paragraph, pg. 14).</p><p>The value of the present study would seem to rest on the distinction between simple and DO cells and the selection criteria for the NSNDO population. I appreciate that there is some arbitrariness in how cells are categorized, and the authors have attempted to show that the main conclusion is maintained if category assignments are made using two different criteria. But I wonder if a simpler approach, which I think cleaves nature more naturally along the joints, would be to define cells based on significance of S cone input, and then on whether the L and M inputs have the same sign or different sign. This approach would leave the categorization of &quot;simple&quot; and &quot;double opponent&quot; to the discussion, and it would preclude an objection of the results/conclusions on the grounds of miss-categorization. The anatomy suggests that neurons carrying S cone signals are distinct, and probably have different patterns of wiring; and cells that respond with the same sign to L increments and M increments (without responding to S cone stimuli) would seem to be functionally different from neurons that respond in an L-vs-M opponent fashion. Moreover, there is considerable data (from at least two groups, Horwitz and Conway), that V1 cells with strong S-cone input show striking nonlinearities. (Are the greater number of NLI cells in the DO population and the simple cell population those with stronger S cone responses?) The physiological responses documented in the present report would be more valuable, in my opinion, if they provided clues that link with the anatomy, rather than being constrained by categorization based on potentially arbitrary physiological criteria (such as &quot;simple&quot; vs. &quot;double opponent&quot;). Of course, this is only a suggestion, and the authors should be free to analyze and present their data as they see best.</p></disp-quote><p>Thank you for these suggestions. We have added a new analysis to the manuscript showing the relationship between the magnitude of S-cone weight and NLI. As the Reviewer predicted, neurons with large S-cone weights tend to be nonlinear. However, some neurons in our data set appeared to receive little S-cone input but nonetheless were highly non-linear. Defining cone weights for these neurons is difficult. Our estimates of how much input a neuron receives from the three cone types depends critically on how linearly these inputs are combined whereas our estimates of linearity are not trivially influenced by the strength of input from the three cone types. For these reasons, we have maintained the original criteria (screening first on the basis of linearity and second on the basis of cone weights) for defining the three groups of cells. However, we have changed the Introduction to more clearly explain these criteria.</p><disp-quote content-type="editor-comment"><p>The analysis side-steps the important temporal dynamics of the cell responses. As with simple cells and double-opponent cells, responses are often push-pull in space and in time. It would seem important to test the extent to which the assigned linearity score of a neuron in space is predictive of its linearity score in time.</p></disp-quote><p>We agree that the integration of visual information over time by V1 neurons is an important issue, but the data we collected are ill-suited for investigating this issue with the care it deserves. Ideally, to measure temporal linearity, we would have probed neurons with pairs of stimuli that are identical in space but separated in time (as in Conway and Livingstone, 2006). Instead, we probed neurons with pairs of stimuli that were separated in space but coincident in time, which is more appropriate for measuring spatial than temporal linearity.</p><p>Nevertheless, inspired by the Reviewer's suggestion, we analyzed our data for signs of push-pull excitation-inhibition, which manifests in OFF responses following the removal of a suppressive stimulus. For each neuron, we examined responses following the disappearance of a stimulus and measured the correlation of these responses with the isoresponse NLI. We would like to have have restricted this analysis to the removal of <italic>suppressive</italic> stimuli, but few of the stimuli presented were suppressive. As a proxy, we considered only trials in which no spikes were generated during the stimulus presentation period (consistent with the stimulus having been suppressive). We counted spikes from the disappearance of the stimulus (plus an additional latency derived from the hyperpixel STA) until 150 ms after stimulus disappearance. Fixation breaks during this epoch aborted trials. We found no significant relationship between the average OFF response and the isoresponse NLI (r=-0.01, p=0.89, Spearman’s rank correlation).</p><p>We also considered a stricter criterion, considering only neurons for which the average firing rate before the stimulus presentation (the baseline firing rate) was &gt; 0 spikes per second (71/96 neurons satisfied the criteria). This allowed us to more easily identify suppressive stimuli. Even within this subset of neurons, we still did not find a significant correlation (r=0.01, p=0.84, Spearman’s rank correlation). The fact that we did not present many suppressive stimuli may have prevented us from observing strong OFF responses.</p><p>In interpreting these data, we note that linearity can be dissociated from OFFresponses; a linear neuron with a biphasic temporal impulse response produces an OFF response, but a linear neuron with a monophasic temporal impulse response does not (<xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>) .</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><caption><title>Two hypothetical, purely linear L-M neurons stimulated with L-cone isolating contrast increments and decrements.</title><p>If the temporal impulse response is monophasic (<bold>A</bold>), then the response to a step (<bold>B</bold>) is sustained, and no OFF-response occurs when the stimulus disappears. (<bold>C</bold> and <bold>D</bold>) same as <bold>A</bold> and <bold>B</bold> but for a neuron with a biphasic temporal impulse response. In this case, the disappearance of a suppressive stimulus produces an OFF response (dashed gray line).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68133-sa2-fig1-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>The hyperpixel paradigm involves presenting the stimuli at a fixed spatial location while the monkeys maintain fixation. The validity of the approach depends on the extent to which a given receptive field subregion is stimulated reliability and exclusively despite small eye movements. Some assurance (ideally with data) that this is the case would be helpful. My worry is that the interpretability of the results (given the eye movements) depends on the neurons being linear.</p></disp-quote><p>We have included new analyses of fixational eye movements to the revised manuscript. Differences in fixation eye movements across neurons of different type were subtle, if present. This is expected: fixational eye movements shift the stimulus on the RF, but these shifts tend to be small with respect to the hyperpixels. Eye movements can make a two-subfield RF appear to have a single subfield (if the two hyperpixels spend an equal amount of time stimulating each subfield), but they cannot make a one-subfield RF present as an STA with multiple spectrally distinct subregions. All of the neurons described in this report had STAs with multiple spectrally distinct subregions. Moreover, we never observed a neuron that had two RF subregions in response to the pixel white noise but only one in response to hyperpixel white noise.</p><p>Importantly, in <italic>Phase 3</italic> of the experiment, images were flashed briefly, spikes were counted, and stimuli were not averaged together. The fact that we were able to cancel an increase in preferred color on one side of the RF with a similar change in light on the other side attests to the stability of the image on the retina (opponent regions of the RF were successfully targeted). We are unsure how eye movements might affect the interpretation of the data differentially for linear and nonlinear cells. Perhaps the reviewer is alluding to the fact that eye movements could cause a linear neuron to have a significant PC1 if these movements bring individual hyperpixels onto multiple subfields of different spectral sensitivity. Through this mechanism, eye movements would be expected to increase the significance of the PC1 of linear neurons. In this sense, our PC1 criterion is conservative.</p><disp-quote content-type="editor-comment"><p>Finally, the paper does not explore the color tuning of the subunits, except to state that &quot;the colors on the two sides of the hyperpixel STA were complementary or nearly so&quot;. The Pearson's r analysis is insufficient: it tells us nothing about the color tuning, and high correlation values can be obtained for trivial reasons. The paradigm illustrated in Figure 2B provides a terrific chance to determine, directly, what the color tuning is of the separate subunits, and the extent to which the color tuning of one subunit of a given cell can predict the color tuning of the other subunits. This is important because color tuning inferred from cone weights suggests a bias (M+S vs L) that the paper is poised to directly test. Such an analysis could also help tease apart the distinction between simple and DO cells.</p></disp-quote><p>Thank you for this suggestion. We have added a new analysis of cone weights from the two hyperpixels separately. This analysis more clearly shows the distinction between simple cells and DO cells, documents the fact that the RF subfields of neurons in both groups have approximately opposite spectral tuning, and confirms the M+S vs L bias that has been documented before.</p><disp-quote content-type="editor-comment"><p>Other comments</p><p>Methods. The procedure by which different proportions of the two images were combined to create the family of stimuli is not entirely clear to me. The proportionality needs to be done by quantifying the stimuli in some way. The authors state that this was done by defining the 45 degree direction as the projection of the RGB values onto one half of the STA. But here's where I get tripped up: the goal of defining the family of stimuli is to then assess whether the neuron responses map on a line in the space or on a curve. If the space is arbitrarily defined, then a given neural response can be captured either by a line or a space depending on how the space is defined. I need some way out of this (apparent) circularity.</p></disp-quote><p>Thank you for pointing out this confusing part of the manuscript. The reviewer is correct that isoresponse contours have different shapes in different color spaces. However, lines in one color space remain lines in all color spaces that are related by a linear transformation. The color space we used is related to many conventional color spaces by a linear transformation (e.g. cone-contrast and DKL). This is clarified in the revised manuscript.</p><p>At each of the two hyperpixels, the STA reveals the neuron's relative sensitivity to the red, green, and blue primaries (and, by extension, the relative sensitivity to modulations of the L-, M-, and S-cone photoreceptors). We describe this sensitivity with a threeelement, unit vector. For example, if the STA indicated maximal sensitivity to increments of the red primary, half as much sensitivity to decrements of the green primary, and zero sensitivity to the blue primary, this vector would be [0.89 -0.46 0]. If the background was [0.5 0.5 0.5] (where &quot;0&quot; means completely off and &quot;1&quot; means maximum intensity), then possible stimuli at this location included [0.589 0.454 0.5] (reddish), [0.411 0.546 0.5] (greenish), and [0.5 0.5 0.5] (invisible). To express the contrast of each stimulus with a single number, we subtracted the background and then projected onto the unit vector: ([0.589 0.454 0.5]-[0.5 0.5 0.5])*[0.89 -0.46 0]' = 0.1. This calculation provides one of the two coordinates needed to represent the stimulus as a point on a plane. The other coordinate was calculated by performing the identical procedure on the other half of the STA. We have added the above explanation to the revised text.</p><disp-quote content-type="editor-comment"><p>Intro. Given the relevance to simple cells, it might be useful to have a reference to the experimental evidence of simple cells in NHPs (there was a time, not too long ago, when dogma was that NHPs did not have simple cells).</p></disp-quote><p>References to the existence of simple cells in NHPs have been added to the Introduction.</p><disp-quote content-type="editor-comment"><p>Results. Given the validity of the results hinges on the distinction between simple, double-opponent, and NSNDO cells, I think it would be helpful to present the categorization criteria in the Results section, rather than relegating this information to the methods.</p></disp-quote><p>We have expanded the explanation of the cell classification criteria in the Results section.</p><disp-quote content-type="editor-comment"><p>Results, pg. 6. The &quot;hyperpixel&quot; approach is analogous to the two-bar approach used in earlier studies. Except that in the earlier study the pair of bars were presented across the RF, which allowed quantification of more than two subunits. In the present work, did the stimulus always comprise just two halves? What if the cell had more than two subunits, as is not uncommon for simple and DO cells (and appears to be true for the example cell in Figure 2A)?</p></disp-quote><p>We did occasionally observe simple cells (and less frequently, DO cells) with &gt; 2 subfields. For cells with more than 2 subfields, we selected for visual stimulation the most prominent pair of subfields (the three-subfield neuron in Figure 2A is a good example). We wholeheartedly agree that measuring spatial integration across multiple (&gt; 2) subfields is important, but the three-phase, closed-loop technique implemented in the current study does not scale well beyond 2 subfields.</p><disp-quote content-type="editor-comment"><p>Results, pg. 6. I was a bit tripped up by the flow of the results: the STA analysis (2A) is what is used to recover the NLI histograms (2D-2F); the panels in 2B and 2C show a separate experiment. Perhaps regrouping the figures accordingly would help avoid the confusion that Figure 2D-2F quantify what is shown in Figure 2C (which is what would be logically assumed given the current sequence of panels and how they are described in the text).</p></disp-quote><p>Thank you for alerting us to this confusing issue. The NLI histograms (Figures 2D-2F) are computed from responses to the hyperpixel white noise (Figure 2B), and not the pixel white noise (Figure 2A). We have modified each mention of white noise or STA in the manuscript to specify whether we are referring to the pixel or the hyperpixel stimulus.</p><disp-quote content-type="editor-comment"><p>Results, pg. 7. Is it not true that the extra parameters of the nonlinear model will also make it more likely that cross-validated data will be better fit by it? In other words, using cross validation doesn't get over the unfairness of comparing the GQM and GLM models, does it?</p></disp-quote><p>Yes, we believe that cross-validation gets over the unfairness of comparing the GQM and GLM models. A non-cross-validated comparison would be unfair because the GQM makes the identical predictions to the GLM if some of the parameters of the GQM are set to zero. If these parameters are allowed to be something other than zero, the GQM will fit the data better unless the best-fitting values of these parameters happen to be zero, in which case there will be a tie.</p><p>When the data used to fit the model differ from the data used to test the model, as is the case in cross-validation, the GQM no longer enjoys this advantage over the GLM. The GQM will continue to fit the <italic>training</italic> data better than the GLM does, and this is for one of two reasons: The GQM may fit genuine structure in the data (patterns that are consistent across datasets produced by the same data generating mechanism) that the GLM does not fit. In this case, we expect the GQM to fit a new data set (or, equivalently, a held-out data set) better than the GLM does. Alternatively, the GQM may fit noise (patterns that are specific to the particular dataset being fit) that the GLM does not fit. In this case, we expect the GQM to fit a new data set worse than the GLM does.</p><disp-quote content-type="editor-comment"><p>Results, pg. 8. The Kruskal-Wallis test outcome is driven entirely by the NSNDO population, which likely includes complex cells. It is well established that complex cells and simple cells differ in linearity, so it's not clear to me what this NLI analysis recovers. As the authors point out, the reverse-correlation mapping studies published previously only recover spatial structure if the cells have a linear component. So we already know that DO cells are more linear than the average V1 cell.</p></disp-quote><p>Yes, the Kruskal-Wallis test outcome is driven by the OSO (previously called “NSNDO”) cells. However, a spatially structured STA was a requirement for inclusion in this study. Pure complex cells, which respond identically to contrast increments and decrements, were not studied. It seems likely that some neurons in the OSO category responded to contrast increments and decrements in the same RF locations, but with different sensitivity to each, and therefore had STAs with some spatial structure. We suspect that many of these cells would have been classified as complex cells by other procedures, but we cannot know for sure.</p><p>The white noise NLI is related to the spike-triggered covariance criterion that was used to exclude complex cells from the simple and DO cell categories but is not redundant with it. Please see our response to Reviewer 2, comment 20 for a more complete explanation of how these criteria differ.</p><disp-quote content-type="editor-comment"><p>Results, pg. 10. The discussion of the necessity of the technique is helpful. Is this is the same logic underlying the use of responses to L-decrements to measure suppression by L (for green-ON cells) and M-decrements to measure suppression by M (for red-ON cells) by others?</p></disp-quote><p>There may be a connection between the advantages we lay out for the isoresponse method and the use of responses to L-decrements to measure suppression by L and the use of M-decrements to measure suppression by M, but this connection is not obvious to us.</p><p>In this section, we focus on responses to pairs of stimuli and to each member of a pair separately. The key piece of logic is that two stimuli, when presented together, may drive a response that is not equal to the sum of the responses to the individual members of the pair but may still be predictable from these individual responses. The use of L-decrements to measure suppression by L and the use of M-decrements to measure suppression by M requires an assumption that two types of stimuli exert equal and opposite effects on the firing rate, which is not required in the above explanation.</p><disp-quote content-type="editor-comment"><p>Results, pg. 10. It would be helpful to state what conclusion (curved or linear) the authors interpret Figure 2C as showing. I'm assuming curved because the pattern of gray shading forms an arc around the 0,0 point. But then what are the dashed white lines? If they are intended to show model fits of stimuli that elicit the same firing rate, then I think something is wrong with that algorithm because the data do not, to my eye, align with the dashed lines. If they are intended to show theoretically which stimuli would have the same firing rate if the neuron were linear, then I'm confused why the lines are tilted.</p></disp-quote><p>The reviewer is correct that the neuron in Figure 2C was fit slightly better by the GQM than the GLM. The GQM vs. GLM comparison for this example cell (quantified by the hyperpixel white noise NLI) is shown in Figure 2D as a red vertical tick mark. This neuron was selected as an example because its NLI lies near the mode of the distribution.</p><p>The data shown in Figure 2C are binned for the purposes of visualization. This binning was necessary because stimulus projections onto the two halves of the hyperpixel STA varied continuously. Please see Figure 2 —figure supplement 1 for a scatterplot of the stimulus projections (panel A, red points) and the corresponding binned histogram (panel C). Bins that are far from the center of the box (0,0) contain few stimuli and thus estimates of spiking probability for these bins are noisy. Also, estimates of the probability of spiking are rendered in uncalibrated grayscale, making it difficult to compare differences in gray level by eye. The GLM and GQM were fit to the unbinned data.</p><p>We have revised the text to clarify these points and have updated Figure 2C to show firing rate predictions from the GQM fit, which are similar to those from the GLM fit. We note that tilted isoresponse lines are consistent with linearity and indicate that one subfield was dominant over the other.</p><disp-quote content-type="editor-comment"><p>Results, pg. 10. It seems odd to set the target firing rate to be lower than significantly (substantially) above baseline firing rate for any cells (even three). It would be useful to know the range, mean, and confidence limits around the mean, for the target firing rates (in terms of % above background firing rate).</p></disp-quote><p>We have summarized the information about baseline firing rates and target firing rates in Figure 3—figure supplement 2. On average, the target firing rate was 15.65 standard deviations above the mean baseline firing rate. The target firing rate of three neurons fell between the 90<sup>th</sup> and 95<sup>th</sup> percentiles (none were lower). Removing these neurons from the data set did not change the main conclusions of this study.</p><disp-quote content-type="editor-comment"><p>Discussion, pg. 12. I appreciate the point the authors are trying to make, but as framed here, it seems weak (&quot;we used a visual stimulation paradigm that only works if the cells are linear to test if the cells are linear&quot;).</p></disp-quote><p>We believe that the reviewer is referring to our statement that we &quot;characterized the spatial integration by individual V1 neurons using… white noise RF mapping&quot;. White noise stimulation can be used to characterize both linear and nonlinear neurons, but we agree that the concept of an RF map assumes linearity. We have changed the text from &quot;white noise RF mapping&quot; to &quot;white noise visual stimulation&quot;.</p><disp-quote content-type="editor-comment"><p>Discussion, pg. 13. The prior study discussed by the authors concluded that the responses to pairs of bars was linear. Another earlier study (Conway, 2001) showed two-bar interaction maps for two cells, one of which was clearly non-linear (and the non-linear cell was the one with strong S-cone input).</p></disp-quote><p>These studies are cited in the revised Discussion.</p><disp-quote content-type="editor-comment"><p>Discussion, pg. 13. The authors state that the prior work made an assumption that excitatory responses to an increment were the same size but opposite sign to suppression of a contrast decrement. It's not clear to me that this was an assumption rather than a test. The reverse-correlation procedure used in the earlier work used as a baseline the responses to stimuli presented well outside the receptive field, which allows the assumption to be directly tested.</p></disp-quote><p>The idea that the excitatory response to a stimulus is the same magnitude, but opposite sign, as the suppression to a contrast-inverted stimulus is described by Conway and Livingstone (2006) as an assumption:</p><p>“The suppression shown by many [V1] neurons to some stimuli resulted in a near complete reduction in background firing rate, leading one to suspect that the stimulus was capable of more suppression than could by measured extracellularly. To overcome this rectification nonlinearity in simple cells, the full extent of the response is often inferred by subtracting the responses to opposite-contrast stimuli (Ferster, 1994). The assumption that the excitatory response to a stimulus is the same magnitude, but opposite sign, as the suppression to a stimulus has been shown to be valid for LGN cells in the cat (Martinez et al., 2005). We made this assumption, too, to represent the responses succinctly by difference maps, which allow a direct quantitative calculation of the cone weights.” (emphasis added)</p><p>Our intention is simply to paraphrase this description.</p><disp-quote content-type="editor-comment"><p>Discussion, pg. 16 &quot;In either case, DO cells are a likely basis for the chromatic sensitivity of color-sensitive complex cells (Michael, 1978).&quot; This isn't clear to me. It seems equally plausible (arguably more plausible) that color-sensitive complex cells could derive color tuning by direct sampling of geniculate inputs.</p></disp-quote><p>We consider this possibility in the revised Discussion.</p><disp-quote content-type="editor-comment"><p>Figure 3. It would be helpful to show the STA for each of the example cells. The distribution of data points in Figure 3A is stated in the results as being linear, but it looks curved to me (the two outliers at the far left notwithstanding). None of the example cells in Figure 3 are L-vs.-M cells, which is odd since the majority of &quot;classical&quot; double-opponent cells are defined by L-vs.-M opponency. By contrast, all the cells in Figure 3A could plausibly be simple cells. I'm a bit confused how meaningful the responses of a cell are if they fall on a line that goes through the origin. Responses at the origin are to a null stimulus (blank gray), which indicates that the target firing rate is nota much different from baseline.</p></disp-quote><p>The hyperpixel STA for each neuron is presented in Figures 3A–C as the image at the top of each Figure. We have added the pixel white noise STA to these figures as well as bar plots of normalized cone weights (which the color rendering in the figure captures inadequately).</p><p>The Reviewer is correct that a point at the origin would indicate a response to a blank screen. None of the data points are at the origin, but some come very close to it and so does the fit. We have added a new supplementary figure (Figure 3 —figure supplement 3) that shows a zoomed in representation of the origin from Figures 3A and 3B.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>General. I think this paper would benefit from a sharpening of terminology and usage throughout. For example, always being explicit about what sort of non-linearity is being considered in any given sentence, and about which of thet two types of white noise experiments is being referred to in each place where a reference is made. I could almost always figure out it what was intended from context, but that was extra work and left some uncertainty, as well distracted from following the flow of ideas. Specific examples given in some of the comments below.</p></disp-quote><p>We have edited the manuscript to better indicate which type of non-linearity and which type of white noise are being considered throughout.</p><disp-quote content-type="editor-comment"><p>Starting on page 3 and throughout. A key to understanding this paper is to understand the taxonomy the authors have applied to the neurons they recorded from. I struggled with the simple cell terminology, though. The criteria the authors use are different from more conventional ways used distinguish simple and complex cells. I think that if one applied F1/F0 criteria using luminance grating stimulation, one might well call at least some of the DO cells simple, as well as possibly some of the cells not studied. The criteria here are that the hyperpixel white noise analysis shows that cone contrast inputs are combined linearly and that the RFs are not cone opponent. I would have an easier time if the term simple cell were not used, to avoid confusion with the conventional taxonomy. Perhaps single opponent cells, or spatially-opponent non-cone-opponent cells. Thesse suggestion don't capture the linearity aspect of the criteria, but nor does the term double opponent and the authors are content with that. Maybe both terms should more clearly denote the linearity criteria. With a different choice of terminology, the relation to the conventional simple/complex taxonomy could be handled entirely in the discussion, with some care devoted to treating possible differences in classification. Avoiding the simple cell terminology might also allow ease exposition on the possible relation between NSNDO cells in the current study and chromatically sensitive complex cells, where I think more elaboration would be helpful.</p></disp-quote><p>As pointed out by the reviewer, several criteria had to be met for a neuron to qualify as simple or DO in this study: spatial opponency and the lack of a significant PC1(for both cell types), and cone opponency or cone non-opponency (for DO cells and simple cells, respectively). Capturing all of these criteria with concise labels is difficult. The term &quot;single-opponent&quot; has already been used to describe neurons that have uniform coneopponency throughout their RFs (Johnson et al., 2008; Livingstone 1984; Shapley 2011).</p><p>We agree that many of the DO cells that we studied would likely have been classified as simple cells by the standard F1/F0 criterion, which is almost always measured with isochromatic stimuli. Simple cells were first described in the cat, an animal with few cone-opponent V1 cells, and the distinction between cone-opponency and nonopponency is more important in the macaque. Double-opponent cells in macaques are, by definition, cone-opponent, and we know of no widely accepted term for doubleopponent cells that lack cone-opponency. Such cells have RFs consisting of spatially distinct, oriented ON and OFF RF subfields, and are almost certain to be categorized as simple cells by standard criteria. As pointed out by the reviewer, however, so are others.</p><p>To maximize the accessibility of our manuscript to the broad readership of <italic>eLife</italic>, we have elected to retain the “simple cell&quot; terminology in our revision. We believe that this label captures the key characteristics of the approximately linear, spatially opponent, cone non-opponent, orientation-tuned cells that we studied. Nevertheless, we have added text explaining that our definition of simple cells is unconventional because is excludes cone-opponent cells and cells with certain types of nonlinearities. We have also revised the manuscript to clarify the categorization criteria, their rationale, and their relationships to classical criteria.</p><disp-quote content-type="editor-comment"><p>Page 3. Introduction: &quot;The first stage of the primate visual system at which spatial comparison of spectral signals is implemented by individual neurons is area V1.&quot; – This statement is mysterious to me. Spatial comparisons are made at the first synapse, as signals from cones interact with signals from horizontal cells, and these interactions can involve spectral differences as signals from different classes of cones participate. Perhaps the authors mean something very specific when the qualify with &quot;by individual neurons&quot; but it is not clear what this is.</p></disp-quote><p>Thank you for pointing this out. V1 is the first stage of the primate visual system that contains DO cells. This has been clarified in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>Page 4. I think more should be said about the 134 neurons that were recorded from and not studied further. These don't have a name in the current study and it is not entirely clear to me what caused them to be excluded. Perhaps only that they did not show any spatial opponency in the initial pixel white noise analysis (page 6), but I'm not sure that's the only reason so more detail on the exclusion criteria would be helpful.</p></disp-quote><p>We have expanded discussion of these neurons in the revised manuscript. There are three reasons that neurons were excluded from the current study:</p><p>1. The STA was indistinguishable from noise.</p><p>2. The STA did not reveal spatial opponency (e.g. it resembled a uniform blob).</p><p>3. Electrical isolation was lost early during or prior to <italic>Phase 3</italic> (the isoresponse contour measurement).</p><p>Many neurons in the first group (and possibly some in the second group) may have been complex cells. Others may have had contrast thresholds that were too high, RFs that were too small to be adequately stimulated by the pixel white noise, or had noise levels that were too high to produce a clear STA. Neurons in the second group appeared to have spatially homogeneous RFs and were therefore unsuitable for the current study. We were unable to collect sufficient data from neurons in the third group.</p><disp-quote content-type="editor-comment"><p>Page 5. I agree with the authors that equating stimulus contrast across chromatic directions is a difficult and subtle matter, and that whenever possible it is useful to look for ways to frame questions that are robust to such equation. I diverge in that I don't see that their method avoids this difficulty. Just as one example, the frame selection criteria (pp. 21-22) are based on deciding which STA frame differs most from the background. That calculation is using some metric across color directions. Similarly with the criterion used to decide that the chromatic preferences of the two subfields of a DO neuron differ from each other.</p></disp-quote><p>We have edited the text to be clearer about the color space-specificity of the analyses.</p><p>As pointed out by the reviewer, the STA frame that differed most from the background was selected on the basis of the (background subtracted) R<sup>2</sup>+G<sup>2</sup>+B<sup>2</sup>, which is a color space-specific statistic. Under the null hypothesis, this statistic has a scaled chi-squared distribution, which simplified the analysis. Had the analysis been done in, for example, (background subtracted) LMS space, correlations between the three color channels would have complicated the distribution (of L<sup>2</sup>+M<sup>2</sup>+S<sup>2</sup>). Correcting for these correlations is equivalent to doing the analysis in RGB space.</p><p>For each neuron, there were only 3–6 STA frames that were clearly different from noise. Across these 3–6 frames, R:G:B ratios changed little, so the light selected would have been similar under any reasonable selection rule (e.g. see Figure 2B). The frame selection procedure was used only to select lights on the two sides of the RF to stimulate the cell in <italic>Phase 3</italic>, and we have no reason to think that small changes in these lights would have had a large effect on the results.</p><p>As pointed out by the reviewer, Pearson’s correlation coefficient depends on the color space in which the analysis is performed. In the revised manuscript, we present a new analysis of cone weights estimated separately from the two subfields of each STA. This analysis (which is also color space-specific) confirms that chromatic preferences of the simple and DO cells are approximately opposite in this more-physiological color space.</p><disp-quote content-type="editor-comment"><p>Page 12. While we're on this point, the authors have used device primary RGB as their metric. The justify the reasonableness of this choice by writing &quot;The fact that DO cells and simple cells combined light intensities across space approximately linearly in this representation shows that it is a reasonable one for analyzing V1 neurons.&quot; This seems odd, first because it assumes the answer to the question being studied in this paper. Second, because if the combination is revealed to be linear in one choice of color representation, it will also be linear in another choice that is a linear transformation of the first. (Indeed, the authors themselves say this in the sentence after the one quoted.) So I don't see how the linearity of the result tells us much about whether the representational choice was good. If nothing else, I would ask that the authors provide enough information about their device so that others can transform their data into a device independent representation such as LMS contrast with respect to a well-defined choice of cone fundamentals.</p></disp-quote><p>We agree and have removed the statement about the reasonableness of RGB space from the text. We provide tabulated primary emission spectra and background RGB levels (γ-corrected) at https://github.com/horwitzlab/Chromatic_spatial_contrast.</p><disp-quote content-type="editor-comment"><p>Page 6. Figure 2B. I assumed the noise is independent across color channels in RGB, but would be good to say so explicitly.</p></disp-quote><p>This information is now stated explicitly.</p><disp-quote content-type="editor-comment"><p>Page 8. Figure 3. What should we make of the high indices for some DO cells, and the low indices for many NSNDO cells? Both distributions suggest at least that possibility that neither group is a homogeneous population with respect to non-linear spatial summation. More discussion of this seems worthwhile.</p></disp-quote><p>We agree and have amended the Discussion to clarify our perspective that DO cells lie on a continuum with some NSNDO cells with regard to the linearity of spatial summation.</p><disp-quote content-type="editor-comment"><p>Page 10. How were the target firing rates chosen?</p></disp-quote><p>Baseline firing rates for each neuron were monitored online during <italic>Phases 1 and 2</italic> of the experiment. Target firing rates were chosen such that they were substantially higher than the mean baseline firing rate (on average, 15.65 SDs higher). We have added a supplementary figure (Figure 3 —figure supplement 2) showing target firing rates and baseline firing rates for each neuron studied.</p><disp-quote content-type="editor-comment"><p>Page 13. &quot;Nearly all quantitative studies of V1 RFs have used achromatic stimuli&quot;. Perhaps worth listing the studies of this sort that have used chromatic stimuli. Also, I think that by &quot;V1 RFs&quot; the authors mean &quot;V1 spatial RF properties&quot; and this might be worth spelling out.</p></disp-quote><p>We have revised the text as per the reviewer’s suggestions.</p><disp-quote content-type="editor-comment"><p>Page 13. &quot;This maximal response exceeded the response to either bar in isolation, consistent with linearity as well as with other models.&quot; Might make explicit that the linearity in this sentence is the linearity of spatial summation, as well as that the reason the result could be consistent with summation linearity is that there could be a response non-linearity after spatial summation.</p></disp-quote><p>We have revised the text as per the reviewer’s suggestion.</p><disp-quote content-type="editor-comment"><p>Page 14. &quot;Reclassifying cells …. &quot; There's a lot of cell classification in this paper; perhaps sharpen here to emphasize that it is the simple/DO dichotomy classification being referred to here.</p></disp-quote><p>We have revised the text as per the reviewer’s suggestion.</p><disp-quote content-type="editor-comment"><p>Page 14. &quot;Most other recent studies of DO cells used cone-isolating stimuli, which cannot reveal interactions among cone types (Conway, 2001; Johnson et al., 2001, 2004; Conway and Livingstone, 2006; Johnson et al., 2008).&quot; Johnson et al., used mixtures in some of their reported measurements.</p></disp-quote><p>We have revised the sentence.</p><disp-quote content-type="editor-comment"><p>Page 14. &quot;We classified neurons with nonlinear responses to white noise as NSNDO. This criterion was necessary to satisfy the assumptions underlying the conversion of the STA to cone weights.&quot; (A) In the first sentence, &quot;nonlinear&quot; seems too general since the paper believes it worthwhile to check for a specific type of nonlinearity in the simple and DO cells. (B) I don't understand this because the authors go on to apply the conversion of the STA to cone weights with the NSNDO cells, in that such conversion is used for the test in Phase 2, as shown in Figure 3F. (C) Here is an other places, it would be helpful to say &quot;hyperpixel white noise&quot; rather than just &quot;white noise&quot;</p></disp-quote><p>A. We have revised this part of the text to clarify that we mean specifically nonlinearities that manifest in a PC1 that is significantly larger than expected by chance (e.g. the contrast-polarity invariance exhibited by complex cells).</p><p>B. We use the STA of the NSNDO cells only to identify lights on the two sides of the RF that are likely to drive a strong response. We agree that calculating cone weights from the NSNDO cells is unlikely to be a useful conversion. Nevertheless, we do this in Figure 6 for the sake of completeness.</p><p>C. We have specified which type of white noise we are referring to throughout the revised manuscript.</p><disp-quote content-type="editor-comment"><p>Page 15. &quot;Pooling LGN afferents with the same sign (ON or OFF) creates non-opponent spectral sensitivity.&quot; I'm not following what is meant here, need more detail on what is being assumed about chromatic properties of the afferents as well as exactly what is being pooled.</p></disp-quote><p>Thank you for pointing out this confusing section. The intended meaning is that pooling L- and M-cone-dominated ON afferents from one part of the visual space produces sensitivity to cone non-opponent increments, the precise details of which depends on the net spectral sensitivity of the afferents (e.g. L-cone dominated, M-cone dominated, or balanced). Surrounds are assumed to contribute little, spatially, relative to the center, and this is the case in the LGN under conditions similar to those examined in this study (e.g. (Horwitz 2020)). On the other hand, S-ON and S-OFF afferents carry strong, asymmetric L- and M-cone signals and therefore do not fit into this simple framework. This is explained more completely in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>Page 17 and Figure 4. If the authors are going to show this data can they say anything about how the results for the experiments that are the focus of the current paper would come out for these two cells? That would connect these preliminary data better to the rest of the paper. And, did the authors find any cells like the one shown in 4C, but with the responses to luminance and chromatic gratings flipped?</p></disp-quote><p>Thank you for this question. We suspect, but do not know, that the neurons in Figure 7C (formerly Figure 4C) would have been either passed over in this study or would have been classified as NSNDO given their insensitivity to the phase of drifting gratings.</p><p>No, we have never seen a complex cell with a vigorous response to chromatic (L-M) modulation that did not also have a vigorous response to luminance (L+M) modulation (see also Horwitz, Chichilnisky, and Albright, 2007).</p><disp-quote content-type="editor-comment"><p>Page 22. Please provide criteria used to decide whether the two subfields had distinct chromatic preferences, and how this related to cell classification. On page 7, correlations (computed how?) between the two halves of the STA are given, and it sounds like this is result obtained before selecting or classifying cells. One page 24 a percent variance explained number is given, again independent of cell classification. But I'm not entirely sure that this property wasn't required for cells to be included for further study.</p></disp-quote><p>The criteria used to decide whether the two subfields had distinct chromatic preferences online were qualitative. The pixel STA was rendered on the display of the data acquisition computer. If the experimenter could identify two visually distinct regions of the STA, these regions were manually segmented for the hyperpixel white noise stimulus (<italic>Phase 2</italic>). As soon as the two subfields of the hyperpixel STA (again, rendered online) became visually distinct and clearly different from the background gray, the experiment advanced to <italic>Phase 3</italic>.</p><p>The % variance explained refers to how well the hyperpixel STA is recovered by combining the color and spatial weighting functions computed by SVD. All cells were subjected to this analysis. Every neuron in the data set had a spatial weighting function consisting of one positive and one negative weight, consistent with opposite spectral sensitivity in the adjacent subfields.</p><p>Cells that survived this filter were classified into simple, DO, and OSO categories. We computed Pearson’s correlation between the 2 sets of background-subtracted RGB values (one for each subfield) from the hyperpixel STA of each neuron. We have revised the text to explain this procedure more clearly.</p><disp-quote content-type="editor-comment"><p>Page 22. The authors note that using small pixels and a fast frame rate in the white noise experiments leads to the neurons being weakly driven. They might comment/think about whether the choices they made for these parameters are optimal – if they were to do the work again, could they consider using larger white noise pixels and a slower refresh rate to obtain better responses? That is, small/fast is at one end of a continuum, and maybe some other choice would be better for future work of this sort. Similarly, any requirement for use of the Gaussian distribution on the noise? Maybe a uniform or some other distribution would produce larger drive.</p></disp-quote><p>The pixel size was matched to the size of the average fixational saccade (0.2°) made by monkeys viewing similar displays (Hass and Horwitz 2011). Longer frame durations (or, really, repeated frames, since the stimulus was shown on a CRT) might have been preferable for this study because temporal aspects of the response were of secondary interest. Gaussian distributions facilitate the interpretation of the spike-triggered covariance analysis relative to uniform distributions, which we agree would likely drive the cells harder (Paninski 2003).</p><disp-quote content-type="editor-comment"><p>Page 22, last paragraph and into p. 23. The paragraph starts off talking about frames as six-dimensional vectors, but by the end it sounds like two separate 3-dimensional projections are done, yielding the two scalars one for each subfield. Would be clearer, I think, if only one of the two ways of talking about it is used here. Also might remind reader that this is the hyperpixel white noise STA, not the pixel white noise STA.</p></disp-quote><p>Thank you for pointing out this confusing passage. We have simplified the explanation and emphasized that the analysis was performed on two separate 3-dimensional projections onto the hyperpixel STA.</p><disp-quote content-type="editor-comment"><p>Page 23. We visualized a firing rate map from these projections by computing the ratio of spike-triggered stimuli to the total stimuli.&quot; I don't understand what metric of stimuli is being used in the ratio, which visualization in the paper this refers to, nor how the ratio of stimuli as described provides a map of firing rate.</p></disp-quote><p>Thank you for alerting us to this confusing section. The stimuli were represented as linearized, background-subtracted RGB values, and these stimuli were projected onto the two halves of the STA. Each stimulus therefore produced a pair of scalars that define a location in a plane (Figure 2C). Because the elements of the white noise stimulus are jointly Gaussian, this distribution of projections is a bivariate Gaussian.</p><p>This procedure was performed on every stimulus that was shown in the experiment. Some of these stimuli preceded spikes, and most did not. We gridded the plane into small, square bins and, within each bin, counted the number of stimuli that preceded a spike and the number that did not. We estimate the probability of spiking, conditional on a stimulus being in a particular bin, as the number of stimuli in that bin that preceded a spike divided by the total number of stimuli in that bin. We refer to the probability of spiking as a function of two stimulus projections as a firing rate map. This has been clarified in the revised text.</p><disp-quote content-type="editor-comment"><p>Page 23. &quot;Direction represents the overall contrast between …&quot; Worth noting that what these axes represent in stimulus space is cell-specific, in that the axes for each cell are derived from that cell's hyperpixel STA. Also, although this is a matter of convention and up to the authors, I would find it more intuitive if the STA axes were the x and y axes of the plot, not the 45 and 135 directions.</p></disp-quote><p>We have revised the text based on reviewer’s suggestions.</p><p>The rationale for the unusual plotting convention is that most of the stimuli that were sampled in <italic>Phase 3</italic> provided positive contrast to both subfields. If we were to align the STA axes with the abscissa and ordinate, the figure would be rotated by 45°, and approximately half of the figure would be unused white space. In an effort to use the figure space efficiently, we have elected to retain the current rotation of the axes.</p><disp-quote content-type="editor-comment"><p>Page 24. 232 neurons were recorded from. 98 are reported on here. What can we say about the rest, and why they were not included here. The one clear exclusion criterion is that some neurons had only a single spatial region revealed by the pixel white noise STA. Was that the only reason? On this point, I don't think NSNDO is the best term for the set of neurons out of the 98 that were not classified as simple or DO, because of all the other neurons that were not included and that also weren't classified as simple or DO.</p></disp-quote><p>Please see our response to comment #26 for the answer to this question. We refer to the NSNDO cells as “other spatially opponent” (OSO) cells in the revised manuscript.</p><disp-quote content-type="editor-comment"><p>Page 24. Is it a theorem that if you take the first row singular vector and the first column singular vector, that this is the optimal color-space separable accounting of the STA? Or could a joint analysis do better?</p></disp-quote><p>Yes, the Eckart-Young-Mirsky theorem (Eckart 1936) states that the outer-product of the first column singular vector and the first row singular vector (multiplied by the first singular value) is the separable (rank 1) matrix that comes as close as possible to the original matrix in the sense of Frobenius norm. We have added a sentence to the text to inform the reader of the optimality of this procedure.</p><disp-quote content-type="editor-comment"><p>Page 24-25. On page 25, the classification of cells into simple, DO, and NSNDO is described. Because the term &quot;white noise&quot; is used to describe the protocol used for the classification and because this applies to both Phase 1 (pixel white noise) and Phase 2 (hyperpixel white noise) of the experiment, it would be good to remind the reader that it is (I think) the hyperpixel white noise that's relevant here. Indeed, I would try to be explicit each time in the paper the term white noise or STA is used, which of the two it refers to. Also, why is a substantial S cone input a requirement to be a DO cell? This seems like it would exclude cells with perfectly good spatially opponent L-M inputs. And, I'm not clear what happens to such cells, if there were any. I think from the next sentence that like neurons with a significant PC1, they get called NSNDO. But because the flow of this section had me thinking at the start that it was just those neurons with signifiant PC1 that were NSNDO, I'm also not clear on this. If they are NSNDO, then it is worth being explicit elsewhere that heterogeneous criteria were used to place neurons in this category, and perhaps looking at NLI separately for cells that arrived as NSNDO viat different paths.</p></disp-quote><p>We apologize for the ambiguity and explicitly mention which white noise (pixel or hyperpixel) was used throughout the revised text.</p><p>Our criteria for double-opponency did admit neurons with spatially opponent L-M inputs and small (or even non-existent) S-cone inputs. If a neuron had oppositely signed L- and M-cone weights, each of which accounted for at least 20% of the total, the neuron was classified as double-opponent, irrespective of the magnitude of the S-cone weight. The threshold on weight magnitude prevented neurons with non-opponent cone weights from being misclassified (small, independent noise in RGB produces small, anticorrelated noise in LM). Additionally, neurons were classified as DO if they had oppositely signed cone weights and an S-cone weight that accounted for at least 20% total. The former criteria selected the opponent L-M DO cells whereas the latter criteria selected the S-M+L , S+M-L and S-M-L DO cells (irrespective of the magnitudes of their L- and M-cone weights). We have rewritten the text to clarify the DO cell classification better.</p><p>The revised text is more explicit about the multiple criteria that were used to place neurons in the OSO (formerly NSNDO) category. Large differences across neurons that arrived in this category via different routes were looked for in response to this comment but not observed. (75% of the cells in the OSO category arrived via the PC1 criterion.)</p><disp-quote content-type="editor-comment"><p>Page 26. I'm surprised that Equation 1 doesn't include an amplitude parameter that captures the overall responsivity of the cell.</p></disp-quote><p>The amplitude parameter in Equation 1 is exp(c), where &quot;c&quot; is a fitted parameter. “Pred resp” in Equation 1 represents the probability that a stimulus will evoke a spike, and therefore has an upper asymptote of 1.</p><disp-quote content-type="editor-comment"><p>Figure 2 —figure supplement 1. I am not sure what is in panel D. Are these from Phase 2? And how does the 5th and 95th percentile information mentioned in the caption show up in the figure? More generally, I think the point of this figure is to provide a sense of how much harder the Phase 3 stimuli drive the cells than the Phase 1 and 2 stimuli, but I am not seeing this in the figure itself. Where are the Phase 3 data?</p></disp-quote><p>Thank you for alerting us to this confusing figure. Panel D shows data from <italic>Phase 2</italic> in the same format as panel A. The square firing rate map in the center of panel D shows, in grayscale, the proportion of stimuli (the red dots in panel A) that drove spikes. The 5th and 95th percentiles relate to the size of this square; had we included stimuli from the 1st to 99th percentiles, the box would have subsumed nearly all of the red points in panel A and thus been larger, but our estimate of the proportion of stimuli that drove a spike in bins near the edges would have been noisier because counts in these bins would have been low.</p><p>The previously submitted manuscript did not include an analysis of how much harder the <italic>Phase 3</italic> stimuli drove the cells than the <italic>Phase 1 and 2</italic> stimuli. We include this new analysis in Figure 2 —figure supplement 2 of the revised manuscript.</p><disp-quote content-type="editor-comment"><p>Figure 2 —figure supplement 2. Can you clarify the temporal parameters that go into this analysis?</p></disp-quote><p>We considered 15 frames of the hyperpixel STA prior to when a spike occurred, which is equivalent to 200 ms (frame rate = 75 Hz)(Figure 2B). We then convolved the hyperpixel white noise video with the two halves of the hyperpixel STA to obtain the projection values for each time bin. We have clarified these temporal parameters in the revised text.</p><disp-quote content-type="editor-comment"><p>Figure 3 —figure supplement 3. The staircase shown suggests that using the last stimulus presented does not give as good an estimate of stimulus that produces the criterion firing rate as would an analysis of the whole staircase. Do I understand that the last stimulus magnitude is what was used? If so, please elaborate why. If not, please clarify.</p></disp-quote><p>Yes, the final stimulus contrast magnitude was used to estimate the isoresponse point. Inspired by this comment, we repeated the analysis, defining isoresponse points in two new ways: first, as the geometric mean of the last 5 staircase points (geometric mean because the contrast was scaled multiplicatively in the staircase), and second, interpolation using a Naka-Rushton fit to the entire staircase assuming Poisson error. As shows in <xref ref-type="fig" rid="sa2fig2">Author response image 2</xref> and <xref ref-type="fig" rid="sa2fig3">Author response image 3</xref> the results from these three procedures are almost identical. For simplicity, we have decided to stay with the original definition.</p><fig id="sa2fig2" position="float"><label>Author response image 2.</label><caption><title>Comparison of staircase termination points with the geometric mean of the last 5 points in the staircase.</title><p>(<bold>A</bold>) Data from the example DO cell shown in Figure 3A. Black dots indicate staircase terminations and red dots indicate the geometric mean of the last 5 points in the staircase. (<bold>B</bold>) Staircase termination points are plotted against the geometric mean of the last 5 points of successful staircase terminations. (<bold>C</bold> and <bold>D</bold>) Same as <bold>A</bold> and <bold>B</bold>. but for the example simple cell shown in Figure 3B. (<bold>E</bold> and <bold>F</bold>) Same as <bold>A</bold> and <bold>B</bold>. but for the example OSO cell shown in Figure 3C.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68133-sa2-fig2-v2.tif"/></fig><fig id="sa2fig3" position="float"><label>Author response image 3.</label><caption><title>Comparison of staircase termination points with contrasts producing the target firing rate as interpolated from fitted Naka-Rushton functions.</title><p>(<bold>A</bold>) Data from the example DO cell shown in Figure 3A. Black dots indicate staircase terminations and red dots indicate Naka-Rushton fitted points. (<bold>B</bold>) Staircase termination points are plotted against the Naka Rushton fitted points. (<bold>C</bold>) and (<bold>D</bold>) same as (<bold>A</bold>) and (<bold>B</bold>) but for the example simple cell shown in Figure 3B. (<bold>E</bold>) and (<bold>F</bold>) same as (<bold>A</bold>) and (<bold>B</bold>) but for the example OSO cell shown in Figure 3C.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-68133-sa2-fig3-v2.tif"/></fig><p>References</p><p>Eckart C, and Young, G. The approximation of one matrix by another of lower rank. <italic>Psychometrika</italic> 1: 211-218, 1936.</p><p>Hass CA, and Horwitz GD. Effects of microsaccades on contrast detection and V1 responses in macaques. <italic>J Vis</italic> 11: 1-17, 2011.</p><p>Horwitz GD. Temporal information loss in the macaque early visual system. <italic>PLoS Biology</italic> 18: e3000570, 2020.</p><p>Horwitz GD, and Hass CA. Nonlinear analysis of macaque V1 color tuning reveals cardinal directions for cortical color processing. <italic>Nature Neuroscience</italic> 15: 913-919, 2012.</p><p>Johnson EN, Hawken MJ, and Shapley R. The orientation selectivity of color-responsive neurons in macaque V1. <italic>The Journal of Neuroscience</italic> 28: 8096-8106, 2008.</p><p>Livingstone MS, Hubel, D. H. Anatomy and physiology of a color system in the primate visual cortex. <italic>J Neurosci</italic> 4: 309-356, 1984.</p><p>Paninski L. Convergence properties of some spike-triggered analysis techniques. <italic>Advances in neural information processing systems</italic> 189-196, 2003.</p><p>Shapley R, and Hawken, M. J. Color in the cortex: single-and double-opponent cells. <italic>Vision research</italic> 51: 701-717, 2011.</p></body></sub-article></article>