<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">94165</article-id><article-id pub-id-type="doi">10.7554/eLife.94165</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.94165.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Progressively shifting patterns of co-modulation among premotor cortex neurons carry dynamically similar signals during action execution and observation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Zhao</surname><given-names>Zhonghao</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Schieber</surname><given-names>Marc H</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4315-8161</contrib-id><email>mschiebe@ur.rochester.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/022kthw22</institution-id><institution>Department of Biomedical Engineering, University of Rochester</institution></institution-wrap><addr-line><named-content content-type="city">Rochester</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/022kthw22</institution-id><institution>Department of Neurology, University of Rochester</institution></institution-wrap><addr-line><named-content content-type="city">Rochester</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/022kthw22</institution-id><institution>Department of Neuroscience, University of Rochester</institution></institution-wrap><addr-line><named-content content-type="city">Rochester</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Gallego</surname><given-names>Juan Alvaro</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/041kmwe10</institution-id><institution>Imperial College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Makin</surname><given-names>Tamar R</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/013meh722</institution-id><institution>University of Cambridge</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>14</day><month>08</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP94165</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-11-06"><day>06</day><month>11</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-11-06"><day>06</day><month>11</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.11.06.565833"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-01-10"><day>10</day><month>01</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.94165.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-03-21"><day>21</day><month>03</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.94165.2"/></event></pub-history><permissions><copyright-statement>© 2024, Zhao and Schieber</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Zhao and Schieber</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-94165-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-94165-figures-v1.pdf"/><abstract><p>Neurons in macaque premotor cortex show firing rate modulation whether the subject performs an action or observes another individual performing a similar action. Although such mirror neurons have been thought to have highly congruent discharge during execution and observation, many, if not most, show noncongruent activity. Studies of reaching movements, for which low-dimensional neural trajectories exhibit comparatively simple dynamical motifs, have shown that these prevalent patterns of co-modulation pass through subspaces which are shared in part, but in part are visited exclusively during either execution or observation. The neural dynamics of hand movements are more complex, however. We developed a novel approach to examine prevalent patterns of co-modulation during execution and observation of a task that involved reaching, grasping, and manipulation. Rather than following neural trajectories in subspaces that contain their entire time course, we identified time series of instantaneous subspaces, calculated principal angles among them, sampled trajectory segments at the times of selected behavioral events, and projected those segments into the time series of instantaneous subspaces. These instantaneous neural subspaces most often remained distinct during execution versus observation. Nevertheless, latent dynamics during execution and observation could be partially aligned with canonical correlation, indicating some similarity of the relationships among neural representations of different movements relative to one another during execution and observation. We also found that during action execution, mirror neurons showed consistent patterns of co-modulation both within and between sessions, but other non-mirror neurons that were modulated only during action execution and not during observation showed considerable variability of co-modulation.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>grasp</kwd><kwd>hand</kwd><kwd>latent dynamics</kwd><kwd>manipulation</kwd><kwd>neural state space</kwd><kwd>population trajectory</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><award-id>R01NS102343</award-id><principal-award-recipient><name><surname>Schieber</surname><given-names>Marc H</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Population trajectories of premotor cortex mirror neurons progress through distinct subspaces during execution versus observation of reach-grasp-manipulate movements, yet latent dynamics can be aligned, indicating similar relationships among neural representations.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Although the premotor (PM) and primary motor cortex (M1) are generally thought to be involved in the planning and execution of movement, many neurons in these areas have been found to discharge not only when the subject executes a movement, but also when the subject observes a similar movement being performed by another individual. Such neurons have been found in the ventral premotor cortex (PMv) (<xref ref-type="bibr" rid="bib32">Maranesi et al., 2014</xref>; <xref ref-type="bibr" rid="bib17">Gallese et al., 1996</xref>), dorsal premotor cortex (PMd) (<xref ref-type="bibr" rid="bib6">Cisek and Kalaska, 2004</xref>; <xref ref-type="bibr" rid="bib38">Papadourakis and Raos, 2019</xref>; <xref ref-type="bibr" rid="bib1">Albertini et al., 2021</xref>; <xref ref-type="bibr" rid="bib39">Pezzulo et al., 2022</xref>), and M1 (<xref ref-type="bibr" rid="bib10">Dushanova and Donoghue, 2010</xref>; <xref ref-type="bibr" rid="bib31">Kraskov et al., 2014</xref>; <xref ref-type="bibr" rid="bib58">Vigneswaran et al., 2013</xref>). The prevalence of such execution/observation neurons in cortical motor areas argues against their activity during observation being merely an epiphenomenon unrelated to their activity during execution but also poses a larger question: What is the nature of the relationship between their activity during execution versus observation?</p><p>Early studies of these neurons emphasized those with congruent discharge during execution and observation contexts. Congruent neurons discharged during the same type of grasp (<xref ref-type="bibr" rid="bib17">Gallese et al., 1996</xref>; <xref ref-type="bibr" rid="bib42">Rizzolatti et al., 1996</xref>) or retained the same preferred direction (<xref ref-type="bibr" rid="bib10">Dushanova and Donoghue, 2010</xref>; <xref ref-type="bibr" rid="bib27">Kilner and Lemon, 2013</xref>) during both execution and observation. Emphasis on such congruent neurons led to the notion that they mediate understanding of observed actions as they mirror their own activity during execution (<xref ref-type="bibr" rid="bib9">di Pellegrino et al., 1992</xref>; <xref ref-type="bibr" rid="bib43">Rizzolatti and Craighero, 2004</xref>).</p><p>In addition to congruent neurons, however, even early studies also reported many other noncongruent neurons that also discharged during execution and during observation but discharged differently in the two contexts (<xref ref-type="bibr" rid="bib17">Gallese et al., 1996</xref>). In many studies, roughly half or more of the neurons modulated during both execution and observation were noncongruent (<xref ref-type="bibr" rid="bib10">Dushanova and Donoghue, 2010</xref>; <xref ref-type="bibr" rid="bib31">Kraskov et al., 2014</xref>; <xref ref-type="bibr" rid="bib34">Mazurek et al., 2018</xref>; <xref ref-type="bibr" rid="bib22">Jiang et al., 2020</xref>). Of PMv neurons modulated during both execution and observation, over the time course of behavioral trials, only ~20% showed brief periods with strictly congruent firing rates (<xref ref-type="bibr" rid="bib40">Pomper et al., 2023</xref>). And in both PMv and PMd, the proportion of congruent neurons may not be different from that expected by chance alone (<xref ref-type="bibr" rid="bib38">Papadourakis and Raos, 2019</xref>). Though many authors apply the term mirror neurons (MNs) strictly to highly congruent neurons, here, we will refer to all neurons modulated during both contexts—execution and observation—as MNs.</p><p>That so many MNs are active differently during action execution versus observation calls into question not only the extent to which the representation of movements by these neuron populations actually matches in the two contexts, but also the extent to which MN activity during observation has any meaningful function for the organism (<xref ref-type="bibr" rid="bib19">Hickok, 2009</xref>; <xref ref-type="bibr" rid="bib29">Krakauer et al., 2017</xref>). Nevertheless, multiple studies have found that of the neurons in cortical motor areas that are modulated during execution, a large fraction are also modulated during observation. For example, 31 of 64 (49%) pyramidal tract neurons in PMv and 65 of 132 (49%) in M1 showed modulation during both execution and observation (<xref ref-type="bibr" rid="bib30">Kraskov et al., 2009</xref>; <xref ref-type="bibr" rid="bib58">Vigneswaran et al., 2013</xref>; <xref ref-type="bibr" rid="bib31">Kraskov et al., 2014</xref>). Such findings suggest that the observation-related activity of execution-related neurons in PMv, PMd, and M1, some of which project to the spinal cord, is somehow related to the motoric functions of these cortical areas.</p><p>The widely varying degrees of congruence versus noncongruence among individual MNs may obscure population-level relationships between their patterns of co-modulation during execution and observation. Behavior evolving in time may be represented more accurately by the temporal progression of co-modulation in populations of neurons than by the temporal pattern of firing rate in single neurons (<xref ref-type="bibr" rid="bib53">Shenoy et al., 2013</xref>; <xref ref-type="bibr" rid="bib7">Cunningham and Yu, 2014</xref>; <xref ref-type="bibr" rid="bib59">Vyas et al., 2020</xref>). Patterns of co-modulation can be considered in a high-dimensional neural-state space where the firing rate of each neuron is a separate, orthogonal dimension. The instantaneous, simultaneous firing rates of all <italic>N</italic> neurons then form a point in this space, and the time series of these instantaneous points traces out a neural trajectory over time. Neural population trajectories do not visit all regions of the <italic>N</italic>-dimensional state space equivalently, however. Dimensionality reduction techniques can be used to identify a small set of latent dimensions—a subspace—that captures the most prevalent patterns of co-modulation among the population of <italic>N</italic> neurons.</p><p>Studies of neural trajectories underlying action execution that focused on reaching movements made with the arm have revealed that rotational motifs in a low-dimensional subspace capture much of the neural population’s firing rate variance (<xref ref-type="bibr" rid="bib5">Churchland et al., 2012</xref>; <xref ref-type="bibr" rid="bib49">Russo et al., 2020</xref>). But the M1 neural trajectories underlying grasping movements (<xref ref-type="bibr" rid="bib57">Suresh et al., 2020</xref>) or force production at the wrist (<xref ref-type="bibr" rid="bib8">Dekleva et al., 2024</xref>) are more complex. The latent subspaces that capture the predominant patterns of co-modulation among M1 neurons, for example, shift progressively over the time course of behavioral trials involving reaching for, grasping, and manipulating various objects at various locations (<xref ref-type="bibr" rid="bib47">Rouse and Schieber, 2018</xref>).</p><p>A relevant but often overlooked aspect of such dynamics in neuron populations active during both execution and observation has to do with the distinction between condition-independent and condition-dependent variation in neuronal activity (<xref ref-type="bibr" rid="bib24">Kaufman et al., 2016</xref>; <xref ref-type="bibr" rid="bib47">Rouse and Schieber, 2018</xref>). The variance in neural activity averaged across all the conditions in a given task context is condition-independent. For example, in an eight-direction center-out reaching task, averaging a unit’s firing rate as a function of time across all eight directions may show an initially low firing rate that increases prior to movement onset, peaks during the movement, and then declines during the final hold, irrespective of the movement direction. Subtracting this condition-independent activity from the unit’s firing rate during each trial gives the remaining variance, and averaging separately across trials in each of the eight directions then averages out noise variance, leaving the condition-dependent variance that represents the unit’s modulation among the eight directions (conditions). Alternatively, condition-independent, condition-dependent, and noise variance can be partitioned through demixed principal component analysis (PCA) (<xref ref-type="bibr" rid="bib28">Kobak et al., 2016</xref>; <xref ref-type="bibr" rid="bib15">Gallego et al., 2018</xref>). The extent to which neural dynamics occur in a subspace shared by execution and observation versus subspaces unique to execution or observation may differ for the condition-independent versus condition-dependent partitions of neural activity. Here, we tested the hypothesis that the condition-dependent activity of PM MN populations progresses through distinct subspaces during execution versus observation, which would indicate distinct patterns of co-modulation among MNs during execution versus observation.</p><p>Because of the complexity of condition-dependent neural trajectories for movements involving the hand, we developed a novel approach. Rather than examining trajectories over the entire time course of behavioral trials, we identified time series of instantaneous PM MN subspaces covering the time course of behavioral trials. We identified separate time series for execution trials and for observation trials, both involving four different reach-grasp-manipulate (RGM) movements. Given that each subspace in these time series is instantaneous (a snapshot in time), it captures condition-dependent variance in the neural activity among the four RGM movements while minimizing condition-independent (time-dependent) variance.</p><p>We then tested the hypothesis that the condition-dependent subspace shifts progressively over the time course of behavioral trials (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) by calculating the principal angles between four selected instantaneous subspaces that occurred at times easily defined in each behavioral trial—instruction onset (I), go cue (G), movement onset (M), and the beginning of the final hold (H)—and every other instantaneous subspace in the time series. Initial analyses showed that condition-dependent neural trajectories for the four RGM movements tended to separate increasingly over the course of behavioral trials. We therefore additionally examined the combined effects of (i) the progressively shifting subspaces and (ii) the increasing trajectory separation, by decoding neural trajectory segments sampled for 100 ms after times I, G, M, and H and projected into the time series of instantaneous subspaces (<xref ref-type="fig" rid="fig1">Figure 1B</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Conceptual approach.</title><p>(<bold>A</bold>) We hypothesized that the condition-dependent instantaneous subspace of premotor cortex mirror neuron (PM MN) activity shifts progressively throughout the time course of behavioral trials both during execution (orange) and during observation (green). Such shifting can be examined by calculating the principal angles between a selected instantaneous subspace and every other subspace in the time series, <italic>t</italic>. (<bold>B</bold>) Segments clipped from the neural trajectories of two different movements (magenta, purple) in a high-dimensional space, <italic>I</italic>, show varying distance between them when projected into a time series (<italic>t=i, ii, iii</italic>) of shifting, low-dimensional instantaneous subspaces (gray). This varying distance indicative of the progressive shifting of the instantaneous subspace can be followed by decoding the different movements from the trajectory segments projected into the time series of instantaneous subspaces. (<bold>C</bold>) Neural trajectory segments from the four reach-grasp-manipulate (RGM) movements (magenta, purple, cyan, and yellow) during execution and during observation originate in the same high-dimensional space (a), but project into distinct low-dimensional execution (orange, b1) and observation (green, b2) subspaces. Nevertheless, canonical correlation analysis (CCA) may identify another subspace (pale blue, c) where the projected magenta, purple, cyan, and yellow segments from both execution and observation show a similar spatial relationship to one another, with the two segments of each color projecting close to one another. Such correlation between the two sets of trajectory segments projected into the same subspace would indicate similar latent dynamic relationships among the four movements during execution and observation.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94165-fig1-v1.tif"/></fig><p>Finally, we used canonical correlation to ask whether the prevalent patterns of MN co-modulation showed similar relationships among the four RGM movements during execution and observation (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). Such alignment would indicate that the relationships among the trajectory segments in the execution subspace are similar to the relationships among the trajectory segments in the observation subspace, indicating a corresponding structure in the latent dynamic representations of execution and observation movements by the same PM MN population. And finally, because we previously have found that during action execution, the activity of PM MNs tends to lead that of non-MNs which are active only during action execution (AE neurons) (<xref ref-type="bibr" rid="bib35">Mazurek and Schieber, 2019</xref>), we performed parallel analyses of the instantaneous state space of PM AE neurons.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We recorded spiking activity as each of three monkeys executed a delayed response RGM task, and then as each monkey observed the same task being performed by an experimenter (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). Because we chose to study relatively naturalistic movements, the RGM components were not performed separately, but rather in a continuous fluid motion during the movement epoch of the task sequence (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). In previous studies involving a version of this task without separate instruction and delay epochs, we have shown that joint kinematics, EMG activity, and neuron activity in the M1 all vary throughout the movement epoch in relation to both reach location and object grasped, with location predominating early in the movement epoch and object predominating later (<xref ref-type="bibr" rid="bib44">Rouse and Schieber, 2015</xref>; <xref ref-type="bibr" rid="bib45">Rouse and Schieber, 2016a</xref>; <xref ref-type="bibr" rid="bib46">Rouse and Schieber, 2016b</xref>). The present task, however, did not dissociate the reach, the hand shape used to grasp the object, and the manipulation performed on the object. Additional details of the behavioral task are described in the Methods. Three sessions were recorded from each of the three monkeys, R, F, and T (a 6 kg female, 10 kg male, and 10 kg male, respectively). The numbers of successful execution trials (Exe) and observation trials (Obs) involving each of the four objects—sphere, button, coaxial cylinder, and perpendicular cylinder—are given in <xref ref-type="table" rid="table1">Table 1</xref>.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>The reach-grasp-manipulate (RGM) task.</title><p>(<bold>A</bold>) In separate blocks of trials, monkeys reached for, grasped, and manipulated four different objects themselves (Exe) and then observed a human performing the same task (Obs). (<bold>B</bold>) The times of eight behavioral events from start-of-trial to end-of-trial divided each trial into seven epochs from initial hold to reward. For analyses, the data were aligned separately on, and trajectories were sampled for 100 ms following the times of four selected events—instruction onset (I), go cue (G), movement onset (M), and the beginning of the final hold (H). (<bold>C</bold>) Recording array locations in ventral premotor cortex (PMv) (green) and dorsal premotor cortex (PMd) (orange) for each monkey have been redrawn from intraoperative photographs. PCD—precentral dimple; AS—arcuate sulcus; CS—central sulcus; r—rostral; m—medial. Scale bars representing 4 mm apply to all three monkeys.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94165-fig2-v1.tif"/></fig><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Numbers of trials in each session.</title><p>For each of the three sessions from each of the three monkeys, numbers of trials involving each of the four objects (sphere, button, coaxial cylinder, perpendicular cylinder) are given in parentheses separately for execution and for observation.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"/><th align="center" valign="bottom" colspan="2">Monkey R</th><th align="center" valign="bottom" colspan="2">Monkey F</th><th align="center" valign="bottom" colspan="2">Monkey T</th></tr></thead><tbody><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Exe</td><td align="left" valign="bottom">Obs</td><td align="left" valign="bottom">Exe</td><td align="left" valign="bottom">Obs</td><td align="left" valign="bottom">Exe</td><td align="left" valign="bottom">Obs</td></tr><tr><td align="left" valign="bottom">Session 1</td><td align="char" char="." valign="bottom">(22,8,25,26)</td><td align="char" char="." valign="bottom">(32,31,30,31)</td><td align="char" char="." valign="bottom">(58,59,62,63)</td><td align="char" char="." valign="bottom">(71,72,71,72)</td><td align="char" char="." valign="bottom">(57,54,57,55)</td><td align="char" char="." valign="bottom">(60,61,59,57)</td></tr><tr><td align="left" valign="bottom">Session 2</td><td align="char" char="." valign="bottom">(34,26,34,38)</td><td align="char" char="." valign="bottom">(40,41,40,37)</td><td align="char" char="." valign="bottom">(59,58,60,56)</td><td align="char" char="." valign="bottom">(73,72,75,74)</td><td align="char" char="." valign="bottom">(47,53,52,43)</td><td align="char" char="." valign="bottom">(57,53,58,58)</td></tr><tr><td align="left" valign="bottom">Session 3</td><td align="char" char="." valign="bottom">(42,41,49,45)</td><td align="char" char="." valign="bottom">(49,50,51,49)</td><td align="char" char="." valign="bottom">(63,58,58,58)</td><td align="char" char="." valign="bottom">(72,75,74,74)</td><td align="char" char="." valign="bottom">(43,41,38,42)</td><td align="char" char="." valign="bottom">(50,48,48,50)</td></tr></tbody></table></table-wrap><p>The three monkeys each were implanted with floating microelectrode arrays (FMAs, Microprobes for Life Sciences) in the PMv and in the PMd. The locations of the arrays in each monkey are illustrated in <xref ref-type="fig" rid="fig2">Figure 2C</xref>. Using object and epoch as factors, we performed two-way repeated measures analysis of variance (ANOVA) on the firing rate of each sorted unit recorded from the arrays in each session (see Methods). Because unit firing rates typically differed during execution and observation, we performed such ANOVAs separately on execution trials and observation trials. <xref ref-type="table" rid="table2">Table 2</xref> gives the numbers of PM (PMv+PMd) units identified in each session as being modulated significantly during both execution and observation, which we refer to as MNs, along with the numbers of units modulated significantly during execution but not observation (AE), during observation but not execution (AO), or with no significant modulation during either execution or observation (NS). The numbers of AO and NS units were consistently small across monkeys and sessions. The present analyses therefore focus on MNs and, for comparison, AE neurons.</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Numbers of premotor cortex units in each session.</title><p>For each of the three sessions from each of the three monkeys (R, T, and F), numbers of PM units are given for each of four classes in the format of total (PMv, PMd). MNs—mirror neurons, modulated significantly during action execution and during action observation. AE—action execution neurons, modulated during execution but not during observation. AO—action observation neurons, modulated during observation but not execution. NS—not significant, units not modulated significantly during either execution or observation.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Monkey</th><th align="left" valign="bottom">Session</th><th align="left" valign="bottom">MN</th><th align="left" valign="bottom">AE</th><th align="left" valign="bottom">AO</th><th align="left" valign="bottom">NS</th></tr></thead><tbody><tr><td align="left" valign="bottom" rowspan="3"><bold>R</bold></td><td align="char" char="." valign="bottom"><bold>1</bold></td><td align="char" char="." valign="bottom">48 (19,29)</td><td align="char" char="." valign="bottom">35 (20,15)</td><td align="char" char="." valign="bottom">3 (1,2)</td><td align="char" char="." valign="bottom">5 (2,3)</td></tr><tr><td align="char" char="." valign="bottom"><bold>2</bold></td><td align="char" char="." valign="bottom">47 (21,26)</td><td align="char" char="." valign="bottom">25 (16,9)</td><td align="char" char="." valign="bottom">5 (1,4)</td><td align="char" char="." valign="bottom">11 (4,7)</td></tr><tr><td align="char" char="." valign="bottom"><bold>3</bold></td><td align="char" char="." valign="bottom">37 (19,18)</td><td align="char" char="." valign="bottom">49 (20,29)</td><td align="char" char="." valign="bottom">1 (1,0)</td><td align="char" char="." valign="bottom">8 (7,1)</td></tr><tr><td align="left" valign="bottom" rowspan="3"><bold>T</bold></td><td align="char" char="." valign="bottom"><bold>1</bold></td><td align="char" char="." valign="bottom">79 (37,42)</td><td align="char" char="." valign="bottom">15 (5,10)</td><td align="char" char="." valign="bottom">2 (0,2)</td><td align="char" char="." valign="bottom">7 (1,6)</td></tr><tr><td align="char" char="." valign="bottom"><bold>2</bold></td><td align="char" char="." valign="bottom">91 (48,43)</td><td align="char" char="." valign="bottom">22 (6,16)</td><td align="char" char="." valign="bottom">3 (1,2)</td><td align="char" char="." valign="bottom">7 (1,6)</td></tr><tr><td align="char" char="." valign="bottom"><bold>3</bold></td><td align="char" char="." valign="bottom">100 (48,52)</td><td align="char" char="." valign="bottom">18 (7,11)</td><td align="char" char="." valign="bottom">0 (0,0)</td><td align="char" char="." valign="bottom">6 (2,4)</td></tr><tr><td align="left" valign="bottom" rowspan="3"><bold>F</bold></td><td align="char" char="." valign="bottom"><bold>1</bold></td><td align="char" char="." valign="bottom">44 (24,20)</td><td align="char" char="." valign="bottom">7 (5,2)</td><td align="char" char="." valign="bottom">1 (1,0)</td><td align="char" char="." valign="bottom">8 (8,0)</td></tr><tr><td align="char" char="." valign="bottom"><bold>2</bold></td><td align="char" char="." valign="bottom">47 (32,15)</td><td align="char" char="." valign="bottom">10 (9,1)</td><td align="char" char="." valign="bottom">5 (1,4)</td><td align="char" char="." valign="bottom">3 (3,0)</td></tr><tr><td align="char" char="." valign="bottom"><bold>3</bold></td><td align="char" char="." valign="bottom">42 (28,14)</td><td align="char" char="." valign="bottom">9 (7,2)</td><td align="char" char="." valign="bottom">3 (1,2)</td><td align="char" char="." valign="bottom">3 (3,0)</td></tr></tbody></table></table-wrap><sec id="s2-1"><title>Condition-dependent versus condition-independent neural activity in PM MNs</title><p>Whereas a large fraction of condition-dependent neural variance during reaching movements without grasping can be captured in a two-dimensional subspace (<xref ref-type="bibr" rid="bib5">Churchland et al., 2012</xref>; <xref ref-type="bibr" rid="bib2">Ames et al., 2014</xref>), condition-dependent activity in movements that involve grasping is more complex (<xref ref-type="bibr" rid="bib57">Suresh et al., 2020</xref>). In part, this may reflect the greater complexity of controlling the 24 degrees of freedom (DOFs) in the hand and wrist as compared to the 4 DOFs in the elbow and shoulder (<xref ref-type="bibr" rid="bib55">Sobinov and Bensmaia, 2021</xref>). <xref ref-type="fig" rid="fig3">Figure 3</xref> illustrates this complexity in a PM MN population during the present RGM movements. Here, PCA was performed on the activity of a PM MN population across the entire time course of execution trials involving all four objects. The colored traces in <xref ref-type="fig" rid="fig3">Figure 3A</xref> show neural trajectories averaged separately across trials involving each of the four objects and then projected into the PC1 versus PC2 plane of the total neural space. Most of the variance in these four trajectories is comprised of a shared rotational component. The black trajectory, obtained by averaging trajectories from trials involving all four objects together, represents this condition-independent (i.e. independent of the object involved) activity. The condition-dependent (i.e. dependent on which object was involved) variation in activity is reflected by the variation in the colored trajectories around the black trajectory. The condition-dependent portions can be isolated by subtracting the black trajectory from each of the colored trajectories. The resulting four condition-dependent trajectories have been projected into the PC1 versus PC2 plane of their own common subspace in <xref ref-type="fig" rid="fig3">Figure 3B</xref>. Rather than exhibiting a simple rotational motif, these trajectories appear knotted. To better understand how these complex, condition-dependent trajectories progress over the time course of RGM trials, we chose to examine time series of instantaneous subspaces.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Neural trajectories of condition-independent versus condition-dependent activity.</title><p>(<bold>A</bold>) Neural trajectories of premotor cortex mirror neuron firing rates averaged across multiple execution trials involving each of the four objects (sphere—purple, button—cyan, coaxial cylinder [Coax]—magenta, perpendicular cylinder [Perp]—yellow) have been projected into the PC1 versus PC2 plane of the total neural activity. Averaging these four trajectories gives their common, condition-independent (CI) trajectory (black). Time proceeds clockwise from left, with data separately aligned at four selected times: triangle—instruction onset (I); circle—go cue (G); square—movement onset (M); diamond—beginning of final hold (H). (<bold>B</bold>) Condition-dependent trajectories obtained by subtracting the CI trajectory (black) from each of the four single-object trajectories (colors) in (<bold>A</bold>), and then projected into the PC1 versus PC2 plane of their common, condition-dependent (CD) subspace across the entire time course of trials. Data from monkey R, session 2.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94165-fig3-v1.tif"/></fig></sec><sec id="s2-2"><title>Instantaneous subspaces shift progressively during both execution and observation</title><p>We identified an instantaneous subspace at each 1 ms time step of RGM trials. At each time step, we applied PCA to the 4 instantaneous neural states (i.e. the 4 points on the neural trajectories representing trials involving the 4 different objects each averaged across 20 trials per object, totaling 80 trials), yielding a three-dimensional subspace at that time (see Methods). Note that because these three-dimensional subspaces are essentially instantaneous, they capture the condition-dependent variation in neural states, but not the common, condition-independent variation. To examine the temporal progression of these instantaneous subspaces, we then calculated the principal angles between each 80-trial instantaneous subspace and the instantaneous subspaces averaged across <italic>all</italic> trials at four behavioral time points that could be readily defined across trials, sessions, and monkeys: the onset of the instruction (I), the go cue (G), the movement onset (M), and the beginning of the final hold (H). This process was repeated 10 times with replacement to assess the variability of the principal angles. The closer the principal angles are to 0°, the closer the two subspaces are to being identical; the closer to 90°, the closer the two subspaces are to being orthogonal.</p><p><xref ref-type="fig" rid="fig4">Figure 4A–D</xref> illustrates the temporal progression of the first principal angle of the MN population in the three sessions (red, green, and blue) from monkey R during execution trials. As illustrated in <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> (see also the related Methods), in each session, all three principal angles, each of which could range from 0° to 90°, tended to follow a similar time course. In the Results, we therefore illustrate only the first (i.e. smallest) principal angle. Solid traces represent the mean across 10-fold cross-validation using the 80-trial subsets of all the available trials; shading indicates ±1 standard deviation. As would be expected, the instantaneous subspace using 80 trials approaches the subspace using all trials at each of the four selected times—I, G, M, and H—indicated by the relatively narrow trough dipping toward 0°. Of greater interest are the slower changes in the first principal angle in between these four time points. <xref ref-type="fig" rid="fig4">Figure 4A</xref> shows that after instruction onset (I), the instantaneous subspace shifted quickly away from the subspace at time I, indicated by a rapid increase in principal angle to levels not much lower than what might be expected by chance alone (horizontal dashed line). In contrast, throughout the remainder of the instruction and delay epochs (from I to G), <xref ref-type="fig" rid="fig4">Figure 4B and C</xref> show that the 80-trial instantaneous subspace shifted gradually and concurrently, not sequentially, toward the all-trial subspaces that would be reached at the end of the delay period (G) and then at the onset of movement (M), indicated by the progressive decreases in principal angle. As shown by <xref ref-type="fig" rid="fig4">Figure 4D</xref>, shifting toward the H subspace did not begin until the movement onset (M). To summarize, these changes in principal angles indicate that after shifting briefly toward the subspace present at time the instruction appeared (I), the instantaneous subspace shifted progressively throughout the instruction and delay epochs toward the subspace that would be reached at the time of the go cue (G), then further toward that at the time of movement onset (M), and only thereafter shifted toward the instantaneous subspace that would be present at the time of the hold (H).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Time course of the first principal angle between instantaneous subspaces.</title><p>(<bold>A–D</bold>) Mirror neuron (MN) populations during execution trials; (<bold>E–H</bold>) MN populations during observation trials; (<bold>I–L</bold>) AE neuron populations during execution trials. Each frame shows the time course of the first principal angle between the time series of instantaneous subspaces and that present at one of four selected times—A, E, I: instruction onset; B, F, J: go cue; C, G, K: movement onset; or D, H, L: the beginning of the final hold. Results in 1 ms steps have been aligned separately at the times of the instruction onset (<bold>I</bold>), go cue (<bold>G</bold>), movement onset (<bold>M</bold>), and hold (<bold>H</bold>) —each indicated by a vertical line as labeled in the frame at upper left. Red, green, and blue traces represent sessions 1, 2, and 3, respectively, from monkey R. Solid traces represent means, and shaded areas represent ±1 standard deviation across 10-fold cross-validation as described in the Methods. Horizontal black lines indicate the average (solid) and the average minus 3 standard deviations (dashed) of the first principal angle between a fixed 3D space and other 3D spaces chosen randomly within an <italic>N</italic>-dimensional space (see <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref> and related Methods). Here, <italic>N</italic>=37, the number of MNs in session 3. Horizontal purple bars in the left column (<bold>A, E, I</bold>) indicate 500 ms, which applies to the entire row.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94165-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>First, second, and third principal angles as a function of time.</title><p>An example in which the three principal angles, <inline-formula><alternatives><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft1">\begin{document}$\theta _{1},\theta _{2},\theta _{3}$\end{document}</tex-math></alternatives></inline-formula>, between the instantaneous subspace at time M (movement onset) and the entire time series of instantaneous subspaces have been plotted as a function of time for premotor cortex mirror neurons (PM MNs). (Data from monkey R, session 1.) Note that all three principal angles go to 0° at time M when the current instantaneous subspace is, by definition, the subspace at time M.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94165-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>First principal angles between a fixed 3D subspace and 5000 other 3D subspaces randomly chosen from spaces of dimensionality, <italic>N</italic>, varying from 5 to 500.</title><p>Error bars indicate ±1 standard deviation from the mean. Note that as the dimensionality of the parent space decreases, the random principal angle also decreases.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94165-fig4-figsupp2-v1.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>Time course of the first principal angle of instantaneous subspaces for AE neurons during observation trials.</title><p>As would be expected given that AE neurons were not modulated significantly during observation trials, in the observation context AE populations had no gradual changes in principal angle, showing only relatively sharp troughs dipping toward 0° at each of the four selected times when the current instantaneous subspace, by definition, approached that at times I, G, M, or H. Formatting is the same as in <xref ref-type="fig" rid="fig4">Figure 4</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94165-fig4-figsupp3-v1.tif"/></fig></fig-group><p><xref ref-type="fig" rid="fig4">Figure 4E–H</xref> shows the progression of the first principal angle of the MN population during observation trials. Overall, the temporal progression of the MN instantaneous subspace during observation was similar to that found during execution, particularly around times I and H. The decrease in principal angle relative to the G and M instantaneous subspaces during the delay epoch was less pronounced during observation than during execution. Nevertheless, these findings support the hypothesis that the condition-dependent subspace of PM MNs shifts progressively over the time course of RGM trials during both execution and observation, as illustrated schematically in <xref ref-type="fig" rid="fig1">Figure 1A</xref>.</p><p>We also examined the temporal progression of the instantaneous subspace of AE neurons. As would be expected given that AE neurons were not modulated significantly during observation trials, in the observation context AE populations had no gradual changes in principal angle (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>). During execution, however, <xref ref-type="fig" rid="fig4">Figure 4I–L</xref> shows that the AE populations had a pattern of gradual decrease in principal angle similar to that found in the MN population (<xref ref-type="fig" rid="fig4">Figure 4A–D</xref>). After the instruction onset, the instantaneous subspace shifted quickly away from that present at time I and progressed gradually toward that present at times G and M, only shifting toward that present at time H after movement onset. As for the PM MN populations, the condition-dependent subspace of the PM AE populations shifted progressively over the time course of execution RGM trials.</p></sec><sec id="s2-3"><title>Neural trajectories separate progressively during both execution and observation</title><p>The progressive changes in principal angles do not capture another important aspect of condition-dependent neural activity. The neural trajectories during trials involving different objects separated increasingly as trials progressed in time. To illustrate this increasing separation, we clipped 100 ms segments of high-dimensional MN population trial-averaged trajectories beginning at times I, G, M, and H, for trials involving each of the four objects. We then projected the set of four object-specific trajectory segments clipped at each time into each of the four instantaneous 3D subspaces at times I, G, M, and H. This process was repeated separately for execution trials and for observation trials.</p><p>For visualization, we projected these trial-averaged trajectory segments from an example session into the PC1 versus PC2 planes (which consistently captured &gt;70% of the variance) of the I, G, M, or H instantaneous 3D subspaces. In <xref ref-type="fig" rid="fig5">Figure 5</xref>, the trajectory segments for each of the four objects (sphere—purple, button—cyan, coaxial cylinder—magenta, perpendicular cylinder—yellow) sampled at different times (rows) have been projected into each of the four instantaneous subspaces defined at different times (columns). Rather than appearing knotted as in <xref ref-type="fig" rid="fig3">Figure 3</xref>, these short trajectory segments are distinct when projected into each instantaneous subspace.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Mirror neuron trajectory segments projected into instantaneous subspaces.</title><p>(<bold>A</bold>) Using execution data from an example session (monkey T, session 3), trajectory segments averaged across trials involving each of the four objects (sphere—purple, button—cyan, coaxial cylinder [coax]—magenta, perpendicular cylinder [perp]—yellow) were clipped for 100 ms immediately following each of four behavioral events (rows: instruction onset, go cue, movement onset, hold). Each set of these four segments was then projected into the PC1 versus PC2 plane of the instantaneous 3D subspace present at four different times (columns: <bold>I</bold>, <bold>G, M, H</bold>). (<bold>B</bold>) The same process was performed using observation data from the same session. The PC1 versus PC2 scales at lower left in (<bold>B</bold>) apply to all frames in both (<bold>A</bold> and <bold>B</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94165-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Cumulative separation.</title><p>To summarize the changes in trajectory separation illustrated in <xref ref-type="fig" rid="fig5">Figure 5</xref>, we calculated the three-dimensional cumulative separation (<italic>CS)</italic>, the summed pointwise Euclidean distance between all pairwise combinations of the four object-specific trajectory segments (see Methods) for each set of four segments projected into each of the four instantaneous subspaces at times I, G, M, or H. <italic>CS</italic> values, which we use only to characterize the phenomenon of trajectory separation, are illustrated for execution from the example session of <xref ref-type="fig" rid="fig5">Figure 5</xref> as a color matrix in (<bold>A</bold>) and for observation in (<bold>B</bold>). For both execution and observation, the highest <italic>CS</italic> values lie on the main diagonal, increasing in temporal order from instruction to go to movement to hold, with the exception that for execution, <italic>CS</italic> for hold was less than for movement. (<bold>C</bold>) and (<bold>D</bold>) show <italic>CS</italic> matrices averaged across all three sessions from all three monkeys for execution and observation, respectively, demonstrating that the features seen in the example session of <xref ref-type="fig" rid="fig5">Figure 5</xref> were relatively consistent across sessions. Across all nine sessions, two-way analysis of variance (ANOVA) showed significant main effects on <italic>CS</italic> values of both segment and subspace, as well as a significant interaction effect during both execution and observation (p&lt;0.05). In both of these contexts, as the instantaneous subspace of the PM MN population shifted progressively over the time course of reach-grasp-manipulate (RGM) trials, the separation of condition-dependent neural trajectories also increased.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94165-fig5-figsupp1-v1.tif"/></fig></fig-group><p>Along the main diagonal of <xref ref-type="fig" rid="fig5">Figure 5A</xref>, each set of trajectory segments is projected into its corresponding subspace, showing that during execution the trajectory segments for the four objects were close together at the time of instruction onset (I), became more separated at the time of the go cue (G), had separated further still at movement onset (M), and had become somewhat less separated at the beginning of the final hold (H). During observation (<xref ref-type="fig" rid="fig5">Figure 5B</xref>), a similar trend is evident along the main diagonal, although the separation is less, reflecting the commonly described lower firing rates of MNs during observation than during execution (<xref ref-type="bibr" rid="bib12">Ferroni et al., 2021</xref>). In addition, during observation, the separation of the four trajectories was somewhat greater at the beginning of the hold (H) than at movement onset (M). Off-diagonal frames along the rows (same trajectory segments, different instantaneous subspaces) or along the columns (different trajectory segments, same instantaneous subspaces) show less separation than along the main diagonal, both during execution and during observation. To summarize these differences in trajectory separation, we calculated the three-dimensional cumulative separation (<italic>CS</italic>—see Methods) for each set of four segments projected into each of the four instantaneous subspaces both for this example session and averaged across all nine sessions (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). These differences in separation when the same trajectory segments are projected into different subspaces reflect the progressive shifting of the condition-dependent instantaneous subspace of the PM MN population as trials progressed over time, as illustrated schematically in <xref ref-type="fig" rid="fig1">Figure 1B</xref>.</p></sec><sec id="s2-4"><title>Decodable information changes progressively during both execution and observation</title><p>As RGM trials proceeded in time, the condition-dependent neural activity of the PM MN population thus changed in two ways. First, the instantaneous condition-dependent subspace shifted, indicating that the patterns of firing rate co-modulation among neurons representing the four different RGM movements changed progressively, both during execution and during observation. Second, as firing rates generally increased, the neural trajectories representing the four RGM movements became progressively more separated, more so during execution than during observation.</p><p>To evaluate the combined effects of these two progressive changes, we clipped 100 ms single-trial trajectory segments beginning at times I, G, M, or H, and projected these trajectory segments from individual trials into the instantaneous 3D subspaces at 50 ms time steps. At each of these time steps, we trained a separate long short-term memory (LSTM) decoder to classify individual trials according to which of the four objects was involved in that trial. We expected that the trajectory segments would be classified most accurately when projected into instantaneous subspaces near the time at which the trajectory segments were clipped. At other times, we reasoned that classification accuracy would depend both on the similarity of the current instantaneous subspace to that found at the clip time as evaluated by the principal angle (<xref ref-type="fig" rid="fig4">Figure 4</xref>) and on the separation of the four trajectories at the clip time (<xref ref-type="fig" rid="fig5">Figure 5</xref>).</p><p><xref ref-type="fig" rid="fig6">Figure 6A–D</xref> shows the resulting classification accuracy as a function of trial time for the 100 ms instruction, go, movement, or hold MN execution trajectory segments, each projected into the same time series of instantaneous MN execution subspaces from the same session. Solid curves indicate classification accuracy averaged across 10-fold cross-validation (as described in the Methods); the surrounding shaded areas indicate ±1 standard deviation from that average; different colors indicate results from the three different sessions in monkey R. Horizontal lines indicate the range of classification accuracies that would have been obtained had the instantaneous subspaces been chosen randomly, which we estimated for each set of trajectory segments by bootstrapping—projecting the trajectory segments into a randomly selected 3D space, training an LSTM decoder, and classifying single trials, repeated 500 times (<xref ref-type="bibr" rid="bib36">Natraj et al., 2022</xref>).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Decodable information as a function of time.</title><p>(<bold>A–D</bold>) Classification accuracy for mirror neuron execution trajectory segments projected into instantaneous execution subspaces; (<bold>E–H</bold>) for mirror neuron observation trajectory segments projected into their instantaneous observation subspaces; (<bold>I–L</bold>) for action-execution neuron trajectory segment projected into their instantaneous execution subspaces. (<bold>A, E, I</bold>) Instruction trajectory segments; (<bold>B, F, J</bold>) go segments; (<bold>C, G, K</bold>) movement segments; (<bold>D, H, L</bold>) hold segments. Red, green, and blue traces represent sessions 1, 2, and 3, respectively, from monkey R. Results in 50 ms steps have been aligned separately at the times of the instruction onset (I), go cue (G), movement onset (M), and hold (H)—each indicated by a vertical line as labeled in the frame at upper left. In each frame, the short horizontal orange flag at the top of the vertical lines indicates the 100 ms during which each set of trajectory segments was clipped; the horizontal purple bar at lower left represents 500 ms. Solid curves indicate mean classification accuracy across 10-fold cross-validation as a function of time, with the shaded areas indicating 1 standard deviation. Horizontal black lines indicate the mean (solid) ±3 standard deviations (dashed) classification accuracy obtained by projecting each set of trajectory segments into 500 randomly selected 3D spaces.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94165-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Decodable information as a function of time in premotor cortex (PM) AE neuron populations.</title><p>Formatting is the same as in <xref ref-type="fig" rid="fig6">Figure 6</xref>. As might have been expected, AE populations showed little, if any, decodable information during observation.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94165-fig6-figsupp1-v1.tif"/></fig></fig-group><p>As might have been expected based both on principal angles and on trajectory separation, classification accuracy consistently peaked at a time point within or near the 100 ms duration of the corresponding trajectory segments (orange flags at the top of the vertical lines). Classification accuracy decreased progressively at times preceding and following each of these peaks. In monkey R, mean classification of the instruction trajectory segments (<xref ref-type="fig" rid="fig6">Figure 6A</xref>) initially was ~0.25, rose toward ~0.50 around the time of the instruction onset, and then fell back to ~0.25. Mean accuracy for the go segments (<xref ref-type="fig" rid="fig6">Figure 6B</xref>) also began at ~0.25, rose gradually during the delay epoch to peak at ~0.75 around the time of the go cue, and decreased thereafter. For the movement (<xref ref-type="fig" rid="fig6">Figure 6C</xref>) and hold (<xref ref-type="fig" rid="fig6">Figure 6D</xref>) segments, classification accuracy started somewhat higher (reflecting greater trajectory segment separation at the time they were clipped, <xref ref-type="fig" rid="fig5">Figure 5</xref>) and peaked at ~0.90. Similar trends were seen for monkeys T and F. For each monkey, classification accuracy for each of the four sets of trajectory segments—instruction, go, movement, and hold—as a function of time was relatively consistent across sessions.</p><p>Although classification accuracy consistently peaked near the behavioral event at which time each set of trajectory segments was clipped, the rise in accuracy before and the decline after the peak differed depending on the behavioral event. Peak classification accuracy for instruction segments was modest, beginning to rise from mean chance levels ~100 ms before the instruction onset and quickly falling back thereafter (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). At times outside of this brief peak, however, the instantaneous subspace was no more similar to that at the time of instruction onset than would be expected from chance alone.</p><p>In contrast, classification accuracy for the go trajectory segments (<xref ref-type="fig" rid="fig6">Figure 6B</xref>) was elevated above mean chance levels for more of the RGM trial duration. Though exceeding 3 standard deviations from mean chance only late in the delay epoch, go segment classification accuracy rose steadily through the delay epoch, peaked near the go cue, then fell back to near mean chance levels during the reaction (G to M) and movement (M to H) epochs. Likewise, the rise in classification accuracy of movement trajectory segments (<xref ref-type="fig" rid="fig6">Figure 6C</xref>) also began, not after the go cue, but earlier, in the middle of the delay epoch (I to G). Movement segment classification accuracy rose steadily from the second half of the delay epoch through the reaction epoch (G to M), peaked above chance levels shortly after movement onset (M), and fell back to near baseline during the movement epoch (M to H). Had the condition-dependent instantaneous subspaces during the delay epoch been orthogonal to those at the time of movement onset, the movement trajectory segments would have had no projection in delay epoch subspaces and classification accuracy would have remained at baseline. The progressive increase in classification accuracy of movement trajectory segments during the preparatory delay and reaction epochs indicates that as these epochs proceeded, the condition-dependent neural trajectories of PM MNs shifted gradually, not abruptly, toward where they would be at movement onset.</p><p>Classification accuracy of the hold trajectory segments (<xref ref-type="fig" rid="fig6">Figure 6D</xref>) increased relatively late in execution trials. During the instruction, delay, and reaction epochs, the instantaneous subspaces were no more similar than chance to that at the beginning of the hold epoch. Classification accuracy of hold trajectory segments began to increase only after movement onset (M), rising through the movement epoch, peaking near the beginning of the hold epoch and decreasing thereafter.</p><p>We performed a similar classification accuracy analysis for observation trials. For instruction trajectory segments (<xref ref-type="fig" rid="fig6">Figure 6E</xref>), the brief peak of classification accuracy occurring around the time of instruction onset (I) during observation trials was quite like that found during execution trials. For the go and movement segments (<xref ref-type="fig" rid="fig6">Figure 6F and G</xref>), although classification accuracy tended to be lower, a gradual rise again began during the delay epoch. Classification accuracy of the hold trajectory segments, during observation as during execution, began to increase only after movement onset (<xref ref-type="fig" rid="fig6">Figure 6H</xref>).</p><p>During execution trials, classification accuracy for AE populations (<xref ref-type="fig" rid="fig6">Figure 6I–L</xref>) showed a time course quite similar to that for MN populations, though amplitudes were lower overall, most likely because of the smaller population sizes. During observation, AE populations showed only low-amplitude, short-lived peaks of classification accuracy around times I, G, M, and H (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). Given that individual AE neurons showed no statistically significant modulation during observation trials, even these small peaks might not have been expected. Previous studies have indicated, however, that neurons not individually related to task events nevertheless may contribute to a population response (<xref ref-type="bibr" rid="bib53">Shenoy et al., 2013</xref>; <xref ref-type="bibr" rid="bib7">Cunningham and Yu, 2014</xref>; <xref ref-type="bibr" rid="bib14">Gallego et al., 2017</xref>; <xref ref-type="bibr" rid="bib22">Jiang et al., 2020</xref>).</p></sec><sec id="s2-5"><title>Do PM MNs progress through the same subspaces during execution and observation?</title><p>Having found that PM MN populations show similar progressive shifts in their instantaneous neural subspace during execution and observation of RGM trials, as well as similar changes in decodable information, we then asked whether this progression passes through similar subspaces during execution and observation. To address this question, we first calculated the principal angles between the instantaneous MN <italic>execution</italic> subspace at selected times I, G, M, or H and the entire time series of instantaneous MN <italic>observation</italic> subspaces (<xref ref-type="fig" rid="fig7">Figure 7A–D</xref>). Conversely, we calculated the principal angles between the instantaneous <italic>observation</italic> subspaces at selected times I, G, M, or H and the entire time series of instantaneous <italic>execution</italic> subspaces (<xref ref-type="fig" rid="fig7">Figure 7E–H</xref>). Although the principal angles were slightly smaller than might be expected from chance alone, indicating some minimal overlap of execution and observation instantaneous subspaces, the instantaneous observation subspaces did not show any progressive shift toward the I, G, M, or H execution subspace (<xref ref-type="fig" rid="fig7">Figure 7A–D</xref>), nor did the instantaneous execution subspaces shift toward the I, G, M, or H observation subspace (<xref ref-type="fig" rid="fig7">Figure 7E–H</xref>). We also used classification accuracy to evaluate cross-projected trajectory segments and again found little evidence of overlap between execution and observation subspaces (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). Although monkey T did show evidence of some degree of overlap (<xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>), throughout the time course of trials in monkeys R and F, the instantaneous execution and observation condition-dependent subspaces showed little, if any, overlap.</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Time course of the first principal angle cross-calculated between instantaneous execution and observation subspaces of premotor cortex mirror neurons as a function of time.</title><p>First principal angles between the instantaneous <italic>execution</italic> subspace at selected times I, G, M, or H and the entire time series of instantaneous <italic>observation</italic> subspaces are shown above (<bold>A–D</bold>); between the instantaneous <italic>observation</italic> subspace at selected times I, G, M, or H and the entire time series of instantaneous <italic>execution</italic> subspaces below (<bold>E–H</bold>). Formatting is the same as in <xref ref-type="fig" rid="fig4">Figure 4</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94165-fig7-v1.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>Classification accuracy of trajectory segments cross-projected between instantaneous execution and observation subspaces of premotor cortex mirror neurons as a function of time.</title><p>On top, instruction, go, movement, and hold <italic>execution trajectory segments</italic> (<bold>A, B, C, D</bold>, respectively) from individual trials have been projected into the time series of <italic>instantaneous observation subspaces</italic> and classified with a separate long short-term memory (LSTM) decoder at each time point. Below, instruction, go, movement, and hold <italic>observation trajectory segments</italic> (<bold>E, F, F, H </bold>, respectively) have been projected into the time series of <italic>instantaneous execution subspaces</italic> and classified. Neither of these cross-projections showed gradual progression to peaks of classification accuracy. Nor did the classification accuracy in either cross-projection exceed that expected from chance alone (horizontal dashed lines). These results confirm that little, if any, overlap between instantaneous, condition-dependent execution and observation subspaces was present in monkey R. Findings were similar in monkey F. Formatting is the same as in <xref ref-type="fig" rid="fig6">Figure 6</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94165-fig7-figsupp1-v1.tif"/></fig><fig id="fig7s2" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 2.</label><caption><title>Partial overlap of execution and observation subspaces in monkey T.</title><p>(<bold>A–D</bold>) The first principal angles between the instantaneous <italic>execution</italic> subspace at times I, G, or M (though not H) and the time series of instantaneous <italic>observation</italic> subspaces showed an abrupt drop beginning at the time of instruction onset (<bold>I</bold>) and continuing until the time of movement onset (<bold>M</bold>). This drop, which reflects partial overlap of the execution and observation subspaces, was marked during session 1 (red), but less so during sessions 2 and 3 (green and blue, respectively). (<bold>A’–D’</bold>) Likewise, instruction, go, or movement, <italic>execution trajectory segments</italic> projected into the time series of <italic>instantaneous observation subspaces</italic> showed a rise in decodable information, also indicative of some degree of overlap, beginning at the time of instruction onset (<bold>I</bold>). (<bold>A–D</bold>) are formatted as <xref ref-type="fig" rid="fig4">Figure 4</xref>; (<bold>A’–D’</bold>) as in <xref ref-type="fig" rid="fig6">Figure 6</xref>. Overlap like that seen here in monkey T was not found in monkey R or F.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94165-fig7-figsupp2-v1.tif"/></fig></fig-group></sec><sec id="s2-6"><title>Alignment of latent dynamics</title><p>We next asked whether MN execution and observation trajectory segments, though progressing through distinct subspaces, nevertheless could be aligned using canonical correlation analysis (CCA) to project both sets of trajectory segments into another, common subspace, as illustrated schematically in <xref ref-type="fig" rid="fig1">Figure 1C</xref>. Such alignment would indicate that neural representations of trials involving the four objects bore a similar relationship to one another in neural space during execution and observation, even though they occurred in different subspaces. For example, the trajectories of PMd+M1 neuron populations recorded from two different monkeys during center-out reaching movements could be aligned well (<xref ref-type="bibr" rid="bib50">Safaie et al., 2023</xref>). CCA showed, for example, that in both brains, the neural trajectory for the movement to the target at 0° was closer to the trajectory for movement to the target at 45° than to the trajectory for the movement to the target at 180°. Relationships among these latent dynamic representations of the eight movements were thus similar even though the neural populations were recorded from two different monkeys.</p><p>We therefore applied CCA (see Methods) to align the trajectory segments of execution trials with those of observation trials. As an example, trial-averaged hold execution trajectory segments in their original execution subspace at time H and hold observation trajectory segments in their original observation subspace at time H are shown in <xref ref-type="fig" rid="fig8">Figure 8A</xref>. The relationships among the execution trajectory segments appear substantially different than that among the observation trajectory segments. But when both sets of trajectory segments are projected into another common subspace identified with CCA, as shown in <xref ref-type="fig" rid="fig8">Figure 8B</xref>, a similar relationship among the neural representations of the four movements during execution and observation is revealed. In both behavioral contexts, the neural representation of movements involving the sphere (purple) is now closest to the representation of movements involving the coaxial cylinder (magenta) and farthest from that of movements involving the button (cyan). The two sets of trajectory segments are more or less ‘aligned’.</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Alignment of trajectory segments by canonical correlation.</title><p>(<bold>A</bold>) For an example session (monkey F, session 2), mirror neuron (MN) hold trajectory segments from execution trials have been projected into their original instantaneous execution subspace at time H (left) and from observation trials into their original instantaneous observation subspace also at time H (right). (<bold>B</bold>) The same execution (left) and observation (right) trajectory segments all have been projected into another, common subspace identified with canonical correlation. Colors indicate trajectory segments from trials involving the sphere—purple, coaxial cylinder (coax)—magenta, perpendicular cylinder (perp)—yellow, and button—cyan. (<bold>C</bold>) The three correlation coefficients resulting from canonical correlation analysis (CCA) (CC1, CC2, and CC3) have been averaged across comparisons from all sessions from the three monkeys. Thick bars representing the standard deviations of the three coefficients cross at their means, with a thin line dropped vertically from that point to the CC1 versus CC2 plane. CCA of MN trajectory segments from execution trials recorded in two different sessions from the same monkey (black, MN:1/2) is used as a point of reference with which to compare alignment of MN execution versus observation trials collected in the same session (red, MN:E/O) and MN versus AE neuron execution segments from the same session (blue, MN/AE). (<bold>D</bold>) Correlation coefficients from within-group CCA alignment for MN execution segments (gray, MN:E/E), MN observation trajectory segments (orange, MN:O/O), and AE execution segments (light blue, AE:E/E). See text for further description.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-94165-fig8-v1.tif"/></fig><p>As a positive control, we first aligned MN execution trajectory segments from two different sessions in the same monkey (which we abbreviate as MN:1/2). The two sessions in monkey R provided only one possible comparison, but the three sessions in monkeys T and F each provided three comparisons. For each of these seven comparisons, we found the bootstrapped average of CC1, of CC2, and of CC3. The 3D means ± standard deviations of these seven averages for the instruction, go, movement, and hold trajectory segments have been plotted in <xref ref-type="fig" rid="fig8">Figure 8C</xref> (black). The progressive increase in mean correlation coefficients (CCs) reflects the general increase in firing rates relative to trial-by-trial variability from the early to later trial epochs. The highest values for MN:1/2 correlations were obtained for the movement trajectory segments (<inline-formula><alternatives><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>1</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.89</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mover><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>2</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.77</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mover><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>3</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.61</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft2">\begin{document}$\overline{CC\text{1}}=0.89,\, \overline{\, CC\text{2}}=0.77,\, \overline{\, CC\text{3}}=0.61$\end{document}</tex-math></alternatives></inline-formula>). These relatively high values indicate relatively consistent relationships among the movement neural trajectory segments representing the four different RGM movements from session to session, as would have been expected from previous studies (<xref ref-type="bibr" rid="bib15">Gallego et al., 2018</xref>; <xref ref-type="bibr" rid="bib16">Gallego et al., 2020</xref>; <xref ref-type="bibr" rid="bib50">Safaie et al., 2023</xref>).</p><p>Given that PM MN activity progressed largely through nonoverlapping instantaneous subspaces during execution versus observation, we proceeded to ask whether the relationship among the neural representations of the four RGM movements was similar during execution versus observation. To address this question, we aligned MN execution trajectory segments with MN observation trajectory segments from the same session (MN:E/O; two sessions from monkey R, three from monkey T, three from monkey F). The 3D mean ± standard deviation CCs for these eight alignments also have been plotted in <xref ref-type="fig" rid="fig8">Figure 8C</xref> (red). Here, the highest values were reached for the hold trajectory segments (<inline-formula><alternatives><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>1</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.73</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mover><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>2</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.54</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mover><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>3</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.39</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft3">\begin{document}$\overline{CC\text{1}}=0.73,\, \overline{\, CC\text{2}}=0.54,\, \overline{\, CC\text{3}}=0.39$\end{document}</tex-math></alternatives></inline-formula>). Though not as high as for execution/execution alignment, these values indicate substantial alignment of MN trajectory segments from execution and observation. PM MN populations thus showed some degree of similarity in the relationships among their latent dynamic representations of the four RGM movements during execution and observation, particularly at the time of the hold.</p><p>Although MNs are known to be present in considerable numbers in both the M1 and PM (see Introduction), most studies of movement-related cortical activity in these areas make no distinction between neurons with activity only during action execution (AE neurons) and those with activity during both execution and observation (MNs). This reflects an underlying assumption that during action execution, MNs function in parallel with AE neurons, differing only during observation. We therefore tested the hypothesis that MN and AE neuron execution trajectory segments from the same session would align well. <xref ref-type="fig" rid="fig8">Figure 8C</xref> (blue) shows the mean CCs between MN and AE execution trajectory segments across eight alignments (MN/AE; 2R, 3T, 3F), which reached the highest values for the hold segments (<inline-formula><alternatives><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>1</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.57</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mover><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>2</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.35</mml:mn><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mover><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>3</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.19</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft4">\begin{document}$\overline{CC\text{1}}=0.57,\, \overline{\, CC\text{2}}=0.35,\ \overline{\, CC\text{3}}=0.19$\end{document}</tex-math></alternatives></inline-formula>). All three of these coefficients were substantially lower than those for the MN execution versus observation alignments given above. Surprisingly, the alignment of AE neuron execution trajectory segments with those of the simultaneously recorded MN population was weaker than the alignment of MN trajectories during execution versus observation.</p><p>Statistical comparisons across the three sets of alignments illustrated in <xref ref-type="fig" rid="fig8">Figure 8C</xref> (MN:1/2; MN:E/O; and MN/AE) showed significant variation in each of the three CCA coefficients for each set of trajectory segments, with the exception of the instruction segments which were all quite low (Kruskal-Wallis tests; instruction segments, p&gt;0.05; go segments, p&lt;0.01; movement segments, p&lt;0.01; hold segments, p&lt;0.001). Post hoc testing showed that in all significant cases (9 cases: 3 CCA coefficients × 3 sets of trajectory segments, Tukey’s honestly significant difference tests), though the MN:E/O coefficients might not be significantly lower than the corresponding MN/1:2 coefficients and/or significantly higher than the MN/AE coefficients, the MN/AE coefficients were significantly lower than the corresponding MN/1:2 coefficients in all 9 cases. These findings fail to support the hypothesis that during action execution, MN and AE neuron trajectory segments would align well and suggest instead that the patterns of co-modulation among AE neurons during the four different RGM movements did not align with the patterns of co-modulation among MNs.</p><p>Did these differences in MN:1/2, MN:E/O, and MN/AE alignment result from consistent differences in their respective patterns of co-modulation, or from greater trial-by-trial variability in the patterns of co-modulation among MNs during observation than during execution, and still greater variability among AE neurons during execution? The bootstrapping approach we used for CCA (see Methods) enabled us to evaluate the consistency of relationships among trajectory segments across repeated samplings of trials recorded from the same neuron population in the same session and in the same context (execution or observation). We therefore performed 500 iterations of CCA between two different random samples of MN execution (MN:E/E), MN observation (MN:O/O), or AE execution (AE:E/E) trajectory segments from a given session (2R, 3T, 3F). This within-group alignment of MN execution trajectory segments from the same session (<xref ref-type="fig" rid="fig8">Figure 8D</xref>, MN:E/E, gray, hold: <inline-formula><alternatives><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>1</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.88</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mover><mml:mrow><mml:mtext> </mml:mtext><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>2</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.74</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mover><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>3</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.55</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft5">\begin{document}$\overline{CC\text{1}}=0.88,\, \overline{\ CC\text{2}}=0.74,\, \overline{\, CC\text{3}}=0.55$\end{document}</tex-math></alternatives></inline-formula>) was as strong as between-session alignment (<xref ref-type="fig" rid="fig8">Figure 8C</xref>, MN/1:2, black). But within-group alignment of MN observation trajectory segments (<xref ref-type="fig" rid="fig8">Figure 8D</xref>, MN:O/O, orange, hold: <inline-formula><alternatives><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>1</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.65</mml:mn><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mover><mml:mrow><mml:mtext> </mml:mtext><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>2</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.46</mml:mn><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mover><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>3</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.24</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft6">\begin{document}$\overline{CC\text{1}}=0.65,\ \overline{\ CC\text{2}}=0.46,\ \overline{\, CC\text{3}}=0.24$\end{document}</tex-math></alternatives></inline-formula>) was lower than that found with MN execution segments (<xref ref-type="fig" rid="fig8">Figure 8C</xref>, MN:E/O, red, <inline-formula><alternatives><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>1</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.73</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mover><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>2</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.54</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mover><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>3</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.39</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft7">\begin{document}$\overline{CC\text{1}}=0.73,\, \overline{\, CC\text{2}}=0.54,\, \overline{\, CC\text{3}}=0.39$\end{document}</tex-math></alternatives></inline-formula>). Likewise, within-group alignment of AE neuron trajectory segments (<xref ref-type="fig" rid="fig8">Figure 8D</xref>, AE:E/E, light blue, hold: <inline-formula><alternatives><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>1</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.46</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mover><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>2</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mover><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>3</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.10</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft8">\begin{document}$\overline{CC\text{1}}=0.46,\, \overline{\, CC\text{2}}=0.25,\ \overline{\, CC\text{3}}=0.10$\end{document}</tex-math></alternatives></inline-formula>) was lower than their alignment with MN execution segments (<xref ref-type="fig" rid="fig8">Figure 8C</xref>, MN/AE, blue, hold: <inline-formula><alternatives><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>1</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.57</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mover><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>2</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.35</mml:mn><mml:mo>,</mml:mo><mml:mspace width="thinmathspace"/><mml:mover><mml:mrow><mml:mspace width="thinmathspace"/><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mtext>3</mml:mtext></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.19</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft9">\begin{document}$\overline{CC\text{1}}=0.57,\, \overline{\, CC\text{2}}=0.35,\, \overline{\, CC\text{3}}=0.19$\end{document}</tex-math></alternatives></inline-formula>). Whereas MN execution trajectories were relatively consistent within sessions, MN observation trajectories and AE execution trajectories were less so.</p><p>Statistical comparisons across these three sets of within-group alignments (MN:E/E; MN:O/O; and AE:E/E) showed significant variation in each of the three CCA coefficients for all four trajectory segments (Kruskal-Wallis tests; instruction segments, p&lt;0.05; go segments, p&lt;0.01; movement segments, p&lt;0.001; hold segments, p&lt;0.001). Post hoc testing showed that in all significant cases (12 cases: 3 CCA coefficients × 4 sets of trajectory segments, Tukey’s honestly significant difference tests), though the within-group MN:O/O coefficients might not be significantly lower than the corresponding MN:E/E coefficients and/or significantly higher than the AE:E/E coefficients, the within-group AE:E/E coefficients were significantly lower than the corresponding MN:E/E coefficients in all 12 cases. These findings suggest that the patterns of co-modulation among AE neurons during the four different RGM movements, as well as the patterns of co-modulation among MNs during observation, were more variable from trial to trial than were the patterns of MN co-modulation during execution. This greater trial-to-trial variability in co-modulation of MNs during observation, and even greater variability in AE neurons during execution (<xref ref-type="fig" rid="fig8">Figure 8D</xref>), likely contribute to the weaker alignment of MN observation segments with MN execution segments and even weaker alignment of AE and MN execution segments (<xref ref-type="fig" rid="fig8">Figure 8C</xref>). Whereas the predominant patterns of co-modulation among MNs during the four different RGM movements were relatively consistent, co-modulation among MNs during observation was less consistent, and co-modulation of AE neurons during execution even less so.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>As neurophysiological studies have advanced from examination of single neurons to neuron populations, analytic approaches have advanced from analyses of single neuron firing rates to analyses of co-modulation patterns among neuron populations. The co-modulation in a neuronal population can be expressed as the trajectory of the simultaneous firing rates of the <italic>N</italic> neurons through their <italic>N</italic>-dimensional state space, and the predominant patterns of co-modulation can be extracted by projecting this high-dimensional trajectory into a low-dimensional subspace that captures a large proportion of the population’s firing rate variance. Previous studies of reaching movements have shown that the low-dimensional population trajectories of PMd and M1 neurons occupy one subspace during a preparatory delay epoch and then transition to a different subspace during the reaching movement per se (<xref ref-type="bibr" rid="bib23">Kaufman et al., 2014</xref>; <xref ref-type="bibr" rid="bib11">Elsayed et al., 2016</xref>). Compared to reaching movements, however, the low-dimensional trajectories of neuronal activity controlling hand movements are relatively complex (<xref ref-type="bibr" rid="bib47">Rouse and Schieber, 2018</xref>; <xref ref-type="bibr" rid="bib57">Suresh et al., 2020</xref>). To approach this problem, rather than examining neural trajectories in subspaces that capture only a selected epoch of the behavioral task, we identified time series of instantaneous, condition-dependent subspaces covering the entire time course of RGM behavioral trials that included a preparatory delay epoch.</p><p>Using this approach, we found that the instantaneous, condition-dependent subspace of PM MN populations shifts progressively during both execution and observation of RGM trials. The instantaneous subspace of AE neuron populations likewise shifts progressively during action execution. This progressive shifting of the instantaneous subspace resembles that found previously using fractional overlap of condition-dependent variance in M1 neuron populations performing a similar RGM task without a delay epoch (<xref ref-type="bibr" rid="bib47">Rouse and Schieber, 2018</xref>). Although the progressive shifting described here is a rotation in the mathematical sense, it is not necessarily a smooth rotation in a few dimensions. We therefore have used the word ‘shift’ to contrast with the smooth rotation of neural trajectories in a low-dimensional subspace described in other studies, particularly those using jPCA (<xref ref-type="bibr" rid="bib5">Churchland et al., 2012</xref>; <xref ref-type="bibr" rid="bib49">Russo et al., 2020</xref>; <xref ref-type="bibr" rid="bib48">Rouse et al., 2022</xref>).</p><sec id="s3-1"><title>Features of the instantaneous subspace</title><p>Short bursts of ‘signal’ related discharge are known to occur in a substantial fraction of PMd neurons beginning at latencies of ~60 ms following an instructional stimulus (<xref ref-type="bibr" rid="bib60">Weinrich et al., 1984</xref>; <xref ref-type="bibr" rid="bib6">Cisek and Kalaska, 2004</xref>). Here, we found that the instantaneous subspace shifted briefly toward the subspace present at the time of instruction onset (I), similarly during execution and observation. This brief trough in principal angle (<xref ref-type="fig" rid="fig4">Figure 4A</xref>) and the corresponding peak in classification accuracy (<xref ref-type="fig" rid="fig7">Figure 7A</xref>) in part may reflect smoothing of firing rates with a 50 ms Gaussian kernel. We speculate, however, that the early rise of this peak at the time of instruction onset also reflects the anticipatory activity often seen in PMd neurons in expectation of an instruction, which may not be entirely nonspecific, but rather may position the neural population to receive one of a limited set of potential instructions (<xref ref-type="bibr" rid="bib33">Mauritz and Wise, 1986</xref>). We attribute the relatively low amplitude of peak classification accuracy for instruction trajectory segments to the likely possibility that only the last 40 ms of our 100 ms instruction segments captured signal-related discharge.</p><p>The firing rates of MNs in both PMv and PMd have been shown previously to modulate during preparatory delay periods (<xref ref-type="bibr" rid="bib6">Cisek and Kalaska, 2004</xref>; <xref ref-type="bibr" rid="bib32">Maranesi et al., 2014</xref>). During execution of a reaching task, condition-dependent subspaces during the preparatory delay are orthogonal to those found during the subsequent movement epochs (<xref ref-type="bibr" rid="bib23">Kaufman et al., 2014</xref>; <xref ref-type="bibr" rid="bib11">Elsayed et al., 2016</xref>). Studies that have identified such orthogonal subspaces specifically optimized preparatory and movement subspaces to be orthogonal to one another, however, whereas the present approach did not. Here, we found that during the preparatory delay epoch of the present RGM task, the condition-dependent, instantaneous subspace did not remain orthogonal to that which would be present at movement onset or during the movement epoch. Rather, as the preparatory delay proceeded, the instantaneous subspace shifted concurrently toward both the subspace that would be present at the time of the go cue ending the preparatory delay (G) and that which would be present at movement onset (M). By time G, the instantaneous subspace had already shifted approximately halfway toward the time M subspace. This difference in the orthogonality of preparatory versus movement subspaces may reflect differences in reaching without grasping, which involves coordinated motion in 4 DOFs at the shoulder and elbow, versus the present RGM movements, which involve simultaneous, fluidly coordinated motion in at least 22 DOFs of the shoulder, elbow, wrist, and digits (<xref ref-type="bibr" rid="bib44">Rouse and Schieber, 2015</xref>). Finally, we note that the progressive shift toward the subspace present at the onset of the final hold (H) did begin only after the delay period had ended (G) and around the time of movement onset (M).</p></sec><sec id="s3-2"><title>PM MN populations during execution versus observation</title><p>In general, instantaneous execution subspaces were distinct from instantaneous observation subspaces, indicated by the continuously large principal angles between them (<xref ref-type="fig" rid="fig7">Figure 7</xref>) and by low classification accuracy when execution trajectories were cross-projected into observation subspaces and vice versa (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). This was the case not only during corresponding time points in execution and observation trials, but throughout their entire time course. Moreover, in all three monkeys, progressive shifting of the instantaneous, condition-dependent subspace was absent both in the principal angles between execution and observation subspaces and in the decoding of execution trajectory segments cross-projected into observation subspaces (and vice versa). These findings indicate that the predominant modes of co-modulation among PM MNs are largely distinct during execution and observation.</p><p>Although MNs originally were thought to provide highly congruent neural representations of action execution and action observation (<xref ref-type="bibr" rid="bib17">Gallese et al., 1996</xref>; <xref ref-type="bibr" rid="bib42">Rizzolatti et al., 1996</xref>), the present findings are consistent with recent studies that have emphasized the considerable fraction of neurons with noncongruent activity, as well as differences in neural population activity during action execution versus action observation (<xref ref-type="bibr" rid="bib22">Jiang et al., 2020</xref>; <xref ref-type="bibr" rid="bib40">Pomper et al., 2023</xref>). As more situations have been investigated, the number of conditions needed to define a ‘true’ MN in the strict sense of being entirely congruent has grown, making the duration of such congruence brief and/or its likelihood comparable to chance (<xref ref-type="bibr" rid="bib38">Papadourakis and Raos, 2019</xref>; <xref ref-type="bibr" rid="bib40">Pomper et al., 2023</xref>).</p><p>We did not attempt to classify neurons in our PM MN populations as strictly congruent, broadly congruent, or noncongruent. Nevertheless, the minimal overlap we found in instantaneous execution and observation subspaces would be consistent with a low degree of congruence in our PM MN populations. Particularly during one session, monkey T was an exception in this regard, showing a considerable degree of overlap between execution and observation subspaces, not unlike the shared subspace found in other studies that identified orthogonal execution and observation subspaces as well (<xref ref-type="bibr" rid="bib22">Jiang et al., 2020</xref>). Although our microelectrode arrays were placed in similar cortical locations in the three monkeys, by chance, monkey T’s PM MN population may have included a substantial proportion of congruent neurons.</p></sec><sec id="s3-3"><title>Alignment of trajectory segments with canonical correlation</title><p>Given the complexity of condition-dependent neural trajectories across the entire time course of RGM trials (<xref ref-type="fig" rid="fig3">Figure 3B</xref>), rather than attempting to align entire neural trajectories, we applied canonical correlation to trajectory segments clipped for 100 ms following four well-defined behavioral events: instruction onset, go cue, movement onset, and the beginning of the final hold. In all cases, alignment was poorest for instruction segments, somewhat higher for go segments, and strongest for movement and hold segments (<xref ref-type="fig" rid="fig8">Figure 8C</xref>). This progressive increase in alignment likely reflects a progressive increase in the difference between average neuron firing rates for trials involving different objects (<xref ref-type="fig" rid="fig5">Figure 5</xref>) relative to the trial-by-trial variance in firing rate for a given object.</p><p>Corresponding neural representations of action execution and observation during task epochs with higher neural firing rates have been described previously in PMd MNs and in PMv MNs using representational similarity analysis (<xref ref-type="bibr" rid="bib38">Papadourakis and Raos, 2019</xref>). And during force production in eight different directions, neural trajectories of PMd neurons draw similar ‘clocks’ during execution, cooperative execution, and passive observation (<xref ref-type="bibr" rid="bib39">Pezzulo et al., 2022</xref>). Likewise, in the present study, despite execution and observation trajectories progressing through largely distinct subspaces, in all three monkeys, execution and observation trajectory segments showed some degree of alignment, particularly the movement and hold segments (<xref ref-type="fig" rid="fig8">Figure 8C</xref>), indicating similar relationships among the latent dynamic representations of the four RGM movements during execution and observation.</p><p>Alignment between trajectory segments of the same PM MN population during execution versus observation in the same session, however, was less than that found between MN execution segments from two different sessions in the same monkey. In part, this may reflect the lower firing rates of PM MNs typically found during observation as compared to execution trials (<xref ref-type="bibr" rid="bib12">Ferroni et al., 2021</xref>). Alternatively, the lower alignment may reflect more trial-by-trial variability in MN observation segments than in MN execution segments, as indicated by the limited within-group alignment of MN observation trajectory segments (<xref ref-type="fig" rid="fig8">Figure 8D</xref>).</p><p>Based on the assumption that AE neurons and MNs function as a homogenous neuron population during action execution, we had expected AE and MN execution trajectory segments to align closely. During execution trials, the progression of instantaneous condition-dependent subspaces and of classification accuracy in AE populations was quite similar to that in MN populations. We were surprised to find, therefore, that alignment between execution trajectory segments from AE populations and from the simultaneously recorded MN populations was even lower than alignment between MN execution and observation segments (<xref ref-type="fig" rid="fig8">Figure 8C</xref>, blue versus red). Moreover, whereas within-group alignment of MN execution trajectory segments was high, within-group alignment of AE neuron execution trajectory segments was low (<xref ref-type="fig" rid="fig8">Figure 8D</xref>, gray versus light blue). These findings indicate that the predominant patterns of co-modulation among MNs during execution are quite consistent within sessions, but the patterns of co-modulation among AE neurons are considerably more variable. Together with our previous finding that modulation of MNs leads that of non-MNs in time—both at the single neuron level and at the population level (<xref ref-type="bibr" rid="bib35">Mazurek and Schieber, 2019</xref>)—this difference in consistency versus variability leads us to speculate that, during action execution, MNs carry a consistent forward model of the intended movement, while AE neurons carry more variable feedback information.</p></sec><sec id="s3-4"><title>The role of MN populations</title><p>Neither the congruence versus noncongruence of individual MN discharge nor the canonical correlation of population dynamics during execution and observation provides direct causal evidence that MNs mediate understanding of the observed actions of other individuals (<xref ref-type="bibr" rid="bib19">Hickok, 2009</xref>; <xref ref-type="bibr" rid="bib61">Yuste, 2015</xref>; <xref ref-type="bibr" rid="bib29">Krakauer et al., 2017</xref>). Many interpretations of such findings are possible, and testing various hypotheses ultimately may require selective experimental manipulation (e.g. inactivation) of MN activity during observation in ways beyond our current capabilities. Nevertheless, the common finding that large fractions of neurons in both PM and M1 discharge both during execution and during observation makes it unlikely that the discharge of MNs during observation is vestigial, with no meaning for the organism.</p><p>Although we did not track extraocular movements, video monitoring demonstrated that our monkeys remained attentive throughout the blocks of observation trials, actively scanning the visual environment. Though perhaps not following the experimenter’s movements closely with eye movements, or even with covert visual attention, the present results in and of themselves demonstrate that during observation trials the PM MN population was processing information on the sequential epochs of the behavioral task (<xref ref-type="bibr" rid="bib34">Mazurek et al., 2018</xref>), as well as the object to which the experimenter’s actions were directed on each trial. These findings are consistent with the notion that the PM MN population predictively represents the sequence of behavioral events during observation trials (<xref ref-type="bibr" rid="bib26">Kilner et al., 2007</xref>; <xref ref-type="bibr" rid="bib32">Maranesi et al., 2014</xref>; <xref ref-type="bibr" rid="bib12">Ferroni et al., 2021</xref>). Our finding that within-group alignment of MN observation trajectory segments was lower than that of MN execution segments (<xref ref-type="fig" rid="fig8">Figure 8D</xref>), however, indicates more trial-by-trial variability of MN co-modulation during observation than during execution. In addition to any consistent, predictive, forward model of the observed experimenter’s expected performance, MNs thus may also receive visual input that incorporates more variable, trial-by-trial deviation from the predicted performance being observed.</p><p>One classic interpretation of similar latent dynamics in the PM MN population during execution and observation would be that this similarity provides a means for the brain to recognize similar movements performed by the monkey during execution and by the experimenter during observation. Through some process akin to a communication subspace (<xref ref-type="bibr" rid="bib52">Semedo et al., 2019</xref>), brain regions beyond PM might recognize the correspondence between the latent dynamics of the executed and observed actions.</p><p>Alternatively, given that observation of another individual can be considered a form of social interaction, PM MN population activity during action observation, rather than representing movements made by another individual similar to one’s own movements, instead may represent different movements one might execute oneself in response to those made by another individual (<xref ref-type="bibr" rid="bib37">Ninomiya et al., 2020</xref>; <xref ref-type="bibr" rid="bib4">Bonini et al., 2022</xref>; <xref ref-type="bibr" rid="bib13">Ferrucci et al., 2022</xref>; <xref ref-type="bibr" rid="bib40">Pomper et al., 2023</xref>). This possibility is consistent with the finding that the neural dynamics of PM MN populations are more similar during observation of biological versus non-biological movements than during execution versus observation (<xref ref-type="bibr" rid="bib1">Albertini et al., 2021</xref>). Though neurons active only during observation of others (AO units) have been hypothesized to drive observation activity in MNs, the present AO populations were too small to analyze with the approaches we applied here. Nevertheless, the similar relative organization of the execution and observation population activity in PM MNs revealed here by alignment of their latent dynamics through CCA could constitute a correspondence between particular movements that might be made by the subject in response to particular movements made by the other individual, i.e., responsive movements which would not necessarily be motorically similar to the observed movements.</p><p>The present analyses, as well as others, have focused on the condition-dependent variance in MN population activity (<xref ref-type="bibr" rid="bib22">Jiang et al., 2020</xref>). Other studies that have not separated the condition-dependent versus condition-independent variance in neural activity have described even more similar latent dynamics during execution and observation (<xref ref-type="bibr" rid="bib34">Mazurek et al., 2018</xref>; <xref ref-type="bibr" rid="bib21">Jerjian et al., 2020</xref>; <xref ref-type="bibr" rid="bib39">Pezzulo et al., 2022</xref>). We speculate that condition-dependent activity may represent particular types of movement (e.g. sphere, button, coaxial cylinder, or perpendicular cylinder) in a manner that differs depending on the actor (one’s self versus another individual). Concurrently, condition-independent activity may provide a neural representation of a class of action (e.g. RGM movements) independent of the actor.</p></sec></sec><sec id="s4" sec-type="methods"><title>Methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Reagent type (species) or resource</th><th align="left" valign="bottom">Designation</th><th align="left" valign="bottom">Source or reference</th><th align="left" valign="bottom">Identifiers</th><th align="left" valign="bottom">Additional information</th></tr></thead><tbody><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">Trellis</td><td align="left" valign="bottom">Ripple</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://rippleneuro.com/support/software-downloads-updates/">https://rippleneuro.com/support/software-downloads-updates/</ext-link></td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">MATLAB</td><td align="left" valign="bottom">MathWorks</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://www.mathworks.com/products/matlab.html">https://www.mathworks.com/products/matlab.html</ext-link></td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom"/><td align="left" valign="bottom">Custom code for data analysis</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://github.com/ShiftingSubspace/shiftsubs">https://github.com/ShiftingSubspace/shiftsubs</ext-link></td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">Floating Microelectrode Arrays</td><td align="left" valign="bottom">Microprobes for Life Sciences</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://www.microprobes.com/products/multichannel-arrays/fma">https://www.microprobes.com/products/multichannel-arrays/fma</ext-link></td><td align="left" valign="bottom">See Neuron recording</td></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">Trek</td><td align="left" valign="bottom">Ripple</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://rippleneuro.com/ripple-products/trek-electrophysiology-system/">https://rippleneuro.com/ripple-products/trek-electrophysiology-system/</ext-link></td><td align="left" valign="bottom">See Neuron recording</td></tr></tbody></table></table-wrap><p>Three Rhesus monkeys, R, T, and F (a 6 kg female, a 10 kg male, and an 11 kg male, <italic>Macaca mulatta</italic>) were used in the present study. All procedures for the care and use of these nonhuman primates followed the Guide for the Care and Use of Laboratory Animals and were approved by the University Committee on Animal Resources at the University of Rochester, Rochester, New York, under protocol #101058.</p><sec id="s4-1"><title>Execution trials</title><p>Each monkey was trained to perform a delayed-response RGM task (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Prior to each trial, a ring of blue LEDs was illuminated around the pole supporting a center object, and a 4 kHz tone began, both signaling the end of an inter-trial interval and the opportunity to begin a new trial. The monkey initiated the following sequence by pulling the center object for an initial hold epoch of randomly varied duration (500–1000 ms). A ring of blue LEDs around the pole supporting one of four peripheral objects was then illuminated, instructing the monkey as to the target object for the current trial. After 500 ms, these instruction LEDs were extinguished, and the monkey was required to wait for a preparatory delay epoch lasting randomly 500–2000 ms. At the end of this preparatory delay epoch, the blue LEDs for the center object were extinguished and the 4 kHz tone ceased, providing a go cue. The monkey then reached for, grasped, and manipulated the remembered target object—turning a sphere, pushing a button, pulling a coaxial cylinder (coax), or pulling a perpendicular cylinder (perp). The RGM sequence was performed as a single, uninterrupted, fluid movement of the entire upper extremity (<xref ref-type="bibr" rid="bib44">Rouse and Schieber, 2015</xref>; <xref ref-type="bibr" rid="bib45">Rouse and Schieber, 2016a</xref>; <xref ref-type="bibr" rid="bib46">Rouse and Schieber, 2016b</xref>). Once the instructed object had been manipulated, a ring of green LEDs around the object illuminated (indicating successful manipulation of the object) and the ring of blue LEDs for that object also illuminated (indicating correct object). The monkey was then required to hold the instructed object in its manipulated position for a final hold epoch of 1000 ms, after which the blue LEDs were extinguished. (The green LEDs extinguished whenever the monkey released the object.) After a 300 ms delay, the monkey received a liquid reward on each successful trial.</p><p>The selection and sequence of target objects in successive trials were controlled by custom software (Unified Task Control System, Gil Rivlis, <ext-link ext-link-type="uri" xlink:href="https://github.com/grivlis/UTCS3_RGM">https://github.com/grivlis/UTCS3_RGM</ext-link>), which also (1) generated behavioral event marker codes (<xref ref-type="fig" rid="fig2">Figure 2B</xref>) and (2) arranged trials involving the four different objects in a pseudorandom block design (<xref ref-type="bibr" rid="bib41">Rivlis, 2025</xref>). The behavioral event marker codes indicated the times at which specific behavioral events occurred: start of trial, instruction onset, instruction offset, go cue (delay epoch ended), movement onset, hold began, hold ended, end of trial. One trial involving each of the four different objects was presented sequentially in a block. Once a block had been completed, the sequence of the four objects was shuffled randomly for the next block. To prevent the monkey from skipping more difficult objects, if the monkey failed to complete a trial successfully, the same target was repeated until the monkey succeeded.</p></sec><sec id="s4-2"><title>Observation trials</title><p>In a separate block of trials, the monkey observed an experimenter performing the same delayed-response RGM task. The experimenter occasionally made errors intentionally. The monkey received a reward each time the experimenter performed a successful trial, but not when the experimenter made an error, which kept the monkey attentive to the experimenter’s performance. Although extraocular movements were not recorded or controlled, video monitoring verified that the monkey remained alert and attentive throughout blocks of observation trials.</p></sec><sec id="s4-3"><title>Neuron recording</title><p>Each of the three monkeys was implanted with FMAs (Microprobes for Life Sciences) in the PMv and the PMd. In monkeys R and T, 16-channel FMAs were implanted; in monkey F, 32-channel FMAs were used (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). Monkeys R and F each had a total of 64 recording electrodes implanted in PMd and 64 in PMv, whereas monkey T had 64 in PMd, but only 48 in PMv. Broadband signals were recorded simultaneously from all 128 electrodes using a Trek/Trellis data acquisition system (Ripple, Salt Lake City, UT, USA), which also recorded the behavioral event marker codes generated by the behavioral control system. In each recording session, data were collected during similar numbers of successful trials involving each target object during execution and then during observation, as summarized in <xref ref-type="table" rid="table2">Table 2</xref>. Off-line, spike waveforms were extracted and sorted using custom software (<xref ref-type="bibr" rid="bib45">Rouse and Schieber, 2016a</xref>). Sorted units were classified as definite single units, probably single units, multiunits, or noise based on their signal-to-noise ratio and estimated fraction of false-positive spikes using our previously published criteria. All three types of units were included in the present analyses.</p></sec><sec id="s4-4"><title>MN identification</title><p>Although many studies have focused on neurons from either PMv or PMd, given that neurons in each area have been shown to be modulated during both reaching and grasping (<xref ref-type="bibr" rid="bib56">Stark et al., 2007</xref>) and during both execution and observation (<xref ref-type="bibr" rid="bib38">Papadourakis and Raos, 2019</xref>), we chose to combine units from these two cortical areas for the present analyses. Each unit was tested for task-related modulation. Because a given neuron’s firing rates during execution and observation trials almost always differed (<xref ref-type="bibr" rid="bib12">Ferroni et al., 2021</xref>; <xref ref-type="bibr" rid="bib40">Pomper et al., 2023</xref>), we tested each unit for modulation using data from these two contexts separately. Spike counts from each successful behavioral trial were extracted during eleven 200 ms periods: (i) before instruction onset, (ii) after instruction onset, (iii) before instruction offset, (iv) after instruction offset (delay epoch began), (v) before delay ended, (vi) after delay ended (reaction epoch began), (vii) before movement onset, (viii) after movement onset (movement epoch began), (ix) before movement ended, (x) after movement ended (hold epoch began), (xi) before hold ended. We then conducted two-way ANOVA on these spike counts using object and time period as factors. We considered a unit task-related if it showed a significant main effect of either (i) object or (ii) time period, or a significant (iii) interaction effect. Any unit modulated significantly both during execution and during observation was considered to be a MN. Because each unit thus had six opportunities to show significance, we used a corrected significance criterion of p&lt;0.0083 (&lt;0.05/6). Any unit modulated during execution but not during observation was considered an action execution (AE) neuron. Any unit modulated during action observation but not during execution was considered an action observation neuron (AO). Units unmodulated during both execution and observation were considered not significantly (NS) related to the task.</p></sec><sec id="s4-5"><title>Data analysis</title><p>All data analysis was performed in MATLAB using custom code (<ext-link ext-link-type="uri" xlink:href="https://github.com/ShiftingSubspace/shiftsubs">https://github.com/ShiftingSubspace/shiftsubs</ext-link>; <xref ref-type="bibr" rid="bib62">Zhao, 2024</xref>). Spike times for each neuron were binned (bin width = 1 ms), smoothed with a Gaussian kernel (<inline-formula><alternatives><mml:math id="inf10"><mml:mi mathvariant="normal">σ</mml:mi></mml:math><tex-math id="inft10">\begin{document}$\mathrm{\sigma }$\end{document}</tex-math></alternatives></inline-formula>=50 ms), and square-root transformed to render variance similar from low to high firing rates (<xref ref-type="bibr" rid="bib25">Kihlberg et al., 1972</xref>; <xref ref-type="bibr" rid="bib54">Snedecor and Cochran, 1980</xref>). The activity of each neuron was time-aligned to four behavioral events and truncated before and after using the median delay, reaction, and movement times per object and per session as follows: (i) instruction onset (I)—500 ms before to 500 ms after; (ii) go cue (G)—median delay duration before to half the median reaction time after; (iii) movement onset (M)—half the median reaction time before to 200 ms after; and (iv) start of final hold (H)—200 ms before to 200 ms after. These four snippets of neural activity were concatenated for each trial. Neural activity was then stored as a three-dimensional tensor (<italic>N</italic> × <italic>K</italic> × <italic>T</italic>, where <italic>N</italic> is the number of neurons, <italic>K</italic> the number of trials, and <italic>T</italic> the number of time points) for each of the four target objects.</p></sec><sec id="s4-6"><title>Instantaneous subspace identification</title><p>Instantaneous neural subspaces were identified at 1 ms intervals. At each 1 ms time step, the <italic>N</italic>-dimensional neural firing rates from trials involving the four different objects—sphere, button, coaxial cylinder, and perpendicular cylinder—were averaged separately, providing four points in the <italic>N</italic>-dimensional space representing the average neural activity for trials involving the different objects at that time step. PCA then was performed on these four points. Because three dimensions capture all the variance of four points, three principal component dimensions fully defined each instantaneous subspace. Each instantaneous 3D subspace can be considered a filter described by a matrix, <inline-formula><alternatives><mml:math id="inf11"><mml:mi>W</mml:mi></mml:math><tex-math id="inft11">\begin{document}$W$\end{document}</tex-math></alternatives></inline-formula>, that can project high-dimensional neural activity into a low-dimensional subspace, with the time series of instantaneous subspaces, <inline-formula><alternatives><mml:math id="inf12"><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft12">\begin{document}$W_{i}$\end{document}</tex-math></alternatives></inline-formula>, forming a time series of filters (<xref ref-type="fig" rid="fig1">Figure 1B</xref>).</p></sec><sec id="s4-7"><title>Trajectory visualization and separation</title><p>We projected 100 ms segments of neural activity into each instantaneous subspace by multiplying the neural activity, <inline-formula><alternatives><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>X</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft13">\begin{document}$X\left (t\right)$\end{document}</tex-math></alternatives></inline-formula>, by the transforming matrix for the <italic>i</italic>th subspace, <inline-formula><alternatives><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft14">\begin{document}$W_{i}$\end{document}</tex-math></alternatives></inline-formula>, which yielded low-dimensional trajectory segments, <inline-formula><alternatives><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>L</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mi>X</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft15">\begin{document}$L\left (t\right)=\ X\left (t\right)W_{i}\ \ \left (t\in T\right)$\end{document}</tex-math></alternatives></inline-formula>. This process was repeated for each instantaneous subspace in the time domain of interest. To quantify the separation between the four trial-averaged trajectory segments involving the different objects in a given instantaneous subspace, we then calculated their cumulative separation (<inline-formula><alternatives><mml:math id="inf16"><mml:mi>C</mml:mi><mml:mi>S</mml:mi></mml:math><tex-math id="inft16">\begin{document}$CS$\end{document}</tex-math></alternatives></inline-formula>) as:<disp-formula id="equ1"><alternatives><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>C</mml:mi><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:munder><mml:mi>D</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:munder><mml:mspace width="thinmathspace"/><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t1">\begin{document}$$\displaystyle  CS=\frac{1}{T}\sum _{t\in T}D\left (t\right)=\frac{1}{T}\sum _{t\in T}\, \sum _{i\neq j}d_{ij}\left (t\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft17">\begin{document}$d_{ij}\left (t\right)$\end{document}</tex-math></alternatives></inline-formula> is the three-dimensional Euclidean distance between the <italic>i</italic>th and <italic>j</italic>th trajectories at time point <inline-formula><alternatives><mml:math id="inf18"><mml:mi>t</mml:mi></mml:math><tex-math id="inft18">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula>. We summed the six pairwise distances between the four trajectory segments across time points and normalized by the number of time points, <inline-formula><alternatives><mml:math id="inf19"><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:math><tex-math id="inft19">\begin{document}$T=100$\end{document}</tex-math></alternatives></inline-formula>. The larger the <inline-formula><alternatives><mml:math id="inf20"><mml:mi>C</mml:mi><mml:mi>S</mml:mi></mml:math><tex-math id="inft20">\begin{document}$CS$\end{document}</tex-math></alternatives></inline-formula>, the greater the separation of the trajectory segments.</p></sec><sec id="s4-8"><title>Subspace comparisons—principal angles</title><p>To assess the progressive shift of instantaneous subspaces, we computed the principal angles (<xref ref-type="bibr" rid="bib3">Björck and Golub, 1973</xref>; <xref ref-type="bibr" rid="bib15">Gallego et al., 2018</xref>) between the instantaneous subspace at each of four selected time points—onset of the instruction (I), go cue (G), onset of movement (M), and beginning of the final hold (H)—and each of the other instantaneous subspaces in a time series. For example, given the three-dimensional instantaneous subspace at the time of movement onset, <inline-formula><alternatives><mml:math id="inf21"><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft21">\begin{document}$W_{M}$\end{document}</tex-math></alternatives></inline-formula>, and at any other time, <inline-formula><alternatives><mml:math id="inf22"><mml:msub><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft22">\begin{document}$W_{i}$\end{document}</tex-math></alternatives></inline-formula>, we calculated their 3×3 inner product matrix and performed singular value decomposition to obtain:<disp-formula id="equ2"><alternatives><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mi>C</mml:mi><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="t2">\begin{document}$$\displaystyle W_{M}^{T}W_{i}=\, P_{M}CP_{i}^{T}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where 3×3 matrices <inline-formula><alternatives><mml:math id="inf23"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft23">\begin{document}$P_{M}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf24"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft24">\begin{document}$P_{i}$\end{document}</tex-math></alternatives></inline-formula> define new manifold directions which successively minimize the three principal angles specific to the two subspaces being compared. The elements of the diagonal matrix <inline-formula><alternatives><mml:math id="inf25"><mml:mi>C</mml:mi></mml:math><tex-math id="inft25">\begin{document}$C$\end{document}</tex-math></alternatives></inline-formula> are then the ranked cosines of the principal angles, <inline-formula><alternatives><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft26">\begin{document}$\theta _{i}$\end{document}</tex-math></alternatives></inline-formula>, ordered from smallest to largest:<disp-formula id="equ3"><alternatives><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="t3">\begin{document}$$\displaystyle C=diag\left (\cos \left (\theta _{1}\right),\cos \left (\theta _{2}\right),\cos \left (\theta _{3}\right)\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>In <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, using all trials from monkey R, session 1, we have plotted the three principal angles as a function of time. Note that at the time when <inline-formula><alternatives><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft27">\begin{document}$W_{i}=\, W_{M}$\end{document}</tex-math></alternatives></inline-formula>, all three principal angles are zero by definition, and the sharp decline before time M and the sharp rise afterward reflect the Gaussian kernel (<inline-formula><alternatives><mml:math id="inf28"><mml:mi mathvariant="normal">σ</mml:mi></mml:math><tex-math id="inft28">\begin{document}$\mathrm{\sigma }$\end{document}</tex-math></alternatives></inline-formula>=50 ms) used to smooth unit firing rates. These sharp troughs thus are trivial, but both the gradual decline before and the gradual rise following the sharp troughs are not. Given that the set of three principal angles typically followed similar time courses, in the Results, we illustrate only the first principal angle, <inline-formula><alternatives><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft29">\begin{document}$\theta _{1}$\end{document}</tex-math></alternatives></inline-formula>.</p><p>Furthermore, to provide some indication of the degree of variability in the first principal angle, we randomly selected 20 trials involving each target object (totaling 80 trials) with replacement and calculated the first principal angle as a function of time, repeating this process 10 times. The results, shown in <xref ref-type="fig" rid="fig4">Figures 4</xref> and <xref ref-type="fig" rid="fig7">7</xref>, <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>, and <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>, are presented as the mean ± 1 standard deviation across these 10-fold cross-validations. Note that this mean never reaches zero because the instantaneous subspaces at times I, G, M, and H were computed using all the available trials.</p><p>In the example of <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, the first principal angle never reached 90° either. To determine whether this reflected a lack of orthogonality or a limitation of population size, we computed the first principal angle between a fixed three-dimensional subspace and 5000 three-dimensional subspaces randomly chosen from <italic>N</italic>-dimensional spaces, for <italic>N</italic> varying from 5 to 500. <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref> shows that for large <italic>N</italic>, principal angles between a fixed subspace and other randomly chosen subspaces are likely to be close to 90°. But as <italic>N</italic> decreases, these random principal angles are less likely to approach 90°, without necessarily indicating nonrandom overlap of the subspaces. In <xref ref-type="fig" rid="fig4">Figures 4</xref> and <xref ref-type="fig" rid="fig7">7</xref>, <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>, and <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>, we therefore indicate levels of principal angles that might arise by chance alone using the smallest <italic>N</italic> from any of the three sessions for a given monkey (see <xref ref-type="table" rid="table2">Table 2</xref>).</p></sec><sec id="s4-9"><title>Decodable information—LSTM</title><p>As illustrated schematically in <xref ref-type="fig" rid="fig1">Figure 1B</xref>, the same segment of high-dimensional neural activity projected into different instantaneous subspaces can generate low-dimensional trajectories of varying separation. The degree of separation among the projected trajectory segments will depend not only on their separation at the time when the segments were clipped, but also on the similarity of the subspaces into which the trajectory segments are projected. To quantify the combined effects of trajectory separation and projection into different subspaces, we projected high-dimensional neural trajectory segments (each including 100 points at 1 ms intervals) from successful trials involving each of the four different target objects into time series of three-dimensional instantaneous subspaces at 50 ms intervals. In each of these instantaneous subspaces, the neural trajectory segment from each trial thus became a 100 time point × three-dimensional matrix. For each instantaneous subspace in the time series, we then trained a separate LSTM (<xref ref-type="bibr" rid="bib20">Hochreiter and Schmidhuber, 1997</xref>) classifier to attribute each of the neural trajectories from individual trials to one of the four target object labels: sphere, button, coaxial cylinder, or perpendicular cylinder. Using MATLAB’s Deep Learning Toolbox, each LSTM classifier had 3 inputs (instantaneous subspace dimensions), 20 hidden units in the bidirectional LSTM layer, and a softmax layer preceding the classification layer which had 4 output classes (target objects). The total number of successful trials available in each session for each object is given in <xref ref-type="table" rid="table1">Table 1</xref>. To avoid bias based on the total number of successful trials, we used the minimum number of successful trials across the four objects in each session, selecting that number from the total available randomly with replacement. Each LSTM classifier was trained with MATLAB’s adaptive moment estimation (Adam) optimizer on 40% of the selected trials, and the remaining 60% were decoded by the trained classifier. The success of this decoding was used as an estimate of classification accuracy from 0 (no correct classifications) to 1 (100% correct classifications). This process was repeated 10 times, and the mean ± standard deviation across the 10 folds was reported as the classification accuracy at that time. Classification accuracy of trials projected into each instantaneous subspace at 50 ms intervals was plotted as a function of trial time.</p></sec><sec id="s4-10"><title>Similarity of aligned latent dynamics</title><p>We used CCA to compare the similarity of latent dynamics in different subspaces (<xref ref-type="bibr" rid="bib16">Gallego et al., 2020</xref>). In brief, given latent dynamics (trajectory segments) in two original subspaces, <inline-formula><alternatives><mml:math id="inf30"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft30">\begin{document}$L_{A}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf31"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft31">\begin{document}$L_{B}$\end{document}</tex-math></alternatives></inline-formula>, CCA finds a linear transformation of each original subspace such that, when projected into a common subspace, the aligned latent dynamics, <inline-formula><alternatives><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>L</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft32">\begin{document}$\tilde{L}_{A}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>L</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft33">\begin{document}$\tilde{L}_{B}$\end{document}</tex-math></alternatives></inline-formula> , are maximally correlated in each dimension of the common subspace. Larger canonical correlation coefficient (CCs) indicate a higher degree of alignment.</p><p>CCA was performed as follows: The original latent dynamics, <inline-formula><alternatives><mml:math id="inf34"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft34">\begin{document}$L_{A}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf35"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft35">\begin{document}$L_{B}$\end{document}</tex-math></alternatives></inline-formula>, were first transformed and decomposed as <inline-formula><alternatives><mml:math id="inf36"><mml:msubsup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft36">\begin{document}$L_{A}^{T}=Q_{A}R_{A}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf37"><mml:msubsup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft37">\begin{document}$L_{B}^{T}=Q_{B}R_{B}$\end{document}</tex-math></alternatives></inline-formula> . The first <italic>m=</italic>3 column vectors of each <inline-formula><alternatives><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft38">\begin{document}$Q_{i}$\end{document}</tex-math></alternatives></inline-formula> provide an orthonormal basis for the column vectors of <inline-formula><alternatives><mml:math id="inf39"><mml:msubsup><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft39">\begin{document}$L_{i}^{T}$\end{document}</tex-math></alternatives></inline-formula> (where <inline-formula><alternatives><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mo>,</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft40">\begin{document}$i=A,B$\end{document}</tex-math></alternatives></inline-formula>). Singular value decomposition on the inner product matrix of <inline-formula><alternatives><mml:math id="inf41"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft41">\begin{document}$Q_{A}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf42"><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft42">\begin{document}$Q_{B}$\end{document}</tex-math></alternatives></inline-formula> then gives <inline-formula><alternatives><mml:math id="inf43"><mml:msubsup><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>Q</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>U</mml:mi><mml:mi>S</mml:mi><mml:msup><mml:mrow><mml:mi>V</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft43">\begin{document}$Q_{A}^{T}Q_{B}=USV^{T}$\end{document}</tex-math></alternatives></inline-formula>, and new manifold directions that maximize pairwise correlations are provided by <inline-formula><alternatives><mml:math id="inf44"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mi>U</mml:mi></mml:math><tex-math id="inft44">\begin{document}$M_{A}=R_{A}^{- 1}U$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf45"><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mi>V</mml:mi></mml:math><tex-math id="inft45">\begin{document}$M_{B}=R_{B}^{- 1}V$\end{document}</tex-math></alternatives></inline-formula> . We then projected the original latent dynamics into the new, common subspace: <inline-formula><alternatives><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>L</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft46">\begin{document}$\tilde{L}_{A}^{T}=L_{A}^{T}M_{A}$\end{document}</tex-math></alternatives></inline-formula>; <inline-formula><alternatives><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>L</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft47">\begin{document}$\tilde{L}_{B}^{T}=L_{B}^{T}M_{B}$\end{document}</tex-math></alternatives></inline-formula> . Pairwise CCs between the aligned latent dynamics sorted from largest to smallest are then given by the elements of the diagonal matrix <inline-formula><alternatives><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>L</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mover><mml:mi>L</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft48">\begin{document}$S=\tilde{L}_{A}\tilde{L}_{B}^{T}$\end{document}</tex-math></alternatives></inline-formula> .</p><p>To provide an estimate of variability, we used a bootstrapping approach to CCA. From each of two datasets, we randomly selected 20 trials involving each target object (totaling 80 trials) with replacement, clipped trajectory segments from each of those trials for 100 ms (100 points at 1 ms intervals) after the instruction onset, go cue, movement onset, or beginning of the final hold, and performed CCA as described above. (Note that because session 1 from monkey R included only eight button trials [<xref ref-type="table" rid="table1">Table 1</xref>], we excluded this session from CCA analyses.) With 500 iterations, we obtained a distribution of the CCs between the two datasets in each of the three dimensions of the aligned subspace, which permitted statistical comparisons. We then used this approach to evaluate alignment of latent dynamics between different sessions (e.g. execution trials on two different days), between different contexts (e.g. execution and observation), and between different neural populations (e.g. MNs and AE neurons). This bootstrapping approach further enabled us to assess the consistency of relationships among neural trajectories within a given group—i.e. the same neural population during the same context (execution or observation) in the same session—by drawing two separate random samples of 80 trials from the same population, context, and session (<xref ref-type="fig" rid="fig8">Figure 8D</xref>), which would not have been possible had we concatenated trajectory segments from all trials in the session (<xref ref-type="bibr" rid="bib16">Gallego et al., 2020</xref>; <xref ref-type="bibr" rid="bib50">Safaie et al., 2023</xref>).</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Software, Formal analysis, Validation, Visualization, Methodology, Writing - original draft</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Data curation, Supervision, Funding acquisition, Investigation, Visualization, Methodology, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All procedures for the care and use of these non-human primates followed the Guide for the Care and Use of Laboratory Animals and were approved by the University Committee on Animal Resources at the University of Rochester, Rochester, New York under protocol #101058.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-94165-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Processed data for each of the 9 recording sessions analyzed in this study are publicly available at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/dryad.cvdncjtfq">https://doi.org/10.5061/dryad.cvdncjtfq</ext-link>. The raw data for all 9 sessions requires ~1.5 Tb of storage space and therefore have not been shared in their entirety on a publicly accessible server. However, as an example, the raw data files from one of the 9 recording sessions (monkey R, session 2) also are publicly available at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/dryad.cvdncjtfq">https://doi.org/10.5061/dryad.cvdncjtfq</ext-link>. Upon request, the remainder of the raw data files are available from the lead contact, Marc H. Schieber (mschiebe@ur.rochester.edu). Files will be sent on an external hard drive. No application or project proposal is required. Also available at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/dryad.cvdncjtfq">https://doi.org/10.5061/dryad.cvdncjtfq</ext-link> are the processed data used for Figure 8, panels C and D, and for Figure 5, figure supplement 1. Other figures were generated from the processed data files using the analysis code packages available as described below. Code packages for all analyses performed in this work are available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/ShiftingSubspace/shiftsubs">https://github.com/ShiftingSubspace/shiftsubs</ext-link> (copy archived at <xref ref-type="bibr" rid="bib51">Schieber, 2024</xref>). Code for the custom task control software used in this study is available at: <ext-link ext-link-type="uri" xlink:href="https://github.com/grivlis/UTCS3_RGM">https://github.com/grivlis/UTCS3_RGM</ext-link> (copy archived at <xref ref-type="bibr" rid="bib18">grivlis, 2025</xref>).</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>Z</given-names></name><name><surname>Schieber</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>Data from: Progressively shifting patterns of co-modulation among premotor cortex neurons carry dynamically similar signals during action execution and observation</data-title><source>Dryad Digital Repository</source><pub-id pub-id-type="doi">10.5061/dryad.cvdncjtfq</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>The authors thank John Housel and Jennifer Gardinier for technical assistance, Gil Rivlis for custom task-control software, and Marsha Hayles for editorial comments. This work was supported by grant R01NS102343 (MHS) from the National Institute of Neurological Disorders and Stroke.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Albertini</surname><given-names>D</given-names></name><name><surname>Lanzilotto</surname><given-names>M</given-names></name><name><surname>Maranesi</surname><given-names>M</given-names></name><name><surname>Bonini</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Largely shared neural codes for biological and nonbiological observed movements but not for executed actions in monkey premotor areas</article-title><source>Journal of Neurophysiology</source><volume>126</volume><fpage>906</fpage><lpage>912</lpage><pub-id pub-id-type="doi">10.1152/jn.00296.2021</pub-id><pub-id pub-id-type="pmid">34379489</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ames</surname><given-names>KC</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neural dynamics of reaching following incorrect or absent motor preparation</article-title><source>Neuron</source><volume>81</volume><fpage>438</fpage><lpage>451</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.11.003</pub-id><pub-id pub-id-type="pmid">24462104</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Björck</surname><given-names>Ȧke</given-names></name><name><surname>Golub</surname><given-names>GH</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>Numerical methods for computing angles between linear subspaces</article-title><source>Mathematics of Computation</source><volume>27</volume><fpage>579</fpage><lpage>594</lpage><pub-id pub-id-type="doi">10.1090/S0025-5718-1973-0348991-3</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonini</surname><given-names>L</given-names></name><name><surname>Rotunno</surname><given-names>C</given-names></name><name><surname>Arcuri</surname><given-names>E</given-names></name><name><surname>Gallese</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Mirror neurons 30 years later: implications and applications</article-title><source>Trends in Cognitive Sciences</source><volume>26</volume><fpage>767</fpage><lpage>781</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2022.06.003</pub-id><pub-id pub-id-type="pmid">35803832</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Foster</surname><given-names>JD</given-names></name><name><surname>Nuyujukian</surname><given-names>P</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural population dynamics during reaching</article-title><source>Nature</source><volume>487</volume><fpage>51</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1038/nature11129</pub-id><pub-id pub-id-type="pmid">22722855</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cisek</surname><given-names>P</given-names></name><name><surname>Kalaska</surname><given-names>JF</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Neural correlates of mental rehearsal in dorsal premotor cortex</article-title><source>Nature</source><volume>431</volume><fpage>993</fpage><lpage>996</lpage><pub-id pub-id-type="doi">10.1038/nature03005</pub-id><pub-id pub-id-type="pmid">15496925</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Yu</surname><given-names>BM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dimensionality reduction for large-scale neural recordings</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1500</fpage><lpage>1509</lpage><pub-id pub-id-type="doi">10.1038/nn.3776</pub-id><pub-id pub-id-type="pmid">25151264</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dekleva</surname><given-names>BM</given-names></name><name><surname>Chowdhury</surname><given-names>RH</given-names></name><name><surname>Batista</surname><given-names>AP</given-names></name><name><surname>Chase</surname><given-names>SM</given-names></name><name><surname>Yu</surname><given-names>BM</given-names></name><name><surname>Boninger</surname><given-names>ML</given-names></name><name><surname>Collinger</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Motor cortex retains and reorients neural dynamics during motor imagery</article-title><source>Nature Human Behaviour</source><volume>8</volume><fpage>729</fpage><lpage>742</lpage><pub-id pub-id-type="doi">10.1038/s41562-023-01804-5</pub-id><pub-id pub-id-type="pmid">38287177</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>di Pellegrino</surname><given-names>G</given-names></name><name><surname>Fadiga</surname><given-names>L</given-names></name><name><surname>Fogassi</surname><given-names>L</given-names></name><name><surname>Gallese</surname><given-names>V</given-names></name><name><surname>Rizzolatti</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Understanding motor events: a neurophysiological study</article-title><source>Experimental Brain Research</source><volume>91</volume><fpage>176</fpage><lpage>180</lpage><pub-id pub-id-type="doi">10.1007/BF00230027</pub-id><pub-id pub-id-type="pmid">1301372</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dushanova</surname><given-names>J</given-names></name><name><surname>Donoghue</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Neurons in primary motor cortex engaged during action observation</article-title><source>The European Journal of Neuroscience</source><volume>31</volume><fpage>386</fpage><lpage>398</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2009.07067.x</pub-id><pub-id pub-id-type="pmid">20074212</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elsayed</surname><given-names>GF</given-names></name><name><surname>Lara</surname><given-names>AH</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Reorganization between preparatory and movement population responses in motor cortex</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>13239</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms13239</pub-id><pub-id pub-id-type="pmid">27807345</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferroni</surname><given-names>CG</given-names></name><name><surname>Albertini</surname><given-names>D</given-names></name><name><surname>Lanzilotto</surname><given-names>M</given-names></name><name><surname>Livi</surname><given-names>A</given-names></name><name><surname>Maranesi</surname><given-names>M</given-names></name><name><surname>Bonini</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Local and system mechanisms for action execution and observation in parietal and premotor cortices</article-title><source>Current Biology</source><volume>31</volume><fpage>2819</fpage><lpage>2830</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2021.04.034</pub-id><pub-id pub-id-type="pmid">33984266</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ferrucci</surname><given-names>L</given-names></name><name><surname>Nougaret</surname><given-names>S</given-names></name><name><surname>Falcone</surname><given-names>R</given-names></name><name><surname>Cirillo</surname><given-names>R</given-names></name><name><surname>Ceccarelli</surname><given-names>F</given-names></name><name><surname>Genovesio</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Dedicated representation of others in the macaque frontal cortex: From action monitoring and prediction to outcome evaluation</article-title><source>Cerebral Cortex</source><volume>32</volume><fpage>891</fpage><lpage>907</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhab253</pub-id><pub-id pub-id-type="pmid">34428277</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallego</surname><given-names>JA</given-names></name><name><surname>Perich</surname><given-names>MG</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name><name><surname>Solla</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neural manifolds for the control of movement</article-title><source>Neuron</source><volume>94</volume><fpage>978</fpage><lpage>984</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.05.025</pub-id><pub-id pub-id-type="pmid">28595054</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallego</surname><given-names>JA</given-names></name><name><surname>Perich</surname><given-names>MG</given-names></name><name><surname>Naufel</surname><given-names>SN</given-names></name><name><surname>Ethier</surname><given-names>C</given-names></name><name><surname>Solla</surname><given-names>SA</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Cortical population activity within a preserved neural manifold underlies multiple motor behaviors</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>4233</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-06560-z</pub-id><pub-id pub-id-type="pmid">30315158</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallego</surname><given-names>JA</given-names></name><name><surname>Perich</surname><given-names>MG</given-names></name><name><surname>Chowdhury</surname><given-names>RH</given-names></name><name><surname>Solla</surname><given-names>SA</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Long-term stability of cortical population dynamics underlying consistent behavior</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>260</fpage><lpage>270</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0555-4</pub-id><pub-id pub-id-type="pmid">31907438</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallese</surname><given-names>V</given-names></name><name><surname>Fadiga</surname><given-names>L</given-names></name><name><surname>Fogassi</surname><given-names>L</given-names></name><name><surname>Rizzolatti</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Action recognition in the premotor cortex</article-title><source>Brain</source><volume>119 (Pt 2)</volume><fpage>593</fpage><lpage>609</lpage><pub-id pub-id-type="doi">10.1093/brain/119.2.593</pub-id><pub-id pub-id-type="pmid">8800951</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="software"><person-group person-group-type="author"><collab>grivlis</collab></person-group><year iso-8601-date="2025">2025</year><data-title>UTCS3_RGM</data-title><version designator="swh:1:rev:fa3eecc9c62c799c412801711a61c25a9be738a7">swh:1:rev:fa3eecc9c62c799c412801711a61c25a9be738a7</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:fdbadaf7b530c13dae74b965c360e3cddcd15c25;origin=https://github.com/grivlis/UTCS3_RGM;visit=swh:1:snp:f1081f42a50e4279e834c660ba06ea901ddd9505;anchor=swh:1:rev:fa3eecc9c62c799c412801711a61c25a9be738a7">https://archive.softwareheritage.org/swh:1:dir:fdbadaf7b530c13dae74b965c360e3cddcd15c25;origin=https://github.com/grivlis/UTCS3_RGM;visit=swh:1:snp:f1081f42a50e4279e834c660ba06ea901ddd9505;anchor=swh:1:rev:fa3eecc9c62c799c412801711a61c25a9be738a7</ext-link></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hickok</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Eight problems for the mirror neuron theory of action understanding in monkeys and humans</article-title><source>Journal of Cognitive Neuroscience</source><volume>21</volume><fpage>1229</fpage><lpage>1243</lpage><pub-id pub-id-type="doi">10.1162/jocn.2009.21189</pub-id><pub-id pub-id-type="pmid">19199415</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hochreiter</surname><given-names>S</given-names></name><name><surname>Schmidhuber</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Long short-term memory</article-title><source>Neural Computation</source><volume>9</volume><fpage>1735</fpage><lpage>1780</lpage><pub-id pub-id-type="doi">10.1162/neco.1997.9.8.1735</pub-id><pub-id pub-id-type="pmid">9377276</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jerjian</surname><given-names>SJ</given-names></name><name><surname>Sahani</surname><given-names>M</given-names></name><name><surname>Kraskov</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Movement initiation and grasp representation in premotor and primary motor cortex mirror neurons</article-title><source>eLife</source><volume>9</volume><elocation-id>e54139</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.54139</pub-id><pub-id pub-id-type="pmid">32628107</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>X</given-names></name><name><surname>Saggar</surname><given-names>H</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Kao</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Structure in neural activity during observed and executed movements is shared at the neural population level, not in single neurons</article-title><source>Cell Reports</source><volume>32</volume><elocation-id>108006</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2020.108006</pub-id><pub-id pub-id-type="pmid">32783934</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Cortical activity in the null space: permitting preparation without movement</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>440</fpage><lpage>448</lpage><pub-id pub-id-type="doi">10.1038/nn.3643</pub-id><pub-id pub-id-type="pmid">24487233</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Seely</surname><given-names>JS</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The largest response component in the motor cortex reflects movement timing but not movement type</article-title><source>eNeuro</source><volume>3</volume><elocation-id>ENEURO.0085-16.2016</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0085-16.2016</pub-id><pub-id pub-id-type="pmid">27761519</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kihlberg</surname><given-names>JK</given-names></name><name><surname>Herson</surname><given-names>JH</given-names></name><name><surname>Schotz</surname><given-names>WE</given-names></name></person-group><year iso-8601-date="1972">1972</year><article-title>Square Root Transformation Revisited</article-title><source>Applied Statistics</source><volume>21</volume><elocation-id>76</elocation-id><pub-id pub-id-type="doi">10.2307/2346609</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kilner</surname><given-names>JM</given-names></name><name><surname>Friston</surname><given-names>KJ</given-names></name><name><surname>Frith</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Predictive coding: an account of the mirror neuron system</article-title><source>Cognitive Processing</source><volume>8</volume><fpage>159</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1007/s10339-007-0170-2</pub-id><pub-id pub-id-type="pmid">17429704</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kilner</surname><given-names>JM</given-names></name><name><surname>Lemon</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>What we know currently about mirror neurons</article-title><source>Current Biology</source><volume>23</volume><fpage>R1057</fpage><lpage>R1062</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.10.051</pub-id><pub-id pub-id-type="pmid">24309286</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kobak</surname><given-names>D</given-names></name><name><surname>Brendel</surname><given-names>W</given-names></name><name><surname>Constantinidis</surname><given-names>C</given-names></name><name><surname>Feierstein</surname><given-names>CE</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name><name><surname>Qi</surname><given-names>XL</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Demixed principal component analysis of neural population data</article-title><source>eLife</source><volume>5</volume><elocation-id>e10989</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.10989</pub-id><pub-id pub-id-type="pmid">27067378</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krakauer</surname><given-names>JW</given-names></name><name><surname>Ghazanfar</surname><given-names>AA</given-names></name><name><surname>Gomez-Marin</surname><given-names>A</given-names></name><name><surname>MacIver</surname><given-names>MA</given-names></name><name><surname>Poeppel</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neuroscience needs behavior: Correcting a reductionist bias</article-title><source>Neuron</source><volume>93</volume><fpage>480</fpage><lpage>490</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.12.041</pub-id><pub-id pub-id-type="pmid">28182904</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kraskov</surname><given-names>A</given-names></name><name><surname>Dancause</surname><given-names>N</given-names></name><name><surname>Quallo</surname><given-names>MM</given-names></name><name><surname>Shepherd</surname><given-names>S</given-names></name><name><surname>Lemon</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Corticospinal neurons in macaque ventral premotor cortex with mirror properties: a potential mechanism for action suppression?</article-title><source>Neuron</source><volume>64</volume><fpage>922</fpage><lpage>930</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.12.010</pub-id><pub-id pub-id-type="pmid">20064397</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kraskov</surname><given-names>A</given-names></name><name><surname>Philipp</surname><given-names>R</given-names></name><name><surname>Waldert</surname><given-names>S</given-names></name><name><surname>Vigneswaran</surname><given-names>G</given-names></name><name><surname>Quallo</surname><given-names>MM</given-names></name><name><surname>Lemon</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Corticospinal mirror neurons</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>369</volume><elocation-id>20130174</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2013.0174</pub-id><pub-id pub-id-type="pmid">24778371</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maranesi</surname><given-names>M</given-names></name><name><surname>Livi</surname><given-names>A</given-names></name><name><surname>Fogassi</surname><given-names>L</given-names></name><name><surname>Rizzolatti</surname><given-names>G</given-names></name><name><surname>Bonini</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Mirror neuron activation prior to action observation in a predictable context</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>14827</fpage><lpage>14832</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2705-14.2014</pub-id><pub-id pub-id-type="pmid">25378150</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mauritz</surname><given-names>KH</given-names></name><name><surname>Wise</surname><given-names>SP</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Premotor cortex of the rhesus monkey: neuronal activity in anticipation of predictable environmental events</article-title><source>Experimental Brain Research</source><volume>61</volume><fpage>229</fpage><lpage>244</lpage><pub-id pub-id-type="doi">10.1007/BF00239513</pub-id><pub-id pub-id-type="pmid">3948938</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazurek</surname><given-names>KA</given-names></name><name><surname>Rouse</surname><given-names>AG</given-names></name><name><surname>Schieber</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Mirror neuron populations represent sequences of behavioral epochs during both execution and observation</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>4441</fpage><lpage>4455</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3481-17.2018</pub-id><pub-id pub-id-type="pmid">29654188</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mazurek</surname><given-names>KA</given-names></name><name><surname>Schieber</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Mirror neurons precede non-mirror neurons during action execution</article-title><source>Journal of Neurophysiology</source><volume>122</volume><fpage>2630</fpage><lpage>2635</lpage><pub-id pub-id-type="doi">10.1152/jn.00653.2019</pub-id><pub-id pub-id-type="pmid">31693444</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Natraj</surname><given-names>N</given-names></name><name><surname>Silversmith</surname><given-names>DB</given-names></name><name><surname>Chang</surname><given-names>EF</given-names></name><name><surname>Ganguly</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Compartmentalized dynamics within a common multi-area mesoscale manifold represent a repertoire of human hand movements</article-title><source>Neuron</source><volume>110</volume><fpage>154</fpage><lpage>174</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.10.002</pub-id><pub-id pub-id-type="pmid">34678147</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ninomiya</surname><given-names>T</given-names></name><name><surname>Noritake</surname><given-names>A</given-names></name><name><surname>Kobayashi</surname><given-names>K</given-names></name><name><surname>Isoda</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A causal role for frontal cortico-cortical coordination in social action monitoring</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>5233</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-19026-y</pub-id><pub-id pub-id-type="pmid">33067461</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Papadourakis</surname><given-names>V</given-names></name><name><surname>Raos</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neurons in the macaque dorsal premotor cortex respond to execution and observation of actions</article-title><source>Cerebral Cortex</source><volume>29</volume><fpage>4223</fpage><lpage>4237</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhy304</pub-id><pub-id pub-id-type="pmid">30535385</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pezzulo</surname><given-names>G</given-names></name><name><surname>Donnarumma</surname><given-names>F</given-names></name><name><surname>Ferrari-Toniolo</surname><given-names>S</given-names></name><name><surname>Cisek</surname><given-names>P</given-names></name><name><surname>Battaglia-Mayer</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Shared population-level dynamics in monkey premotor cortex during solo action, joint action and action observation</article-title><source>Progress in Neurobiology</source><volume>210</volume><elocation-id>102214</elocation-id><pub-id pub-id-type="doi">10.1016/j.pneurobio.2021.102214</pub-id><pub-id pub-id-type="pmid">34979174</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pomper</surname><given-names>JK</given-names></name><name><surname>Shams</surname><given-names>M</given-names></name><name><surname>Wen</surname><given-names>S</given-names></name><name><surname>Bunjes</surname><given-names>F</given-names></name><name><surname>Thier</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Non-shared coding of observed and executed actions prevails in macaque ventral premotor mirror neurons</article-title><source>eLife</source><volume>12</volume><elocation-id>e77513</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.77513</pub-id><pub-id pub-id-type="pmid">37458338</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Rivlis</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>UTCS3_RGM</data-title><version designator="fa3eecc">fa3eecc</version><source>Github</source><ext-link ext-link-type="uri" xlink:href="https://github.com/grivlis/UTCS3_RGM">https://github.com/grivlis/UTCS3_RGM</ext-link></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rizzolatti</surname><given-names>G</given-names></name><name><surname>Fadiga</surname><given-names>L</given-names></name><name><surname>Gallese</surname><given-names>V</given-names></name><name><surname>Fogassi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Premotor cortex and the recognition of motor actions</article-title><source>Cognitive Brain Research</source><volume>3</volume><fpage>131</fpage><lpage>141</lpage><pub-id pub-id-type="doi">10.1016/0926-6410(95)00038-0</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rizzolatti</surname><given-names>G</given-names></name><name><surname>Craighero</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>The mirror-neuron system</article-title><source>Annual Review of Neuroscience</source><volume>27</volume><fpage>169</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.27.070203.144230</pub-id><pub-id pub-id-type="pmid">15217330</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouse</surname><given-names>AG</given-names></name><name><surname>Schieber</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Spatiotemporal distribution of location and object effects in reach-to-grasp kinematics</article-title><source>Journal of Neurophysiology</source><volume>114</volume><fpage>3268</fpage><lpage>3282</lpage><pub-id pub-id-type="doi">10.1152/jn.00686.2015</pub-id><pub-id pub-id-type="pmid">26445870</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouse</surname><given-names>AG</given-names></name><name><surname>Schieber</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2016">2016a</year><article-title>Spatiotemporal distribution of location and object effects in primary motor cortex neurons during reach-to-grasp</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>10640</fpage><lpage>10653</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1716-16.2016</pub-id><pub-id pub-id-type="pmid">27733614</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouse</surname><given-names>AG</given-names></name><name><surname>Schieber</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2016">2016b</year><article-title>Spatiotemporal distribution of location and object effects in the electromyographic activity of upper extremity muscles during reach-to-grasp</article-title><source>Journal of Neurophysiology</source><volume>115</volume><fpage>3238</fpage><lpage>3248</lpage><pub-id pub-id-type="doi">10.1152/jn.00008.2016</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouse</surname><given-names>AG</given-names></name><name><surname>Schieber</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Condition-dependent neural dimensions progressively shift during reach to grasp</article-title><source>Cell Reports</source><volume>25</volume><fpage>3158</fpage><lpage>3168</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2018.11.057</pub-id><pub-id pub-id-type="pmid">30540947</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rouse</surname><given-names>AG</given-names></name><name><surname>Schieber</surname><given-names>MH</given-names></name><name><surname>Sarma</surname><given-names>SV</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Cyclic, condition-independent activity in primary motor cortex predicts corrective movement behavior</article-title><source>eNeuro</source><volume>9</volume><elocation-id>eNeuro</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0354-21.2022</pub-id><pub-id pub-id-type="pmid">35346960</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Russo</surname><given-names>AA</given-names></name><name><surname>Khajeh</surname><given-names>R</given-names></name><name><surname>Bittner</surname><given-names>SR</given-names></name><name><surname>Perkins</surname><given-names>SM</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neural trajectories in the supplementary motor area and motor cortex exhibit distinct geometries, compatible with different classes of computation</article-title><source>Neuron</source><volume>107</volume><fpage>745</fpage><lpage>758</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.05.020</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Safaie</surname><given-names>M</given-names></name><name><surname>Chang</surname><given-names>JC</given-names></name><name><surname>Park</surname><given-names>J</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name><name><surname>Dudman</surname><given-names>JT</given-names></name><name><surname>Perich</surname><given-names>MG</given-names></name><name><surname>Gallego</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Preserved neural dynamics across animals performing similar behaviour</article-title><source>Nature</source><volume>623</volume><fpage>765</fpage><lpage>771</lpage><pub-id pub-id-type="doi">10.1038/s41586-023-06714-0</pub-id><pub-id pub-id-type="pmid">37938772</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Schieber</surname><given-names>MH</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>shiftsubs</data-title><version designator="swh:1:rev:a604c1b72c242c03775024a4c2ed3f634bf78f5b">swh:1:rev:a604c1b72c242c03775024a4c2ed3f634bf78f5b</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:21afbe1856fb0c89c339129a0384c4ee4b47d55d;origin=https://github.com/ShiftingSubspace/shiftsubs;visit=swh:1:snp:59ede282551686d5794f0731344f4f011317a667;anchor=swh:1:rev:a604c1b72c242c03775024a4c2ed3f634bf78f5b">https://archive.softwareheritage.org/swh:1:dir:21afbe1856fb0c89c339129a0384c4ee4b47d55d;origin=https://github.com/ShiftingSubspace/shiftsubs;visit=swh:1:snp:59ede282551686d5794f0731344f4f011317a667;anchor=swh:1:rev:a604c1b72c242c03775024a4c2ed3f634bf78f5b</ext-link></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Semedo</surname><given-names>JD</given-names></name><name><surname>Zandvakili</surname><given-names>A</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name><name><surname>Yu</surname><given-names>BM</given-names></name><name><surname>Kohn</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Cortical areas interact through a communication subspace</article-title><source>Neuron</source><volume>102</volume><fpage>249</fpage><lpage>259</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.01.026</pub-id><pub-id pub-id-type="pmid">30770252</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Sahani</surname><given-names>M</given-names></name><name><surname>Churchland</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cortical control of arm movements: a dynamical systems perspective</article-title><source>Annual Review of Neuroscience</source><volume>36</volume><fpage>337</fpage><lpage>359</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-062111-150509</pub-id><pub-id pub-id-type="pmid">23725001</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Snedecor</surname><given-names>GW</given-names></name><name><surname>Cochran</surname><given-names>WG</given-names></name></person-group><year iso-8601-date="1980">1980</year><source>Statistical Methods</source><publisher-name>Iowa State University Press</publisher-name></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sobinov</surname><given-names>AR</given-names></name><name><surname>Bensmaia</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The neural mechanisms of manual dexterity</article-title><source>Nature Reviews. Neuroscience</source><volume>22</volume><fpage>741</fpage><lpage>757</lpage><pub-id pub-id-type="doi">10.1038/s41583-021-00528-7</pub-id><pub-id pub-id-type="pmid">34711956</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stark</surname><given-names>E</given-names></name><name><surname>Asher</surname><given-names>I</given-names></name><name><surname>Abeles</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Encoding of reach and grasp by single neurons in premotor cortex is independent of recording site</article-title><source>Journal of Neurophysiology</source><volume>97</volume><fpage>3351</fpage><lpage>3364</lpage><pub-id pub-id-type="doi">10.1152/jn.01328.2006</pub-id><pub-id pub-id-type="pmid">17360824</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Suresh</surname><given-names>AK</given-names></name><name><surname>Goodman</surname><given-names>JM</given-names></name><name><surname>Okorokova</surname><given-names>EV</given-names></name><name><surname>Kaufman</surname><given-names>M</given-names></name><name><surname>Hatsopoulos</surname><given-names>NG</given-names></name><name><surname>Bensmaia</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neural population dynamics in motor cortex are different for reach and grasp</article-title><source>eLife</source><volume>9</volume><elocation-id>e58848</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.58848</pub-id><pub-id pub-id-type="pmid">33200745</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vigneswaran</surname><given-names>G</given-names></name><name><surname>Philipp</surname><given-names>R</given-names></name><name><surname>Lemon</surname><given-names>RN</given-names></name><name><surname>Kraskov</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>M1 corticospinal mirror neurons and their role in movement suppression during action observation</article-title><source>Current Biology</source><volume>23</volume><fpage>236</fpage><lpage>243</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.12.006</pub-id><pub-id pub-id-type="pmid">23290556</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vyas</surname><given-names>S</given-names></name><name><surname>Golub</surname><given-names>MD</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Computation through neural population dynamics</article-title><source>Annual Review of Neuroscience</source><volume>43</volume><fpage>249</fpage><lpage>275</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-092619-094115</pub-id><pub-id pub-id-type="pmid">32640928</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weinrich</surname><given-names>M</given-names></name><name><surname>Wise</surname><given-names>SP</given-names></name><name><surname>Mauritz</surname><given-names>KH</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>A neurophysiological study of the premotor cortex in the rhesus monkey</article-title><source>Brain</source><volume>107 (Pt 2)</volume><fpage>385</fpage><lpage>414</lpage><pub-id pub-id-type="doi">10.1093/brain/107.2.385</pub-id><pub-id pub-id-type="pmid">6722510</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yuste</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>From the neuron doctrine to neural networks</article-title><source>Nature Reviews. Neuroscience</source><volume>16</volume><fpage>487</fpage><lpage>497</lpage><pub-id pub-id-type="doi">10.1038/nrn3962</pub-id><pub-id pub-id-type="pmid">26152865</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Shiftsubs</data-title><version designator="a604c1b">a604c1b</version><source>Github</source><ext-link ext-link-type="uri" xlink:href="https://github.com/ShiftingSubspace/shiftsubs">https://github.com/ShiftingSubspace/shiftsubs</ext-link></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.94165.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Gallego</surname><given-names>Juan Alvaro</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Imperial College London</institution><country>United Kingdom</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Valuable</kwd></kwd-group></front-stub><body><p>This <bold>valuable</bold> study reports on the characteristics of premotor cortical population activity during the execution and observation of a moderately complex reaching and grasping task. By using new variants of well-established techniques to analyse neural population activity, the authors provide <bold>solid</bold> evidence that while the geometry of neural population activity changes between execution and observation, their dynamics are largely preserved. Although these findings are novel and robust, pending additional controls and analyses, the authors should further clarify the functional implications of their findings.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.94165.3.sa1</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>The authors investigated the similarity (or lack thereof) of neural dynamics while monkeys reached to and manipulated one of 4 objects in each trial, compared to observing similar movements performed by experimenters. They focused on mirror neurons (MNs) and rather convincingly showed that MNs dynamics are dissimilar during executing vs. observing actions. The manuscript has improved quite significantly compared to the previous version and I congratulate the authors for that. However, there are still a few points I would like to raise that I think will improve the manuscript scientifically and make it more pleasant to read.</p><p>- I appreciate the nicely compiled literature review which provides the context for the manuscript.</p><p>- Message: The takeaway message of the paper is inconsistent and changes throughout the paper. To me, the main takeaway is that observation and execution subspaces progress during the trial (Fig 4), and that they are distinct processes and rather dissimilar, as stated in #440-441, #634-635, etc. But the title of the paper implies the opposite. Some of the interpretations of the results (e.g., Fig 8) also imply similarity of dynamics.</p><p>- Readability: I have many issues with the readability/organisation of the paper. Unfortunately, I still find the quality of data presentation low. Below I list a few points:</p><p>(1) In 5 sessions out of 9, there are fewer than 20 neurons categorised as AE. This means this population is under-sampled in the data which makes applying any neural population techniques questionable. Moreover, the relevance of the AE analysis is also sometimes unclear: In Fig 4, the AE-related panels are just referred to once in the paper. Yet AE results are presented right next to the main results throughout the paper.</p><p>(2) Figures are low resolution and pixelated. There are some faded horizontal and vertical lines in Fig1B that are barely visible. Moreover, it may be my personal preference, but I think Fig1 is more confusing than helpful. Although panel A shows some planes rotating, indicating time-varying dynamics, I couldn't understand what more panel B is trying to convey. The arrow of time is counterclockwise, but the planes progress clockwise (i &gt; ii &gt; iii). Similarly, panel C just seems to show some points being projected to orthogonal subspaces (even though later in the paper we'll see that observation and execution subspaces are not orthogonal), and the CCA subspace illustrated in the same high-d space, which mathematically may be inaccurate, as CCA projects the data to a new space.</p><p>In Fig 2A, the objects are too small and pixelated as well. I suggest an overhaul of the figures to make the paper more accessible.</p><p>(3) Clarity of the text: The manuscript text could be more concise, to the point, avoiding repetitions, self-consistent, and simply readable. To name a few issues: Single letter acronyms were used to refer to trial epochs (I/G/M/H). M alone has been re-defined 13 different times in the text as in: ...Movement (M)..., excluding every related figure. The acronym (I) refers to the instruction epoch, the high-d space in Fig 1, and panel I of some figures. The acronym MN for Mirror Neurons was defined 4 separate times in the text yet spelled out as Mirror Neuron more than 2 dozen times. CD is defined in the caption of Fig 3 and never used, despite condition-dependent being a common term in the text. Many sentences, e.g., &quot;In contrast, throughout...&quot; in #265-#269, and &quot;To summarize,...&quot; in #270-#275, are too long with difficult wording. To get the point from these sentences, I had to read them many times, and go back and forth between them and the figure. Rewriting such sentences makes the manuscript much more accessible.</p><p>- Figure 3: It appears that the condition independent signal has been calculated by subtracting the average of the 4 neural trajectories in Fig 3A, corresponding to different objects. Whereas #133 suggests that it should be calculated by subtracting the average firing rate of different conditions. Assuming I got the methods right, dynamics being &quot;knotted&quot; (#234) after removing the condition independent signal could be because they are similar, so subtracting the condition independent signal leaves us with the noise component. This matters for the manuscript especially since this is the reason for performing the more sensitive instantaneous subspaces.</p><p>- Decoding results: I appreciate that the authors improved the decoding results in this version of the manuscript. Now it is much more interesting. However oddly, it appears that only data from 1 monkey is shown. #370 says the results from the other 2 are similar. The decoding data from every monkey must be shown. If the results are similar, they must be at least in Supplements. Currently, only 1 session (out of 3) in the Observation condition seems to decode the object type. This effect, if consistent across animals and session, is very interesting on its own and challenges other claims in the paper.</p><p>- Figure8: I reiterate the issue #7 in my previous review. I appreciate the authors clearing some methods, but my concern persists. As per line #839, spiking activity has been smoothed with a 50ms kernel. Thus, unless trial data is concatenated, I suspect the 100ms window used for this analysis is too short (small sample size), thus the correlation values (CCs) might be spurious. References cited in this section use a smaller smoothing kernel (30ms) and a much longer window (~450ms).</p><p>Moreover, I don't know why the authors chose to show correlation values in 3D space! Values of Fig8C-red are impossible to know. Furthermore, the manuscript insists on CC values of the Hold period being high, which is probably correct. But I wonder why the focus on the Hold period? I think the most relevant epoch for analysing the MNs is the Movement where the actual action happens. Interestingly, in the movement epoch, the CC values are visibly low. The reason why Hold results are more important and why the CCs in Movement are so low should be clarified in the text. Especially, statements like that in #661 seem particularly unjustified.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.94165.3.sa2</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>In their study, Zhao et al. investigated the population activity of mirror neurons (MNs) in the premotor cortex of monkeys either executing or observing a task consisting of reaching to, grasping, and manipulating various objects. The authors proposed an innovative method for analyzing the population activity of MNs during both execution and observation trials. This method enabled to isolate the condition dependent variance in neural data and to study its temporal evolution over the course of single trials. The method proposed by the authors consists of building a time series of &quot;instantaneous&quot; subspaces with single time step resolution, rather than a single subspace spanning the entire task duration. As these subspaces are computed on an instant time basis, projecting neural activity from a given task time into them results in latent trajectories that capture condition-dependent variance while minimizing the condition-independent one. Authors then analyzed the time evolution of these instantaneous subspaces and revealed that a progressive shift is present in subspaces of both execution and observation trials, with slower shifts during the grasping and manipulating phases compared to the initial preparation phase. Finally, they compared the instantaneous subspaces between execution and observation trials and observed that neural population activity did not traverse the same subspaces in these two conditions. However, they showed that these distinct neural representations can be aligned with Canonical Correlation Analysis, indicating dynamic similarities of neural data when executing and observing the task. The authors speculated that such similarities might facilitate the nervous system's ability to recognize actions performed by oneself or another individual.</p><p>Unlike other areas of the brain, the analysis of neural population dynamics of premotor cortex MNs is not well established. Furthermore, analyzing population activity recorded during non-trivial motor actions, distinct from the commonly used reaching tasks, serves as a valuable contribution to computational neuroscience. This study holds particular significance as it bridges both domains, shedding light on the temporal evolution of the shift in neural states when executing and observing actions. The results are moderately robust, and the proposed analytical method could potentially be used in other neuroscience contexts.</p></body></sub-article><sub-article article-type="referee-report" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.94165.3.sa3</article-id><title-group><article-title>Reviewer #4 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>In this study, the authors explore the neural dynamics of mirror neurons in the premotor cortex, focusing on the relationship between neural activity during action execution and observation. The study presents a rich dataset from three monkeys, with recordings from two regions per monkey. The authors use a method to analyze instantaneous neural subspaces and track their temporal evolution. Consistent with prior literature, they report that execution and observation subspaces remain largely distinct throughout the trial. However, after applying canonical correlation analysis, they observe a notable alignment between execution and observation activities, suggesting the presence of shared neural codes. The study is well-designed, and the analyses are thoroughly documented, occasionally overly so in the main text. While most findings are compelling, I find the conclusions drawn from Figure 8 less convincing. Specifically, I am skeptical about the application of CCA in this context and the subsequent interpretations regarding execution-observation similarity, which is a central claim of the manuscript.</p><p>• The authors cite Safaie et al. 2023 as a precedent for applying CCA to align neural population dynamics. However, in that study, CCA was used to align neural dynamics across different animals, a justifiable approach given that neural trajectories exist in separate neural state spaces for each animal. Here, CCA is applied to align execution and observation activities within the same neural state space of the same MNs. I find this application of CCA less well-justified, as it may overestimate execution-observation similarity.</p><p>• The control conditions presented in Figures 8C and 8D are somewhat reassuring, as they show that the similarity introduced by CCA is not universally high. However, these controls appear to be limited to the Hold epoch. It remains unclear whether the same holds true for the Go and Movement epochs.</p><p>• In Figure 5, the authors display low-dimensional representations of four objects across task epochs during execution (A) and observation (B). The diagonals of the matrices reveal clear differences between execution and observation configurations across all four epochs. The authors suggest using CCA to align these configurations; however, this alignment seems to require time-specific application of CCA for each epoch (as demonstrated in Figure 8 for the Hold epoch). The need for time-specific adjustments likely depends on the fact that execution and observation subspaces are continuously shifting over time (as authors show in Figure 4), but this approach appears to be a strained attempt to demonstrate similarity between execution and observation codes.</p><p>• The authors themselves offer an alternative hypothesis (line 730): that &quot;PM MN population activity during action observation, rather than representing movements made by another individual similar to one's own movements, instead may represent different movements one might execute oneself in response to those made by another individual&quot;. This interpretation appears more congruent with the data presented.</p><p>• In the end, I am left with a sense of ambiguity: which analysis should be considered more reliable, the negligible correspondence between execution and observation activity depicted in Figure 7, or the considerable similarity shown in Figure 8? The authors should address this apparent contradiction and provide a clearer discussion to reconcile these findings.</p></body></sub-article><sub-article article-type="author-comment" id="sa4"><front-stub><article-id pub-id-type="doi">10.7554/eLife.94165.3.sa4</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Zhao</surname><given-names>Zhonghao</given-names></name><role specific-use="author">Author</role><aff><institution>University of Rochester</institution><addr-line><named-content content-type="city">Rochester, NY</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Schieber</surname><given-names>Marc</given-names></name><role specific-use="author">Author</role><aff><institution>University of Rochester</institution><addr-line><named-content content-type="city">Rochester, NY</named-content></addr-line><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><p>Major changes in the revised manuscript include:</p><p>(1) The distinction between condition-dependent versus condition-independent variation in neural activity has been clarified.</p><p>(2) Principal angle calculations have been added.</p><p>(3) Neurons modulated during action execution but not during action observation have been analyzed to compare and contrast with mirror neurons.</p><p>(4) Canonical correlation analysis has been extended to three dimensions.</p><p>(5) Speculations have been moved to and modified in the Discussion.</p><p>(6) Computational details have been expanded in the Methods.</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public Review):</bold></p><p>Summary and strengths. This paper starts with an exceptionally fair and balanced introduction to a topic, the mirror neuron literature, which is often debated and prone to controversies even in the choice of the terminology. In my opinion, the authors made an excellent job in this regard, and I really appreciated it. Then, they propose a novel method to look at population dynamics to compare neural selectivity and alignment between execution and observation of actions performed with different types of grip.</p></disp-quote><p>Thank you.</p><disp-quote content-type="editor-comment"><p>Weakness.</p><p>Unfortunately, the goal and findings within this well-described framework are less clear to me. The authors aimed to investigate, using a novel analytic approach, whether and to what extent a match exists between population codes and neural dynamics when a monkey performs an action or observes it performed by an experimenter. This motivation stems from the fact that the general evidence in the literature is that the match between visual and motor selectivity of mirror neuron responses is essentially at a chance level. While the approach devised by the author is generally well-described and understandable, the main result obtained confirms this general finding of a lack of matching between the two contexts in 2 out of the three monkeys. Nevertheless, the authors claim that the patterns associated with execution and observation can be re-aligned with canonical correlation, indicating that these distinct neural representations show dynamical similarity that may enable the nervous system to recognize particular actions. This final conclusion is hardly acceptable to me, and constitutes my major concern, at least without a more explicit explanation: how do we know that this additional operation can be performed by the brain?</p></disp-quote><p>Point taken. In the Discussion, we now have clarified that this is our speculation rather than a conclusion and we also offer an alternative interpretation (lines 724 to 744):</p><p>“One classic interpretation of similar latent dynamics in the PM MN population during execution and observation would be that this similarity provides a means for the brain to recognize similar movements performed by the monkey during execution and by the experimenter during observation. Through some process akin to a communication subspace (Semedo et al., 2019), brain regions beyond PM might recognize the correspondence between the latent dynamics of the executed and observed actions.</p><p>Alternatively, given that observation of another individual can be considered a form of social interaction, PM MN population activity during action observation, rather than representing movements made by another individual similar to one’s own movements, instead may represent different movements one might execute oneself in response to those made by another individual (Ninomiya et al., 2020; Bonini et al., 2022; Ferrucci et al., 2022; Pomper et al., 2023). This possibility is consistent with the finding that the neural dynamics of PM MN populations are more similar during observation of biological versus non-biological movements than during execution versus observation (Albertini et al., 2021). Though neurons active only during observation of others (AO units) have been hypothesized to drive observation activity in MNs, the present AO populations were too small to analyze with the approaches we applied here. Nevertheless, the similar relative organization of the execution and observation population activity in PM MNs revealed here by alignment of their latent dynamics through CCA could constitute a correspondence between particular movements that might be made by the subject in response to particular movements made by the other individual, i.e. responsive movements which would not necessarily be motorically similar to the observed movements.”</p><disp-quote content-type="editor-comment"><p>Is this a computational trick to artificially align something that is naturally non-aligned, or can it capture something real and useful?</p></disp-quote><p>We feel this is more than a trick. In the Introduction, we now have clarified (lines 166 to 170):</p><p>“Such alignment would indicate that the relationships among the trajectory segments in the execution subspace are similar to the relationships among the trajectory segments in the observation subspace, indicating a corresponding structure in the latent dynamic representations of execution and observation movements by the same PM MN population.”</p><p>In the Results we give the follow example (lines 446 to 455):</p><p>“Such alignment would indicate that neural representations of trials involving the four objects bore a similar relationship to one another in neural space during execution and observation, even though they occurred in different subspaces. For example, the trajectories of PMd+M1 neuron populations recorded from two different monkeys during center-out reaching movements could be aligned well (Safaie et al., 2023). CCA showed, for example, that in both brains the neural trajectory for the movement to the target at 0° was closer to the trajectory for movement to the target at 45° than to the trajectory for the movement to the target at 180°. Relationships among these latent dynamic representations of the eight movements thus were similar even though the neural populations were recorded from two different monkeys.”</p><p>And in the Discussion we now compare (lines 677 to 686):</p><p>“Corresponding neural representations of action execution and observation during task epochs with higher neural firing rates have been described previously in PMd MNs and in PMv MNs using representational similarity analysis RSA (Papadourakis and Raos, 2019). And during force production in eight different directions, neural trajectories of PMd neurons draw similar “clocks” during execution, cooperative execution, and passive observation (Pezzulo et al., 2022). Likewise in the present study, despite execution and observation trajectories progressing through largely distinct subspaces, in all three monkeys execution and observation trajectory segments showed some degree of alignment, particularly the Movement and Hold segments (Figure 8C), indicating similar relationships among the latent dynamic representations of the four RGM movements during execution and observation.”</p><disp-quote content-type="editor-comment"><p>Based on the accumulated evidence on space-constrained coding of others' actions by mirror neurons (e.g., Caggiano et al. 2009; Maranesi et al. 2017), recent evidence also cited by the authors (Pomper et al. 2023), and the most recent views supported even by the first author of the original discovery (i.e., Vittorio Gallese, see Bonini et al. 2022 on TICS), it seems that one of the main functions of these cells, especially in monkeys, might be to prepare actions and motor responses during social interaction rather than recognizing the actions of others - something that visual brain areas could easily do better than motor ones in most situations. In this perspective, and given the absence of causal evidence so far, the lack of visuo-motor congruence is a potentially relevant feature of the mechanism rather than something to be computationally cracked at all costs.</p></disp-quote><p>We agree that this perspective provides a valuable interpretation of our findings. In the Discussion, we have added the following paragraph (lines 730 to 744):</p><p>“Alternatively, given that observation of another individual can be considered a form of social interaction, PM MN population activity during action observation, rather than representing movements made by another individual similar to one’s own movements, instead may represent different movements one might execute oneself in response to those made by another individual (Ninomiya et al., 2020; Bonini et al., 2022; Ferrucci et al., 2022; Pomper et al., 2023). This possibility is consistent with the finding that the neural dynamics of PM MN populations are more similar during observation of biological versus non-biological movements than during execution versus observation (Albertini et al., 2021). Though neurons active only during observation of others (AO units) have been hypothesized to drive observation activity in MNs, the present AO populations were too small to analyze with the approaches we applied here. Nevertheless, the similar relative organization of the execution and observation population activity in PM MNs revealed here by alignment of their latent dynamics through CCA could constitute a correspondence between particular movements that might be made by the subject in response to particular movements made by the other individual, i.e. responsive movements which would not necessarily be motorically similar to the observed movements.”</p><disp-quote content-type="editor-comment"><p>Specific comments on Results/Methods:</p><p>I can understand, based on the authors' hypothesis, that they employed an ANOVA to preliminarily test whether and which of the recorded neurons fit their definition of &quot;mirror neurons&quot;. However, given the emphasis on the population level, and the consolidated finding of highly different execution and observation responses, I think it could be interesting to apply the same analysis on (at least also) the whole recorded neuronal population, without any preselection-based on a single neuron statistic. Such preselection of mirror neurons could influence the results of EXE-OBS comparisons since all the neurons activated only during EXE or OBS are excluded. Related to this point, the authors could report the total number of recorded neurons per monkey/session, so that also the fraction of neurons fitting their definition of mirror neuron is explicit.</p></disp-quote><p>We are aware that a number of recent studies from other laboratories already have analyzed the entire population of neurons during execution versus observation, without selectively analyzing neurons active during both execution and observation (Jiang et al., 2020; Albertini et al., 2021). However, our focus lies not in how the entire PM neural population encodes execution versus observation, but in the differential activity of the mirror neuron subpopulation in these two contexts. Our new Table 2 presents the numbers of mirror neurons (MN), action execution only neurons (AE), action observation only neurons (AO), and neurons not significantly task-related during either execution or observation (NS). Although we often recorded substantial numbers of AE neurons, very few AO neurons were found in our recordings. In analyzing the AE subpopulation, we found unexpected differences in canonical correlation alignment between and within the MN and AE neuron populations. In view of the editors’ comments that “…the reviewers provided several specific recommendations of new analyses to include. However, now the paper feels extremely long…”. We have chosen to focus on comparing AE neurons with MNs.</p><disp-quote content-type="editor-comment"><p>Furthermore, the comparison of the dynamics of the classification accuracy in figures 4 and 5, and therefore the underlying assumption of subspaces shift in execution and observation, respectively, reveal substantial similarities between monkeys despite the different contexts, which are clearly greater than the similarities among neural subspaces shifts across task epochs: to me, this suggests that the main result is driven by the selected neural populations in different monkeys/implants rather than by an essential property of the neuronal dynamics valid across animals. Could the author comment on this issue? This could easily explain the &quot;strange&quot; result reported in figure 6 for monkey T.</p></disp-quote><p>We have taken the general approach of emphasizing findings common across individual animals, but also reporting individual differences. We have added the following in the Discussion (lines 645 to 654):</p><p>“We did not attempt to classify neurons in our PM MN populations as strictly congruent, broadly congruent, or non-congruent. Nevertheless, the minimal overlap we found in instantaneous execution and observation subspaces would be consistent with a low degree of congruence in our PM MN populations. Particularly during one session monkey T was an exception in this regard, showing a considerable degree of overlap between execution and observation subspaces, not unlike the shared subspace found in other studies that identified orthogonal execution and observation subspaces as well (Jiang et al., 2020). Although our microelectrode arrays were placed in similar cortical locations in the three monkeys, by chance monkey T’s PM MN population may have included a substantial proportion of congruent neurons.”</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public Review):</bold></p><p>In this work, the authors set out to identify time-varying subspaces in the premotor cortical activity of monkeys as they executed/observed a reach-grasp-hold movement of 4 different objects. Then, they projected the neural activity to these subspaces and found evidence of shifting subspaces in the time course of a trial in both conditions, executing and observing. These shifting subspaces appear to be distinct in execution and observation trials. However, correlation analysis of neural dynamics reveals the similarity of dynamics in these distinct subspaces. Taken together, Zhao and Schieber speculate that the condition-dependent activity studied here provides a representation of movement that relies on the actor.</p><p>This work addresses an interesting question. The authors developed a novel approach to identify instantaneous subspaces and decoded the object type from the projected neural dynamics within these subspaces. As interesting as these results might be, I have a few suggestions and questions to improve the manuscript:</p><p>(1) Repeating the analyses in the paper, e.g., in Fig5, using non-MN units only or the entire population, and demonstrating that the results are specific to MNs would make the whole study much more compelling.</p></disp-quote><p>We have added analyses of those non-MNs modulated significantly during action execution but not during observation, which we refer to as AE neurons. The additional findings from these analyses are spread throughout the manuscript:</p><p>Lines 284-293:</p><p>“We also examined the temporal progression of the instantaneous subspace of AE neurons. As would be expected given that AE neurons were not modulated significantly during observation trials, in the observation context AE populations had no gradual changes in principal angle (Figure 4 – figure supplement 3). During execution, however, Figure 4I-L show that the AE populations had a pattern of gradual decrease in principal angle similar to that found in the MN population (Figure 4A-D). After the instruction onset, the instantaneous subspace shifted quickly away from that present at time I and progressed gradually toward that present at times G and M, only shifting toward that present at time H after movement onset. As for the PM MN populations, the condition-dependent subspace of the PM AE populations shifted progressively over the time course of execution RGM trials.”</p><p>Lines 411-419:</p><p>“During execution trials, classification accuracy for AE populations (Figure 6I-L) showed a time course quite similar to that for MN populations, though amplitudes were lower overall, most likely because of the smaller population sizes. During observation, AE populations showed only low-amplitude, short-lived peaks of classification accuracy around times I, G, M, and H (Figure 6 – figure supplement 1). Given that individual AE neurons showed no statistically significant modulation during observation trials, even these small peaks might not have been expected. Previous studies have indicated, however, that neurons not individually related to task events nevertheless may contribute to a population response (Shenoy et al., 2013; Cunningham and Yu, 2014; Gallego et al., 2017; Jiang et al., 2020).”</p><p>Lines 495-508:</p><p>“Although MNs are known to be present in considerable numbers in both the primary motor cortex and premotor cortex (see Introduction), most studies of movement-related cortical activity in these areas make no distinction between neurons with activity only during action execution (AE neurons) and those with activity during both execution and observation (MNs). This reflects an underlying assumption that during action execution, mirror neurons function in parallel with AE neurons, differing only during observation. We therefore tested the hypothesis that MN and AE neuron execution trajectory segments from the same session would align well. Figure 8C (blue) shows the mean CCs between MN and AE execution trajectory segments across 8 alignments (MN/AE; 2 R, 3 T, 3 F), which reached the highest values for the Hold segments <inline-formula><alternatives><mml:math id="sa4m1"><mml:mo stretchy="false">(</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mo accent="true">―</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.57</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mo accent="true">―</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.35</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:mrow><mml:mo accent="true">―</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.19</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft49">\begin{document}$(\overline{C C 1}=0.57, \overline{C C 2}=0.35, \overline{C C 3}=0.19)$\end{document}</tex-math></alternatives></inline-formula>. All three of these coefficients were substantially lower than those for the MN execution vs. observation alignments given above. Surprisingly, the alignment of AE neuron execution trajectory segments with those of the simultaneously recorded MN population was weaker than the alignment of MN trajectories during execution vs. observation.</p><p>Did these differences in MN:1/2, MN:E/O, and MN/AE alignment result from consistent differences in their respective patterns of co-modulation, or from of greater trial-by-trial variability in the patterns of co-modulation among MNs during observation than during execution, and still greater variability among AE neurons during execution? The bootstrapping approach we used for CCA (see Methods) enabled us to evaluate the consistency of relationships among trajectory segments across repeated samplings of trials recorded from the same neuron population in the same session and in the same context (execution or observation). We therefore performed 500 iterations of CCA between two different random samples of MN execution (MN:E/E), MN observation (MN:O/O), or AE execution (AE:E/E) trajectory segments from a given session (2 R, 3 T, 3 F). This within-group alignment of MN execution trajectory segments from the same session (Figure 8D, MN:E/E, gray, Hold: <inline-formula><alternatives><mml:math id="sa4m2"><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mo accent="true">―</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.88</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mo accent="true">―</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.74</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:mrow><mml:mo accent="true">―</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.55</mml:mn></mml:math><tex-math id="inft50">\begin{document}$\overline{C C 1}=0.88, \overline{C C 2}=0.74, \overline{C C 3}=0.55$\end{document}</tex-math></alternatives></inline-formula>) was as strong as between session alignment (Figure 8C, MN/1:2, black). But within-group alignment of MN observation trajectory segments (Figure 8D, MN:O/O, orange, Hold: <inline-formula><alternatives><mml:math id="sa4m3"><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mo accent="true">―</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.65</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mo accent="true">―</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.46</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:mrow><mml:mo accent="true">―</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.24</mml:mn></mml:math><tex-math id="inft51">\begin{document}$\overline{C C 1}=0.65, \overline{C C 2}=0.46, \overline{C C 3}=0.24$\end{document}</tex-math></alternatives></inline-formula>) was lower than that found with MN execution segments Figure 8C, MN:E/O, red, <inline-formula><alternatives><mml:math id="sa4m4"><mml:mo stretchy="false">(</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mo accent="true">―</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.73</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mo accent="true">―</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.54</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:mrow><mml:mo accent="true">―</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.39</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:math><tex-math id="inft52">\begin{document}$(\overline{C C 1}=0.73, \overline{C C 2}=0.54, \overline{C C 3}=0.39)$\end{document}</tex-math></alternatives></inline-formula>. Likewise, within-group alignment of AE neuron trajectory segments (Figure 8D, AE:E/E, light blue, Hold: <inline-formula><alternatives><mml:math id="sa4m5"><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mo accent="true">―</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.46</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mo accent="true">―</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:mrow><mml:mo accent="true">―</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.10</mml:mn></mml:math><tex-math id="inft53">\begin{document}$\overline{C C 1}=0.46, \overline{C C 2}=0.25, \overline{C C 3}=0.10$\end{document}</tex-math></alternatives></inline-formula>) was lower than their alignment with MN execution segments (Figure 8C, MN/AE, blue, Hold: <inline-formula><alternatives><mml:math id="sa4m6"><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mo accent="true">―</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.57</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mo accent="true">―</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.35</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:mrow><mml:mo accent="true">―</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.19</mml:mn></mml:math><tex-math id="inft54">\begin{document}$\overline{C C 1}=0.57, \overline{C C 2}=0.35, \overline{C C 3}=0.19$\end{document}</tex-math></alternatives></inline-formula>). Whereas MN execution trajectories were relatively consistent within sessions, MN observation trajectories and AE execution trajectories were less so.”</p><p>And in the Discussion we now suggest (lines 682 to 698):</p><p>“Based on the assumption that AE neurons and MNs function as a homogenous neuron population during action execution, we had expected AE and MN execution trajectory segments to align closely. During execution trials, the progression of instantaneous condition-dependent subspaces and of classification accuracy in AE populations was quite similar to that in MN populations. We were surprised to find, therefore, that alignment between execution trajectory segments from AE populations and from the simultaneously recorded MN populations was even lower than alignment between MN execution and observation segments (Figure 8C, blue versus red). Moreover, whereas within-group alignment of MN execution trajectory segments was high, within-group alignment of AE neuron execution trajectory segments was low (Figure 8D, gray versus light blue). These findings indicate that the predominant patterns of co-modulation among MNs during execution are quite consistent within sessions, but the patterns of comodulation among AE neurons are considerably more variable. Together with our previous finding that modulation of MNs leads that of non-mirror neurons in time, both at the single neuron level and at the population level (Mazurek and Schieber, 2019), this difference in consistency versus variability leads us to speculate that during action execution, while MNs carry a consistent forward model of the intended movement, AE neurons carry more variable feedback information.”</p><disp-quote content-type="editor-comment"><p>(2) The method presented here is similar and perhaps related to principal angles (https://doi.org/10.2307/2005662). It would be interesting to confirm these results with principal angles. For instance, instead of using the decoding performance as a proxy for shifting subspaces, principal angles could directly quantify the 'shift' (similar to Gallego et al, Nat Comm, 2018).</p></disp-quote><p>Point taken. We now have calculated the principal angles as a function of time and present them as a new section of the Results including new figure 4 (lines 237 to 293).</p><p>“Instantaneous subspaces shift progressively during both execution and observation</p><p>We identified an instantaneous subspace at each one millisecond time step of RGM trials. At each time step, we applied PCA to the 4 instantaneous neural states (i.e. the 4 points on the neural trajectories representing trials involving the 4 different objects each averaged across 20 trials per object, totaling 80 trials), yielding a 3-dimensional subspace at that time (see Methods). Note that because these 3-dimensional subspaces are essentially instantaneous, they capture the condition-dependent variation in neural states, but not the common, condition-independent variation. To examine the temporal progression of these instantaneous subspaces, we then calculated the principal angles between each 80-trial instantaneous subspace and the instantaneous subspaces averaged across all trials at four behavioral time points that could be readily defined across trials, sessions, and monkeys: the onset of the instruction (I), the go cue (G), the movement onset (M), and the beginning of the final hold (H). This process was repeated 10 times with replacement to assess the variability of the principal angles. The closer the principal angles are to 0°, the closer the two subspaces are to being identical; the closer to 90°, the closer the two subspaces are to being orthogonal.</p><p>Figure 4A-D illustrate the temporal progression of the first principal angle of the mirror neuron population in the three sessions (red, green, and blue) from monkey R during execution trials. As illustrated in Figure 4 – figure supplement 1 (see also the related Methods), in each session all three principal angles, each of which could range from 0° to 90°, tended to follow a similar time course. In the Results we therefore illustrate only the first (i.e. smallest) principal angle. Solid traces represent the mean across 10-fold cross validation using the 80-trial subsets of all the available trials; shading indicates ±1 standard deviation. As would be expected, the instantaneous subspace using 80 trials approaches the subspace using all trials at each of the four selected times—I, G, M, and H—indicated by the relatively narrow trough dipping toward 0°. Of greater interest are the slower changes in the first principal angle in between these four time points. Figure 4A shows that after instruction onset (I) the instantaneous subspace shifted quickly away from the subspace at time I, indicated by a rapid increase in principal angle to levels not much lower than what might be expected by chance alone (horizontal dashed line). In contrast, throughout the remainder of the instruction and delay epochs (from I to G), Figure 4B and C show that the 80-trial instantaneous subspace shifted gradually and concurrently, not sequentially, toward the all-trial subspaces that would be reached at the end of the delay period (G) and then at the onset of movement (M), indicated by the progressive decreases in principal angle. As shown by Figure 4D, shifting toward the H subspace did not begin until the movement onset (M). To summarize, these changes in principal angles indicate that after shifting briefly toward the subspace present at time the instruction appeared (I), the instantaneous subspace shifted progressively throughout the instruction and delay epochs toward the subspace that would be reached at the time of the go cue (G), then further toward that at the time of movement onset (M), and only thereafter shifted toward the instantaneous subspace that would be present at the time of the hold (H).</p><p>Figure 4E-H show the progression of the first principal angle of the mirror neuron population during observation trials. Overall, the temporal progression of the MN instantaneous subspace during observation was similar to that found during execution, particularly around times I and H. The decrease in principal angle relative to the G and M instantaneous subspaces during the delay epoch was less pronounced during observation than during execution. Nevertheless, these findings support the hypothesis that the condition-dependent subspace of PM MNs shifts progressively over the time course of RGM trials during both execution and observation, as illustrated schematically in Figure 1A.</p><p>We also examined the temporal progression of the instantaneous subspace of AE neurons. As would be expected given that AE neurons were not modulated significantly during observation trials, in the observation context AE populations had no gradual changes in principal angle (Figure 4 – figure supplement 3). During execution, however, Figure 4I-L show that the AE populations had a pattern of gradual decrease in principal angle similar to that found in the MN population (Figure 4A-D). After the instruction onset, the instantaneous subspace shifted quickly away from that present at time I and progressed gradually toward that present at times G and M, only shifting toward that present at time H after movement onset. As for the PM MN populations, the condition-dependent subspace of the PM AE populations shifted progressively over the time course of execution RGM trials.”</p><disp-quote content-type="editor-comment"><p>The related Methods are now described in subsection “Subspace Comparisons—Principal Angles”</p></disp-quote><p>Relatedly, why the decoding of the 'object type' is used to establish the progressive shifting of the subspaces? I would be interested to see the authors' argument.</p><p>We have clarified the reason for our decoding analysis as follows (lines 295 to 297):</p><p>“The progressive changes in principal angles do not capture another important aspect of condition-dependent neural activity. The neural trajectories during trials involving different objects separated increasingly as trials progressed in time.”</p><p>And… (lines 332 to 348):</p><p>“Decodable information changes progressively during both execution and observation</p><p>As RGM trials proceeded in time, the condition-dependent neural activity of the PM MN population thus changed in two ways. First, the instantaneous condition-dependent subspace shifted, indicating that the patterns of firing-rate co-modulation among neurons representing the four different RGM movements changed progressively, both during execution and during observation. Second, as firing rates generally increased, the neural trajectories representing the four RGM movements became progressively more separated, more so during execution than during observation.</p><p>To evaluate the combined effects of these two progressive changes, we clipped 100 ms single-trial trajectory segments beginning at times I, G, M, or H, and projected these trajectory segments from individual trials into the instantaneous 3D subspaces at 50 ms time steps. At each of these time steps, we trained a separate LSTM decoder to classify individual trials according to which of the four objects was involved in that trial. We expected that the trajectory segments would be classified most accurately when projected into instantaneous subspaces near the time at which the trajectory segments were clipped. At other times we reasoned that classification accuracy would depend both on the similarity of the current instantaneous subspace to that found at the clip time as evaluated by the principal angle (Figure 4), and on the separation of the four trajectories at the clip time (Figure 5).”</p><disp-quote content-type="editor-comment"><p>The object type should be much more decodable during movement or hold, than instruction, which is probably why the chance-level decoding performance (horizontal lines) is twice the instruction segment for the movement segment.</p></disp-quote><p>Indeed, the object type is more decodable during the movement and hold than during instruction or delay epochs.</p><disp-quote content-type="editor-comment"><p>(3) Why aren't execution and observation subspaces compared together directly? Especially given that there are both types of trials in the same session with the same recorded population of neurons. Using instantaneous subspaces, or the principal angles between manifolds during exec trials vs obs trials.</p></disp-quote><p>Point taken. We now have added comparison of the execution and observation subspaces using the principal angles between instantaneous subspaces (lines 421 to 436):</p><p>“Do PM mirror neurons progress through the same subspaces during execution and observation?</p><p>Having found that PM mirror neuron populations show similar progressive shifts in their instantaneous neural subspace during execution and observation of RGM trials, as well as similar changes in decodable information, we then asked whether this progression passes through similar subspaces during execution and observation. To address this question, we first calculated the principal angles between the instantaneous mirror-neuron execution subspace at selected times I, G, M, or H and the entire time series of instantaneous mirror-neuron observation subspaces (Figure 7A-D). Conversely, we calculated the principal angles between the instantaneous observation subspaces at selected times I, G, M, or H and the entire time series of instantaneous execution subspaces (Figure 7E-H). Although the principal angles were slightly smaller than might be expected from chance alone, indicating some minimal overlap of execution and observation instantaneous subspaces, the instantaneous observation subspaces did not show any progressive shift toward the I, G, M, or H execution subspace (Figure 7A-D), nor did the instantaneous execution subspaces shift toward the I, G, M, or H observation subspace (Figure 7E-H).”</p><disp-quote content-type="editor-comment"><p>(4) The definition of the instantaneous subspaces is a critical point in the manuscript. I think it is slightly unclear: based on the Methods section #715-722 and the main text #173-#181, I gather that the subspaces are based on trial averaged neural activity for each of the 4 objects, separately. So for each object and per timepoint, a vector of size (1, n) -n neurons- is reduced to a vector of (1, 2 or 3 -the main text says 2, methods say 3-) which would be a single point in the low-d space. Is this description accurate? This should be clarified in the manuscript.</p></disp-quote><p>In the Methods, we now have clarified (lines 849 to 859):</p><p>“Instantaneous subspace identification</p><p>Instantaneous neural subspaces were identified at 1 ms intervals. At each 1 ms time step, the N-dimensional neural firing rates from trials involving the four different objects— sphere, button, coaxial cylinder, and perpendicular cylinder—were averaged separately, providing four points in the N-dimensional space representing the average neural activity for trials involving the different objects at that time step. PCA then was performed on these four points. Because three dimensions capture all the variance of four points, three principal component dimensions fully defined each instantaneous subspace. Each instantaneous 3D subspace can be considered a filter described by a matrix, W, that can project high-dimensional neural activity into a low-dimensional subspace, with the time series of instantaneous subspaces, W_i, forming a time series of filters (Figure 1B).”</p><disp-quote content-type="editor-comment"><p>(5) Isn't the process of projecting segments of neural dynamics and comparing the results equivalent to comparing the projection matrices in the first place? If so, that might have been a more intuitive avenue to follow.</p></disp-quote><p>As described in more detail in our responses to item 2, above, we have added analyses of principal angles to compare the projection matrices directly. However, “the process of projecting segments of neural dynamics and comparing the results” incorporates the progressively increasing separation of the trajectory segments and hence is not simply equivalent to comparing the subspaces with principal angles.</p><disp-quote content-type="editor-comment"><p>(6) Lines #385-#389: This process seems unnecessarily complicated. Also, given the number of trials available, this sometimes doesn't make sense. E.g. Monkey R exec has only 8 trials of one of the objects, so bootstrapping 20 trials 500 times would be spurious. Why not, as per Gallego et al, Nat Neurosci 2020 and Safaie et al, Nat 2023 which are cited, concatenate the trials?</p></disp-quote><p>In the Methods we now clarify that (lines 953 to 969):</p><p>“To provide an estimate of variability, we used a bootstrapping approach to CCA. From each of two data sets we randomly selected 20 trials involving each target object (totaling 80 trials) with replacement, clipped trajectory segments from each of those trials for 100 ms (100 points at 1 ms intervals) after the instruction onset, go cue, movement onset, or beginning of the final hold, and performed CCA as described above. (Note that because session 1 from monkey R included only 8 button trials (Table 1), we excluded this session from CCA analyses.) With 500 iterations, we obtained a distribution of the correlation coefficients (CCs) between the two data sets in each of the three dimensions of the aligned subspace, which permitted statistical comparisons. We then used this approach to evaluate alignment of latent dynamics between different sessions (e.g. execution trials on two different days), between different contexts (e.g. execution and observation), and between different neural populations (e.g. MNs and AE neurons).This bootstrapping approach further enabled us to assess the consistency of relationships among neural trajectories within a given group—i.e. the same neural population during the same context (execution or observation) in the same session—by drawing two separate random samples of 80 trials from the same population, context, and session (Figure 8D), which would not have been possible had we concatenated trajectory segments from all trials in the session (Gallego et al., 2020; Safaie et al., 2023).”</p><p>And we report results that could not have been obtained by concatenating all the trials (lines 522 to 541):</p><p>“Did these differences in MN:1/2, MN:E/O, and MN/AE alignment result from consistent differences in their respective patterns of co-modulation, or from of greater trial-by-trial variability in the patterns of co-modulation among MNs during observation than during execution, and still greater variability among AE neurons during execution? The bootstrapping approach we used for CCA (see Methods) enabled us to evaluate the consistency of relationships among trajectory segments across repeated samplings of trials recorded from the same neuron population in the same session and in the same context (execution or observation). We therefore performed 500 iterations of CCA between two different random samples of MN execution (MN:E/E), MN observation (MN:O/O), or AE execution (AE:E/E) trajectory segments from a given session (2 R, 3 T, 3 F). This within-group alignment of MN execution trajectory segments from the same session (Figure 8D, MN:E/E, gray, Hold: <inline-formula><alternatives><mml:math id="sa4m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.88</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.74</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.55</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft55">\begin{document}$\overline{C C 1}=0.88, \overline{C C 2}=0.74, \overline{C C 3}=0.55$\end{document}</tex-math></alternatives></inline-formula>) was as strong as between session alignment (Figure 8C, MN/1:2, black). But within-group alignment of MN observation trajectory segments (Figure 8D, MN:O/O, orange, Hold: <inline-formula><alternatives><mml:math id="sa4m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.65</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.46</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.24</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft56">\begin{document}$\overline{C C 1}=0.65, \overline{C C 2}=0.46, \overline{C C 3}=0.24$\end{document}</tex-math></alternatives></inline-formula>) was lower than that found with MN execution segments Figure 8C, MN:E/O, red, <inline-formula><alternatives><mml:math id="sa4m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.73</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.54</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.39</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft57">\begin{document}$(\overline{C C 1}=0.73, \overline{C C 2}=0.54, \overline{C C 3}=0.39)$\end{document}</tex-math></alternatives></inline-formula>. Likewise, within-group alignment of AE neuron trajectory segments (Figure 8D, AE:E/E, light blue, Hold: <inline-formula><alternatives><mml:math id="sa4m10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.46</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.10</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft58">\begin{document}$\overline{C C 1}=0.46, \overline{C C 2}=0.25, \overline{C C 3}=0.10$\end{document}</tex-math></alternatives></inline-formula>) was lower than their alignment with MN execution segments (Figure 8C, MN/AE, blue, Hold: <inline-formula><alternatives><mml:math id="sa4m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.57</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.35</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.19</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft59">\begin{document}$\overline{C C 1}=0.57, \overline{C C 2}=0.35, \overline{C C 3}=0.19$\end{document}</tex-math></alternatives></inline-formula>). Whereas MN execution trajectories were relatively consistent within sessions, MN observation trajectories and AE execution trajectories were less so.”</p><p>Because only 8 button trials were available in Session 1 from Monkey R, we excluded this session from the CCA analyses. Sessions 2 and 3 from monkey R provide valid results, however. For example, we now state explicitly (lines 468 to 472):</p><p>“As a positive control, we first aligned MN execution trajectory segments from two different sessions in the same monkey (which we abbreviate as MN:1/2). The 2 sessions in monkey R provided only 1 possible comparison, but the 3 sessions in monkeys T and F each provided 3 comparisons. For each of these 7 comparisons, we found the bootstrapped average of CC1, of CC2, and of CC3.”</p><disp-quote content-type="editor-comment"><p>(7) Related to the CCA analysis, what behavioural epoch has been used here, the same as the previous analyses, i.e. 100ms? how many datapoint is that in time? Given that CCA is essentially a correlation value, too few datapoints make it rather meaningless. If that's the case, I encourage using, let's say, one window combined of I and G until movement, and one window of movement and hold, such that they are both easier to interpret. Indeed low values of exec-exec in CC2 compared to Gallego et al, Nat Neurosci, 2020 might be a sign of a methodological error.</p></disp-quote><p>In the Methods described for CCA, we now have clarified that (lines 953 to 961):</p><p>“To provide an estimate of variability, we used a bootstrapping approach to CCA. From each of two data sets we randomly selected 20 trials involving each target object (totaling 80 trials) with replacement, clipped trajectory segments from each of those trials for 100 ms (100 points at 1 ms intervals) after the instruction onset, go cue, movement onset, or beginning of the final hold, and performed CCA as described above. (Note that because session 1 from monkey R included only 8 button trials (Table 1), we excluded this session from CCA analyses.) With 500 iterations, we obtained a distribution of the correlation coefficients (CCs) between the two data sets in each of the three dimensions of the aligned subspace, which permitted statistical comparisons.”</p><p>And in the Results we report that (lines 475 to 480):</p><p>“The highest values for MN:1/2 correlations were obtained for the Movement trajectory segments <inline-formula><alternatives><mml:math id="sa4m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.89</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.77</mml:mn><mml:mo>,</mml:mo><mml:mover><mml:mrow><mml:mi>C</mml:mi><mml:mi>C</mml:mi><mml:mn>3</mml:mn></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.61</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft60">\begin{document}$(\overline{C C 1}=0.89, \overline{C C 2}=0.77, \overline{C C 3}=0.61)$\end{document}</tex-math></alternatives></inline-formula>. These values indicate consistent relationships among the Movement neural trajectory segments representing the four different RGM movements from session to session, as would have been expected from previous studies (Gallego et al., 2018; Gallego et al., 2020; Safaie et al., 2023).”</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public Review):</bold></p><p>Summary:</p><p>In their study, Zhao et al. investigated the population activity of mirror neurons (MNs) in the premotor cortex of monkeys either executing or observing a task consisting of reaching to, grasping, and manipulating various objects. The authors proposed an innovative method for analyzing the population activity of MNs during both execution and observation trials. This method enabled to isolate the condition-dependent variance in neural data and to study its temporal evolution over the course of single trials. The method proposed by the authors consists of building a time series of &quot;instantaneous&quot; subspaces with single time step resolution, rather than a single subspace spanning the entire task duration. As these subspaces are computed on an instant time basis, projecting neural activity from a given task time into them results in latent trajectories that capture condition-dependent variance while minimizing the condition-independent one. The authors then analyzed the time evolution of these instantaneous subspaces and revealed that a progressive shift is present in subspaces of both execution and observation trials, with slower shifts during the grasping and manipulating phases compared to the initial preparation phase. Finally, they compared the instantaneous subspaces between execution and observation trials and observed that neural population activity did not traverse the same subspaces in these two conditions. However, they showed that these distinct neural representations can be aligned with Canonical Correlation Analysis, indicating dynamic similarities of neural data when executing and observing the task. The authors speculated that such similarities might facilitate the nervous system's ability to recognize actions performed by oneself or another individual.</p><p>Strengths:</p><p>Unlike other areas of the brain, the analysis of neural population dynamics of premotor cortex MNs is not well established. Furthermore, analyzing population activity recorded during non-trivial motor actions, distinct from the commonly used reaching tasks, serves as a valuable contribution to computational neuroscience. This study holds particular significance as it bridges both domains, shedding light on the temporal evolution of the shift in neural states when executing and observing actions. The results are moderately robust, and the proposed analytical method could potentially be used in other neuroscience contexts.</p><p>Weaknesses:</p><p>While the overall clarity is satisfactory, the paper falls short in providing a clear description of the mathematical formulas for the different methods used in the study.</p></disp-quote><p>We have added the various mathematical formulas in the Methods.</p><p>For Cumulative Separation (lines 864 to 871):</p><p>“To quantify the separation between the four trial-averaged trajectory segments involving the different objects in a given instantaneous subspace, we then calculated their cumulative separation (𝐶𝑆) as:<disp-formula id="sa4equ1"><alternatives><mml:math id="sa4m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>C</mml:mi><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:munder><mml:mi>D</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>∈</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:munder><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t4">\begin{document}$$\displaystyle  C S=\frac{1}{T} \sum_{t \in T} D(t)=\frac{1}{T} \sum_{t \in T} \sum_{i \neq j} d_{i j}(t)$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <italic>dij(t)</italic> is the 3-dimensional Euclidean distance between the <italic>ith</italic> and <italic>jth</italic> trajectories at time point 𝑡. We summed the 6 pairwise distances between the 4 trajectory segments across time points and normalized by the number of time points, 𝑇 = 100. The larger the 𝐶𝑆, the greater the separation of the trajectory segments.”</p><p>For principal angles (lines 877 to 884):</p><p><bold>“</bold>For example, given the 3-dimensional instantaneous subspace at the time of movement onset, <italic>WM</italic> and at any other time, <italic>Wi</italic>, we calculated their 3x3 inner product matrix and performed singular value decomposition to obtain:<disp-formula id="sa4equ2"><alternatives><mml:math id="sa4m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mi>C</mml:mi><mml:msubsup><mml:mi>P</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="t5">\begin{document}$$\displaystyle W_{M}^{T} W_{i}=P_{M} C P_{i}^{T}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where 3x3 matrices <italic>PM</italic> and <italic>WP</italic> define new manifold directions which successively minimize the 3 principal angles specific to the two subspaces being compared. The elements of diagonal matrix 𝐶 then are the ranked cosines of the principal angles, 𝜃𝑖 , ordered from smallest to largest:<disp-formula id="sa4equ3"><alternatives><mml:math id="sa4m15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mi>diag</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="t6">\begin{document}$$\displaystyle C=\operatorname{diag}\left(\cos \left(\theta_{1}\right), \cos \left(\theta_{2}\right), \cos \left(\theta_{3}\right)\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>For CCA (lines 945 to 952):</p><p>“CCA was performed as follows: The original latent dynamics, <italic>LA</italic> and <italic>LB</italic>, first were transformed and decomposed as <inline-formula><alternatives><mml:math id="sa4m16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft61">\begin{document}$L_{A}^{T}=Q_{A} R_{A}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="sa4m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft62">\begin{document}$L_{B}^{T}=Q_{B} R_{B}$\end{document}</tex-math></alternatives></inline-formula>. The first m = 3 column vectors of each 𝑄𝑖 provide an orthonormal basis for the column vectors of <inline-formula><alternatives><mml:math id="sa4m18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft63">\begin{document}$L_{i}^{T}$\end{document}</tex-math></alternatives></inline-formula> (where 𝑖 = 𝐴, 𝐵). Singular value decomposition on the inner product matrix of 𝑄𝐴 and 𝑄𝐵 then gives <inline-formula><alternatives><mml:math id="sa4m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>Q</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>U</mml:mi><mml:mi>S</mml:mi><mml:msup><mml:mi>V</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft64">\begin{document}$Q_{A}^{T} Q_{B}=U S V^{T}$\end{document}</tex-math></alternatives></inline-formula>, and new manifold directions that maximize pairwise correlations are provided by <inline-formula><alternatives><mml:math id="sa4m20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mi>U</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft65">\begin{document}$M_{A}=R_{A}^{-1} U$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="sa4m21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>R</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mi>V</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft66">\begin{document}$M_{R}=R_{R}^{-1} V$\end{document}</tex-math></alternatives></inline-formula>. We then projected the original latent dynamics into the new, common subspace: <inline-formula><alternatives><mml:math id="sa4m22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>L</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mspace width="1em"/><mml:msubsup><mml:mrow><mml:mover><mml:mi>L</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math><tex-math id="inft67">\begin{document}$\tilde{L}_{A}^{T}=L_{A}^{T} M_{A} ; \quad \tilde{L}_{B}^{T}=L_{B}^{T} M_{B}$\end{document}</tex-math></alternatives></inline-formula>. Pairwise correlation coefficients between the aligned latent dynamics sorted from largest to smallest then are given by the elements of the diagonal matrix <inline-formula><alternatives><mml:math id="sa4m23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>L</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>A</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mrow><mml:mover><mml:mi>L</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math><tex-math id="inft68">\begin{document}$S=\tilde{L}_{A} \tilde{L}_{B}^{T}$\end{document}</tex-math></alternatives></inline-formula>.”</p><disp-quote content-type="editor-comment"><p>Moreover, it was not immediately clear why the authors did not consider a (relatively) straightforward metric to quantity the progressive shift of the instantaneous subspaces, such as computing the angle between consecutive subspaces, rather than choosing a (in my opinion) more cumbersome metric based on classification of trajectory segments representing different movements.</p></disp-quote><p>Point taken. We now have calculated the principal angles as a function of time and present them as a new section of the Results including new figure 4 (lines 237 to 293).</p><p>“Instantaneous subspaces shift progressively during both execution and observation</p><p>We identified an instantaneous subspace at each one millisecond time step of RGM trials. At each time step, we applied PCA to the 4 instantaneous neural states (i.e. the 4 points on the neural trajectories representing trials involving the 4 different objects each averaged across 20 trials per object, totaling 80 trials), yielding a 3-dimensional subspace at that time (see Methods). Note that because these 3-dimensional subspaces are essentially instantaneous, they capture the condition-dependent variation in neural states, but not the common, condition-independent variation. To examine the temporal progression of these instantaneous subspaces, we then calculated the principal angles between each 80-trial instantaneous subspace and the instantaneous subspaces averaged across all trials at four behavioral time points that could be readily defined across trials, sessions, and monkeys: the onset of the instruction (I), the go cue (G), the movement onset (M), and the beginning of the final hold (H). This process was repeated 10 times with replacement to assess the variability of the principal angles. The closer the principal angles are to 0°, the closer the two subspaces are to being identical; the closer to 90°, the closer the two subspaces are to being orthogonal.</p><p>Figure 4A-D illustrate the temporal progression of the first principal angle of the mirror neuron population in the three sessions (red, green, and blue) from monkey R during execution trials. As illustrated in Figure 4 – figure supplement 1 (see also the related Methods), in each session all three principal angles, each of which could range from 0° to 90°, tended to follow a similar time course. In the Results we therefore illustrate only the first (i.e. smallest) principal angle. Solid traces represent the mean across 10-fold cross validation using the 80-trial subsets of all the available trials; shading indicates ±1 standard deviation. As would be expected, the instantaneous subspace using 80 trials approaches the subspace using all trials at each of the four selected times—I, G, M, and H—indicated by the relatively narrow trough dipping toward 0°. Of greater interest are the slower changes in the first principal angle in between these four time points. Figure 4A shows that after instruction onset (I) the instantaneous subspace shifted quickly away from the subspace at time I, indicated by a rapid increase in principal angle to levels not much lower than what might be expected by chance alone (horizontal dashed line). In contrast, throughout the remainder of the instruction and delay epochs (from I to G), Figure 4B and C show that the 80-trial instantaneous subspace shifted gradually and concurrently, not sequentially, toward the all-trial subspaces that would be reached at the end of the delay period (G) and then at the onset of movement (M), indicated by the progressive decreases in principal angle. As shown by Figure 4D, shifting toward the H subspace did not begin until the movement onset (M). To summarize, these changes in principal angles indicate that after shifting briefly toward the subspace present at time the instruction appeared (I), the instantaneous subspace shifted progressively throughout the instruction and delay epochs toward the subspace that would be reached at the time of the go cue (G), then further toward that at the time of movement onset (M), and only thereafter shifted toward the instantaneous subspace that would be present at the time of the hold (H).</p><p>Figure 4E-H show the progression of the first principal angle of the mirror neuron population during observation trials. Overall, the temporal progression of the MN instantaneous subspace during observation was similar to that found during execution, particularly around times I and H. The decrease in principal angle relative to the G and M instantaneous subspaces during the delay epoch was less pronounced during observation than during execution. Nevertheless, these findings support the hypothesis that the condition-dependent subspace of PM MNs shifts progressively over the time course of RGM trials during both execution and observation, as illustrated schematically in Figure 1A.</p><p>We also examined the temporal progression of the instantaneous subspace of AE neurons. As would be expected given that AE neurons were not modulated significantly during observation trials, in the observation context AE populations had no gradual changes in principal angle (Figure 4 – figure supplement 3). During execution, however, Figure 4I-L show that the AE populations had a pattern of gradual decrease in principal angle similar to that found in the MN population (Figure 4A-D). After the instruction onset, the instantaneous subspace shifted quickly away from that present at time I and progressed gradually toward that present at times G and M, only shifting toward that present at time H after movement onset. As for the PM MN populations, the condition-dependent subspace of the PM AE populations shifted progressively over the time course of execution RGM trials.”</p><p>The related Methods are now described in subsection “Subspace Comparisons—Principal Angles”</p><disp-quote content-type="editor-comment"><p>Specific comments:</p><p>In the methods, it is stated that instantaneous subspaces are found with 3 PCs. Why does it say 2 here?</p></disp-quote><p>We now have clarified. (lines 295 to 310):</p><p>“The progressive changes in principal angles do not capture another important aspect of condition-dependent neural activity. The neural trajectories during trials involving different objects separated increasingly as trials progressed in time. To illustrate this increasing separation, we clipped 100 ms segments of high-dimensional MN population trial-averaged trajectories beginning at times I, G, M, and H, for trials involving each of the four objects. We then projected the set of four object-specific trajectory segments clipped at each time into each of the four instantaneous 3D subspaces at times I, G, M, and H. This process was repeated separately for execution trials and for observation trials.</p><p>For visualization, we projected these trial-averaged trajectory segments from an example session into the PC1 vs PC2 planes (which consistently captured &gt; 70% of the variance) of the I, G, M, or H instantaneous 3D subspaces. In Figure 5, the trajectory segments for each of the four objects (sphere – purple, button – cyan, coaxial cylinder – magenta, perpendicular cylinder – yellow) sampled at different times (rows) have been projected into each of the four instantaneous subspaces defined at different times (columns). Rather than appearing knotted as in Figure 3, these short trajectory segments are distinct when projected into each instantaneous subspace.”</p><p>And in the legend for Figure 5 we now clarify that:</p><p>“Each set of these four segments then was projected into the PC1 vs PC2 plane of the instantaneous 3D subspace present at four different times (columns: I, G, M, H).”</p><disp-quote content-type="editor-comment"><p>Another doubt on how instantaneous subspaces are computed: in the methods you state that you apply PCA on trial-averaged activity at each 50ms time step. From the next sentence, I gather that you apply PCA on an Nx4 data matrix (N being the number of neurons, and 4 being the trial-averaged activity of the four objects) every 50 ms. Is this right? It would help to explicitly specify the dimensions of the data matrix that goes into PCA computation.</p></disp-quote><p>We apologize for this confusion. Although the LSTM decoding was performed in 50 ms time steps, the instantaneous subspaces were calculated at 1 ms intervals. In the Methods we now have clarified (lines 849 to 759):</p><p>“Instantaneous subspace identification</p><p>Instantaneous neural subspaces were identified at 1 ms intervals. At each 1 ms time step, the N-dimensional neural firing rates from trials involving the four different objects— sphere, button, coaxial cylinder, and perpendicular cylinder—were averaged separately, providing four points in the N-dimensional space representing the average neural activity for trials involving the different objects at that time step. PCA then was performed on these four points. Because three dimensions capture all the variance of four points, three principal component dimensions fully defined each instantaneous subspace. Each instantaneous 3D subspace can be considered a filter described by a matrix, W, that can project high-dimensional neural activity into a low-dimensional subspace, with the time series of instantaneous subspaces, W_i, forming a time series of filters (Figure 1B).”</p><disp-quote content-type="editor-comment"><p>It would help to include some equations in the methods section related to the LSTM decoding. Just to make sure I understood correctly: after having identified the instantaneous subspaces (every 50 ms), you projected the Instruction, Go, Movement, and Holding segments from individual trials (each containing 100 samples, since they are sampled from a 100ms window) onto each instantaneous subspace. So you have four trajectories for each subspace. In the methods, it is stated that a single LSTM classifier is trained for each subspace. Do you also have a separate classifier for each trajectory segment? What is used as input to the classifier? Each trajectory segment should be a 100x3 matrix once projected in an instantaneous subspace. Is that what (each of) the LSTMs take as input? And lastly, what is the LSTM trained to predict exactly? Just a label indicating the type of object that was manipulated in that trial? I apologize if I overlooked any detail, but I believe a clearer explanation of the LSTM, preferably with mathematical formulas, would greatly help readers understand this section.</p></disp-quote><p>LSTM decoding is not readily described with a set of equations. However, we have expanded our description to provide the information requested (lines 910 to 937):</p><p>“Decodable information—LSTM</p><p>As illustrated schematically in Figure 1B, the same segment of high-dimensional neural activity projected into different instantaneous subspaces can generate low-dimensional trajectories of varying separation. The degree of separation among the projected trajectory segments will depend, not only on their separation at the time when the segments were clipped, but also on the similarity of the subspaces into which the trajectory segments are projected. To quantify the combined effects of trajectory separation and projection into different subspaces, we projected high-dimensional neural trajectory segments (each including 100 points at 1 ms intervals) from successful trials involving each of the four different target objects into time series of 3-dimensional instantaneous subspaces at 50 ms intervals. In each of these instantaneous subspaces, the neural trajectory segment from each trial thus became a 100 point x 3 dimensional matrix. For each instantaneous subspace in the time series, we then trained a separate long short-term memory (LSTM, (Hochreiter and Schmidhuber, 1997)) classifier to attribute each of the neural trajectories from individual trials to one of the four target object labels: sphere, button, coaxial cylinder, or perpendicular cylinder. Using MATLAB’s Deep Learning Toolbox, each LSTM classifier had 3 inputs (instantaneous subspace dimensions), 20 hidden units in the bidirectional LSTM layer, and a softmax layer preceding the classification layer which had 4 output classes (target objects). The total number of successful trials available in each session for each object is given in Table 1. To avoid bias based on the total number of successful trials, we used the minimum number of successful trials across the four objects in each session, selecting that number from the total available randomly with replacement. Each LSTM classifier was trained with MATLAB’s adaptive moment estimation (Adam) optimizer on 40% of the selected trials, and the remaining 60% were decoded by the trained classifier. The success of this decoding was used as an estimate of classification accuracy from 0 (no correct classifications) to 1 (100% correct classifications). This process was repeated 10 times and the mean ± standard deviation across the 10 folds was reported as the classification accuracy at that time. Classification accuracy of trials projected into each instantaneous subspace at 50 ms intervals was plotted as a function of trial time.”</p><disp-quote content-type="editor-comment"><p><bold>Recommendations for the authors:</bold></p><p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p><p>Here are some more specific comments.</p><p>Abstract. Line 41. &quot;same action&quot; is not justified, there is plenty of evidence showing that the action does not need to be the same (or it has not even to be an action), rephrasing or substituting with &quot;similar&quot; is necessary, especially in the light of the subsequent sentence (which is totally correct).</p></disp-quote><p>Thank you for pointing this out. As recommended, we have changed “same” to “similar” (lines 40 to 41):</p><p>“Many neurons in the premotor cortex show firing rate modulation whether the subject performs an action or observes another individual performing a similar action.”</p><disp-quote content-type="editor-comment"><p>Introduction. A relevant, missing reference in the otherwise exhaustive introduction is Albertini et al. 2021 J Neurophysiol, showing that neural dynamics and similarities between biological and nonbiological movements in premotor areas are greater than those between the same executed and observed movements.</p></disp-quote><p>Thank you for pointing out this important finding. After revision, we felt it was now cited most appropriately in the revised Discussion as follows (lines 730 to 736):</p><p>“Alternatively, given that observation of another individual can be considered a form of social interaction, PM MN population activity during action observation, rather than representing movements made by another individual similar to one’s own movements, instead may represent different movements one might execute oneself in response to those made by another individual (Ninomiya et al., 2020; Bonini et al., 2022; Ferrucci et al., 2022; Pomper et al., 2023). This possibility is consistent with the finding that the neural dynamics of PM MN populations are more similar during observation of biological versus non-biological movements than during execution versus observation (Albertini et al., 2021).&quot;</p><disp-quote content-type="editor-comment"><p>In Line 85, the sentence about Papadourakis and Raos 2019 has to be generalized to PMv, as they show that the proportion of congruent MNs is at chance in both PMd and PMv.</p></disp-quote><p>Point taken. We have rephrased this sentence as follows (lines 88 to 89):</p><p>“And in both PMv and PMd, the proportion of congruent neurons may not be different from that expected by chance alone (Papadourakis and Raos, 2019).”</p><disp-quote content-type="editor-comment"><p>Lines 122-132. The initial sentence was unclear to me at first glance. I was wondering how subspaces could be &quot;at other times over the course of the trial&quot; if they are instantaneous. I could imagine that the subspaces referred to corresponding behavioral intervals of execution and observation conditions (and this may be what they will later call &quot;condition dependent&quot; activity), but nevertheless, they could hardly be understood as &quot;instantaneous&quot;. I grasped the author's idea only when reading the results, with the statement &quot;no-time dependent variance is captured&quot;. The idea is to take a static snapshot of the evolution of population activity at each checkpoint (i.e. I, G, M, and H): I suggest clarifying this point immediately in the introduction to improve readability.</p></disp-quote><p>We have clarified this point by adding two paragraphs to the Introduction first defining condition independent versus condition-dependent variance and then explaining the use of instantaneous subspaces (lines 125 to 153):</p><p>“A relevant but often overlooked aspect of such dynamics in neuron populations active during both execution and observation has to do with the distinction between condition independent and condition-dependent variation in neuronal activity (Kaufman et al., 2016; Rouse and Schieber, 2018). The variance in neural activity averaged across all the conditions in a given task context is condition-independent. For example, in an 8-direction center-out reaching task, averaging a unit’s firing rate as a function of time across all 8 directions may show an initially low firing rate that increases prior to movement onset, peaks during the movement, and then declines during the final hold, irrespective of the movement direction. Subtracting this condition-independent activity from the unit’s firing rate during each trial gives the remaining variance, and averaging separately across trials in each of the 8 directions then averages out noise variance, leaving the condition-dependent variance that represents the unit’s modulation among the 8 directions (conditions). Alternatively, condition-independent, condition dependent, and noise variance can be partitioned through demixed principal component analysis (Kobak et al., 2016; Gallego et al., 2018). The extent to which neural dynamics occur in a subspace shared by execution and observation versus subspaces unique to execution or observation may differ for the condition-independent versus condition-dependent partitions of neural activity. Here, we tested the hypothesis that the condition-dependent activity of PM mirror neuron populations progresses through distinct subspaces during execution versus observation, which would indicate distinct patterns of co-modulation amongst mirror neurons during execution versus observation.</p><p>Because of the complexity of condition-dependent neural trajectories for movements involving the hand, we developed a novel approach. Rather than examining trajectories over the entire time course of behavioral trials, we identified time series of instantaneous PM mirror neuron subspaces covering the time course of behavioral trials. We identified separate time series for execution trials and for observation trials, both involving four different reach-graspmanipulation (RGM) movements. Given that each subspace in these time series is instantaneous (a snapshot in time), it captures condition-dependent variance in the neural activity among the four RGM movements while minimizing condition-independent (time dependent) variance.”</p><disp-quote content-type="editor-comment"><p>Results.</p><p>Regarding the execution-observation alignment, as explained in my initial comment, it does not sound convincing. Applying a CCA to align EXE and OBS activities (which the authors had just shown being essentially not aligned), even separately for each epoch segment (line 396), seems to be a trick to show that they nonetheless share some similarities. Couldn't this be applied to any pairs of differently encoded conditions to create some sort of artificial link between them? Is the similarity in the neural data or rather in the method used to realign them?</p></disp-quote><p>CCA would not align arbitrary sets of neural data. The similarity is in the data, not in the method. For example, in an 8-direction center-out task, the neural representation of movement to the 45° target is between the neural representations of the 0° and the 90° targets. If the same is true in a second data set, then CCA will give high correlation coefficients. But if in the second data set the neural representation of the 45° target is between the 135° and 180° targets, CCA will give low correlation coefficients.</p><disp-quote content-type="editor-comment"><p>In the end, what does this tell us about the brain?</p></disp-quote><p>In the Introduction we now clarify that (lines 166 to 170):</p><p>“Such alignment would indicate that the relationships among the trajectory segments in the execution subspace are similar to the relationships among the trajectory segments in the observation subspace, indicating a corresponding structure in the latent dynamic representations of execution and observation movements by the same PM MN population.”</p><p>And in the Results (lines 449 to 455):</p><p>“For example, the trajectories of PMd+M1 neuron populations recorded from two different monkeys during center-out reaching movements could be aligned well (Safaie et al., 2023). CCA showed, for example, that in both brains the neural trajectory for the movement to the target at 0° was closer to the trajectory for movement to the target at 45° than to the trajectory for the movement to the target at 180°. Relationships among these latent dynamic representations of the eight movements thus were similar even though the neural populations were recorded from two different monkeys.”</p><p>In relation to Figure 8 (lines 461 to 467)</p><p>“But when both sets of trajectory segments are projected into another common subspace identified with CCA, as shown in Figure 8B, a similar relationship among the neural representations of the four movements during execution and observation is revealed. In both behavioral contexts the neural representation of movements involving the sphere (purple) is now closest to the representation of movements involving the coaxial cylinder (magenta) and farthest from that of movements involving the button (cyan). The two sets of trajectory segments are more or less “aligned.”</p><p>And in the Discussion (lines 665 to 674):</p><p>“Corresponding neural representations of action execution and observation during task epochs with higher neural firing rates have been described previously in PMd MNs and in PMv MNs using representational similarity analysis RSA (Papadourakis and Raos, 2019). And during force production in eight different directions, neural trajectories of PMd neurons draw similar “clocks” during execution, cooperative execution, and passive observation (Pezzulo et al., 2022). Likewise in the present study, despite execution and observation trajectories progressing through largely distinct subspaces, in all three monkeys execution and observation trajectory segments showed some degree of alignment, particularly the Movement and Hold segments (Figure 12A), indicating similar relationships among the latent dynamic representations of the four RGM movements during execution and observation.”</p><disp-quote content-type="editor-comment"><p>Concerning the discussion, I would like to reconsider it after having seen the authors' response to the comments above and to my general concern about the relevance of the findings from the neurophysiological point of view.</p></disp-quote><p>Certainly, please do.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p><p>Here are a few issues that I want to bring to the authors' attention (in no particular order):</p><p>• I am not clear on what is meant by &quot;condition-dependent&quot;. Is the condition exec vs obs, or the object types?</p></disp-quote><p>In the Introduction, we now clarify (lines 125 to 144):</p><p>“A relevant but often overlooked aspect of such dynamics in neuron populations active during both execution and observation has to do with the distinction between condition independent and condition-dependent variation in neuronal activity (Kaufman et al., 2016; Rouse and Schieber, 2018). The variance in neural activity averaged across all the conditions in a given task context is condition-independent. For example, in an 8-direction center-out reaching task, averaging a unit’s firing rate as a function of time across all 8 directions may show an initially low firing rate that increases prior to movement onset, peaks during the movement, and then declines during the final hold, irrespective of the movement direction. Subtracting this condition-independent activity from the unit’s firing rate during each trial gives the remaining variance, and averaging separately across trials in each of the 8 directions then averages out noise variance, leaving the condition-dependent variance that represents the unit’s modulation among the 8 directions (conditions). Alternatively, condition-independent, condition dependent, and noise variance can be partitioned through demixed principal component analysis (Kobak et al., 2016; Gallego et al., 2018). The extent to which neural dynamics occur in a subspace shared by execution and observation versus subspaces unique to execution or observation may differ for the condition-independent versus condition-dependent partitions of neural activity. Here, we tested the hypothesis that the condition-dependent activity of PM mirror neuron populations progresses through distinct subspaces during execution versus observation, which would indicate distinct patterns of co-modulation amongst mirror neurons during execution versus observation.”</p><p>And in the Results, we have added a new Figure 3 to illustrate condition-independent versus conditiondependent activity using an example from the present data sets (lines 208 to 236):</p><p>“Condition-dependent versus condition-independent neural activity in PM MNs</p><p>Whereas a large fraction of condition-dependent neural variance during reaching movements without grasping can be captured in a two-dimensional subspace (Churchland et al., 2012; Ames et al., 2014), condition-dependent activity in movements that involve grasping is more complex (Suresh et al., 2020). In part, this may reflect the greater complexity of controlling the 24 degrees of freedom in the hand and wrist as compared to the 4 degrees of freedom in the elbow and shoulder (Sobinov and Bensmaia, 2021). Figure 3 illustrates this complexity in a PM MN population during the present RGM movements. Here, PCA was performed on the activity of a PM MN population across the entire time course of execution trials involving all four objects. The colored traces in Figure 3A show neural trajectories averaged separately across trials involving each of the four objects and then projected into the PC1 vs PC2 plane of the total neural space. Most of the variance in these four trajectories is comprised of a shared rotational component. The black trajectory, obtained by averaging trajectories from trials involving all four objects together, represents this condition-independent (i.e. independent of the object involved) activity. The condition-dependent (i.e. dependent on which object was involved) variation in activity is reflected by the variation in the colored trajectories around the black trajectory. The condition-dependent portions can be isolated by subtracting the black trajectory from each of the colored trajectories. The resulting four condition dependent trajectories have been projected into the PC1 vs PC2 plane of their own common subspace in Figure 3B. Rather than exhibiting a simple rotational motif, these trajectories appear knotted. To better understand how these complex, condition-dependent trajectories progress over the time course of RGM trials, we chose to examine time series of instantaneous subspaces.”</p><disp-quote content-type="editor-comment"><p>While there is an emphasis on the higher complexity of manipulating objects compared to just reaching movements in the Abstract, the majority of the analysis relates to the instruction, movement initiation, and grasp, and there is no specific analyses looking at manipulation and how those presumably more complex dynamics compare to the reaching dynamics, and how they differ from reaching in the mirror neurons.</p></disp-quote><p>We have clarified that (lines 178 to 187):</p><p>“Because we chose to study relatively naturalistic movements, the reach, grasp, and manipulation components were not performed separately, but rather in a continuous fluid motion during the movement epoch of the task sequence (Figure 2B). In previous studies involving a version of this task without separate instruction and delay epochs, we have shown that joint kinematics, EMG activity, and neuron activity in the primary motor cortex, all vary throughout the movement epoch in relation to both reach location and object grasped, with location predominating early in the movement epoch and object predominating later (Rouse and Schieber, 2015, 2016a, b). The present task, however, did not dissociate the reach, the hand shape used to grasp the object, and the manipulation performed on the object.”</p><disp-quote content-type="editor-comment"><p>• The analysis in Fig3C,D is interesting, however, in my opinion, requires control. For instance, what would these values look like if you projected the segments to a subspace defined by the activity during the entire length of the trial, or if you projected the activity during intertrials, just to get a sense of how meaningful these values are?</p></disp-quote><p>This material is now presented in Figure 5 – figure supplement 1. In the legend to this figure supplement, we have clarified that (lines 327 to 328):</p><p>“CS values, which we use only to characterize the phenomenon of trajectory separation,….”</p><disp-quote content-type="editor-comment"><p>• MN is used (#85) before definition (#91). Similar for RGM, I believe.</p></disp-quote><p>Thanks for catching this problem. We have now defined these abbreviations at first use as follows:</p><p>In lines 89 to 92:</p><p>“Though many authors apply the term mirror neurons strictly to highly congruent neurons, here we will refer to all neurons modulated during both contexts—execution and observation—as mirror neurons (MNs).”</p><p>And in lines 148 to 150:</p><p>We identified separate time series for execution trials and for observation trials, both involving four different reach-grasp-manipulation (RGM) movements.”</p><disp-quote content-type="editor-comment"><p>• I believe in the Intro when presenting the three hypotheses, there is a First, and a Third, but no Second.</p></disp-quote><p>We have revised this part of the Introduction without numbering our hypotheses as follows (lines 145 to 173):</p><p>“Because of the complexity of condition-dependent neural trajectories for movements involving the hand, we developed a novel approach. Rather than examining trajectories over the entire time course of behavioral trials, we identified time series of instantaneous PM mirror neuron subspaces covering the time course of behavioral trials. We identified separate time series for execution trials and for observation trials, both involving four different reach-graspmanipulation (RGM) movements. Given that each subspace in these time series is instantaneous (a snapshot in time), it captures condition-dependent variance in the neural activity among the four RGM movements while minimizing condition-independent (time dependent) variance.</p><p>We then tested the hypothesis that the condition-dependent subspace shifts progressively over the time course of behavioral trials (Figure 1A) by calculating the principal angles between four selected instantaneous subspaces that occurred at times easily defined in each behavioral trial—instruction onset (I), go cue (G), movement onset (M), and the beginning of the final hold (H)—and every other instantaneous subspace in the time series. Initial analyses showed that condition-dependent neural trajectories for the four RGM movements tended to separate increasingly over the course of behavioral trials. We therefore additionally examined the combined effects of (i) the progressively shifting subspaces and (ii) the increasing trajectory separation, by decoding neural trajectory segments sampled for 100 msec after times I, G, M, and H and projected into the time series of instantaneous subspaces (Figure 1B).</p><p>Finally, we used canonical correlation to ask whether the prevalent patterns of mirror neuron co-modulation showed similar relationships among the four RGM movements during execution and observation (Figure 1C). Such alignment would indicate that the relationships among the trajectory segments in the execution subspace are similar to the relationships among the trajectory segments in the observation subspace, indicating a corresponding structure in the latent dynamic representations of execution and observation movements by the same PM MN population. And finally, because we previously have found that during action execution the activity of PM mirror neurons tends to lead that of non-mirror neurons which are active only during action execution (AE neurons) (Mazurek and Schieber, 2019), we performed parallel analyses of the instantaneous state space of PM AE neurons.”</p><disp-quote content-type="editor-comment"><p>• The use of the term 'instantaneous subspaces' in the abstract confused me initially, as I wasn't sure what it meant. It might be a good idea to define or rephrase it.</p></disp-quote><p>In the Abstract we now state (lines 51 to 52):</p><p>“Rather than following neural trajectories in subspaces that contain their entire time course, we identified time series of instantaneous subspaces …”</p><p>And in the Introduction, we have clarified (lines 145 to 153):</p><p>“Because of the complexity of condition-dependent neural trajectories for movements involving the hand, we developed a novel approach. Rather than examining trajectories over the entire time course of behavioral trials, we identified time series of instantaneous PM mirror neuron subspaces covering the time course of behavioral trials. We identified separate time series for execution trials and for observation trials, both involving four different reach-graspmanipulation (RGM) movements. Given that each subspace in these time series is instantaneous (a snapshot in time), it captures condition-dependent variance in the neural activity among the four RGM movements while minimizing condition-independent (time dependent) variance.”</p><p>And in the Methods (lines 849 to 859):</p><p>“Instantaneous subspace identification</p><p>Instantaneous neural subspaces were identified at 1 ms intervals. At each 1 ms time step, the N-dimensional neural firing rates from trials involving the four different objects— sphere, button, coaxial cylinder, and perpendicular cylinder—were averaged separately, providing four points in the N-dimensional space representing the average neural activity for trials involving the different objects at that time step. PCA then was performed on these four points. Because three dimensions capture all the variance of four points, three principal component dimensions fully defined each instantaneous subspace. Each instantaneous 3D subspace can be considered a filter described by a matrix, 𝑊, that can project high-dimensional neural activity into a low-dimensional subspace, with the time series of instantaneous subspaces, 𝑊𝑖, forming a time series of filters (Figure 1B).”</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Recommendations For The Authors):</bold></p><p>(1) Page 4, lines 127-131. In the introduction, it was not immediately clear to me what you meant by 'separation' and 'decoding' of the projected neural activity. You do mention that you are separating/decoding trajectory segments representing different movements at the end of this paragraph, but at this point of the paper it was not very clear to me what those different movements were (I only understood that after reading the results section). I suggest briefly expanding on these concepts here.</p></disp-quote><p>To clarify these points in the Introduction, we have expanded exposition of these concepts (lines 145 to 163):</p><p>“Because of the complexity of condition-dependent neural trajectories for movements involving the hand, we developed a novel approach. Rather than examining trajectories over the entire time course of behavioral trials, we identified time series of instantaneous PM mirror neuron subspaces covering the time course of behavioral trials. We identified separate time series for execution trials and for observation trials, both involving four different reach-graspmanipulation (RGM) movements. Given that each subspace in these time series is instantaneous (a snapshot in time), it captures condition-dependent variance in the neural activity among the four RGM movements while minimizing condition-independent (time dependent) variance.</p><p>We then tested the hypothesis that the condition-dependent subspace shifts progressively over the time course of behavioral trials (Figure 1A) by calculating the principal angles between four selected instantaneous subspaces that occurred at times easily defined in each behavioral trial—instruction onset (I), go cue (G), movement onset (M), and the beginning of the final hold (H)—and every other instantaneous subspace in the time series. Initial analyses showed that condition-dependent neural trajectories for the four RGM movements tended to separate increasingly over the course of behavioral trials. We therefore additionally examined the combined effects of (i) the progressively shifting subspaces and (ii) the increasing trajectory separation, by decoding neural trajectory segments sampled for 100 msec after times I, G, M, and H and projected into the time series of instantaneous subspaces (Figure 1B).”</p><disp-quote content-type="editor-comment"><p>(2) Page 6, line 175. In the methods, it is stated that instantaneous subspaces are found with 3 PCs. Why does it say 2 here?</p></disp-quote><p>Thank you for noticing this discrepancy. In the Methods, we have clarified that the instantaneous subspaces are 3-dimensional (see our reply to the next comment), but in Figure 5 (previously Figure 3), for purposes of visualization, we are projecting trajectory segments into the PC1-PC2 plane (lines 295 to 308):</p><p>“The progressive changes in principal angles do not capture another important aspect of condition-dependent neural activity. The neural trajectories during trials involving different objects separated increasingly as trials progressed in time. To illustrate this increasing separation, we clipped 100 ms segments of high-dimensional MN population trial-averaged trajectories beginning at times I, G, M, and H, for trials involving each of the four objects. We then projected the set of four object-specific trajectory segments clipped at each time into each of the four instantaneous 3D subspaces at times I, G, M, and H. This process was repeated separately for execution trials and for observation trials.</p><p>For visualization, we projected these trial-averaged trajectory segments from an example session into the PC1 vs PC2 planes (which consistently captured &gt; 70% of the variance) of the I, G, M, or H instantaneous 3D subspaces. In Figure 5, the trajectory segments for each of the four objects (sphere – purple, button – cyan, coaxial cylinder – magenta, perpendicular cylinder – yellow) sampled at different times (rows) have been projected into each of the four instantaneous subspaces defined at different times (columns).”</p><p>And in the legend for Figure 5 we now clarify that:</p><p>“Each set of these four segments then was projected into the PC1 vs PC2 plane of the instantaneous 3D subspace present at four different times (columns: I, G, M, H).”</p><disp-quote content-type="editor-comment"><p>Another doubt on how instantaneous subspaces are computed: in the methods you state that you apply PCA on trial-averaged activity at each 50ms time step. From the next sentence, I gather that you apply PCA on an Nx4 data matrix (N being the number of neurons, and 4 being the trial-averaged activity of the four objects) every 50 ms. Is this right? It would help to explicitly specify the dimensions of the data matrix that goes into PCA computation.</p></disp-quote><p>Thank you for catching an error: The instantaneous subspaces were computed at 1 ms intervals. (It is the LSTM decoding that was done in 50 ms time steps). We have clarified how the instantaneous subspaces were computed in the Methods (lines 849 to 859):</p><p>“Instantaneous subspace identification</p><p>Instantaneous neural subspaces were identified at 1 ms intervals. At each 1 ms time step, the N-dimensional neural firing rates from trials involving the four different objects— sphere, button, coaxial cylinder, and perpendicular cylinder—were averaged separately, providing four points in the N-dimensional space representing the average neural activity for trials involving the different objects at that time step. PCA then was performed on these four points. Because three dimensions capture all the variance of four points, three principal component dimensions fully defined each instantaneous subspace. Each instantaneous 3D subspace can be considered a filter described by a matrix, 𝑊, that can project high-dimensional neural activity into a low-dimensional subspace, with the time series of instantaneous subspaces, 𝑊𝑖, forming a time series of filters (Figure 1B).”</p><disp-quote content-type="editor-comment"><p>(3) Page 7, line 210-212. I am not sure if I missed it in the discussion, but have you speculated on why the greatest separation in observation trials was observed during the holding phase while in execution trials during the movement phase?</p></disp-quote><p>This was a consistent finding, and we therefore point it out as a difference between execution and observation. Of course, this reflects greater condition-dependent variance in the PM MN population in the movement epoch than in the hold epoch during execution, whereas the reverse is true during observation. We have no clear speculation as to why this occurs, however.</p><disp-quote content-type="editor-comment"><p>(4) Figure 3. Add a legend with color scheme for each object in panels A and B. Also, please specify what metric is represented by the colorbar of panels C, D, E, F (write it down next to the colorbar itself and not just in the caption).</p></disp-quote><p>This is now Figure 5. We have added a color legend for A and B. Panels C, D, E, and F, now have been moved to Figure 5 – figure supplement 1, where we have indicated that the colorbar represents cumulative separation.</p><disp-quote content-type="editor-comment"><p>(5) Page 9, line 228. I found the description of this decoding analysis a bit confusing initially (and perhaps still do), this should be clarified.</p></disp-quote><p>We have clarified our decoding analysis in the Methods (lines 910 to 937):</p><p>“Decodable information—LSTM</p><p>As illustrated schematically in Figure 1B, the same segment of high-dimensional neural activity projected into different instantaneous subspaces can generate low-dimensional trajectories of varying separation. The degree of separation among the projected trajectory segments will depend, not only on their separation at the time when the segments were clipped, but also on the similarity of the subspaces into which the trajectory segments are projected. To quantify the combined effects of trajectory separation and projection into different subspaces, we projected high-dimensional neural trajectory segments (each including 100 points at 1 ms intervals) from successful trials involving each of the four different target objects into time series of 3-dimensional instantaneous subspaces at 50 ms intervals. In each of these instantaneous subspaces, the neural trajectory segment from each trial thus became a 100 point x 3 dimensional matrix. For each instantaneous subspace in the time series, we then trained a separate long short-term memory (LSTM, (Hochreiter and Schmidhuber, 1997)) classifier to attribute each of the neural trajectories from individual trials to one of the four target object labels: sphere, button, coaxial cylinder, or perpendicular cylinder. Using MATLAB’s Deep Learning Toolbox, each LSTM classifier had 3 inputs (instantaneous subspace dimensions), 20 hidden units in the bidirectional LSTM layer, and a softmax layer preceding the classification layer which had 4 output classes (target objects). The total number of successful trials available in each session for each object is given in Table 1. To avoid bias based on the total number of successful trials, we used the minimum number of successful trials across the four objects in each session, selecting that number from the total available randomly with replacement. Each LSTM classifier was trained with MATLAB’s adaptive moment estimation (Adam) optimizer on 40% of the selected trials, and the remaining 60% were decoded by the trained classifier. The success of this decoding was used as an estimate of classification accuracy from 0 (no correct classifications) to 1 (100% correct classifications). This process was repeated 10 times and the mean ± standard deviation across the 10 folds was reported as the classification accuracy at that time. Classification accuracy of trials projected into each instantaneous subspace at 50 ms intervals was plotted as a function of trial time.”</p><disp-quote content-type="editor-comment"><p>(6) Page 9, line 268. This might be trivial, but can you speculate on why the accuracy for Instruction segments had a lower peak compared to the rest of the segments? Is it because there is less 'distinct' information embedded in neural data about the type of object manipulated until you are actually reaching toward it or holding it? The latter seems straightforward, but the former not so much.</p></disp-quote><p>Thank you for asking this question. We have added the following speculations (lines 592 to 604):</p><p>“Short bursts of “signal” related discharge are known to occur in a substantial fraction of PMd neurons beginning at latencies of ~60 ms following an instructional stimulus (Weinrich et al., 1984; Cisek and Kalaska, 2004). Here we found that the instantaneous subspace shifted briefly toward the subspace present at the time of instruction onset (I), similarly during execution and observation. This brief trough in principal angle (Figure 4A) and the corresponding peak in classification accuracy (Figure 7A) in part may reflect smoothing of firing rates with a 50 ms Gaussian kernel. We speculate, however, that the early rise of this peak at the time of instruction onset also reflects the anticipatory activity often seen in PMd neurons in expectation of an instruction, which may not be entirely non-specific, but rather may position the neural population to receive one of a limited set of potential instructions (Mauritz and Wise, 1986). We attribute the relatively low amplitude of peak classification accuracy for Instruction trajectory segments to the likely possibility that only the last 40 ms of our 100 ms Instruction segments captured signal related discharge.”</p><disp-quote content-type="editor-comment"><p>(7) Figure 8. Shouldn't the plots in panel A resemble those in Figure 3? Here you are projecting the hold trajectory segments into the subspace at time H, which should be the same as in Fig. 3A/B bottom right panel.</p></disp-quote><p>The previous Figure 8 is now Figure 8 panels A and B, and the previous Figure 3 is now Figure 5. The data used in these two figures come from two different recording sessions in two different monkeys. The current Figure 8A,B uses data from monkey F, session 2; whereas Figure 5 uses data from monkey T, session 3, which we now state in the legend to each figure, respectively. Consequently, the relative arrangement of the trajectory segments in the instantaneous subspace at time H differs. The session used in Figure 8A,B, which we now show in three dimensions, better illustrates how CCA identifies a common subspace in which execution versus observations segments show alignment (Figure 8B) that was not evident in their original subspaces (Figure 8A).</p><disp-quote content-type="editor-comment"><p>(8) Page 14, line 369. Are you computing CCA using only 2 components? I thought the subspaces were 3 dimensional. Why not align all three dimensions?</p></disp-quote><p>We have expanded this analysis to use all three dimensions, as illustrated in Figure 8 above.</p><disp-quote content-type="editor-comment"><p>(9) Page 14, line 407. Does this mean that instantaneous subspaces between execution and observation trials are more similar to each other during the Movement and Holding phase? Is this related to the fact that in those moments there is a smaller progressive shift of the subspaces within execution and observation trials?</p></disp-quote><p>Our new analyses of principal angles (see our reply to your comment 11, below) show that the progressive shifting of the instantaneous subspace continues through the movement and hold epochs. We now discuss this better alignment of the Movement and Hold trajectory segments as follows (lines 656 to 664):</p><p>“Given the complexity of condition-dependent neural trajectories across the entire time course of RGM trials (Figure 3B), rather than attempting to align entire neural trajectories, we applied canonical correlation to trajectory segments clipped for 100 ms following four well defined behavioral events: Instruction onset, Go cue, Movement onset, and the beginning of the final Hold. In all cases, alignment was poorest for Instruction segments, somewhat higher for Go segments, and strongest for Movement and Hold segments. This progressive increase in alignment likely reflects a progressive increase in the difference between average neuron firing rates for trials involving different objects (Figure 6) relative to the trial-by-trial variance in firing rate for a given object.”</p><disp-quote content-type="editor-comment"><p>(10) page 15, line 431. Typo, it should be Table 3.</p></disp-quote><p>We have removed Table 3 which no longer applies.</p><disp-quote content-type="editor-comment"><p>(11) A more general observation: did you try to compute another metric to assess the progressive shift of subspaces over time? I am thinking of something like computing the principal angles between consecutive subspaces. If it is true that the shifts happen over time, but it slows down during movement and hold, you should be able to conclude it from principal angles as well. Am I missing something? Is there any reason you went with classification accuracy instead of a metric like this?</p></disp-quote><p>Point taken. We now have calculated the principal angles as a function of time and have presented them as a new section of the Results including new Figure 4 and Figure 4 – figure supplement 3 (lines 237 to 293).</p><p>“Instantaneous subspaces shift progressively during both execution and observation</p><p>We identified an instantaneous subspace at each one millisecond time step of RGM trials. At each time step, we applied PCA to the 4 instantaneous neural states (i.e. the 4 points on the neural trajectories representing trials involving the 4 different objects each averaged across 20 trials per object, totaling 80 trials), yielding a 3-dimensional subspace at that time (see Methods). Note that because these 3-dimensional subspaces are essentially instantaneous, they capture the condition-dependent variation in neural states, but not the common, condition-independent variation. To examine the temporal progression of these instantaneous subspaces, we then calculated the principal angles between each 80-trial instantaneous subspace and the instantaneous subspaces averaged across all trials at four behavioral time points that could be readily defined across trials, sessions, and monkeys: the onset of the instruction (I), the go cue (G), the movement onset (M), and the beginning of the final hold (H). This process was repeated 10 times with replacement to assess the variability of the principal angles. The closer the principal angles are to 0°, the closer the two subspaces are to being identical; the closer to 90°, the closer the two subspaces are to being orthogonal.</p><p>Figure 4A-D illustrate the temporal progression of the first principal angle of the mirror neuron population in the three sessions (red, green, and blue) from monkey R during execution trials. As illustrated in Figure 4 – figure supplement 1 (see also the related Methods), in each session all three principal angles, each of which could range from 0° to 90°, tended to follow a similar time course. In the Results we therefore illustrate only the first (i.e. smallest) principal angle. Solid traces represent the mean across 10-fold cross validation using the 80-trial subsets of all the available trials; shading indicates ±1 standard deviation. As would be expected, the instantaneous subspace using 80 trials approaches the subspace using all trials at each of the four selected times—I, G, M, and H—indicated by the relatively narrow trough dipping toward 0°. Of greater interest are the slower changes in the first principal angle in between these four time points. Figure 4A shows that after instruction onset (I) the instantaneous subspace shifted quickly away from the subspace at time I, indicated by a rapid increase in principal angle to levels not much lower than what might be expected by chance alone (horizontal dashed line). In contrast, throughout the remainder of the instruction and delay epochs (from I to G), Figure 4B and C show that the 80-trial instantaneous subspace shifted gradually and concurrently, not sequentially, toward the all-trial subspaces that would be reached at the end of the delay period (G) and then at the onset of movement (M), indicated by the progressive decreases in principal angle. As shown by Figure 4D, shifting toward the H subspace did not begin until the movement onset (M). To summarize, these changes in principal angles indicate that after shifting briefly toward the subspace present at time the instruction appeared (I), the instantaneous subspace shifted progressively throughout the instruction and delay epochs toward the subspace that would be reached at the time of the go cue (G), then further toward that at the time of movement onset (M), and only thereafter shifted toward the instantaneous subspace that would be present at the time of the hold (H).</p><p>Figure 4E-H show the progression of the first principal angle of the mirror neuron population during observation trials. Overall, the temporal progression of the MN instantaneous subspace during observation was similar to that found during execution, particularly around times I and H. The decrease in principal angle relative to the G and M instantaneous subspaces during the delay epoch was less pronounced during observation than during execution. Nevertheless, these findings support the hypothesis that the condition-dependent subspace of PM MNs shifts progressively over the time course of RGM trials during both execution and observation, as illustrated schematically in Figure 1A.</p><p>We also examined the temporal progression of the instantaneous subspace of AE neurons. As would be expected given that AE neurons were not modulated significantly during observation trials, in the observation context AE populations had no gradual changes in principal angle (Figure 4 – figure supplement 3). During execution, however, Figure 4I-L show that the AE populations had a pattern of gradual decrease in principal angle similar to that found in the MN population (Figure 4A-D). After the instruction onset, the instantaneous subspace shifted quickly away from that present at time I and progressed gradually toward that present at times G and M, only shifting toward that present at time H after movement onset. As for the PM MN populations, the condition-dependent subspace of the PM AE populations shifted progressively over the time course of execution RGM trials.”</p><p>The related Methods are now described is subsection “Subspace Comparisons—Principal Angles”</p><disp-quote content-type="editor-comment"><p>Is there any reason you went with classification accuracy instead of a metric like this?</p></disp-quote><p>We now point out that (lines 295 to 297):</p><p>“The progressive changes in principal angles do not capture another important aspect of condition-dependent neural activity. The neural trajectories during trials involving different objects separated increasingly as trials progressed in time.”</p><p>And we further clarify this as follows (lines 331 to 348):</p><p>“Decodable information changes progressively during both execution and observation</p><p>As RGM trials proceeded in time, the condition-dependent neural activity of the PM MN population thus changed in two ways. First, the instantaneous condition-dependent subspace shifted, indicating that the patterns of firing-rate co-modulation among neurons representing the four different RGM movements changed progressively, both during execution and during observation. Second, as firing rates generally increased, the neural trajectories representing the four RGM movements became progressively more separated, more so during execution than during observation.</p><p>To evaluate the combined effects of these two progressive changes, we clipped 100 ms single-trial trajectory segments beginning at times I, G, M, or H, and projected these trajectory segments from individual trials into the instantaneous 3D subspaces at 50 ms time steps. At each of these time steps, we trained a separate LSTM decoder to classify individual trials according to which of the four objects was involved in that trial. We expected that the trajectory segments would be classified most accurately when projected into instantaneous subspaces near the time at which the trajectory segments were clipped. At other times we reasoned that classification accuracy would depend both on the similarity of the current instantaneous subspace to that found at the clip time as evaluated by the principal angle (Figure 4), and on the separation of the four trajectories at the clip time (Figure 5).”</p></body></sub-article></article>