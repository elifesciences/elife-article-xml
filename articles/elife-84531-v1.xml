<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.1d3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">84531</article-id><article-id pub-id-type="doi">10.7554/eLife.84531</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Are single-peaked tuning curves tuned for speed rather than accuracy?</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-297727"><name><surname>Lenninger</surname><given-names>Movitz</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-297728"><name><surname>Skoglund</surname><given-names>Mikael</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-138557"><name><surname>Herman</surname><given-names>Pawel Andrzej</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6553-823X</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="par-1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-31619"><name><surname>Kumar</surname><given-names>Arvind</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8044-9195</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="corresp" rid="cor2">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">Division of Information Science and Engineering</institution>, <institution>KTH Royal Institute of Technology</institution>, <addr-line><named-content content-type="city">Stockholm</named-content></addr-line>, <country>Sweden</country></aff><aff id="aff2"><institution content-type="dept">Division of Computational Science and Technology</institution>, <institution>KTH Royal Institute of Technology</institution>, <addr-line><named-content content-type="city">Stockholm</named-content></addr-line>, <country>Sweden</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-6945"><name><surname>Latham</surname><given-names>Peter</given-names></name><role>Reviewing editor</role><aff><institution>University College London</institution>, <country>United Kingdom</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>movitzle@kth.se</email> (ML);</corresp><corresp id="cor2"><label>*</label>For correspondence: <email>arvkumar@kth.se</email> (AK);</corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>16</day><month>05</month><year>2023</year></pub-date><volume>12</volume><elocation-id>e84531</elocation-id><history><date date-type="received"><day>28</day><month>10</month><year>2022</year></date><date date-type="accepted"><day>11</day><month>05</month><year>2023</year></date></history><permissions><copyright-statement>© 2023, Lenninger et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Lenninger et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> permitting unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-84531-v1.pdf"/><abstract><p>According to the efficient coding hypothesis, sensory neurons are adapted to provide maximal information about the environment, given some biophysical constraints. In early visual areas, stimulus-induced modulations of neural activity (or tunings) are predominantly single-peaked. However, periodic tuning, as exhibited by grid cells, has been linked to a significant increase in decoding performance. Does this imply that the tuning curves in early visual areas are sub-optimal? We argue that the time scale at which neurons encode information is imperative to understanding the advantages of single-peaked and periodic tuning curves. Here, we show that the possibility of catastrophic (large) errors creates a trade-off between decoding time and decoding ability. We investigate how decoding time and stimulus dimensionality affect the optimal shape of tuning curves for removing catastrophic errors. In particular, we focus on the spatial periods of the tuning curves for a class of circular tuning curves. We show an overall trend for minimal decoding time to increase with increasing Fisher information, implying a trade-off between accuracy and speed. This trade-off is reinforced whenever the stimulus dimensionality is high, or there is ongoing activity. Thus, given constraints on processing speed, we present normative arguments for the existence of the single-peaked tuning organization observed in early visual areas.</p></abstract><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution>Digital Futures</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Lenninger</surname><given-names>Movitz</given-names></name><name><surname>Skoglund</surname><given-names>Mikael</given-names></name><name><surname>Herman</surname><given-names>Pawel Andrzej</given-names></name><name><surname>Kumar</surname><given-names>Arvind</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004359</institution-id><institution>Vetenskapsrådet</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Kumar</surname><given-names>Arvind</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution>Institute of Advanced Studies Fellowship, University of Strasbourg, France</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Kumar</surname><given-names>Arvind</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group></article-meta></front><back><sec id="s1" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interest</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group></sec><sec id="s2" sec-type="supplementary-material"><title>Additional Files</title><sec id="s3" sec-type="data-availability"><title>Data availability</title><p>Code has been made publicly available on Github (https://github.com/movitzle/Short_Decoding_Time)</p></sec><supplementary-material><ext-link xlink:href="elife-84531-supp-v1.zip">Download zip</ext-link><p>Any figures and tables for this article are included in the PDF. The zip folder contains additional supplemental files.</p></supplementary-material></sec></back></article>