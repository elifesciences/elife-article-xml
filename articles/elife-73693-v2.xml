<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">73693</article-id><article-id pub-id-type="doi">10.7554/eLife.73693</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Short Report</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A generalized cortical activity pattern at internally generated mental context boundaries during unguided narrative recall</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-252612"><name><surname>Lee</surname><given-names>Hongmi</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8023-0727</contrib-id><email>hongmi.lee@jhu.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-91451"><name><surname>Chen</surname><given-names>Janice</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00za53h95</institution-id><institution>Department of Psychological and Brain Sciences, Johns Hopkins University</institution></institution-wrap><addr-line><named-content content-type="city">Baltimore</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Schlichting</surname><given-names>Margaret L</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03dbr7087</institution-id><institution>University of Toronto</institution></institution-wrap><country>Canada</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Baker</surname><given-names>Chris I</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04xeg9z08</institution-id><institution>National Institute of Mental Health, National Institutes of Health</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>30</day><month>05</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e73693</elocation-id><history><date date-type="received" iso-8601-date="2021-09-07"><day>07</day><month>09</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2022-05-29"><day>29</day><month>05</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2021-09-08"><day>08</day><month>09</month><year>2021</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2021.09.07.459300"/></event></pub-history><permissions><copyright-statement>© 2022, Lee and Chen</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Lee and Chen</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-73693-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-73693-figures-v2.pdf"/><abstract><p>Current theory and empirical studies suggest that humans segment continuous experiences into events based on the mismatch between predicted and actual sensory inputs; detection of these ‘event boundaries’ evokes transient neural responses. However, boundaries can also occur at transitions between internal mental states, without relevant external input changes. To what extent do such ‘internal boundaries’ share neural response properties with externally driven boundaries? We conducted an fMRI experiment where subjects watched a series of short movies and then verbally recalled the movies, unprompted, in the order of their choosing. During recall, transitions between movies thus constituted major boundaries between internal mental contexts, generated purely by subjects’ unguided thoughts. Following the offset of each recalled movie, we observed stereotyped spatial activation patterns in the default mode network, especially the posterior medial cortex, consistent across different movie contents and even across the different tasks of movie watching and recall. Surprisingly, the between-movie boundary patterns did not resemble patterns at boundaries between events within a movie. Thus, major transitions between mental contexts elicit neural phenomena shared across internal and external modes and distinct from within-context event boundary detection, potentially reflecting a cognitive state related to the flushing and reconfiguration of situation models.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>memory</kwd><kwd>event segmentation</kwd><kwd>fMRI</kwd><kwd>default mode network</kwd><kwd>internal cognition</kwd><kwd>narrative</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000879</institution-id><institution>Alfred P. Sloan Foundation</institution></institution-wrap></funding-source><award-id>Sloan Research Fellowship</award-id><principal-award-recipient><name><surname>Chen</surname><given-names>Janice</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100006785</institution-id><institution>Google</institution></institution-wrap></funding-source><award-id>Google Faculty Research Award</award-id><principal-award-recipient><name><surname>Chen</surname><given-names>Janice</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Prominent transitions between different mental contexts produce a stereotyped brain state shared across internally and externally generated transitions but distinct from minor within-context transitions, potentially reflecting a major flushing and updating of mental models.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Humans perceive and remember continuous experiences as discrete events (<xref ref-type="bibr" rid="bib10">Brunec et al., 2018</xref>; <xref ref-type="bibr" rid="bib18">Clewett et al., 2019</xref>; <xref ref-type="bibr" rid="bib51">Shin and DuBrow, 2021</xref>; <xref ref-type="bibr" rid="bib70">Zacks, 2020</xref>). Studies of event segmentation have shown that when participants attend to external information (e.g., watch a video), (1) boundaries between events are detected when mismatches arise between predicted and actual sensory input (<xref ref-type="bibr" rid="bib67">Zacks et al., 2007</xref>; <xref ref-type="bibr" rid="bib69">Zacks et al., 2011</xref>), and (2) boundary detection evokes transient neural responses in a consistent set of brain areas (<xref ref-type="bibr" rid="bib47">Reagh et al., 2020</xref>; <xref ref-type="bibr" rid="bib58">Speer et al., 2007</xref>; <xref ref-type="bibr" rid="bib66">Zacks et al., 2001</xref>). Among these areas is the default mode network (DMN; <xref ref-type="bibr" rid="bib11">Buckner and DiNicola, 2019</xref>) proposed to be involved in representing complex mental models of events (<xref ref-type="bibr" rid="bib46">Ranganath and Ritchey, 2012</xref>; <xref ref-type="bibr" rid="bib48">Ritchey and Cooper, 2020</xref>). However, a substantial portion of human cognition is internally driven (<xref ref-type="bibr" rid="bib28">Hasselmo, 1995</xref>; <xref ref-type="bibr" rid="bib30">Honey et al., 2018</xref>), and such spontaneous production of thoughts and actions is also punctuated by mental context transitions (<xref ref-type="bibr" rid="bib17">Christoff et al., 2016</xref>; <xref ref-type="bibr" rid="bib37">Mildner and Tamir, 2019</xref>; <xref ref-type="bibr" rid="bib52">Smallwood and Schooler, 2015</xref>; <xref ref-type="bibr" rid="bib61">Tseng and Poppenk, 2020</xref>). What manner of brain activity marks boundaries between mental contexts when they are internally generated? Are the brain responses at internal boundaries similar to those at external boundaries?</p><p>Here, we used naturalistic movie viewing and free spoken recall with fMRI to characterize neural activity at boundaries between internally generated mental contexts (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Subjects watched 10 short movies (encoding phase), then verbally recounted the movies in any order, in their own words (recall phase). The transitions between recalled movies were determined purely by subjects’ internal mentation; no external cues prompted the recall onset or offset of each movie. Moreover, the unguided spoken recall allowed us to identify the exact moments of context transitions and explicitly track shifts in the contents of thoughts (<xref ref-type="bibr" rid="bib15">Chen et al., 2017</xref>; <xref ref-type="bibr" rid="bib59">Sripada and Taxali, 2020</xref>), which was not possible in prior studies using silent rest (<xref ref-type="bibr" rid="bib32">Karapanagiotidis et al., 2020</xref>; <xref ref-type="bibr" rid="bib61">Tseng and Poppenk, 2020</xref>). At these internal boundaries between recalled movies, we observed transient, highly generalizable and fine-grained activation patterns throughout the DMN, consistent across diverse movie contents and similar to those at external between-movie boundaries during encoding. Moreover, these between-movie boundary patterns were not merely stronger versions of within-movie ‘event boundaries,’ but instead manifested as a distinct type of neural transition. We propose that these cortical patterns reflect a cognitive state related to the major flushing and reconfiguration of mental context (<xref ref-type="bibr" rid="bib23">DuBrow et al., 2017</xref>; <xref ref-type="bibr" rid="bib35">Manning et al., 2016</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Experimental procedures and univariate responses.</title><p>(<bold>A</bold>) In the encoding phase, subjects watched 10 short movies approximately 2–8 min long. Each movie started with a 6 s title scene. In the free spoken recall phase, subjects verbally recounted each movie plot in as much detail as possible regardless of the order of presentation. After recalling one movie, subjects spontaneously proceeded to the next movie, and the transitions between movies were considered as internally driven boundaries. Red arrows indicate the boundaries (onsets and offsets) between watched or recalled movies. Black arrows indicate the non-boundary moments (middle) of each watched or recalled movie. (<bold>B</bold>) Whole-brain maps of unthresholded mean activation (blood oxygen level-dependent [BOLD] signals z-scored across all volumes within a scanning run) following between-movie boundaries during recall (4.5–19.5 s from the offset of each movie). Blue areas indicate regions with lower-than-average activation, where the average activation of a scanning run was z = 0. Likewise, red areas indicate regions with higher-than-average activation. White outlines indicate areas that showed significantly lower or higher activation following between-movie boundaries compared to non-boundary periods (false discovery rate-corrected <italic>q</italic> &lt; 0.05; minimum surface area = 16 mm<sup>2</sup>). The non-boundary periods were defined as the middle 15 s of each recalled movie, shifted forward by 4.5 s. Changes in whole-brain univariate responses across time around the boundaries are shown in <xref ref-type="video" rid="fig1video1">Figure 1—video 1</xref> (recall phase) and <xref ref-type="video" rid="fig1video2">Figure 1—video 2</xref> (encoding phase).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-73693-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Mean activation time courses around between-movie boundaries.</title><p>For each subject and region of interest (top row = posterior medial cortex [PMC]; middle row = angular gyrus [ANG]; bottom row = auditory cortex [AUD]), blood oxygen level-dependent [BOLD] signals measured during the encoding phase (left column) or recall phase (right column) were locked to the offset of each watched or recalled movie, and then averaged across movies. Thin gray lines show individual subjects’ time courses. Thick black lines show the mean time courses averaged across all subjects. Red bars on the <italic>x</italic>-axis indicate the 15 s boundary period time window (4.5–19.5 s from the offset of each movie) used for subsequent analyses comparing the boundary and non-boundary periods.</p><p><supplementary-material id="fig1s1sdata1"><label>Figure 1—figure supplement 1—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-73693-fig1-figsupp1-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-73693-fig1-figsupp1-v2.tif"/></fig><media id="fig1video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-73693-fig1-video1.mp4"><label>Figure 1—video 1.</label><caption><title>Changes in univariate activation at between-movie boundaries during recall (video).</title><p>The animation shows the time series of whole-brain activation maps (blood oxygen level-dependent [BOLD] signals z-scored across all volumes within a scanning run) locked to the offset of the recall of each movie, from 30 s before to 45 s after the offset. Within each of the 7.5 s time windows shown as a red bar on the time axis, BOLD signals in each vertex were averaged across time points, movies, and subjects. Blue-cyan areas indicate regions with lower-than-average activation. Red-yellow areas indicate regions with higher-than-average activation.</p></caption></media><media id="fig1video2" mime-subtype="mp4" mimetype="video" xlink:href="elife-73693-fig1-video2.mp4"><label>Figure 1—video 2.</label><caption><title>Changes in univariate activation at between-movie boundaries during encoding (video).</title><p>The animation shows the time series of whole-brain activation maps (blood oxygen level-dependent [BOLD] signals z-scored across all volumes within a scanning run) locked to the offset of each movie clip during the encoding phase, from 30 s before to 45 s after the offset. Within each of the 7.5 s time windows shown as a red bar on the time axis, BOLD signals in each vertex were averaged across time points, movies, and subjects. Blue-cyan areas indicate regions with lower-than-average activation. Red-yellow areas indicate regions with higher-than-average activation.</p></caption></media></fig-group></sec><sec id="s2" sec-type="results"><title>Results</title><p>We first examined whether internally driven boundaries evoke changes in blood oxygen level-dependent (BOLD) signals during recall. We observed transient changes in activation at the boundaries between recalled movies in widespread cortical regions (<xref ref-type="video" rid="fig1video1">Figure 1—video 1</xref>; see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> for activation time courses). A whole-brain analysis with multiple comparisons correction revealed that the mean activation of boundary periods (15 s following the offset of each movie) was generally lower than that of non-boundary periods (middle 15 s within each movie) in multiple areas, including the motor, auditory, and inferior parietal cortices, although a smaller number of regions showed higher activation during non-boundary periods (<xref ref-type="fig" rid="fig1">Figure 1B</xref>).</p><p>Next, we tested whether there were neural activation patterns specific to internally driven boundaries and consistent across different movies. We performed a whole-brain pattern similarity analysis on the recall data to identify regions where (1) boundary period activation patterns were positively correlated across different recalled movies (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, blue arrow <italic>a</italic> &gt; 0), and (2) this correlation was higher at boundaries than at non-boundaries (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, blue arrows <italic>a</italic> &gt; <italic>b</italic>). We observed a consistent boundary pattern, that is, whenever participants transitioned from talking about one movie to the next, in several cortical parcels (<xref ref-type="bibr" rid="bib49">Schaefer et al., 2018</xref>), including the DMN and auditory/motor areas (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Thus, the boundary patterns within the recall phase were likely to be driven by both shared low-level sensory/motor factors (e.g., breaks in recall speech generation) as well as cognitive states (e.g., memory retrieval) at recall boundaries. No cortical parcel showed significantly negative correlations between boundary patterns or greater correlations in the non-boundary compared to boundary conditions.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Consistent activation patterns associated with between-movie boundaries.</title><p>(<bold>A</bold>) Schematic of the pattern similarity analysis. Boundary patterns were defined as the mean pattern averaged across 15 s following the offset of each watched or recalled movie. Non-boundary patterns were defined as the mean pattern averaged across 15 s in the middle of each watched or recalled movie. For each subject and cortical parcel (<xref ref-type="bibr" rid="bib49">Schaefer et al., 2018</xref>; 200 parcels per hemisphere), we computed pairwise between-movie pattern similarity (Pearson correlation), separately for boundary patterns and non-boundary patterns measured during recall (a and b, blue arrows). We also computed between-movie and between-phase (encoding-recall) pattern similarity, again separately for boundary and non-boundary patterns (c and d, red arrows). The time windows for both boundary and non-boundary periods were shifted forward by 4.5 s to account for the hemodynamic response delay. (<bold>B</bold>) Whole-brain <italic>t</italic> statistic map of cortical parcels that showed consistent between-movie boundary patterns during recall. These parcels displayed significantly greater between-movie pattern similarity in the boundary condition compared to the non-boundary condition during recall. The map was masked by parcels that showed significantly positive between-movie pattern similarity in the boundary condition during recall. Both effects were Bonferroni corrected across parcels (p&lt;0.05). (<bold>C</bold>) Whole-brain <italic>t</italic> statistic map of cortical parcels that showed consistent between-movie boundary patterns across encoding and recall. These parcels displayed significantly greater between-movie and between-phase pattern similarity in the boundary condition compared to the non-boundary condition. The map was masked by parcels that showed significantly positive between-movie and between-phase pattern similarity in the boundary condition. Both effects were Bonferroni corrected across parcels (p&lt;0.05).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-73693-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Consistent activation patterns during shorter (4.5 s) time windows following between-movie boundaries.</title><p>(<bold>A</bold>) Whole-brain <italic>t</italic> statistic map of cortical parcels that showed consistent between-movie boundary patterns during recall. These parcels displayed significantly greater between-movie pattern similarity in the boundary condition compared to the non-boundary condition during recall. The map was masked by parcels that showed significantly positive between-movie pattern similarity in the boundary condition during recall. Both effects were Bonferroni corrected across parcels (p&lt;0.05). (<bold>B</bold>) Whole-brain <italic>t</italic> statistic map of cortical parcels that showed consistent between-movie boundary patterns across encoding and recall. These parcels displayed significantly greater between-movie and between-phase pattern similarity in the boundary condition compared to the non-boundary condition. The map was masked by parcels that showed significantly positive between-movie and between-phase pattern similarity in the boundary condition. Both effects were Bonferroni corrected across parcels (p&lt;0.05). For both (<bold>A</bold>) and (<bold>B</bold>), boundary periods were defined as 4.5–9 s from the offset of each movie. Non-boundary periods were defined as the middle 4.5 s of each movie, shifted forward by 4.5 s to account for hemodynamic response delay.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-73693-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Similar visual input cannot explain between-movie boundary patterns consistent across experimental phases.</title><p>(<bold>A</bold>) To test whether shared visual features (i.e., mostly blank black screen) produced boundary (offset) patterns consistent across encoding and recall, we performed a whole-brain pattern similarity analysis. For each subject and cortical parcel, we computed the mean correlation between boundary patterns across different movies and experimental phases (a, red arrow). We also computed the mean correlation between encoding boundary patterns and recall non-boundary (middle) patterns across different movies (c, blue arrow). Note that visual input (a fixation dot) was identical across boundary and non-boundary periods during recall. The duration of boundary and non-boundary periods was 15 s. (<bold>B</bold>) Whole-brain <italic>t</italic> statistic map of cortical parcels that showed greater pattern correlations between encoding and recall boundary patterns (a, red arrow) compared to correlations between encoding boundary patterns and recall non-boundary patterns (c, blue arrow). Bonferroni correction was applied across parcels to correct for multiple comparisons (p&lt;0.05). Several parcels in higher associative cortices showed greater correlations between encoding and recall boundary patterns, suggesting that low-level visual features contributed little to the consistent boundary patterns in those areas.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-73693-fig2-figsupp2-v2.tif"/></fig></fig-group><p>To what extent is the internally driven boundary pattern, measured during recall, similar to patterns observed at boundaries during encoding? To test this, we again computed between-movie pattern similarity for all cortical parcels in the brain, but now across the encoding and recall phases (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, red arrows). We found that DMN areas showed a consistent boundary pattern across task phases (encoding and recall) and across movies (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). Again, no cortical parcel showed negative correlations between boundary patterns or greater correlations in the non-boundary condition. Among the DMN areas, the posterior medial cortex (PMC) showed the most consistent boundary patterns; thus, we next examined the phenomenon in more detail specifically in PMC. <xref ref-type="fig" rid="fig3">Figure 3A and C</xref> visualize the high and consistently positive correlations of PMC boundary patterns across different movies both within the recall phase (recall offset vs. recall offset, <italic>t</italic>(14) = 11.82, p&lt;0.001, Cohen’s <italic>d</italic><sub>z</sub> = 3.05, 95% confidence interval (CI) = [0.28,0.41]) and even between experimental phases (recall offset vs. encoding offset, <italic>t</italic>(14) = 14.54, p&lt;0.001, Cohen’s <italic>d</italic><sub>z</sub> = 3.75, 95% CI = [0.28,0.38]). No such correlation was present between non-boundary patterns (<italic>t</italic>(14)s &lt; 1, <italic>p</italic>s &gt; 0.3). Individual subjects’ activation maps visualize the similarity between boundary patterns during encoding and recall (<xref ref-type="fig" rid="fig3">Figure 3B</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). We observed similar results in the lateral parietal DMN subregion (angular gyrus; <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>), as well as using shorter (4.5 s) time windows of boundary and non-boundary periods (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>, <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Boundary pattern in the posterior medial cortex (PMC).</title><p>(<bold>A</bold>) PMC activation pattern similarity (Pearson correlation) between the 10 movie stimuli (M1–10), conditions (offset = boundary, middle = non-boundary), and experimental phases (encoding, recall), averaged across all subjects. The boundary pattern of a movie was defined as the mean pattern averaged across the 15 s window following the offset of the movie. The non-boundary pattern was defined as the mean pattern averaged across the 15 s window in the middle of a movie. The time windows for both boundary and non-boundary patterns were shifted forward by 4.5 s to account for the hemodynamic response delay. PMC regions of interest (ROIs) are shown as white areas on the inflated surface of a template brain. (<bold>B</bold>) Subject-specific mean activation patterns associated with between-movie boundaries during encoding (left) and recall (right). The boundary patterns were averaged across all movies and then <italic>z</italic>-scored across vertices within the PMC ROI mask, separately for each experimental phase. PMC (demarcated by black outlines) of four example subjects (S1–4) are shown on the medial surface of the right hemisphere of the fsaverage6 template brain. (<bold>C</bold>) Within-phase (recall-recall) and between-phase (encoding-recall) pattern similarity across different movies, computed separately for the boundary (offset) and non-boundary (middle) patterns in PMC. Bar graphs show the mean across subjects. Circles represent individual subjects. Error bars show SEM across subjects. ***p&lt;.001. (<bold>D</bold>) Time-point-by-time-point PMC pattern similarity across the encoding phase and recall phase activation patterns around between-movie boundaries, averaged across all subjects. The time series of activation patterns were locked to either the onset (left) or the offset (right) of each movie. During encoding, the onset of a movie and the offset of the preceding movie were separated by a 6 s title scene. During recall, onsets and offsets of recalled movies were separated by, on average, a 9.3 s pause (boundaries concatenated across subjects, SD = 16.8 s). Dotted lines on the left and right panels indicate the mean offset times of the preceding movies and the mean onset times of the following movies, respectively. Note that in this figure zero corresponds to the true stimulus/behavior time, with no shifting for hemodynamic response delay. Areas outlined by black lines indicate correlations significantly different from zero after multiple comparisons correction (Bonferroni corrected p&lt;0.05). Time–time correlations within each experimental phase can be found in <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>.</p><p><supplementary-material id="fig3sdata1"><label>Figure 3—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig3">Figure 3</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-73693-fig3-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-73693-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Subject-specific boundary patterns in the posterior medial cortex (PMC).</title><p>The between-movie boundary patterns were averaged across all movies and then <italic>z</italic>-scored across vertices within the PMC region of interest (ROI) mask, separately for the encoding phase and the recall phase. PMC of 11 subjects (S5–15) are shown on the medial surface of the right hemisphere of the fsaverage6 template brain.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-73693-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Boundary pattern in the angular gyrus (ANG).</title><p>(<bold>A</bold>) ANG activation pattern similarity (Pearson correlation) between the 10 movie stimuli (M1–10), conditions (offset = boundary, middle = non-boundary), and experimental phases (encoding, recall), averaged across all subjects. The boundary pattern of a movie was defined as the mean pattern averaged across the 15 s window following the offset of the movie. The non-boundary pattern was defined as the mean pattern averaged across the 15 s window in the middle of a movie. The time windows for both boundary and non-boundary patterns were shifted forward by 4.5 s to account for the hemodynamic response delay. ANG regions of interest (ROIs) are shown as white areas on the inflated surface of a template brain. (<bold>B</bold>) Subject-specific mean activation patterns associated with between-movie boundaries during encoding (left) and recall (right). The boundary patterns were averaged across all movies and then <italic>z</italic>-scored across vertices within the ANG ROI mask, separately for each experimental phase. ANG (demarcated by black outlines) of four example subjects (S1–4) are shown on the lateral surface of the left hemisphere of the fsaverage6 template brain. (<bold>C</bold>) Within-phase (recall-recall) and between-phase (encoding-recall) pattern similarity across different movies, computed separately for the boundary (offset) and non-boundary (middle) patterns in ANG. Bar graphs show the mean across subjects. Circles represent individual subjects. Error bars show SEM across subjects. ***p&lt;0.001. (<bold>D</bold>) Time-point-by-time-point ANG pattern similarity across the encoding phase and recall phase activation patterns around between-movie boundaries, averaged across all subjects. The time series of activation patterns were locked to either the onset (left) or the offset (right) of each movie. Dotted lines on the left and right panels indicate the mean offset times of the preceding movies and the mean onset times of the following movies, respectively. Note that in this figure zero corresponds to the true stimulus/behavior time, with no shifting for hemodynamic response delay. Areas outlined by black lines indicate correlations significantly different from zero after multiple comparisons correction (Bonferroni corrected p&lt;0.05).</p><p><supplementary-material id="fig3s2sdata1"><label>Figure 3—figure supplement 2—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-73693-fig3-figsupp2-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-73693-fig3-figsupp2-v2.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Boundary patterns in regions of interest measured during shorter (4.5 s) time windows.</title><p>Within-phase (recall-recall) and between-phase (encoding-recall) pattern similarity across different movies, computed separately for the boundary (offset) and non-boundary (middle) patterns in the posterior medial cortex (PMC; left panel) and the angular gyrus (ANG; right panel). Boundary periods were defined as 4.5–9 s from the offset of each movie. Non-boundary periods were defined as the middle 4.5 s of each movie, shifted forward by 4.5 s to account for hemodynamic response delay. Bar graphs show the mean across subjects. Circles represent individual subjects. Error bars show SEM across subjects. ***p&lt;0.001.</p><p><supplementary-material id="fig3s3sdata1"><label>Figure 3—figure supplement 3—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-73693-fig3-figsupp3-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-73693-fig3-figsupp3-v2.tif"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 4.</label><caption><title>Time–time pattern similarity in the posterior medial cortex (PMC).</title><p>The similarity matrices show Pearson correlations between PMC patterns across time points around between-movie boundaries during encoding (<bold>A</bold>, <bold>B</bold>) and recall (<bold>C</bold>, <bold>D</bold>), calculated within each subject and then averaged across all subjects. The time series of activation patterns were locked to either the onset (<bold>A</bold>, <bold>C</bold>) or the offset (<bold>B</bold>, <bold>D</bold>) of each movie. Dotted lines in (<bold>A</bold>) and (<bold>C</bold>) indicate the mean offset times of the preceding movies. Dotted lines in (<bold>B</bold>) and (<bold>D</bold>) indicate the mean onset times of the following movies. Note that in this figure zero corresponds to the true stimulus/behavior time, with no shifting for hemodynamic response delay. Areas outlined by black lines indicate correlations that significantly deviate from zero after multiple comparisons correction (Bonferroni corrected p&lt;0.05). The boundary pattern emerged following the offsets but preceded the onsets of watched or recalled movies. In addition, the boundary pattern was stronger and lasted longer following encoding offsets compared to recall offsets; this may be because boundaries between movies were more salient during initial movie watching as they accompanied both external and internal mental context changes, whereas recall boundaries accompanied internal context changes only. Encoding boundaries were also more unpredictable and may require a more gradual build-up of the upcoming mental context, compared to self-generated boundaries between already stored memories during recall.</p><p><supplementary-material id="fig3s4sdata1"><label>Figure 3—figure supplement 4—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-73693-fig3-figsupp4-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-73693-fig3-figsupp4-v2.tif"/></fig></fig-group><p>Thus far, we tested boundary responses following offsets, based on prior findings that post-stimulus neural responses contribute to memory formation (<xref ref-type="bibr" rid="bib6">Ben-Yakov et al., 2013</xref>; <xref ref-type="bibr" rid="bib5">Ben-Yakov and Dudai, 2011</xref>; <xref ref-type="bibr" rid="bib36">Medvedeva et al., 2021</xref>). However, other studies also reported neural responses specific to the onset of an episode (<xref ref-type="bibr" rid="bib12">Bulkin et al., 2020</xref>; <xref ref-type="bibr" rid="bib26">Fox et al., 2005</xref>; <xref ref-type="bibr" rid="bib64">Wen et al., 2020</xref>). Is the generalized boundary pattern evoked by the onset of a movie, rather than the offset? We examined this question by comparing the temporal emergence of the generalized boundary pattern following movie offsets versus onsets (<xref ref-type="fig" rid="fig3">Figure 3D</xref>); note that the offset of a movie was temporally separated from the onset of the following movie during both encoding and recall (see <xref ref-type="fig" rid="fig1">Figure 1A</xref>). Specifically, we extracted the mean time series of PMC activation patterns around between-movie boundaries, time-locked to either the onset or offset of each watched or recalled movie. We then computed between-phase (encoding-recall) pattern similarity across the individual time points of the activation pattern time series. We found that significantly positive between-phase correlations emerged well before the encoding and recall onsets (<xref ref-type="fig" rid="fig3">Figure 3D</xref>, left panel), starting from 4.5 s following the offsets of the preceding watched or recalled movie (<xref ref-type="fig" rid="fig3">Figure 3D</xref>, right panel). Thus, boundary patterns were not exclusively triggered by movie onsets; it is likely that offset responses significantly contributed to the boundary patterns.</p><p>We focused our analyses up to this point on transitions between movies because they provided clear boundaries between mental contexts during recall. However, event boundaries in naturalistic movie stimuli are often defined as transitions between scenes within a movie (<xref ref-type="bibr" rid="bib4">Baldassano et al., 2017</xref>; <xref ref-type="bibr" rid="bib15">Chen et al., 2017</xref>; <xref ref-type="bibr" rid="bib68">Zacks et al., 2010</xref>). In prior work, it has been shown that for within-movie event boundaries neural responses scale positively with human judgments of the ‘strength’ of scene transitions (<xref ref-type="bibr" rid="bib7">Ben-Yakov and Henson, 2018</xref>). Thus, we hypothesized that boundaries between movies (i.e., between mental contexts) would manifest as stronger versions of within-movie boundaries with qualitatively similar patterns; in other words, boundary patterns would generalize across different scales of boundaries. To test this idea, we first confirmed that there were consistent within-movie event boundary patterns in PMC during encoding; within-movie boundary patterns were more similar to each other than to non-boundary patterns (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). We then tested whether this within-movie boundary pattern resembled the between-movie boundary pattern by measuring the correlation between (1) the mean between-movie boundary pattern during recall and (2) the mean within-movie event boundary pattern during encoding (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Surprisingly, the two were negatively correlated (<italic>t</italic>(14) = 5.10, p&lt;0.001, Cohen’s <italic>d</italic><sub>z</sub> = 1.32, 95% CI = [–0.34, –0.14]), in contrast to the strong positive correlation across encoding and recall between-movie boundary patterns (<italic>t</italic>(14) = 25.02, p&lt;.001, Cohen’s <italic>d</italic><sub>z</sub> = 6.46, 95% CI = [0.67,0.79]). The within-movie event boundary pattern was also negatively correlated with the encoding phase between-movie boundary pattern (<italic>t</italic>(14) = 7.31, p&lt;0.001, Cohen’s <italic>d</italic><sub>z</sub> = 1.89, 95% CI = [–0.44, –0.24]). Within-movie and between-movie boundary patterns did not resemble each other, regardless of the specific time windows used to define the boundary periods (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). These results suggest that the between-movie boundary pattern may reflect a cognitive state qualitatively different from the state elicited by within-movie event boundaries during movie watching.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Comparing between-movie and within-movie boundary patterns in the posterior medial cortex (PMC).</title><p>(<bold>A</bold>) Schematic of the analysis. For each subject, we created the template PMC activation pattern associated with between-movie boundaries by averaging activation patterns following the offset of each between-movie boundary (orange bars), separately for encoding and recall phases. Likewise, the template within-movie event boundary pattern was created by averaging the activation patterns following the offset of each within-movie boundary during encoding (green bars). We then measured the similarity (Pearson correlation) between the mean between-movie boundary patterns during encoding and recall (a, orange arrow). We also measured the similarity between the mean within-movie boundary pattern during encoding and the mean between-movie boundary pattern during recall (b, green arrow). For both between- and within-movie boundaries, boundary periods were 15 s long, shifted forward by 4.5 s. (<bold>B</bold>) Pattern similarity between template boundary patterns. The orange bar shows the mean correlation across the between-movie boundary patterns during encoding and recall. The green bar shows the mean correlation across the between-movie boundary pattern during recall and the within-movie boundary pattern during encoding. Circles represent individual subjects. Error bars show SEM across subjects. ***p&lt;0.001 against zero.</p><p><supplementary-material id="fig4sdata1"><label>Figure 4—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig4">Figure 4</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-73693-fig4-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-73693-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Comparing within-movie boundary patterns and non-boundary (middle) patterns in the posterior medial cortex (PMC) during encoding.</title><p>The mean correlation between within-movie boundary patterns across different movies (within-within) was greater than zero (<italic>t</italic>(14) = 5.23, p&lt;0.001, Cohen’s <italic>d</italic><sub>z</sub> = 1.35, 95% CI = [0.03,0.07]). The mean correlation between within-movie boundary patterns and non-boundary patterns across different movies (within-middle) was also greater than zero (<italic>t</italic>(14) = 3.73, p=0.002, Cohen’s <italic>d</italic><sub>z</sub> = .96, 95% CI = [0.01,0.02]). Critically, within-movie boundary patterns were more similar to each other than to non-boundary patterns (within-within vs. within-middle; <italic>t</italic>(14) = 3.29, p=0.005, Cohen’s <italic>d</italic><sub>z</sub> = .85, 95% CI of the difference = [0.01,0.06]). The duration of within-movie boundary and non-boundary periods was 15 s. Two non-boundary patterns that partially overlapped with the within-movie boundary patterns were excluded from analysis. Circles represent individual subjects. Error bars show SEM across subjects. **p&lt;0.01, ***p&lt;0.001.</p><p><supplementary-material id="fig4s1sdata1"><label>Figure 4—figure supplement 1—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-73693-fig4-figsupp1-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-73693-fig4-figsupp1-v2.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Examining the effects of boundary period time windows on the between- and within-movie boundary pattern similarity in the posterior medial cortex (PMC).</title><p>(<bold>A</bold>) Pattern similarity between the template boundary patterns in PMC measured during a shorter (4.5 s) boundary period time window following the offset of each boundary. The orange bar shows the average correlation across the mean between-movie boundary patterns during encoding and recall. The green bar shows the average correlation across the mean between-movie boundary pattern during recall and the mean within-movie event boundary pattern during encoding. There was a strong positive correlation across the encoding and recall between-movie boundary patterns (<italic>t</italic>(14) = 15.08, p&lt;0.001, Cohen’s <italic>d</italic><sub>z</sub> = 3.89, 95% CI = [0.52,0.69]), whereas no such correlation was observed across the within- and between-movie boundary patterns (<italic>t</italic>(14) = 1.26, p=0.23, Cohen’s <italic>d</italic><sub>z</sub> = .32, 95% CI = [–0.26,0.07]). Circles represent individual subjects. Error bars show SEM across subjects. ***p&lt;0.001 against zero. (<bold>B</bold>) PMC pattern correlations across time points around between-movie boundaries during recall and within-movie event boundaries during encoding. The time series of activation patterns were locked to the offset of a movie or a prominent within-movie event. The correlations were first calculated within each subject and then averaged across all subjects. Time zero corresponds to the true stimulus/behavior time, with no shifting for hemodynamic response delay. Areas outlined by black lines indicate correlations that significantly deviate from zero after multiple comparisons correction (Bonferroni corrected p&lt;0.05). No significant positive correlations were observed across encoding and recall immediately following the within- and between-movie boundaries.</p><p><supplementary-material id="fig4s2sdata1"><label>Figure 4—figure supplement 2—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-73693-fig4-figsupp2-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-73693-fig4-figsupp2-v2.tif"/></fig></fig-group><p>Is the generalized between-movie boundary pattern driven by shared low-level perceptual or motoric factors rather than cognitive states? First, shared visual features at between-movie boundaries (i.e., black screen) cannot explain the transient, boundary-specific similarity between encoding and recall phases because visual input was identical across boundary and non-boundary periods during recall (i.e., a fixation dot on black background). Indeed, encoding boundary patterns were more similar to recall boundary patterns than to recall non-boundary patterns in DMN areas, suggesting a limited contribution of shared visual input to the generalized boundary pattern (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>). Likewise, the absence of verbal responses at boundaries cannot explain the boundary pattern generalized across encoding and recall phases as no speech was generated throughout the entire encoding phase. Moreover, PMC boundary patterns showed positive between-phase pattern correlations (<italic>t</italic>(14) = 3.94, p=0.003, Cohen’s <italic>d</italic><sub>z</sub> = 1.25, 95% CI = [0.1,0.36]) greater than those of non-boundary patterns (<italic>t</italic>(14) = 3.22, p=0.011, Cohen’s <italic>d</italic><sub>z</sub> = 1.02, 95% CI of the difference = [0.06,0.36]) even when restricted to boundaries without pauses between recalled movies. We also ruled out the possibility that silence during movie title scenes and pauses at recall boundaries drove the generalized boundary pattern in PMC; the recall boundary pattern was not correlated with the pattern associated with silent periods during encoding (<italic>t</italic>(14) = 1.93, p=0.074, Cohen’s <italic>d</italic><sub>z</sub> = 0.498, 95% CI = [–0.19,0.01]), whereas the auditory cortex showed a positive correlation between the two (<italic>t</italic>(14) = 10.31, p&lt;0.001, Cohen’s <italic>d</italic><sub>z</sub> = 2.66, 95% CI = [0.3,0.45]) (<xref ref-type="fig" rid="fig5">Figure 5</xref>). Likewise, the movies’ audio amplitudes modulated the time course of similarity between the recall boundary pattern and the encoding data in the auditory cortex, but not in PMC (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplements 1</xref> and <xref ref-type="fig" rid="fig5s2">2</xref>).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Examining the effects of silence on the generalized boundary pattern.</title><p>For each subject, we computed a Pearson correlation between the mean activation pattern of the moments of silence during encoding (blue bars) and the mean activation pattern of between-movie boundaries during recall (orange bar) in the posterior medial cortex (PMC) and the auditory cortex (AUD). The moments of silence near between-movie boundaries (i.e., within the first 45 s of each movie) during encoding were excluded from the analysis. PMC and AUD regions of interest are shown as white areas on the inflated surface of template brains. Gray bars on the right panel indicate the mean pattern similarity across subjects. Circles represent individual subjects. Error bars show SEM across subjects. ***p&lt;0.001 against zero.</p><p><supplementary-material id="fig5sdata1"><label>Figure 5—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig5">Figure 5</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-73693-fig5-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-73693-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Time series of audio amplitudes during encoding and the similarity to the recall boundary pattern.</title><p>(<bold>A</bold>) Audio amplitudes of the movie stimuli. The audio amplitudes were convolved with a hemodynamic response function and <italic>z</italic>-scored across time points. (<bold>B</bold>) Posterior medial cortex (PMC) pattern similarity (Pearson correlation) between each volume of encoding data and the template between-movie boundary pattern measured during recall (average of 4.5–19.5 s from the offset of each recalled movie). (<bold>C</bold>) Auditory cortex (AUD) pattern similarity between each volume of encoding data and the template between-movie boundary pattern measured during recall. In (<bold>A</bold>–<bold>C</bold>), the vertical dotted line in the middle indicates the boundary between the two encoding scanning runs. Vertical red lines indicate the offsets of each movie clip. In (<bold>B</bold>) and (<bold>C</bold>), black lines show the mean across subjects. Shaded areas indicate the standard deviation across subjects. Red dots mark time points that showed significantly positive pattern correlations after multiple comparisons correction across time points (Bonferroni corrected p&lt;0.05).</p><p><supplementary-material id="fig5s1sdata1"><label>Figure 5—figure supplement 1—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-73693-fig5-figsupp1-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-73693-fig5-figsupp1-v2.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 2.</label><caption><title>Relationship between audio amplitudes during encoding and the similarity to the recall boundary pattern.</title><p>We computed correlations between the time series of audio amplitudes and the time series of similarity between the recall boundary pattern and each volume of encoding data in the posterior medial cortex (PMC) and the auditory cortex (AUD). Time points within each of the 10 movies after excluding the first 45 s were included in the analysis. PMC correlations were not significantly different from zero (<italic>t</italic>(14) = 1.7, p=0.11, Cohen’s <italic>d</italic><sub>z</sub> = 0.44, 95% CI = [–0.04,0.004]), whereas AUD showed significantly negative correlations (<italic>t</italic>(14) = 18.66, p&lt;0.001, Cohen’s <italic>d</italic><sub>z</sub> = 4.82, 95% CI = [–0.26, –0.21]). Bar graphs show the mean across subjects. Circles represent individual subjects. Error bars show SEM across subjects. ***p&lt;0.001 against zero.</p><p><supplementary-material id="fig5s2sdata1"><label>Figure 5—figure supplement 2—source data 1.</label><caption><title>Source data for <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>.</title></caption><media mime-subtype="xlsx" mimetype="application" xlink:href="elife-73693-fig5-figsupp2-data1-v2.xlsx"/></supplementary-material></p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-73693-fig5-figsupp2-v2.tif"/></fig></fig-group></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>This study investigated brain responses to internally generated boundaries between mental contexts during continuous and unguided memory recall of naturalistic narratives. We found that internally driven mental context boundaries evoke generalized neural activation patterns in core posterior-medial areas of the DMN (<xref ref-type="bibr" rid="bib48">Ritchey and Cooper, 2020</xref>). These cortical patterns were similar to those observed at major boundaries between externally driven contexts (different audiovisual movies), suggesting that they reflect a general cognitive state associated with mental context transitions. However, these between-context patterns were distinct from within-context event boundary detection signals.</p><p>The highly similar neural activation patterns for internally- and externally driven boundaries observed in this study demonstrate event segmentation without changes in external input. This finding diverges from the currently dominant empirical and theoretical perspectives on event segmentation; in most studies, event boundaries are defined or manipulated by changes in perceptual or spatiotemporal features (e.g., <xref ref-type="bibr" rid="bib15">Chen et al., 2017</xref>; <xref ref-type="bibr" rid="bib22">DuBrow and Davachi, 2013</xref>; <xref ref-type="bibr" rid="bib43">Radvansky and Copeland, 2006</xref>), and boundary detection is posited to occur when those changes mismatch our expectations of the current situation (<xref ref-type="bibr" rid="bib67">Zacks et al., 2007</xref>; <xref ref-type="bibr" rid="bib69">Zacks et al., 2011</xref>). This prediction error framework successfully explains various phenomena related to event perception and memory organization (see <xref ref-type="bibr" rid="bib70">Zacks, 2020</xref> for a review); however, evidence has also shown that predicted changes in external features can create boundaries and have similar behavioral effects (<xref ref-type="bibr" rid="bib41">Pettijohn and Radvansky, 2016</xref>; <xref ref-type="bibr" rid="bib50">Schapiro et al., 2013</xref>). To resolve the discrepancy, an alternative theoretical framework has recently proposed that boundaries are perceived when the probability distribution of inferred current situations, rather than observed external features per se, changes from the previous time point (<xref ref-type="bibr" rid="bib51">Shin and DuBrow, 2021</xref>). According to this account, event segmentation can occur when there is no perceptual change or when transitions are already predicted, which may explain the boundary-related neural responses at self-generated transitions between memories during recall in our study.</p><p>The boundary pattern that generalized across internally and externally driven boundaries was most strongly observed in the DMN, in line with earlier findings implicating the DMN in mental context transitions (<xref ref-type="bibr" rid="bib4">Baldassano et al., 2017</xref>; <xref ref-type="bibr" rid="bib19">Crittenden et al., 2015</xref>; <xref ref-type="bibr" rid="bib54">Smith et al., 2018</xref>). Prior studies have shown that the DMN responds to external context transitions, including experimental task switching (<xref ref-type="bibr" rid="bib19">Crittenden et al., 2015</xref>; <xref ref-type="bibr" rid="bib54">Smith et al., 2018</xref>) as well as event boundaries in movie clips (<xref ref-type="bibr" rid="bib47">Reagh et al., 2020</xref>; <xref ref-type="bibr" rid="bib58">Speer et al., 2007</xref>). Considering these findings and the widely known involvement of the DMN in internally oriented cognition (e.g., <xref ref-type="bibr" rid="bib1">Addis et al., 2007</xref>; <xref ref-type="bibr" rid="bib3">Andrews-Hanna et al., 2010</xref>; <xref ref-type="bibr" rid="bib16">Christoff et al., 2009</xref>) together, it has been suggested that the DMN integrates both internal and external information to represent and maintain an abstract mental model of the current situation or state (<xref ref-type="bibr" rid="bib60">Stawarczyk et al., 2021</xref>; <xref ref-type="bibr" rid="bib65">Yeshurun et al., 2021</xref>); located furthest away from sensorimotor areas (<xref ref-type="bibr" rid="bib53">Smallwood et al., 2021</xref>), the DMN integrates information across different modalities (<xref ref-type="bibr" rid="bib8">Bonnici et al., 2016</xref>; <xref ref-type="bibr" rid="bib45">Ramanan et al., 2018</xref>) and over long timescales (<xref ref-type="bibr" rid="bib14">Chang et al., 2021</xref>; <xref ref-type="bibr" rid="bib29">Hasson et al., 2015</xref>). Supporting this idea, neural activation patterns in subregions of the DMN, especially PMC, tend to persist for extended periods of time during naturalistic movie watching, and transitions between these persistent neural states coincide with perceived event boundaries (<xref ref-type="bibr" rid="bib4">Baldassano et al., 2017</xref>; <xref ref-type="bibr" rid="bib27">Geerligs et al., 2021</xref>). Our study extends this finding by identifying a transient, boundary-induced phenomenon, which is a unique and independent state represented in the DMN. That is, at major event boundaries, a temporary boundary state may exist in between the neural patterns representing the two events, rather than one event pattern switching directly to the next.</p><p>Although the boundary-related PMC activation patterns were consistent across internally and externally driven boundaries, they did not generalize across within- and between-movie boundaries. Relatedly, a recent human neurophysiological study (<xref ref-type="bibr" rid="bib71">Zheng et al., 2022</xref>) reported that medial temporal cortex neurons distinguished within- and between-movie boundaries while subjects were watching short video clips; some neurons responded only to between-movie boundaries, whereas a separate group of neurons responded to both types of boundaries. These findings may be in line with the view that event boundaries have a hierarchical structure, with different brain areas along the information pathway reflecting different levels of boundaries, from fine-grained sensory transitions to coarse-grained situational transitions (<xref ref-type="bibr" rid="bib4">Baldassano et al., 2017</xref>; <xref ref-type="bibr" rid="bib14">Chang et al., 2021</xref>; <xref ref-type="bibr" rid="bib27">Geerligs et al., 2021</xref>). However, it is still puzzling that within- and between-movie boundaries in our study produced qualitatively distinct neural patterns within a highest-order area (PMC), even though both categories consisted of prominent boundaries between situations spanning tens of seconds to several minutes. What are the crucial differences between the two levels of boundaries? One important factor might be the presence or absence of inter-event connections. Even the most salient within-movie boundaries still demand some integration of information across events as the events are semantically or causally related, and ultimately constitute a single coherent narrative (<xref ref-type="bibr" rid="bib33">Lee and Chen, 2021</xref>; <xref ref-type="bibr" rid="bib56">Song et al., 2021b</xref>). In contrast, an entire cluster of related events, or the narrative as a whole, might be completely ‘flushed’ at between-movie boundaries; this difference could induce distinct cognitive states at the two levels of boundaries, giving rise to different PMC patterns.</p><p>What is the cognitive state that is generalized across internal- and external boundaries between completely different contexts, but distinct from the state evoked by boundaries within the same context? We speculate that the between-movie boundary state may be a temporary ‘relay’ state that occurs when no one mental model wins the competition to receive full attentional focus following the flushing of the prior mental context. Namely, when one major mental context switches to another, the brain may pass through a transient off-focus (<xref ref-type="bibr" rid="bib39">Mittner et al., 2016</xref>) or mind-blanking (<xref ref-type="bibr" rid="bib40">Mortaheb et al., 2021</xref>; <xref ref-type="bibr" rid="bib63">Ward and Wegner, 2013</xref>) state that is distinct from both processing external stimuli (e.g., movie watching) and engaging in internal thoughts (e.g., memory recall). This account may also explain the difference between within- vs. between-movie boundary patterns: in terms of attentional fluctuation (<xref ref-type="bibr" rid="bib31">Jayakumar et al., 2022</xref>; <xref ref-type="bibr" rid="bib55">Song et al., 2021a</xref>), external attention is enhanced at within-movie event boundaries (<xref ref-type="bibr" rid="bib42">Pradhan and Kumar, 2021</xref>; <xref ref-type="bibr" rid="bib67">Zacks et al., 2007</xref>), whereas the relay state is associated with lapses in attention (<xref ref-type="bibr" rid="bib20">deBettencourt et al., 2018</xref>; <xref ref-type="bibr" rid="bib25">Esterman et al., 2014</xref>). An alternative, but not mutually exclusive, possibility is that the boundary state involves the recruitment of cognitive control to resolve the competition between mental contexts. This idea is based on the observation that the areas showing relatively higher activation at between-movie boundaries overlap with the frontoparietal control network (FPCN; <xref ref-type="bibr" rid="bib62">Vincent et al., 2008</xref>) both during encoding and recall (<xref ref-type="fig" rid="fig1">Figure 1B</xref>, <xref ref-type="video" rid="fig1video2">Figure 1—video 2</xref>). As the FPCN is interdigitated with the DMN and other nearby areas within individual subjects (<xref ref-type="bibr" rid="bib9">Braga and Buckner, 2017</xref>), relative activation of the FPCN may create the stereotyped boundary pattern in higher associative cortices. It is also noteworthy that both of these candidate cognitive states are triggered not by the onset but by the offset of a mental context; the onset would rather signal the resolution of competition between mental contexts, hence the end of those states. This dovetails with our results showing that the generalized boundary pattern appears well before movie onsets, suggesting a major contribution of offset responses.</p><p>In conclusion, we found that internally driven boundaries between memories produce a stereotyped activation pattern in the DMN, potentially reflecting a unique cognitive state associated with the flushing and updating of mental contexts. By demonstrating stimulus-independent event segmentation during continuous and naturalistic recall, our study bridges the gap between the fields of event segmentation and spontaneous internal thoughts (also see <xref ref-type="bibr" rid="bib61">Tseng and Poppenk, 2020</xref>). Without any task demands or external constraints, the mind constantly shifts between different internal contexts (<xref ref-type="bibr" rid="bib44">Raffaelli et al., 2021</xref>; <xref ref-type="bibr" rid="bib59">Sripada and Taxali, 2020</xref>). What are the characteristics of neural responses to different types of spontaneous mental context boundaries (e.g., between two different memories, between external attention and future thinking)? Is the boundary pattern observed in this study further generalizable to mental context transitions even more stark than between-movie transitions in our experiment? Are there specific neural signatures that predict subsequent thought transitions? Future work will explore answers to these questions by employing neuroimaging methods with behavioral paradigms that explicitly and continuously track the unconstrained flow of thoughts in naturalistic settings.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>Here, we provide a selective overview of procedures and analysis methods. More detailed descriptions of participants, stimuli, experimental procedures, fMRI data acquisition, and preprocessing can be found in <xref ref-type="bibr" rid="bib33">Lee and Chen, 2021</xref>.</p><sec id="s4-1"><title>Participants</title><p>Twenty-one subjects (12 females) between the ages of 20 and 33 participated in the study. Informed consent was obtained in accordance with procedures approved by the Princeton University Institutional Review Board (protocol #5516). Six subjects were excluded from analyses due to excessive motion.</p></sec><sec id="s4-2"><title>Stimuli</title><p>Ten audiovisual movies (range 2.15–7.75 min) were used in the experiment. The movies varied in format (animation, live-action) and content. Each movie clip was prepended with a title scene where the movie title in white letters faded in and out at the center of the black screen. The movie title was shown approximately for 3 s of the 6-s-long title scene. At the beginning of each scanning run, a 39-s-long audiovisual introductory cartoon was played before the movie stimuli. The introductory cartoon was excluded from analyses.</p></sec><sec id="s4-3"><title>Experimental procedures</title><p>The experiment consisted of two phases, encoding and free spoken recall (<xref ref-type="fig" rid="fig1">Figure 1A</xref>), both performed inside the MRI scanner. In the encoding phase, subjects watched a series of 10 short movies. Subjects were instructed to pay attention to the movies, and no behavioral responses were required. There were two scanning runs, and subjects watched five movies in each run. Stimulus presentation began 3 s after the first volume of each run. In the free spoken recall phase, subjects were instructed to verbally recount what they remembered from the movies, regardless of the order of presentation. Subjects were encouraged to describe their memory in their own words in as much detail as possible. A white dot was presented in the center of the black screen during the free spoken recall phase, though subjects were not required to fixate. The recall phase consisted of two scanning runs in 4 of the 15 subjects included in the analysis. The other subjects had a single scanning run. Subjects’ recall speech was audio-recorded using an MR-compatible noise-canceling microphone and then manually transcribed. The recall transcripts were also timestamped to identify the onset and offset of the description of each movie (there were no intrusions across movies during recall).</p></sec><sec id="s4-4"><title>fMRI acquisition and preprocessing</title><p>Imaging data were collected on a 3 T Siemens Prisma scanner at Princeton Neuroscience Institute. Functional images were acquired using a T2*- weighted multiband accelerated echo-planar imaging sequence (TR = 1.5 s; TE = 39 ms; flip angle = 50°; acceleration factor = 4; 60 slices; 2 × 2 × 2 mm<sup>3</sup>). Whole-brain anatomical images and fieldmap images were also acquired. Functional images were motion-corrected and unwarped using FSL, and then coregistered to the anatomical image, resampled to the fsaverage6 cortical surface, and smoothed (FWHM 4 mm) using FreeSurfer Functional Analysis Stream. The smoothed data were also high-pass filtered (cutoff = 140 s) and z-scored within each scanning run. The first five volumes of encoding scanning runs and the first three volumes of free spoken recall scanning runs were excluded from analyses.</p></sec><sec id="s4-5"><title>Cortical parcellation and region of interest (ROI) definition</title><p>For whole-brain pattern similarity analysis, we used an atlas (<xref ref-type="bibr" rid="bib49">Schaefer et al., 2018</xref>) that divided the cortical surface into 400 parcels (200 parcels per hemisphere) based on functional connectivity patterns (17 networks version). For ROI analyses, we defined the bilateral PMC by combining the parcels corresponding to the precuneus and posterior cingulate cortex within Default Network A as in our prior study (<xref ref-type="bibr" rid="bib33">Lee and Chen, 2021</xref>). The precuneus and posterior cingulate cortex together spanned the area that showed the strongest content-and task-general boundary patterns in the whole-brain analysis (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). The bilateral angular gyrus ROI consisted of the parcels corresponding to the inferior parietal cortex within Default Network A, B, and C. The bilateral auditory cortex ROI was defined by combining the parcels corresponding to the primary and secondary auditory cortices within Somatomotor Network B.</p></sec><sec id="s4-6"><title>Univariate activation analysis</title><p>We performed whole-brain univariate activation analysis to identify brain areas that show activation changes at between-movie boundaries compared to non-boundary periods during recall (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). The boundary periods were the first 15 s following the offset of each recalled movie, and the non-boundary periods were the 15 s in the middle of each recalled movie. Both boundary and non-boundary period time windows were shifted forward by 4.5 s to account for the hemodynamic response delay. We used a relatively long 15 s duration for the boundary and non-boundary periods to capture most of the boundary-related signals during recall, based on exploratory analyses that examined the time courses of univariate boundary responses (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>) and boundary-triggered activation patterns (<xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4D</xref>). For each vertex in each subject’s brain, we computed the mean boundary activation by first averaging preprocessed BOLD signals across time points within each boundary period, and then across all recalled movies. Likewise, we computed the mean non-boundary activation for each subject and vertex by first averaging preprocessed BOLD signals across time points within each non-boundary period, and then across all recalled movies. We then computed the difference between the boundary and non-boundary activation for each subject. Finally, we performed a group-level one-sample <italic>t</italic>-test against zero (two-tailed). The Benjamini–Hochberg procedure (false discovery rate <italic>q</italic> &lt; 0.05) was applied to correct for multiple comparisons across vertices on the resulting whole-brain statistical parametric map.</p></sec><sec id="s4-7"><title>Pattern similarity analysis</title><p>We performed whole-brain pattern similarity analysis (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) to identify brain areas that showed content-and task-general neural activation patterns associated with between-movie boundaries. For each cortical parcel of each subject’s brain, we extracted boundary and non-boundary activation patterns for each movie, separately for the encoding phase and the recall phase. Boundary patterns were generated by averaging the spatial patterns of activation within the boundary period (the first 15 s following the offset) of each watched or recalled movie. Non-boundary patterns were generated by averaging spatial patterns within the non-boundary period (the middle 15 s) of each watched or recalled movie. Again, both boundary and non-boundary time windows were shifted forward by 4.5 s to account for the hemodynamic response delay. We then computed Pearson correlation coefficients between the patterns within and across different movies, conditions (boundary, non-boundary), and experimental phases.</p><p>Using the resulting correlation matrix (see <xref ref-type="fig" rid="fig3">Figure 3A</xref> for an example) for each parcel, we first identified brain areas that showed boundary patterns that were consistent <italic>across recalled movies</italic> (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). For each subject’s recall phase, we computed the mean of all pairwise between-movie correlations, separately for the boundary patterns and the non-boundary patterns. We then performed a group-level two-tailed one-sample <italic>t</italic>-test against zero on the mean boundary pattern correlations to test whether the boundary pattern similarity was overall positive. We also performed a group-level two-tailed paired-samples <italic>t</italic>-test between the mean boundary vs. non-boundary pattern correlations to test whether the boundary pattern similarity was greater than the non-boundary pattern similarity. Each of the resulting whole-brain statistical parametric maps was corrected for multiple comparisons across parcels using the Bonferroni method. Finally, we identified parcels that showed significant effects in both tests after the correction by masking the areas that showed higher pattern similarity for the boundary than non-boundary conditions with the areas that showed overall positive similarity between boundary patterns (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Thus, the identified parcels showed spatially similar activation patterns across different movies at recall boundaries, and the patterns were specifically associated with boundary periods only. Likewise, we identified brain areas that showed boundary patterns that were consistent <italic>across the encoding and recall phases</italic> as well as across movies (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). This was achieved by repeating the identical analysis procedures using the boundary and non-boundary pattern correlations computed across the encoding and recall phases, instead of using the correlations computed within the recall phase.</p><p>We also performed the same pattern similarity analysis in the PMC (<xref ref-type="fig" rid="fig3">Figure 3</xref>) and angular gyrus (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>) ROIs, as done for an individual cortical parcel in the whole-brain analysis. In addition, we repeated the same analyses using shorter (4.5 s) boundary and non-boundary period time windows and obtained similar results (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>, <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>).</p></sec><sec id="s4-8"><title>Comparing the onset- and offset-locked boundary patterns</title><p>To test whether the consistent activation patterns associated with between-movie boundaries were evoked by the onset or offset of a movie, we examined TR-by-TR pattern correlations across time points around the boundaries. The time points were locked to either the onset or the offset of (1) each video clip (excluding the title scene) or (2) recall of each movie. For each subject and ROI, we extracted the time series of activation patterns from 30 s before to 60 s after the onset/offset of each watched or recalled movie. We averaged the time series across movies to create a single time series of boundary-related activation patterns per experimental phase. We then computed Pearson correlation coefficients across different time points in the time series of mean activation patterns within each experimental phase (i.e., encoding-encoding and recall-recall correlation; <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>) or between phases (i.e., encoding-recall correlation; <xref ref-type="fig" rid="fig3">Figure 3D</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2D</xref>). Finally, we performed two-tailed one-sample <italic>t</italic>-tests against zero on each cell of the time–time correlation matrices from all subjects to identify the time points at which significantly positive or negative pattern correlations appeared. Bonferroni correction was applied to correct for multiple comparisons across all cells in the time–time correlation matrix.</p></sec><sec id="s4-9"><title>Comparing the between-movie and within-movie boundary patterns</title><p>To test whether the recall activation patterns evoked by between-movie boundaries were similar to encoding activation patterns evoked by event boundaries within a movie, we identified the strongest event boundaries within each movie. We utilized the fine-grained event boundaries defined in our previous study (<xref ref-type="bibr" rid="bib33">Lee and Chen, 2021</xref>), which divided the 10 movie stimuli into 202 events excluding title scenes (mean duration = 13.5 s, range 2–42 s). We had four independent coders watch the movie stimuli and then choose which of the fine-grained event boundaries were the most important. The coders were instructed to select the boundaries such that the 10 movies were divided into 60 ± 10 events excluding title scenes. Of these, 25 event boundaries were identified as important by all four coders, which resulted in 27 ‘coarse’ events in total (ranging between 1 and 5 events per movie; mean duration = 100.9 s, range 21–417 s). To mitigate the possibility of carryover effects from the between-movie boundaries, within-movie event boundaries that occurred within the first 45 s of each movie clip were excluded from the analysis, leaving 15 within-movie event boundaries in total.</p><p>We first examined whether there were consistent activation patterns following the within-movie event boundaries distinct from non-boundary patterns (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). For each subject, we generated the mean PMC activation pattern for each within-movie boundary by averaging patterns from 4.5 to 19.5 s following the within-movie boundary during encoding. We then computed pairwise between-movie Pearson correlations across the within-movie boundary patterns and averaged the correlations. A two-tailed one-sample <italic>t</italic>-test against zero was performed to test whether the similarity between the within-movie boundary patterns was overall positive. We also computed pairwise between-movie correlations across the within-movie boundary patterns and non-boundary patterns during encoding. The non-boundary pattern for each movie was generated by averaging activation patterns within the middle 15 s of the movie (time window shifted forward by 4.5 s). A two-tailed paired-samples <italic>t</italic>-test was performed to test whether the similarity between within-movie boundary patterns was greater than the similarity between within-movie boundary patterns and non-boundary patterns. Two of the non-boundary periods partially overlapped with the within-movie boundary periods by 13.5 and 4.5 s, respectively, and were excluded when correlating within-movie boundary patterns and non-boundary patterns. Note that the two non-boundary periods were included in other analyses in this study comparing between-movie boundary patterns and non-boundary patterns. However, excluding or including the two non-boundary periods did not significantly change any of the mean pairwise between-movie correlations across (1) encoding non-boundary patterns, (2) encoding non-boundary and between-movie boundary patterns, (3) encoding non-boundary and recall non-boundary patterns, and (4) encoding non-boundary and recall between-movie boundary patterns in PMC (two-tailed paired-samples <italic>t</italic>-tests, all <italic>t</italic>(14)s &lt; 1.45, all ps&gt;0.17).</p><p>We next compared the template activation pattern at the within-movie event boundaries to the pattern at between-movie boundaries (<xref ref-type="fig" rid="fig4">Figure 4</xref>). For each subject, we generated the mean within-movie event boundary pattern of PMC by averaging activation patterns from 4.5 to 19.5 s following each of the 15 event boundaries during encoding. The patterns were first averaged across all time points within each boundary period time window and then across different boundaries. Likewise, the mean between-movie boundary pattern was generated by averaging all activation patterns from 4.5 to 19.5 s following the offset of each movie during encoding or recall. We then computed a Pearson correlation coefficient across the mean within-movie event boundary pattern and the mean encoding or recall between-movie boundary pattern. For comparison, we computed a correlation across the encoding and recall mean between-movie boundary patterns. A two-tailed one-sample <italic>t</italic>-test against zero was performed to test whether the group-level similarity between the two patterns was positive. We also repeated the same pattern similarity analysis using shorter (4.5 s) time windows for the boundary periods, from 4.5 to 9 s following the within- or between-movie boundaries (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2A</xref>).</p><p>To explore the temporal unfolding of the similarity between the within- and between-movie boundary patterns, we additionally examined the between-phase TR-by-TR pattern similarity across individual time points around the boundaries (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2B</xref>). For each subject, we extracted the PMC activation pattern time series from 30 s before to 60 s after (1) each within-movie event boundary during encoding and (2) the offset of each movie during recall. The time series were averaged across boundaries within each experimental phase. We then computed Pearson correlation coefficients across different time points in the activation pattern time series between the encoding and recall phases. Finally, we performed two-tailed one-sample <italic>t</italic>-tests against zero on each cell of the time–time correlation matrices from all subjects to identify the time points at which significantly positive or negative pattern correlations appeared. Bonferroni correction was applied to correct for multiple comparisons across cells.</p></sec><sec id="s4-10"><title>Testing the effect of visual features</title><p>Between-movie boundary periods during encoding and those during recall shared low-level visual features (i.e., mostly blank black screen). To test whether the similar visual features produced similar activation patterns at between-movie boundaries across phases, we performed a whole-brain pattern similarity analysis (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplement 2</xref>). For each subject and cortical parcel, we computed the mean boundary and non-boundary activation patterns for each movie, separately for encoding and recall. The boundary periods were defined as the first 15 s following the offset of each watched or recalled movie. The non-boundary periods were defined as the middle 15 s of each movie. Both boundary and non-boundary time windows were shifted forward by 4.5 s. We then computed Pearson correlations between encoding boundary patterns and recall boundary patterns across different movies, and averaged all the correlations. Likewise, we computed the average correlation between boundary patterns during encoding and non-boundary patterns during recall across different movies. A group-level two-tailed paired-samples <italic>t</italic>-test was performed to test whether the similarity between encoding and recall boundary patterns was greater than the similarity between encoding boundary patterns and recall non-boundary patterns, even though boundary and non-boundary patterns were visually identical during recall. The resulting whole-brain map was corrected for multiple comparisons across parcels using the Bonferroni method.</p></sec><sec id="s4-11"><title>Testing the effect of audio amplitudes</title><p>Brief periods of silence were present at transitions between movies during both encoding and recall. During encoding, the 6 s title period between movies was silent. During recall, subjects often paused speaking for several seconds between recall of different movies. We tested whether the between-movie boundary patterns were associated with the absence of sound in general, as opposed to between-movie transitions specifically.</p><p>We first compared the activation pattern associated with any silent periods within movies during encoding and the activation pattern evoked by between-movie boundaries during recall (<xref ref-type="fig" rid="fig5">Figure 5</xref>). To identify all periods of silence within the movies, we extracted the audio amplitudes of the movie clips (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1A</xref>) by applying a Hilbert transform to the single-channel audio signals (44.1 kHz). The audio amplitudes were downsampled to match the temporal resolution of fMRI data (TR = 1.5 s), convolved with a double-gamma hemodynamic response function, and <italic>z</italic>-scored across time points. The periods of silence were defined as the within-movie time points (again excluding the first 45 s of each movie) whose audio amplitudes were equal to or lower than the mean amplitude of the time points corresponding to the silent between-movie title periods. For each subject and ROI, we averaged the activation patterns across all time points within these within-movie silent time periods to produce the mean activation pattern associated with the absence of sound. The mean pattern was then correlated with the template between-movie boundary pattern produced by averaging 4.5–19.5 s following the offset of each movie during recall. A two-tailed one-sample <italic>t</italic>-test was performed to compare the group-level correlation coefficients against zero.</p><p>We additionally tested whether the time course of audio amplitude was correlated with the time course of pattern similarity (Pearson correlation) between the recall phase between-movie boundary pattern and each time point of the encoding phase data (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1B and C</xref>, <xref ref-type="fig" rid="fig5s2">Figure 5—figure supplement 2</xref>). The time courses were generated for all time points within each movie, excluding the first 45 s of each movie. We first computed each subject’s Pearson correlation coefficient between the two types of time courses. We then performed a group-level one-sample <italic>t</italic>-test against zero (two-tailed).</p></sec><sec id="s4-12"><title>Citation diversity statement</title><p>Recent work in several fields of science has identified a bias in citation practices such that papers from women and other minority scholars are under-cited relative to the number of such papers in the field (<xref ref-type="bibr" rid="bib13">Caplar et al., 2017</xref>; <xref ref-type="bibr" rid="bib21">Dion et al., 2018</xref>; <xref ref-type="bibr" rid="bib24">Dworkin et al., 2020</xref>; <xref ref-type="bibr" rid="bib34">Maliniak et al., 2013</xref>; <xref ref-type="bibr" rid="bib38">Mitchell et al., 2013</xref>). Here, we sought to proactively consider choosing references that reflect the diversity of the field in thought, form of contribution, gender, race, ethnicity, and other factors. First, we obtained the predicted gender of the first and last author of each reference by using databases that store the probability of a first name being carried by a woman (<xref ref-type="bibr" rid="bib24">Dworkin et al., 2020</xref>; <xref ref-type="bibr" rid="bib72">Zhou et al., 2020</xref>). By this measure (and excluding self-citations to the first and last authors of this article), our references contain 14.52% women (first)/women (last), 16.13% men/women, 31.26% women/men, and 38.09% men/men. This method is limited in that (a) names, pronouns, and social media profiles used to construct the databases may not, in every case, be indicative of gender identity and (b) it cannot account for intersex, non-binary, or transgender people. Second, we obtained predicted racial/ethnic category of the first and last author of each reference by databases that store the probability of a first and last name being carried by an author of color (<xref ref-type="bibr" rid="bib2">Ambekar et al., 2009</xref>; <xref ref-type="bibr" rid="bib57">Sood and Laohaprapanon, 2018</xref>). By this measure (and excluding self-citations), our references contain 7.21% author of color (first)/author of color (last), 14.37% white author/author of color, 23.51% author of color/white author, and 54.91% white author/white author. This method is limited in that (a) names, Census entries, and Wikipedia profiles used to make the predictions may not be indicative of racial/ethnic identity, and (b) it cannot account for indigenous and mixed-race authors, or those who may face differential biases due to the ambiguous racialization or ethnicization of their names. We look forward to future work that could help us to better understand how to support equitable practices in science.</p></sec></sec></body><back><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Methodology, Project administration, Software, Visualization, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Funding acquisition, Investigation, Project administration, Resources, Supervision, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Informed consent was obtained in accordance with procedures approved by the Princeton University Institutional Review Board (Protocol #5516).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-73693-transrepform1-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>The raw neuroimaging and behavioral data analyzed in the current study are publicly available via OpenNeuro (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.18112/openneuro.ds004042.v1.0.0">https://doi.org/10.18112/openneuro.ds004042.v1.0.0</ext-link>). Source data files have been provided for Figure 1-figure supplement 3, Figure 3, Figure 3-figure supplements 2, 3, &amp; 4, Figure 4, Figure 4-figure supplements 1 &amp; 2, Figure 5, and Figure 5-figure supplements 1 &amp; 2.</p><p>The following previously published dataset was used:</p><p><element-citation id="dataset1" publication-type="data" specific-use="references"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>H</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>FilmFestival</data-title><source>OpenNeuro</source><pub-id pub-id-type="doi">10.18112/openneuro.ds004042.v1.0.0</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Sarah DuBrow, Christopher J Honey, and Megan T deBettencourt for comments on earlier versions of the manuscript. We also thank Yiyuan Zhang for assisting with within-movie event boundary identification. This work was supported by the Sloan Research Fellowship (JC) and Google Faculty Research Award (JC).</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Addis</surname><given-names>DR</given-names></name><name><surname>Wong</surname><given-names>AT</given-names></name><name><surname>Schacter</surname><given-names>DL</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Remembering the past and imagining the future: common and distinct neural substrates during event construction and elaboration</article-title><source>Neuropsychologia</source><volume>45</volume><fpage>1363</fpage><lpage>1377</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2006.10.016</pub-id><pub-id pub-id-type="pmid">17126370</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ambekar</surname><given-names>A</given-names></name><name><surname>Ward</surname><given-names>C</given-names></name><name><surname>Mohammed</surname><given-names>J</given-names></name><name><surname>Male</surname><given-names>S</given-names></name><name><surname>Skiena</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Name-ethnicity classification from open sources</article-title><conf-name>the 15th ACM SIGKDD international conference</conf-name><fpage>49</fpage><lpage>58</lpage><pub-id pub-id-type="doi">10.1145/1557019.1557032</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andrews-Hanna</surname><given-names>JR</given-names></name><name><surname>Reidler</surname><given-names>JS</given-names></name><name><surname>Sepulcre</surname><given-names>J</given-names></name><name><surname>Poulin</surname><given-names>R</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Functional-anatomic fractionation of the brain’s default network</article-title><source>Neuron</source><volume>65</volume><fpage>550</fpage><lpage>562</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.02.005</pub-id><pub-id pub-id-type="pmid">20188659</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baldassano</surname><given-names>C</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Zadbood</surname><given-names>A</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Discovering Event Structure in Continuous Narrative Perception and Memory</article-title><source>Neuron</source><volume>95</volume><fpage>709</fpage><lpage>721</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.041</pub-id><pub-id pub-id-type="pmid">28772125</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ben-Yakov</surname><given-names>A</given-names></name><name><surname>Dudai</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Constructing realistic engrams: poststimulus activity of hippocampus and dorsal striatum predicts subsequent episodic memory</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>9032</fpage><lpage>9042</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0702-11.2011</pub-id><pub-id pub-id-type="pmid">21677186</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ben-Yakov</surname><given-names>A</given-names></name><name><surname>Eshel</surname><given-names>N</given-names></name><name><surname>Dudai</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Hippocampal immediate poststimulus activity in the encoding of consecutive naturalistic episodes</article-title><source>Journal of Experimental Psychology. General</source><volume>142</volume><fpage>1255</fpage><lpage>1263</lpage><pub-id pub-id-type="doi">10.1037/a0033558</pub-id><pub-id pub-id-type="pmid">23815458</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ben-Yakov</surname><given-names>A</given-names></name><name><surname>Henson</surname><given-names>RN</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The Hippocampal Film Editor: Sensitivity and Specificity to Event Boundaries in Continuous Experience</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>10057</fpage><lpage>10068</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0524-18.2018</pub-id><pub-id pub-id-type="pmid">30301758</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonnici</surname><given-names>HM</given-names></name><name><surname>Richter</surname><given-names>FR</given-names></name><name><surname>Yazar</surname><given-names>Y</given-names></name><name><surname>Simons</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Multimodal Feature Integration in the Angular Gyrus during Episodic and Semantic Retrieval</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>5462</fpage><lpage>5471</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4310-15.2016</pub-id><pub-id pub-id-type="pmid">27194327</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braga</surname><given-names>RM</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Parallel Interdigitated Distributed Networks within the Individual Estimated by Intrinsic Functional Connectivity</article-title><source>Neuron</source><volume>95</volume><fpage>457</fpage><lpage>471</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.038</pub-id><pub-id pub-id-type="pmid">28728026</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunec</surname><given-names>IK</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name><name><surname>Barense</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Boundaries Shape Cognitive Representations of Spaces and Events</article-title><source>Trends in Cognitive Sciences</source><volume>22</volume><fpage>637</fpage><lpage>650</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.03.013</pub-id><pub-id pub-id-type="pmid">29706557</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buckner</surname><given-names>RL</given-names></name><name><surname>DiNicola</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The brain’s default network: updated anatomy, physiology and evolving insights</article-title><source>Nature Reviews. Neuroscience</source><volume>20</volume><fpage>593</fpage><lpage>608</lpage><pub-id pub-id-type="doi">10.1038/s41583-019-0212-7</pub-id><pub-id pub-id-type="pmid">31492945</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bulkin</surname><given-names>DA</given-names></name><name><surname>Sinclair</surname><given-names>DG</given-names></name><name><surname>Law</surname><given-names>LM</given-names></name><name><surname>Smith</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Hippocampal state transitions at the boundaries between trial epochs</article-title><source>Hippocampus</source><volume>30</volume><fpage>582</fpage><lpage>595</lpage><pub-id pub-id-type="doi">10.1002/hipo.23180</pub-id><pub-id pub-id-type="pmid">31793687</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caplar</surname><given-names>N</given-names></name><name><surname>Tacchella</surname><given-names>S</given-names></name><name><surname>Birrer</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Quantitative evaluation of gender bias in astronomical publications from citation counts</article-title><source>Nature Astronomy</source><volume>1</volume><fpage>1</fpage><lpage>5</lpage><pub-id pub-id-type="doi">10.1038/s41550-017-0141</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>CHC</given-names></name><name><surname>Nastase</surname><given-names>SA</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Information Flow across the Cortical Timescales Hierarchy during Narrative Construction</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.12.01.470825</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Leong</surname><given-names>YC</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name><name><surname>Yong</surname><given-names>CH</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Shared memories reveal shared structure in neural activity across individuals</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>115</fpage><lpage>125</lpage><pub-id pub-id-type="doi">10.1038/nn.4450</pub-id><pub-id pub-id-type="pmid">27918531</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christoff</surname><given-names>K</given-names></name><name><surname>Gordon</surname><given-names>AM</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Smith</surname><given-names>R</given-names></name><name><surname>Schooler</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Experience sampling during fMRI reveals default network and executive system contributions to mind wandering</article-title><source>PNAS</source><volume>106</volume><fpage>8719</fpage><lpage>8724</lpage><pub-id pub-id-type="doi">10.1073/pnas.0900234106</pub-id><pub-id pub-id-type="pmid">19433790</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christoff</surname><given-names>K</given-names></name><name><surname>Irving</surname><given-names>ZC</given-names></name><name><surname>Fox</surname><given-names>KCR</given-names></name><name><surname>Spreng</surname><given-names>RN</given-names></name><name><surname>Andrews-Hanna</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Mind-wandering as spontaneous thought: A dynamic framework</article-title><source>Nature Reviews. Neuroscience</source><volume>17</volume><fpage>718</fpage><lpage>731</lpage><pub-id pub-id-type="doi">10.1038/nrn.2016.113</pub-id><pub-id pub-id-type="pmid">27654862</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Clewett</surname><given-names>D</given-names></name><name><surname>DuBrow</surname><given-names>S</given-names></name><name><surname>Davachi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Transcending time in the brain: How event memories are constructed from experience</article-title><source>Hippocampus</source><volume>29</volume><fpage>162</fpage><lpage>183</lpage><pub-id pub-id-type="doi">10.1002/hipo.23074</pub-id><pub-id pub-id-type="pmid">30734391</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crittenden</surname><given-names>BM</given-names></name><name><surname>Mitchell</surname><given-names>DJ</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Recruitment of the default mode network during a demanding act of executive control</article-title><source>eLife</source><volume>4</volume><elocation-id>e06481</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.06481</pub-id><pub-id pub-id-type="pmid">25866927</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>deBettencourt</surname><given-names>MT</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Forgetting from lapses of sustained attention</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>25</volume><fpage>605</fpage><lpage>611</lpage><pub-id pub-id-type="doi">10.3758/s13423-017-1309-5</pub-id><pub-id pub-id-type="pmid">28585055</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dion</surname><given-names>ML</given-names></name><name><surname>Sumner</surname><given-names>JL</given-names></name><name><surname>Mitchell</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Gendered Citation Patterns across Political Science and Social Science Methodology Fields</article-title><source>Political Analysis</source><volume>26</volume><fpage>312</fpage><lpage>327</lpage><pub-id pub-id-type="doi">10.1017/pan.2018.12</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DuBrow</surname><given-names>S</given-names></name><name><surname>Davachi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The influence of context boundaries on memory for the sequential order of events</article-title><source>Journal of Experimental Psychology. General</source><volume>142</volume><fpage>1277</fpage><lpage>1286</lpage><pub-id pub-id-type="doi">10.1037/a0034024</pub-id><pub-id pub-id-type="pmid">23957281</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DuBrow</surname><given-names>S</given-names></name><name><surname>Rouhani</surname><given-names>N</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Does mental context drift or shift?</article-title><source>Current Opinion in Behavioral Sciences</source><volume>17</volume><fpage>141</fpage><lpage>146</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2017.08.003</pub-id><pub-id pub-id-type="pmid">29335678</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dworkin</surname><given-names>JD</given-names></name><name><surname>Linn</surname><given-names>KA</given-names></name><name><surname>Teich</surname><given-names>EG</given-names></name><name><surname>Zurn</surname><given-names>P</given-names></name><name><surname>Shinohara</surname><given-names>RT</given-names></name><name><surname>Bassett</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The extent and drivers of gender imbalance in neuroscience reference lists</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>918</fpage><lpage>926</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-0658-y</pub-id><pub-id pub-id-type="pmid">32561883</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Esterman</surname><given-names>M</given-names></name><name><surname>Rosenberg</surname><given-names>MD</given-names></name><name><surname>Noonan</surname><given-names>SK</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Intrinsic fluctuations in sustained attention and distractor processing</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>1724</fpage><lpage>1730</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2658-13.2014</pub-id><pub-id pub-id-type="pmid">24478354</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fox</surname><given-names>MD</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Barch</surname><given-names>DM</given-names></name><name><surname>Gusnard</surname><given-names>DA</given-names></name><name><surname>Raichle</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Transient BOLD responses at block transitions</article-title><source>NeuroImage</source><volume>28</volume><fpage>956</fpage><lpage>966</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2005.06.025</pub-id><pub-id pub-id-type="pmid">16043368</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Geerligs</surname><given-names>L</given-names></name><name><surname>Gözükara</surname><given-names>D</given-names></name><name><surname>Oetringer</surname><given-names>D</given-names></name><name><surname>Campbell</surname><given-names>K</given-names></name><name><surname>van Gerven</surname><given-names>M</given-names></name><name><surname>Güçlü</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A Partially Nested Cortical Hierarchy of Neural States Underlies Event Segmentation in the Human Brain</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.02.05.429165</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Neuromodulation and cortical function: modeling the physiological basis of behavior</article-title><source>Behavioural Brain Research</source><volume>67</volume><fpage>1</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1016/0166-4328(94)00113-t</pub-id><pub-id pub-id-type="pmid">7748496</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name><name><surname>Honey</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Hierarchical process memory: memory as an integral component of information processing</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>304</fpage><lpage>313</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.04.006</pub-id><pub-id pub-id-type="pmid">25980649</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Honey</surname><given-names>CJ</given-names></name><name><surname>Newman</surname><given-names>EL</given-names></name><name><surname>Schapiro</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Switching between internal and external modes: A multiscale learning principle</article-title><source>Network Neuroscience (Cambridge, Mass.)</source><volume>1</volume><fpage>339</fpage><lpage>356</lpage><pub-id pub-id-type="doi">10.1162/NETN_a_00024</pub-id><pub-id pub-id-type="pmid">30090870</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Jayakumar</surname><given-names>M</given-names></name><name><surname>Balusu</surname><given-names>C</given-names></name><name><surname>Aly</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Attentional Fluctuations and the Temporal Organization of Memory</article-title><source>PsyArXiv</source><pub-id pub-id-type="doi">10.31234/osf.io/j32bn</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karapanagiotidis</surname><given-names>T</given-names></name><name><surname>Vidaurre</surname><given-names>D</given-names></name><name><surname>Quinn</surname><given-names>AJ</given-names></name><name><surname>Vatansever</surname><given-names>D</given-names></name><name><surname>Poerio</surname><given-names>GL</given-names></name><name><surname>Turnbull</surname><given-names>A</given-names></name><name><surname>Ho</surname><given-names>NSP</given-names></name><name><surname>Leech</surname><given-names>R</given-names></name><name><surname>Bernhardt</surname><given-names>BC</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The psychological correlates of distinct neural states occurring during wakeful rest</article-title><source>Scientific Reports</source><volume>10</volume><elocation-id>21121</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-020-77336-z</pub-id><pub-id pub-id-type="pmid">33273566</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>H</given-names></name><name><surname>Chen</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Predicting Memory from the Network Structure of Naturalistic Events</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.04.24.441287</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maliniak</surname><given-names>D</given-names></name><name><surname>Powers</surname><given-names>R</given-names></name><name><surname>Walter</surname><given-names>BF</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The Gender Citation Gap in International Relations</article-title><source>International Organization</source><volume>67</volume><fpage>889</fpage><lpage>922</lpage><pub-id pub-id-type="doi">10.1017/S0020818313000209</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manning</surname><given-names>JR</given-names></name><name><surname>Hulbert</surname><given-names>JC</given-names></name><name><surname>Williams</surname><given-names>J</given-names></name><name><surname>Piloto</surname><given-names>L</given-names></name><name><surname>Sahakyan</surname><given-names>L</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A neural signature of contextually mediated intentional forgetting</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>23</volume><fpage>1534</fpage><lpage>1542</lpage><pub-id pub-id-type="doi">10.3758/s13423-016-1024-7</pub-id><pub-id pub-id-type="pmid">27150815</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Medvedeva</surname><given-names>A</given-names></name><name><surname>Saw</surname><given-names>R</given-names></name><name><surname>Silvestri</surname><given-names>C</given-names></name><name><surname>Sirota</surname><given-names>M</given-names></name><name><surname>Fuggetta</surname><given-names>G</given-names></name><name><surname>Galli</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Offset-related brain activity in the left ventrolateral prefrontal cortex promotes long-term memory formation of verbal events</article-title><source>Brain Stimulation</source><volume>14</volume><fpage>564</fpage><lpage>570</lpage><pub-id pub-id-type="doi">10.1016/j.brs.2021.03.002</pub-id><pub-id pub-id-type="pmid">33722660</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mildner</surname><given-names>JN</given-names></name><name><surname>Tamir</surname><given-names>DI</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Spontaneous Thought as an Unconstrained Memory Process</article-title><source>Trends in Neurosciences</source><volume>42</volume><fpage>763</fpage><lpage>777</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2019.09.001</pub-id><pub-id pub-id-type="pmid">31627848</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitchell</surname><given-names>SM</given-names></name><name><surname>Lange</surname><given-names>S</given-names></name><name><surname>Brus</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Gendered Citation Patterns in International Relations Journals</article-title><source>International Studies Perspectives</source><volume>14</volume><fpage>485</fpage><lpage>492</lpage><pub-id pub-id-type="doi">10.1111/insp.12026</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mittner</surname><given-names>M</given-names></name><name><surname>Hawkins</surname><given-names>GE</given-names></name><name><surname>Boekel</surname><given-names>W</given-names></name><name><surname>Forstmann</surname><given-names>BU</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A Neural Model of Mind Wandering</article-title><source>Trends in Cognitive Sciences</source><volume>20</volume><fpage>570</fpage><lpage>578</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2016.06.004</pub-id><pub-id pub-id-type="pmid">27353574</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Mortaheb</surname><given-names>S</given-names></name><name><surname>Van Calster</surname><given-names>L</given-names></name><name><surname>Raimondo</surname><given-names>F</given-names></name><name><surname>Klados</surname><given-names>MA</given-names></name><name><surname>Boulakis</surname><given-names>PA</given-names></name><name><surname>Georgoula</surname><given-names>K</given-names></name><name><surname>Majerus</surname><given-names>S</given-names></name><name><surname>Van De Ville</surname><given-names>D</given-names></name><name><surname>Demertzi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Mind Blanking Is a Distinct Mental State Linked to a Recurrent Brain Profile of Globally Positive Connectivity during Ongoing Mentation</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.05.10.443428</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pettijohn</surname><given-names>KA</given-names></name><name><surname>Radvansky</surname><given-names>GA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Narrative event boundaries, reading times, and expectation</article-title><source>Memory &amp; Cognition</source><volume>44</volume><fpage>1064</fpage><lpage>1075</lpage><pub-id pub-id-type="doi">10.3758/s13421-016-0619-6</pub-id><pub-id pub-id-type="pmid">27170375</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pradhan</surname><given-names>R</given-names></name><name><surname>Kumar</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Event segmentation and event boundary advantage: Role of attention and postencoding processing</article-title><source>Journal of Experimental Psychology</source><volume>10</volume><elocation-id>1155</elocation-id><pub-id pub-id-type="doi">10.1037/xge0001155</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Radvansky</surname><given-names>GA</given-names></name><name><surname>Copeland</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Walking through doorways causes forgetting: situation models and experienced space</article-title><source>Memory &amp; Cognition</source><volume>34</volume><fpage>1150</fpage><lpage>1156</lpage><pub-id pub-id-type="doi">10.3758/bf03193261</pub-id><pub-id pub-id-type="pmid">17128613</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raffaelli</surname><given-names>Q</given-names></name><name><surname>Mills</surname><given-names>C</given-names></name><name><surname>de Stefano</surname><given-names>N-A</given-names></name><name><surname>Mehl</surname><given-names>MR</given-names></name><name><surname>Chambers</surname><given-names>K</given-names></name><name><surname>Fitzgerald</surname><given-names>SA</given-names></name><name><surname>Wilcox</surname><given-names>R</given-names></name><name><surname>Christoff</surname><given-names>K</given-names></name><name><surname>Andrews</surname><given-names>ES</given-names></name><name><surname>Grilli</surname><given-names>MD</given-names></name><name><surname>O’Connor</surname><given-names>M-F</given-names></name><name><surname>Andrews-Hanna</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The think aloud paradigm reveals differences in the content, dynamics and conceptual scope of resting state thought in trait brooding</article-title><source>Scientific Reports</source><volume>11</volume><elocation-id>19362</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-021-98138-x</pub-id><pub-id pub-id-type="pmid">34593842</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramanan</surname><given-names>S</given-names></name><name><surname>Piguet</surname><given-names>O</given-names></name><name><surname>Irish</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Rethinking the Role of the Angular Gyrus in Remembering the Past and Imagining the Future: The Contextual Integration Model</article-title><source>The Neuroscientist</source><volume>24</volume><fpage>342</fpage><lpage>352</lpage><pub-id pub-id-type="doi">10.1177/1073858417735514</pub-id><pub-id pub-id-type="pmid">29283042</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ranganath</surname><given-names>C</given-names></name><name><surname>Ritchey</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Two cortical systems for memory-guided behaviour</article-title><source>Nature Reviews. Neuroscience</source><volume>13</volume><fpage>713</fpage><lpage>726</lpage><pub-id pub-id-type="doi">10.1038/nrn3338</pub-id><pub-id pub-id-type="pmid">22992647</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reagh</surname><given-names>ZM</given-names></name><name><surname>Delarazan</surname><given-names>AI</given-names></name><name><surname>Garber</surname><given-names>A</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Aging alters neural activity at event boundaries in the hippocampus and Posterior Medial network</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>3980</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-17713-4</pub-id><pub-id pub-id-type="pmid">32769969</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritchey</surname><given-names>M</given-names></name><name><surname>Cooper</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Deconstructing the Posterior Medial Episodic Network</article-title><source>Trends in Cognitive Sciences</source><volume>24</volume><fpage>451</fpage><lpage>465</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2020.03.006</pub-id><pub-id pub-id-type="pmid">32340798</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaefer</surname><given-names>A</given-names></name><name><surname>Kong</surname><given-names>R</given-names></name><name><surname>Gordon</surname><given-names>EM</given-names></name><name><surname>Laumann</surname><given-names>TO</given-names></name><name><surname>Zuo</surname><given-names>XN</given-names></name><name><surname>Holmes</surname><given-names>AJ</given-names></name><name><surname>Eickhoff</surname><given-names>SB</given-names></name><name><surname>Yeo</surname><given-names>BTT</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Local-Global Parcellation of the Human Cerebral Cortex from Intrinsic Functional Connectivity MRI</article-title><source>Cerebral Cortex (New York, N.Y</source><volume>28</volume><fpage>3095</fpage><lpage>3114</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhx179</pub-id><pub-id pub-id-type="pmid">28981612</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name><name><surname>Cordova</surname><given-names>NI</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neural representations of events arise from temporal community structure</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>486</fpage><lpage>492</lpage><pub-id pub-id-type="doi">10.1038/nn.3331</pub-id><pub-id pub-id-type="pmid">23416451</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shin</surname><given-names>YS</given-names></name><name><surname>DuBrow</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Structuring Memory Through Inference-Based Event Segmentation</article-title><source>Topics in Cognitive Science</source><volume>13</volume><fpage>106</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1111/tops.12505</pub-id><pub-id pub-id-type="pmid">32459391</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Schooler</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The science of mind wandering: empirically navigating the stream of consciousness</article-title><source>Annual Review of Psychology</source><volume>66</volume><fpage>487</fpage><lpage>518</lpage><pub-id pub-id-type="doi">10.1146/annurev-psych-010814-015331</pub-id><pub-id pub-id-type="pmid">25293689</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Bernhardt</surname><given-names>BC</given-names></name><name><surname>Leech</surname><given-names>R</given-names></name><name><surname>Bzdok</surname><given-names>D</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The default mode network in cognition: a topographical perspective</article-title><source>Nature Reviews. Neuroscience</source><volume>22</volume><fpage>503</fpage><lpage>513</lpage><pub-id pub-id-type="doi">10.1038/s41583-021-00474-4</pub-id><pub-id pub-id-type="pmid">34226715</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>V</given-names></name><name><surname>Mitchell</surname><given-names>DJ</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Role of the Default Mode Network in Cognitive Transitions</article-title><source>Cerebral Cortex (New York, N.Y</source><volume>28</volume><fpage>3685</fpage><lpage>3696</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhy167</pub-id><pub-id pub-id-type="pmid">30060098</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>H</given-names></name><name><surname>Finn</surname><given-names>ES</given-names></name><name><surname>Rosenberg</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2021">2021a</year><article-title>Neural signatures of attentional engagement during narratives and its consequences for event memory</article-title><source>PNAS</source><volume>118</volume><elocation-id>e2021905118</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2021905118</pub-id><pub-id pub-id-type="pmid">34385312</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>H</given-names></name><name><surname>Park</surname><given-names>BY</given-names></name><name><surname>Park</surname><given-names>H</given-names></name><name><surname>Shim</surname><given-names>WM</given-names></name></person-group><year iso-8601-date="2021">2021b</year><article-title>Cognitive and Neural State Dynamics of Narrative Comprehension</article-title><source>The Journal of Neuroscience</source><volume>41</volume><fpage>8972</fpage><lpage>8990</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0037-21.2021</pub-id><pub-id pub-id-type="pmid">34531284</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Sood</surname><given-names>G</given-names></name><name><surname>Laohaprapanon</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Predicting Race and Ethnicity from the Sequence of Characters in a Name</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1805.02109">https://arxiv.org/abs/1805.02109</ext-link></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Speer</surname><given-names>NK</given-names></name><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Reynolds</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Human brain activity time-locked to narrative event boundaries</article-title><source>Psychological Science</source><volume>18</volume><fpage>449</fpage><lpage>455</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.2007.01920.x</pub-id><pub-id pub-id-type="pmid">17576286</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sripada</surname><given-names>C</given-names></name><name><surname>Taxali</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Structure in the stream of consciousness: Evidence from a verbalized thought protocol and automated text analytic methods</article-title><source>Consciousness and Cognition</source><volume>85</volume><elocation-id>103007</elocation-id><pub-id pub-id-type="doi">10.1016/j.concog.2020.103007</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stawarczyk</surname><given-names>D</given-names></name><name><surname>Bezdek</surname><given-names>MA</given-names></name><name><surname>Zacks</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Event Representations and Predictive Processing: The Role of the Midline Default Network Core</article-title><source>Topics in Cognitive Science</source><volume>13</volume><fpage>164</fpage><lpage>186</lpage><pub-id pub-id-type="doi">10.1111/tops.12450</pub-id><pub-id pub-id-type="pmid">31486286</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tseng</surname><given-names>J</given-names></name><name><surname>Poppenk</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Brain meta-state transitions demarcate thoughts across task contexts exposing the mental noise of trait neuroticism</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>3480</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-17255-9</pub-id><pub-id pub-id-type="pmid">32661242</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vincent</surname><given-names>JL</given-names></name><name><surname>Kahn</surname><given-names>I</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Raichle</surname><given-names>ME</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Evidence for a frontoparietal control system revealed by intrinsic functional connectivity</article-title><source>Journal of Neurophysiology</source><volume>100</volume><fpage>3328</fpage><lpage>3342</lpage><pub-id pub-id-type="doi">10.1152/jn.90355.2008</pub-id><pub-id pub-id-type="pmid">18799601</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ward</surname><given-names>AF</given-names></name><name><surname>Wegner</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Mind-blanking: when the mind goes away</article-title><source>Frontiers in Psychology</source><volume>4</volume><elocation-id>650</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2013.00650</pub-id><pub-id pub-id-type="pmid">24098287</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wen</surname><given-names>T</given-names></name><name><surname>Duncan</surname><given-names>J</given-names></name><name><surname>Mitchell</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Hierarchical Representation of Multistep Tasks in Multiple-Demand and Default Mode Networks</article-title><source>The Journal of Neuroscience</source><volume>40</volume><fpage>7724</fpage><lpage>7738</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0594-20.2020</pub-id><pub-id pub-id-type="pmid">32868460</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yeshurun</surname><given-names>Y</given-names></name><name><surname>Nguyen</surname><given-names>M</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The default mode network: where the idiosyncratic self meets the shared social world</article-title><source>Nature Reviews. Neuroscience</source><volume>22</volume><fpage>181</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1038/s41583-020-00420-w</pub-id><pub-id pub-id-type="pmid">33483717</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Braver</surname><given-names>TS</given-names></name><name><surname>Sheridan</surname><given-names>MA</given-names></name><name><surname>Donaldson</surname><given-names>DI</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Ollinger</surname><given-names>JM</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name><name><surname>Raichle</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Human brain activity time-locked to perceptual event boundaries</article-title><source>Nature Neuroscience</source><volume>4</volume><fpage>651</fpage><lpage>655</lpage><pub-id pub-id-type="doi">10.1038/88486</pub-id><pub-id pub-id-type="pmid">11369948</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Speer</surname><given-names>NK</given-names></name><name><surname>Swallow</surname><given-names>KM</given-names></name><name><surname>Braver</surname><given-names>TS</given-names></name><name><surname>Reynolds</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Event perception: A mind-brain perspective</article-title><source>Psychological Bulletin</source><volume>133</volume><fpage>273</fpage><lpage>293</lpage><pub-id pub-id-type="doi">10.1037/0033-2909.133.2.273</pub-id><pub-id pub-id-type="pmid">17338600</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Speer</surname><given-names>NK</given-names></name><name><surname>Swallow</surname><given-names>KM</given-names></name><name><surname>Maley</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The Brain’s Cutting-Room Floor: Segmentation of Narrative Cinema</article-title><source>Frontiers in Human Neuroscience</source><volume>4</volume><elocation-id>168</elocation-id><pub-id pub-id-type="doi">10.3389/fnhum.2010.00168</pub-id><pub-id pub-id-type="pmid">20953234</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zacks</surname><given-names>JM</given-names></name><name><surname>Kurby</surname><given-names>CA</given-names></name><name><surname>Eisenberg</surname><given-names>ML</given-names></name><name><surname>Haroutunian</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Prediction error associated with the perceptual segmentation of naturalistic events</article-title><source>Journal of Cognitive Neuroscience</source><volume>23</volume><fpage>4057</fpage><lpage>4066</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_00078</pub-id><pub-id pub-id-type="pmid">21671745</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zacks</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Event Perception and Memory</article-title><source>Annual Review of Psychology</source><volume>71</volume><fpage>165</fpage><lpage>191</lpage><pub-id pub-id-type="doi">10.1146/annurev-psych-010419-051101</pub-id><pub-id pub-id-type="pmid">31905113</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>J</given-names></name><name><surname>Schjetnan</surname><given-names>AGP</given-names></name><name><surname>Yebra</surname><given-names>M</given-names></name><name><surname>Gomes</surname><given-names>BA</given-names></name><name><surname>Mosher</surname><given-names>CP</given-names></name><name><surname>Kalia</surname><given-names>SK</given-names></name><name><surname>Valiante</surname><given-names>TA</given-names></name><name><surname>Mamelak</surname><given-names>AN</given-names></name><name><surname>Kreiman</surname><given-names>G</given-names></name><name><surname>Rutishauser</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Neurons detect cognitive boundaries to structure episodic memories in humans</article-title><source>Nature Neuroscience</source><volume>25</volume><fpage>358</fpage><lpage>368</lpage><pub-id pub-id-type="doi">10.1038/s41593-022-01020-w</pub-id><pub-id pub-id-type="pmid">35260859</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>D</given-names></name><name><surname>Cornblath</surname><given-names>EJ</given-names></name><name><surname>Stiso</surname><given-names>J</given-names></name><name><surname>Teich</surname><given-names>EG</given-names></name><name><surname>Dworkin</surname><given-names>JD</given-names></name><name><surname>Blevins</surname><given-names>AS</given-names></name><name><surname>Bassett</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2020">2020</year><data-title>Gender diversity statement and code notebook v1.0</data-title><source>Zenodo</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.3672110">https://doi.org/10.5281/zenodo.3672110</ext-link></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.73693.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Schlichting</surname><given-names>Margaret L</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03dbr7087</institution-id><institution>University of Toronto</institution></institution-wrap><country>Canada</country></aff></contrib></contrib-group><related-object id="sa0ro1" link-type="continued-by" object-id="10.1101/2021.09.07.459300" object-id-type="id" xlink:href="https://sciety.org/articles/activity/10.1101/2021.09.07.459300"/></front-stub><body><p>This paper provides convincing evidence that internally generated event boundaries occurring at abrupt shifts in mental state evoke similar neural responses as those triggered by a change in sensory input. Given that much past work has linked the detection of event boundaries to the discrepancy between prediction and input, these new findings are significant and anticipated to spur much future research on event boundaries in the absence of external change. This innovative and methodologically rigorous study will be of interest to cognitive neuroscientists working on topics broadly related to memory, event segmentation, and mental context.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.73693.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Schlichting</surname><given-names>Margaret L</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03dbr7087</institution-id><institution>University of Toronto</institution></institution-wrap><country>Canada</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Schlichting</surname><given-names>Margaret L</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03dbr7087</institution-id><institution>University of Toronto</institution></institution-wrap><country>Canada</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Reagh</surname><given-names>Zachariah M</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01yc7t268</institution-id><institution>Washington University in St. Louis</institution></institution-wrap><addr-line><named-content content-type="city">St. Louis</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Geerligs</surname><given-names>Linda</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/016xsfp80</institution-id><institution>Radboud University</institution></institution-wrap><country>Netherlands</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2021.09.07.459300">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2021.09.07.459300v2">the preprint</ext-link> for the benefit of readers; ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;A generalized cortical activity pattern at internally-generated mental context boundaries during unguided narrative recall&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, including Margaret L Schlichting as the Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Chris Baker as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Zachariah M. Reagh (Reviewer #2); Linda Geerligs (Reviewer #3).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1. Experiential similarity with the blank screen: How might the similarity of experience (black screen, no auditory input) across boundary periods be driving the analysis? Please consider this in a revision. Specifically, the authors should: (a) revise (perhaps correct, or at least clarify) statements in the text that seem to suggest consistent input across boundary and non-boundary periods (see comments from Reviewer #1 and #3 for more on this point). Moreover, (b) please perform additional analyses to control for this confound. Reviewers had specific suggestions for how the authors might perform these controls, but the authors are also welcome to carry out these controls in a different way, as they see fit.</p><p>2. Selection of temporal epochs for both boundary and non boundary time periods: All Reviewers were concerned about the long boundary period (15s) – they had questions including why it was defined this way, whether that decision matters, and how it might cloud interpretations of comparisons across these different time period (since, for example, we might expect boundary signatures to be more transient for within-movie boundaries than between-movie ones). The Reviewers have conferred on this issue and suggest the authors use a shorter temporal window to address this comment (rather than e.g., provide justification in the text) as suggested by Reviewer #3, given the expected transience of the univariate response.</p><p>3. Concerns about within-run pattern similarity analysis: It would be important to know whether the results hold when limiting to only cross-run comparisons (see more from Reviewer #1). Moreover, please clarify in the revision how many runs there were for the recall task.</p><p>4. Providing more background for the focus on PMC: What was the reason for the focus on PMC? Reviewer #1 was not sure whether the results were specific to the PMC, and/or whether and why this was an a priori ROI. Are the operations thought to be unique to the PMC, or shared with other DMN regions? Also, Reviewer #2 was not sure why PCC and precuneus were combined to make PMC rather than considered separately. Please provide more on the logic behind these choices.</p><p>5. Univariate responses to boundaries: The description of the results in Figure 1B do not seem to match with the results show in the figure. There seem to be widespread transient changes and a larger number of vertices that show a decline in BOLD activity after a boundary. In addition, there seems to be a strong positive BOLD response throughout the default mode network. Please clarify.</p><p>6. Paper format: Reviewers felt the paper would be better suited for a longer format article, with separate Results and Discussion sections. That would allow for a more extensive discussion (see following points) of what the results might mean for our current understanding of how event segmentation works.</p><p>7. Discussion: Reviewers felt the Discussion was too short, and felt the authors' interesting and thought-providing findings warranted a more extensive unpacking. Reviewers would like to see a more fleshed-out exploration of what this general cognitive state that may exist between events might look like, and what it might be doing.</p><p>8. Also to consider in the expanded the Discussion: It is very unclear at this point whether the observed pattern of neural responses is related to the specific setup of the study or whether subtle shifts in context versus more intense transitions involve fundamentally different mechanism. I understand that this question probably cannot be answered with the current dataset, but I would appreciate some additional discussion related to this question, as well suggestions for how this could be clarified in future studies.</p><p>9. Figure 4 results presentation: Regarding the correlations between the average between-movie boundary pattern and (1) between-movie boundaries, (2) moments of silence, (3) within-movie boundaries (i.e., the data displayed in Figure 4), we had to re-read this figure caption and Results section a few times to feel that we really grasped what comparisons were being made, and how these correlations were being conducted. We think this could stand to be tweaked to be clearer, with perhaps a conceptual diagram like the one in Figure 2A included to aid in understanding.</p><p>10. Clarifying no-sound condition: Following from the above point, we were initially not totally clear on the relevance or importance of the 'no sound' condition. Upon reading further into the Results, it made sense, but seeing as this figure is referenced well before this condition is expanded upon, we think this could be motivated a little earlier to mitigate unnecessary confusion. As of now, this set of analyses seems to be motivated after presentation of the data rather than before, and simply shifting this around could aid in understanding.</p><p>11. Figure 3 results presentation: I was not sure I fully understood the offset vs. onset yoking analysis-both how it was performed, and how the conclusions followed from the results. First, I was a bit confused about how the difference in delay duration between movies at encoding (6s) versus at recall (9.3s on average, but variable; see also comment #5) would play into this and whether those are meaningful time points to display on the Figure 3D charts that might help the reader interpret those findings. Second, the authors state that this analysis shows the boundary patterns were driven by offset (more than onset) responses, but I was not sure what aspect of the results led to that conclusion. Can the authors say more about the evidence supporting this conclusion? It looks to me like there are strong correlations that emerge both after offset and onset (i.e., just above and to the right of the origin there are numerous time points with positive [red] correlations). Perhaps it is because the red positive correlations start earlier, prior to the recall itself, when yoked to the onset, but I am not sure why this means it is related to offset and not some preparation for the onset of recall (see also comment #5). Also, is it interesting or meaningful that the patterns seem more compressed at recall than at encoding (i.e., the outlined red areas are skinnier than they are tall)? Please clarify.</p><p>12. Reasoning behind masking decisions: I am not sure the reason for masking Figure 2B and C with the a&gt;0 and c&gt;0 maps. First of all, it seems as though in RSA the actual correlation being positive or negative is not terribly meaningful and can depend on preprocessing decisions, etc. In addition to that potential issue though I'm also just generally interested in more understanding the logic behind this decision. Can the authors explain that and include it in the main paper? Were there any regions that showed for example a</p><p>13. Clarity suggestions: The Reviewers also had several other suggestions that might increase the clarity of results presentation and/or depictions. The authors should please consider these suggestions and implement if they see fit.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>1. I had a couple more specific comments and ideas/suggestions:</p><p>a) Regarding p. 6, line 218-219: &quot;boundary and non-boundary periods were identical in terms of visual input during recall and speech generation during movie watching&quot;: Please clarify this phrasing. I thought boundary periods would be a blank screen, and non-boundary would be a movie playing during encoding and have verbal recall happening during recall. How is it true that they are identical in terms of visual input?</p><p>b) For overcoming the concern about visual input, I am wondering if perhaps the authors might be able to leverage the title screen before the very first movie in a run as a control, since this is not really a &quot;boundary&quot;? Alternatively, perhaps duration of blank screen viewing could be useful as a control since if what this is picking up on is blank-screne-ness, maybe it would increase with more time spent looking at the blank screen(?).</p><p>2. I have a number of clarification questions-these are mainly methodological choices that I simply didn't understand, and felt that further explanation or justification for these decisions should be included in the paper:</p><p>a) What was the reason for the focus on PMC? I was not sure whether the results were specific to the PMC, and/or whether and why this was an a priori ROI. Are the operations thought to be unique to the PMC, or shared with other DMN regions? More logic behind this choice would be very helpful.</p><p>b) The run structure was a bit unclear to me. Sorry if I missed this, but I saw there were two encoding scans but could not work out how many recall scans there were.</p><p>c) For the non-boundary comparisons, this was described as being the middle 15s of the movie. Were there efforts made to ensure there were no (within-movie) boundaries during this period? I was not sure whether these would be different (and if so, how different) from the event offset comparisons.</p><p>d) I was not sure how the &quot;higher-than-average&quot; and &quot;lower-than-average&quot; regions were defined, specifically. What is the average in this case?</p><p>e) Page 6, line 130: this phrasing was confusing to me: &quot;this correlation was higher at boundaries than at non-boundaries (Figure 2A, blue arrows).&quot; It made me think that the &quot;blue arrows&quot; in the parentheses may refer to the non-boundaries, but the blue arrows in the figure appear to be across-movie correlation for both boundary (left activation pattern pair in Figure 2A), and non-boundary (right pair Figure 2A) time points. Perhaps rephrase? Maybe &quot;Figure 2A, a versus b blue arrows&quot;?</p><p>f) Another phrasing question: &quot;…, suggesting that the between-movie boundary pattern may reflect a cognitive state qualitatively different from the state elicited by event boundaries during movie watching (e.g., attentional engagement; Song et al., 2021).&quot; I'm not quite sure what the authors mean by &quot;e.g., attentional engagement&quot;. Can you explain further? Differences in attentional engagement across these two experience types, perhaps?</p><p>g) As may be clear from my public comment #2, the presentation of results in Figure 3D was hard for me to understand. Perhaps the authors could think of ways to plot this differently or spell out more explicitly the patterns of interest in the paper or legend to help readers understand. I would have loved more hand-holding for this analysis.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>We really enjoyed this manuscript and had very few suggestions or requests for tweaks. We note these below:</p><p>1. We recognize that this is a short-format submission, but honestly, the 'Discussion' section of this paper just felt far too short. These are very interesting and thought-provoking results, which did not feel commensurate with the very small amount of text devoted to unpacking the findings and their implications. Note that we are not suggesting the authors did a poor job of constructing these two paragraphs, but rather we think that this is simply not enough space to really do justice to a broader conversation that can be had about these findings. We suggest (if possible, from an editorial standpoint) that a lengthier discussion could really solidify the contributions of this paper and make the connections to other studies and other ideas about event cognition and event memory more explicit. In particular, I would love to hear a more fleshed-out exploration of what this general cognitive state that may exist between events might look like, and what it might be doing.</p><p>2. The authors operationalized boundary periods as &quot;…the first 15 seconds following the offset of each recalled movie, and the non-boundary periods…&quot; as &quot;…the 15 seconds in the middle of each recalled movie.&quot; Why was a window of 15 seconds chosen? While I do not have any reason to suspect the results would be wildly different if, say, a 10 or 20 second window was used, we think some justification or indication of why this particular parameter was chosen would be good to include.</p><p>3. Regarding Figure 2, we personally think that a different color gradient might be a better choice for the dark gray inflated brain image. This is a minor nit-pick, but the darker red colors do not show up against the dark sulcus portions of the map particularly well, and a different gradient might be preferable. This would be particularly true if individuals were to view this figure in grayscale, or in cases of color-blindness.</p><p>4. If so many individual parcels from the Schaefer atlas were examined, it is not clear why PCC and Precuneus were combined into a PMC ROI. While we do not particularly suspect that PCC and precuneus should look very different, we think a brief note of why these regions were combined and many others weren't would be good to include.</p><p>5. Regarding the correlations between the average between-movie boundary pattern and (1) between-movie boundaries, (2) moments of silence, (3) within-movie boundaries (i.e., the data displayed in Figure 4), we had to re-read this figure caption and Results section a few times to feel that we really grasped what comparisons were being made, and how these correlations were being conducted. We think this could stand to be tweaked to be clearer, with perhaps a conceptual diagram like the one in Figure 2A included to aid in understanding.</p><p>6. Following from the above point, we were initially not totally clear on the relevance or importance of the 'no sound' condition. Upon reading further into the Results, it made sense, but seeing as this figure is referenced well before this condition is expanded upon, we think this could be motivated a little earlier to mitigate unnecessary confusion. As of now, this set of analyses seems to be motivated after presentation of the data rather than before, and simply shifting this around could aid in understanding.</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>Specific suggestions the authors related to the points mentioned above:</p><p>1. To address the effect of similarity between encoding and recall due to the (lack of) perceptual input, it would be relevant to add an additional comparisons to the analyses as shown in figure 2: the similarity between middle segments during recall and boundary segments during encoding.</p><p>2. I wonder why the authors choose to focus on a long window of 15 seconds after stimulus onset rather than a shorter window. I would suggest investigating the similarity between the within-movie and between-movie event boundaries by focusing on a shorter window (e.g. 2 TRs). Additionally, I would propose running an analysis like the one in figure 3D for the within-movie and between-movie event boundaries to see how the (dis)similarity develops over time.</p><p>3. It is very unclear at this point whether the observed pattern of neural responses is related to the specific setup of the study or whether subtle shifts in context versus more intense transitions involve fundamentally different mechanism. I understand that this question probably cannot be answered with the current dataset, but I would appreciate some additional discussion related to this question, as well suggestions for how this could be clarified in future studies. I think the paper might be more suitable for a longer format, with a separate results and Discussion section. That would allow for a more extensive discussion for what the results might mean for our current understanding of how event segmentation works.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.73693.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1. Experiential similarity with the blank screen: How might the similarity of experience (black screen, no auditory input) across boundary periods be driving the analysis? Please consider this in a revision. Specifically, the authors should: (a) revise (perhaps correct, or at least clarify) statements in the text that seem to suggest consistent input across boundary and non-boundary periods (see comments from Reviewer #1 and #3 for more on this point). Moreover, (b) please perform additional analyses to control for this confound. Reviewers had specific suggestions for how the authors might perform these controls, but the authors are also welcome to carry out these controls in a different way, as they see fit.</p></disp-quote><p>We thank the reviewers for their comments and suggestions on the potential confounds due to similar visual and auditory input across boundary periods. First of all, we fully agree that boundary periods share perceptual and motoric features within each experimental phase, and these shared experiences likely contributed to higher within-phase pattern similarity for boundary periods compared to non-boundary periods. This issue was described in our original text but with insufficient clarity and prominence, for which we apologize. Indeed, this explains why more parcels showed significantly positive boundary pattern similarity <italic>within</italic> the recall phase than <italic>across</italic> encoding and recall phases (Figure 2B/C). We revised the Results section of the manuscript as below to make this point clearer:</p><p>p.5. “We observed a consistent boundary pattern, i.e., whenever participants transitioned from talking about one movie to the next, in several cortical parcels (Schaefer et al., 2018) including the DMN and auditory/motor areas (Figure 2B). Thus, the boundary patterns within the recall phase were likely to be driven by both shared low-level sensory/motor factors (e.g., breaks in recall speech generation) as well as cognitive states (e.g., memory retrieval) at recall boundaries.”</p><p>As the confound could not be resolved in the current dataset, the rest of our manuscript focused on the boundary pattern which was consistent <italic>across</italic> encoding and recall phases. This transient across-phase pattern similarity, observed specifically during boundary periods but not during non-boundary periods, is far less easily explained by shared perceptual or motoric features:</p><p>– Subjects viewed the black screen throughout the entire recall phase, so if the black screen at the boundaries during encoding was driving the boundary pattern, the similarity between encoding boundary patterns and recall non-boundary patterns should also be positive, but it was not (see Figure 3A/D).</p><p>– Likewise, subjects did not make any verbal response throughout the entire encoding phase, so if the absence of verbal responses at the boundaries during recall was responsible for the boundary pattern, the similarity between recall boundary patterns and encoding non-boundary patterns should also be positive-- but it was not.</p><p>We clarified this point by revising the ambiguous sentence in the Result section (“boundary and non-boundary periods were identical in terms of visual input during recall and speech generation during movie watching&quot;), as suggested by Reviewer 1. The sentence was supposed to state two separate facts: (1) visual input was identical across boundary and non-boundary periods <italic>during recall</italic>, as subjects viewed a fixation dot on black screen throughout the recall phase, and (2) boundary and non-boundary periods were identical in terms of speech generation (i.e., no speech generated) <italic>during movie watching</italic>, as subjects did not make verbal responses at all throughout the encoding phase. We revised the text as below:</p><p>p.11. “Is the generalized between-movie boundary pattern driven by shared low-level perceptual or motoric factors rather than cognitive states? First, shared visual features at between-movie boundaries (i.e., black screen) cannot explain the transient, boundary-specific similarity between encoding and recall phases, because visual input was identical across boundary and non-boundary periods during recall (i.e., a fixation dot on black background). Indeed, encoding boundary patterns were more similar to recall boundary patterns than to recall non-boundary patterns in DMN areas, suggesting a limited contribution of shared visual input to the generalized boundary pattern (Figure 2—figure supplement 2). Likewise, the absence of verbal responses at boundaries cannot explain the boundary pattern generalized across encoding and recall phases, as no speech was generated throughout the entire encoding phase.”</p><p>In addition, we performed two new analyses to address the possible effects of shared input at boundaries:</p><p>First, following the suggestions of Reviewers 1 and 3, we performed a new analysis to control for the effects of shared visual input. Specifically, we directly compared the similarity between encoding and recall boundary patterns against the similarity between encoding boundary patterns and recall non-boundary patterns. Again, if the generalized boundary patterns that we observed were predominantly driven by shared low-level visual features, the similarity between encoding and recall boundary patterns would be approximately the same as the similarity between encoding boundary patterns and recall non-boundary patterns. However, we found that several cortical parcels, especially within the DMN, showed significantly greater encoding-recall boundary pattern similarity compared to the similarity between encoding boundary patterns and recall non-boundary patterns; the resulting maps were highly similar to the results reported in Figure 2C. Thus, the consistent boundary patterns observed in higher associative areas were not likely to be mainly due to low-level visual features shared across the experimental phases. We now report this analysis in Figure 2—figure supplement 2.</p><p>We revised the Results and Methods sections of the manuscript accordingly:</p><p>p.5. “First, shared visual features at between-movie boundaries (i.e., black screen) cannot explain the transient, boundary-specific similarity between encoding and recall phases, because visual input was identical across boundary and non-boundary periods during recall (i.e., a fixation dot on black background). Indeed, encoding boundary patterns were more similar to recall boundary patterns than to recall non-boundary patterns in DMN areas, suggesting a limited contribution of shared visual input to the generalized boundary pattern (Figure 2—figure supplement 2).”</p><p>p.22. “Testing the effect of visual features</p><p>Between-movie boundary periods during encoding and those during recall shared low-level visual features (i.e., mostly blank black screen). To test whether the similar visual features produced similar activation patterns at between-movie boundaries across phases, we performed a whole-brain pattern similarity analysis (Figure 2—figure supplement 2). For each subject and cortical parcel, we computed the mean boundary and non-boundary activation patterns for each movie, separately for encoding and recall. The boundary periods were defined as the first 15 seconds following the offset of each watched or recalled movie. The non-boundary periods were defined as the middle 15 seconds of each movie. Both boundary and non-boundary time windows were shifted forward by 4.5 seconds. We then computed Pearson correlations between encoding boundary patterns and recall boundary patterns across different movies, and averaged all the correlations. Likewise, we computed the average correlation between boundary patterns during encoding and non-boundary patterns during recall across different movies. A group-level two-tailed paired-samples t-test was performed to test whether the similarity between encoding and recall boundary patterns was greater than the similarity between encoding boundary patterns and recall non-boundary patterns, even though boundary and non-boundary patterns were visually identical during recall. The resulting whole-brain map was corrected for multiple comparisons across parcels using the Bonferroni method.”</p><p>Second, to further examine the effects of similar experiences at boundaries, we performed a new analysis (see <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>) comparing the similarity between <italic>boundary</italic> patterns from <italic>different</italic> movies (Mb-diff) to the similarity between <italic>non-boundary</italic> patterns from the <italic>same</italic> movies during encoding (Mnb-same) in PMC. If the consistent boundary patterns were simply driven by similar external experiences during boundary periods, the boundary pattern similarity between different movies could not be higher than the non-boundary pattern similarity between the same movies; the external experience was “exactly” the same across the correlated non-boundary periods, because they were the same middle segments from the identical movie. Note that in this analysis, we had to compute between-subject pattern similarity (i.e., one subject’s pattern was correlated with the remaining subjects’ patterns) rather than within-subject pattern similarity, because there was only one non-boundary pattern for each movie and subject as each subject watched each movie only once. However, as shown in the left panel of <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>, the boundary pattern similarity across different movies was higher than the non-boundary pattern similarity across the same movies. Moreover, even the boundary pattern similarity <italic>across different movies and experimental phases</italic> (MRb-diff) was numerically higher than the non-boundary pattern similarity across the same movies within the encoding phase (Mnb-same)(right panel). Together, these results suggest that shared cognitive features beyond audiovisual input contributed to the generalized boundary pattern. Because all other pattern-similarity analyses in the manuscript measured within-subject similarity, we opted not to report these results in the manuscript for consistency and to avoid readers’ confusion. However, we would be happy to include these results if the reviewers feel it will improve the manuscript.</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-73693-sa2-fig1-v2.tif"/></fig><disp-quote content-type="editor-comment"><p>2. Selection of temporal epochs for both boundary and non boundary time periods: All Reviewers were concerned about the long boundary period (15s) – they had questions including why it was defined this way, whether that decision matters, and how it might cloud interpretations of comparisons across these different time period (since, for example, we might expect boundary signatures to be more transient for within-movie boundaries than between-movie ones). The Reviewers have conferred on this issue and suggest the authors use a shorter temporal window to address this comment (rather than e.g., provide justification in the text) as suggested by Reviewer #3, given the expected transience of the univariate response.</p></disp-quote><p>Our choice of the boundary/non-boundary period time windows was primarily based on the time courses of boundary-related univariate responses, examined during the basic exploration of recall offset effects. As shown in Figure 1—figure supplement 1, boundary-related signals tended to last up to 30 seconds from recall offset, with the largest responses (deactivation) observed around approximately 15 seconds from the offset. Thus, we decided to use a time window of 15 seconds (shown as a red bar on the x axis) to include most of the time points that showed boundary responses.</p><p>In addition, as shown in Figure 3D, the time-time correlations between activation patterns around boundaries indicated that the generalized boundary activation pattern in PMC lasted until around 15 seconds from the movie/recall offset. That is, activation patterns remained stable for at least about 15 seconds from the offset. Thus, we aimed to generate clearer activation patterns to be used for analyses by taking the average of the stable patterns across time points that spanned the 15-s window.</p><p>We now clarify our decision for using a relatively long time window of 15 seconds in the Methods section as below:</p><p>p.18. “The boundary periods were the first 15 seconds following the offset of each recalled movie, and the non-boundary periods were the 15 seconds in the middle of each recalled movie. Both boundary and non-boundary period time windows were shifted forward by 4.5 seconds to account for the hemodynamic response delay. We used a relatively long 15-s duration for the boundary and non-boundary periods to capture most of the boundary-related signals during recall, based on exploratory analyses that examined the time courses of univariate boundary responses (Figure 1—figure supplement 1) and boundary-triggered activation patterns (Figure 3—figure supplement 4D).”</p><p>That said, we agree with the reviewers that 15 seconds (10 TRs) is a relatively long time window for pattern similarity analysis. As suggested by the reviewers, we re-analyzed the data using a shorter time window (3 TRs = 4.5 seconds) which is more conventional in pattern-based analyses, and obtained similar results. For example, we observed generalized boundary patterns consistent across different movie stimuli and experimental phases in the DMN areas. We now report these results in Figure 2—figure supplement 1 and Figure 3—figure supplement 3.</p><p>We revised the Results section and the Methods section of the manuscript accordingly:</p><p>p.7. “We observed similar results in the lateral parietal DMN sub-region (angular gyrus; Figure 3—figure supplement 2), as well as using shorter (4.5 s) time windows of boundary and non-boundary periods (Figure 2—figure supplement 1, Figure 3—figure supplement 3).”</p><p>p.19. “We also performed the same pattern similarity analysis in the PMC (Figure 3) and angular gyrus (Figure 3—figure supplement 2) ROIs, as done for an individual cortical parcel in the whole-brain analysis. In addition, we repeated the same analyses using shorter (4.5 seconds) boundary and non-boundary period time windows and obtained similar results (Figure 2—figure supplement 1, Figure 3—figure supplement 3). “</p><p>Finally, to test whether using a relatively longer/shorter time window would affect the similarity across the between-movie boundary pattern and the within-movie boundary pattern, we performed two extra analyses and reported the results in Figure 4—figure supplement 2.</p><p>First, we repeated the pattern similarity analysis comparing the ‘template’ between- and within-movie boundary patterns in PMC using a shorter (4.5 seconds) time window (Figure 4—figure supplement 2A). We replicated our original finding that there was no positive correlation across the two types of boundary patterns; the correlation was numerically negative, although it was not significantly different from zero.</p><p>Second, as Reviewer 3 suggested, we performed the time-time pattern correlation analysis comparing between-movie boundaries to within-movie boundaries in PMC (Figure 4—figure supplement 2B). This analysis examined whether the (dis)similarity between the two types of boundary patterns would change across time: namely, whether the within-movie boundary pattern was in fact similar (rather than dissimilar) to the between-boundary pattern in the short time window immediately following the boundary, but our long time window had caused us to miss the effect. However, we observed no effect of time windows as the patterns temporally unfolded; there was no significantly positive correlation across within- and between-movie boundary patterns in any of the time points following boundaries. Overall, these results support our original finding that within- and between-movie boundary patterns do not resemble each other.</p><p>We revised the Results section and the Methods section to report the new results:</p><p>p.9. “Within-movie and between-movie boundary patterns did not resemble each other, regardless of the specific time windows used to define the boundary periods (Figure 4—figure supplement 2).”</p><p>pp.21-22. “We also repeated the same pattern similarity analysis using shorter (4.5 s) time windows for the boundary periods, from 4.5 to 9 seconds following the within- or between-movie boundaries (Figure 4—figure supplement 2A).”</p><p>To explore the temporal unfolding of the similarity between the within- and between-movie boundary patterns, we additionally examined the between-phase TR-by-TR pattern similarity across individual time points around the boundaries (Figure 4—figure supplement 2B). For each subject, we extracted the PMC activation pattern time series from 30 seconds before to 60 seconds after 1) each within-movie event boundary during encoding and 2) the offset of each movie during recall. The time series were averaged across boundaries within each experimental phase. We then computed Pearson correlation coefficients across different time points in the activation pattern time series between the encoding and recall phases. Finally, we performed two-tailed one-sample <italic>t</italic>-tests against zero on each cell of the time-time correlation matrices from all subjects to identify the time points at which significantly positive or negative pattern correlations appeared. Bonferroni correction was applied to correct for multiple comparisons across cells.”</p><p>Additionally, as the similarity across between- and within-movie boundary patterns was only numerically negative when we used the shorter time window, we revised the following sentence in the abstract to deemphasize the “negative” correlation between the two.</p><p>p.2. “Surprisingly, the between-movie boundary patterns did not resemble patterns at boundaries between events within a movie.”</p><disp-quote content-type="editor-comment"><p>3. Concerns about within-run pattern similarity analysis: It would be important to know whether the results hold when limiting to only cross-run comparisons (see more from Reviewer #1). Moreover, please clarify in the revision how many runs there were for the recall task.</p></disp-quote><p>We first apologize for not clearly reporting how many scanning runs there were for the recall task. There were always two encoding runs for all subjects, but only a subset of subjects had two recall runs: 4 subjects had two recall runs, and the other subjects had one recall run. We wrote in our prior manuscript using the same dataset (Lee and Chen, 2021, bioRxiv, https://doi.org/10.1101/2021.04.24.4412874) that “in case subjects needed to take a break or the duration of the scanning run exceeded the scanner limit (35 minutes), we stopped the scan in the middle and started a new scanning run where subjects resumed from where they had stopped in the previous run. 4 of the 15 subjects included in the analysis had such a break within their spoken recall session.” We have revised the Methods section of the current manuscript as below to report the number of recall phase scanning runs.</p><p>p.17. “The recall phase consisted of two scanning runs in 4 of the 15 subjects included in the analysis. The other subjects had a single scanning run.”</p><p>Thus, as Reviewer #1 pointed out, the results of within-phase pattern similarity analyses (encoding-encoding and recall-recall) were partially derived from within-run pattern correlations. It is also true that correlating patterns within the same run could potentially lead to greater pattern similarity. However, we believe that temporal autocorrelation within a scanning run had little influence on our reported results, for the following reasons:</p><p>First of all, we did not simply show positive pattern correlations between boundary patterns; we compared them against pattern correlations between non-boundary patterns, which was also partially derived from within-run pattern correlations. Thus, any effect of within-run comparisons would influence both boundary and non-boundary conditions. Yet, we still observed much greater similarity across boundary patterns compared to non-boundary patterns. Moreover, the main focus of our study was the generalized boundary pattern consistent across encoding and recall phases, which was computed purely across different scanning runs.</p><p>Finally, to directly test the effect of computing within-run pattern correlations, we performed a new pattern similarity analysis comparing within-run pattern similarity and between-run pattern similarity using the PMC encoding phase data. Recall data were not considered, as there were only 4 subjects who had two separate scanning runs. As shown in <xref ref-type="fig" rid="sa2fig2">Author response image 2</xref>, we computed the mean within-run, between-movie pattern similarity across boundary patterns (Within-run Boundary) and across non-boundary patterns (Within-run Nonboundary). Likewise, we computed the mean between-run, between-movie pattern similarity across boundary patterns (Between-run Boundary) and across non-boundary patterns (Between-run Nonboundary).</p><fig id="sa2fig2" position="float"><label>Author response image 2.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-73693-sa2-fig2-v2.tif"/></fig><p>The results show that between-movie pattern similarity was greater in the boundary than non-boundary conditions regardless of whether the pattern similarity was measured within the same run or between different runs (<italic>t</italic>s &gt; 10, <italic>p</italic>s &lt;.001). Moreover, the overall boundary pattern similarity did not differ across within-run and between-run correlations (i.e., Within-run Boundary vs. Between-run Boundary; <italic>t</italic>(14) = 1.21, <italic>p</italic> = .25). Thus, the generalized boundary pattern we reported in our manuscript was not likely to be primarily driven by potential confounds associated with within-run comparisons. This also suggests that although we observed more widespread Recall-Recall than Encoding-Recall similarity in Figure 2B-C, it is likely to be due to shared sensory/motor factors within the recall phase as we noted in our manuscript (“the boundary patterns within the recall phase were likely to be driven by both shared low-level sensory/motor factors (e.g., breaks in recall speech generation) as well as cognitive states (e.g., memory retrieval) at recall boundaries.”), rather than the effect of temporal autocorrelations.</p><disp-quote content-type="editor-comment"><p>4. Providing more background for the focus on PMC: What was the reason for the focus on PMC? Reviewer #1 was not sure whether the results were specific to the PMC, and/or whether and why this was an a priori ROI. Are the operations thought to be unique to the PMC, or shared with other DMN regions? Also, Reviewer #2 was not sure why PCC and precuneus were combined to make PMC rather than considered separately. Please provide more on the logic behind these choices.</p></disp-quote><p>We focused on PMC primarily because PMC was the area that showed the strongest content- and task-general boundary patterns in the exploratory whole-brain analysis (Figure 2C). We clarified this reasoning behind our choice of PMC as the major region of interest in the manuscript as below:</p><p>p.7. “To what extent is the internally-driven boundary pattern, measured during recall, similar to patterns observed at boundaries during encoding? To test this, we again computed between-movie pattern similarity for all cortical parcels in the brain, but now across the encoding and recall phases (Figure 2A, red arrows). We found that DMN areas showed a consistent boundary pattern across task phases (encoding and recall) and across movies (Figure 2C). Again, no cortical area showed negative correlations between boundary patterns or greater correlations for non-boundary compared to boundary patterns. Among the DMN areas, the posterior medial cortex (PMC) showed the most consistent boundary patterns; thus, we next examined the phenomenon in more detail specifically in PMC.”</p><p>We also had a priori speculation that PMC is likely to be involved in processing transitions between situations or events, based on prior studies demonstrating that the region accumulates information over long timescales (e.g., Hasson et al., 2015) and represents relatively abstract situation-level information (e.g., Ranganath and Ritchey, 2012; Chen et al., 2017). However, this does not necessarily mean that these operations are unique to PMC. Indeed, we observed generalized boundary patterns in other DMN areas as well, especially in the angular gyrus, as demonstrated in the whole-brain map in Figure 3C. We therefore performed pattern similarity analysis targeting the angular gyrus, and obtained results highly similar to those obtained from PMC. The angular gyrus results are reported in Figure 3—figure supplement 2 and mentioned in the main text as below:</p><p>p.7. “Individual subjects’ activation maps visualize the similarity between boundary patterns during encoding and recall (Figure 3B, Figure 3—figure supplement 1). We observed similar results in the lateral parietal DMN sub-region (angular gyrus; Figure 3—figure supplement 2), as well as using shorter (4.5 s) time windows of boundary and non-boundary periods (Figure 2—figure supplement 1, Figure 3—figure supplement 3).”</p><p>We created a single PMC ROI mask by combining the PCC and precuneus to be consistent with our prior study that analyzed the same region of interest (Lee and Chen, 2021). Our decision to use PMC including both the PCC and precuneus in our current and prior studies was based on the atlas of functional networks widely used in the field (Schaefer et al., 2018). In the Schaefer atlas, the two regions together form the posterior medial sub-region of the default network, and the parcels that we combined to create the PMC ROI all fell within the default network. In addition, we observed the content- and task-general boundary pattern in the larger PMC area in our whole-brain analysis (Figure 2C), and thus we opted to use a single large PMC mask for our ROI analysis rather than breaking the continuous area into several sub-regions. As Reviewer 2 mentioned in their Recommendations #4, it is unlikely that the PCC and precuneus would show qualitatively different results, because the whole-brain analysis using smaller parcels already demonstrated that the PCC and precuneus as well as their fine-grained sub-areas all showed boundary patterns consistent across experimental phases. We revised the Methods section of the manuscript as below to explain our reasons for combining the two regions:</p><p>p.17. “For region-of-interest analyses, we defined the bilateral posterior-medial cortex (PMC) by combining the parcels corresponding to the precuneus and posterior cingulate cortex within Default Network A as in our prior study (Lee and Chen, 2021). The precuneus and posterior cingulate cortex together spanned the area that showed the strongest content-and task-general boundary patterns in the whole-brain analysis (Figure 3C). The bilateral angular gyrus ROI consisted of the parcels corresponding to the inferior parietal cortex within Default Network A, B and C.”</p><disp-quote content-type="editor-comment"><p>5. Univariate responses to boundaries: The description of the results in Figure 1B do not seem to match with the results show in the figure. There seem to be widespread transient changes and a larger number of vertices that show a decline in BOLD activity after a boundary. In addition, there seems to be a strong positive BOLD response throughout the default mode network. Please clarify.</p></disp-quote><p>We apologize for not being clear in describing our whole-brain univariate activation results. In the original version of the manuscript, we described the changes in univariate activity as “limited” because there were only a few vertices that showed <italic>significant</italic> effects after multiple comparisons correction (shown as small white dots in the original version of Figure 1B). Note that the red-blue color gradient in Figure 1B indicates the level of <italic>unthresholded</italic> responses, shown to provide a more complete picture of univariate responses at between-movie boundaries. However, we fully agree with the reviewers that there were widespread responses across the entire cortex at between-movie boundaries, although they did not reach statistical significance after Bonferroni correction. In addition, applying Bonferroni correction to 81924 vertices might be an overly conservative correction. Thus, we applied the Benjamini-Hochberg FDR correction instead of Bonferroni and revised Figure 1B.</p><p>By switching to FDR correction, we were able to identify more widespread areas that showed significant changes in activation following between-movie boundaries (including both increase and decrease in activation), consistent with Reviewer 3’s observation. We believe that this revised result provides a better description of the neural phenomena associated with between-movie boundaries, compared to the previous result (i.e., significant BOLD changes in only a few vertices) based on Bonferroni correction. We revised the Results and the Methods accordingly:</p><p>p.5. “We first examined whether internally-driven boundaries evoke changes in blood oxygen level-dependent (BOLD) signals during recall. We observed transient changes in activation at the boundaries between recalled movies in widespread cortical regions (Figure 1—video 1; see Figure 1—figure supplement 1 for activation time courses). A whole-brain analysis with multiple comparisons correction revealed that the mean activation of boundary periods (15 seconds following the offset of each movie) was generally lower than that of non-boundary periods (middle 15 seconds within each movie) in multiple areas including the motor, auditory, and inferior parietal cortices, although a smaller number of regions showed higher activation during non-boundary periods (Figure 1B).”</p><p>p.18. “The Benjamini-Hochberg procedure (False Discovery Rate <italic>q</italic> &lt;.05) was applied to correct for multiple comparisons across vertices on the resulting whole-brain statistical parametric map.”</p><p>In addition, we now present activation time courses around between-movie boundaries from three regions of interest used in the study (posterior medial cortex, angular gyrus, and auditory cortex) in Figure 1—figure supplement 1. The activation time courses show transient increases in activation followed by longer-lasting decreases in activation at between-movie boundaries during recall. Thus, although the whole-brain maps in Figure 1B show positive responses in a subset of DMN areas, both positive responses and (perhaps more predominantly) negative responses are present in the DMN following boundaries. Figure 1—video 1 also clearly demonstrates the whole-brain BOLD time course.</p><disp-quote content-type="editor-comment"><p>6. Paper format: Reviewers felt the paper would be better suited for a longer format article, with separate Results and Discussion sections. That would allow for a more extensive discussion (see following points) of what the results might mean for our current understanding of how event segmentation works.</p></disp-quote><p>We agree with the reviewers that the manuscript can be improved by separating the Results and Discussion sections and adding more in-depth treatment of the findings. Following the reviewers’ suggestions, we divided Results and Discussion into two separate sections and substantially expanded the Discussion (see our responses for Comments 7-8 below). We greatly appreciate the opportunity to expand on our ideas in a longer format.</p><disp-quote content-type="editor-comment"><p>7. Discussion: Reviewers felt the Discussion was too short, and felt the authors' interesting and thought-providing findings warranted a more extensive unpacking. Reviewers would like to see a more fleshed-out exploration of what this general cognitive state that may exist between events might look like, and what it might be doing.</p></disp-quote><p>We thank the reviewers for their suggestions. We expanded the discussion on the potential nature of the general boundary state in the revised Discussion section as below. We also added extended text relating our results to existing empirical and theoretical work. Please see the revised manuscript for the remaining parts of the Discussion section.</p><p>p.15. “What is the cognitive state that is generalized across internal- and external boundaries between completely different contexts, but distinct from the state evoked by boundaries within the same context? We speculate that the between-movie boundary state may be a temporary “relay” state that occurs when no one mental model wins the competition to receive full attentional focus following the flushing of the prior mental context. Namely, when one major mental context switches to another, the brain may pass through a transient off-focus (Mittner et al., 2016) or mind-blanking (Mortaheb et al., 2022; Ward and Wegner, 2013) state which is distinct from both processing external stimuli (e.g., movie watching) and engaging in internal thoughts (e.g., memory recall). This account may also explain the difference between within- vs. between-movie boundary patterns: in terms of attentional fluctuation (Jayakumar et al., 2022; Song, Finn, et al., 2021), external attention is enhanced at within-movie event boundaries (Pradhan and Kumar, 2021; Zacks et al., 2007), whereas the relay state is associated with lapses in attention (deBettencourt et al., 2018; Esterman et al., 2014). An alternative, but not mutually exclusive, possibility is that the boundary state involves the recruitment of cognitive control to resolve the competition between mental contexts. This idea is based on the observation that the areas showing relatively higher activation at between-movie boundaries overlap with the frontoparietal control network (FPCN; Vincent et al., 2008) both during encoding and recall (Figure 1B, Figure 1-video 2). As the FPCN is interdigitated with the DMN and other nearby areas within individual subjects (Braga and Buckner, 2017), relative activation of the FPCN may create the stereotyped boundary pattern in higher associative cortices. It is also noteworthy that both of these candidate cognitive states are triggered not by the onset but by the offset of a mental context; the onset would rather signal the resolution of competition between mental contexts, hence the end of those states. This dovetails with our results showing that the generalized boundary pattern appears well before movie onsets, suggesting a major contribution of offset responses.”</p><disp-quote content-type="editor-comment"><p>8. Also to consider in the expanded the Discussion: It is very unclear at this point whether the observed pattern of neural responses is related to the specific setup of the study or whether subtle shifts in context versus more intense transitions involve fundamentally different mechanism. I understand that this question probably cannot be answered with the current dataset, but I would appreciate some additional discussion related to this question, as well suggestions for how this could be clarified in future studies.</p></disp-quote><p>Following the Reviewers’ suggestions, we now provide more in-depth discussion on the within- vs. between-movie boundary distinction (i.e., subtle vs. intense transitions) in the revised Discussion section as below:</p><p>p.14. “Although the boundary-related PMC activation patterns were consistent across internally- and externally-driven boundaries, they did not generalize across within- and between-movie boundaries. Relatedly, a recent human neurophysiological study (Zheng et al., 2022) reported that medial temporal cortex neurons distinguished within- and between-movie boundaries while subjects were watching short video clips; some neurons responded only to between-movie boundaries, whereas a separate group of neurons responded to both types of boundaries. These findings may be in line with the view that event boundaries have a hierarchical structure, with different brain areas along the information pathway reflecting different levels of boundaries, from fine-grained sensory transitions to coarse-grained situational transitions (Baldassano et al., 2017; Chang et al., 2021; Geerligs et al., 2021). However, it is still puzzling that within- and between-movie boundaries in our study produced qualitatively distinct neural patterns within a highest-order area (PMC), even though both categories consisted of prominent boundaries between situations spanning tens of seconds to several minutes. What are the crucial differences between the two levels of boundaries? One important factor might be the presence or absence of inter-event connections. Even the most salient within-movie boundaries still demand some integration of information across events, as the events are semantically or causally related, and ultimately constitute a single coherent narrative (Lee and Chen, 2021; Song, Park, et al., 2021). In contrast, an entire cluster of related events, or the narrative as a whole, might be completely “flushed” at between-movie boundaries; this difference could induce distinct cognitive states at the two levels of boundaries, giving rise to different PMC patterns.”</p><p>In addition, in the last paragraph of the Discussion section, we suggest a future study for testing whether our findings would be generalized in more realistic and unconstrained settings:</p><p>pp.15-16. “In conclusion, we found that internally-driven boundaries between memories produce a stereotyped activation pattern in the DMN, potentially reflecting a unique cognitive state associated with the flushing and updating of mental contexts. By demonstrating stimulus-independent event segmentation during continuous and naturalistic recall, our study bridges the gap between the fields of event segmentation and spontaneous internal thoughts (also see Tseng and Poppenk, 2020). Without any task demands or external constraints, the mind constantly shifts between different internal contexts (Raffaelli et al., 2021; Sripada and Taxali, 2020). What are the characteristics of neural responses to different types of spontaneous mental context boundaries (e.g., between two different memories, between external attention and future thinking)? Is the boundary pattern observed in the current study further generalizable to mental context transitions even more stark than between-movie transitions in our experiment? Are there specific neural signatures that predict subsequent thought transitions? Future work will explore answers to these questions by employing neuroimaging methods with behavioral paradigms that explicitly and continuously track the unconstrained flow of thoughts in naturalistic settings.”</p><disp-quote content-type="editor-comment"><p>9. Figure 4 results presentation: Regarding the correlations between the average between-movie boundary pattern and (1) between-movie boundaries, (2) moments of silence, (3) within-movie boundaries (i.e., the data displayed in Figure 4), we had to re-read this figure caption and Results section a few times to feel that we really grasped what comparisons were being made, and how these correlations were being conducted. We think this could stand to be tweaked to be clearer, with perhaps a conceptual diagram like the one in Figure 2A included to aid in understanding.</p></disp-quote><p>We apologize for the ambiguity in visualizing our results in Figure 4. To help readers understand the figure, we divided Figure 4 into two different figures: Figure 4 reporting the between-movie vs. within-movie boundary pattern comparison, and Figure 5 reporting control analyses regarding the silence at boundaries (also see our response to Comment #10). In the revised Figure 4 we added a new panel explaining the analysis method with a detailed caption. We used a color scheme that connects the specific comparisons depicted in the analysis schematic (Figure 4A) and the conditions reported in the result graph (Figure 4B). Note that we now report results from PMC only, as the within- vs. between-movie boundary comparison in the auditory cortex was not the focus of the analysis and was not discussed in the text.</p><p>We also revised the Results section and the Methods section as below. We report the correlation between the between-movie and within-movie boundary patterns within the encoding phase (in addition to the cross-phase correlation) to provide more complete results from the analysis.</p><p>p.9. “The within-movie event boundary pattern was also negatively correlated with the encoding phase between-movie boundary pattern (<italic>t</italic>(14) = 7.31, <italic>p</italic> &lt;.001, Cohen’s <italic>d</italic><sub>z</sub> = 1.89, 95% CI = [-.44, -.24]).”</p><p>p.21. “For each subject, we generated the mean within-movie event boundary pattern of PMC by averaging activation patterns from 4.5 to 19.5 seconds following each of the 15 event boundaries during encoding. The patterns were first averaged across all time points within each boundary period time window and then across different boundaries. Likewise, the mean between-movie boundary pattern was generated by averaging all activation patterns from 4.5 to 19.5 seconds following the offset of each movie during encoding or recall. We then computed a Pearson correlation coefficient across the mean within-movie event boundary pattern and the mean encoding or recall between-movie boundary pattern.”</p><p>To report the ‘No sound’ condition from PMC and the auditory cortex in the previous version of Figure 4, we created Figure 5. We additionally included a schematic of the analysis to help readers understand the analysis.</p><disp-quote content-type="editor-comment"><p>10. Clarifying no-sound condition: Following from the above point, we were initially not totally clear on the relevance or importance of the 'no sound' condition. Upon reading further into the Results, it made sense, but seeing as this figure is referenced well before this condition is expanded upon, we think this could be motivated a little earlier to mitigate unnecessary confusion. As of now, this set of analyses seems to be motivated after presentation of the data rather than before, and simply shifting this around could aid in understanding.</p></disp-quote><p>We thank the reviewers for their suggestion. As we wrote in our response to the comment #9 above, we divided Figure 4 into two so that the revised Figure 4 shows the comparison between within- and between-movie boundary patterns only, and the new Figure 5 shows the control analysis corresponding to the ‘no sound’ condition in the original Figure 4. We now present Figure 5 after the paragraph describing the control analyses, so that there is no confusion due to the order in which the results and figures are presented.</p><disp-quote content-type="editor-comment"><p>11. Figure 3 results presentation: I was not sure I fully understood the offset vs. onset yoking analysis-both how it was performed, and how the conclusions followed from the results. First, I was a bit confused about how the difference in delay duration between movies at encoding (6s) versus at recall (9.3s on average, but variable; see also comment #5) would play into this and whether those are meaningful time points to display on the Figure 3D charts that might help the reader interpret those findings.</p></disp-quote><p>We apologize for not being clearer in describing the analysis methods and conclusion of the offset vs. onset analysis. Regarding the delay duration, we first agree with the reviewer that displaying the delay duration between movie offsets and onsets on the time-time correlation matrices will facilitate interpretation of the results. Unlike in many prior studies where the offset of an event is identical to the onset of the following event (e.g., Baldassano et al., 2017), movie offsets and onsets were temporally separated in our study. This is an important point that allowed us to distinguish the temporal emergence of the boundary pattern following movie offsets versus onsets. Thus, we now indicate the delay between onsets and offsets, on Figure 3D and Figure 3—figure supplements 2 and 4, by marking the onsets/offsets of the following/preceding movies with dotted lines.</p><p>As for whether/how the difference in the delay duration between encoding and recall phases affected the offset vs. onset analysis results, we believe that our reported results and interpretation of the offset vs. onset analysis were not systematically influenced by the “longer” delay duration during recall. As the reviewer pointed out, different delay duration can affect activation patterns around between-movie boundaries; if the delay is short, there would be a greater chance that offset responses to one movie and onset responses to the following movie are mixed together. Thus, if we assume that the offset and onset patterns are not identical to each other, mixed responses due to shorter delay duration during encoding may lower the encoding-recall pattern similarity around boundaries time-locked to either onsets or offsets. However, this cannot explain why positive encoding-recall pattern correlations appear “before” movie onsets when the activation pattern time series were time-locked to the onsets, which is the main finding of the offset vs. onset analysis. Instead, if the offset and onset patterns were mixed together during encoding (i.e., relatively early periods of encoding onset responses are actually the mixture of onset and offset responses), one would expect that positive encoding-recall pattern correlations would appear much later following onsets. Therefore, the current results can be explained by either assuming that 1) the boundary patterns are predominantly driven by offsets, or 2) the boundary responses arise following both offsets as well as onsets, and their associated activation patterns are identical; both of these accounts reject the possibility that the boundary patterns were primarily driven by movie onsets. Moreover, the effect of mixed patterns would be identical regardless of whether the delay duration is shorter during encoding or during recall. Likewise, the “greater variability” in delay duration during recall is also not likely to systematically bias the offset vs. onset difference, as it would equally affect the offset-locked encoding-recall pattern similarity and onset-locked encoding-recall pattern similarity.</p><disp-quote content-type="editor-comment"><p>Second, the authors state that this analysis shows the boundary patterns were driven by offset (more than onset) responses, but I was not sure what aspect of the results led to that conclusion. Can the authors say more about the evidence supporting this conclusion? It looks to me like there are strong correlations that emerge both after offset and onset (i.e., just above and to the right of the origin there are numerous time points with positive [red] correlations). Perhaps it is because the red positive correlations start earlier, prior to the recall itself, when yoked to the onset, but I am not sure why this means it is related to offset and not some preparation for the onset of recall (see also comment #5).</p></disp-quote><p>As the reviewer mentioned, our conclusion that offset responses have significantly contributed to the generalized boundary pattern is based on the result shown in Figure 3D (left panel): positive encoding-recall pattern correlations arose several seconds before the onset of a movie. Especially considering hemodynamic response delay (i.e., the responses actually occurred even earlier), it is unlikely that the boundary pattern arose as a “reaction” to movie onsets only. That said, we acknowledge that our results do not completely rule out the possibility that movie onsets produced similar boundary patterns as the offset patterns, because on average the temporal gaps between onsets and offsets were not large enough to perfectly distinguish onset and offset signals. Thus, we have revised the Results section as below to reframe the question being addressed (“is it the onset effect?” rather than “is it the onset effect or the offset effect?”) and clarify our interpretation of the results:</p><p>p.7. “Is the generalized boundary pattern evoked by the onset of a movie, rather than the offset? We examined this question by comparing the temporal emergence of the generalized boundary pattern following movie offsets versus onsets (Figure 3D); note that the offset of a movie was temporally separated from the onset of the following movie during both encoding and recall (see Figure 1A). Specifically, we extracted the mean time series of PMC activation patterns around between-movie boundaries, time-locked to either the onset or offset of each watched or recalled movie. We then computed between-phase (encoding-recall) pattern similarity across the individual time points of the activation pattern time series. We found that significantly positive between-phase correlations emerged well before the encoding and recall onsets (Figure 3D, left panel), starting from 4.5 seconds following the offsets of the preceding watched or recalled movie (Figure 3D, right panel). Thus, boundary patterns were not exclusively triggered by movie onsets; it is likely that offset responses significantly contributed to the boundary patterns.”</p><p>Regarding the possibility that the boundary pattern that comes right before a movie onset is related to preparatory responses to the recall onset rather than a response to the offset of the preceding recall, we first agree that there might be preparatory cognitive processes before recall speech onsets associated with covert memory retrieval of the upcoming movie. However, as the reviewer wrote, “during recall, it seems as though the participant would be bringing to mind memories of the upcoming movie B they are about to recall, while there is no way for participants to anticipate anything specific about the upcoming movie during encoding.” Thus, the anticipatory recall processing would lead to more dissimilar cognitive states between encoding and recall phases; that is, it would decrease, rather than increase, the encoding-recall pattern similarity right before the movie/recall onset. Therefore, it is unlikely to be the main factor driving the positive encoding-retrieval pattern correlations that precede onsets. The generalized boundary pattern arises <italic>despite</italic> the preparatory responses, and the more parsimonious explanation is that offset responses significantly contributed to the boundary pattern.</p><disp-quote content-type="editor-comment"><p>Also, is it interesting or meaningful that the patterns seem more compressed at recall than at encoding (i.e., the outlined red areas are skinnier than they are tall)? Please clarify.</p></disp-quote><p>The reviewer’s observation is correct: boundary patterns were stronger and lasted longer during encoding than during recall, which was also observed in univariate activation responses (e.g., Figure 1—videos 1-2). This tendency is more clearly depicted in the within-phase time-time pattern correlation matrices in Figure 3—figure supplement 4. Our speculation is that boundary patterns lasted longer during encoding partly because the between-movie boundaries were more salient during encoding, as they accompanied both external and internal context changes, whereas recall boundaries accompanied internal context changes only. In addition, compared to self-generated boundaries between already stored memories during recall, boundaries between previously unseen movies during encoding are likely to be more unpredictable and may require building a completely new mental context for the post-boundary movie. These characteristics may prolong the boundary (“relay”) cognitive state during encoding. We now briefly discuss the differential boundary pattern duration between encoding and recall in the Figure 3—figure supplement 4 caption.</p><disp-quote content-type="editor-comment"><p>12. Reasoning behind masking decisions: I am not sure the reason for masking Figure 2B and C with the a&gt;0 and c&gt;0 maps. First of all, it seems as though in RSA the actual correlation being positive or negative is not terribly meaningful and can depend on preprocessing decisions, etc. In addition to that potential issue though I'm also just generally interested in more understanding the logic behind this decision. Can the authors explain that and include it in the main paper? Were there any regions that showed for example a&lt;b, or a&lt;0 and if so, why were these not considered?</p></disp-quote><p>We apologize for not being clear about the reasoning behind masking the boundary &gt; non-boundary map with the boundary &gt; 0 map. As the reviewer mentioned, raw correlation values are generally not very meaningful in pattern similarity analysis; more important are differences between conditions of interest. However, the current study aimed to show the spatial similarity between boundary patterns across different movies/tasks, such as shown in the individual subjects’ maps in Figure 3B, and thus we wanted to confirm that the correlations between patterns were at least greater than zero. At the same time, to make sure that the consistent spatial patterns were associated with boundaries and not driven by factors unrelated to fluctuating cognitive states/situations (e.g., blood vessel shape/location), we tested whether the boundary pattern similarity was greater than the non-boundary pattern similarity. Finally, by masking the boundary &gt; non-boundary map with the boundary &gt; 0 map, we aimed to identify the conjunction areas that satisfied both criteria; note that masking the boundary &gt; 0 map with the boundary &gt; non-boundary map would indicate the same areas. We revised the Methods section of the manuscript as below to explain our reasoning:</p><p>p.19. “Finally, we identified parcels that showed significant effects in both tests after the correction, by masking the areas that showed higher pattern similarity for the boundary than non-boundary conditions with the areas that showed overall positive similarity between boundary patterns (Figure 2B). Thus, the identified parcels showed spatially similar activation patterns across different movies at recall boundaries, and the patterns were specifically associated with boundary periods only.”</p><p>In <xref ref-type="fig" rid="sa2fig3">Author response image 3</xref> we also show the boundary &gt; non-boundary maps and the boundary &gt; 0 maps without masking, each corrected for multiple comparisons. The boundary &gt; non-boundary maps and the boundary &gt; 0 maps largely overlapped with each other in both Recall-Recall pattern similarity and Encoding-Recall pattern similarity; thus, the masking procedure actually had negligible effects on the masked whole-brain maps presented in Figure 2. We opted not to show these unmasked maps in the manuscript as they are redundant to the maps presented in Figure 2 and its supplements. However, we would be happy to include them if the reviewers feel it will improve the paper.</p><fig id="sa2fig3" position="float"><label>Author response image 3.</label><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-73693-sa2-fig3-v2.tif"/></fig><p>Finally, as shown in <xref ref-type="fig" rid="sa2fig3">Author response image 3</xref>, no cortical parcel showed significantly negative pattern similarity between boundary patterns in both Recall-Recall pattern similarity and Encoding-Recall pattern similarity. Likewise, no cortical parcel showed significantly lower pattern similarity between boundary patterns compared to the similarity between non-boundary patterns. We now report these findings in the text as below:</p><p>p.5. “Thus, the boundary patterns within the recall phase were likely to be driven by both shared low-level sensory/motor factors (e.g., breaks in recall speech generation) as well as cognitive states (e.g., memory retrieval) at recall boundaries. No cortical parcel showed significantly negative correlations between boundary patterns or greater correlations in the non-boundary compared to boundary conditions.”</p><p>p.7. “To test this, we again computed between-movie pattern similarity for all cortical parcels in the brain, but now across the encoding and recall phases (Figure 2A, red arrows). We found that DMN areas showed a consistent boundary pattern across task phases (encoding and recall) and across movies (Figure 2C). Again, no cortical parcel showed negative correlations between boundary patterns or greater correlations in the non-boundary condition.”</p><disp-quote content-type="editor-comment"><p>13. Clarity suggestions: The Reviewers also had several other suggestions that might increase the clarity of results presentation and/or depictions. The authors should please consider these suggestions and implement if they see fit.</p></disp-quote><p>We thank the reviewers for providing valuable suggestions that helped us improve the clarity of the manuscript. We carefully addressed all suggestions and revised the text, figures, and figure supplements accordingly. Please see our responses to individual comments from the “Recommendations for the authors” by each reviewer.</p><disp-quote content-type="editor-comment"><p>Reviewer #1 (Recommendations for the authors):</p><p>1. I had a couple more specific comments and ideas/suggestions:</p><p>a) Regarding p. 6, line 218-219: &quot;boundary and non-boundary periods were identical in terms of visual input during recall and speech generation during movie watching&quot;: Please clarify this phrasing. I thought boundary periods would be a blank screen, and non-boundary would be a movie playing during encoding and have verbal recall happening during recall. How is it true that they are identical in terms of visual input?</p></disp-quote><p>[Copied from Essential Revisions 1] We apologize for the ambiguous phrasing. The sentence was supposed to state two separate facts: (1) visual input was identical across boundary and non-boundary periods <italic>during recall</italic>, as subjects viewed a fixation dot on black screen throughout the recall phase, and (2) boundary and non-boundary periods were identical in terms of speech generation (i.e., no speech generated) <italic>during movie watching</italic>, as subjects did not make verbal responses at all throughout the encoding phase. We revised the text as below:</p><p>p.11. “Is the generalized between-movie boundary pattern driven by shared low-level perceptual or motoric factors rather than cognitive states? First, shared visual features at between-movie boundaries (i.e., black screen) cannot explain the transient, boundary-specific similarity between encoding and recall phases, because visual input was identical across boundary and non-boundary periods during recall (i.e., a fixation dot on black background). Indeed, encoding boundary patterns were more similar to recall boundary patterns than to recall non-boundary patterns in DMN areas, suggesting a limited contribution of shared visual input to the generalized boundary pattern (Figure 2—figure supplement 2). Likewise, the absence of verbal responses at boundaries cannot explain the boundary pattern generalized across encoding and recall phases, as no speech was generated throughout the entire encoding phase.”</p><disp-quote content-type="editor-comment"><p>b) For overcoming the concern about visual input, I am wondering if perhaps the authors might be able to leverage the title screen before the very first movie in a run as a control, since this is not really a &quot;boundary&quot;? Alternatively, perhaps duration of blank screen viewing could be useful as a control since if what this is picking up on is blank-screne-ness, maybe it would increase with more time spent looking at the blank screen (?).</p></disp-quote><p>We appreciate the reviewer’s suggestion for potential control analyses. However, unfortunately, the suggested analyses would not be able to provide an appropriate control for the effects of visual input considering the design of the current study. First, there was a short (39 s) introductory cartoon played at the beginning of each encoding scanning run (see ‘Stimuli’ in the Materials and methods section), thus the title scene before the first movie of a run was also a boundary between the cartoon introduction and the movie. As for the duration of blank screen viewing, the title scene duration was largely consistent across all movies, with minimal variability depending on whether the movie clips had extra black screen periods (usually &lt; 3 s) at the beginning or end of the clips. Thus, we think the suggested analysis of relating the boundary pattern to the duration of blank screen viewing would not be sensitive enough to control for the effects of visual input.</p><p>That said, we believe that similar visual input (e.g., mostly blank black screen) is unlikely to produce the boundary pattern generalizable across encoding and recall, because the boundary pattern was transient (as shown in the time-time correlation matrices in Figure 3D) whereas visual input was consistent throughout the recall phase. [Copied from Essential Revisions 1] We confirmed this by performing an analysis directly comparing the similarity between encoding and recall boundary patterns against the similarity between encoding boundary patterns and recall non-boundary patterns. If the generalized boundary patterns that we observed were predominantly driven by shared low-level visual features, the similarity between encoding and recall boundary patterns would be approximately the same as the similarity between encoding boundary patterns and recall non-boundary patterns. However, we found that several cortical parcels, especially within the DMN, showed significantly greater encoding-recall boundary pattern similarity compared to the similarity between encoding boundary patterns and recall non-boundary patterns; the resulting maps were highly similar to the results reported in Figure 2C. Thus, the consistent boundary patterns observed in higher associative areas were not likely to be mainly due to low-level visual features shared across the experimental phases.</p><p>We revised the Results and Methods sections of the manuscript accordingly.</p><disp-quote content-type="editor-comment"><p>2. I have a number of clarification questions-these are mainly methodological choices that I simply didn't understand, and felt that further explanation or justification for these decisions should be included in the paper:</p><p>a) What was the reason for the focus on PMC? I was not sure whether the results were specific to the PMC, and/or whether and why this was an a priori ROI. Are the operations thought to be unique to the PMC, or shared with other DMN regions? More logic behind this choice would be very helpful.</p></disp-quote><p>[Copied from Essential Revisions 4] We focused on PMC primarily because PMC was the area that showed the strongest content- and task-general boundary patterns in the exploratory whole-brain analysis (Figure 2C). We clarified this reasoning behind our choice of PMC as the major region of interest in the manuscript.</p><disp-quote content-type="editor-comment"><p>b) The run structure was a bit unclear to me. Sorry if I missed this, but I saw there were two encoding scans but could not work out how many recall scans there were.</p></disp-quote><p>[Copied from Essential Revisions 3] We apologize for not clearly reporting how many scanning runs there were for the recall task. There were always two encoding runs for all subjects, but only a subset of subjects had two recall runs: 4 subjects had two recall runs, and the other subjects had one recall run. We wrote in our prior manuscript using the same dataset (Lee and Chen, 2021, bioRxiv, https://doi.org/10.1101/2021.04.24.4412874) that “in case subjects needed to take a break or the duration of the scanning run exceeded the scanner limit (35 minutes), we stopped the scan in the middle and started a new scanning run where subjects resumed from where they had stopped in the previous run. 4 of the 15 subjects included in the analysis had such a break within their spoken recall session.” We have revised the Methods section of the current manuscript as below to report the number of recall phase scanning runs.</p><p>p.17. “The recall phase consisted of two scanning runs in 4 of the 15 subjects included in the analysis. The other subjects had a single scanning run.”</p><disp-quote content-type="editor-comment"><p>c) For the non-boundary comparisons, this was described as being the middle 15s of the movie. Were there efforts made to ensure there were no (within-movie) boundaries during this period? I was not sure whether these would be different (and if so, how different) from the event offset comparisons.</p></disp-quote><p>We thank the reviewer for raising this important point. Two of the 15-s non-boundary (middle) periods partially overlapped with within-movie event boundary periods by 3 TRs and 9 TRs, respectively. However, for our initial main analyses comparing between-movie boundary periods and non-boundary periods, we opted not to exclude or adjust the non-boundary periods that overlapped with the within-movie boundary periods. There were two reasons for this decision:</p><p>– First, within-movie boundaries were not of a priori interest. The focus of our study was internally-generated boundaries during recall; while between-movie boundaries were easy to identify during recall for all subjects, within-movie event boundaries often could not be reliably defined during recall because it was common for subjects to summarize or combine several events, and subjects varied in how they did so. This was the primary reason that we chose to examine between-movie boundaries rather than within-movie event boundaries.</p><p>– In addition, it is very difficult to completely avoid any event boundary when selecting a non-boundary time window within a movie. Although we included only the strongest within-movie event boundaries in our analysis to maximize effects when comparing within vs. between-movie boundaries, within-movie event boundaries are easily perceived at much finer-grained levels, occurring every few seconds. These finer-grained event boundaries could also be perceived at different moments across subjects. In other words, regardless of how we define non-boundary periods, there are almost always some possibilities of including these weaker within-event boundaries.</p><p>For these reasons, we chose not to consider the within-movie event boundaries in our primary boundary vs. non-boundary comparison; and thus it was reasonable for us to define non-boundary periods as the time windows farthest away from any between-movie boundaries (i.e., middle segments) rather than identifying and avoiding all possible within-movie boundaries. This choice also allowed us to define non-boundary patterns in all 10 movies and keep the non-boundary period definition consistent across movies.</p><p>That said, we performed extra analyses to confirm that including the two non-boundary periods that partially overlapped with within-movie event boundary periods did not influence the results in our study. Specifically, we computed the PMC pattern similarity between non-boundary patterns from different movies within the encoding phase (i.e., encoding-encoding non-boundary pattern similarity), and across encoding and recall phases (i.e., encoding-recall non-boundary pattern similarity), including or excluding the two periods overlapping with within-movie boundary periods. Likewise, we also computed the between-movie PMC pattern similarity between non-boundary and movie-offset patterns, within the encoding phase (i.e., encoding-encoding boundary-non-boundary similarity) and across experimental phases (i.e., encoding-recall boundary-non-boundary similarity), including or excluding the two periods. The results confirmed that including or excluding the two non-boundary periods overlapping with within-movie boundary periods does not change any of the pattern similarity measures (two-tailed paired <italic>t</italic>-tests, all <italic>t</italic>(14)s &lt; 1.45, all <italic>p</italic>s &gt;.17). We now report the overlap between non-boundary and within-movie boundary periods and its effect in the Methods section of the revised manuscript as below:</p><p>p.21. “Two of the non-boundary periods partially overlapped with the within-movie boundary periods by 13.5 seconds and 4.5 seconds, respectively, and were excluded when correlating within-movie boundary patterns and non-boundary patterns. Note that the two non-boundary periods were included in other analyses in the current study comparing between-movie boundary patterns and non-boundary patterns. However, excluding or including the two non-boundary periods did not significantly change any of the mean pairwise between-movie correlations across (1) encoding non-boundary patterns, (2) encoding non-boundary and between-movie boundary patterns, (3) encoding non-boundary and recall non-boundary patterns, and (4) encoding non-boundary and recall between-movie boundary patterns in PMC (two-tailed paired-samples <italic>t</italic>-tests, all <italic>t</italic>(14)s &lt; 1.45, all <italic>p</italic>s &gt;.17).”</p><p>A remaining important question would be whether there are consistent within-movie boundary patterns distinct from non-boundary patterns. To test this, we performed a new analysis: we first computed the mean PMC pattern similarity between within-movie boundaries across different movies, and then compared it against the mean pattern similarity between the within-movie boundary patterns and the non-boundary patterns during encoding across different movies. The two non-boundary patterns that overlapped with within-movie boundaries were excluded from this analysis. We found that there were positive correlations between within-movie event boundary patterns, and the correlation was higher than the correlation between within-movie boundary patterns and non-boundary patterns, as shown in Figure 4—figure supplement 1. In other words, during encoding, within-movie event boundary patterns were more similar to other within-movie event boundary patterns from different movies, than to non-boundary patterns in different movies. Although the overall similarity between within-movie event boundary patterns was much lower than the similarity between movie offset patterns, this may suggest the presence of consistent within-movie boundary patterns not identical to non-boundary patterns.</p><p>We revised the Results and Methods sections accordingly:</p><p>p.9. “Thus, we hypothesized that boundaries between movies (i.e., between mental contexts) would manifest as stronger versions of within-movie boundaries with qualitatively similar patterns; in other words, boundary patterns would generalize across different scales of boundaries. To test this idea, we first confirmed that there were consistent within-movie event boundary patterns in PMC during encoding; within-movie boundary patterns were more similar to each other than to non-boundary patterns (Figure 4—figure supplement 1).”</p><p>pp.20-21. “We first examined whether there were consistent activation patterns following the within-movie event boundaries distinct from non-boundary patterns (Figure 4—figure supplement 1). For each subject, we generated the mean PMC activation pattern for each within-movie boundary by averaging patterns from 4.5 to 19.5 seconds following the within-movie boundary during encoding. We then computed pairwise between-movie Pearson correlations across the within-movie boundary patterns, and averaged the correlations. A two-tailed one-sample <italic>t</italic>-test against zero was performed to test whether the similarity between the within-movie boundary patterns was overall positive. We also computed pairwise between-movie correlations across the within-movie boundary patterns and non-boundary patterns during encoding. The non-boundary pattern for each movie was generated by averaging activation patterns within the middle 15 seconds of the movie (time window shifted forward by 4.5 seconds). A two-tailed paired-samples <italic>t</italic>-test was performed to test whether the similarity between within-movie boundary patterns was greater than the similarity between within-movie boundary patterns and non-boundary patterns.”</p><disp-quote content-type="editor-comment"><p>d) I was not sure how the &quot;higher-than-average&quot; and &quot;lower-than-average&quot; regions were defined, specifically. What is the average in this case?</p></disp-quote><p>The average activation was the average BOLD responses of all volumes collected within a scanning run, and the BOLD responses were z-scored within each run. Thus, the average value was z = 0, and the whole-brain maps in Figure 1 show areas that were relatively activated (positive z) or deactivated (negative z) following between-movie boundaries compared to the average. We have revised the caption for Figure 1 to clarify what the average activation means.</p><p>p. 4. “Blue areas indicate regions with lower-than-average activation, where the average activation of a scanning run was z = 0. Likewise, red areas indicate regions with higher-than-average activation.”</p><disp-quote content-type="editor-comment"><p>e) Page 6, line 130: this phrasing was confusing to me: &quot;this correlation was higher at boundaries than at non-boundaries (Figure 2A, blue arrows).&quot; It made me think that the &quot;blue arrows&quot; in the parentheses may refer to the non-boundaries, but the blue arrows in the figure appear to be across-movie correlation for both boundary (left activation pattern pair in Figure 2A), and non-boundary (right pair Figure 2A) time points. Perhaps rephrase? Maybe &quot;Figure 2A, a versus b blue arrows&quot;?</p></disp-quote><p>We apologize for the ambiguous phrasing. We have revised the text as below:</p><p>p.5. “We performed a whole-brain pattern similarity analysis on the recall data to identify regions where (1) boundary period activation patterns were positively correlated across different recalled movies (Figure 2A, blue arrow <italic>a</italic> &gt; 0), and (2) this correlation was higher at boundaries than at non-boundaries (Figure 2A, blue arrows <italic>a</italic> &gt; <italic>b</italic>).”</p><disp-quote content-type="editor-comment"><p>f) Another phrasing question: &quot;…, suggesting that the between-movie boundary pattern may reflect a cognitive state qualitatively different from the state elicited by event boundaries during movie watching (e.g., attentional engagement; Song et al., 2021).&quot; I'm not quite sure what the authors mean by &quot;e.g., attentional engagement&quot;. Can you explain further? Differences in attentional engagement across these two experience types, perhaps?</p></disp-quote><p>By mentioning the “attentional engagement,” we meant a possible increase in attentional engagement or arousal at within-movie event boundaries. We speculated that this increased attention at event boundaries might be different from the cognitive states associated with the complete reconfiguration of situation models that might occur at between-movie boundaries. We revised the sentence in the Results section as below, and provided further explanation in the Discussion section to clarify this point:</p><p>p.9. “These results suggest that the between-movie boundary pattern may reflect a cognitive state qualitatively different from the state elicited by within-movie event boundaries during movie watching.”</p><p>p.15. “We speculate that the between-movie boundary state may be a temporary “relay” state that occurs when no one mental model wins the competition to receive full attentional focus following the flushing of the prior mental context. Namely, when one major mental context switches to another, the brain may pass through a transient off-focus (Mittner et al., 2016) or mind-blanking (Mortaheb et al., 2022; Ward and Wegner, 2013) state which is distinct from both processing external stimuli (e.g., movie watching) and engaging in internal thoughts (e.g., memory recall). This account may also explain the difference between within- vs. between-movie boundary patterns: in terms of attentional fluctuation (Jayakumar et al., 2022; Song, Finn, et al., 2021), external attention is enhanced at within-movie event boundaries (Pradhan and Kumar, 2021; Zacks et al., 2007), whereas the relay state is associated with lapses in attention (deBettencourt et al., 2018; Esterman et al., 2014).”</p><disp-quote content-type="editor-comment"><p>g) As may be clear from my public comment #2, the presentation of results in Figure 3D was hard for me to understand. Perhaps the authors could think of ways to plot this differently or spell out more explicitly the patterns of interest in the paper or legend to help readers understand. I would have loved more hand-holding for this analysis.</p></disp-quote><p>We apologize for the unclear description of the offset vs. onset analysis depicted in Figure 3D. To clarify the logic behind the analysis and the results, we now provide more detailed explanations in the Results section of the manuscript as below:</p><p>p.7. “Is the generalized boundary pattern evoked by the onset of a movie, rather than the offset? We examined this question by comparing the temporal emergence of the generalized boundary pattern following movie offsets versus onsets (Figure 3D); note that the offset of a movie was temporally separated from the onset of the following movie during both encoding and recall (see Figure 1A). Specifically, we extracted the mean time series of PMC activation patterns around between-movie boundaries, time-locked to either the onset or offset of each watched or recalled movie. We then computed between-phase (encoding-recall) pattern similarity across the individual time points of the activation pattern time series. We found that significantly positive between-phase correlations emerged well before the encoding and recall onsets (Figure 3D, left panel), starting from 4.5 seconds following the offsets of the preceding watched or recalled movie (Figure 3D, right panel). Thus, boundary patterns were not exclusively triggered by movie onsets; it is likely that offset responses significantly contributed to the boundary patterns.”</p><p>Following the reviewer’s suggestion, we also indicated the delay duration between onsets and offsets on Figure 3D and Figure 3—figure supplements 2 and 4, by marking the onsets/offsets of the following/preceding movies with dotted lines</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the authors):</p><p>We really enjoyed this manuscript and had very few suggestions or requests for tweaks. We note these below:</p><p>1. We recognize that this is a short-format submission, but honestly, the 'Discussion' section of this paper just felt far too short. These are very interesting and thought-provoking results, which did not feel commensurate with the very small amount of text devoted to unpacking the findings and their implications. Note that we are not suggesting the authors did a poor job of constructing these two paragraphs, but rather we think that this is simply not enough space to really do justice to a broader conversation that can be had about these findings. We suggest (if possible, from an editorial standpoint) that a lengthier discussion could really solidify the contributions of this paper and make the connections to other studies and other ideas about event cognition and event memory more explicit. In particular, I would love to hear a more fleshed-out exploration of what this general cognitive state that may exist between events might look like, and what it might be doing.</p></disp-quote><p>[Copied from Essential Revisions 7] We thank the reviewers for their suggestions. We expanded the discussion on the potential nature of the general boundary state in the revised Discussion section. We also added extended text relating our results to existing empirical and theoretical work. Please see the revised manuscript for the remaining parts of the Discussion section.</p><disp-quote content-type="editor-comment"><p>2. The authors operationalized boundary periods as &quot;…the first 15 seconds following the offset of each recalled movie, and the non-boundary periods…&quot; as &quot;…the 15 seconds in the middle of each recalled movie.&quot; Why was a window of 15 seconds chosen? While I do not have any reason to suspect the results would be wildly different if, say, a 10 or 20 second window was used, we think some justification or indication of why this particular parameter was chosen would be good to include.</p></disp-quote><p>[Copied from Essential Revisions 2] Our choice of the boundary/non-boundary period time windows was primarily based on the time courses of boundary-related univariate responses, examined during the basic exploration of recall offset effects. As shown in Figure 1—figure supplement 1, boundary-related signals tended to last up to 30 seconds from recall offset, with the largest responses (deactivation) observed around approximately 15 seconds from the offset. Thus, we decided to use a time window of 15 seconds (shown as a red bar on the x axis) to include most of the time points that showed boundary responses.</p><p>In addition, as shown in Figure 3D, the time-time correlations between activation patterns around boundaries indicated that the generalized boundary activation pattern in PMC lasted until around 15 seconds from the movie/recall offset. That is, activation patterns remained stable for at least about 15 seconds from the offset. Thus, we aimed to generate clearer activation patterns to be used for analyses by taking the average of the stable patterns across time points that spanned the 15-s window.</p><p>We now clarify our decision for using a relatively long time window of 15 seconds in the Methods section.</p><disp-quote content-type="editor-comment"><p>3. Regarding Figure 2, we personally think that a different color gradient might be a better choice for the dark gray inflated brain image. This is a minor nit-pick, but the darker red colors do not show up against the dark sulcus portions of the map particularly well, and a different gradient might be preferable. This would be particularly true if individuals were to view this figure in grayscale, or in cases of color-blindness.</p></disp-quote><p>We thank the reviewers for their suggestion to use an alternative color gradient so that our manuscript becomes more accessible to colorblind and visually impaired readers. Following the reviewers’ comment, we changed the colormap used in Figure 2B-C.</p><disp-quote content-type="editor-comment"><p>4. If so many individual parcels from the Schaefer atlas were examined, it is not clear why PCC and Precuneus were combined into a PMC ROI. While we do not particularly suspect that PCC and precuneus should look very different, we think a brief note of why these regions were combined and many others weren't would be good to include.</p></disp-quote><p>[Copied from Essential Revisions 4] We created a single PMC ROI mask by combining the PCC and precuneus to be consistent with our prior study that analyzed the same region of interest (Lee and Chen, 2021). Our decision to use PMC including both the PCC and precuneus in our current and prior studies was based on the atlas of functional networks widely used in the field (Schaefer et al., 2018). In the Schaefer atlas, the two regions together form the posterior medial sub-region of the default network, and the parcels that we combined to create the PMC ROI all fell within the default network. In addition, we observed the content- and task-general boundary pattern in the larger PMC area in our whole-brain analysis (Figure 2C), and thus we opted to use a single large PMC mask for our ROI analysis rather than breaking the continuous area into several sub-regions. As Reviewer 2 mentioned in their Recommendations #4, it is unlikely that the PCC and precuneus would show qualitatively different results, because the whole-brain analysis using smaller parcels already demonstrated that the PCC and precuneus as well as their fine-grained sub-areas all showed boundary patterns consistent across experimental phases. We revised the Methods section of the manuscript as below to explain our reasons for combining the two regions:</p><p>p.17. “For region-of-interest analyses, we defined the bilateral posterior-medial cortex (PMC) by combining the parcels corresponding to the precuneus and posterior cingulate cortex within Default Network A as in our prior study (Lee and Chen, 2021). The precuneus and posterior cingulate cortex together spanned the area that showed the strongest content-and task-general boundary patterns in the whole-brain analysis (Figure 3C). The bilateral angular gyrus ROI consisted of the parcels corresponding to the inferior parietal cortex within Default Network A, B and C.”</p><disp-quote content-type="editor-comment"><p>5. Regarding the correlations between the average between-movie boundary pattern and (1) between-movie boundaries, (2) moments of silence, (3) within-movie boundaries (i.e., the data displayed in Figure 4), we had to re-read this figure caption and Results section a few times to feel that we really grasped what comparisons were being made, and how these correlations were being conducted. We think this could stand to be tweaked to be clearer, with perhaps a conceptual diagram like the one in Figure 2A included to aid in understanding.</p></disp-quote><p>[Copied from Essential Revisions 9] We apologize for the ambiguity in visualizing our results in Figure 4. To help readers understand the figure, we divided Figure 4 into two different figures: Figure 4 reporting the between-movie vs. within-movie boundary pattern comparison, and Figure 5 reporting control analyses regarding the silence at boundaries (also see our response to Comment #10). In the revised Figure 4, we added a new panel explaining the analysis method with a detailed caption. We used a color scheme that connects the specific comparisons depicted in the analysis schematic (Figure 4A) and the conditions reported in the result graph (Figure 4B). Note that we now report results from PMC only, as the within- vs. between-movie boundary comparison in the auditory cortex was not the focus of the analysis and was not discussed in the text.</p><p>We also revised the Results section and the Methods section. We report the correlation between the between-movie and within-movie boundary patterns within the encoding phase (in addition to the cross-phase correlation) to provide more complete results from the analysis.</p><disp-quote content-type="editor-comment"><p>6. Following from the above point, we were initially not totally clear on the relevance or importance of the 'no sound' condition. Upon reading further into the Results, it made sense, but seeing as this figure is referenced well before this condition is expanded upon, we think this could be motivated a little earlier to mitigate unnecessary confusion. As of now, this set of analyses seems to be motivated after presentation of the data rather than before, and simply shifting this around could aid in understanding.</p></disp-quote><p>[Copied from Essential Revisions 10] We thank the reviewers for their suggestion. As we wrote in our response to the comment #5 above, we divided Figure 4 into two so that the revised Figure 4 shows the comparison between within- and between-movie boundary patterns only, and the new Figure 5 shows the control analysis corresponding to the ‘no sound’ condition in the original Figure 4. We now present Figure 5 after the paragraph describing the control analyses, so that there is no confusion due to the order in which the results and figures are presented.</p><disp-quote content-type="editor-comment"><p>Reviewer #3 (Recommendations for the authors):</p><p>Specific suggestions the authors related to the points mentioned above:</p><p>1. To address the effect of similarity between encoding and recall due to the (lack of) perceptual input, it would be relevant to add an additional comparisons to the analyses as shown in figure 2: the similarity between middle segments during recall and boundary segments during encoding.</p></disp-quote><p>We thank the reviewer for suggesting this analysis. Following the reviewer’s suggestion, we performed a new whole-brain pattern similarity analysis directly comparing the similarity between encoding and recall boundary patterns against the similarity between encoding boundary patterns and recall non-boundary patterns. As visual input was consistent across the boundary and non-boundary periods during recall, this analysis allowed us to control for the effects of shared visual features on the generalized boundary patterns. [Copied from Essential Revisions 1] That is, if the generalized boundary patterns that we observed were predominantly driven by shared low-level visual features (i.e., subjects viewed mostly-blank screens during boundary periods in both encoding and recall phases), the similarity between encoding and recall boundary patterns would be approximately the same as the similarity between encoding boundary patterns and recall non-boundary patterns. However, we found that several cortical parcels, especially within the DMN, showed significantly greater encoding-recall boundary pattern similarity compared to the similarity between encoding boundary patterns and recall non-boundary patterns; the resulting maps were highly similar to the results reported in Figure 2C. Thus, the consistent boundary patterns observed in higher associative areas were not likely to be mainly due to low-level visual features shared across the experimental phases. We now report this analysis in Figure 2—figure supplement 2.</p><p>We revised the Results and Methods sections of the manuscript accordingly.</p><disp-quote content-type="editor-comment"><p>2. I wonder why the authors choose to focus on a long window of 15 seconds after stimulus onset rather than a shorter window. I would suggest investigating the similarity between the within-movie and between-movie event boundaries by focusing on a shorter window (e.g. 2 TRs). Additionally, I would propose running an analysis like the one in figure 3D for the within-movie and between-movie event boundaries to see how the (dis)similarity develops over time.</p></disp-quote><p>[Copied from Essential Revisions 2] Our choice of the boundary/non-boundary period time windows was primarily based on the time courses of boundary-related univariate responses, examined during the basic exploration of recall offset effects. As shown in Figure 1—figure supplement 1, boundary-related signals tended to last up to 30 seconds from recall offset, with the largest responses (deactivation) observed around approximately 15 seconds from the offset. Thus, we decided to use a time window of 15 seconds (shown as a red bar on the x axis) to include most of the time points that showed boundary responses.</p><p>In addition, as shown in Figure 3D, the time-time correlations between activation patterns around boundaries indicated that the generalized boundary activation pattern in PMC lasted until around 15 seconds from the movie/recall offset. That is, activation patterns remained stable for at least about 15 seconds from the offset. Thus, we aimed to generate clearer activation patterns to be used for analyses by taking the average of the stable patterns across time points that spanned the 15-s window.</p><p>We now clarify our decision for using a relatively long time window of 15 seconds in the Methods section.</p><disp-quote content-type="editor-comment"><p>3. It is very unclear at this point whether the observed pattern of neural responses is related to the specific setup of the study or whether subtle shifts in context versus more intense transitions involve fundamentally different mechanism. I understand that this question probably cannot be answered with the current dataset, but I would appreciate some additional discussion related to this question, as well suggestions for how this could be clarified in future studies. I think the paper might be more suitable for a longer format, with a separate results and Discussion section. That would allow for a more extensive discussion for what the results might mean for our current understanding of how event segmentation works.</p></disp-quote><p>[Copied from Essential Revisions 6, 8] We agree with the reviewer that the manuscript can be improved by separating the Results and Discussion sections and adding more in-depth treatment of the findings. Following the reviewer’ suggestions, we divided Results and Discussion into two separate sections and substantially expanded the Discussion. We now provide more in-depth discussion on the within- vs. between-movie boundary distinction (i.e., subtle vs. intense transitions) in the revised Discussion section as below:</p><p>p.14. “Although the boundary-related PMC activation patterns were consistent across internally- and externally-driven boundaries, they did not generalize across within- and between-movie boundaries. Relatedly, a recent human neurophysiological study (Zheng et al., 2022) reported that medial temporal cortex neurons distinguished within- and between-movie boundaries while subjects were watching short video clips; some neurons responded only to between-movie boundaries, whereas a separate group of neurons responded to both types of boundaries. These findings may be in line with the view that event boundaries have a hierarchical structure, with different brain areas along the information pathway reflecting different levels of boundaries, from fine-grained sensory transitions to coarse-grained situational transitions (Baldassano et al., 2017; Chang et al., 2021; Geerligs et al., 2021). However, it is still puzzling that within- and between-movie boundaries in our study produced qualitatively distinct neural patterns within a highest-order area (PMC), even though both categories consisted of prominent boundaries between situations spanning tens of seconds to several minutes. What are the crucial differences between the two levels of boundaries? One important factor might be the presence or absence of inter-event connections. Even the most salient within-movie boundaries still demand some integration of information across events, as the events are semantically or causally related, and ultimately constitute a single coherent narrative (Lee and Chen, 2021; Song, Park, et al., 2021). In contrast, an entire cluster of related events, or the narrative as a whole, might be completely “flushed” at between-movie boundaries; this difference could induce distinct cognitive states at the two levels of boundaries, giving rise to different PMC patterns.”</p><p>In addition, in the last paragraph of the Discussion section, we suggest a future study for testing whether our findings would be generalized in more realistic and unconstrained settings:</p><p>pp.15-16. “In conclusion, we found that internally-driven boundaries between memories produce a stereotyped activation pattern in the DMN, potentially reflecting a unique cognitive state associated with the flushing and updating of mental contexts. By demonstrating stimulus-independent event segmentation during continuous and naturalistic recall, our study bridges the gap between the fields of event segmentation and spontaneous internal thoughts (also see Tseng and Poppenk, 2020). Without any task demands or external constraints, the mind constantly shifts between different internal contexts (Raffaelli et al., 2021; Sripada and Taxali, 2020). What are the characteristics of neural responses to different types of spontaneous mental context boundaries (e.g., between two different memories, between external attention and future thinking)? Is the boundary pattern observed in the current study further generalizable to mental context transitions even more stark than between-movie transitions in our experiment? Are there specific neural signatures that predict subsequent thought transitions? Future work will explore answers to these questions by employing neuroimaging methods with behavioral paradigms that explicitly and continuously track the unconstrained flow of thoughts in naturalistic settings.”</p></body></sub-article></article>