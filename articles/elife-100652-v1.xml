<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">100652</article-id><article-id pub-id-type="doi">10.7554/eLife.100652</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.100652.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Robust variability of grid cell properties within individual grid modules enhances encoding of local space</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" equal-contrib="yes"><name><surname>Redman</surname><given-names>William T</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4147-2026</contrib-id><email>will.redman@jhuapl.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Acosta-Mendoza</surname><given-names>Santiago</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0003-6698-476X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Wei</surname><given-names>Xue-Xin</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Goard</surname><given-names>Michael J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5366-8501</contrib-id><email>michael.goard@lifesci.ucsb.edu</email><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="aff" rid="aff8">8</xref><xref ref-type="aff" rid="aff9">9</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02t274463</institution-id><institution>Interdepartmental Graduate Program in Dynamical Neuroscience, University of California, Santa Barbara</institution></institution-wrap><addr-line><named-content content-type="city">Santa Barbara</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/029pp9z10</institution-id><institution>Intelligent Systems Center, Johns Hopkins University Applied Physics Lab</institution></institution-wrap><addr-line><named-content content-type="city">Laurel</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hj54h04</institution-id><institution>Department of Neuroscience, The University of Texas at Austin</institution></institution-wrap><addr-line><named-content content-type="city">Austin</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hj54h04</institution-id><institution>Center for Learning and Memory, The University of Texas at Austin</institution></institution-wrap><addr-line><named-content content-type="city">Austin</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hj54h04</institution-id><institution>Center for Perceptual Systems, The University of Texas at Austin</institution></institution-wrap><addr-line><named-content content-type="city">Austin</named-content></addr-line><country>United States</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hj54h04</institution-id><institution>Center for Theoretical and Computational Neuroscience, The University of Texas at Austin</institution></institution-wrap><addr-line><named-content content-type="city">Austin</named-content></addr-line><country>United States</country></aff><aff id="aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02t274463</institution-id><institution>Department of Psychological and Brain Sciences, University of California, Santa Barbara</institution></institution-wrap><addr-line><named-content content-type="city">Santa Barbara</named-content></addr-line><country>United States</country></aff><aff id="aff8"><label>8</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02t274463</institution-id><institution>Department of Molecular, Cellular, and Developmental Biology, University of California, Santa Barbara</institution></institution-wrap><addr-line><named-content content-type="city">Santa Barbara</named-content></addr-line><country>United States</country></aff><aff id="aff9"><label>9</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02t274463</institution-id><institution>Neuroscience Research Institute, University of California, Santa Barbara</institution></institution-wrap><addr-line><named-content content-type="city">Santa Barbara</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Peyrache</surname><given-names>Adrien</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01pxwe438</institution-id><institution>McGill University</institution></institution-wrap><country>Canada</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Poirazi</surname><given-names>Panayiota</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01gzszr18</institution-id><institution>FORTH Institute of Molecular Biology and Biotechnology</institution></institution-wrap><country>Greece</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>20</day><month>02</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP100652</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-07-01"><day>01</day><month>07</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-06-13"><day>13</day><month>06</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.02.27.582373"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-09-13"><day>13</day><month>09</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.100652.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-02-04"><day>04</day><month>02</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.100652.2"/></event></pub-history><permissions><copyright-statement>© 2024, Redman, Acosta-Mendoza et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Redman, Acosta-Mendoza et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-100652-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-100652-figures-v1.pdf"/><abstract><p>Although grid cells are one of the most well-studied functional classes of neurons in the mammalian brain, whether there is a single orientation and spacing value per grid module has not been carefully tested. We analyze a recent large-scale recording of medial entorhinal cortex to characterize the presence and degree of heterogeneity of grid properties within individual modules. We find evidence for small, but robust, variability and hypothesize that this property of the grid code could enhance the encoding of local spatial information. Performing analysis on synthetic populations of grid cells, where we have complete control over the amount heterogeneity in grid properties, we demonstrate that grid property variability of a similar magnitude to the analyzed data leads to significantly decreased decoding error. This holds even when restricted to activity from a single module. Our results highlight how the heterogeneity of the neural response properties may benefit coding and opens new directions for theoretical and experimental analysis of grid cells.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>grid cells</kwd><kwd>entorhinal cortex</kwd><kwd>spatial coding</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01 NS121919</award-id><principal-award-recipient><name><surname>Goard</surname><given-names>Michael J</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100001391</institution-id><institution>Whitehall Foundation</institution></institution-wrap></funding-source><award-id>2022-05-009</award-id><principal-award-recipient><name><surname>Goard</surname><given-names>Michael J</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>2318065</award-id><principal-award-recipient><name><surname>Wei</surname><given-names>Xue-Xin</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>1934288</award-id><principal-award-recipient><name><surname>Goard</surname><given-names>Michael J</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Grid cells within an individual module show significantly more variability in grid properties than would be expected by chance, resulting in improved neural representation of animal location in the environment.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The discovery of grid cells in medial entorhinal cortex (MEC; <xref ref-type="bibr" rid="bib34">Hafting et al., 2005</xref>) has led to considerable experimental and computational work aimed at identifying their origin (<xref ref-type="bibr" rid="bib33">Guanella and Verschure, 2006</xref>; <xref ref-type="bibr" rid="bib25">Fuhs and Touretzky, 2006</xref>; <xref ref-type="bibr" rid="bib6">Blair et al., 2007</xref>; <xref ref-type="bibr" rid="bib13">Couey et al., 2013</xref>; <xref ref-type="bibr" rid="bib19">Dordek et al., 2016</xref>; <xref ref-type="bibr" rid="bib14">Cueva and Wei, 2018</xref>; <xref ref-type="bibr" rid="bib5">Banino et al., 2018</xref>; <xref ref-type="bibr" rid="bib90">Weber and Sprekeler, 2018</xref>; <xref ref-type="bibr" rid="bib81">Sorscher et al., 2019</xref>; <xref ref-type="bibr" rid="bib40">Khona et al., 2022</xref>; <xref ref-type="bibr" rid="bib82">Sorscher et al., 2023</xref>) and their function (<xref ref-type="bibr" rid="bib55">McNaughton et al., 2006</xref>; <xref ref-type="bibr" rid="bib79">Solstad et al., 2006</xref>; <xref ref-type="bibr" rid="bib71">Rolls et al., 2006</xref>; <xref ref-type="bibr" rid="bib8">Burak and Fiete, 2009</xref>; <xref ref-type="bibr" rid="bib15">de Almeida et al., 2009</xref>; <xref ref-type="bibr" rid="bib45">Kubie and Fox, 2015</xref>; <xref ref-type="bibr" rid="bib9">Bush et al., 2015</xref>; <xref ref-type="bibr" rid="bib60">Ormond and McNaughton, 2015</xref>; <xref ref-type="bibr" rid="bib50">Mallory et al., 2018</xref>). The organization of grid cells into discrete modules (<xref ref-type="bibr" rid="bib86">Stensola et al., 2012</xref>; <xref ref-type="bibr" rid="bib32">Gu et al., 2018</xref>), with grid properties (grid spacing and orientation) clustered within module, but not between modules, has fundamentally shaped this research. For instance, the increasing size and spacing of grid modules along the dorsal-ventral axis of MEC, by discontinuous jumps of a near constant ratio, has been argued to be optimal for encoding local spatial information (<xref ref-type="bibr" rid="bib91">Wei et al., 2015</xref>; <xref ref-type="bibr" rid="bib85">Stemmler et al., 2015</xref>) when grid cell activity across all modules is integrated together (<xref ref-type="bibr" rid="bib24">Fiete et al., 2008</xref>; <xref ref-type="bibr" rid="bib83">Sreenivasan and Fiete, 2011</xref>; <xref ref-type="bibr" rid="bib52">Mathis et al., 2012a</xref>; <xref ref-type="bibr" rid="bib91">Wei et al., 2015</xref>; <xref ref-type="bibr" rid="bib85">Stemmler et al., 2015</xref>). This is despite the fact that the individual neurons in hippocampus, a downstream target of the MEC, receive inputs from only a portion of the dorsal-ventral axis (<xref ref-type="bibr" rid="bib89">van Strien et al., 2009</xref>). The modularity of the grid system has also been proposed to simplify the wiring necessary for generating continuous attractor dynamics (<xref ref-type="bibr" rid="bib25">Fuhs and Touretzky, 2006</xref>; <xref ref-type="bibr" rid="bib33">Guanella and Verschure, 2006</xref>; <xref ref-type="bibr" rid="bib8">Burak and Fiete, 2009</xref>; <xref ref-type="bibr" rid="bib13">Couey et al., 2013</xref>), a computational mechanism theorized to underlie grid cells function that enjoys considerable experimental support (<xref ref-type="bibr" rid="bib93">Yoon et al., 2013</xref>; <xref ref-type="bibr" rid="bib21">Dunn et al., 2015</xref>; <xref ref-type="bibr" rid="bib32">Gu et al., 2018</xref>; <xref ref-type="bibr" rid="bib27">Gardner et al., 2019</xref>; <xref ref-type="bibr" rid="bib88">Trettel et al., 2019</xref>; <xref ref-type="bibr" rid="bib28">Gardner et al., 2022</xref>).</p><p>Much of this prior theoretical work has made the additional assumption that grid cell properties are identical, up to a phase shift, within a single module (<xref ref-type="bibr" rid="bib83">Sreenivasan and Fiete, 2011</xref>; <xref ref-type="bibr" rid="bib52">Mathis et al., 2012a</xref>; <xref ref-type="bibr" rid="bib91">Wei et al., 2015</xref>; <xref ref-type="bibr" rid="bib85">Stemmler et al., 2015</xref>; <xref ref-type="bibr" rid="bib20">Dorrell et al., 2023</xref>). However, as experimentalists have been aware, the distributions of measured orientation and spacing show non-zero variability (<xref ref-type="bibr" rid="bib86">Stensola et al., 2012</xref>; <xref ref-type="bibr" rid="bib93">Yoon et al., 2013</xref>; <xref ref-type="bibr" rid="bib28">Gardner et al., 2022</xref>). This could be due to finite recording time, neurophysiological noise, and/or the sensitivity of numerical methods used to fit grid properties. Alternatively, this variability could reflect underlying inhomogeneity, at a fine scale, within modules. Despite the fundamental way in which grid cell function has been informed by their modular organization, to the best of our knowledge, no characterization of the degree and robustness of variability in grid properties within individual modules has been performed.</p><p>If robust variability of grid properties does exist, then it is possible that this heterogeneity could be exploited to encode additional information about local space, reducing the requirement of integration across multiple grid modules (<xref ref-type="fig" rid="fig1">Figure 1</xref>). In particular, when all grid cells in a module have the same grid orientation and spacing, the joint population activity has a translational invariance that persists, even as larger populations of grid cells are considered (<xref ref-type="fig" rid="fig1">Figure 1</xref>, ‘Fixed grid properties within module’). Thus, it is not possible to resolve spatial position from population activity. In contrast, if grid cells within a module have variability in their grid orientation and spacing, then – over a finite area – the translational invariance of the population activity is broken. In such a case, distinct patterns of population activity emerge in distinct locations of space (<xref ref-type="fig" rid="fig1">Figure 1</xref>, ‘Variable grid properties within module’). As an example, the blue and green grid cells in <xref ref-type="fig" rid="fig1">Figure 1</xref> show the most overlap in the upper left half of the arena (denoted by cyan pixels), while the red and blue grid cells show the most overlap in the lower right portion of the arena (denoted by purple pixels). This is despite the fact that the variability in spacing and orientation is only on the order of a few centimeters and degrees, respectively. We expect that these patterns should become more complex and contain more information that could be used to disentangle spatial location as more grid cells are considered.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Variability in grid cell properties within a module leads to enhanced encoding of local space.</title><p>When the activity of three idealized grid cells, all with the same grid spacing and orientation, are considered, the periodicity of the responses limits the amount of information conveyed about local space (Left column – ‘Fixed grid properties within module’). That is, there are multiple locations in physical space with identical population level activity. However, when three grid cells with variable grid spacing and orientation (in the realm of what is measured within individual grid modules – see Results), their joint activity contains considerably more information (Right column – ‘Variable grid properties within module’). This benefit of spatial inhomogeneity is expected to increase with larger populations of grid cells. Dashed squares in the joint activity map are enlarged below.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100652-fig1-v1.tif"/></fig><p>In this paper, we perform detailed analysis of recent state-of-the-art MEC electrophysiological recordings, which were made publicly available (<xref ref-type="bibr" rid="bib28">Gardner et al., 2022</xref>). We characterize the variability of grid orientation and spacing within individual modules and find evidence for small, but robust, variability. This variability is present whether a single value of grid orientation and spacing is assigned to each grid cell, or whether grid distortion (<xref ref-type="bibr" rid="bib16">Derdikman et al., 2009</xref>; <xref ref-type="bibr" rid="bib44">Krupic et al., 2015</xref>) is taken into account by considering three grid orientations and spacings independently. Performing similar analysis on recent normative recurrent neural network (RNN) models of grid cells (<xref ref-type="bibr" rid="bib81">Sorscher et al., 2019</xref>), we find the presence of comparable variability. This provides another possible explanation for why these RNN models have been found to capture MEC grid cell response profiles (<xref ref-type="bibr" rid="bib58">Nayebi et al., 2021</xref>). To assess the functional implications of this heterogeneity, we perform simulation experiments with synthetic, noisy grid cell populations, where we have complete control over the distribution of grid orientation and spacing. We find that the variability in grid cell orientation and spacing, at a similar degree as present in the data we analyze, leads to lower decoding error of local space when using the activity of a <italic>single</italic> module.</p><p>Taken together, our results challenge a frequently made assumption in the theoretical literature and support a growing understanding of the spatial information encoded by grid cell populations (<xref ref-type="bibr" rid="bib17">Diehl et al., 2017</xref>; <xref ref-type="bibr" rid="bib37">Ismakov et al., 2017</xref>; <xref ref-type="bibr" rid="bib22">Dunn et al., 2017</xref>; <xref ref-type="bibr" rid="bib29">Ginosar et al., 2023</xref>). Additionally, our results encourage consideration of the broader benefits that multiple modules may provide, beyond the encoding of local space (<xref ref-type="bibr" rid="bib36">Hawkins et al., 2018</xref>; <xref ref-type="bibr" rid="bib42">Klukas et al., 2020</xref>; <xref ref-type="bibr" rid="bib72">Rueckemann et al., 2021</xref>).</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Robust differences in grid cell properties within individual modules</title><p>To determine the extent to which variability of grid properties in individual modules exists, and to what extent this variability is a robust property of the grid code, we analyzed previously published MEC recordings (<xref ref-type="bibr" rid="bib28">Gardner et al., 2022</xref>), which include tens to hundreds of grid cells simultaneously recorded. This allows us to characterize the distribution of grid properties within a single grid module, to an extent not possible with other data sets.</p><p>For each grid cell, we compute the grid spacing (<inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) and orientation (<inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) by measuring properties associated with the six hexagonally distributed peaks of the spatial autocorrelogram (SAC), as traditionally performed (<xref ref-type="bibr" rid="bib73">Sargolini et al., 2006</xref>; <xref ref-type="fig" rid="fig2">Figure 2A</xref>; see Materials and methods). For clarity, we begin by focusing on a single module, recorded from an open field environment (recording identifier: Rat R, Day 1, Module 2 – R12). This module was picked for its long recording time (approximately 130 min of recorded activity, as compared to the other open field recordings that have 30 min or less of recorded activity) and for its large number of simultaneously recorded putative grid cells (<inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>168</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>). In this module, we find that grid cells with high grid scores (<inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&gt;</mml:mo><mml:mn>0.85</mml:mn><mml:mo>;</mml:mo><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>74</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) have a range of grid orientation and spacing (example cells shown in <xref ref-type="fig" rid="fig2">Figure 2B</xref>; distributions across module shown in <xref ref-type="fig" rid="fig2">Figure 2E and F</xref>), with <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> ranging from approximately 65 cm to 90 cm and <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> ranging from approximately <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mn>2</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> to <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mn>9</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. Overlaying the SACs of pairs of grid cells with similar grid spacing and different grid orientation (<xref ref-type="fig" rid="fig2">Figure 2C</xref>) or vice versa (<xref ref-type="fig" rid="fig2">Figure 2D</xref>) enables visualization of the extent of this variability.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Grid properties are variable within a single grid module (recording ID R12).</title><p>(<bold>A</bold>) Overview of the standard procedure used to calculate the grid spacing and orientation of a given grid cell. First, spike maps are computed by identifying the location of the animal at the time of each spike. Gray line denotes the trajectory of the rat, red dots denote locations of spikes. A rate map is constructed by binning space and normalizing by the amount of time the rat spent in each spatial bin. A spatial autocorrelogram (SAC) is computed and, after the center peak is masked out (white pixels in the center of the spatial autocorrelogram – leading to change in color scale), the grid properties are fit by measuring the length and angle of the three peaks closest to 0°. (<bold>B</bold>) Example grid cells from the same module (recording ID R12), with estimated grid score, orientation (<inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>), and spacing (<inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:math></inline-formula>). (<bold>C, D</bold>) SAC overlaid for two pairs of grid cells (from <bold>B</bold>); one pair with different <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and similar <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (<bold>C</bold>) and the other with similar <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and different <inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (<bold>D</bold>). (<bold>E, F</bold>) Distribution of <inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (<bold>E</bold>) and <inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (<bold>F</bold>) across all grid cells with grid score &gt;0.85 (N=74).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100652-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Variability in grid spacing within a single module exists when computing <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> directly from the rate maps.</title><p>(<bold>A</bold>) (Left) Example grid cell rate maps from the same module (recording ID R12) with overlaid triangles, corresponding to the spacing between each of the three most central peaks. Grid spacing is computed as the average of the three lengths. (Right) To aid comparison, the triangles are enlarged (with their relative size fixed) and overlaid. Note that these cells are the same ones plotted in <xref ref-type="fig" rid="fig2">Figure 2B</xref>. (<bold>B</bold>) Distribution of grid spacing computed using the SAC and the rate maps. (<bold>C</bold>) The grid spacing of all grid cells, from recording R12, computed using the SAC and the rate map. Red dashed line is the linear regression fit with <inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>R</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> and <italic>p</italic>-value reported above.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100652-fig2-figsupp1-v1.tif"/></fig></fig-group><p>Because individual grid fields can be cut-off by the boundaries of the environment, it is possible that computing the grid spacing from the SAC (which considers all grid fields) could lead to an under-estimate of <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:math></inline-formula> for some grid cells. To verify that the broad distribution of grid spacing that we see within the same module is not due to the specifics of the SAC, we recomputed the grid spacing for all grid cells directly from their rate maps, considering only the three grid fields closest to the center of the environment (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A</xref>; see Materials and methods). We find that while the grid spacing estimated from the SAC tends to be larger than the grid spacing estimated from the rate maps, a similarly broad range of <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is again present (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1B, C</xref>).</p><p>To assess whether the heterogeneity of grid properties present in a single grid module is a robust feature or attributable to noise (either in the recording or the grid property fitting procedure), we measure the variability in grid orientation and spacing within a single grid cell and between pairs of grid cells. If the heterogeneity is explainable by noise then we expect that the within-cell variability will be of the same magnitude as the between-cell variability. In contrast, if the heterogeneity is a robust feature of the grid code, then we expect the within-cell variability will be significantly smaller than the between-cell variability.</p><p>To measure the within- and between-cell variability, we split the recording into evenly spaced 30 s bins, randomly assigning each temporal bin to one of two equal length halves and computing the grid properties for each half of the recording (<xref ref-type="fig" rid="fig3">Figure 3A</xref>; see Materials and methods). We set inclusion criteria to filter out cells that do not have consistent hexagonally structured SACs across splits of the recording (see Materials and methods). Although these requirements are strict (see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> for percent of cells rejected), they set a conservative estimate on the amount of grid property variability, ensuring that we do not artificially inflate the variability due to inclusion of unreliable grid cells. We found that the length of the temporal bin used to split the data does not have a large impact on the percentage of cells accepted by this criteria (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>; see Materials and methods).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Variability of grid properties is a robust feature of individual grid module (recording ID R12).</title><p>(<bold>A</bold>) Schematic overview of approach used to compute the between- and within-cell variability of grid orientation and spacing. (<bold>B, C</bold>) Distribution of within- and between-cell variability of <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, respectively. Note that the distribution is across all 100 random shuffles of the data into two halves. (<bold>D</bold>) Average within-cell variability of grid orientation (<inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>θ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>within</mml:mtext></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>), compared to average between-cell variability of grid spacing (<inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>θ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>between</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>). (<bold>E</bold>) Same as (<bold>D</bold>), but for <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>. 1 cell was excluded from (<bold>E</bold>) for visualization (<inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>λ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>between</mml:mtext></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>20</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>), but was included in non-parametric statistical analysis. For (<bold>D, E</bold>), <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>82</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100652-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Accepted and rejected cells across all grid modules.</title><p>(Left) The percent of all cells, across all modules, that were rejected by our inclusion criteria. Cells that were rejected as not having SACs, computed with all data, that were well described by hexagonal structure (‘Rejected: Poor grid fits’) are shown in red. Cells that were rejected as not reliably having SACs, computed from splits of the data, that were well described by hexagonal structure (‘Rejected: Unreliable’) are shown in yellow. Cells that met these criteria (‘Accepted’) are shown in blue. (Middle) Grid score of all cells, with coloring denoting whether they were accepted or rejected. Dashed gray line denotes population mean. (Right) The number of splits of the data (out of 100) that cells had SAC’s with poor grid fits, as a function of each cell’s grid score.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100652-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Bin length does not affect the percent of cells accepted for analysis.</title><p>The percent of cells with good grid fits (i.e. those cells that do not get rejected for having ‘poor grid fits’) that are accepted by not being deemed unreliable, as a function of the size of the bins used in the shuffle analysis. All modules are plotted (each line is colored based on its recording ID).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100652-fig3-figsupp2-v1.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Average field width does not play a significant role in explaining the between-cell variability in spacing.</title><p>(<bold>A</bold>) Schematic illustration of how the average field width was approximated. The first minima along 1-dimensional slices through the center of the SAC are used to estimate the field width. (<bold>B</bold>) An example ratemap with the four strongest grid fields overlaid with circles having the diameter of the estimated field width. (<bold>C</bold>) Between-cell spacing variability (<inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>λ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>between</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) as a function of average field width for all cells from recording R12 that passed our inclusion criteria. Red line is the linear regression fit with <inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> and p-value reported. <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, for all other modules: Q1 = 0.06; Q2 = 0.40; R11 = 0.04; R13 = 0.03; R21 = 0.12; R22 = 0.12; S1 = 0.00.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100652-fig3-figsupp3-v1.tif"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 4.</label><caption><title>Between-cell variability does not significantly change across recording time.</title><p>(<bold>A</bold>) Schematic illustrating the sliding window analysis. Red line denotes half of data used to compute the grid properties. (<bold>B, C</bold>) Between-cell variability (estimated by computing the standard deviation of the population <inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> values) as a function of sliding window number. The slope estimated from a linear regression fit is reported. Slope in <inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, for all other modules: Q1 = 0.015 and 0.028; Q2 = –0.039 and 0.003; R11 = –0.001 and –0.005; R13 = 0.005 and –0.000; R21 = 0.014 and 0;.020; R22 = 0.044 and 0.016; S1 = 0.034 and 0.014.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100652-fig3-figsupp4-v1.tif"/></fig><fig id="fig3s5" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 5.</label><caption><title>Variability in grid spacing and orientation is not significantly affected by location of arena boundaries.</title><p>(<bold>A</bold>) Example spike map for one cell (from R12) as increasingly more of the arena is removed. Computed <inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> are reported above the spike maps. (<bold>B</bold>) SACs corresponding to the spike maps. (<bold>C, D</bold>) Between-cell variability (estimated by computing the standard deviation of the population <inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> values) as a function of how much of the arena was removed from our analysis for all modules.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100652-fig3-figsupp5-v1.tif"/></fig><fig id="fig3s6" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 6.</label><caption><title>Conjunctive head direction grid cells do not significantly affect the variability in grid orientation and spacing.</title><p>(<bold>A, B</bold>) Same as <xref ref-type="fig" rid="fig2">Figure 2D and E</xref>, but with conjunctive and non-conjunctive cells differentiated. Note that the slight difference in position of the dots between this figure and <xref ref-type="fig" rid="fig3">Figure 3</xref> is due to re-computing with a different random seed. (<bold>C, D</bold>) Distribution of between-cell variability in orientation and spacing, when computing <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>θ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>between</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>λ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>between</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> with and without the conjunctive cells. To allow paired comparisons, the variability is calculated for only the non-conjunctive cells, but either includes (grey) or does not include (red) variability comparisons to the conjunctive cells. A paired <italic>t</italic>-test is used to determine whether the distributions are significantly different (p<italic>-</italic>values reported in <bold>C, D</bold>). <italic>P</italic>-value in <inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>, for all other modules: Q1 = 0.65 and 0.78; Q2 = 0.86 and 0.92; R11 = 0.13 and 0.75; R13 = 0.99 and 0.97; R21 = 0.29 and 0.98; R22 = 0.87 and 0.95; S1 = 0.07 and 0.77.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100652-fig3-figsupp6-v1.tif"/></fig><fig id="fig3s7" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 7.</label><caption><title>Path integrating recurrent neural networks (RNNs) that develop grid cells exhibit variability in spacing and orientation that scales with recurrent weight sparsity.</title><p>(<bold>A, B</bold>) Spatial autocorrelogram (SAC) overlaid for two pairs of units in the recurrent layer with high grid score; one pair with different <inline-formula><mml:math id="inf43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi></mml:mstyle></mml:math></inline-formula> and similar <inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (<bold>A</bold>) and the other with similar <inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and different <inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (<bold>B</bold>). (<bold>C, D</bold>) Distribution of <inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi></mml:mstyle></mml:math></inline-formula> (<bold>C</bold>) and <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:math></inline-formula> (<bold>D</bold>) across all units in the recurrent layer with grid score &gt; 0.85 (N = 326). Two and four units were excluded for visualization from (<bold>C</bold>) and (<bold>D</bold>), respectively, since they were outside the plotting axes. (<bold>E, F</bold>) Standard deviation of <inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi></mml:mstyle></mml:math></inline-formula> (<bold>E</bold>) and <inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (<bold>F</bold>) distributions, <inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> respectively, across different amounts of weight decay used in training. The circle markers indicate the mean across three independently trained networks and the lines indicate the minimum and maximum of all three networks.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100652-fig3-figsupp7-v1.tif"/></fig></fig-group><p>We find that the distribution, across 100 random shuffles of the data into two halves, of within-cell variability of grid orientation and spacing is more concentrated around 0 than the between-cell variability (<xref ref-type="fig" rid="fig3">Figure 3B and C</xref>). Comparing the average within- and between-cell variability of grid spacing and orientation reveals that nearly all of the grid cells that passed the criteria for inclusion (<inline-formula><mml:math id="inf53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>82</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) exhibit more between-cell than within-cell variability (<xref ref-type="fig" rid="fig3">Figure 3D and E</xref>): 95.1% grid cells for orientation (<inline-formula><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>θ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>within</mml:mtext></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mn>1.2</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>θ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>between</mml:mtext></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mn>2.0</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo>;</mml:mo><mml:mrow><mml:mo>⟨</mml:mo><mml:mo>⋅</mml:mo><mml:mo>⟩</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes mean across cells) and 100% of grid cells for spacing (<inline-formula><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>λ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>within</mml:mtext></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>=</mml:mo><mml:mn>1.9</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>λ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>between</mml:mtext></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>=</mml:mo><mml:mn>6.9</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>). A Wilcoxon-Signed-Rank Test indicates that between-cell variability is significantly greater than within-cell variability, for both orientation and spacing (<inline-formula><mml:math id="inf58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>θ</mml:mi><mml:mo>:</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>λ</mml:mi><mml:mo>:</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>). We perform a number of control analyses to confirm that our results are robust, finding that: (1) the average grid field width does not significantly affect the between-cell variability (<xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>), (2) the amount of between-cell variability does not change significantly across the recording duration (<xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>), (3) the between-cell variability is not significantly impacted by the boundaries of the arena (<xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref>), and (4) the amount of between-cell variability is not driven by the presence of cells that have both head direction and grid cell like tuning ‘conjunctive’ cells (<xref ref-type="bibr" rid="bib73">Sargolini et al., 2006</xref>; <xref ref-type="fig" rid="fig3s6">Figure 3—figure supplement 6</xref>).</p><p>In keeping with convention, the reported grid cell properties are the average of those computed for each of the three independent axes in the SAC (Axis 1: aligned to ≈ 0°; Axis 2: aligned to ≈ 60°; Axis 3: aligned to ≈ 60° <xref ref-type="bibr" rid="bib87">Stensola et al., 2015</xref>). To ensure that this averaging is not contributing to greater between-cell variability, we repeated the analysis above, restricting ourselves to each axis separately. The results again demonstrate that grid properties are significantly more robust within-cell than between-cell (<xref ref-type="fig" rid="fig4">Figure 4A and B</xref>). For each axis, the average between-cell variability for every cell was significantly higher than the average within-cell variability (<xref ref-type="fig" rid="fig4">Figure 4C and D</xref>), as reported by the Wilcoxon-Signed-Rank Test for orientation (p &lt; 0.001, for all three axes) and for spacing (p &lt; 0.001, for all three axes).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Variability of grid properties, restricted to the same axis, is a robust feature of individual grid module (recording ID R12).</title><p>Same analysis as in <xref ref-type="fig" rid="fig3">Figure 3B–E</xref>, but for variability measured on each axis independently. (<bold>A</bold>) Distribution of orientation variability (Δθ) for each grid axis. (<bold>B</bold>) Distribution of spacing variability (Δλ) for each grid axis. (<bold>C</bold>) Within- vs. between-cell orientation variability (<inline-formula><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>θ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></inline-formula>) for each grid axis. (<bold>D</bold>) Within- vs. between-cell spacing variability (<inline-formula><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>λ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></inline-formula>) for each grid axis. For visualization, we exclude a small number of cells that were outside the axes limits, including 2, 5, and 10 cells for Axes 1–3, respectively (<bold>C</bold>); and 3, 4, and 3 cells for Axes 1–2, respectively (<bold>D</bold>); these cells were included in non-parametric statistical analyses.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100652-fig4-v1.tif"/></fig><p>Having demonstrated that grid cell properties are robustly heterogeneous in a single module, we proceed to analyze the remaining recordings in the data set (<inline-formula><mml:math id="inf62"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>420</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> cells across 8 modules; one module in the data set had no cells that passed our criteria; <xref ref-type="bibr" rid="bib28">Gardner et al., 2022</xref>). Although there are differences across recordings, we find larger between- than within-cell variability for grid orientation and spacing is present across all recordings (<xref ref-type="fig" rid="fig5">Figure 5A and B</xref>; 80.0% of grid cells have greater between- than within-cell variability for orientation, <inline-formula><mml:math id="inf63"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>θ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>within</mml:mtext></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mn>1.4</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>θ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>between</mml:mtext></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mn>1.9</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo>;</mml:mo><mml:mn>87.9</mml:mn><mml:mi mathvariant="normal">%</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> of grid cells have greater between- than within-variability for spacing, <inline-formula><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>λ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>within</mml:mtext></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>=</mml:mo><mml:mn>1.7</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>λ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>between</mml:mtext></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>=</mml:mo><mml:mn>3.6</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>). A Wilcoxon-Signed-Rank Test finds that these differences are significant (<inline-formula><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>θ</mml:mi><mml:mo>:</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn><mml:mo>;</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>λ</mml:mi><mml:mo>:</mml:mo><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>). We do not find evidence suggesting that the within-cell variability is influenced by grid score (<xref ref-type="fig" rid="fig5">Figure 5C and D</xref>; linear regression for <inline-formula><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>:</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula><inline-formula><mml:math id="inf69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>0.03</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.55</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> Wald Test; linear regression for  <inline-formula><mml:math id="inf70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>:</mml:mo><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mn>0.07</mml:mn><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.14</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> Wald Test).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Within module grid property variability is a robust feature across modules.</title><p>(<bold>A</bold>) Average within-cell variability of grid orientation (<inline-formula><mml:math id="inf71"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>θ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>within</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>), compared to average between-cell variability of grid orientation (<inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>θ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>between</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) for each cell (<inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>420</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>) across 8 modules (cells colored by their corresponding recording ID). The histogram above the plot shows the distribution of <inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>θ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>within</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and the histogram to the right shows the distribution of <inline-formula><mml:math id="inf75"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>θ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>between</mml:mtext></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>. (<bold>B</bold>) Same as (<bold>A</bold>), but for grid spacing. For visualization, 5 cells are excluded (<inline-formula><mml:math id="inf76"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>λ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>between</mml:mtext></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>15</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>), but are included in non-parametric statistical analyses. Dashed gray lines show the population mean. (<bold>C, D</bold>) Average within cell variability of <inline-formula><mml:math id="inf77"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (respectively), as a function of grid score. For visualization, 3 and 22 cells are excluded from (<bold>C, D</bold>), respectively, but are included in statistical analyses. Black solid line is linear regression, with <inline-formula><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <italic>p</italic>-value reported above.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100652-fig5-v1.tif"/></fig><p>To understand whether the observed grid cell variability may be a heretofore unknown property of MEC computational models, we trained recurrent neural networks (RNN) to perform path integration. These RNN models have previously been shown to develop grid responses (<xref ref-type="bibr" rid="bib5">Banino et al., 2018</xref>; <xref ref-type="bibr" rid="bib14">Cueva and Wei, 2018</xref>; <xref ref-type="bibr" rid="bib81">Sorscher et al., 2019</xref>) and have been argued to develop continuous attractor network structure (<xref ref-type="bibr" rid="bib82">Sorscher et al., 2023</xref>), making them normative models for MEC function. We find that the RNNs develop grid responses with a distribution of grid spacing and orientation (<xref ref-type="fig" rid="fig3s7">Figure 3—figure supplement 7A-D</xref>), much like the neural data we analyzed (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Changing the sparsity of the recurrent layer by increasing the strength of weight decay regularization reduces the variability (<xref ref-type="fig" rid="fig3s7">Figure 3—figure supplement 7E, F</xref>).</p><p>Taken together, our analysis of large-scale MEC recordings demonstrates that grid cells in the same grid module do not have a single grid spacing and orientation, but instead have a restricted range of values around the module mean. This property is a robust feature that cannot be explained by noise from the recording or fitting procedures and emerges in existing normative models of MEC.</p></sec><sec id="s2-2"><title>Variability in grid properties within individual modules improves the encoding of local space</title><p>The variability of grid cell properties within individual grid modules, while statistically significant, is small in magnitude. Can a computational benefit in the encoding of local space be gained from this level of inhomogeneity? How sensitive might such a computational benefit be to the exact amount of variability present?</p><p>To address these questions, we generate populations of synthetic grid cells (see Materials and methods), where we have complete control over the number of grid cells and their firing properties. For simplicity, we assume that all grid cells in our population have grid orientation and spacing sampled from Gaussian distributions, with means <inline-formula><mml:math id="inf80"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf81"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and standard deviations <inline-formula><mml:math id="inf82"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf83"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, respectively. Assigning each grid cell in our population a grid orientation and spacing, we are able to generate ‘ideal’ rate maps (<xref ref-type="bibr" rid="bib79">Solstad et al., 2006</xref>). Sampling from a Poisson process on these ideal rate maps, we generate noisy grid cell rate maps (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). Using a simple linear decoder (see Materials and methods), we can examine how decoding error of local space is affected by the number of grid cells in the population and the amount of variability (<inline-formula><mml:math id="inf84"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf85"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Variability in grid properties enables improved decoding of local space from the activity of grid cells within a single module.</title><p>(<bold>A</bold>) Example noisy grid cell rate maps generated from a Poisson process. The size of the square arena is set to 1.5 m ×1.5 m to be consistent with what was used in the experimental set-up analyzed (<xref ref-type="bibr" rid="bib28">Gardner et al., 2022</xref>). (<bold>B, C</bold>) Distribution of sampled grid spacing and orientation from synthetic population, when using <inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mn>85</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mn>6</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf88"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> cm, and <inline-formula><mml:math id="inf89"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>1</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>; compare to the distribution measured from real data (<xref ref-type="fig" rid="fig2">Figure 2E and F</xref>). (<bold>D</bold>) Decoding error, as a function of grid cell population size, with populations having either no variability in grid properties (black line) or variability similar to what was present in the data analyzed (blue line). The solid line is the mean across 25 independent grid cell populations and the shaded area is ± standard deviation of the 25 independent populations. The dashed black line shows chance level decoding error. (<bold>E</bold>) Decoding error for synthetic populations and real data for up to <inline-formula><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>64</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> cells (red line). (<bold>F</bold>) Decoding error, over a grid of <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf92"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> values, for populations of <inline-formula><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>1024</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> grid cells. White star denotes values used in (<bold>D</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100652-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Variability in grid properties improves decoding of local space for grid modules with different mean grid spacings.</title><p>(<bold>A, B</bold>) Same as <xref ref-type="fig" rid="fig6">Figure 6F</xref>, for <inline-formula><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mn>50</mml:mn></mml:mstyle></mml:math></inline-formula> cm and <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mstyle></mml:math></inline-formula> cm, respectively. <inline-formula><mml:math id="inf96"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></inline-formula> is set to 0°.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100652-fig6-figsupp1-v1.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 2.</label><caption><title>Variability in grid properties improves decoding of local space for multiple modules, when the modules have integer multiple mean spacing.</title><p>(<bold>A–D</bold>) Same as <xref ref-type="fig" rid="fig6">Figure 6D</xref>, when decoding from multiple modules. (<bold>A</bold>) <inline-formula><mml:math id="inf97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mn>70</mml:mn><mml:mo>,</mml:mo><mml:mn>100</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf98"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mn>0</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>B</bold>) <inline-formula><mml:math id="inf99"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mn>50</mml:mn><mml:mo>,</mml:mo><mml:mn>100</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mn>0</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>C</bold>) <inline-formula><mml:math id="inf101"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mn>65.0</mml:mn><mml:mo>,</mml:mo><mml:mn>100.0</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf102"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mn>0</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> (<bold>D</bold>) <inline-formula><mml:math id="inf103"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mn>48.4</mml:mn><mml:mo>,</mml:mo><mml:mn>98.4</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf104"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mn>0</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>. The values in (<bold>A, B</bold>) were chosen such that <inline-formula><mml:math id="inf105"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt><mml:msub><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf106"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. The values in (<bold>C, D</bold>) were chosen to match those found in Rat 14257 from <xref ref-type="bibr" rid="bib86">Stensola et al., 2012</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100652-fig6-figsupp2-v1.tif"/></fig></fig-group><p>We begin by investigating the decoding capabilities of a synthetic module with properties similar to that of the experimentally recorded module that was analyzed in detail (recording identifier R12; <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig3">3</xref>). We therefore set <inline-formula><mml:math id="inf107"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mn>85</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf108"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>θ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mn>6</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>. To determine an appropriate value for <inline-formula><mml:math id="inf109"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, we subtract the mean between-cell variability by the mean within-cell variability (<inline-formula><mml:math id="inf111"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>θ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>between</mml:mtext></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>−</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>θ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>within</mml:mtext></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mn>2.0</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:msup><mml:mn>1.2</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf112"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>λ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>between</mml:mtext></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>−</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:msub><mml:mover><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>λ</mml:mi></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mtext>within</mml:mtext></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>=</mml:mo><mml:mn>6.9</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mo>−</mml:mo><mml:mspace width="thinmathspace"/><mml:mn>1.9</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mn>5.0</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>). We interpret these values as the amount of variability in grid spacing and orientation that is not due to noise. Therefore, we set <inline-formula><mml:math id="inf113"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>1</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf114"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>5</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. This amount of variability leads to similar sampled distributions of <inline-formula><mml:math id="inf115"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf116"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> as was found in the real data (compare <xref ref-type="fig" rid="fig6">Figure 6B and C</xref> with <xref ref-type="fig" rid="fig2">Figure 2E and F</xref>).</p><p>Applying the linear decoder to populations of synthetic grid cells, we find that decoding error decreases as the number of grid cells is increased (<xref ref-type="fig" rid="fig6">Figure 6D</xref>, blue line). When <inline-formula><mml:math id="inf117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>1024</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, the decoding error is ≈ 20 cm, substantially better than random decoding (<xref ref-type="fig" rid="fig6">Figure 6D</xref>, dashed black line). As expected, this result is not seen in a synthetic population of grid cells with zero variability in grid properties (<inline-formula><mml:math id="inf118"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>0</mml:mn><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf119"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>; <xref ref-type="fig" rid="fig6">Figure 6D</xref>, black line). In particular, while the restricted number of grid firing fields enables a decoding error smaller than chance, the population with fixed grid properties exhibits little change in decoding error with increasing numbers of grid cells. This demonstrates that the improved encoding is specific to populations with inhomogeneity in their grid spacing and orientation.</p><p>To validate that the synthetic population is a reasonable surrogate to the experimentally recorded data, we perform the same decoding analysis on grid cells from recording ID R12 (see Materials and methods). As the real data is limited in the number of cells, we are only able to compare up to populations of <inline-formula><mml:math id="inf120"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>64</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig6">Figure 6E</xref>). However, in this restricted range, we find agreement between the synthetic population with grid property variability and the recorded data (<xref ref-type="fig" rid="fig6">Figure 6E</xref>, compare red and blue lines). This supports our hypothesis that the observed amounts of inhomogeneity in grid spacing and orientation can lead to improved decoding of local space.</p><p>To determine the extent to which the decrease in decoding error depends the exact variability of grid spacing and orientation, we perform a grid search over 36 pairs of <inline-formula><mml:math id="inf121"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> values in [0°, 1°, ... ,5°]×[0 cm, 1 cm, ... , 5 cm]. As expected, when the variability of both grid properties is large, we find nearly 0 cm decoding error of local space (<xref ref-type="fig" rid="fig6">Figure 6E</xref>, bottom right). However, there is additionally a range of <inline-formula><mml:math id="inf122"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>λ</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf123"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>θ</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> values that lead to improved decoding, including values smaller than the values matched to the experimental data (<xref ref-type="fig" rid="fig6">Figure 6E</xref>, above and to the left of the white star). We perform the same grid search on synthetic populations of grid cells with different spacings, <inline-formula><mml:math id="inf124"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mn>50</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf125"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mn>100</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1A, B</xref>), finding again that the decoding error drops below that of the fixed population with sufficient grid property variability. For the synthetic module with smaller spacing (<inline-formula><mml:math id="inf126"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mn>50</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>), the existence of more grid fields in the 1.5 m × 1.5 m arena leads to greater complexity of interference patterns (<xref ref-type="fig" rid="fig1">Figure 1</xref>), enabling the same amount of variability in grid spacing and orientation to lead to a sharper decrease in decoding error. Additionally, for the synthetic module with smaller spacing, a given value of <inline-formula><mml:math id="inf127"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is a larger percentage of <inline-formula><mml:math id="inf128"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, as compared to the synthetic module with larger spacing.</p><p>Finally, we consider how decoding within a single module compares to decoding across two modules. When the two modules are consecutive (e.g. modules 1 and 2), their mean grid spacing, <inline-formula><mml:math id="inf129"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf130"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, has been experimentally found to be related via <inline-formula><mml:math id="inf131"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt><mml:msub><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib86">Stensola et al., 2012</xref>). In such a case, decoding activity from populations with fixed grid properties leads to nearly 0 cm error (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2A</xref>, black line). The addition of variability in grid properties does not significantly change the behavior of the decoding (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2A</xref>, blue line). This suggests that small amounts of inhomogeneity may not disrupt the previously achieved theoretical bounds on decoding from multiple grid modules (<xref ref-type="bibr" rid="bib52">Mathis et al., 2012a</xref>; <xref ref-type="bibr" rid="bib53">Mathis et al., 2012b</xref>; <xref ref-type="bibr" rid="bib85">Stemmler et al., 2015</xref>; <xref ref-type="bibr" rid="bib91">Wei et al., 2015</xref>). However, if the two modules being decoded from are non-consecutive (e.g. modules 1 and 3) then the mean grid spacing can be related by an integer multiple, <inline-formula><mml:math id="inf132"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>. In such a setting, the grid fields of the larger module are a subset of the grid fields of the smaller module, up to a rotation (due to the difference in orientation between the two modules), and we again find that variability in grid properties can improve decoding accuracy (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2B</xref>, compare black and blue lines). Similar results are found when using experimentally found values of <inline-formula><mml:math id="inf133"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib86">Stensola et al., 2012</xref>) and not assuming an exact <inline-formula><mml:math id="inf134"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt><mml:msub><mml:mrow><mml:mover><mml:mi>λ</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> relationship (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2C, D</xref>).</p><p>Taken together, these results suggest that <italic>individual</italic> grid modules can exhibit significant encoding of local space via heterogeneity in their grid properties, even when the extent of the variability in <inline-formula><mml:math id="inf135"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf136"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:math></inline-formula> is similar to that found in the analysis of the experimental recordings. This benefit can also improve encoding in cases when multiple, non-consecutive modules are considered.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>The multiple firing fields of grid cells, organized along a triangular lattice, has been historically interpreted as a limiting feature for the encoding of local space. Particularly influential in shaping this view has been the discovery of the distribution of grid cells into distinct modules, with grid cell spacing (<inline-formula><mml:math id="inf137"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) and orientation (<inline-formula><mml:math id="inf138"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>) preserved within, but not across, modules (<xref ref-type="bibr" rid="bib86">Stensola et al., 2012</xref>; <xref ref-type="bibr" rid="bib32">Gu et al., 2018</xref>), making integration across multiple modules necessary for spatial information to be decoded (<xref ref-type="bibr" rid="bib24">Fiete et al., 2008</xref>; <xref ref-type="bibr" rid="bib83">Sreenivasan and Fiete, 2011</xref>; <xref ref-type="bibr" rid="bib52">Mathis et al., 2012a</xref>; <xref ref-type="bibr" rid="bib91">Wei et al., 2015</xref>; <xref ref-type="bibr" rid="bib85">Stemmler et al., 2015</xref>). While evidence for discontinuity in the grid cell properties across modules is strong, the corollary assumption, that within-module values of <inline-formula><mml:math id="inf139"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf140"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> are identical (up to the bounds of noise), has not been systematically studied.</p><p>Analyzing recently collected MEC recordings, we found the range of <inline-formula><mml:math id="inf141"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf142"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi></mml:mstyle></mml:math></inline-formula> values was large, with examples of grid cell pairs in the same module having over 5° difference in grid orientation and 20 cm difference in grid spacing (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Statistical analysis shows that the variability is more robust than expected from noise, for the majority of grid cells (<xref ref-type="fig" rid="fig5">Figure 5</xref>). This was despite the fact that we used a very conservative criteria for assessing whether a grid cell was consistent enough to be included in the analysis.</p><p>Our comparison of within- and between-cell grid property variability was key to our argument, as it was for previous work using it to study the robustness of differences in peak grid field firing rates (<xref ref-type="bibr" rid="bib22">Dunn et al., 2017</xref>). The absence of its use in the characterization of distribution of <inline-formula><mml:math id="inf143"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf144"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>θ</mml:mi></mml:mstyle></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib93">Yoon et al., 2013</xref>) may be why the consistency of this heterogeneity was not identified until now. We find that our conclusion holds when performing a number of control experiments (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>, <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>, <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4</xref>, <xref ref-type="fig" rid="fig3s5">Figure 3—figure supplement 5</xref>, <xref ref-type="fig" rid="fig3s6">Figure 3—figure supplement 6</xref>) and whether we treat each grid field independently (<xref ref-type="fig" rid="fig3">Figure 3</xref>) or take the average across grid fields (<xref ref-type="fig" rid="fig4">Figure 4</xref>). This challenges the assumption that the variability observed in the grid orientation and spacing is attributable solely to measurement noise.</p><p>We find that normative recurrent neural network models that develop grid cells when optimized to perform path integration (<xref ref-type="bibr" rid="bib14">Cueva and Wei, 2018</xref>; <xref ref-type="bibr" rid="bib5">Banino et al., 2018</xref>; <xref ref-type="bibr" rid="bib81">Sorscher et al., 2019</xref>) develop similar amounts of grid property variability (<xref ref-type="fig" rid="fig3s7">Figure 3—figure supplement 7</xref>). This illustrates the ability of these RNN models to capture aspects of grid cell properties that have not been previously studied, and may provide another explanation for why these models have greater similarity to real MEC recordings than other models (<xref ref-type="bibr" rid="bib58">Nayebi et al., 2021</xref>). Probing these computational models in greater depth may enable a more detailed understanding of the observed grid property heterogeneity.</p><p>We hypothesized that this variability may be used to increase the fidelity at which individual grid modules can encode local space. This idea is consistent with a large body of literature showing that heterogeneity in the responses of populations of neurons increases the robustness of encoding (<xref ref-type="bibr" rid="bib77">Shamir and Sompolinsky, 2006</xref>; <xref ref-type="bibr" rid="bib11">Chelaru and Dragoi, 2008</xref>; <xref ref-type="bibr" rid="bib30">Gjorgjieva et al., 2016</xref>; <xref ref-type="bibr" rid="bib63">Perez Nieves et al., 2021</xref>). We find, in noisy synthetic populations of grid cells, that a level of variability in grid properties similar to what is quantified in the real data can be sufficient to accurately decode information of local space (<xref ref-type="fig" rid="fig6">Figure 6</xref>). This benefit is increased with larger numbers of grid cells in the population (<xref ref-type="fig" rid="fig6">Figure 6D</xref>) and is observed over a range of values for the underlying variability (<xref ref-type="fig" rid="fig6">Figure 6F</xref>). We find that the improvement was most pronounced in modules with small grid spacing (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1A</xref>), although larger modules can see a decrease in decoding error for amounts of variability consistent with was was found in the analyzed data (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1B</xref>).</p><p>We note that our results are additionally aligned with recent findings of heterogeneity in maximal firing rates across individual grid fields (<xref ref-type="bibr" rid="bib17">Diehl et al., 2017</xref>; <xref ref-type="bibr" rid="bib37">Ismakov et al., 2017</xref>; <xref ref-type="bibr" rid="bib22">Dunn et al., 2017</xref>) and grid sheering (<xref ref-type="bibr" rid="bib16">Derdikman et al., 2009</xref>; <xref ref-type="bibr" rid="bib44">Krupic et al., 2015</xref>; <xref ref-type="bibr" rid="bib29">Ginosar et al., 2023</xref>). Our work further demonstrates that, even in the absence of these perturbations, individual grid modules may encode considerably more local spatial information than previously believed.</p><p>Finally, models of the formation of orientation maps in visual cortex have demonstrated that slight angular offsets of retinal mosaics, along which retinal receptive fields are organized, can generate complex patterns (<xref ref-type="bibr" rid="bib62">Paik and Ringach, 2011</xref>) similar to those found in visual cortex orientation maps (<xref ref-type="bibr" rid="bib7">Blasdel and Salama, 1986</xref>). Our results indicate that grid cells in MEC may take advantage of a similar computational principle, suggesting that mosaic patterns might be a broadly utilized feature of neural coding (<xref ref-type="bibr" rid="bib78">Smith and Smith, 2011</xref>).</p><sec id="s3-1"><title>Limitations</title><p>While the data set we analyzed (<xref ref-type="bibr" rid="bib28">Gardner et al., 2022</xref>) represents an advance in the ability to simultaneously record from tens to hundreds of putative grid cells, across grid modules, the MEC remains a challenging brain region to access for large-scale neurophysiological experiments. Indeed, with our conservative inclusion criteria, we were ultimately limited by having only 420 grid cells included in our analysis. Future work can perform more detailed and complete characterizations of grid property heterogeneity, as new neurotechnologies that enable larger yield of grid cells are developed (<xref ref-type="bibr" rid="bib48">Low et al., 2014</xref>; <xref ref-type="bibr" rid="bib95">Zong et al., 2022</xref>).</p><p>Our decoding analysis, while demonstrating the possibility that variability in grid properties can be used by individual grid modules to enhance the encoding of local spatial information, made several simplifying assumptions, including: (1) independent Poisson noise for neural activity, (2) linear decoding, and (3) normal distribution of grid properties. Although comparison to real data showed that these assumptions are reasonable (<xref ref-type="fig" rid="fig6">Figure 6E</xref>), future work can assess the extent to which these restrictions can be lifted (e.g. to incorporate correlated neural noise), while still enabling individual grid modules to have low decoding error.</p></sec><sec id="s3-2"><title>Open questions</title><p>The heterogeneity in grid properties we characterize motivates the investigation of several new lines of research. Because these are directions that we believe to be fruitful for the field as a whole, we outline them below, with our hypotheses for possible answers.</p><sec id="s3-2-1"><title>Q1: How does grid property variability affect continuous attractor network structure?</title><p>Continuous attractor network models of grid cells (<xref ref-type="bibr" rid="bib25">Fuhs and Touretzky, 2006</xref>; <xref ref-type="bibr" rid="bib33">Guanella and Verschure, 2006</xref>; <xref ref-type="bibr" rid="bib8">Burak and Fiete, 2009</xref>; <xref ref-type="bibr" rid="bib13">Couey et al., 2013</xref>) enjoy considerable experimental support (<xref ref-type="bibr" rid="bib93">Yoon et al., 2013</xref>; <xref ref-type="bibr" rid="bib21">Dunn et al., 2015</xref>; <xref ref-type="bibr" rid="bib32">Gu et al., 2018</xref>; <xref ref-type="bibr" rid="bib28">Gardner et al., 2022</xref>; <xref ref-type="bibr" rid="bib27">Gardner et al., 2019</xref>; <xref ref-type="bibr" rid="bib88">Trettel et al., 2019</xref>), making them one of the ‘canonical’ models in neuroscience. However, these models make use of the assumption that all the grid cells in a given module have the same grid orientation and spacing to simplify the network connectivity. In particular, by assuming equal grid orientation and spacing, it becomes possible to arrange grid cells in a two-dimensional space spanned by their phases (i.e. a ‘neural sheet’ <xref ref-type="bibr" rid="bib8">Burak and Fiete, 2009</xref>). Neurons close in this space are wired with excitatory connections and neurons far in this space are wired with inhibitory connections. As the data set we analyzed was found by others to provide strong support for the basic predictions of continuous attractor networks (i.e. toroidal topology of the activity manifold; <xref ref-type="bibr" rid="bib28">Gardner et al., 2022</xref>), we do not view our results as directly challenging these models. That the RNN models we investigate (<xref ref-type="fig" rid="fig3s7">Figure 3—figure supplement 7</xref>) are explicitly trained to perform path integration (and achieve highly accurate performance <xref ref-type="bibr" rid="bib82">Sorscher et al., 2023</xref>) supports our hypothesis that variability in grid properties does not necessarily destroy the continuous attractor or path integration capabilities of the MEC. Understanding how this is possible is an exciting future direction, and use of geometric (<xref ref-type="bibr" rid="bib1">Acosta et al., 2023</xref>) and dynamical systems based tools (<xref ref-type="bibr" rid="bib67">Redman et al., 2022a</xref>; <xref ref-type="bibr" rid="bib69">Redman et al., 2023</xref>; <xref ref-type="bibr" rid="bib61">Ostrow et al., 2024</xref>) may shed new light on this. We hypothesize that the degree in variability of grid spacing and orientation may strike a balance between being small enough to keep the continuous attractor network structure stable, but large enough to enable encoding of local information of space.</p></sec><sec id="s3-2-2"><title>Q2: What causes grid property variability?</title><p>A natural direction to address is identifying the source of the heterogeneity in grid cell properties we observe. One hypothesis is that this could be driven by ‘defects’ in the specific connectivity pattern that is needed for a continuous attractor. This could be due to synaptic connections between grid cells and other functional classes of neurons in the MEC, such as border (<xref ref-type="bibr" rid="bib80">Solstad et al., 2008</xref>), band (<xref ref-type="bibr" rid="bib43">Krupic et al., 2012</xref>), and non-spatial (<xref ref-type="bibr" rid="bib17">Diehl et al., 2017</xref>) cells. Because the path integrating RNN models have been found to develop analogous responses to these classes (<xref ref-type="bibr" rid="bib5">Banino et al., 2018</xref>; <xref ref-type="bibr" rid="bib14">Cueva and Wei, 2018</xref>; <xref ref-type="bibr" rid="bib76">Schøyen et al., 2023</xref>; <xref ref-type="bibr" rid="bib64">Pettersen et al., 2024a</xref>; <xref ref-type="bibr" rid="bib65">Pettersen et al., 2024b</xref>), as well as capture general properties of MEC activity (<xref ref-type="bibr" rid="bib58">Nayebi et al., 2021</xref>), we examined the affect of ‘connectivity noise’ in RNNs. In particular, we swept across different strengths of weight decay regularization, which controls the amount of sparsity in the recurrent layer. We find that smaller weight decay (and thus, denser connectivity between units) led to greater variability in grid properties (<xref ref-type="fig" rid="fig3s7">Figure 3—figure supplement 7E, F</xref>). Increasing the weight decay (and thus, enforcing sparser connectivity) led to a reduction of grid property variability (<xref ref-type="fig" rid="fig3s7">Figure 3—figure supplement 7E, F</xref>). This supports the hypothesis that the heterogeneity in grid properties we observe may be due to ‘non-perfect’ connectivity.</p><p>Alternatively, the coupling between hippocampus and MEC, which has been shown to lead to variability in grid field firing rates (as experimentally observed; <xref ref-type="bibr" rid="bib22">Dunn et al., 2017</xref>; <xref ref-type="bibr" rid="bib2">Agmon and Burak, 2020</xref>), may lead to differences in grid orientation and spacing. In particular, a previous computational model that learned grid cells from place cell input, using non-negative principal component analysis, has shown that place field width affects grid cell orientation and spacing (<xref ref-type="bibr" rid="bib19">Dordek et al., 2016</xref>). Heterogeneity in the spatial coding properties of place cells has been found along the transverse axis of CA3 (<xref ref-type="bibr" rid="bib46">Lee et al., 2015</xref>; <xref ref-type="bibr" rid="bib49">Lu et al., 2015</xref>; <xref ref-type="bibr" rid="bib68">Redman et al., 2022b</xref>), suggesting there may be a systematic differences in the place field widths of hippocampal inputs to MEC grid cells. Further, it was shown that this place-to-grid cell computational model has a linear relationship between place field width and grid spacing, and a non-monotonic relationship between place field width and grid orientation (<xref ref-type="bibr" rid="bib19">Dordek et al., 2016</xref>). These may explain why we find stronger average variability in grid spacing than grid orientation (<xref ref-type="fig" rid="fig5">Figure 5A and B</xref>).</p></sec><sec id="s3-2-3"><title>Q3: How does grid property variability shape hippocampal representations?</title><p>The projections from MEC to hippocampus suggest that the variability in grid properties may influence hippocampal representations (even if grid cells do not comprise the majority of its inputs <xref ref-type="bibr" rid="bib17">Diehl et al., 2017</xref>). We consider two possible ways in which this may happen. First, given that grid cells have been reported to maintain their grid spacing and orientation across exposures to new environments, while undergoing a change in their grid phase (<xref ref-type="bibr" rid="bib26">Fyhn et al., 2007</xref>; <xref ref-type="bibr" rid="bib93">Yoon et al., 2013</xref>), the integration across multiple modules has been necessary to explain place field remapping. However, grid phase plays an important role in generating the specific complex interference patterns that emerge when considering the joint activity of grid cells with variable grid properties (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Thus the reported changes in phase may be sufficient to generate large (and seemingly random) changes in local spatial information conveyed by grid cells to hippocampal cells. This could drive additional changes in the local spatial information projected to hippocampus, as well as explain the significant differences in correlation structure between CA1 neurons across different environments (<xref ref-type="bibr" rid="bib47">Levy et al., 2023</xref>).</p><p>And second, recent work on hippocampal place field drift (<xref ref-type="bibr" rid="bib51">Mankin et al., 2012</xref>; <xref ref-type="bibr" rid="bib94">Ziv et al., 2013</xref>; <xref ref-type="bibr" rid="bib35">Hainmueller and Bartos, 2018</xref>; <xref ref-type="bibr" rid="bib31">Gonzalez et al., 2019</xref>; <xref ref-type="bibr" rid="bib18">Dong et al., 2021</xref>) has demonstrated that there is a significant change in the place field location across time, especially in CA1. One possible source of this phenomenon is the reported instability of dendritic spines on the apical dendrites of CA1 place cells (<xref ref-type="bibr" rid="bib56">Mizrahi et al., 2004</xref>; <xref ref-type="bibr" rid="bib4">Attardo et al., 2015</xref>; <xref ref-type="bibr" rid="bib66">Pfeiffer et al., 2018</xref>; <xref ref-type="bibr" rid="bib68">Redman et al., 2022b</xref>), ostensibly leading to changes in the MEC inputs to these neurons. However, if grid cells across multiple modules are necessary for local spatial information, turnover in synaptic input is unlikely to cause large changes in the spatial preferences of CA1 neurons, as integration over several scales should provide stable encoding properties. In contrast, different subpopulations of grid cells with variable grid properties can lead to differences in the local spatial information encoded by their joint activity, even if they come from a single module, possibly influencing the spatial preferences of CA1 place cells.</p></sec><sec id="s3-2-4"><title>Q4: Why are there multiple modules?</title><p>Given that our results demonstrate the ability of single grid modules to encode information about local space – a feat previously believed to be possible only if activity from multiple grid modules was integrated together – why is does MEC have multiple modules? While the variability removes the necessity for encoding local space with multiple modules, higher fidelity representations is achievable by integrating across multiple modules (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>). In addition, the use of grid cells beyond spatial navigation (<xref ref-type="bibr" rid="bib41">Killian et al., 2012</xref>; <xref ref-type="bibr" rid="bib12">Constantinescu et al., 2016</xref>; <xref ref-type="bibr" rid="bib3">Aronov et al., 2017</xref>; <xref ref-type="bibr" rid="bib38">Julian et al., 2018</xref>; <xref ref-type="bibr" rid="bib57">Nau et al., 2018</xref>; <xref ref-type="bibr" rid="bib92">Wilming et al., 2018</xref>; <xref ref-type="bibr" rid="bib59">Neupane et al., 2024</xref>), where hierarchical representations are important (<xref ref-type="bibr" rid="bib42">Klukas et al., 2020</xref>; <xref ref-type="bibr" rid="bib72">Rueckemann et al., 2021</xref>), may be a sufficient implicit bias for the formation of multiple modules (<xref ref-type="bibr" rid="bib75">Schaeffer et al., 2024</xref>). In particular, encoding information at multiple distinct scales is critical for multi-scale reasoning, a cognitive function grid cells may support.</p></sec></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Electrophysiology recordings</title><p>The neural activity analyzed in this paper comes from a publicly available data set, which has previously been described in detail (<xref ref-type="bibr" rid="bib28">Gardner et al., 2022</xref>). We provide brief summary of the methodology and the experimental paradigms used during the recordings.</p><p>Three male rats (Long Evans – Rats Q, R, and S) were implanted with Neuropixels silicon probes (<xref ref-type="bibr" rid="bib39">Jun et al., 2017</xref>; <xref ref-type="bibr" rid="bib84">Steinmetz et al., 2021</xref>). These probes were targeted at the MEC-parasubiculum region and the surgery was performed as described previously (<xref ref-type="bibr" rid="bib27">Gardner et al., 2019</xref>; <xref ref-type="bibr" rid="bib84">Steinmetz et al., 2021</xref>). After three hours of recovery, recordings were performed.</p><p>In the recordings analyzed, the rats foraged for randomly dispersed corn puffs in a 1.5 × 1.5m<sup>2</sup> square open field arena, with walls of height 50 cm. The rats were familiar with the environment and task, having trained 10–20 times prior to the implantation. The rats were food restricted to motivate their foraging, being kept at a minimum of 90% of their original body weight (300–500 g).</p><p>All procedures in the original study were approved by the Norwegian Food and Safety Authority and done in accordance with the Norwegian Animal Welfare Act and the European Convention for the Protection of Vertebrate Animals used for Experimental and Other Scientific Purposes. Protocols were approved by the Norwegian Food Safety Authority (FOTS ID 18011 and 18013).</p></sec><sec id="s4-2"><title>Electrophysiology post-processing</title><p>The neural activity analyzed in this paper was post-processed, before made publicly available. We describe, in brief, the post-processing performed (<xref ref-type="bibr" rid="bib28">Gardner et al., 2022</xref>), as well as the post-processing we performed on the downloaded data.</p><p>Spike sorting, via KiloSort 2.5 (<xref ref-type="bibr" rid="bib84">Steinmetz et al., 2021</xref>), was applied to the data recorded from the Neuropixel probes. Individual units were deemed putative cells if their average spike rate was in the range of 0.5–10 Hz, and 99% of their interspike intervals were greater than 2ms.</p><p>For each putative cell, rate maps were constructed by averaging the activity at binned spatial positions in the open field arena. This raw rate map was smoothed, using a Gaussian kernel. The autocorrelation of these rate maps were computed, and a grid score calculated, as described previously (<xref ref-type="bibr" rid="bib73">Sargolini et al., 2006</xref>).</p><p>From the downloaded spike trains, we constructed rate maps and autocorrelograms in a similar manner, using code made publicly available (<xref ref-type="bibr" rid="bib5">Banino et al., 2018</xref>; <xref ref-type="fig" rid="fig2">Figure 2</xref>).</p></sec><sec id="s4-3"><title>Grid module classification</title><p>The public data set we analyzed (<xref ref-type="bibr" rid="bib28">Gardner et al., 2022</xref>) contained the module identity of all putative grid cells. In brief, these module identities were assigned by first projecting the 2D autocorrelogram of every recorded unit onto a 2D space using the non-linear dimensionality reduction algorithm UMAP (<xref ref-type="bibr" rid="bib54">McInnes et al., 2018</xref>). Then, the DBSCAN algorithm (<xref ref-type="bibr" rid="bib23">Ester et al., 1996</xref>) was used to cluster the units, based on their position in the dimensionally reduced space. Cluster membership served as the basis for grid module classification, with the largest cluster being removed as it was found to not contain spatially selective autocorrelograms. This non-supervised module assignment yielded clusters of high grid scores and similar grid spacing and orientation within each cluster-module. More details can be found in <xref ref-type="bibr" rid="bib28">Gardner et al., 2022</xref>. We performed no further analysis regarding module identity.</p></sec><sec id="s4-4"><title>Computing grid score, orientation, and spacing from the spatial autocorrelogram</title><p>Grid spacing and grid orientation were computed according to standard methods described in detail previously (<xref ref-type="bibr" rid="bib86">Stensola et al., 2012</xref>; <xref ref-type="bibr" rid="bib10">Butler et al., 2019</xref>). Briefly, the goal of the procedure is to identify the location of the six nearest fields in the spatial autocorrelogram (SAC; <xref ref-type="fig" rid="fig2">Figure 2A</xref>). This was achieved by performing the following steps. First, the SAC was smoothed using a 2D Gaussian filter with <inline-formula><mml:math id="inf145"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. Second, the center of the SAC was excluded by applying a mask. Because the size of the SAC’s central peak changes for every module, the radius of such mask was re-computed for each module. Third, we thresholded the SAC by applying an extended-maxima transform <monospace>ndimage.maximum_filter</monospace>. Fourth, we identified the center of every field by using the function <monospace>scipy.stats.find_peaks</monospace>.</p><p>Once the peaks of every field had been found, we computed the location of every peak in polar coordinates. We then selected the 6 peaks that were closest to the center of the SAC, based on the computed radial components. Because every SAC is symmetric, we considered for further analysis the 3 peaks closest to the X axis in angular distance (Axis 1, 2, and 3 <xref ref-type="bibr" rid="bib87">Stensola et al., 2015</xref>). Grid spacing was computed as the arithmetic mean of the radial component of the 3 peaks (except when each peak was analyzed separately – <xref ref-type="fig" rid="fig4">Figure 4</xref>). Given that the SAC dimensions are twice of that of the real arena, we multiplied the SAC radial mean by a factor of 2. Grid orientation was computed as the angular mean of orientations (relative to the x-axis) of the three peaks (except when each peak was analyzed separately – <xref ref-type="fig" rid="fig4">Figure 4</xref>).</p><p>In order to ensure that subsequent analysis was performed only on cells whose SAC’s could be well described by hexagonal structure, we imposed the following constraints: (1) the relative angle between two peaks could not be &lt; 30°; (2) the relative angle between two peaks could not be &gt; 90°; (3) the values for grid spacing between the peaks could not be substantially different (the ratio of spacings between any two peaks must be &gt; 0.5 and &lt; 2). Cells that did not meet these criteria were determined to have “Poor grid fit” and were rejected from all subsequent analysis. The percentage of all cells that were removed by this inclusion criteria is shown in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>. We note that cells from one of the nine modules in the publicly available data set that we analyzed had 98.4% of cells rejected by this criteria (recording identifier – R23). We therefore did not include it in any subsequent analysis.</p><p>To compute the grid score of recorded MEC cells, we made use of previously published code (<xref ref-type="bibr" rid="bib5">Banino et al., 2018</xref>), that is based on metrics that have become standards in quantifying grid cell properties (<xref ref-type="bibr" rid="bib73">Sargolini et al., 2006</xref>).</p><p>For analysis of the distribution of grid properties (<xref ref-type="fig" rid="fig2">Figure 2E and F</xref>), we included only grid cells with grid scores greater than 0.85. This was done to demonstrate that variability was present even in cells that exhibit robust grid cell properties. In the subsequent analyses, an alternative criteria is used, which considers the reliability of the grid responses (see below).</p></sec><sec id="s4-5"><title>Computing spacing from the rate maps</title><p>In order to characterize the spacing with a method that is less susceptible to the effects of having grid fields at the boundaries of the environment (as the SAC method could be), we compute the spacing using the rate maps of individual grid cells (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A</xref>). Once the rate map was computed, we smoothed it with a Gaussian filter, setting <inline-formula><mml:math id="inf146"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>1.5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. Then, using the function <monospace>scikit-image.feature.peak_local_max</monospace> we extract the position of the center of each firing field. Because our goal with this analysis is to show that the fields in the border do not impact our analysis with the SAC, we restrict ourselves to the 3 peaks that are closest to the center of the arena (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A</xref>). We compute the distances between those three peaks to each other and report the spacing as the average of the distances measured.</p></sec><sec id="s4-6"><title>Within and between cells splits</title><p>To characterize the within- and between-cell variability of grid spacing and orientation, we employed the following approach. First, we split the data into bins of fixed length (30 s). From this, we randomly assigned each interval to one of two blocks (denoted as blocks <inline-formula><mml:math id="inf147"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>A</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf148"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>B</mml:mi></mml:mstyle></mml:math></inline-formula>), with exactly half the total number of intervals in each block. For each grid cell, we computed the grid spacing [<inline-formula><mml:math id="inf149"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf150"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>B</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula>] and orientation [<inline-formula><mml:math id="inf151"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf152"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>], from the data in each block. The within-cell differences of grid spacing and orientation was determined as <inline-formula><mml:math id="inf153"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mtext>within</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf154"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mtext>within</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>. Each grid cell’s properties were also compared those of another grid cell, with the match being made using random sampling without replacement. These comparisons were determined as <inline-formula><mml:math id="inf155"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mtext>between</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf156"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mtext>between</mml:mtext></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula>. This process was repeated 100 times (referring to each iteration as a ‘shuffle’), per recording. Examples of splits of the data, for different shuffles, is schematically illustrated in <xref ref-type="fig" rid="fig3">Figure 3A</xref>. The resulting distributions of <inline-formula><mml:math id="inf157"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mtext>within</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf158"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>within</mml:mtext></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf159"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mtext>within</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf160"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mtext>between</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, across grid cells and splits of the data were then compared. If the within-cell variability in grid spacing and orientation was smaller than between-cell variability, we concluded that the variability of grid cell properties was a robust feature of the data and not due to noise.</p><p>When performing this shuffle analysis, we found that some cells, despite having a good grid fit when all the data was considered, did not have SACs that were well described by hexagonal structure when the data was split in half. We viewed this a manifestation of unreliable grid coding and a possible confound in our quantification of variability. As such, we introduced a new inclusion criteria (replacing that of requiring a grid score of &gt; 0.85), only considering cells that had poor grid fits on &lt; 5% of all shuffles. The percentage of all cells that were removed by this inclusion criteria is shown in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>. In general, we found that cells with high grid score were reliable, although there were exceptions. Additionally, we found that size of the bin used for splitting the data did not significantly affect the percent of cells with good grid fits (passed the prior inclusion criteria) that were considered reliable (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>).</p></sec><sec id="s4-7"><title>Synthetic grid cells</title><p>To study how variability in grid cell properties might endow the grid code with computational advantages, we generated synthetic grid cell rate maps, so that we could have complete control over the distribution of their properties. These synthetic grid cell rate maps were constructed as follows.</p><p>First, the lengths of each dimension the ‘arena’ within which the simulated grid cells exist (<inline-formula><mml:math id="inf161"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf162"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) were set. Then, for <inline-formula><mml:math id="inf163"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi><mml:mo>∈</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">N</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> grid cells, the grid spacing and orientation were sampled via <inline-formula><mml:math id="inf164"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf165"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>θ</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> where <inline-formula><mml:math id="inf166"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi class="mathcal" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is a normal distribution with mean μ and variance <inline-formula><mml:math id="inf167"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. Grid phase was sampled as <inline-formula><mml:math id="inf168"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="mathcal" mathvariant="script">U</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>×</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf169"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>ϕ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> is a two dimensional vector, with first component uniformly sampled from <inline-formula><mml:math id="inf170"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> and second component uniformly sampled from <inline-formula><mml:math id="inf171"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mstyle></mml:math></inline-formula>. To construct a population with no variability in grid properties (to use as a control), we set <inline-formula><mml:math id="inf172"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>λ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">m</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. and <inline-formula><mml:math id="inf173"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>θ</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>0</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula>.</p><p>For each grid cell, we generated idealized grid responses by summing three two-dimensional sinusoids (<xref ref-type="bibr" rid="bib79">Solstad et al., 2006</xref>), such that the activity at <inline-formula><mml:math id="inf174"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo stretchy="false">]</mml:mo><mml:mspace width="thinmathspace"/><mml:mo>×</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is given by<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mi>X</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mtext>max</mml:mtext></mml:mrow></mml:msubsup><mml:mfrac><mml:mn>2</mml:mn><mml:mn>3</mml:mn></mml:mfrac><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>3</mml:mn></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mn>3</mml:mn></mml:munderover><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">[</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mtext mathvariant="bold">k</mml:mtext></mml:mrow><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mtext mathvariant="bold">x</mml:mtext></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.623em" minsize="1.623em">]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf175"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>max</mml:mtext></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> is the maximal firing rate and <inline-formula><mml:math id="inf176"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext mathvariant="bold">k</mml:mtext></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> are the wave vectors with 0°, 60°, and 120° angular differences<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>k</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mi>k</mml:mi><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:mfrac><mml:mo>⋅</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>12</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>12</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>12</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>12</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>k</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mi>k</mml:mi><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:mfrac><mml:mo>⋅</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>5</mml:mn><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>12</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>5</mml:mn><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>12</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>5</mml:mn><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>12</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>5</mml:mn><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>12</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>k</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mi>k</mml:mi><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt></mml:mfrac><mml:mo>⋅</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>3</mml:mn><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>4</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>3</mml:mn><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>4</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>3</mml:mn><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>4</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>3</mml:mn><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>4</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf177"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:mi>π</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msqrt><mml:mn>3</mml:mn></mml:msqrt><mml:msub><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>.</p><p>To match the recorded neural data, where individual grid cells have distinct maximal firing rates, <inline-formula><mml:math id="inf178"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>max</mml:mtext></mml:mrow></mml:msubsup><mml:mo>∼</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>13</mml:mn><mml:mo>,</mml:mo><mml:mn>8</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. We enforced <inline-formula><mml:math id="inf179"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>max</mml:mtext></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> to be within [2, 30], by setting any sampled values outside of this range to the boundary values (i.e. 2 or 30).</p><p>To determine the extent to which local spatial information can be decoded from the activity of populations of grid cells with different degrees of variability in their grid properties, we performed the following analysis.</p><p>We generated noisy synthetic spike rates of <inline-formula><mml:math id="inf180"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math></inline-formula> grid cells by assuming a Poisson process and sampling using the idealized rate maps (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>). More concretely, the activity of grid cell <inline-formula><mml:math id="inf181"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math></inline-formula> at position <inline-formula><mml:math id="inf182"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula> was assumed to be a random variable with a Poisson distribution, whose mean was <inline-formula><mml:math id="inf183"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. Thus, the probability of observing <inline-formula><mml:math id="inf184"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mi>X</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> spikes, at position <inline-formula><mml:math id="inf185"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, is given by<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mi>X</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="mathcal" mathvariant="script">P</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-8"><title>Linear decoding synthetic data</title><p>For a given resolution of the arena, we generated <inline-formula><mml:math id="inf186"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>X</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf187"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. That is, we constructed 10 noisy rate maps. We performed cross-validated decoding by averaging across 9 of the 10 rate maps, to get an average rate map <inline-formula><mml:math id="inf188"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mover><mml:mi>X</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. For sake of simplicity, consider <inline-formula><mml:math id="inf189"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>X</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:mn>9</mml:mn><mml:munderover><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>9</mml:mn></mml:mrow></mml:munderover><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>X</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>j</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math></inline-formula>. To decode local position from the held out noisy rate map [e.g. <inline-formula><mml:math id="inf190"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mrow><mml:mover><mml:mi>X</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>], we multiplied the activity at each position by all the positions in the average rate map, taking the sum and assigning the decoded position as that with the largest value. The Euclidean distance between the decoded position and the true position is considered the error. This was performed 10 times (holding out each rate map once) and the average error across all positions in the environment was then averaged across all 10 of the validation splits.</p></sec><sec id="s4-9"><title>Linear decoding experimental data</title><p>To decode the electrophysiological data (<xref ref-type="bibr" rid="bib28">Gardner et al., 2022</xref>), we sampled subpopulations of grid cells from the <inline-formula><mml:math id="inf191"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>82</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> units (recording ID R12) that passed the criteria described previously. For each subpopulation, we split the recorded activity into 10 evenly spaced temporal bins, and constructed average ratemaps for each bin. This is consistent with what was done in decoding the synthetic data. All ratemaps, for each cell, were normalized by the maximal activity. We then randomly chose 5 of the 10 time bins to serve as the ‘train’ data, the remaining 5 served as the ‘test’ data. The rate maps were averaged and then the linear decoder was applied. We sampled 10 different choices of splitting the data and 25 choices of subpopulation.</p></sec><sec id="s4-10"><title>Recurrent neural network model</title><p>Code used for training and evaluating path integrating recurrent neural network (RNNs) (<xref ref-type="bibr" rid="bib81">Sorscher et al., 2019</xref>; <xref ref-type="bibr" rid="bib82">Sorscher et al., 2023</xref>) was pulled from <ext-link ext-link-type="uri" xlink:href="https://github.com/ganguli-lab/grid-pattern-formation">https://github.com/ganguli-lab/grid-pattern-formation</ext-link> (<xref ref-type="bibr" rid="bib74">Schaeffer et al., 2023</xref>). We used the same hyperparameters as are present on the repository (see <xref ref-type="table" rid="table1">Table 1</xref>), except when examining the effect of weight regularization on grid property variability, in which case we trained RNNs with weight decay magnitude from {10<sup>-6</sup>, 10<sup>-5</sup>, 10<sup>-4</sup>, 2.5 . 10<sup>-4</sup>}. The greater the value, the greater the enforced sparsity. These were chosen as they had previously been found to lead to good path integration performance and have high grid scores (<xref ref-type="bibr" rid="bib82">Sorscher et al., 2023</xref>). We independently verified that this was true for the resulting RNNs. We computed the grid score, spacing, and orientation using similar code implementations as was used for the neural data. For each value of weight decay, we trained three independent RNNs, using different random seeds.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Parameters used to train RNNs on path integration.</title><p>See <xref ref-type="bibr" rid="bib81">Sorscher et al., 2019</xref>; <xref ref-type="bibr" rid="bib82">Sorscher et al., 2023</xref> for more information on these parameters.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameter</th><th align="left" valign="bottom">Value</th></tr></thead><tbody><tr><td align="left" valign="bottom">Epochs</td><td align="left" valign="bottom">100</td></tr><tr><td align="left" valign="bottom">Batch size</td><td align="left" valign="bottom">200</td></tr><tr><td align="left" valign="bottom">Batches per epoch</td><td align="left" valign="bottom">1000</td></tr><tr><td align="left" valign="bottom">Path length (<italic>T</italic>)</td><td align="left" valign="bottom">20</td></tr><tr><td align="left" valign="bottom">Arena length (L)</td><td align="left" valign="bottom">2.2m</td></tr><tr><td align="left" valign="bottom">Learning rate</td><td align="left" valign="bottom">10<sup>-4</sup></td></tr><tr><td align="left" valign="bottom">Place cells (n<sub>p</sub>)</td><td align="left" valign="bottom">512</td></tr><tr><td align="left" valign="bottom">Grid cells (n<sub>G</sub>)</td><td align="left" valign="bottom">2096</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf192"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.12</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf193"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.24</td></tr><tr><td align="left" valign="bottom">Activation</td><td align="left" valign="bottom">ReLU</td></tr><tr><td align="left" valign="bottom">Weight decay</td><td align="left" valign="bottom">10<sup>-4</sup></td></tr><tr><td align="left" valign="bottom">Optimizer</td><td align="left" valign="bottom">Adam</td></tr></tbody></table></table-wrap></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Supervision, Validation, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Supervision, Funding acquisition, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-100652-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Code used for analysis is publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/ucsb-goard-lab/Robust-Grid-Cell-Variability">GitHub</ext-link>, copy archived at <xref ref-type="bibr" rid="bib70">Redman, 2025</xref>. Data was made available by the Moser Lab at <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.16764508">figshare</ext-link> (<xref ref-type="bibr" rid="bib28">Gardner et al., 2022</xref>).</p><p>The following previously published dataset was used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset1"><person-group person-group-type="author"><name><surname>Gardner</surname><given-names>R</given-names></name><name><surname>Hermansen</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Toroidal topology of population activity in grid cells</data-title><source>figshare</source><pub-id pub-id-type="doi">10.6084/m9.figshare.16764508</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank the members of the Goard Lab, Francisco Acosta, Spencer Smith, Caleb Kemere, Will Dorrell, and the DYNS graduate students for useful discussions surrounding this work. We thank Andreas Herz for suggesting the analysis present in <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> and William Dorrell for suggesting the analysis present in <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2C, D</xref>. We thank the eLife reviewers for their suggestions. This work was supported by grants to MJG from NIH (R01 NS121919), NSF (1934288), and the Whitehall Foundation, and a grant to XXW from NSF (2318065).</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Acosta</surname><given-names>F</given-names></name><name><surname>Sanborn</surname><given-names>S</given-names></name><name><surname>Duc</surname><given-names>KD</given-names></name><name><surname>Madhav</surname><given-names>M</given-names></name><name><surname>Miolane</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Quantifying extrinsic curvature in neural manifolds</article-title><conf-name>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</conf-name><fpage>610</fpage><lpage>619</lpage><pub-id pub-id-type="doi">10.1109/CVPRW59228.2023.00068</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Agmon</surname><given-names>H</given-names></name><name><surname>Burak</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A theory of joint attractor dynamics in the hippocampus and the entorhinal cortex accounts for artificial remapping and grid cell field-to-field variability</article-title><source>eLife</source><volume>9</volume><elocation-id>e56894</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.56894</pub-id><pub-id pub-id-type="pmid">32779570</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aronov</surname><given-names>D</given-names></name><name><surname>Nevers</surname><given-names>R</given-names></name><name><surname>Tank</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Mapping of a non-spatial dimension by the hippocampal-entorhinal circuit</article-title><source>Nature</source><volume>543</volume><fpage>719</fpage><lpage>722</lpage><pub-id pub-id-type="doi">10.1038/nature21692</pub-id><pub-id pub-id-type="pmid">28358077</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Attardo</surname><given-names>A</given-names></name><name><surname>Fitzgerald</surname><given-names>JE</given-names></name><name><surname>Schnitzer</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Impermanence of dendritic spines in live adult CA1 hippocampus</article-title><source>Nature</source><volume>523</volume><fpage>592</fpage><lpage>596</lpage><pub-id pub-id-type="doi">10.1038/nature14467</pub-id><pub-id pub-id-type="pmid">26098371</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Banino</surname><given-names>A</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Uria</surname><given-names>B</given-names></name><name><surname>Blundell</surname><given-names>C</given-names></name><name><surname>Lillicrap</surname><given-names>T</given-names></name><name><surname>Mirowski</surname><given-names>P</given-names></name><name><surname>Pritzel</surname><given-names>A</given-names></name><name><surname>Chadwick</surname><given-names>MJ</given-names></name><name><surname>Degris</surname><given-names>T</given-names></name><name><surname>Modayil</surname><given-names>J</given-names></name><name><surname>Wayne</surname><given-names>G</given-names></name><name><surname>Soyer</surname><given-names>H</given-names></name><name><surname>Viola</surname><given-names>F</given-names></name><name><surname>Zhang</surname><given-names>B</given-names></name><name><surname>Goroshin</surname><given-names>R</given-names></name><name><surname>Rabinowitz</surname><given-names>N</given-names></name><name><surname>Pascanu</surname><given-names>R</given-names></name><name><surname>Beattie</surname><given-names>C</given-names></name><name><surname>Petersen</surname><given-names>S</given-names></name><name><surname>Sadik</surname><given-names>A</given-names></name><name><surname>Gaffney</surname><given-names>S</given-names></name><name><surname>King</surname><given-names>H</given-names></name><name><surname>Kavukcuoglu</surname><given-names>K</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Hadsell</surname><given-names>R</given-names></name><name><surname>Kumaran</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Vector-based navigation using grid-like representations in artificial agents</article-title><source>Nature</source><volume>557</volume><fpage>429</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0102-6</pub-id><pub-id pub-id-type="pmid">29743670</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blair</surname><given-names>HT</given-names></name><name><surname>Welday</surname><given-names>AC</given-names></name><name><surname>Zhang</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Scale-invariant memory representations emerge from moiré interference between grid fields that produce theta oscillations: a computational model</article-title><source>The Journal of Neuroscience</source><volume>27</volume><fpage>3211</fpage><lpage>3229</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4724-06.2007</pub-id><pub-id pub-id-type="pmid">17376982</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blasdel</surname><given-names>GG</given-names></name><name><surname>Salama</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Voltage-sensitive dyes reveal a modular organization in monkey striate cortex</article-title><source>Nature</source><volume>321</volume><fpage>579</fpage><lpage>585</lpage><pub-id pub-id-type="doi">10.1038/321579a0</pub-id><pub-id pub-id-type="pmid">3713842</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burak</surname><given-names>Y</given-names></name><name><surname>Fiete</surname><given-names>IR</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Accurate path integration in continuous attractor network models of grid cells</article-title><source>PLOS Computational Biology</source><volume>5</volume><elocation-id>e1000291</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000291</pub-id><pub-id pub-id-type="pmid">19229307</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bush</surname><given-names>D</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Manson</surname><given-names>D</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Using grid cells for navigation</article-title><source>Neuron</source><volume>87</volume><fpage>507</fpage><lpage>520</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.07.006</pub-id><pub-id pub-id-type="pmid">26247860</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Butler</surname><given-names>WN</given-names></name><name><surname>Hardcastle</surname><given-names>K</given-names></name><name><surname>Giocomo</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Remembered reward locations restructure entorhinal spatial maps</article-title><source>Science</source><volume>363</volume><fpage>1447</fpage><lpage>1452</lpage><pub-id pub-id-type="doi">10.1126/science.aav5297</pub-id><pub-id pub-id-type="pmid">30923222</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chelaru</surname><given-names>MI</given-names></name><name><surname>Dragoi</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Efficient coding in heterogeneous neuronal populations</article-title><source>PNAS</source><volume>105</volume><fpage>16344</fpage><lpage>16349</lpage><pub-id pub-id-type="doi">10.1073/pnas.0807744105</pub-id><pub-id pub-id-type="pmid">18854413</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Constantinescu</surname><given-names>AO</given-names></name><name><surname>O’Reilly</surname><given-names>JX</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Organizing conceptual knowledge in humans with a gridlike code</article-title><source>Science</source><volume>352</volume><fpage>1464</fpage><lpage>1468</lpage><pub-id pub-id-type="doi">10.1126/science.aaf0941</pub-id><pub-id pub-id-type="pmid">27313047</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Couey</surname><given-names>JJ</given-names></name><name><surname>Witoelar</surname><given-names>A</given-names></name><name><surname>Zhang</surname><given-names>SJ</given-names></name><name><surname>Zheng</surname><given-names>K</given-names></name><name><surname>Ye</surname><given-names>J</given-names></name><name><surname>Dunn</surname><given-names>B</given-names></name><name><surname>Czajkowski</surname><given-names>R</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Roudi</surname><given-names>Y</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Recurrent inhibitory circuitry as a mechanism for grid formation</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>318</fpage><lpage>324</lpage><pub-id pub-id-type="doi">10.1038/nn.3310</pub-id><pub-id pub-id-type="pmid">23334580</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Cueva</surname><given-names>CJ</given-names></name><name><surname>Wei</surname><given-names>XX</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Emergence of grid-like representations by training recurrent neural networks to perform spatial localization</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.1803.07770</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Almeida</surname><given-names>L</given-names></name><name><surname>Idiart</surname><given-names>M</given-names></name><name><surname>Lisman</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The input-output transformation of the hippocampal granule cells: from grid cells to place fields</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>7504</fpage><lpage>7512</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6048-08.2009</pub-id><pub-id pub-id-type="pmid">19515918</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Derdikman</surname><given-names>D</given-names></name><name><surname>Whitlock</surname><given-names>JR</given-names></name><name><surname>Tsao</surname><given-names>A</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Fragmentation of grid cell maps in a multicompartment environment</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1325</fpage><lpage>1332</lpage><pub-id pub-id-type="doi">10.1038/nn.2396</pub-id><pub-id pub-id-type="pmid">19749749</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diehl</surname><given-names>GW</given-names></name><name><surname>Hon</surname><given-names>OJ</given-names></name><name><surname>Leutgeb</surname><given-names>S</given-names></name><name><surname>Leutgeb</surname><given-names>JK</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Grid and nongrid cells in medial entorhinal cortex represent spatial location and environmental features with complementary coding schemes</article-title><source>Neuron</source><volume>94</volume><fpage>83</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.03.004</pub-id><pub-id pub-id-type="pmid">28343867</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dong</surname><given-names>C</given-names></name><name><surname>Madar</surname><given-names>AD</given-names></name><name><surname>Sheffield</surname><given-names>MEJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Distinct place cell dynamics in CA1 and CA3 encode experience in new environments</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>2977</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-23260-3</pub-id><pub-id pub-id-type="pmid">34016996</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dordek</surname><given-names>Y</given-names></name><name><surname>Soudry</surname><given-names>D</given-names></name><name><surname>Meir</surname><given-names>R</given-names></name><name><surname>Derdikman</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Extracting grid cell characteristics from place cell inputs using non-negative principal component analysis</article-title><source>eLife</source><volume>5</volume><elocation-id>e10094</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.10094</pub-id><pub-id pub-id-type="pmid">26952211</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Dorrell</surname><given-names>W</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Whittington</surname><given-names>JCR</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Actionable neural representations: grid cells from minimal constraints</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.2209.15563</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dunn</surname><given-names>B</given-names></name><name><surname>Mørreaunet</surname><given-names>M</given-names></name><name><surname>Roudi</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Correlations and functional connections in a population of grid cells</article-title><source>PLOS Computational Biology</source><volume>11</volume><elocation-id>e1004052</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004052</pub-id><pub-id pub-id-type="pmid">25714908</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Dunn</surname><given-names>B</given-names></name><name><surname>Wennberg</surname><given-names>D</given-names></name><name><surname>Huang</surname><given-names>Z</given-names></name><name><surname>Roudi</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Grid cells show field-to-field variability and this explains the aperiodic response of inhibitory interneurons</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.1101/101899</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Ester</surname><given-names>M</given-names></name><name><surname>Kriegel</surname><given-names>HP</given-names></name><name><surname>Sander</surname><given-names>J</given-names></name><name><surname>Xu</surname><given-names>X</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>A density-based algorithm for discovering clusters in large spatial databases with noise</article-title><conf-name>KDD: Proceedings. International Conference on Knowledge Discovery &amp; Data Mining</conf-name><fpage>226</fpage><lpage>231</lpage></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiete</surname><given-names>IR</given-names></name><name><surname>Burak</surname><given-names>Y</given-names></name><name><surname>Brookings</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>What grid cells convey about rat location</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>6858</fpage><lpage>6871</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5684-07.2008</pub-id><pub-id pub-id-type="pmid">18596161</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuhs</surname><given-names>MC</given-names></name><name><surname>Touretzky</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A spin glass model of path integration in rat medial entorhinal cortex</article-title><source>The Journal of Neuroscience</source><volume>26</volume><fpage>4266</fpage><lpage>4276</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4353-05.2006</pub-id><pub-id pub-id-type="pmid">16624947</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>Treves</surname><given-names>A</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Hippocampal remapping and grid realignment in entorhinal cortex</article-title><source>Nature</source><volume>446</volume><fpage>190</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1038/nature05601</pub-id><pub-id pub-id-type="pmid">17322902</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gardner</surname><given-names>RJ</given-names></name><name><surname>Lu</surname><given-names>L</given-names></name><name><surname>Wernle</surname><given-names>T</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Correlation structure of grid cells is preserved during sleep</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>598</fpage><lpage>608</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0360-0</pub-id><pub-id pub-id-type="pmid">30911185</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gardner</surname><given-names>RJ</given-names></name><name><surname>Hermansen</surname><given-names>E</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Burak</surname><given-names>Y</given-names></name><name><surname>Baas</surname><given-names>NA</given-names></name><name><surname>Dunn</surname><given-names>BA</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Toroidal topology of population activity in grid cells</article-title><source>Nature</source><volume>602</volume><fpage>123</fpage><lpage>128</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-04268-7</pub-id><pub-id pub-id-type="pmid">35022611</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ginosar</surname><given-names>G</given-names></name><name><surname>Aljadeff</surname><given-names>J</given-names></name><name><surname>Las</surname><given-names>L</given-names></name><name><surname>Derdikman</surname><given-names>D</given-names></name><name><surname>Ulanovsky</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Are grid cells used for navigation? on local metrics, subjective spaces, and black holes</article-title><source>Neuron</source><volume>111</volume><fpage>1858</fpage><lpage>1875</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2023.03.027</pub-id><pub-id pub-id-type="pmid">37044087</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gjorgjieva</surname><given-names>J</given-names></name><name><surname>Drion</surname><given-names>G</given-names></name><name><surname>Marder</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Computational implications of biophysical diversity and multiple timescales in neurons and synapses for circuit performance</article-title><source>Current Opinion in Neurobiology</source><volume>37</volume><fpage>44</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2015.12.008</pub-id><pub-id pub-id-type="pmid">26774694</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gonzalez</surname><given-names>WG</given-names></name><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>Harutyunyan</surname><given-names>A</given-names></name><name><surname>Lois</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Persistence of neuronal representations through time and damage in the hippocampus</article-title><source>Science</source><volume>365</volume><fpage>821</fpage><lpage>825</lpage><pub-id pub-id-type="doi">10.1126/science.aav9199</pub-id><pub-id pub-id-type="pmid">31439798</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gu</surname><given-names>Y</given-names></name><name><surname>Lewallen</surname><given-names>S</given-names></name><name><surname>Kinkhabwala</surname><given-names>AA</given-names></name><name><surname>Domnisoru</surname><given-names>C</given-names></name><name><surname>Yoon</surname><given-names>K</given-names></name><name><surname>Gauthier</surname><given-names>JL</given-names></name><name><surname>Fiete</surname><given-names>IR</given-names></name><name><surname>Tank</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A map-like micro-organization of grid cells in the medial entorhinal cortex</article-title><source>Cell</source><volume>175</volume><fpage>736</fpage><lpage>750</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.08.066</pub-id><pub-id pub-id-type="pmid">30270041</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Guanella</surname><given-names>A</given-names></name><name><surname>Verschure</surname><given-names>PF</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A model of grid cells based on A path integration mechanism</article-title><conf-name>Artificial NeuralNetworks–ICANN 2006: 16th International Conference, Athens, Greece, September 10-14, 2006. Proceedings, Part I 16</conf-name><fpage>740</fpage><lpage>749</lpage><pub-id pub-id-type="doi">10.1007/11840817_77</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Molden</surname><given-names>S</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Microstructure of a spatial map in the entorhinal cortex</article-title><source>Nature</source><volume>436</volume><fpage>801</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1038/nature03721</pub-id><pub-id pub-id-type="pmid">15965463</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hainmueller</surname><given-names>T</given-names></name><name><surname>Bartos</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Parallel emergence of stable and dynamic memory engrams in the hippocampus</article-title><source>Nature</source><volume>558</volume><fpage>292</fpage><lpage>296</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0191-2</pub-id><pub-id pub-id-type="pmid">29875406</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hawkins</surname><given-names>J</given-names></name><name><surname>Lewis</surname><given-names>M</given-names></name><name><surname>Klukas</surname><given-names>M</given-names></name><name><surname>Purdy</surname><given-names>S</given-names></name><name><surname>Ahmad</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A framework for intelligence and cortical function based on grid cells in the neocortex</article-title><source>Frontiers in Neural Circuits</source><volume>12</volume><elocation-id>121</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2018.00121</pub-id><pub-id pub-id-type="pmid">30687022</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ismakov</surname><given-names>R</given-names></name><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Jeffery</surname><given-names>K</given-names></name><name><surname>Derdikman</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Grid cells encode local positional information</article-title><source>Current Biology</source><volume>27</volume><fpage>2337</fpage><lpage>2343</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.06.034</pub-id><pub-id pub-id-type="pmid">28756950</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Julian</surname><given-names>JB</given-names></name><name><surname>Keinath</surname><given-names>AT</given-names></name><name><surname>Frazzetta</surname><given-names>G</given-names></name><name><surname>Epstein</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Human entorhinal cortex represents visual space using a boundary-anchored grid</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>191</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1038/s41593-017-0049-1</pub-id><pub-id pub-id-type="pmid">29311745</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jun</surname><given-names>JJ</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Siegle</surname><given-names>JH</given-names></name><name><surname>Denman</surname><given-names>DJ</given-names></name><name><surname>Bauza</surname><given-names>M</given-names></name><name><surname>Barbarits</surname><given-names>B</given-names></name><name><surname>Lee</surname><given-names>AK</given-names></name><name><surname>Anastassiou</surname><given-names>CA</given-names></name><name><surname>Andrei</surname><given-names>A</given-names></name><name><surname>Aydın</surname><given-names>Ç</given-names></name><name><surname>Barbic</surname><given-names>M</given-names></name><name><surname>Blanche</surname><given-names>TJ</given-names></name><name><surname>Bonin</surname><given-names>V</given-names></name><name><surname>Couto</surname><given-names>J</given-names></name><name><surname>Dutta</surname><given-names>B</given-names></name><name><surname>Gratiy</surname><given-names>SL</given-names></name><name><surname>Gutnisky</surname><given-names>DA</given-names></name><name><surname>Häusser</surname><given-names>M</given-names></name><name><surname>Karsh</surname><given-names>B</given-names></name><name><surname>Ledochowitsch</surname><given-names>P</given-names></name><name><surname>Lopez</surname><given-names>CM</given-names></name><name><surname>Mitelut</surname><given-names>C</given-names></name><name><surname>Musa</surname><given-names>S</given-names></name><name><surname>Okun</surname><given-names>M</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Putzeys</surname><given-names>J</given-names></name><name><surname>Rich</surname><given-names>PD</given-names></name><name><surname>Rossant</surname><given-names>C</given-names></name><name><surname>Sun</surname><given-names>W-L</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Harris</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Fully integrated silicon probes for high-density recording of neural activity</article-title><source>Nature</source><volume>551</volume><fpage>232</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1038/nature24636</pub-id><pub-id pub-id-type="pmid">29120427</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Khona</surname><given-names>M</given-names></name><name><surname>Chandra</surname><given-names>S</given-names></name><name><surname>Fiete</surname><given-names>IR</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>From Smooth Cortical Gradients to Discrete Modules: Spontaneous and Topologically Robust Emergence of Modularity in Grid Cells</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.10.28.466284</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Killian</surname><given-names>NJ</given-names></name><name><surname>Jutras</surname><given-names>MJ</given-names></name><name><surname>Buffalo</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A map of visual space in the primate entorhinal cortex</article-title><source>Nature</source><volume>491</volume><fpage>761</fpage><lpage>764</lpage><pub-id pub-id-type="doi">10.1038/nature11587</pub-id><pub-id pub-id-type="pmid">23103863</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klukas</surname><given-names>M</given-names></name><name><surname>Lewis</surname><given-names>M</given-names></name><name><surname>Fiete</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Efficient and flexible representation of higher-dimensional cognitive variables with grid cells</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1007796</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007796</pub-id><pub-id pub-id-type="pmid">32343687</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krupic</surname><given-names>J</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural representations of location composed of spatially periodic bands</article-title><source>Science</source><volume>337</volume><fpage>853</fpage><lpage>857</lpage><pub-id pub-id-type="doi">10.1126/science.1222403</pub-id><pub-id pub-id-type="pmid">22904012</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krupic</surname><given-names>J</given-names></name><name><surname>Bauza</surname><given-names>M</given-names></name><name><surname>Burton</surname><given-names>S</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Grid cell symmetry is shaped by environmental geometry</article-title><source>Nature</source><volume>518</volume><fpage>232</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1038/nature14153</pub-id><pub-id pub-id-type="pmid">25673417</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kubie</surname><given-names>JL</given-names></name><name><surname>Fox</surname><given-names>SE</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Do the spatial frequencies of grid cells mold the firing fields of place cells?</article-title><source>PNAS</source><volume>112</volume><fpage>3860</fpage><lpage>3861</lpage><pub-id pub-id-type="doi">10.1073/pnas.1503155112</pub-id><pub-id pub-id-type="pmid">25829538</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Deshmukh</surname><given-names>SS</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neural population evidence of functional heterogeneity along the CA3 transverse axis: pattern completion versus pattern separation</article-title><source>Neuron</source><volume>87</volume><fpage>1093</fpage><lpage>1105</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.07.012</pub-id><pub-id pub-id-type="pmid">26298276</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levy</surname><given-names>ERJ</given-names></name><name><surname>Carrillo-Segura</surname><given-names>S</given-names></name><name><surname>Park</surname><given-names>EH</given-names></name><name><surname>Redman</surname><given-names>WT</given-names></name><name><surname>Hurtado</surname><given-names>JR</given-names></name><name><surname>Chung</surname><given-names>S</given-names></name><name><surname>Fenton</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>A manifold neural population code for space in hippocampal coactivity dynamics independent of place fields</article-title><source>Cell Reports</source><volume>42</volume><elocation-id>113142</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2023.113142</pub-id><pub-id pub-id-type="pmid">37742193</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Low</surname><given-names>RJ</given-names></name><name><surname>Gu</surname><given-names>Y</given-names></name><name><surname>Tank</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Cellular resolution optical access to brain regions in fissures: imaging medial prefrontal cortex and grid cells in entorhinal cortex</article-title><source>PNAS</source><volume>111</volume><fpage>18739</fpage><lpage>18744</lpage><pub-id pub-id-type="doi">10.1073/pnas.1421753111</pub-id><pub-id pub-id-type="pmid">25503366</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lu</surname><given-names>L</given-names></name><name><surname>Igarashi</surname><given-names>KM</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Topography of place maps along the CA3-to-CA2 axis of the hippocampus</article-title><source>Neuron</source><volume>87</volume><fpage>1078</fpage><lpage>1092</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.07.007</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mallory</surname><given-names>CS</given-names></name><name><surname>Hardcastle</surname><given-names>K</given-names></name><name><surname>Bant</surname><given-names>JS</given-names></name><name><surname>Giocomo</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Grid scale drives the scale and long-term stability of place maps</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>270</fpage><lpage>282</lpage><pub-id pub-id-type="doi">10.1038/s41593-017-0055-3</pub-id><pub-id pub-id-type="pmid">29335607</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mankin</surname><given-names>EA</given-names></name><name><surname>Sparks</surname><given-names>FT</given-names></name><name><surname>Slayyeh</surname><given-names>B</given-names></name><name><surname>Sutherland</surname><given-names>RJ</given-names></name><name><surname>Leutgeb</surname><given-names>S</given-names></name><name><surname>Leutgeb</surname><given-names>JK</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neuronal code for extended time in the hippocampus</article-title><source>PNAS</source><volume>109</volume><fpage>19462</fpage><lpage>19467</lpage><pub-id pub-id-type="doi">10.1073/pnas.1214107109</pub-id><pub-id pub-id-type="pmid">23132944</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Herz</surname><given-names>AVM</given-names></name><name><surname>Stemmler</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012a</year><article-title>Optimal population codes for space: grid cells outperform place cells</article-title><source>Neural Computation</source><volume>24</volume><fpage>2280</fpage><lpage>2317</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00319</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Herz</surname><given-names>AVM</given-names></name><name><surname>Stemmler</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2012">2012b</year><article-title>Resolution of nested neuronal representations can be exponential in the number of neurons</article-title><source>Physical Review Letters</source><volume>109</volume><elocation-id>e8103</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevLett.109.018103</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>McInnes</surname><given-names>L</given-names></name><name><surname>Healy</surname><given-names>J</given-names></name><name><surname>Saul</surname><given-names>N</given-names></name><name><surname>Großberger</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Umap: Uniform Manifold Approximation and Projection for Dimension Reduction</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.21105/joss.00861</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Battaglia</surname><given-names>FP</given-names></name><name><surname>Jensen</surname><given-names>O</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Path integration and the neural basis of the “cognitive map”</article-title><source>Nature Reviews Neuroscience</source><volume>7</volume><fpage>663</fpage><lpage>678</lpage><pub-id pub-id-type="doi">10.1038/nrn1932</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mizrahi</surname><given-names>A</given-names></name><name><surname>Crowley</surname><given-names>JC</given-names></name><name><surname>Shtoyerman</surname><given-names>E</given-names></name><name><surname>Katz</surname><given-names>LC</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>High-resolution in vivo imaging of hippocampal dendrites and spines</article-title><source>The Journal of Neuroscience</source><volume>24</volume><fpage>3147</fpage><lpage>3151</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5218-03.2004</pub-id><pub-id pub-id-type="pmid">15056694</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nau</surname><given-names>M</given-names></name><name><surname>Navarro Schröder</surname><given-names>T</given-names></name><name><surname>Bellmund</surname><given-names>JLS</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Hexadirectional coding of visual space in human entorhinal cortex</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>188</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1038/s41593-017-0050-8</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Nayebi</surname><given-names>A</given-names></name><name><surname>Attinger</surname><given-names>A</given-names></name><name><surname>Campbell</surname><given-names>MG</given-names></name><name><surname>Hardcastle</surname><given-names>K</given-names></name><name><surname>Low</surname><given-names>IIC</given-names></name><name><surname>Mallory</surname><given-names>CS</given-names></name><name><surname>Mel</surname><given-names>GC</given-names></name><name><surname>Sorscher</surname><given-names>B</given-names></name><name><surname>Williams</surname><given-names>AH</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name><name><surname>Giocomo</surname><given-names>LM</given-names></name><name><surname>Yamins</surname><given-names>DLK</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Explaining heterogeneity in medial entorhinal cortex with task-driven neural networks</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.10.30.466617</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neupane</surname><given-names>S</given-names></name><name><surname>Fiete</surname><given-names>I</given-names></name><name><surname>Jazayeri</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Mental navigation in the primate entorhinal cortex</article-title><source>Nature</source><volume>630</volume><fpage>704</fpage><lpage>711</lpage><pub-id pub-id-type="doi">10.1038/s41586-024-07557-z</pub-id><pub-id pub-id-type="pmid">38867051</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ormond</surname><given-names>J</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Place field expansion after focal MEC inactivations is consistent with loss of Fourier components and path integrator gain reduction</article-title><source>PNAS</source><volume>112</volume><fpage>4116</fpage><lpage>4121</lpage><pub-id pub-id-type="doi">10.1073/pnas.1421963112</pub-id><pub-id pub-id-type="pmid">25733884</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Ostrow</surname><given-names>M</given-names></name><name><surname>Eisen</surname><given-names>A</given-names></name><name><surname>Kozachkov</surname><given-names>L</given-names></name><name><surname>Fiete</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Beyond geometry: comparing the temporal structure of computation in neural circuits with dynamical similarity analysis</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.32470/CCN.2023.1356-0</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paik</surname><given-names>S-B</given-names></name><name><surname>Ringach</surname><given-names>DL</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Retinal origin of orientation maps in visual cortex</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>919</fpage><lpage>925</lpage><pub-id pub-id-type="doi">10.1038/nn.2824</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perez Nieves</surname><given-names>N</given-names></name><name><surname>Leung</surname><given-names>VCH</given-names></name><name><surname>Dragotti</surname><given-names>PL</given-names></name><name><surname>Goodman</surname><given-names>DFM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Neural heterogeneity promotes robust learning</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>5791</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-26022-3</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Pettersen</surname><given-names>M</given-names></name><name><surname>Schøyen</surname><given-names>VS</given-names></name><name><surname>Østby</surname><given-names>MD</given-names></name><name><surname>Malthe-Sørenssen</surname><given-names>A</given-names></name><name><surname>Lepperød</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2024">2024a</year><article-title>Self-supervised grid cells without path integration</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2024.05.30.596577</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Pettersen</surname><given-names>MB</given-names></name><name><surname>Schøyen</surname><given-names>VS</given-names></name><name><surname>Malthe-Sørenssen</surname><given-names>A</given-names></name><name><surname>Lepperød</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2024">2024b</year><article-title>Decoding the cognitive map: learning place cells and remapping</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2024.03.14.585049</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfeiffer</surname><given-names>T</given-names></name><name><surname>Poll</surname><given-names>S</given-names></name><name><surname>Bancelin</surname><given-names>S</given-names></name><name><surname>Angibaud</surname><given-names>J</given-names></name><name><surname>Inavalli</surname><given-names>VK</given-names></name><name><surname>Keppler</surname><given-names>K</given-names></name><name><surname>Mittag</surname><given-names>M</given-names></name><name><surname>Fuhrmann</surname><given-names>M</given-names></name><name><surname>Nägerl</surname><given-names>UV</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Chronic 2P-STED imaging reveals high turnover of dendritic spines in the hippocampus in vivo</article-title><source>eLife</source><volume>7</volume><elocation-id>e34700</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.34700</pub-id><pub-id pub-id-type="pmid">29932052</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Redman</surname><given-names>WT</given-names></name><name><surname>Fonoberova</surname><given-names>M</given-names></name><name><surname>Mohr</surname><given-names>R</given-names></name><name><surname>Kevrekidis</surname><given-names>IG</given-names></name><name><surname>Mezic</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2022">2022a</year><article-title>Algorithmic (semi-)conjugacy via Koopman operator theory</article-title><conf-name>2022 IEEE 61st Conference on Decision and Control (CDC</conf-name><conf-loc>Cancun, Mexico</conf-loc><pub-id pub-id-type="doi">10.1109/CDC51059.2022.9992592</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Redman</surname><given-names>WT</given-names></name><name><surname>Wolcott</surname><given-names>NS</given-names></name><name><surname>Montelisciani</surname><given-names>L</given-names></name><name><surname>Luna</surname><given-names>G</given-names></name><name><surname>Marks</surname><given-names>TD</given-names></name><name><surname>Sit</surname><given-names>KK</given-names></name><name><surname>Yu</surname><given-names>C-H</given-names></name><name><surname>Smith</surname><given-names>S</given-names></name><name><surname>Goard</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2022">2022b</year><article-title>Long-term transverse imaging of the hippocampus with glass microperiscopes</article-title><source>eLife</source><volume>11</volume><elocation-id>e75391</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.75391</pub-id><pub-id pub-id-type="pmid">35775393</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Redman</surname><given-names>WT</given-names></name><name><surname>Bello Rivas</surname><given-names>JM</given-names></name><name><surname>Fonoberova</surname><given-names>M</given-names></name><name><surname>Mohr</surname><given-names>R</given-names></name><name><surname>Kevrekidis</surname><given-names>IG</given-names></name><name><surname>Mezić</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>On equivalent optimization of machine learning methods</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.2302.09160</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Redman</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>Robust-grid-cell-variability</data-title><version designator="swh:1:rev:c0bb04c52c817955782894fc07dc4f34cf4ea434">swh:1:rev:c0bb04c52c817955782894fc07dc4f34cf4ea434</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:99393379b6a69e0fb198f341f2a9769c896713d3;origin=https://github.com/ucsb-goard-lab/Robust-Grid-Cell-Variability;visit=swh:1:snp:fcb621cfd5041e7803610fdc16be8300d65d23a9;anchor=swh:1:rev:c0bb04c52c817955782894fc07dc4f34cf4ea434">https://archive.softwareheritage.org/swh:1:dir:99393379b6a69e0fb198f341f2a9769c896713d3;origin=https://github.com/ucsb-goard-lab/Robust-Grid-Cell-Variability;visit=swh:1:snp:fcb621cfd5041e7803610fdc16be8300d65d23a9;anchor=swh:1:rev:c0bb04c52c817955782894fc07dc4f34cf4ea434</ext-link></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname><given-names>ET</given-names></name><name><surname>Stringer</surname><given-names>SM</given-names></name><name><surname>Elliot</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Entorhinal cortex grid cells can map to hippocampal place cells by competitive learning</article-title><source>Network</source><volume>17</volume><fpage>447</fpage><lpage>465</lpage><pub-id pub-id-type="doi">10.1080/09548980601064846</pub-id><pub-id pub-id-type="pmid">17162463</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rueckemann</surname><given-names>JW</given-names></name><name><surname>Sosa</surname><given-names>M</given-names></name><name><surname>Giocomo</surname><given-names>LM</given-names></name><name><surname>Buffalo</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The grid code for ordered experience</article-title><source>Nature Reviews. Neuroscience</source><volume>22</volume><fpage>637</fpage><lpage>649</lpage><pub-id pub-id-type="doi">10.1038/s41583-021-00499-9</pub-id><pub-id pub-id-type="pmid">34453151</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sargolini</surname><given-names>F</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Conjunctive representation of position, direction, and velocity in entorhinal cortex</article-title><source>Science</source><volume>312</volume><fpage>758</fpage><lpage>762</lpage><pub-id pub-id-type="doi">10.1126/science.1125572</pub-id><pub-id pub-id-type="pmid">16675704</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Schaeffer</surname><given-names>R</given-names></name><name><surname>Sorscher</surname><given-names>B</given-names></name><name><surname>Mel de Fontenay</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>Grid-pattern-formation</data-title><version designator="401dd6b">401dd6b</version><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/ganguli-lab/grid-pattern-formation">https://github.com/ganguli-lab/grid-pattern-formation</ext-link></element-citation></ref><ref id="bib75"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Schaeffer</surname><given-names>R</given-names></name><name><surname>Khona</surname><given-names>M</given-names></name><name><surname>Ma</surname><given-names>T</given-names></name><name><surname>Eyzaguirre</surname><given-names>C</given-names></name><name><surname>Koyejo</surname><given-names>S</given-names></name><name><surname>Fiete</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Self-supervised learning of representations for space generates multi-modular grid cells</article-title><source>arXiv</source><pub-id pub-id-type="doi">10.48550/arXiv.2311.02316</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schøyen</surname><given-names>V</given-names></name><name><surname>Pettersen</surname><given-names>MB</given-names></name><name><surname>Holzhausen</surname><given-names>K</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Malthe-Sørenssen</surname><given-names>A</given-names></name><name><surname>Lepperød</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Coherently remapping toroidal cells but not Grid cells are responsible for path integration in virtual agents</article-title><source>iScience</source><volume>26</volume><elocation-id>108102</elocation-id><pub-id pub-id-type="doi">10.1016/j.isci.2023.108102</pub-id><pub-id pub-id-type="pmid">37867941</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shamir</surname><given-names>M</given-names></name><name><surname>Sompolinsky</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Implications of neuronal diversity on population coding</article-title><source>Neural Computation</source><volume>18</volume><fpage>1951</fpage><lpage>1986</lpage><pub-id pub-id-type="doi">10.1162/neco.2006.18.8.1951</pub-id><pub-id pub-id-type="pmid">16771659</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>SL</given-names></name><name><surname>Smith</surname><given-names>IT</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Life imitates op art</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>803</fpage><lpage>804</lpage><pub-id pub-id-type="doi">10.1038/nn.2865</pub-id><pub-id pub-id-type="pmid">21709673</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Solstad</surname><given-names>T</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Einevoll</surname><given-names>GT</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>From grid cells to place cells: a mathematical model</article-title><source>Hippocampus</source><volume>16</volume><fpage>1026</fpage><lpage>1031</lpage><pub-id pub-id-type="doi">10.1002/hipo.20244</pub-id><pub-id pub-id-type="pmid">17094145</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Solstad</surname><given-names>T</given-names></name><name><surname>Boccara</surname><given-names>CN</given-names></name><name><surname>Kropff</surname><given-names>E</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Representation of geometric borders in the entorhinal cortex</article-title><source>Science</source><volume>322</volume><fpage>1865</fpage><lpage>1868</lpage><pub-id pub-id-type="doi">10.1126/science.1166466</pub-id><pub-id pub-id-type="pmid">19095945</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Sorscher</surname><given-names>B</given-names></name><name><surname>Ocko</surname><given-names>SA</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A unified theory for the origin of grid cells through the lens of pattern formation</article-title><conf-name>Advances in Neural Information Processing Systems</conf-name><fpage>121</fpage><lpage>137</lpage></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sorscher</surname><given-names>B</given-names></name><name><surname>Mel</surname><given-names>GC</given-names></name><name><surname>Ocko</surname><given-names>SA</given-names></name><name><surname>Giocomo</surname><given-names>LM</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>A unified theory for the computational and mechanistic origins of grid cells</article-title><source>Neuron</source><volume>111</volume><fpage>121</fpage><lpage>137</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2022.10.003</pub-id><pub-id pub-id-type="pmid">36306779</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sreenivasan</surname><given-names>S</given-names></name><name><surname>Fiete</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Grid cells generate an analog error-correcting code for singularly precise neural computation</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1330</fpage><lpage>1337</lpage><pub-id pub-id-type="doi">10.1038/nn.2901</pub-id><pub-id pub-id-type="pmid">21909090</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Aydin</surname><given-names>C</given-names></name><name><surname>Lebedeva</surname><given-names>A</given-names></name><name><surname>Okun</surname><given-names>M</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Bauza</surname><given-names>M</given-names></name><name><surname>Beau</surname><given-names>M</given-names></name><name><surname>Bhagat</surname><given-names>J</given-names></name><name><surname>Böhm</surname><given-names>C</given-names></name><name><surname>Broux</surname><given-names>M</given-names></name><name><surname>Chen</surname><given-names>S</given-names></name><name><surname>Colonell</surname><given-names>J</given-names></name><name><surname>Gardner</surname><given-names>RJ</given-names></name><name><surname>Karsh</surname><given-names>B</given-names></name><name><surname>Kloosterman</surname><given-names>F</given-names></name><name><surname>Kostadinov</surname><given-names>D</given-names></name><name><surname>Mora-Lopez</surname><given-names>C</given-names></name><name><surname>O’Callaghan</surname><given-names>J</given-names></name><name><surname>Park</surname><given-names>J</given-names></name><name><surname>Putzeys</surname><given-names>J</given-names></name><name><surname>Sauerbrei</surname><given-names>B</given-names></name><name><surname>van Daal</surname><given-names>RJJ</given-names></name><name><surname>Vollan</surname><given-names>AZ</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Welkenhuysen</surname><given-names>M</given-names></name><name><surname>Ye</surname><given-names>Z</given-names></name><name><surname>Dudman</surname><given-names>JT</given-names></name><name><surname>Dutta</surname><given-names>B</given-names></name><name><surname>Hantman</surname><given-names>AW</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Lee</surname><given-names>AK</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Renart</surname><given-names>A</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name><name><surname>Häusser</surname><given-names>M</given-names></name><name><surname>Haesler</surname><given-names>S</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Neuropixels 2.0: a miniaturized high-density probe for stable, long-term brain recordings</article-title><source>Science</source><volume>372</volume><elocation-id>eabf4588</elocation-id><pub-id pub-id-type="doi">10.1126/science.abf4588</pub-id><pub-id pub-id-type="pmid">33859006</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stemmler</surname><given-names>M</given-names></name><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Herz</surname><given-names>AVM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Connecting multiple spatial scales to decode the population activity of grid cells</article-title><source>Science Advances</source><volume>1</volume><elocation-id>e1500816</elocation-id><pub-id pub-id-type="doi">10.1126/science.1500816</pub-id><pub-id pub-id-type="pmid">26824061</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stensola</surname><given-names>H</given-names></name><name><surname>Stensola</surname><given-names>T</given-names></name><name><surname>Solstad</surname><given-names>T</given-names></name><name><surname>Frøland</surname><given-names>K</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The entorhinal grid map is discretized</article-title><source>Nature</source><volume>492</volume><fpage>72</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1038/nature11649</pub-id><pub-id pub-id-type="pmid">23222610</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stensola</surname><given-names>T</given-names></name><name><surname>Stensola</surname><given-names>H</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Shearing-induced asymmetry in entorhinal grid cells</article-title><source>Nature</source><volume>518</volume><fpage>207</fpage><lpage>212</lpage><pub-id pub-id-type="doi">10.1038/nature14151</pub-id><pub-id pub-id-type="pmid">25673414</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Trettel</surname><given-names>SG</given-names></name><name><surname>Trimper</surname><given-names>JB</given-names></name><name><surname>Hwaun</surname><given-names>E</given-names></name><name><surname>Fiete</surname><given-names>IR</given-names></name><name><surname>Colgin</surname><given-names>LL</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Grid cell co-activity patterns during sleep reflect spatial overlap of grid fields during active behaviors</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>609</fpage><lpage>617</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0359-6</pub-id><pub-id pub-id-type="pmid">30911183</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Strien</surname><given-names>NM</given-names></name><name><surname>Cappaert</surname><given-names>NLM</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The anatomy of memory: an interactive overview of the parahippocampal-hippocampal network</article-title><source>Nature Reviews. Neuroscience</source><volume>10</volume><fpage>272</fpage><lpage>282</lpage><pub-id pub-id-type="doi">10.1038/nrn2614</pub-id><pub-id pub-id-type="pmid">19300446</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weber</surname><given-names>SN</given-names></name><name><surname>Sprekeler</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Learning place cells, grid cells and invariances with excitatory and inhibitory plasticity</article-title><source>eLife</source><volume>7</volume><elocation-id>e34560</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.34560</pub-id><pub-id pub-id-type="pmid">29465399</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>XX</given-names></name><name><surname>Prentice</surname><given-names>J</given-names></name><name><surname>Balasubramanian</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A principle of economy predicts the functional architecture of grid cells</article-title><source>eLife</source><volume>4</volume><elocation-id>e08362</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.08362</pub-id><pub-id pub-id-type="pmid">26335200</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilming</surname><given-names>N</given-names></name><name><surname>König</surname><given-names>P</given-names></name><name><surname>König</surname><given-names>S</given-names></name><name><surname>Buffalo</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Entorhinal cortex receptive fields are modulated by spatial attention, even without movement</article-title><source>eLife</source><volume>7</volume><elocation-id>e31745</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.31745</pub-id><pub-id pub-id-type="pmid">29537964</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoon</surname><given-names>K</given-names></name><name><surname>Buice</surname><given-names>MA</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Hayman</surname><given-names>R</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>Fiete</surname><given-names>IR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Specific evidence of low-dimensional continuous attractor dynamics in grid cells</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1077</fpage><lpage>1084</lpage><pub-id pub-id-type="doi">10.1038/nn.3450</pub-id><pub-id pub-id-type="pmid">23852111</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ziv</surname><given-names>Y</given-names></name><name><surname>Burns</surname><given-names>LD</given-names></name><name><surname>Cocker</surname><given-names>ED</given-names></name><name><surname>Hamel</surname><given-names>EO</given-names></name><name><surname>Ghosh</surname><given-names>KK</given-names></name><name><surname>Kitch</surname><given-names>LJ</given-names></name><name><surname>El Gamal</surname><given-names>A</given-names></name><name><surname>Schnitzer</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Long-term dynamics of CA1 hippocampal place codes</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>264</fpage><lpage>266</lpage><pub-id pub-id-type="doi">10.1038/nn.3329</pub-id><pub-id pub-id-type="pmid">23396101</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zong</surname><given-names>W</given-names></name><name><surname>Obenhaus</surname><given-names>HA</given-names></name><name><surname>Skytøen</surname><given-names>ER</given-names></name><name><surname>Eneqvist</surname><given-names>H</given-names></name><name><surname>de Jong</surname><given-names>NL</given-names></name><name><surname>Vale</surname><given-names>R</given-names></name><name><surname>Jorge</surname><given-names>MR</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Large-scale two-photon calcium imaging in freely moving mice</article-title><source>Cell</source><volume>185</volume><fpage>1240</fpage><lpage>1256</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2022.02.017</pub-id><pub-id pub-id-type="pmid">35305313</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.100652.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Peyrache</surname><given-names>Adrien</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>McGill University</institution><country>Canada</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Valuable</kwd></kwd-group></front-stub><body><p>This <bold>valuable</bold> study examines the variability in spacing and direction of entorhinal grid cells, providing <bold>convincing</bold> evidence that such variability helps disambiguate locations within an environment. This study will be of interest to neuroscientists working on spatial navigation and, more broadly, on neural coding.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.100652.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>The present paper by Redman et al. investigated the variability of grid cell properties in the MEC by analyzing publicly available large-scale neural recording data. Although previous studies have proposed that grid spacing and orientation are homogeneous within the same grid module, the authors found a small but robust variability in grid spacing and orientation across grid cells in the same module. The authors also showed, through model simulations, that such variability is useful for decoding spatial position.</p><p>Strengths:</p><p>The results of this study provide novel and intriguing insights into how grid cells compose the cognitive map in the axis of the entorhinal cortex and hippocampus. This study analyzes large data sets in an appropriate manner and the results are convincing.</p><p>Comments on revisions:</p><p>In the revised version of the manuscript, the authors have addressed all the concerns I raised.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.100652.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This paper presents an interesting and useful analysis of grid cell heterogeneity, showing that the experimentally observed heterogeneity of spacing and orientation within a grid cell module can allow more accurate decoding of location from a single module.</p><p>Strengths:</p><p>(1) I found the statistical analysis of the grid cell variability to be very systematic and convincing. I also found the evidence for enhanced decoding of location based on between cell variability within a module to be convincing and important, supporting their conclusions.</p><p>(2) Theoreticians have developed models that focus on the use of grid cells that are highly regular in their parameters, and usually vary only in the spatial phase of cells within modules and the spacing and orientation between modules. This focus on consistency is partly to obtain the generalization of the grid cell code to a broad range of previously unvisited locations. In contrast, most experimentalists working with grid cells know that many if not most grid cells show high variability of firing fields, as demonstrated in the figures in experimental papers. The authors of this current paper have highlighted this discrepancy, and shown that the variability shown in the data could actually enhance decoding of location.</p></body></sub-article><sub-article article-type="referee-report" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.100652.3.sa3</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>Redman and colleagues analyze grid cell data obtained from public databases. They show that there is significant variability in spacing and orientation within a module. They show that the difference in spacing and orientation for a pair of cells is larger than the one obtained for two independent maps of the same cell. They speculate that this variability could be useful to disambiguate the rat position if only information from a single module is used by a decoder.</p><p>Strengths:</p><p>The strengths of this work lie in its conciseness, clarity, and the potential significance of its findings for the grid cell community, which has largely overlooked this issue for the past two decades. Their hypothesis is well stated and the analyses are solid.</p><p>Weaknesses:</p><p>Major weaknesses identified in the original version have been addressed.</p><p>The authors have addressed all of our concerns, providing control analyses that strengthen their claim.</p></body></sub-article><sub-article article-type="author-comment" id="sa4"><front-stub><article-id pub-id-type="doi">10.7554/eLife.100652.3.sa4</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Redman</surname><given-names>William T</given-names></name><role specific-use="author">Author</role><aff><institution>Univesrsity of California, Santa Barbara</institution><addr-line><named-content content-type="city">Santa Barbara</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Acosta-Mendoza</surname><given-names>Santiago</given-names></name><role specific-use="author">Author</role><aff><institution>University of California, Santa Barbara</institution><addr-line><named-content content-type="city">Santa Barbara</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Wei</surname><given-names>Xue-Xin</given-names></name><role specific-use="author">Author</role><aff><institution>UT Austin</institution><addr-line><named-content content-type="city">Austin</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Goard</surname><given-names>Michael J</given-names></name><role specific-use="author">Author</role><aff><institution>University of California, Santa Barbara</institution><addr-line><named-content content-type="city">Santa Barbara</named-content></addr-line><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><p>We thank the reviewers for their time and thoughtful comments. We believe that the further analyses suggested have made the results clearer and more robust. Below, we briefly highlight the key points addressed in the revision and the new evidence supporting them. Then, we address each reviewer’s critiques point-by-point.</p><p>- Changes in variability with respect to time/experience</p><p>Both reviewers #1 and #3 asked whether the variability in grid properties observed was dependent on time or experience. This is an important point, given that such a dependence on time could lead to interesting hypotheses about the underlying dynamics of the grid code. However, in the new analyses we performed, we do not observe changes in grid variability within a session (Fig S5 of the revised manuscript), suggesting that the grid variability seen is constant within the timescale of the data set.</p><p>- The assumption of constant grid parameters in the literature</p><p>Reviewer #2 pointed out that it had been appreciated by experimentalists that grid properties are variable within a module. We agree that we may have overstated the universality of this assumption in the original manuscript, and we have toned down the language in the revision. However, we note that many previous theoretical studies assumed these properties to be constant, within a given module. We provide some examples below, and have added evidence of this assertion, with citations to the theoretical literature, to the revised manuscript .</p><p>- Additional sources of variability</p><p>Reviewer #3 pointed out additional sources that might explain the variability observed in the paper (beyond time and experience). These sources include: field width, border location, and the impact of conjunctive cells. We have run additional analyses and have found no significant impact on the observed variability from any of these factors. We believe that these are important controls, and have added them to the manuscript (Fig S4-S7 of the revised manuscript)</p><p>- Analysis of computational models</p><p>Reviewer #3 noted that our results could be strengthened by performing similar analyses on the output of computational models of grid cells. This is a good idea. We have now measured the variability of grid properties in a recent normative recurrent neural network (RNN) model that develops grid cells when trained to perform path integration (Sorscher et al., 2019). This model has been shown to develop signatures of a 2D toroidal attractor (Sorscher et al., 2023) and achieves a high accuracy on a simple path integration task. Interestingly, the units with the greatest grid scores also exhibit a range of grid spacings and grid orientations (Fig S8 of the revised manuscript). Furthermore, by decreasing the amount of sparsity (through decreasing the weight decay regularization), we found an increase in the variability of the grid properties. This analysis demonstrates a heretofore unknown similarity between the RNN models trained to perform path integration and recorded grid cells from MEC. It additionally provides a framework for computational analysis of the emergence of grid property variability.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1:</bold></p><p>(1) Is the variability in grid spacing and orientation that the authors found intrinsically organized or is it shaped by experience? Previous research has shown that grid representations can be modified through experience (e.g., Boccara et al., Science 2019). To understand the dynamics of the network, it would be important to investigate whether robust variability exists from the beginning of the task period (recording period) or whether variability emerges in an experience-dependent manner within a session.</p></disp-quote><p>This is an interesting question that was not addressed in the paper. To test this, we performed additional analysis to resolve whether the variability changes across a session.</p><p>Using a sliding window, we have measured changes in variability with respect to recording time (Fig S5A). To this end, we compute grid orientation and spacing over a time-window whose length is half the total length of the recording. From the population distribution of orientation and spacing values, we compute the standard deviation as a measure of variability. We repeat the same procedure, sliding the window forward until the variability for the second half of the recording is computed.</p><p>We applied this approach to recording ID R12 (the same as in Figs 2-4) given that this recording session was significantly longer than the rest (nearly two hours). Results are shown in Fig S5B-C. For both orientation and spacing, no changes of variability with respect to time can be observed. Similar results were found for other modules (see caption of Fig S5 for statistics).</p><p>We also note that the rats were already familiarized with the environment for 10-20 sessions prior to the recordings, so there may not be further learning during the period of the grid cell recordings. No changes in variability can be seen in Rat R across days (e.g., in Fig 5B R12 and R22 have similar distributions of variability). However, we note that it may be possible that there are changes in grid properties at time-scales greater than the recordings.</p><disp-quote content-type="editor-comment"><p>(2) It is important to consider the optimal variability size. The larger the variability, the better it is for decoding. On the other hand, as the authors state in the</p></disp-quote><p>Discussion, it is assumed that variability does not exist in the continuous attractor model. Although this study describes that it does not address how such variability fits the attractor theory, it would be better if more detailed ideas and suggestions were provided as to what direction the study could take to clarify the optimal size of variability.</p><p>We appreciate this suggestion and agree that more discussion is warranted on how our results can be reconciled with previously observed attractor dynamics. To explore this, we studied the recurrent neural network (RNN) model from Sorscher et al. (2019), which develops grid responses when trained on path integration. This network has previously been found to develop signatures of toroidal topology (Sorscher et al., 2023), yet we find its grid responses also contain heterogeneity in grid properties (Fig S8). By decreasing the strength of the weight decay regularization (which leads to denser connectivity in the recurrent layer), we find an increase in the grid property variability. Interestingly, decreasing the weight decay regularization has been previously found to lead to weaker grid responses and worse ability of the RNN to perform path integration on environments larger than it was trained on. This approach not only provides preliminary evidence to our claim that too much variability can lead to weaker continuous attractor structure, but also provides a modeling framework with which future work can explore this question in more detail. We have added discussion of this issue to the manuscript text (Discussion).</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2:</bold></p><p>(1) Even though theoreticians might have gotten the mistaken impression that grid cells are highly regular, this might be due to an overemphasis on regularity in a subset of papers. Most experimentalists working with grid cells know that many if not most grid cells show high variability of firing fields within a single neuron, though this analysis focuses on between neurons. In response to this comment, the reviewers should tone down and modify their statements about what are the current assumptions of the field (and if possible provide a short supplemental section with direct quotes from various papers that have made these assumptions).</p></disp-quote><p>We agree that some experimentalists are aware of variability in the recorded grid response patterns and that this work may not come as a complete surprise to them. We have toned down our language in the Introduction, changing “our results challenge a long-held assumption” to “our results challenge a frequently made assumption in the theoretical literature”. Additionally, we have added a caveat that “experimentalists have been aware” of the observed variability in grid properties.</p><p>We would like to emphasize that the lack of work carefully examining the robustness of this variability has prevented a firm understanding of whether this is an inherent property of grid cells or due to measurement noise. The impact of this can be seen in theoretical neuroscience work where a considerable number of articles (including recent publications) start with the assumption that all grid cells within a module have identical properties, with the exception of phase shift and noise. We have now cited a number of these papers in the Introduction, to provide specific references. To further illustrate the pervasiveness of this assumption being explicitly made in theoretical neuroscience, below we provide quotes from a few important papers:</p><p>“Cells with a common spatial period also share a common grid orientation; their responses differ only by spatial translations, or different preferred firing phases, with respect to their common response period” (Sreenivasan and Fiete, 2011)”</p><p>“Grid cells are organized into discrete modules; within each module, the spatial scale and orientation of the grid lattice are the same, but the lattice for different cells is shifted in space.” (Stemmler et al., 2015)”</p><p>“Recently, it was shown that grid cells are organized in discrete modules within which cells share the same orientation and periodicity but vary randomly in phase” (Wei et al., 2015)”</p><p>“...cells within one module have receptive fields that are translated versions of one another, and different modules have firing lattices of different scales and orientations” (Dorrell et al., 2023)”</p><p>In these works, this assumption is used to derive properties relating to the computational properties of grid cells (e.g., error correction, optimal scaling between grid spacings in different modules).</p><p>In addition, since grid cells are assumed to be identical in the computational neuroscience community, there has been little work on quantifying how much variability a given model produces. This makes it challenging to understand how consistent different models are with our observations. This is illustrated in our analysis of a recent recurrent neural network (RNN) model of grid cells (Fig S8), which does exhibit variability.</p><disp-quote content-type="editor-comment"><p>(2) The authors state that &quot;no characterization of the degree and robustness of variability in grid properties within individual modules has been performed.&quot; It is always dangerous to speak in absolute terms about what has been done in scientific studies. It is true that few studies have had the number of grid cells necessary to make comparisons within and between modules, but many studies have clearly shown the distribution of spacing in neuronal data (e.g. Hafting et al., 2005; Barry et al., 2007; Stensola et al., 2012; Hardcastle et al., 2015) so the variability has been visible in the data presentations. Also, most researchers in the field are well aware that highly consistent grid cells are much rarer than messy grid cells that have unevenly spaced firing fields. This doesn't hurt the importance of the paper, but they need to tone down their statements about the lack of previous awareness of variability (specific locations are noted in the specific comments).</p></disp-quote><p>We have toned down our language in the Introduction. However, we note that our point that no detailed analysis had been done on measuring the robustness of this variability stands. Thus, for the general community, it has not been clear whether this previously observed variability is noise or a real feature of the grid code.</p><disp-quote content-type="editor-comment"><p>(3) The methods section needs to have a separate subheading entitled: How grid cells were assigned to modules&quot; that clearly describes how the grid cells were assigned to a module i.e. was this done by Gardner et al., or done as part of this paper's post-processing?</p></disp-quote><p>We thank the reviewer for pointing out this missing information. We have added a new subsection in the Materials and Methods section, entitled “Grid module classification” to clarify how the grid cells are assigned to modules. In short, this was done by Gardner et al. (2022) using an unsupervised clustering approach that was viewed as enabling a less biased identification of modules. We did not perform any additional processing steps on module identity.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3:</bold></p><p>(1) One possible explanation of the dispersion in lambda (not in theta) could be variability in the typical width of the field. For a fixed spacing, wider fields might push the six fields around the center of the autocorrelogram toward the outside, depending on the details of how exactly the position of these fields is calculated. We recommend authors show that lambda does not correlate with field width, or at least that the variability explained by field width is smaller than the overall lambda variability.</p></disp-quote><p>We agree that this option had not been carefully ruled out by our previous analyses. To tackle this question, we compute the field width of a given cell using the value at the minima of its spatial autocorrelogram (Fig S4A-B). For all cells in recording ID R12, there is a non-significant negative linear correlation between grid field width and between-cell variability (Fig S4C) . The variability explained by the width of the field is 4% of the variability, as indicated by the R<sup>2</sup> value of the linear fit. Similar results were found for all other modules (see caption of Fig S4C for statistics). Therefore, we do not think that grid field width explains spacing variability.</p><disp-quote content-type="editor-comment"><p>(2) An alternative explanation could be related to what happens at the borders. The authors tackle this issue in Figure S2 but introduce a different way of measuring lambda based on three fields, which in our view is not optimal. We recommend showing that the dispersions in lambda and theta remain invariant as one removes the border-most part of the maps but estimating lambda through the autocorrelogram of the remaining part of the map. Of course, there is a limit to how much can be removed before measures of lambda and theta become very noisy.</p></disp-quote><p>We have performed additional analysis to explore the role of borders in grid property variability. To do so, we have followed the suggestion by the reviewer and have re-analyzed grid properties from the autocorrelogram when the border-most part of the maps are removed (Fig S6A-B). For all modules, we do not see any changes in variability (computed as the standard deviation of the population distribution) for either orientation or spacing. As predicted by the reviewer, after removing about 25% of the border-most part of the environment we start seeing changes in variability, as measures of theta and lambda become noisy and computed over a smaller spatial range. This result holds for all other modules (Fig S6C-D).</p><disp-quote content-type="editor-comment"><p>(3) A third possibility is slightly more tricky. Some works (for example Kropff et al, 2015) have shown that fields anticipate the rat position, so every time the rat traverses them they appear slightly displaced opposite to the direction of movement. The amount of displacement depends on the velocity. Maps that we construct out of a whole session should be deformed in a perfectly symmetric way if rats traverse fields in all directions and speeds. However, if the cell is conjunctive, we would expect a deformation mainly along the cell's preferred head direction. Since conjunctive cells have all possible preferred directions, and many grid cells are not conjunctive at all, this phenomenon could create variability in theta and lambda that is not a legitimate one but rather associated with the way we pool data to construct maps. To rule away this possibility, we recommend the authors study the variability in theta and lambda of conjunctive vs non-conjunctive grid cells. If the authors suspect that this phenomenon could explain part of their results, they should also take into account the findings of Gerlei and colleagues (2020) from the Nolan lab, that add complexity to this issue.</p></disp-quote><p>We appreciate the reviewer pointing out the possible role conjunctive cells may play. To investigate how conjunctive cells may affect the observed grid property variability, we have performed additional analyses taking into account if the grid cells included in the study are conjunctive. Comparing within- and between-cell variability of conjunctive vs. non-conjunctive cells in recording R12, we do not see any qualitative differences for either orientation or spacing (Fig S7A-B). When excluding conjunctive cells from the between-variability comparison, we do not see any significant difference compared to when these cells are included (Fig S7C-D). As such, it does not appear that conjunctive cells are the source of variability in the population.</p><p>We further note that the number of putative conjunctive cells varied across modules and recordings. For instance, in recording Q1 and Q2, Gardner et al. (2022) reported 3 (out of 97) and 1 (out of 66) conjunctive cells, respectively. Given that we see variability robustly across recordings (Fig 5), we do not believe that conjunctive cells can explain the presence of variability we observe.</p><disp-quote content-type="editor-comment"><p>(4) The results in Figure 6 are correct, but we are not convinced by the argument. The fact that grid cells fire in the same way in different parts of the environment and in different environments is what gives them their appeal as a platform for path integration since displacement can be calculated independently of the location of the animal. Losing this universal platform is, in our view, too much of a price to pay when the only gain is the possibility of decoding position from a single module (or non-adjacent modules) which, as the authors discuss, is probably never the case. Besides, similar disambiguation of positions within the environment would come for free by adding to the decoding algorithm spatial cells (non-hexagonal but spatially stable), which are ubiquitous across the entorhinal cortex. Thus, it seems to us that - at least along this line of argumentation - with variability the network is losing a lot but not gaining much.</p></disp-quote><p>We agree that losing the continuous attractor network (CAN) structure and the ability to path integrate would be a very large loss. However, we do not believe that the variability we observe necessarily destroys either the CAN or path integration. We argue this for two reasons. First, the data we analyzed [from Gardner et al. (2022)] is exactly the data set that was found to have toroidal topology and therefore viewed to be consistent with a major prediction of CANs. Thus, the amount of variability in grid properties does not rule out the underlying presence of a continuous attractor. Second, path integration may still be possible with grid cells that have variable properties. To illustrate this, we analyzed data from Sorscher et al. (2019) recurrent neural network model (RNN) that was trained explicitly on path integration, and found that the grid representations that emerged had variability in spacing and orientation (see point #6 below).</p><disp-quote content-type="editor-comment"><p>(5) In Figure 4 one axis has markedly lower variability. Is this always the same axis? Can the authors comment more on this finding?</p></disp-quote><p>We agree that in Fig 4 the first axis has lower variability. We believe that this is specific to the module R12 and does not reflect any differences in axis or bias in the methods used to compute the axis metrics. To test this, we have performed the same analyses for other modules, finding that other recordings do not exhibit the same bias. Results for the modules with the most cells are shown below (Author response image 1).</p><fig id="sa4fig1" position="float"><label>Author response image 1.</label><caption><title>Grid propertied along Axis 1 are not less variable for many recorded grid modules.</title><p>Same as Fig.4C-D, but for four other recorded modules. Note that the variability along each axis is similar.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-100652-sa4-fig1-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>(6) The paper would gain in depth if maps coming out of different computational models could be analyzed in the same way.</p></disp-quote><p>We agree with the reviewer that examining computational models using the same approach would strengthen our results and we appreciate the suggestion. To address this, we have analyzed the results from a previous normative model for grid cells [Sorscher et al., (2019)] that trained a recurrent neural network (RNN) model to perform path integration and found that units developed grid cell like responses. These models have been found to exhibit signatures of toroidal attractor dynamics [Sorscher et al. (2023)] and exhibit a diversity of responses beyond pure grid cells, making them a good starting point for understanding whether models of MEC may contain uncharacterized variability in grid properties.</p><p>We find that RNN units in these normative models exhibit similar amounts of variability in grid spacing and orientation as observed in the real grid cell recordings (Fig S8A-D). This provides additional evidence that this variability may be expected from a normative framework, and that the variability does not destroy the ability to path integrate (which the RNN is explicitly trained to perform).</p><p>The RNN model offers possibilities to assess what might cause this variability. While we leave a detailed investigation of this to future work, we varied the weight decay regularization hyper-parameter. This value controls how sparse the weights in the hidden recurrent layer are. Large weight decay regularization strength encourages sparser connectivity, while small weight decay regularization strength allows for denser connectivity. We find that increasing this penalty (and enforcing sparser connectivity) decreases the variability of grid properties (Fig S8E-F). This suggests that the observed variability in the Gardner et al. (2022) data set could be due to the fact that grid cells are synaptically connected to other, non-grid cells in MEC.</p><disp-quote content-type="editor-comment"><p>(7) Similarly, it would be very interesting to expand the study with some other data to understand if between-cell delta_theta and delta_lambda are invariant across environments. In a related matter, is there a correlation between delta_theta (delta_lambda) for the first vs for the second half of the session? We expect there should be a significant correlation, it would be nice to show it.</p></disp-quote><p>We agree this would be interesting to examine. For this analysis, it is essential to have a large number of grid cells, and we are not aware of other published data sets with comparable cell numbers using different environments.</p><p>Using a sliding window analysis, we have characterized changes in variability with respect to the recording time (Figure S5A). To do so, we compute grid orientation and spacing over a time-window whose length is half of the total length of the recording. From the population distribution of orientation and spacing values, we compute the standard deviation as a measure of between-cell variability. We repeat the same procedure, sliding the window forward until the variability for the second half of the recording is computed.</p><p>We applied this approach to recording ID R12 (the same as in Figs 2-4) given that this recording session was significantly longer than the rest (almost two hours). Results are shown in Fig S5 B-C. For both orientation and spacing, no systematic changes of variability with respect to time were observed. Similar results were found for other modules (see caption of Fig S5 for statistics).</p><p>We also note that the rats were already familiarized with the environment for 10-20 sessions prior to the recordings, so there may not be further learning during the period of the grid cell recordings. No changes in variability can be seen in Rat R across days (e.g., in Fig 5B R12 and R22 have similar distributions of variability). However, we note that it may be possible that there are changes in grid properties at time-scales greater than the recordings.</p></body></sub-article></article>