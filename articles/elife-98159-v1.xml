<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">98159</article-id><article-id pub-id-type="doi">10.7554/eLife.98159</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.98159.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Basal ganglia output (entopeduncular nucleus) coding of contextual kinematics and reward in the freely moving mouse</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Verma Rodriguez</surname><given-names>Anil K</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0008-5374-4958</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Ramírez-Jarquin</surname><given-names>Josue O</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Rossi-Pool</surname><given-names>Román</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Tecuapetla</surname><given-names>Fatuel</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9191-6553</contrib-id><email>fatuel@ifc.unam.mx</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund9"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01tmp8f25</institution-id><institution>Instituto de Fisiología Celular, Departamento de Neuropatología Molecular, Universidad Nacional Autónoma de México</institution></institution-wrap><addr-line><named-content content-type="city">Mexico city</named-content></addr-line><country>Mexico</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01tmp8f25</institution-id><institution>Instituto de Fisiología Celular, Departamento de Neurociencia Cognitiva, Universidad Nacional Autónoma de México</institution></institution-wrap><addr-line><named-content content-type="city">Mexico City</named-content></addr-line><country>Mexico</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Uchida</surname><given-names>Naoshige</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03vek6s52</institution-id><institution>Harvard University</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Wassum</surname><given-names>Kate M</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/046rm7j60</institution-id><institution>University of California, Los Angeles</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>26</day><month>02</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP98159</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-04-20"><day>20</day><month>04</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-03-27"><day>27</day><month>03</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.03.22.586140"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-07-08"><day>08</day><month>07</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.98159.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-01-07"><day>07</day><month>01</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.98159.2"/></event></pub-history><permissions><copyright-statement>© 2024, Verma Rodriguez et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Verma Rodriguez et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-98159-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-98159-figures-v1.pdf"/><abstract><p>The entopeduncular nucleus (EPN) is often termed as one of the output nuclei of the basal ganglia owing to their highly convergent anatomy. The rodent EPN has been implicated in reward and value coding whereas the primate analog internal Globus Pallidus has been found to be modulated by some movements and in some circumstances. In this study, we sought to understand how the rodent EPN might be coding kinematic, reward, and difficulty parameters, particularly during locomotion. Furthermore, we aimed to understand the level of movement representation: whole-body or specific body parts. To this end, mice were trained in a freely moving two-alternative forced choice task with two periods of displacement (return and go trajectories) and performed electrophysiological recordings together with video-based tracking. We found (1) robust reward coding but not difficulty. (2) Spatio-temporal variables better explain EPN activity during movement compared to kinematic variables, while both types of variables were more robustly represented in reward-related movement. (3) Reward-sensitive units encode kinematics similarly to reward-insensitive ones. (4) Population dynamics that best account for differences between these two periods of movement can be explained by allocentric references like distance to reward port. (5) The representation of paw and licks is not mutually exclusive, discarding a somatotopic muscle-level representation of movement in the EPN. Our data suggest that EPN activity represents movements and reward in a complex way: highly multiplexed, influenced by the objective of the displacement, where trajectories that lead to reward better represent spatial and kinematic variables. Interestingly, there are intertwining representations of whole-body movement kinematics with a single paw and licking variables. Further, reward-sensitive units encode kinematics similarly to reward-insensitive ones, challenging the notion of distinct pathways for reward and movement processing.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>basal ganglia</kwd><kwd>entopeduncular nucleus</kwd><kwd>coding</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution>Consejo Nacional de Humanidades, Ciencias y Tecnologías</institution></institution-wrap></funding-source><award-id>808903</award-id><principal-award-recipient><name><surname>Verma Rodriguez</surname><given-names>Anil K</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution>Consejo Nacional de Humanidades, Ciencias y Tecnologías</institution></institution-wrap></funding-source><award-id>CF-2023-I-305</award-id><principal-award-recipient><name><surname>Tecuapetla</surname><given-names>Fatuel</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100006087</institution-id><institution>Dirección General de Asuntos del Personal Académico, Universidad Nacional Autónoma de México</institution></institution-wrap></funding-source><award-id>IN226517</award-id><principal-award-recipient><name><surname>Tecuapetla</surname><given-names>Fatuel</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100012047</institution-id><institution>Fundación Marcos Moshinsky</institution></institution-wrap></funding-source><award-id>Catedra 2019</award-id><principal-award-recipient><name><surname>Tecuapetla</surname><given-names>Fatuel</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution>Consejo Nacional de Humanidades, Ciencias y Tecnologías</institution></institution-wrap></funding-source><award-id>2022</award-id><principal-award-recipient><name><surname>Tecuapetla</surname><given-names>Fatuel</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100006087</institution-id><institution>Dirección General de Asuntos del Personal Académico, Universidad Nacional Autónoma de México</institution></institution-wrap></funding-source><award-id>IN203420</award-id><principal-award-recipient><name><surname>Tecuapetla</surname><given-names>Fatuel</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100006087</institution-id><institution>Dirección General de Asuntos del Personal Académico, Universidad Nacional Autónoma de México</institution></institution-wrap></funding-source><award-id>IN203123</award-id><principal-award-recipient><name><surname>Tecuapetla</surname><given-names>Fatuel</given-names></name></principal-award-recipient></award-group><award-group id="fund8"><funding-source><institution-wrap><institution>Consejo Nacional de Humanidades, Ciencias y Tecnologías</institution></institution-wrap></funding-source><award-id>2019/154039</award-id><principal-award-recipient><name><surname>Tecuapetla</surname><given-names>Fatuel</given-names></name></principal-award-recipient></award-group><award-group id="fund9"><funding-source><institution-wrap><institution>Consejo Nacional de Humanidades, Ciencias y Tecnologías</institution></institution-wrap></funding-source><award-id>220412</award-id><principal-award-recipient><name><surname>Tecuapetla</surname><given-names>Fatuel</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>The entopeduncular nucleus multiplexes motor and reward signals, with spatio-temporal coding more prominent than kinematic, both shaped by movement goals, challenging prevailing theories of basal ganglia function.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The EPN is often termed as the output of the basal ganglia. The basal ganglia are a group of subcortial nuclei with highly converging anatomy that have been associated with motor and non-motor functions. Whereas the striatum receives inputs from many diverse brain regions (<xref ref-type="bibr" rid="bib8">Hintiryan et al., 2016</xref>; <xref ref-type="bibr" rid="bib10">Hunnicutt et al., 2016</xref>) most of its projections end in the internal Globus Pallidus (GPi, primate analog of EPN) or substantia nigra pars reticulata (SNr, often termed as the output nuclei) through the direct and indirect pathways. This is accompanied by a sharp reduction in the number of neurons: the striatum has 2–3 orders of magnitude more neurons. This highly convergent anatomy suggests information synthesis/convergence.</p><p>Previous studies focusing on the non-motor coding of the internal Globus Pallidus, have found that there is coding of reward (<xref ref-type="bibr" rid="bib9">Hong and Hikosaka, 2008</xref>). Rodent studies have corroborated this finding and suggested the existence of value coding that serves to evaluate actions (<xref ref-type="bibr" rid="bib27">Stephenson-Jones et al., 2016</xref>).</p><p>There is a particular interest in understanding the role of the basal ganglia on movement production since several diseases with motor disturbances have been linked to basal ganglia malfunction. Several studies have found a relationship between the GPi activity and limb movements of the primate. However, studies have found inconsistencies in the coding of movement depending on movement type (ramping vs. stepped, self-paced vs step tracking, <xref ref-type="bibr" rid="bib6">Georgopoulos et al., 1983</xref>) or between identical movements performed under different cognitive states (cued vs memory-dependent <xref ref-type="bibr" rid="bib29">Turner and Anderson, 2005</xref>). Further, some studies agree that self-paced movements are represented in a weaker manner (<xref ref-type="bibr" rid="bib18">Mink and Thach, 1991</xref>; <xref ref-type="bibr" rid="bib29">Turner and Anderson, 2005</xref>). Overall, findings show that GPi units are selectively engaged in some types of movement, but it is so far unclear what cognitive contingency is most engaging.</p><p>On the other hand, current theories of the overall function of the basal ganglia, like the ‘rate theory’ (<xref ref-type="bibr" rid="bib1">Albin et al., 1989</xref>) or the ‘dynamic activity model’ (<xref ref-type="bibr" rid="bib23">Nambu et al., 2023</xref>), posit that the firing rate of the output nuclei is inversely related to movement facilitation.</p><p>In this study, we sought to examine how the information regarding kinematics, particularly during locomotion, was represented in the entopeduncular nucleus of freely moving mice. Given that previous studies have highlighted the importance of reward-related activity, we further sought to understand whether reward-sensitive units would be insensitive to kinematic coding. Finally, we investigated whether the EPN units were modulated by individual movements (limb or licking) as opposed to whole-body movements.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>Given that our main interest lies in how the EPN neuronal activity encodes kinematic and reward-related variables we set up a task and recorded activity in freely moving mice. We first describe the population dynamics that underlie reward, followed by asking how movement is encoded by the units, contrasting both periods of movement in the designed task (Return and Go trajectories). Next, we focus on extracting the population dynamics that make Return and Go trajectories different. Finally, we describe how EPN units are modulated by individual movements by analyzing gait and licking behavior.</p><sec id="s2-1"><title>Mice can perform psychophysical responses on a self-paced two-alternative forced choice task based on frequency-modulated sweeps</title><p>The main goal of this study was to establish the relationships between kinematic variables of mice, particularly during locomotion, and the activity of the entopeduncular nucleus. However, given that previous studies have ascertained that reward is an important variable coded in this nucleus, we sought to evaluate how reward might be related to kinematic coding.</p><p>To this end, we devised a task in which animals were required to displace towards different corners of a triangular arena (side = 35 cm, <xref ref-type="fig" rid="fig1">Figure 1A–B</xref>). In a trial, animals were required to move to the Waiting Corner and wait for ~1 s (0.8–1.5 s). After waiting, an auditory stimulus would play, which would indicate in which other corner a water reward would be available (a two-alternative forced choice). If the animal arrived at the appropriate lick port, it was termed a correct response, and a water droplet (3 μl) was then released. Incorrect responses were signaled by a 10–20 s timeout during which ambient lights were dimmed. Animals would then start another trial (by moving to the Waiting Corner) in a self-paced manner. By performing tracking DeepLabCut, (<xref ref-type="bibr" rid="bib16">Mathis et al., 2018</xref>) of video recordings from a bottom-up view (see <xref ref-type="video" rid="video1">Video 1</xref>), we could measure several variables for each trial (distance to different corners, angular velocity, <xref ref-type="fig" rid="fig1">Figure 1C</xref>) which allowed to establish different events of the task (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). Particularly, we could establish two distinct periods of movement/displacement: Return trajectories (to reach the wait corner) and Go trajectories (to reach a reward corner).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Mice learn to perform a two-alternative forced choice task in a freely moving triangular arena.</title><p>(<bold>A</bold>) Left: Schematic of triangular arena. Right: stimuli were frequency-modulated sweeps. (<bold>B</bold>) Time schematic of task events. The two periods of movement are highlighted. (<bold>C</bold>) Video tracking extracted variables of a single trial. Note that events correspond to B. (<bold>D</bold>) Left: Psychophysical performance of an example session of an animal. Middle: Thin traces are five example days pre (orange) and post (black) electrode implant for an example animal. Thicker traces are averages of pre and post-performance. Right: Thin traces are individual animal averages (n=6) of the 32 recording sessions included in this study. Thicker trace is group average. (<bold>E</bold>) Average reaction time as a function of stimulus deltaFreq. Black line is the linear fit. (<bold>F</bold>) Probability of correct response as a function of reaction time. Traces are grouped per absolute deltaFreq (left and right responses are grouped). Probability of correct responses is computed in reaction time bins of 75 ms, binned reaction time from n=38049 trials, from n=6 animals. (<bold>G</bold>) Instantaneous angular speed (radial axis) of turning per stimulus condition. 90° represents the animals’ position during waiting. (<bold>H</bold>) Mean angular speed per stimulus identity for correct (colored circles) and incorrect (gray circles) trials. Trendlines were drawn following a simple linear regression. Legend shows correlation coefficient and statistical significance, binned angular velocity from n=38049 trials, from n=6 animals. (<bold>I</bold>) Instantaneous displacement speed across the length of the trajectory for left and right stimuli. (<bold>J</bold>) Mean average speed per stimulus for correct (colored circles) and incorrect (gray circles) trials, binned average body speed from n=38049 trials, from n=6 animals. Trendlines were drawn following a simple linear regression. Legend shows correlation coefficient and statistical significance.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-98159-fig1-v1.tif"/></fig><media mimetype="video" mime-subtype="mp4" xlink:href="elife-98159-video1.mp4" id="video1"><label>Video 1.</label><caption><title>Example trials of the task.</title><p>Freely moving two-alternative forced choice task with two periods of displacement. Animals were required to displace towards different corners of a triangular arena. In a trial, animals were required to move to the Waiting Corner and wait for ~1 s (0.8–1.5 s). After waiting, an auditory stimulus would play, which would indicate in which other corner a water reward would be available. If the animal arrived at the appropriate lick port, it was termed a correct response, and a water droplet was then released. Incorrect responses were signaled by a 10–20 s timeout during which ambient lights were dimmed. Animals would then start another trial (by moving to the Waiting Corner) in a self-paced manner.</p></caption></media><p>Auditory stimuli consisted of 0.5 s frequency-modulated sweeps; upward and downward frequency modulation indicated a right and left choice, respectively (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, right). By varying the rate at which the frequency was modulated we attempted to modulate the certainty with which animals decided. This was evidenced by a psychometric curve fitted to the response probability as a function of stimulus deltaFreq (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). Note that the central stimulus was a pure tone that had no information of side. This behavior was reproducible for different sessions before and after electrode implant (<xref ref-type="fig" rid="fig1">Figure 1D</xref>, middle) and in several animals included in this study (n=6; <xref ref-type="fig" rid="fig1">Figure 1D</xref>, right).</p><p>We then quantified how the different stimuli influenced response time and kinematic parameters. Note that stimulus pairs with higher deltaFreq (+/-0.8) were easier than those with less (+/-0.4) or no deltaFreq. The +/-0.2 stimulus pair was dropped from some sessions to increase trials per condition and will not be further analyzed. We quantified Response time as the time from stimulus onset to the onset of turning (<xref ref-type="fig" rid="fig1">Figure 1B–C</xref>), which we defined as the moment when animals had committed to a motor action (either left or right turn). We found a relationship between response time and the stimulus difficulty (correlation coefficient <italic>r</italic>=0.89, p&lt;0.01 permutation test; <xref ref-type="fig" rid="fig1">Figure 1E</xref>). To ascertain whether the evolving deltaFreq of the stimuli had an impact on performance, we calculated the probability of a correct response as a function of response time by binning trials according to response time (bin = 75 ms) and by stimulus difficulty (deltaFreq). For the central stimulus, no amount of response time increases the probability of correct response since the stimulus contains no information on the correct side. For stimuli pairs with varying difficulty, there is a graded increase in the probability of a correct response (<xref ref-type="fig" rid="fig1">Figure 1F</xref>).</p><p>Next, we sought to ask whether the difficulty of the stimuli and thus uncertainty in the decision could modulate the kinematic response of the animals. We hypothesized that responses to easier stimuli would result in faster movement. We calculated the instantaneous angular velocity across the 150° of turning that animals had to perform (<xref ref-type="fig" rid="fig1">Figure 1G</xref>), showing indeed a subtle gradation according to the difficulty of the stimuli. We found a significant correlation between average angular speed and the deltaFreq of stimuli for correct trials but not so for incorrect trials (<xref ref-type="fig" rid="fig1">Figure 1H</xref>, black and gray lines, respectively). We further calculated the instantaneous speed across the trajectory that animals had to complete (Go trajectory, <xref ref-type="fig" rid="fig1">Figure 1I</xref>). Animals performed easy trials faster than more difficult ones, but no significant correlation between stimulus difficulty and speed was found (<xref ref-type="fig" rid="fig1">Figure 1J</xref>).</p><p>From the performance of animals in this task we conclude that animals can perform a psychophysical task based on frequency-modulated sweeps, with easier stimuli resulting in greater hits than more difficult stimuli. The difficulty of the stimuli had an impact on the reaction time, and increasing the sampling time for stimuli with information of correct response increased the probability of performing a correct choice. Furthermore, difficulty had a moderate impact on the way animals turned, but not on the whole period of locomotion.</p></sec><sec id="s2-2"><title>EPN recordings and examples</title><p>After a consistent performance across at least 2 wk (<xref ref-type="fig" rid="fig1">Figure 1D</xref>) animals were implanted with a movable microwire bundle to record the activity of EPN neurons. The microwires were advanced in 50 micrometer steps for 10 steps in total. We inferred the recording position via postmortem histological analysis of the individual microwire tracks and included for further analysis only the ones that were recorded inside of EPN (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Previous reports indicated that the two main cell types in the EPN characterized by parvalbumin + and somatostatin + markers, (<xref ref-type="bibr" rid="bib27">Stephenson-Jones et al., 2016</xref>; <xref ref-type="bibr" rid="bib30">Wallace et al., 2017</xref>) exhibit differences in the coefficient of variation and the duration of the action potentials. To this end, we computed these characteristics for the units recorded in this study (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). However, we could not separate the population into two distinct clusters.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Electrophysiological recordings were obtained from the entopeduncular nucleus (EPN).</title><p>(<bold>A</bold>) Microwire bundles were implanted onto the entopeduncular nucleus. Right pane shows a schematic of electrode placement (n=6). (<bold>B</bold>) Left: Photomicrograph of electrode cannula track. Right: Close-up of individual microwire electrode tracks. Red arrow heads point to microwire tips. (<bold>C</bold>) Peak to valley duration of plotted against inter-spike interval coefficient of variation for recorded spikes. Insets: average waveform for four example units. (<bold>D</bold>) Example recorded unit aligned to events identified in <xref ref-type="fig" rid="fig1">Figure 1B</xref>: return, wait, turn (0°, 75°, 150°), evaluation, averaged according to stimulus presented. First row is rescaled average for correct trials. Second row is average of incorrect trials. Third row is false alarm trials: trials where animals did not wait long enough for the stimulus to appear but that performed the entire movement sequence either to the right or left lick ports. (<bold>E</bold>) Same as D for another example unit. (<bold>F</bold>) Population response for correct left and right responses. (<bold>G</bold>) Upper: Average z-score segregated by left and right, for correct, incorrect, and false alarm trials. Lower: Average z-score per stimulus for correct trials. (<bold>H</bold>) Average speed (upper) and angular velocity (lower) for trials segregated as in the upper pane of G. (<bold>I</bold>) Mean population activity per epoch segregated by movement, turning, and Reward. Wilcoxon signed-rank test used, n = 118 units per condition.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-98159-fig2-v1.tif"/></fig><p><xref ref-type="fig" rid="fig2">Figure 2D–E</xref> shows two examples of the activity recorded aligned to the task-relevant events identified in <xref ref-type="fig" rid="fig1">Figure 1B</xref>: return, wait, turn (0°, 75°, 150°), outcome. Note that we sought to isolate the turn during the Go trajectory by identifying the start (0°), middle (75°), and end (150°) of the turn; the top row shows the raster plots color-coded by the stimulus for all correct trials. Despite the performance of animals being highly stereotyped, there are slight differences due to it being freely moving. Thus, in the three bottom rows, we show the rescaled activity presented in the raster plots for the correct trials, and additionally for the incorrect trials and false alarm trials, respectively. The false alarm trials were trials in which animals did not wait for the auditory stimulus to be presented and performed the entire motor sequence identical to real trials (useful since they are gated by an internal signal without external stimuli with identical motor output).</p><p>The unit in <xref ref-type="fig" rid="fig2">Figure 2D</xref> shows a decreasing firing rate as time/distance from the goal of each of the Return (reach the wait corner) and Go trajectories (reach the reward corner). Further, this unit shows differential activity during left and right turns that follows the direction of turning in correct, incorrect, and false alarm trials. On the other hand, the unit in <xref ref-type="fig" rid="fig2">Figure 2E</xref> exhibited a marked difference in the time/distance varying activity during Return and Go trajectories (with no change and ramping activity, respectively). Further, this second unit exhibits a stark difference in the evaluation period between rewarded and unrewarded trials.</p><p>Heatmaps in <xref ref-type="fig" rid="fig2">Figure 2F</xref> show responses for all recorded units (118 units from 6 animals) averaged for all correct right (<xref ref-type="fig" rid="fig2">Figure 2F</xref>, upper) and left (<xref ref-type="fig" rid="fig2">Figure 2F</xref>, lower) trials, sorted by peak activity in rightward trials. Even if neurons are organized employing only the rightward trials, the population activity displays akin responses. <xref ref-type="fig" rid="fig2">Figure 2G</xref> upper panel shows averaged z-score EPN activity sorted by turn side and outcome (correct, incorrect, and false alarms), with average kinematic measurements of speed and angular velocity presented in <xref ref-type="fig" rid="fig2">Figure 2H</xref>. These population averages show that there is population coding associated to turn and reward. Sorting hit trials based on stimulus identity (<xref ref-type="fig" rid="fig2">Figure 2G</xref>, lower) preserves side representation; however, differences across stimuli are remarkably low.</p><p>We sought to assess how average population activity could be representing movement, turning, and reward. Thus, we obtained the z-score population average during both periods of movement (Return and Go) and the wait period (<xref ref-type="fig" rid="fig2">Figure 2I</xref>). As well, we obtained the average activity during turns ipsilateral and contralateral to the recording site (right hemisphere), and for correct and incorrect trials during the evaluation period. Out of all conditions, reward (evaluation of correct trials) exhibits the highest population activity (p&lt;0.01, Wilcoxon test); correct trials also exhibit a higher activity compared to unrewarded trials despite similar speed (<xref ref-type="fig" rid="fig2">Figure 2H</xref>). Ipsilateral turns exhibit a higher activity compared to contralateral turns and the wait period. Finally, despite a tendency to lower activity during both movement periods (<xref ref-type="fig" rid="fig2">Figure 2G–H</xref>), the data does not show a statistically significant difference on average activity during the wait period compared to the Return and Go periods.</p></sec><sec id="s2-3"><title>Population analysis of the EPN reveals its coding of reward, left and right but not difficulty</title><p>As a first objective, we sought to analyze coding of stimulus difficulty and reward, given previous reports that GPi/EPN neurons code for the value of expected positive and negative outcomes (<xref ref-type="bibr" rid="bib27">Stephenson-Jones et al., 2016</xref>) as well as the spatial position of the expected positive and negative outcomes (<xref ref-type="bibr" rid="bib9">Hong and Hikosaka, 2008</xref>). We began by trying to understand how these variables were represented in the population activity. For population level analyses throughout the study, we pooled recorded units from all animals to construct a pseudo-simultaneous population. We calculated the instantaneous variance associated with these two variables, as well as to left and right trials (<xref ref-type="fig" rid="fig3">Figure 3A</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Stimulus, difficulty, reward, and temporal population dynamics during Go trajectories.</title><p>(<bold>A</bold>) Instantaneous variance associated with trials segregated by left-right, correct/incorrect, and stimuli identity. (<bold>B</bold>) Principal Components and demixed Principal Components sorted by explained variance. Note that the difficulty demixed Principal Component Analysis (dPCA) does not appear within the 10 first components. Statistically significant PCs (n=5) were signaled by a bigger dot. (<bold>C–G</bold>) First five dPCs sorted by variance are shown: Temporal (condition-independent), reward, and side. Note that for traces in C-E t s (n = 16). Weights for each individual dPCs are shown to the right. Lettered circles on top are individual units’ weights shown on <bold>G</bold>. (<bold>H</bold>) Population self-similarity across time. Cosine similarity was calculated for population vectors on the de-meaned (temporal dynamics removed) population activity (see Methods). (<bold>I</bold>) Population vector similarity across time for two time points: t=0.2 s and t=1.8, which correspond to the moments of peak side and reward variance, respectively.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-98159-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Example units.</title><p>(<bold>a–h</bold>) Example units are shown corresponding to lettered circles on weight plots in <xref ref-type="fig" rid="fig3">Figure 3</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-98159-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Stimulus presence, irrespective of identity, and angular velocity best explain entopeduncular nucleus (EPN) activity around turning epoch.</title><p>(<bold>A</bold>) Example unit aligned to stimulus (left) and turn (right), segregated by left and right, correct, incorrect, and false alarm trials. First row is raster plots. Middle row is average firing rate. Lower row is average angular velocity. Note that left column does not contain false alarm trials since there is no stimulus to align to. (<bold>B</bold>) Similar to A for another unit. (<bold>C</bold>) Models fit to data. Four hypotheses were tested. First row is the presence of stimulus (without identity). Second row is difficulty (absolute value of deltaFreq). Third row is stimulus interpretation (incorrectly performed trials show opposite interpretation to the correctly performed counterparts). Fourth row shows angular velocity. (<bold>D</bold>) deltaR2 calculated for each of the models (see Methods and main text). Statistical differences are shown with red lines, p&lt;0.05, Wilcoxon signed-rank test, n = 118 units per condition.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-98159-fig3-figsupp2-v1.tif"/></fig></fig-group><p>In agreement with <xref ref-type="fig" rid="fig2">Figure 2G</xref>, there is a high variance associated with correct and incorrect trials during the evaluation period of the task. Further, left/right variance is increased during the turning period. In concordance with <xref ref-type="fig" rid="fig2">Figure 2G</xref>, the variance associated with difficulty (stimuli) is remarkably low.</p><p>Next, to understand the population dynamics associated to these task parameters we performed demixed Principal Component Analysis (<xref ref-type="bibr" rid="bib12">Kobak et al., 2016a</xref>). This allowed us to generate a low-dimensional space that captures variance related to specific task parameters: condition-independent temporal dynamics, correct and incorrect trials, stimulus difficulty, and side (left and right) of turning. We hypothesized that condition-independent temporal dynamics would include kinematic relationships while marginalizations in correct/incorrect would include reward signals; the left/right marginalization would show angular velocity-related activity, and the difficulty marginalization (that is, the segregation related to the deltaFreq of the auditory stimuli) would show a gradation related to the action value.</p><p>After performing dPCA and sorting the extracted components by the explained total variance (ETV), we find that the first three are condition-independent components (temporal). Further, only five PCs are statistically significant (see Methods). The most prominent dynamic, temporal dPC1 which explains 19.2% of total variance, separates the outcome period from the wait-and-go periods akin to a step function. The right panel in <xref ref-type="fig" rid="fig3">Figure 3C</xref> shows the weights of individual units onto this dynamic. We show individual example units in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> which correspond to the letter markings in the weight panels (<xref ref-type="fig" rid="fig3">Figure 3C–G</xref>, right panels). The second temporal dPC (16.1% ETV) exhibits ramping activity during the Go moving period (<xref ref-type="fig" rid="fig3">Figure 3D</xref>), which could be encoding time or the distance to goal. The third temporal dPC projection exhibits a triphasic dynamic during the moving period, potentially correlating with the speed of the animal’s trajectory (<xref ref-type="fig" rid="fig3">Figure 3E</xref>).</p><p>The fourth and fifth dPCs correspond to correct/incorrect and side, respectively. As expected, the correct/incorrect dPC separates correct from incorrect trials during the evaluation period (<xref ref-type="fig" rid="fig3">Figure 3F</xref>). Further, the side dPC is maximally different during the turning period (<xref ref-type="fig" rid="fig3">Figure 3G</xref>). Note that the weights of these axes are positive and negative centered around zero. This means that units encoding reward can code a rewarded trial as an increase in activity or as a decrease in activity and vice versa (example units are shown in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1g and h</xref>). Similarly, leftwards turns can be encoded as a decrease in activity or an increase in activity (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1a and b</xref>).</p><p>Interestingly, the marginalization of difficulty (stimuli) did not yield a significant dPC. This, coupled with the comparatively low difficulty-associated variance (<xref ref-type="fig" rid="fig3">Figure 3A</xref>) suggests that difficulty coding is not well represented in this dataset. Still, by comparing correct and incorrect trials (with stimulus) vs false alarm trials (without stimulus), some units show stimulus-associated activity (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2A and B</xref>). We looked to further assess whether stimulus-related activity could represent difficulty. We asked whether activity around stimulus and turning could be representing the presence of stimulus, the difficulty of the stimulus, what the animal interpreted from the stimulus (correctly or incorrectly turning to either right or left), or simply the angular velocity (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2C</xref>). Given their overlap, we calculated the delta R2 of each of these possibilities, which measures how much the goodness of fit improves when considering each variable versus only the others (see Methods). This analysis shows that including information about the difficulty or the interpretation are worse at explaining activity than the sole presence of stimuli (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2D</xref>). Further, the variable that best describes the activity in this period is angular velocity.</p><p>To assess how side and reward coding might correlate/covary with each other, we computed the population self-similarity across time (<xref ref-type="fig" rid="fig3">Figure 3H</xref>). This self-similarity was computed from the demeaned responses, which eliminates condition-independent (temporal) coding. We found that the evaluation period is well separated from the Go period and the interaction between them is very low. We assessed the similarity of the population vector at the time points of greatest side and reward variance (t=0.2 s and t=1.8 s, respectively; see <xref ref-type="fig" rid="fig3">Figure 3A</xref>) against the rest of the time bins (<xref ref-type="fig" rid="fig3">Figure 3I</xref>). This shows that turning and reward coding are largely uncoupled.</p><p>The presented analyses in <xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref> show that at the population level the EPN recorded activity in freely moving mice encodes reward and turning side, both of which are encoded positively and negatively. Minimal contribution of difficulty was detected.</p></sec><sec id="s2-4"><title>Contextual motor coding across different periods</title><p>As a second objective, we analyzed the relationships between the activity of the recorded units and kinematic variables. Since one of the most prominent population dynamics describes a linear relationship between time/space and population rate (<xref ref-type="fig" rid="fig3">Figure 3D</xref>), we sought to study spatio-temporal variables as well. By design, the task has two distinct epochs of displacement: Return trajectories (to the waiting corner) and Go trajectories (to either of the reward corners). We hypothesized that purely ‘motor coding’ would be invariant to these two contexts.</p><p><xref ref-type="fig" rid="fig4">Figure 4A–C</xref> shows three example units. Each unit has two raster plots corresponding to Return and Go trajectories, aligned to movement start and sorted by movement duration. We grouped and averaged their activity into six bins for visualization and presented the average firing rate and average speed. All units presented have significant correlations with at least three of the variables presented, which suggests that a multiple regression model is better suited for the analysis.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Kinematic and spatio-temporal coding during Return and Go trajectories.</title><p>(<bold>A–C</bold>) shows three example units. Raster plots show activity for return (left) and Go (right) trajectories sorted by trajectory duration (black circle). They were then grouped into six traces, and average firing rate is presented below. Also, the average speed of the animals locomotion is presented below. Simple linear regression for four different variables presented on the right panels, for Return (orange) and Go (green) trajectories separately. (<bold>D</bold>) Average 10-fold cross-validated R2 for multiple regression models fit on data from the entire trial duration (return, wait, go, and evaluation periods) for kinematic, spatio-temporal and reward-related variables, as well as full model fit on all these variables (n = 118 units). Red line represents a statistically significant difference (p&lt;0.01, Wilcoxon signed-rank test). (<bold>E</bold>) Average 10-fold cross-validated R2 for models for multiple regression models fit separately on Return (orange) and Go (green) trajectory data. Red line represents a statistically significant difference (p&lt;0.01, Wilcoxon signed-rank test). (<bold>F</bold>) Mean cvR2 for single variable models. Shading corresponds to kinematic (gray) and spatio-temporal (pink) variables. Reward-related variables are unshaded. Models were fit with Return (orange), Go (green) and entire trial duration (gray) data, n = 118 units. (<bold>G</bold>) Trained models for Return and Go periods in E were tested using Return and Go data. Individual models for kinematic, spatio-temporal, and a mixed kinematic and spatio-temporal model were tested. Note all models tested on data not used for training were significantly lower than when using training data (p&lt;0.01, Wilcoxon signed-rank test), n = 118 units. (<bold>H</bold>) Upper: Partial correlation coefficient (<bold>r</bold>) was calculated for the distance to goal variable by fitting residuals of model on kinematic variables (excluding spatio-temporal variables). This was done separately for Return (x-axis) and Go (y-axis) data. Dashed line corresponds to the identity line (x=y). Lower: Pie chart summarizing data above. Brown: Units with statistically significant correlations with the distance to goal variable in Go and Return periods. Green: units with statistically significant correlation only during the Go period. Orange: units with statistically significant correlation only during the Return period. Outer pie summarizes the sign of the correlations where gray and salmon represent negative and positive correlations, respectively, in both Return and Go periods. Black represents units that switch signs in Return and Go periods. (<bold>I</bold>) Upper: Partial correlation coefficient of residuals of a model with all spatio-temporal and kinematic variables except angular velocity, separately for Return and Go trajectories. Lower: similar to H. (<bold>J</bold>) Upper: Partial correlation coefficient of residuals of a model with all spatio-temporal and kinematic variables except body speed, separately for Return and Go trajectories. Lower: similar to H. (<bold>K</bold>) Venn diagrams of percentage of total units with a significant partial correlation coefficient for the variables distance to goal, angular velocity and body speed for Return and Go trajectories. (<bold>L</bold>) Left: Mean zScore activity of units segregated according to activity during reward. Top panel shows mean of units unresponsive to reward. Middle and lower panel shows average activity of units with statistically significant difference between rewarded and unrewarded trials in a 250ms window after head entry into the lick port. Middle panel corresponds to reward-positive units that showed an increase in firing rate with rewarded trials (auROC &gt;0.5, p&lt;0.001 permutation test) while the lower panel corresponds to reward-negative units that showed a decrease in activity with rewarded trials (auROC &lt;0.5, p&lt;0.001 permutation test). Right: Dimensionality reduction performed on the regression coefficients on a model fitted Return and Go data using kinematic and spatio-temporal variables. Red dots represent reward-positive units (rewarded trials with higher firing rate that unrewarded ones) and blue ones represent reward-negative units (rewarded trials with lower firing rate). (<bold>M</bold>) Mean cross-validated R2 of models fit on kinematic, spatio-temporal and both types of variables, segregated by reward coding of units (segregated as described in L). Red lines indicate statistically significant difference (Mann-Whitney U test, p&lt;0.01), reward positive n=52 units, reward negative n = 21 units, reward insensitive n = 45 units. (<bold>N</bold>) Mean cross-validated R2 of kinematic, spatio-temporal, and mixed models. Data was segregated according to trial type: correct, incorrect, and false alarm, n=118 units per condition. Panels A-C inserts, error bars are shown in place of individual points (200ms bins), however for regressions the individual datapoints were used.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-98159-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Variables used to fit models.</title><p>(<bold>A</bold>) Single trial variables used to fit models in <xref ref-type="fig" rid="fig4">Figure 4</xref>. (<bold>B</bold>) Correlation coefficient calculated between pairs of variables.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-98159-fig4-figsupp1-v1.tif"/></fig></fig-group><p>For the construction of the multiple regression models, we divided variables into kinematic (measured from the body of the animal) and spatio-temporal (measured in relation with the arena) and reward-related (<xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). Given the possibility of collinearity between measured variables (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>), we employed LASSO regression which introduces a regularization term that shrinks the coefficients and penalizes colinear variables, acting as a feature selection (see Methods). To assess how well the model explained the neural activity we calculated a 10-fold cross-validated R2 for each unit, which ensures that no variance is predicted by chance.</p><p>The group of kinematic variables is worse at explaining single-unit activity when compared to spatio-temporal and reward-related variables (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). However, a model incorporating all three groups of variables outperforms any specific category.</p><p>An important goal of this study was to compare the encoding kinematic and spatio-temporal variables between the Return versus the Go trajectories (two periods of similar movement but different sub-goals).</p><p>By fitting models separately for the Return and Go trajectories, we found that the average cvR2 for models fitted with Go trajectory data is higher for kinematic, and spatio-temporal variables, as well as for a mixed model (<italic>P</italic>&lt;0.001, Wilcoxon test; orange and green bars in <xref ref-type="fig" rid="fig4">Figure 4E</xref>). This implies both kinematic and spatio-temporal variables are best represented during the trajectories that animals performed towards the reward ports (Go trajectories). This is probably partly due to units that are more responsive during the Go trajectory (<xref ref-type="fig" rid="fig2">Figure 2E</xref>).</p><p>Next, we sought to investigate which variables were most relevant for the models’ success. To this end, we constructed single-variable models for each unit and plot the mean cvR2 for each of the measured variables (<xref ref-type="fig" rid="fig4">Figure 4F</xref>). This was also done separately for return (orange) and go (green) trajectories, as well as for the entire duration model (gray). Amongst the kinematic variables the best variable for explaining the neural data variance was the body speed, followed by the head speed and the angular velocity (<xref ref-type="fig" rid="fig4">Figure 4F</xref>). We found that relationships with tested variables are not generalizable between both contexts. Model performance is reduced drastically (<italic>P</italic>&lt;0.001, Wilcoxon test) when switching the test data to that of the other context (<xref ref-type="fig" rid="fig4">Figure 4G</xref>). This is unlikely to be due to over-fitting since models were trained through cross-validation. The implication of this finding is that understanding the relationships between kinematic and spatio-temporal variables in one context is not enough to predict how the population will respond in another context.</p><p>To further examine why these models were not generalizable between contexts, we calculated the partial correlation coefficient for both contexts for three of the variables: distance to goal, speed, and angular velocity (<xref ref-type="fig" rid="fig4">Figure 4H–J</xref>). We fitted the full model minus the variable in question to the data of each of the two contexts and calculated the correlation coefficient with the residuals (see Methods). We plotted the return trajectory correlation coefficient (x-axis) against the go trajectory (y-axis). In a hypothetical scenario where EPN units reflected purely motor coding, all data points would lie within the identity line (dashed line). However, this analysis reveals that some units display a significant partial correlation with the variable during either Return trajectories (orange dots) or the Go trajectories (green dots). Even though there are units that display a significant correlation in both trajectories (brown dots), these units do not solely lie within the I and III quadrants of the cartesian plot, which means that some units have statistically significant correlations with opposite signs during distinct trajectories (<xref ref-type="fig" rid="fig4">Figure 4H–J</xref>, pie charts). Indeed, for angular velocity and body speed only about a third (31%) have significant correlations in both trajectories, but only about a fifth of all units have significant correlations with congruent signs (<xref ref-type="fig" rid="fig4">Figure 4H–J</xref>, pie charts). Overall, these analyses paint a complex picture, where the subset of units that encode each of the variables studied in one context is not the same as those that encode the same variable in the other context. Further, the differing magnitude of the correlation explains why models trained on one trajectory are not generalizable to the other trajectory. Some extreme cases of this instability of coding are those units that have a sign switch between one context and the other (black outer pie in <xref ref-type="fig" rid="fig4">Figure 4H–J</xref>).</p><p>Given that we found that one unit might significantly encode multiple variables, we wished to investigate how the significant partial correlations for these three variables might be distributed amongst the recorded units. In <xref ref-type="fig" rid="fig4">Figure 4K</xref> we plot Venn diagrams of the percentage of units that significantly code each of these three variables during the Return (top) and the Go (bottom) trajectories and their overlap. We find that there is a similar landscape in both periods of movement wherein most units have significant correlations with more than one variable. However, as examined before, the subset of units in each of the categories is not the same from one context to the other.</p></sec><sec id="s2-5"><title>No segregation of units coding for kinematic, spatio-temporal variables and reward</title><p>Next, we asked whether the recorded units could be grouped based upon what variables they code. That is, we sought to understand whether groups of units might encode some variables more strongly than others. Previous reports suggest that EPN units that project to the lateral habenula encode reward as a decrease in firing rate. Thus, we wished to ask whether reward encoding units can code kinematic and spatio-temporal variables as well.</p><p>To this end, we first segregated units upon their reward coding properties: reward-positive (which increased activity with reward) and reward-negative units (which decreased activity with reward). We performed auROC on the 250ms after head entry comparing rewarded trials and incorrect trails (p&lt;0.001, permutation test). Mean activity of reward-insensitive, positive, and negative units is shown in <xref ref-type="fig" rid="fig4">Figure 4L</xref>. Next, we performed a dimensionality reduction on the coefficients of the model that best explained both contexts (kinematic + spatio-temporal model on pooled data) using UMAP (<xref ref-type="bibr" rid="bib17">McInnes et al., 2018</xref>). We observe a continuum rather than discrete clusters (<xref ref-type="fig" rid="fig4">Figure 4L</xref>). Note that individual units are color coded according to their responsivity to reward. We did not find a clear clustering either. This implies that, overall, coding for kinematic and spatio-temporal variables is uniformly distributed and the coding of these variables does not segregate the coding for reward. Interestingly, reward-sensitive units encoded kinematic and spatio-temporal parameters similarly to reward-insensitive units (<xref ref-type="fig" rid="fig4">Figure 4M</xref>). Reward-positive units are better at encoding these variables than are reward-negative units. However, neither type of reward-sensitive units had a significantly different cvR2 than that of reward-insensitive units.</p><p>To ask whether action value might be influencing the way units encoded variables, we segregated trials by their outcome into correct and incorrect. Additionally, we included false alarm trials, which animals performed in the absence of any auditory stimulus. We fitted the models independently for each subset of data. We found that false alarm trials have a statistically significantly lower cvR2 only for the spatio-temporal model, not so for the kinematic one. Thus, time/space varying signals are attenuated during False Alarm trials (the example unit in <xref ref-type="fig" rid="fig2">Figure 2E</xref> exhibits this behavior).</p></sec><sec id="s2-6"><title>What makes return and go trajectories different at a population level?</title><p>To address this question, we next sought to understand what population level dynamics are shared between Return and Go trajectories, and what underlying dynamics might be explaining context differences. To this end, we found highly similar Return and Go trajectories from a motor perspective (see Methods) based on body speed and angular velocity (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). Intriguingly, by projecting the population activity (n=118 units) onto the first 3 PCs (<xref ref-type="fig" rid="fig5">Figure 5B</xref>), Return and Go trajectories occupy different subspaces in this graph (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1A and B</xref>). Indeed, while the kinematic similarity is high between Return and Go trajectories (<xref ref-type="fig" rid="fig5">Figure 5C</xref>, upper), population similarity exhibits two groups based on the context (<xref ref-type="fig" rid="fig5">Figure 5C</xref>, lower).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Return and Go trajectories population dynamics.</title><p>(<bold>A</bold>) Highly similar trajectories were found for Return and Go periods based on body speed and angular velocity (see Methods). Average body speed and angular velocity are plotted for the four conditions found. (<bold>B</bold>) Population trajectories corresponding to the four conditions shows in A projected onto three PCs. (<bold>C</bold>) Cosine similarity of the four conditions based on kinematic parameters (body speed and angular velocity) and population activity. (<bold>D</bold>) Context dPC with most explained variance. Histogram of weights is presented on the right. (<bold>E</bold>) Correlation coefficient between the extracted population dynamics in D and several variables calculated for the same periods. (<bold>F</bold>) Distance from Waiting corner calculated for the four conditions. (<bold>G</bold>) Context dPC with second most explained variance. Histogram of weights is presented on the right. (<bold>H</bold>) Correlation coefficient between the extracted population dynamics in G and several variables calculated for the same periods. (<bold>I</bold>) Velocity from Waiting corner calculated for the four conditions.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-98159-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>demixed Principal components for Return and Go trajectories, continued.</title><p>Projections of population activity onto the first three PCs with most explained variance for the four conditions in <xref ref-type="fig" rid="fig5">Figure 5A</xref>, and separately for right trajectories in <bold>A</bold> and left trajectories in <bold>B</bold>. (<bold>C</bold>) Principal Components and demixed Principal Components sorted by explained variance. Statistical significance of PCs (n=6) is indicated by bigger dots. (<bold>D–G</bold>) temporal (condition-independent) dPCs and Side in D. are presented with their weight histogram and the correlation of these components with individual kinematic and spatio-temporal variables.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-98159-fig5-figsupp1-v1.tif"/></fig></fig-group><p>To find a more interpretable dynamic that may account for the differences between the two contexts we employed dPCA, marginalizing by context, left-right, and temporal components. We hypothesized that temporal components shared by both contexts might exhibit kinematic variables and that left-right marginalization would encompass angular velocity. After performing the dPCA procedure (see Methods), we sorted the components by variance (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1C</xref>). Note that after marginalization upon the desired variables, the extraction of the dynamics is unsupervised. This is to say that extracted dynamics do not have to necessarily produce traces related to individual kinematic parameters, and they are unlikely to do so given the multiplexing of encoded variables (<xref ref-type="fig" rid="fig4">Figure 4K</xref>). However, we sought to interpret the resulting traces based on measurable variables. Thus, we compared the resulting trace with the variables measured on the same time periods by calculating the correlation coefficient and testing significance through permutation testing (p&lt;0.001).</p><p>The contextual marginalization produces two significant dPCs that explain the differences between Return and Go trajectories. Indeed, the contextual dPC1 explains 15% of the total variance (<xref ref-type="fig" rid="fig5">Figure 5D</xref>), and Return vs Go traces exhibit oppositely evolving temporal dynamics. The spatial variable of distance from the waiting corner best explains these contextual traces, while no kinematic variable correlates with these traces. Interestingly, context dPC2 (<xref ref-type="fig" rid="fig5">Figure 5D</xref>) exhibits a high similarity to the speed-correlated temporal dPC2 (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1E</xref>). However, context dPC2 shows oppositely evolving dynamics symmetric over time between Return and Go trajectories. This suggests that there is a simultaneous representation of speed and a spatially referenced velocity (<xref ref-type="fig" rid="fig5">Figure 5G–I</xref>). Indeed, context dPC2 correlates well with the velocity from the waiting corner.</p><p>Condition-independent (temporal) dPCs summarize population dynamics shared by both Return and Go contexts (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). Temporal dPC1 has a high correlation with distance to goal (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1D</xref>) while temporal dPC2 (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1E</xref>) is well correlated to the speed. Note that these traces do not correlate with one specific variable, which is to be expected given the previously established high level of multiplexing (<xref ref-type="fig" rid="fig4">Figure 4H–K</xref>). The marginalization for side (side dPC1, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1G</xref>) produces traces that have a significant correlation with angular velocity, both for the Return and Go trajectories. Note that Go trajectories occurred under the presence of an auditory stimulus, and not the Return trajectories; however, traces corresponding to left and right turns (irrespective of goal) show good overlap. Thus, this further confirms that the associated differences between left and right turning are well explained by angular velocity. We conclude that context-dependent dynamics explain variables whose measurement depends on specific places in the arena. Thus, spatially biased variables have an important representation of the EPN population activity.</p></sec><sec id="s2-7"><title>EPN units are modulated by gait and licking</title><p>Our findings reveal a robust representation of whole-body speed (<xref ref-type="fig" rid="fig4">Figure 4</xref>) as well as spatially biased variables (<xref ref-type="fig" rid="fig4">Figures 4</xref>–<xref ref-type="fig" rid="fig5">5</xref>). However, prior studies have indicated a somatotopic representation in the GPi across various species [humans, non-human primates, cats <xref ref-type="bibr" rid="bib2">Baker et al., 2010</xref>; <xref ref-type="bibr" rid="bib14">Larsen and McBride, 1979</xref>; <xref ref-type="bibr" rid="bib22">Nambu, 2011</xref>]. Therefore, we examined the EPN’s modulation by individual movements of the paw and tongue, using the cyclic nature of gait and licking to examine the potential presence of muscle-level activity since they exhibit a clear flexor-extensor muscle relationship.</p><p>Given that animals were recorded from a bottom-up view, we were able to track individual paws of the animal (<xref ref-type="fig" rid="fig6">Figure 6</xref>). We searched for Return and Go trajectories with at least four individual strides (<xref ref-type="fig" rid="fig6">Figure 6A</xref>, triangles) and used them to align unit activity. <xref ref-type="fig" rid="fig6">Figure 6B</xref> shows two example units simultaneously recorded from different channels. Note how Unit 1 has a very robust stride-locked activity, while Unit 2 shows a smaller stride-based modulation and instead becomes immersed in an evolving temporal dynamic. The average paw position for the session (<xref ref-type="fig" rid="fig6">Figure 6B</xref>, bottom) is well preserved, and that there is a high level of correlation or anticorrelation, which justifies our using only one paw to study. This procedure was performed for all units studied and is presented in <xref ref-type="fig" rid="fig6">Figure 6C</xref>, sorted by peak activity during the step 4 in Return trajectories. This sorting is only slightly preserved in the rest of the steps, highlighting the dynamic nature of this gait modulation.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Gait cycle modulation of units.</title><p>(<bold>A</bold>) Longitudinal position of four paws of a mouse during a return, wait, and go periods. Inset shows body position in time. Colored triangles show identified events for unit alignment. (<bold>B</bold>) Activity of two simultaneously recorded example units in the eight strides studied. Lower row shows average paw position corresponding to the trials shown above. (<bold>C</bold>) Population activity during the four strides. (<bold>D</bold>) Spike gait-phase average vector for all significantly modulated units during eight strides. (<bold>E</bold>) Upper: Fraction of modulated units (with a significant directionality Rayleigh test p&lt;0.001). Middle: Mean phase of population vector. Lower: Mean population vector magnitude. (<bold>F</bold>) Variance explained by Principal Component Analysis (PCA) decomposition of data shown in C. Inset shows first four PCs’ weight distribution. (<bold>G</bold>) Upper: mean absolute correlation coefficient for kinematic and spatio-temporal variables for the first four PCs. (<bold>H</bold>) Population projection of data in C onto PC1, PC2, and PC4 for the four Return strides (in orange tones) and the Go strides (in green tones). (<bold>I</bold>) Left: PC4 population projection for the eight strides studied plotted on top of contralateral hindpaw velocity. Right: correlation coefficient with individual kinematic and spatio-temporal variables. Filled circles represent a statistically significant correlation (permutation testing). (<bold>J</bold>) Population Support Vector Classifiers were trained for different variables (x-axis). Accuracy was assessed for the classifier trained on the original labeled population vectors (in blue) and for vectors trained on shuffled labels (in orange). *p&lt;0.001, permutation testing. Note that paw velocity could not be decoded from the original matrix but could be decoded from the PC4 weighted matrix.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-98159-fig6-v1.tif"/></fig><p>Since locomotion necessitates a coordinated contraction of flexor and extensors during each stride, we hypothesized that if individual muscle activity was represented in the GPi, we would find stride-cycle locked activity in symmetric opposing phases (flexors vs extensors). We calculated the spike- contralateral hindlimb phase locking for each unit at each step studied. In <xref ref-type="fig" rid="fig6">Figure 6D</xref> we plot the average vectors of individual units with significant phase locking (p&lt;0.001, Rayleigh directionality test) for each of the eight steps studied. Note how for each step units tend to point to one phase and not to the antiphase. Further, there is a shift in the mean phase of the paw (<xref ref-type="fig" rid="fig6">Figure 6D–E</xref> middle), for Return and Go trajectories. Surprisingly, as the step number increases (which corresponds to steps closer to the goal of the trajectory), a greater fraction of units has a significantly stride phase-locked activity (<xref ref-type="fig" rid="fig6">Figure 6E</xref>, upper panel). The magnitude of the average vector also increases with step number (<xref ref-type="fig" rid="fig6">Figure 6E</xref>, lower panel), suggesting an increase in phase-locking. These results are not supportive of this activity being muscle related, since most gait-modulated units are biased toward a single phase of gait, with no antiphase representation (<xref ref-type="fig" rid="fig6">Figure 6C</xref>). Further, gait modulation increases with steps closer to the goal, and phase precession would not occur if units were strictly related to muscle activity.</p><p>Given the widespread existence of this phase-locked activity, we hypothesized the presence of a covariance plane that would encompass it. Thus, by performing PCA on the population activity (<xref ref-type="fig" rid="fig6">Figure 6C and F</xref>) we could understand what variable might be represented at a population level. We found that the population projection onto the first three PCs correlated best with spatio-temporal variables (<xref ref-type="fig" rid="fig6">Figure 6G</xref>, upper panel) while the fourth PC had a good correlation with paw velocity (<xref ref-type="fig" rid="fig6">Figure 6g</xref>, lower). Indeed, there is a clear overlap of PC4 projection with paw velocity (<xref ref-type="fig" rid="fig6">Figure 6I</xref>). Finally, we sought to compare the robustness of the representation of the different variables on the population activity. To this end, we trained linear support vector classifiers to discern between Return and Go trajectories (context), step number, and paw position and acceleration (<xref ref-type="fig" rid="fig6">Figure 6J</xref>). Paw velocity could only be decoded above chance on the PC4 weighted matrix, not on the original data. These results support the existence of a relatively weak representation of the paw velocity at a population level. Paw-related PC4 captures only 5% (<xref ref-type="fig" rid="fig6">Figure 6F</xref>) of the variance of this matrix, which includes less time compared to other population analyses (<xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig5">5</xref>), does not segregate by turning direction, and does not include a reward period.</p><p>A final test of kinematic representation was performed by analyzing the relationship between EPN activity and licking behavior. Individual licks could be recorded by a custom-made lickometer (<xref ref-type="fig" rid="fig7">Figure 7A</xref>, see methods and <xref ref-type="video" rid="video2">Video 2</xref>). We found a correlation between licking behavior and EPN activity at two different timescales: as a whole lick bout instance and at the single lick behavior. <xref ref-type="fig" rid="fig7">Figure 7B and C</xref> are raster plots of licks and a unit activity recorded simultaneously, for left and right licking ports. Because of the apparent similarity between lick and firing rate traces, we sought to assess whether units might be encoding licking rate during the licking bout. To this end, we computed the rescaled activity to the average duration of licking bouts. <xref ref-type="fig" rid="fig7">Figure 7D</xref>, upper panel shows the rescaled activity of three simultaneously recorded units and the corresponding licking rate. Despite varying dynamics exhibited by these three units, all three have a high degree of correlation with the lick rate. <xref ref-type="fig" rid="fig7">Figure 7D</xref>, lower panel shows the correlation coefficient between the instantaneous firing rate and the instantaneous lick rate within a lick bout for all units. Indeed, most units (91%) exhibit a positive or negative significant correlation with lick rate (p&lt;0.001, permutation test). We then obtained PETHs of activity related to single licks in the left and right lick ports (red and blue, respectively), as shown in <xref ref-type="fig" rid="fig7">Figure 7E</xref> for the same unit as in <xref ref-type="fig" rid="fig7">Figure 7C</xref>. By extracting the lick phase from the lick probability (sensor crossings, <xref ref-type="fig" rid="fig7">Figure 7E</xref>, upper), we could generate a spike – lick-phase histogram and calculate the resulting vector (<xref ref-type="fig" rid="fig7">Figure 7E</xref>, right). When performing this for all units, it was clear that they fire more strongly in a specific phase of the licking behavior. This is also shown in the heatmap of perievent activity sorted by peak activity (<xref ref-type="fig" rid="fig7">Figure 7G</xref>). Thus, we show that nearly all units (99%) exhibit correlation with lick rate, single licks, or both (<xref ref-type="fig" rid="fig7">Figure 7H</xref>).</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Licking behavior modulation of units.</title><p>(<bold>A</bold>) Infrared sensor-based lickometer. (<bold>B</bold>) Licks of aligned to port entry for left (red) and right (blue) correct trials. (<bold>C</bold>) Example unit activity aligned to the same port entries as in B. (<bold>D</bold>) Upper: Three simultaneously recorded example units’ (blue, orange, and green) activity rescaled to average lick bout duration. Lick rate is shown in gray. Lower: Histogram of Pearson correlation coefficient between instantaneous firing rate and instantaneous lick rate for all units. Black bars represent significantly correlated units (p&lt;0.001, permutation test). (<bold>E</bold>) Example unit shown in C aligned to single left (red) and right (blue) licks. Upper inset shows the probability occurrence as well as the lick cycle phase derived from the lick probability. Right inset shows the spike lick-phase polar histogram for same unit. Black line represents resulting vector with statistically significant directionality (Rayleigh test, p&lt;0.001). (<bold>F</bold>) Polar histogram (bin = 30°) of average vector phase direction. Polar axis is percentage of units. (<bold>G</bold>) Average single lick activity for all recorded units sorted by peak activity. Upper inset: average lick probability. (<bold>H</bold>) Venn diagram showing percentage of units of the total population (n=118) of units with statistically significant correlation with lick rate (Pearson correlation coefficient, p&lt;0.001, permutation test) and/or with single licks (Rayleigh directionality test, p&lt;0.001). (<bold>I</bold>) Single lick average activity segregated by first and last lick, five interspersed licks, and incorrect lick for left and right licks for the same unit shown in C and E. (<bold>J</bold>) Population activity for n=118 units for seven right licks sorted by lick with most activity. Lower: fraction of variance explained by Principal Component Analysis (PCA) decomposition PCA weight for first three components. (<bold>K</bold>) Projection of lick population activity for the 16 licks considered onto first three PCs. (<bold>L</bold>) Population vector decoders for different variables with original labels (blue) compared to population vector decoders with shuffled labels (n=1000). *p&lt;0.001, permutation test.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-98159-fig7-v1.tif"/></fig><media mimetype="video" mime-subtype="mp4" xlink:href="elife-98159-video2.mp4" id="video2"><label>Video 2.</label><caption><title>Lickometer detected individual licks.</title><p>Individual licks could be recorded by a custom-made lickometer. The lick port was equipped with a double infrared sensor to capture head entry and single licks separately. The lickometer IR sensor was inside a 7 mm wide slit, inside which the reward delivery spout was placed. The lickometer slit was just wide enough to fit the tongue and deep enough to evoke a clear tongue protrusion. Rewards consisted of 3 μl droplets delivered through a solenoid, which was calibrated daily.</p></caption></media><p>What is the significance of such a robust representation of licking by nearly all recorded units? We hypothesized that different aspects of a single lick might be represented. To this end we obtained PETH for 16 different licks per unit: the first and last licks per bout, as well as five licks spread out within the bout, right and left. We noticed that occasionally animals would execute one lick when animals performed incorrect or false alarm trials, which we termed an incorrect lick (right and left). This allowed us to analyze a similar motor output (a single lick) performed under different contextual situations. An example unit (<xref ref-type="fig" rid="fig7">Figure 7I</xref>) shows that despite similarities between all these conditions, firing rate traces exhibit clear differences. <xref ref-type="fig" rid="fig7">Figure 7J</xref> shows a heat map for seven right licks during a bout sorted by the lick with highest activity. This highlights that while there is a modulation at the single lick timescale, a whole-bout modulation is also present. After PCA dimensionality reduction (<xref ref-type="fig" rid="fig7">Figure 7J</xref>, lower), we projected the population responses on the three main principal components (<xref ref-type="fig" rid="fig7">Figure 7K</xref>). The population responses for the 16 conditions maintain a circular (cyclic) response. However, they occupy distinct spaces in this state space which suggests that the EPN population can distinguish amongst them. To assess this, we trained support vector classifiers on population vectors for lick phase, left vs right licks, lick number, and correct vs incorrect licks. All these variables could be accurately decoded above chance. Together, these results show that most units in the EPN are modulated by licking behavior at different timescales. Further, information about licking kinematics is simultaneously represented with other contextual variables.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>This study highlights the dynamic nature of kinematic representation within the EPN. It is particularly striking that spatio-temporal dynamics are better at explaining EPN activity than are kinematic ones. Further, relationships between these variables and EPN activity fluctuate across two largely similar periods of movement (Return vs Go). What is more, units multiplex different functions like reward, whole-body movements, and individual movements (paw and licks) with contextual variables. Interestingly, we were unable to find a strong correlate of difficulty.</p><p>The principal goal of this study was to investigate how the activity of entopeduncular nucleus is related to kinematic variables, reward, and difficulty/value, particularly during locomotion. Two previous findings had a particular influence over the study design: (1) the existence of reward and value coding with a spatial bias, and (2) that kinematic coding was unstable and varies depending on cognitive states. To this end, we designed a task that involved decision confidence, reward, and two periods of displacement.</p><sec id="s3-1"><title>Prominent representation of evaluation period, reward, but no difficulty in the EPN</title><p>We found that there is a robust representation of evaluation period and reward. When analyzing the population dynamics (from pooled units from all animals to construct a pseudo-simultaneous population, which assumes homogeneity across subjects) underlying the Go period, we found that a dynamic that separates the evaluation period from the rest of the task captures the most variance (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). Further, a statistically significant reward dPC was found (<xref ref-type="fig" rid="fig3">Figure 3F</xref>). Importantly, reward coding is also represented within this nucleus by reward-positive and negative neurons. These findings support previous studies (<xref ref-type="bibr" rid="bib9">Hong and Hikosaka, 2008</xref>; <xref ref-type="bibr" rid="bib27">Stephenson-Jones et al., 2016</xref>).</p><p>Stephenson-Jones et al. found that a subset of EPN neurons projecting to the habenula encode value of expected outcomes in a classical conditioning task. We hypothesized that by varying the difficulty of stimuli (and thus increasing uncertainty during difficult choices) we could be able to modulate the perceived value of the chosen action. However, the explained variance by this hypothesis is very low (<xref ref-type="fig" rid="fig3">Figure 3</xref>). The stimuli were able to impact the animals’ response time and angular velocity (<xref ref-type="fig" rid="fig1">Figure 1E–H</xref>) which suggests some level of metacognition of the uncertainty in their decision. However, speed was not well correlated with difficulty (<xref ref-type="fig" rid="fig1">Figure 1I–J</xref>), which could imply that this metacognition diluted over time. Further, value coding was documented in neurons recorded during a head-fixed classical conditioning task (<xref ref-type="bibr" rid="bib27">Stephenson-Jones et al., 2016</xref>), where the stimulus-outcome contingency might be more explicit or the coding of neurons less mixed (due to forced immobility). It is still possible that by modifying reward contingencies such as droplet size value coding could be evidenced.</p><p>In this study, we found that rewarding outcomes can be represented by EPN units through either an increase or a decrease in firing rate (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>, and <xref ref-type="fig" rid="fig4">Figure 4L</xref>). While <xref ref-type="bibr" rid="bib27">Stephenson-Jones et al., 2016</xref> found that mice lateral habenula (LHb)-projecting neurons within the EPN of mice primarily encoded rewarding outcomes by a decrease in firing rate, <xref ref-type="bibr" rid="bib9">Hong and Hikosaka, 2008</xref> observed that in primates, LHb-projecting units could encode reward through either a decrease or an increase in firing rate. Thus, our results align more closely with the latter study, which also employed an operant conditioning task.</p></sec><sec id="s3-2"><title>EPN activity can represent movement but with novel considerations</title><p>In this study, we found that Go trajectories have a more robust representation of kinematic and spatio-temporal variables when compared to Return trajectories (<xref ref-type="fig" rid="fig4">Figure 4E</xref>). Indeed, several studies have found an inconsistent relationship between the GPi activity and limb movements of the primate, where units were modulated by movements under certain cognitive conditions but not others. Some hypotheses have been that GPi coding depends on movement type (ramping vs. stepped; self-paced vs step tracking, <xref ref-type="bibr" rid="bib4">DeLong, 1971</xref>; <xref ref-type="bibr" rid="bib6">Georgopoulos et al., 1983</xref>; <xref ref-type="bibr" rid="bib18">Mink and Thach, 1991</xref>) or between identical movements performed under different cognitive states (cued vs memory-dependent <xref ref-type="bibr" rid="bib29">Turner and Anderson, 2005</xref>). Further, some studies agree that self-paced movements are more weekly represented (; <xref ref-type="bibr" rid="bib29">Turner and Anderson, 2005</xref>). Interestingly, while most previous studies have focused on limb movements, here we find that whole-body displacement kinematics are better at explaining EPN activity than individual limb movements. Both Return and Go movements in this study are self-paced, and they are mostly different in their relation to reward.</p><p>Representation of movements seems to be very dependent on what the movement is performed for. Kinematic and spatio-temporal variables are not stably represented across similar movements with different purposes (<xref ref-type="fig" rid="fig4">Figures 4</xref>–<xref ref-type="fig" rid="fig5">5</xref>). Given the sequential nature of the task, Return and Go trajectories are both required to eventually get a reward. While both trajectories have a goal: Return → auditory stimulus, Go → water droplet, they differ in that Go trajectories are performed to receive something rewarding. Indeed, we hypothesize that movements that can lead to a reward are better represented by EPN neurons. A similar conclusion was reached (<xref ref-type="bibr" rid="bib5">Gdowski et al., 2001</xref>) in primates performing wrist movements, where they found that wrist movements that led to reward modulated a higher fraction of units than wrist movements that did not lead to a reward. The findings in this study differ in that kinematic relationships were indeed found in the Return trajectories, but they were attenuated.</p><p>An important finding of this study is that spatio-temporal variables are better at explaining EPN activity than purely kinematic ones, for both Go and Return trajectories. Further, these spatio-temporal variables are sensitive to action value (<xref ref-type="fig" rid="fig4">Figure 4N</xref>, false alarm trials have a lower R2 in the spatio-temporal model). Importantly, we did not find that kinematic representation was affected by action value (<xref ref-type="fig" rid="fig4">Figure 4N</xref>). Only false alarm trials had a weaker relation with spatio-temporal variables than correct trials. It is possible that value influences the spatio-temporal dynamics akin to reward prediction error, (<xref ref-type="bibr" rid="bib3">Dayan and Balleine, 2002</xref>). A previous finding focusing on the decision properties of the GPi neurons found that the main correlate that the GPi has, as compared to other brain regions, was a temporal component which they called urgency (<xref ref-type="bibr" rid="bib28">Thura and Cisek, 2017</xref>). This is similar to our finding that spatio-temporal dynamics dominate EPN activity. They found that decision was not as well represented in the GPi compared to other cortical regions. This suggests that more than movement per se, the EPN might compute contextual relationships present in the task.</p><p>There is a longstanding belief that reward-related functions in the EPN are separate from motor-related functions, since anatomical studies have found two distinct projections to habenula and motor thalamus (<xref ref-type="bibr" rid="bib9">Hong and Hikosaka, 2008</xref>; <xref ref-type="bibr" rid="bib24">Parent et al., 1999</xref>; <xref ref-type="bibr" rid="bib27">Stephenson-Jones et al., 2016</xref>; <xref ref-type="bibr" rid="bib30">Wallace et al., 2017</xref>). In this study, we did not identify recorded units by their projections, however, we could evaluate their sensitivity to reward given the task design. Surprisingly, we did not find differences in the ability of reward-sensitive units to encode kinematic and spatio-temporal variables compared to reward-insensitive (<xref ref-type="fig" rid="fig7">Figure 7L–M</xref>). Given that we did not record from the entire EPN, it is still possible that another region of the nucleus might exhibit more segregation.</p><p>We found that latent population dynamics that best explain differences between the Return and Go trajectories can be best explained by spatially referenced variables (such as distance and velocity from a specific place in the arena, <xref ref-type="fig" rid="fig5">Figure 5</xref>). The similar but contextually opposite dynamics probably reflect the units switching sign between contexts that were found in <xref ref-type="fig" rid="fig4">Figure 4H–J</xref> (outer pie, black). Interestingly, a previous study in primates <xref ref-type="bibr" rid="bib9">Hong and Hikosaka, 2008</xref> found that the direction of rewarded outcome greatly modulated units in a one-direction rewarded task, and switched sign when the spatial location of the rewarded target was alternated. They attributed the activity to the stimulus onset, and did not study it in regards to saccade onset. However, the direction-sensitive activity was appropriately timed to coincide with saccade performance. It is thus possible that an important function of EPN activity is to compute kinematic and spatio-temporal relations between the subject and the reward location. In this study dynamics related to (spatial) side of turning during the Go period and reward were found to be largely uncorrelated (orthogonal to each other, <xref ref-type="fig" rid="fig3">Figure 3H–I</xref>); however, both turns during the Go period (performed to get to the reward port) have similar value. On the other hand, population dynamics that explain the differences between Return and Go periods, which can be said to have different action value, did exhibit sign switching (<xref ref-type="fig" rid="fig5">Figure 5D and G</xref>). Thus, action value (moving to or away from the rewarded location) could explain these opposing dynamics. Indeed, reward prediction error models incorporate/rely on spatio-temporal variables (<xref ref-type="bibr" rid="bib3">Dayan and Balleine, 2002</xref>; <xref ref-type="bibr" rid="bib11">Kim et al., 2020</xref>).</p><p>Previous studies performed in humans, primates, and cats <xref ref-type="bibr" rid="bib2">Baker et al., 2010</xref>; <xref ref-type="bibr" rid="bib14">Larsen and McBride, 1979</xref>; <xref ref-type="bibr" rid="bib22">Nambu, 2011</xref> have suggested the existence of a somatotopic organization in the GPi. We sought to test the hypothesis that this organization could be representing muscle contraction information. To this end, we analyzed two cyclic movements, gait and licking, since they require a coordinated contraction of flexor and extensor muscles. The gait coupling of EPN units has also been found in cats (<xref ref-type="bibr" rid="bib20">Mullié et al., 2020</xref>). However, we found that while units did exhibit a selective firing on a specific phase of both of these cyclic movements, there was no anti-phase balance. This could imply that only flexor muscles are represented, or, more likely, that the activity is not related to muscle contraction. A further fact that is contrary to muscle level modulation of activity is that both representations, gait an licking, largely overlap. That is, units that significantly modulate to gait also do so for licking. Thus, we can conclude that in this mouse data, somatotopic organization is not present, which is a similar conclusion reached by previous primate studies (<xref ref-type="bibr" rid="bib4">DeLong, 1971</xref>; <xref ref-type="bibr" rid="bib19">Mitchell et al., 1987</xref>).</p><p>Finally, it was surprising to find such a robust representation of licking behavior in these units. Practically all units correlate to whole bout licking rate and/or individual licks. This implies that the same units that presented significant correlations with movement during the displacement periods, could robustly represent licking behavior. Further, the population could represent contextual parameters associated with licking (<xref ref-type="fig" rid="fig7">Figure 7K–L</xref>).</p><p>What could be the purpose of having a representation of many types of movements and variables by the same population? The data in this study suggests that action value might be key to the level of movement representation by the EPN. Cued movements (Go, correct trials) are better represented than uncued (False Alarm) ones (<xref ref-type="fig" rid="fig4">Figure 4N</xref>), which in turn are better represented than trajectories that cannot lead to reward (Return trajectories, <xref ref-type="fig" rid="fig4">Figure 4E</xref>). Further, licking, the action of consuming a reward, very robustly modulates the EPN (<xref ref-type="fig" rid="fig7">Figure 7</xref>). Thus, it is possible that the EPN serves as online feedback of the reward properties of an action.</p><p>How do the results in the present study fit in with models of basal ganglia function? Both the ‘firing rate model’ (<xref ref-type="bibr" rid="bib1">Albin et al., 1989</xref>) and the ‘dynamic activity model’ (<xref ref-type="bibr" rid="bib23">Nambu et al., 2023</xref>) rely on an inhibition of basal ganglia output activity to facilitate movement. When solely considering the average population activity we did not find that movement periods exhibited a statistically significant lower activity (<xref ref-type="fig" rid="fig2">Figure 2H</xref>). In fact, reward (evaluation period of correct trials) exhibited higher population activity than the wait period despite presumably more motor output (licking) than waiting. Further, we found very complex relationships between movement and EPN activity at different timescales, which could be affected by aberrant oscillatory activity that is described in the ‘firing pattern model’ (<xref ref-type="bibr" rid="bib7">Guillery et al., 1998</xref>).</p><p>In this study, we have focused on describing the representation of several variables in the EPN activity. However, interpreting how this complex representation affects target nuclei is further complicated by the fact that some subpopulations within the EPN form multi-transmitter synapses of excitatory and inhibitory transmission, particularly onto the lateral habenula (<xref ref-type="bibr" rid="bib30">Wallace et al., 2017</xref>). In fact, simultaneous recordings of GPi and the ventral anterior thalamus, classically considered as the motor output, reveal only weak correlations (<xref ref-type="bibr" rid="bib26">Schwab et al., 2020</xref>).</p><p>A weakness of the current study is the lack of characterization of neuronal subtypes. An area of opportunity for future research could be to perform photo-identification of neuronal subtypes within the EPN which could contribute to the overall description of the information representation. Further, detailed anatomical viral vector strategies could aid to improve anatomical localization of recordings, reduce reliance on histological examination, and solve some current controversies (<xref ref-type="bibr" rid="bib15">Lazaridis et al., 2019</xref>).</p><p>We conclude that EPN neurons exhibit a high degree of multiplexing of diverse variables including reward, spatio-temporal, kinematic. EPN activity can reflect single movements like gait and licking as well as whole-body movements. We found that the correlation that units have with these variables is unstable and varies depending on context. Finally, spatial location of reward can influence population dynamics.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Animals</title><p>All procedures were approved by the Institutional Committee for the Care and Use of Laboratory Animals at the Instituto de Fisiología Celular (Protocol number FTA-121–17). Universidad Nacional Autónoma de México. and the National Norm for the Use of Animals (NOM-062-ZOO-1999). Experiments used C57BL/6 J male (n=2) and female (n=4) mice (2–3 mo of age at the start of training, 6–7 mo during recordings). Animals were housed under a 12 hr light/dark cycle (lights on at 6 am) with ad libitum access to food and water before the start of behavioral experiments. For behavioral training, water was restricted so that the weight of animals was 80% of their original weight.</p></sec><sec id="s4-2"><title>Behavioral apparatus and task design</title><p>The behavioral apparatus consisted of a triangular (side = 30 cm, height = 40 cm) arena with a transparent acrylic floor with a bottom-up camera view. The apparatus was encased in a light controlled and sound attenuated chamber. One of the corners was termed the Waiting Corner and the other two were the lick port corners. The latter had lick ports. The lick port was equipped with a double infrared sensor to capture head entry and single licks separately. The lickometer IR sensor was inside a 7 mm wide slit, inside which the reward delivery spout was placed (see <xref ref-type="fig" rid="fig7">Figure 7A</xref> and <xref ref-type="video" rid="video2">Video 2</xref>). The lickometer slit was just wide enough to fit the tongue and deep enough to evoke a clear tongue protrusion. Rewards consisted of 3 μl droplets delivered through a solenoid, which was calibrated daily. Auditory stimuli were delivered through a tweeter that was placed outside the arena, inside the sound attenuating chamber. The task was controlled by interfacing Bonsai, Python scripts and Arduino chips.</p><p>The task involved a two-alternative forced choice. The animal was required to approach the wait corner, wait for 0.8–1.3 s after which an auditory stimulus was played. Entrance to the waiting corner was controlled by establishing a region of interest on the video feed through Bonsai. Auditory stimuli consisted of 0.5 frequency-modulated sweeps with a start frequency of 9.2 kHz and an end frequency of 0,+/-0.2,+/-0.4,+/-0.6,+/-0.8 octaves. Upwards sweeps indicated a water reward on the right lick port and downwards on the left. The animal then had to walk to the appropriate port. Correct responses were rewarded with a water drop and incorrect ones were punished with a 10–20 s timeout indicated by a dimming of the ambient light (see <xref ref-type="video" rid="video1">Video 1</xref>).</p><p>Training was conducted through successive approximations introducing a new rule after the previous one was acquired. To reach steady performance, animals were trained 3–4 mo, 6 d a week.</p></sec><sec id="s4-3"><title>Recordings</title><p>Movable microwire bundles (16 microwires, 32 micrometers in diameter, held inside a cannula, Innovative Neurophysiology, Durham, NC) were stereotaxtically implanted just above the entopeduncular nucleus (–0.8 AP, 1.7 ML, 3.9 DV). Post-surgical care included antibiotic, analgesic and antiinflammatory pharmacological treatment. After 5 d of recovery, animals were retrained for 1–2 wk. Unitary activity was recorded for 2–6 d at each dorsoventral electrode position and the session with the best electrophysiological (signal-to-noise ratio (&gt;2), stability across time) and behavioral [performance, number of trials (&gt;220)] quality was selected. Microwire electrodes were advanced in 50 micrometer dorsoventral steps for 500 micrometers in total. After experiment completion, animals were perfused with a 4% paraformaldehyde solution. Brains were extracted, dehydrated with a 30% sucrose solution and sectioned in a cryostat into 30 micron thick slices. Slices were mounted and photographed using a light microscope. Microwire tracks of the 16-microwire bundle were analyzed (<xref ref-type="fig" rid="fig2">Figure 2A–B</xref>) and only animals with tracks traversing the EPN were selected (6 out of 10). Finally, we located the final position of microwire tips and inferred the dorsoventral recording position of each of the recording sessions. Only units recorded within the EPN were included.</p><p>Electrophysiological recordings were acquired at 30 KHz (Cereplex Direct, Black Rock Microsystems, UT) high pass filtered at 750 Hz to extract spiking activity. Units with signal-to-noise ratio of at least two were sorted online through a hoop algorithm and further sorted offline (Offline Sorter, Plexon). Relevant behavioral events and video synchronization were stored as digital events.</p><p>Animal video position was extracted using DeepLabCut (<xref ref-type="bibr" rid="bib16">Mathis et al., 2018</xref>). The several kinematic variables like angular velocity, velocity, and acceleration of displacement as well as spatio-temporal the relative position of the animal or time to the different corners were computed (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). We identified four moments per trial to align the spiking activity: (1) return to the wait corner, defined as the start of the negative animal-corner velocity; (2) arrival to wait corner, when animal-corner distance &lt;0.5 pix; (3) turn start, when angular velocity &gt;0.01 degrees/s; (4) evaluation, the moment of lick port infrared sensor crossing. Spiking activity was convolved with a gaussian function (sigma = 25 ms) and rescaled through linear interpolation (<xref ref-type="bibr" rid="bib12">Kobak et al., 2016a</xref>) to the average segment duration across all trials which allowed to construct peri-event time histograms (PETH) (<xref ref-type="fig" rid="fig2">Figures 2</xref>, <xref ref-type="fig" rid="fig3">3</xref> and <xref ref-type="fig" rid="fig5">5</xref>).</p><p>For <xref ref-type="fig" rid="fig2">Figure 2F, G and I</xref> z-score was obtained for each unit across all conditions (eight stimuli, correct, and incorrect) and averaged according to the specified conditions. Statistical testing performed in <xref ref-type="fig" rid="fig2">Figure 2I</xref> was done with the Wilcoxon test.</p></sec><sec id="s4-4"><title>Linear regressions</title><p>Simple linear regressions were employed with some variables, for example, reaction time in <xref ref-type="fig" rid="fig1">Figure 1E, H and J</xref> and individual variables in the examples shown in <xref ref-type="fig" rid="fig4">Figure 4A–C</xref>. Significance testing was done through permutation (n=1000).</p><p>Multiple regression models were used in <xref ref-type="fig" rid="fig4">Figure 4</xref>. Data was obtained by generating a PETH with 0.2 s sliding windows (every 50 ms) and obtaining the value for the different variables tested (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>) through interpolation. The models were fitted through 10-fold cross-validation using an L1 (LASSO) regularization term. Cross-validated R2 values were obtained from untrained data for each fold and reported as the 10-fold mean. Given that regressors were not perfectly independent (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>), the regularization term penalized the magnitude of the coefficients.</p><p>Partial correlation coefficient analyses (<xref ref-type="fig" rid="fig4">Figure 4H–J</xref>) were obtained by fitting a reduced model lacking the variable to be studied and using the residuals to obtain the correlation coefficient. Statistical significance was obtained by pseudo-random permutation (n=1000) of values. For distance to goal, the reduced model included all the kinematic variables (<xref ref-type="fig" rid="fig4">Figure 4F</xref>) and no spatio-temporal ones (given their high level of correlation, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). For angular velocity, the reduced model included all kinematic and spatio-termporal except the variable in question; for body speed, the reduced model also excluded head speed.</p><p>For <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>, we computed the loss of predictive power, delta R2, for each of the four variables tested, similar to <xref ref-type="bibr" rid="bib21">Musall et al., 2019</xref>. We created reduced models in which the datapoints for the specified variable were shuffled. The difference in explained variance between the full and the reduced model equals the contribution (delta R2) of that variable to the model. This provides a metric for unique information (not shared by other variables) that each given variable contributes to the model.</p></sec><sec id="s4-5"><title>Population level analyses</title><p>Population level analyses were employed several times throughout the study (<xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig5">5</xref>—<xref ref-type="fig" rid="fig7">7</xref>), using standard Principal Component Analysis (PCA) and demixed Principal Component Analysis (dPCA) procedures (<xref ref-type="bibr" rid="bib12">Kobak et al., 2016a</xref>).</p><p>Matrix construction varied according to the period and conditions used. For all population level analyses individual units recorded from all sessions and all animals were pooled to construct pseudo-simultaneous population response of data mostly recorded separately. For <xref ref-type="fig" rid="fig3">Figure 3</xref> condition averages were obtained for Go and evaluation periods, 0.3 s before turn start and 2.5 after lick port arrival. The dataset consisted of n=118 units recorded for 16 conditions (eight stimuli, with correct and incorrect responses) for which PETH were obtained as described before. We included units with at least two trials per condition. Note that responses can be classified by the direction of turn (Side), where for each stimulus correct and incorrect responses include turns to the right and left. Further, for left and right turns, there is stimulus gradation (0, +/-0.4, +/-0.6, +/-0.8), corresponding to the difficulty of the task. Thus, the 16 conditions per unit were used to construct a matrix of NxSxDxCxT, where N is the total of units (n=118), S is side (two conditions), D is difficulty (four conditions), C is correct and incorrect responses (two conditions), and T is time.</p><p>This matrix was used to calculate instantaneous variance (<xref ref-type="fig" rid="fig3">Figure 3A</xref>) for the different conditions with the following formulas:<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>S</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>C</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ3"><mml:math id="m3"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>t</mml:mi><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mi>N</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>N</mml:mi></mml:mfrac><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:munderover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>d</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>To compute the population cosine similarity presented in <xref ref-type="fig" rid="fig3">Figure 3H–I</xref> we used the aforementioned matrix, mean-subtracted it to remove condition-independent (temporal) dynamics. Then the following formula to all the population vector pairs at different timepoints:<disp-formula id="equ4"><mml:math id="m4"><mml:mrow><mml:mi>C</mml:mi><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo>⋅</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo symmetric="true">‖</mml:mo></mml:mrow><mml:mrow><mml:mo symmetric="true">‖</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msubsup><mml:mo symmetric="true">‖</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>For PCA analysis, a covariance matrix was constructed by obtaining the pairwise covariance across all conditions. Eigenvalues and eigenvectors were then computed and sorted by variance. For <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref> and <xref ref-type="fig" rid="fig7">Figure 7K</xref> the first three components were used to project the population responses. For <xref ref-type="fig" rid="fig6">Figure 6I</xref>, the fourth PC was used. Projections were obtained by computing the dot product with the eigenvector.</p><p>To assess the dimensionality of the population activity we compared the eigenvalues obtained from the data with those obtained with per-unit time-shuffled matrices. This destroys the time-dependent correlations and thus generates PCs due to chance. We performed this 1000 times and considered first PCs that explained more variance than the time-shuffled ones with a p&lt;0.01 as statistically significant.</p><p>The details and mathematical procedure for dPCA analysis have been outlined elsewhere (<xref ref-type="bibr" rid="bib12">Kobak et al., 2016a</xref>). Briefly, the method decomposes neural activity into the different chosen task variables to produce marginalized covariance matrices. The supervised part of the algorithm consists of choosing the variables to be analyzed. The unsupervised part of the algorithm uses a similar analysis to that of PCA on the marginalized covariance matrices. Our analyses were largely based on an available Python implementation (<ext-link ext-link-type="uri" xlink:href="https://github.com/machenslab/dPCA">https://github.com/machenslab/dPCA</ext-link>, <xref ref-type="bibr" rid="bib13">Kobak et al., 2016b</xref>). In <xref ref-type="fig" rid="fig4">Figure 4</xref> we marginalized the population activity on time (condition-independent dynamics), Side, Difficulty, and Correct vs incorrect.</p><p>The dPCA analysis presented in <xref ref-type="fig" rid="fig5">Figure 5</xref> was performed similarly to that of <xref ref-type="fig" rid="fig3">Figure 3</xref> but using different time periods and conditions. For each session, model trajectories for Go, left and right, were constructed by averaging the body speed and angular velocity. Then, we computed the correlation between the model trajectory and individual trial trajectories, both from the Return and Go periods. We selected those with a correlation coefficient of ≥0.75. Finally, we obtained PETH for the selected, highly similar trajectories.</p><p>For each unit, we obtained four conditions: Return left and right, and Go left and right. With these we constructed a matrix NxCxS, where N is units (n=118), C is context (two conditions, Return vs Go) and S is side (two conditions, left and right). Thus, the marginalizations were performed on the basis of these two variables and time (condition-independent dynamics), mainly to extract the contextual (Return vs Go) population dynamics.</p></sec><sec id="s4-6"><title>Spike - cyclic behavior phase analysis</title><p>We analyzed how spiking was coupled to two cyclic behaviors, gait and licking. For gait, we computed the paw position by projecting the position onto the longitudinal axis of the mouse. We found individual gait cycles by finding the peaks of this signal (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). We used movement periods that had at least four cycles/paces. We applied a band-passed filter (3–6 Hz) to the signal and extracted the instantaneous phase through a Hilbert transform. We then computed the phase at each spike timestamp in a 400 ms window around the peak (which includes around two gait cycles) and generated a spike- gait-phase histogram. This was done with the hindpaw contralateral to recorded hemisphere since hindpaws display a higher amplitude than forepaws. The average vector was computed and tested for directional bias through the Rayleigh test for each of the eight strides analyzed (<xref ref-type="fig" rid="fig6">Figure 6E</xref>). Mean phase and magnitude were computed by averaging the individual per-unit x and y-axis components.</p><p>For licking behavior, we computed the lick probability around an individual lick and applied a 4–10 Hz band-pass filter. This signal was then used to compute the spike - lick-phase in a 400 ms window (around two licks) like that performed with gait.</p></sec><sec id="s4-7"><title>Support vector classifiers (SVCs)</title><p>To understand whether the population could store information for several variables simultaneously we trained SVCs using the implementation in scikit (<xref ref-type="bibr" rid="bib25">Pedregosa et al., 2011</xref>). For gait cycle, the same matrix used for population dimensionality reduction through PCA was used. Each time vector, containing n=118 unit averages was labeled according to the variables analyzed: context, step number, paw position, and paw velocity. Note that continuous signals (position and velocity) were downsampled to five states to allow for 10-fold cross-validation. To assess for statistical significance, we repeated the procedure on data with shuffled labels (n=1000) and assessed the probability of a higher accuracy of the original model. Given that we could not decode paw velocity from the original matrix, we computed the PC4 weighted matrix by using the eigenvector derived from PCA (<xref ref-type="fig" rid="fig6">Figure 6F</xref>).</p><p>For licking we employed the same matrix used for PCA (part of which is shown in <xref ref-type="fig" rid="fig7">Figure 7J</xref>) and trained models for lick phase, left-right licks, lick number, and correct vs incorrect licks. To assess significance, a similar permutation procedure was performed.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Resources, Help with animals and resources adquisition</p></fn><fn fn-type="con" id="con3"><p>Supervision</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Supervision, Funding acquisition, Investigation, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All procedures were approved by the Institutional Committee for the Care and Use of Laboratory Animals at the Instituto de Fisiología Celular (Protocol number FTA-121-17). Universidad Nacional Autónoma de México. and the National Norm for the Useof Animals (NOM-062-ZOO-1999).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Summary statistical table.</title><p>Details of the statistics used for each figure.</p></caption><media xlink:href="elife-98159-supp1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-98159-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Data publicly available: All timestamps data of the current study, instructions and an example code have been made publicly available in <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.14846394">Zenodo</ext-link>. Further information and requests for data and code should be directed to and will be fulfilled by the lead contact, Fatuel Tecuapetla.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Verma-Rodríguez</surname><given-names>AK</given-names></name><name><surname>Tecuapetla</surname><given-names>F</given-names></name><name><surname>Ramírez-Jarquín</surname><given-names>JO</given-names></name><name><surname>Rossi-Pool</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>Basal ganglia output coding - entopeduncular nucleus - of contextual kinematics and reward in the freely moving mouse</data-title><source>Zenodo</source><pub-id pub-id-type="doi">10.5281/zenodo.14846394</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>VRAK is a doctoral student from the Programa de Doctorado en Ciencias Biomédicas, Universidad Nacional Autónoma de México (UNAM) and has received CONAHCyT fellowship CVU 808903. This work was supported by CONACyT grant 220412, Fronteras de la Ciencia CONACyT grants 2022, 2019/154039, CF-2023-I-305, the DGAPA-PAPIIT-UNAM grants IN226517, IN203420, IN203123, and the Moshinsky fellowship to FT. The authors would like to thank A Cesar Poot-Hernández and Carlos A Peralta-Alvaréz from the Bioinformatics Unit for assistance, Gabriel Diaz-deLeon for proofreading the manuscript, and Pavel Rueda-Orozco for helpful discussions.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Albin</surname><given-names>RL</given-names></name><name><surname>Young</surname><given-names>AB</given-names></name><name><surname>Penney</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>The functional anatomy of basal ganglia disorders</article-title><source>Trends in Neurosciences</source><volume>12</volume><fpage>366</fpage><lpage>375</lpage><pub-id pub-id-type="doi">10.1016/0166-2236(89)90074-x</pub-id><pub-id pub-id-type="pmid">2479133</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baker</surname><given-names>KB</given-names></name><name><surname>Lee</surname><given-names>JYK</given-names></name><name><surname>Mavinkurve</surname><given-names>G</given-names></name><name><surname>Russo</surname><given-names>GS</given-names></name><name><surname>Walter</surname><given-names>B</given-names></name><name><surname>DeLong</surname><given-names>MR</given-names></name><name><surname>Bakay</surname><given-names>RAE</given-names></name><name><surname>Vitek</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Somatotopic organization in the internal segment of the globus pallidus in Parkinson’s disease</article-title><source>Experimental Neurology</source><volume>222</volume><fpage>219</fpage><lpage>225</lpage><pub-id pub-id-type="doi">10.1016/j.expneurol.2009.12.030</pub-id><pub-id pub-id-type="pmid">20059997</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Balleine</surname><given-names>BW</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Reward, motivation, and reinforcement learning</article-title><source>Neuron</source><volume>36</volume><fpage>285</fpage><lpage>298</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(02)00963-7</pub-id><pub-id pub-id-type="pmid">12383782</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeLong</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>Activity of pallidal neurons during movement</article-title><source>Journal of Neurophysiology</source><volume>34</volume><fpage>414</fpage><lpage>427</lpage><pub-id pub-id-type="doi">10.1152/jn.1971.34.3.414</pub-id><pub-id pub-id-type="pmid">4997823</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gdowski</surname><given-names>MJ</given-names></name><name><surname>Miller</surname><given-names>LE</given-names></name><name><surname>Parrish</surname><given-names>T</given-names></name><name><surname>Nenonene</surname><given-names>EK</given-names></name><name><surname>Houk</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Context dependency in the globus pallidus internal segment during targeted arm movements</article-title><source>Journal of Neurophysiology</source><volume>85</volume><fpage>998</fpage><lpage>1004</lpage><pub-id pub-id-type="doi">10.1152/jn.2001.85.2.998</pub-id><pub-id pub-id-type="pmid">11160530</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Georgopoulos</surname><given-names>AP</given-names></name><name><surname>DeLong</surname><given-names>MR</given-names></name><name><surname>Crutcher</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Relations between parameters of step-tracking movements and single cell discharge in the globus pallidus and subthalamic nucleus of the behaving monkey</article-title><source>The Journal of Neuroscience</source><volume>3</volume><fpage>1586</fpage><lpage>1598</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.03-08-01586.1983</pub-id><pub-id pub-id-type="pmid">6875658</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guillery</surname><given-names>RW</given-names></name><name><surname>Bergman</surname><given-names>H</given-names></name><name><surname>Feingold</surname><given-names>A</given-names></name><name><surname>Nini</surname><given-names>A</given-names></name><name><surname>Raz</surname><given-names>A</given-names></name><name><surname>Slovin</surname><given-names>H</given-names></name><name><surname>Abeles</surname><given-names>M</given-names></name><name><surname>Vaadia</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Physiological aspects of information processing in the basal ganglia of normal and parkinsonian primates</article-title><source>Trends in Neurosciences</source><volume>21</volume><fpage>32</fpage><lpage>38</lpage><pub-id pub-id-type="doi">10.1016/s0166-2236(97)01151-x</pub-id><pub-id pub-id-type="pmid">9464684</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hintiryan</surname><given-names>H</given-names></name><name><surname>Foster</surname><given-names>NN</given-names></name><name><surname>Bowman</surname><given-names>I</given-names></name><name><surname>Bay</surname><given-names>M</given-names></name><name><surname>Song</surname><given-names>MY</given-names></name><name><surname>Gou</surname><given-names>L</given-names></name><name><surname>Yamashita</surname><given-names>S</given-names></name><name><surname>Bienkowski</surname><given-names>MS</given-names></name><name><surname>Zingg</surname><given-names>B</given-names></name><name><surname>Zhu</surname><given-names>M</given-names></name><name><surname>Yang</surname><given-names>XW</given-names></name><name><surname>Shih</surname><given-names>JC</given-names></name><name><surname>Toga</surname><given-names>AW</given-names></name><name><surname>Dong</surname><given-names>HW</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The mouse cortico-striatal projectome</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>1100</fpage><lpage>1114</lpage><pub-id pub-id-type="doi">10.1038/nn.4332</pub-id><pub-id pub-id-type="pmid">27322419</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hong</surname><given-names>S</given-names></name><name><surname>Hikosaka</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The globus pallidus sends reward-related signals to the lateral habenula</article-title><source>Neuron</source><volume>60</volume><fpage>720</fpage><lpage>729</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.09.035</pub-id><pub-id pub-id-type="pmid">19038227</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunnicutt</surname><given-names>BJ</given-names></name><name><surname>Jongbloets</surname><given-names>BC</given-names></name><name><surname>Birdsong</surname><given-names>WT</given-names></name><name><surname>Gertz</surname><given-names>KJ</given-names></name><name><surname>Zhong</surname><given-names>H</given-names></name><name><surname>Mao</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A comprehensive excitatory input map of the striatum reveals novel functional organization</article-title><source>eLife</source><volume>5</volume><elocation-id>e19103</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.19103</pub-id><pub-id pub-id-type="pmid">27892854</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>HR</given-names></name><name><surname>Malik</surname><given-names>AN</given-names></name><name><surname>Mikhael</surname><given-names>JG</given-names></name><name><surname>Bech</surname><given-names>P</given-names></name><name><surname>Tsutsui-Kimura</surname><given-names>I</given-names></name><name><surname>Sun</surname><given-names>F</given-names></name><name><surname>Zhang</surname><given-names>Y</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Watabe-Uchida</surname><given-names>M</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A unified framework for dopamine signals across timescales</article-title><source>Cell</source><volume>183</volume><fpage>1600</fpage><lpage>1616</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.11.013</pub-id><pub-id pub-id-type="pmid">33248024</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kobak</surname><given-names>D</given-names></name><name><surname>Brendel</surname><given-names>W</given-names></name><name><surname>Constantinidis</surname><given-names>C</given-names></name><name><surname>Feierstein</surname><given-names>CE</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name><name><surname>Qi</surname><given-names>XL</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name></person-group><year iso-8601-date="2016">2016a</year><article-title>Demixed principal component analysis of neural population data</article-title><source>eLife</source><volume>5</volume><elocation-id>e10989</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.10989</pub-id><pub-id pub-id-type="pmid">27067378</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Kobak</surname><given-names>D</given-names></name><name><surname>Brendel</surname><given-names>W</given-names></name><name><surname>Constantinidis</surname><given-names>C</given-names></name><name><surname>Feierstein</surname><given-names>CE</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name><name><surname>Qi</surname><given-names>XL</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name></person-group><year iso-8601-date="2016">2016b</year><data-title>Python</data-title><version designator="639bc14">639bc14</version><source>Github</source><ext-link ext-link-type="uri" xlink:href="https://github.com/machenslab/dPCA">https://github.com/machenslab/dPCA</ext-link></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larsen</surname><given-names>KD</given-names></name><name><surname>McBride</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>The organization of feline entopenduncular nucleus projections: anatomical studies</article-title><source>The Journal of Comparative Neurology</source><volume>184</volume><fpage>293</fpage><lpage>308</lpage><pub-id pub-id-type="doi">10.1002/cne.901840206</pub-id><pub-id pub-id-type="pmid">105022</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lazaridis</surname><given-names>I</given-names></name><name><surname>Tzortzi</surname><given-names>O</given-names></name><name><surname>Weglage</surname><given-names>M</given-names></name><name><surname>Märtin</surname><given-names>A</given-names></name><name><surname>Xuan</surname><given-names>Y</given-names></name><name><surname>Parent</surname><given-names>M</given-names></name><name><surname>Johansson</surname><given-names>Y</given-names></name><name><surname>Fuzik</surname><given-names>J</given-names></name><name><surname>Fürth</surname><given-names>D</given-names></name><name><surname>Fenno</surname><given-names>LE</given-names></name><name><surname>Ramakrishnan</surname><given-names>C</given-names></name><name><surname>Silberberg</surname><given-names>G</given-names></name><name><surname>Deisseroth</surname><given-names>K</given-names></name><name><surname>Carlén</surname><given-names>M</given-names></name><name><surname>Meletis</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A hypothalamus-habenula circuit controls aversion</article-title><source>Molecular Psychiatry</source><volume>24</volume><fpage>1351</fpage><lpage>1368</lpage><pub-id pub-id-type="doi">10.1038/s41380-019-0369-5</pub-id><pub-id pub-id-type="pmid">30755721</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Mamidanna</surname><given-names>P</given-names></name><name><surname>Cury</surname><given-names>KM</given-names></name><name><surname>Abe</surname><given-names>T</given-names></name><name><surname>Murthy</surname><given-names>VN</given-names></name><name><surname>Mathis</surname><given-names>MW</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>DeepLabCut: markerless pose estimation of user-defined body parts with deep learning</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1281</fpage><lpage>1289</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0209-y</pub-id><pub-id pub-id-type="pmid">30127430</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McInnes</surname><given-names>L</given-names></name><name><surname>Healy</surname><given-names>J</given-names></name><name><surname>Saul</surname><given-names>N</given-names></name><name><surname>Großberger</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>UMAP: uniform manifold approximation and projection</article-title><source>Journal of Open Source Software</source><volume>3</volume><elocation-id>861</elocation-id><pub-id pub-id-type="doi">10.21105/joss.00861</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mink</surname><given-names>JW</given-names></name><name><surname>Thach</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Basal ganglia motor control. I. Nonexclusive relation of pallidal discharge to five movement modes</article-title><source>Journal of Neurophysiology</source><volume>65</volume><fpage>273</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1152/jn.1991.65.2.273</pub-id><pub-id pub-id-type="pmid">2016642</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitchell</surname><given-names>SJ</given-names></name><name><surname>Richardson</surname><given-names>RT</given-names></name><name><surname>Baker</surname><given-names>FH</given-names></name><name><surname>DeLong</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>The primate globus pallidus: neuronal activity related to direction of movement</article-title><source>Experimental Brain Research</source><volume>68</volume><fpage>491</fpage><lpage>505</lpage><pub-id pub-id-type="doi">10.1007/BF00249793</pub-id><pub-id pub-id-type="pmid">3691721</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mullié</surname><given-names>Y</given-names></name><name><surname>Arto</surname><given-names>I</given-names></name><name><surname>Yahiaoui</surname><given-names>N</given-names></name><name><surname>Drew</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Contribution of the entopeduncular nucleus and the globus pallidus to the control of locomotion and visually guided gait modifications in the cat</article-title><source>Cerebral Cortex</source><volume>30</volume><fpage>5121</fpage><lpage>5146</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhaa106</pub-id><pub-id pub-id-type="pmid">32377665</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Musall</surname><given-names>S</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Juavinett</surname><given-names>AL</given-names></name><name><surname>Gluf</surname><given-names>S</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Single-trial neural dynamics are dominated by richly varied movements</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1677</fpage><lpage>1686</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0502-4</pub-id><pub-id pub-id-type="pmid">31551604</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nambu</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Somatotopic organization of the primate basal ganglia</article-title><source>Frontiers in Neuroanatomy</source><volume>5</volume><elocation-id>26</elocation-id><pub-id pub-id-type="doi">10.3389/fnana.2011.00026</pub-id><pub-id pub-id-type="pmid">21541304</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nambu</surname><given-names>A</given-names></name><name><surname>Chiken</surname><given-names>S</given-names></name><name><surname>Sano</surname><given-names>H</given-names></name><name><surname>Hatanaka</surname><given-names>N</given-names></name><name><surname>Obeso</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Dynamic activity model of movement disorders: the fundamental role of the hyperdirect pathway</article-title><source>Movement Disorders</source><volume>38</volume><fpage>2145</fpage><lpage>2150</lpage><pub-id pub-id-type="doi">10.1002/mds.29646</pub-id><pub-id pub-id-type="pmid">37986211</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parent</surname><given-names>M</given-names></name><name><surname>Lévesque</surname><given-names>M</given-names></name><name><surname>Parent</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The pallidofugal projection system in primates: evidence for neurons branching ipsilaterally and contralaterally to the thalamus and brainstem</article-title><source>Journal of Chemical Neuroanatomy</source><volume>16</volume><fpage>153</fpage><lpage>165</lpage><pub-id pub-id-type="doi">10.1016/s0891-0618(99)00008-3</pub-id><pub-id pub-id-type="pmid">10422736</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Michel</surname><given-names>V</given-names></name><name><surname>Thirion</surname><given-names>B</given-names></name><name><surname>Grisel</surname><given-names>O</given-names></name><name><surname>Blondel</surname><given-names>M</given-names></name><name><surname>Prettenhofer</surname><given-names>P</given-names></name><name><surname>Weiss</surname><given-names>R</given-names></name><name><surname>Dubourg</surname><given-names>V</given-names></name><name><surname>Vanderplas</surname><given-names>J</given-names></name><name><surname>Passos</surname><given-names>A</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Brucher</surname><given-names>M</given-names></name><name><surname>Perrot</surname><given-names>M</given-names></name><name><surname>Duchesnay</surname><given-names>É</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Scikit-learn: machine learning in python</article-title><source>Journal of Machine Learning Research</source><volume>12</volume><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwab</surname><given-names>BC</given-names></name><name><surname>Kase</surname><given-names>D</given-names></name><name><surname>Zimnik</surname><given-names>A</given-names></name><name><surname>Rosenbaum</surname><given-names>R</given-names></name><name><surname>Codianni</surname><given-names>MG</given-names></name><name><surname>Rubin</surname><given-names>JE</given-names></name><name><surname>Turner</surname><given-names>RS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neural activity during a simple reaching task in macaques is counter to gating and rebound in basal ganglia-thalamic communication</article-title><source>PLOS Biology</source><volume>18</volume><elocation-id>e3000829</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3000829</pub-id><pub-id pub-id-type="pmid">33048920</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stephenson-Jones</surname><given-names>M</given-names></name><name><surname>Yu</surname><given-names>K</given-names></name><name><surname>Ahrens</surname><given-names>S</given-names></name><name><surname>Tucciarone</surname><given-names>JM</given-names></name><name><surname>van Huijstee</surname><given-names>AN</given-names></name><name><surname>Mejia</surname><given-names>LA</given-names></name><name><surname>Penzo</surname><given-names>MA</given-names></name><name><surname>Tai</surname><given-names>LH</given-names></name><name><surname>Wilbrecht</surname><given-names>L</given-names></name><name><surname>Li</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A basal ganglia circuit for evaluating action outcomes</article-title><source>Nature</source><volume>539</volume><fpage>289</fpage><lpage>293</lpage><pub-id pub-id-type="doi">10.1038/nature19845</pub-id><pub-id pub-id-type="pmid">27652894</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thura</surname><given-names>D</given-names></name><name><surname>Cisek</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The basal ganglia do not select reach targets but control the urgency of commitment</article-title><source>Neuron</source><volume>95</volume><fpage>1160</fpage><lpage>1170</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.07.039</pub-id><pub-id pub-id-type="pmid">28823728</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turner</surname><given-names>RS</given-names></name><name><surname>Anderson</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Context-dependent modulation of movement-related discharge in the primate globus pallidus</article-title><source>The Journal of Neuroscience</source><volume>25</volume><fpage>2965</fpage><lpage>2976</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4036-04.2005</pub-id><pub-id pub-id-type="pmid">15772356</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wallace</surname><given-names>ML</given-names></name><name><surname>Saunders</surname><given-names>A</given-names></name><name><surname>Huang</surname><given-names>KW</given-names></name><name><surname>Philson</surname><given-names>AC</given-names></name><name><surname>Goldman</surname><given-names>M</given-names></name><name><surname>Macosko</surname><given-names>EZ</given-names></name><name><surname>McCarroll</surname><given-names>SA</given-names></name><name><surname>Sabatini</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Genetically distinct parallel pathways in the entopeduncular nucleus for limbic and sensorimotor output of the basal ganglia</article-title><source>Neuron</source><volume>94</volume><fpage>138</fpage><lpage>152</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.03.017</pub-id><pub-id pub-id-type="pmid">28384468</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.98159.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Uchida</surname><given-names>Naoshige</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Harvard University</institution><country>United States</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Valuable</kwd></kwd-group></front-stub><body><p>This <bold>valuable</bold> study reports on electrophysiological recording of the spiking activity of single neurons in the entopeduncular nucleus (EPN) in freely-moving mice performing an auditory discrimination task. The data show that the activity of single EPN neurons is modulated by reward and movement kinematics, with the latter further affected by task contexts (e.g. movement toward or away from a reward location). The results provide <bold>solid</bold> evidence for the conclusions. There is some ambiguity as to whether the data contain the population of EPN neurons characterized in previous studies that obtained different results. Investigations separating confounding factors would be of benefit. Nonetheless, the work is overall of interest to those who study how the basal ganglia, particularly the EPN, contribute to behavior.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.98159.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>The authors in this paper investigate the nature of the activity in the rodent EPN during a simple freely moving cue-reward association task. Given that primate literature suggest movement coding whereas other primate and rodent studies suggest mainly reward outcome coding in the EPNs, it is important try to tease apart the two views. Through careful analysis of behavior kinematics, position, and the neural activity in the EPNs, the authors reveal an interesting and complex relationship between the EPN and mouse behavior.</p><p>Strengths:</p><p>(1) The authors use a novel freely moving task to study EPN activity, which displays rich movement trajectories and kinematics. Given that previous studies have mostly looked at reward coding during head fixed behavior, this study adds a valuable dataset to the literature.</p><p>(2) The neural analysis is rich and thorough. Both single neuron level and population level (i.e. PCA) analysis are employed to reveal what EPN encodes.</p><p>Discussion:</p><p>EPN is one of the major output nuclei of the basal ganglia. What information is present within EPN is still unclear, and under investigation. The authors have used electrophysiology to determine the nature of information present within EPN that is likely to be valuable to the field. Future studies should try to address whether this information is specific to certain cell types within EPN or whether there is topography within EPN that reflects the kinematic information present within EPN. This will require more careful dissection of EPN activity based on anatomy. Future experiments should also consider tasks that isolate a single limb (i.e. joystick tasks) in order to better understand the kinematic encoding of forelimb movement. This, combined with recording in forelimb encoding region of EPN, should give us insights into the nature of kinematic control of EPN. Overall, this study will be useful to inspire future investigations in the function of EPN.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.98159.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>This paper examined how the activity of neurons in the entopeduncular nucleus (EPN) of mice relates to kinematics, value, and reward. The authors recorded neural activity during an auditory cued two-alternative choice task, allowing them to examine how neuronal firing relates to specific movements like licking or paw movements, as well as how contextual factors like task stage or proximity to a goal influence the coding of kinematic and spatiotemporal features. The data shows that the firing of individual neurons is linked to kinematic features such as lick or step cycles. However, the majority of neurons exhibited activity related to both movement types, suggesting that EPN neuronal activity does not merely reflect muscle-level representations. This contradicts what would be expected from traditional action selection or action specification models of the basal ganglia.</p><p>The authors also show that spatiotemporal variables account for more variability compared to kinematic features alone. Using demixed Principal Component Analysis, they reveal that at the population level, the three principal components explaining the most variance were related to specific temporal or spatial features of the task, such as ramping activity as mice approached reward ports, rather than trial outcome or specific actions. Notably, this activity was present in neurons whose firing was also modulated by kinematic features, demonstrating that individual EPN neurons integrate multiple features. A weakness is that what the spatiotemporal activity reflects is not well specified. The authors suggest some may relate to action value due to greater modulation when approaching a reward port, but acknowledge action value is not well parametrized or separated from variables like reward expectation.</p><p>A key goal was to determine whether activity related to expected value and reward delivery arose from a distinct population of EPN neurons or was also present in neurons modulated by kinematic and spatiotemporal features. In contrast to previous studies (Hong &amp; Hikosaka 2008 and Stephenson-Jones et al., 2016), the current data reveals that individual neurons can exhibit modulation by both reward and kinematic parameters. Two potential differences may explain this discrepancy: First, the previous studies used head-fixed recordings, where it may have been easier to isolate movement versus reward-related responses. Second, those studies observed prominent phasic responses to the delivery or omission of expected rewards - responses that are present but not common in the current paper. This suggests a possibility that the VGlut2+ EPN neurons that project to the LHb were under/not sampled, antidromic or optogenetic tagging would have been needed to confirm the identity of the populations that were recorded. Alternatively, in the head-fixed recordings, kinematic/spatial coding may have gone undetected due to the forced immobility.</p><p>Overall, this paper offers needed insight into how the basal ganglia output encodes behavior. The EPN recordings from freely moving mice clearly demonstrate that individual neurons integrate reward, kinematic, and spatiotemporal features, challenging traditional models. However, the specific relationship between the spatiotemporal activity and factors like action value remains unclear.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.98159.3.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Verma Rodriguez</surname><given-names>Anil Kumar</given-names></name><role specific-use="author">Author</role><aff><institution>National Autonomous University of Mexico</institution><addr-line><named-content content-type="city">Mexico</named-content></addr-line><country>Mexico</country></aff></contrib><contrib contrib-type="author"><name><surname>Ramírez-Jarquin</surname><given-names>Josue O</given-names></name><role specific-use="author">Author</role><aff><institution>National Autonomous University of Mexico</institution><addr-line><named-content content-type="city">Mexico</named-content></addr-line><country>Mexico</country></aff></contrib><contrib contrib-type="author"><name><surname>Rossi-Pool</surname><given-names>Román</given-names></name><role specific-use="author">Author</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01tmp8f25</institution-id><institution>Universidad Nacional Autónoma de México</institution></institution-wrap><addr-line><named-content content-type="city">Mexico City</named-content></addr-line><country>Mexico</country></aff></contrib><contrib contrib-type="author"><name><surname>Tecuapetla</surname><given-names>Fatuel</given-names></name><role specific-use="author">Author</role><aff><institution>National Autonomous University of Mexico</institution><addr-line><named-content content-type="city">Mexico</named-content></addr-line><country>Mexico</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Public Review):</bold></p><p>The authors in this paper investigate the nature of the activity in the rodent EPN during a simple freely moving cue-reward association task. Given that primate literature suggests movement coding whereas other primate and rodent studies suggest mainly reward outcome coding in the EPNs, it is important to try to tease apart the two views. Through careful analysis of behavior kinematics, position, and neural activity in the EPNs, the authors reveal an interesting and complex relationship between the EPN and mouse behavior.</p><p>Strengths:</p><p>(1) The authors use a novel freely moving task to study EPN activity, which displays rich movement trajectories and kinematics. Given that previous studies have mostly looked at reward coding during head-fixed behavior, this study adds a valuable dataset to the literature. (2) The neural analysis is rich and thorough. Both single neuron level and population level (i.e. PCA) analysis are employed to reveal what EPN encodes.</p></disp-quote><p>Thank you very much for this appreciation.</p><disp-quote content-type="editor-comment"><p>Weaknesses:</p><p>(1) One major weakness in this paper is the way the authors define the EPN neurons. Without a clear method of delineating EPN vs other surrounding regions, it is not convincing enough to call these neurons EPNs solely from looking at the electrode cannula track from Figure 2B. Indeed, EPN is a very small nucleus and previous studies like Stephenson-Jones et al (2016) have used opto-tagging of Vglut2 neurons to precisely label EPN single neurons. Wallace et al (2017) have also shown the existence of SOM and PV-positive neurons in the EPN. By not using transgenic lines and cell-type specific approaches to label these EPN neurons, the authors miss the opportunity to claim that the neurons recorded in this study do indeed come from EPN. The authors should at least consider showing an analysis of neurons slightly above or below EPN and show that these neurons display different waveforms or firing patterns.</p></disp-quote><p>We thank the reviewer for their comment, and we thank the opportunity to expand on the inclusion criteria of studied units after providing an explanation.</p><p>As part of another study, we performed experiments recording in EPN with optrodes and photoidentification in PV-Cre animals. We found optoidentified units in both: animals with correct placement (within the EPN) and on those with off-target placement (within the thalamus or medial to the EPN). Thus, despite the use of Cre animals, we relied on histology to ensure correct EPN recording. We believe that the optotagging based purely on neural makers such as PV, SOM, VGLUT, VGAT would not provide a better anatomical delineation of the EPN since adjacent structures are rich in those same markers. The thalamic reticular nucleus is just dorsal to the EPN and it has been shown to express both SOM and PV (Martinez-Garcia et al., 2020).</p><p>On the other hand, the lateral hypothalamus (just medial to the EPN) also expresses vGlut2 and SOM. Stephenson-Jones (2016), Extended Data Figure 1, panel g, shows vGluT2 and somatostatin labeling of neurons, with important expression of neurons dorsal, ventral and medial to the EPN. Thus, we believe that viral strategies relying on single neuronal markers still depend on careful histological analysis of recording sites.</p><p>A combination of neural markers or more complex viral strategies might be more suitable to delineate the EPN. As an example, for anatomical tracing Stephenson-Jones et al. 2016 performed a rabies-virus based approach involving retrogradely transported virus making use of projection sites through two injections. Two step viral approaches were also performed in Wallace, M. et al. 2017. We attempted to perform a two-step viral approach, using an anterogradely transported Cre-expressing virus (AAV1.hSyn.Cre.WPRE.hGH) injected into the striatum and a second Cre dependent ChR2 into the EPN. However, our preliminary experiments showed that this double viral approach had a stark effect decreasing the performance of animals during the task (we attempted re-training 2-3 weeks after viral infections and animals failed to turn to the contralateral side of the injections). We believe that this approach might have had a toxic effect (Zingg et al., 2017).</p><p>To this point, a recent paper (Lazaridis et al., 2019) repeated an optogenetic experiment performed in the Stephenson-Jones et al. study, using a set of different viral approaches and concluded that increasing the activity of GPi-LHb is not aversive, as it had been previously reported. Thus, future studies attempting to increase anatomical specificity are a must, but they will require using viral approaches amenable to the behavioral paradigm.</p><p>We attempted to find properties regarding waveforms, firing rate, and firing patterns from units above or below, however, we did not find a marker that could generate a clear demarcation. We show here a figure that includes the included units in this study as well as excluded ones to show that there is a clear overlap.</p><fig id="sa3fig1" position="float"><label>Author response image 1.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-98159-sa3-fig1-v1.tif"/></fig><p>Finally, we completely agree with the reviewer in that there is still room for improvement. We have further expanded the Methods section to explain better our efforts to include units recorded within the EPN. Further, we have added a paragraph within the Discussion section to point out this limitation.</p><p>Methods:</p><p>“Recordings. Movable microwire bundles (16 microwires, 32 micrometers in diameter, held inside a cannula, Innovative Neurophysiology, Durham, NC) were stereotaxtically implanted just above the entopeduncular nucleus (-0.8 AP, 1.7 ML, 3.9 DV). Post surgical care included antibiotic, analgesic and antiinflammatory pharmacological treatment. After 5 days of recovery, animals were retrained for 1-2 weeks. Unitary activity was recorded for 2-6 days at each dorsoventral electrode position and the session with the best electrophysiological (signal to noise ratio (&gt;2), stability across time) and behavioral [performance, number of trials (&gt;220)] quality was selected. Microwire electrodes were advanced in 50 micrometer dorsoventral steps for 500 micrometers in total. After experiment completion, animals were perfused with a 4% paraformaldehyde solution. Brains were extracted, dehydrated with a 30% sucrose solution and sectioned in a cryostat into 30micron thick slices. Slices were mounted and photographed using a light microscope. Microwire tracks of the 16-microwire bundle were analyzed (Fig. 2A-B) and only animals with tracks traversing the EPN were selected (6 out of 10). Finally, we located the final position of microwire tips and inferred the dorsoventral recording position of each of the recording sessions. Only units recorded within the EPN were included.”</p><p>Discussion:</p><p>“A weakness of the current study is the lack of characterization of neuronal subtypes. An area of opportunity for future research could be to perform photo-identification of neuronal subtypes within the EPN which could contribute to the overall description of the information representation. Further, detailed anatomical viral vector strategies could aid to improve anatomical localization of recordings, reduce reliance on histological examination, and solve some current controversies (Lazaridis et al., 2019).”</p><disp-quote content-type="editor-comment"><p>(2) The authors fail to replicate the main finding about EPN neurons which is that they encode outcome in a negative manner. Both Stephenson-Jones et al (2016) and Hong and Hikosaka (2008) show a reward response during the outcome period where firing goes down during reward and up during neutral or aversive outcome. However, Figure 2 G top panel shows that the mean population is higher during correct trials and lower during incorrect trials. This could be interesting given that the authors might try recording from another part of EPN that has not been studied before. However, without convincing evidence that the neurons recorded are from EPN in the first place (point 1), it is hard to interpret these results and reconcile them with previous studies.</p></disp-quote><p>We really thank the reviewer for pointing out that we need to better explain how EPN units encode outcome. We now provide an additional panel in Figure 4, its corresponding text in the results section and a new paragraph in the discussion related to this comment.</p><p>We believe that we do indeed recapitulate findings of both of Stephenson-Jones et al (2016) and Hong and Hikosaka (2008). Both studies focus on a specific subpopulation of GPi/EPN neurons that project to the lateral habenula (LHb). Stephenson-Jones et al (2016) posit that GPi-LHb neurons (which they opto-tag as vGluT2) exhibit a decreased firing rate during rewarding outcomes. Hong and Hikosaka (2008) antidromically identified LHb projecting neurons through within the GPi and found reward positive and reward negative neurons, which were respectively modulated either by increasing or decreasing their firing rate with a rewarding outcome (red and green dots on the x-axis of Figure 5A in their paper).</p><p>As the reviewer pointed out the zScore may be misleading. Therefore, in our study we also decomposed population activity on reward axis through dPCA. When marginalizing for reward in Figure 3F, we find that the weights of individual units on this axis are centered around zero, with positive and negative values (Figure 3F, right panel). Thus, units can code a rewarding outcome as either an increase or a decrease of activity. We show example units of such modulation in Figure 3-1g and h.</p><p>We had segregated our analysis of spatio-temporal and kinematic coding upon the reward coding of units in Figure 4L-M. Yet, following this comment and in an effort of further clarifying this segregation, we introduced panels with the mean zScore of units during outcome evaluation in Figure 4L.</p><p>We amended the main text to better explain these findings.</p><p>“Previous reports suggest that EPN units that project to the lateral habenula encode reward as a decrease in firing rate. Thus, we wished to ask whether reward encoding units can code kinematic and spatio-temporal variables as well.</p><p>To this end, we first segregated units upon their reward coding properties: reward positive (which increased activity with reward) and reward negative units (which decreased activity with reward). We performed auROC on the 250ms after head entry comparing rewarded trials and incorrect trails (p&lt;0.001, permutation test). Mean activity of reward insensitive, positive and negative units is shown in Fig. 4L. Next, we performed a dimensionality reduction on the coefficients of the model that best explained both contexts (kinematic + spatio-temporal model on pooled data) using UMAP (McInnes et al., 2018). We observe a continuum rather than discrete clusters (Fig. 4L). Note that individual units are color coded according to their responsivity to reward. We did not find a clear clustering either.”</p><p>Paragraph added in the discussion:</p><p>“In this study, we found that rewarding outcomes can be represented by EPN units through either an increase or a decrease in firing rate (Fig. 3F, 3-1g-h, 4L). While Stephenson-Jones et al., 2016 found that lateral habenula (LHb)-projecting neurons within the EPN of mice primarily encoded rewarding outcomes by a decrease in firing rate, Hong and Hikosaka, 2008 observed that in primates, LHb-projecting units could encode reward through either a decrease or an increase in firing rate. Thus, our results align more closely with the latter study, which also employed an operant conditioning task.”</p><disp-quote content-type="editor-comment"><p>(3) The authors say that: 'reward and kinematic doing are not mutually exclusive, challenging the notion of distinct pathways and movement processing'. However, it is not clear whether the data presented in this work supports this statement. First, the authors have not attempted to record from the entire EPN. Thus it is possible that the coding might be more segregated in other parts of EPN. Second, EPNs have previously been shown to display positive firing for negative outcomes and vice versa, something which the authors do not find here. It is possible that those neurons might not encode kinematic and movement variables. Thus, the authors should point out in the main text the possibility that the EPN activity recorded might be missing some parts of the whole EPN.</p></disp-quote><p>We thank the reviewer for the opportunity to expand on this topic. We believe it is certainly possible that other not-recorded regions of the EPN might exhibit greater segregation of reward and kinematics. However, we considered it worthwhile pointing out that from the dataset collected in this study reward-sensitive units encode kinematics in a similar fashion to reward-insensitive ones (Fig. 4L,M). Moreover, we asked specifically whether reward-negative units (that decrease firing rate with rewarding outcomes, as previously reported) could encode kinematics and spatio-temporal variables with different strength than reward-insensitive ones and could not find significant differences (Fig. 4M).</p><p>We did indeed find units that displayed decreased firing rate upon rewarding outcomes, as has been previously reported. We have addressed this fact more thoroughly in point (2).</p><p>Finally, we agree with the reviewer that the dataset collected in this study is by no means exhaustive of the entire EPN and have thus included a sentence pointing this out in the Discussion section:</p><p>“Given that we did not record from the entire EPN, it is still possible that another region of the nucleus might exhibit more segregation.”</p><disp-quote content-type="editor-comment"><p>(4) The authors use an IR beam system to record licks and make a strong claim about the nature of lick encoding in the EPN. However, the authors should note that IR beam system is not the most accurate way of detecting licks given that any object blocking the path (paw or jaw-dropping) will be detected as lick events. Capacitance based, closed-loop detection, or video capturing is better suited to detect individual licks. Given that the authors are interested in kinematics of licking, this is important. The authors should either point this out in the main text or verify in the system if the IR beam is correctly detecting licks using a combination of those methods.</p></disp-quote><p>We thank the reviewer for the opportunity of clarifying the lick event acquisition. We have experience using electrical alternatives to lickometers; however, we believe they were not best suited to this application. Closed-loop lickometers generally use a metallic grid upon which animals stand so that the loop can be closed; however, we wanted to have a transparent floor. We have found capacitance based lickometers to be useful in head-fixed conditions but have noticed that they are very dependent on animal position and proximity of other bodyparts such as limbs. Given the freely moving aspect of the task this was difficult to control. Finally, both electric alternatives for lickometers are more prone to noise and may introduce electrical artifacts that might contaminate the spiking signal. This is why we opted to use a slit in combination with an IR beam that would only fit the tongue and that forced enough protrusion such that individual licks could be monitored. Further, the slit could not fit other body-parts like the paw or jaw. We have now included a video (Supp. Video 2) showing a closeup of this behavior that better conveys how the jaw and paw do not fit inside the slit. The following text has been added in the corresponding methods section:</p><p>“The lickometer slit was just wide enough to fit the tongue and deep enough to evoke a clear tongue protrusion.”</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p><p>(1)The authors should verify using opto-tagging of either Vglut2, SOM, or PV neurons whether they can see the same firing pattern. If not, the authors should address this weakness in the paper.</p></disp-quote><p>We thank the reviewer for this important point, we have provided a more detailed reply above.</p><disp-quote content-type="editor-comment"><p>(2)The way dPCA or PCA is applied to the data is not stated at all in the main text. Are all units from different mice combined? Or applied separately for each mouse? How does that affect the interpretation of the data? At least a brief text should be included in the main text to guide the readers.</p></disp-quote><p>We thank the reviewer for pointing out this important omission. We have included an explanation in the Methods section and in the Main text.</p><p>Methods:</p><p>“For all population level analyses individual units recorded from all sessions and all animals were pooled to construct pseudo-simultaneous population response of combined data mostly recorded separately.”</p><p>Main text:</p><p>“For population level analyses throughout the study, we pooled recorded units from all animals to construct a pseudo-simultaneous population.”</p><p>Discussion:</p><p>“…(from pooled units from all animals to construct a pseudo-simultaneous population, which assumes homogeneity across subjects)”</p><disp-quote content-type="editor-comment"><p>(3) The authors argue that they do not find 'value coding' in this study. However, the authors never manipulate reward size or probability, but only the uncertainty or difficulty of the task. This might be better termed 'difficulty', and it is difficult to say whether this correlates with value in this task. For instance, mice might be very confident about the choice, even for an intermediate frequency sweep, if the mouse had waited long enough to hear the full sweep. In that case, the difficulty would not correlate with value, given that the mouse will think the value of the port it is going to is high. Thus, authors should avoid using the term value.</p></disp-quote><p>We agree with the reviewer. We have modified the text to specify that difficulty was the variable being studied and added the following sentence in the Discussion:</p><p>“It is still possible that by modifying reward contingencies such as droplet size value coding could be evidenced.”</p><disp-quote content-type="editor-comment"><p>(4) How have the authors obtained Figure 7D bottom panel? It is unclear at all what this correlation represents. Are the authors looking at a correlation between instantaneous firing rate and lick rate during a lick bout?</p></disp-quote><p>We thank the reviewer for pointing out that omission. It is indeed correlation coefficient between the instantaneous firing rate and the instantaneous lick rate for a lick bout. We have included labeling in Figure 7D and pointed this out in the main text:</p><p>“Fig.7D, lower panel shows the correlation coefficient between the instantaneous firing rate and the instantaneous lick rate within a lick bout for all units.”</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public Review):</bold></p><p>This paper examined how the activity of neurons in the entopeduncular nucleus (EPN) of mice relates to kinematics, value, and reward. The authors recorded neural activity during an auditory-cued two-alternative choice task, allowing them to examine how neuronal firing relates to specific movements like licking or paw movements, as well as how contextual factors like task stage or proximity to a goal influence the coding of kinematic and spatiotemporal features. The data shows that the firing of individual neurons is linked to kinematic features such as lick or step cycles. However, the majority of neurons exhibited activity related to both movement types, suggesting that EPN neuronal activity does not merely reflect muscle-level representations. This contradicts what would be expected from traditional action selection or action specification models of the basal ganglia.</p><p>The authors also show that spatiotemporal variables account for more variability compared to kinematic features alone. Using demixed Principal Component Analysis, they reveal that at the population level, the three principal components explaining the most variance were related to specific temporal or spatial features of the task, such as ramping activity as mice approached reward ports, rather than trial outcome or specific actions. Notably, this activity was present in neurons whose firing was also modulated by kinematic features, demonstrating that individual EPN neurons integrate multiple features. A weakness is that what the spatiotemporal activity reflects is not well specified. The authors suggest some may relate to action value due to greater modulation when approaching a reward port, but acknowledge action value is not well parametrized or separated from variables like reward expectation.</p></disp-quote><p>We thank the reviewer for the comment. We indeed believe that further exploring these spatiotemporal signals is important and will be the subject of future studies.</p><disp-quote content-type="editor-comment"><p>A key goal was to determine whether activity related to expected value and reward delivery arose from a distinct population of EPN neurons or was also present in neurons modulated by kinematic and spatiotemporal features. In contrast to previous studies (Hong &amp; Hikosaka 2008 and Stephenson-Jones et al., 2016), the current data reveals that individual neurons can exhibit modulation by both reward and kinematic parameters. Two potential differences may explain this discrepancy: First, the previous studies used head-fixed recordings, where it may have been easier to isolate movement versus reward-related responses. Second, those studies observed prominent phasic responses to the delivery or omission of expected rewards - responses largely absent in the current paper. This absence suggests a possibility that neurons exhibiting such phasic &quot;reward&quot; responses were not sampled, which is plausible since in both primates and rodents, these neurons tend to be located in restricted topographic regions. Alternatively, in the head-fixed recordings, kinematic/spatial coding may have gone undetected due to the forced immobility.</p></disp-quote><p>Thank you for raising this point. Nevertheless, there is some phasic activity associated with reward responses, which can be seen in the new panel in Figure 4L.</p><disp-quote content-type="editor-comment"><p>Overall, this paper offers needed insight into how the basal ganglia output encodes behavior. The EPN recordings from freely moving mice clearly demonstrate that individual neurons integrate reward, kinematic, and spatiotemporal features, challenging traditional models. However, the specific relationship between spatiotemporal activity and factors like action value remains unclear.</p></disp-quote><p>We really appreciate this reviewer for their valuable comments.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p><p>One small suggestion is to make sure that all the panels in the figures are well annotated. I struggled in places to know what certain alignments or groupings meant because they were not labelled. An example would be what do the lines correspond to in the lower panels of Figure 2D and E. I could figure it out from other panels but it would have helped if each panel had better labelling.</p></disp-quote><p>Thanks for pointing this out, we have improved labelling across the figures and corrected the specific example you have pointed out.</p><disp-quote content-type="editor-comment"><p>The paper is very nice though. Congratulations!</p></disp-quote><p>Thank you very much.</p><disp-quote content-type="editor-comment"><p><bold>Editor's note:</bold></p><p>Should you choose to revise your manuscript, please include full statistical reporting including exact p-values wherever possible alongside the summary statistics (test statistic and df) and 95% confidence intervals. These should be reported for all key questions and not only when the p-value is less than 0.05 in the main manuscript.</p></disp-quote><p>We thank the editor for the comment. A statistics table has been added.</p><p>References:</p><p>Lazaridis, I., Tzortzi, O., Weglage, M., Märtin, A., Xuan, Y., Parent, M., Johansson, Y., Fuzik, J., Fürth, D., Fenno, L. E., Ramakrishnan, C., Silberberg, G., Deisseroth, K., Carlén, M., &amp; Meletis, K. (2019). A hypothalamus-habenula circuit controls aversion. Molecular Psychiatry, 24(9), 1351–1368. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41380-019-0369-5">https://doi.org/10.1038/s41380-019-0369-5</ext-link></p><p>Martinez-Garcia, R. I., Voelcker, B., Zaltsman, J. B., Patrick, S. L., Stevens, T. R., Connors, B. W., &amp; Cruikshank, S. J. (2020). Two dynamically distinct circuits drive inhibition in the sensory thalamus. Nature, 583(7818), 813–818. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41586-0202512-5">https://doi.org/10.1038/s41586-0202512-5</ext-link></p><p>McInnes, L., Healy, J., Saul, N., &amp; Großberger, L. (2018). UMAP: Uniform Manifold Approximation and Projection. Journal of Open Source Software, 3(29), 861. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.21105/joss.00861">https://doi.org/10.21105/joss.00861</ext-link></p><p>Zingg, B., Chou, X. lin, Zhang, Z. gang, Mesik, L., Liang, F., Tao, H. W., &amp; Zhang, L. I. (2017). AAV-Mediated Anterograde Transsynaptic Tagging: Mapping Corticocollicular Input-Defined Neural Pathways for Defense Behaviors. Neuron, 93(1), 33–47. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2016.11.045">https://doi.org/10.1016/j.neuron.2016.11.045</ext-link></p></body></sub-article></article>