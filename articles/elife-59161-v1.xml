<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">59161</article-id><article-id pub-id-type="doi">10.7554/eLife.59161</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Analysis of ultrasonic vocalizations from mice using computer vision and machine learning</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-189085"><name><surname>Fonseca</surname><given-names>Antonio H O</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="other" rid="par-9"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-189086"><name><surname>Santana</surname><given-names>Gustavo M</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1897-1625</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="corresp" rid="cor2">*</xref><xref ref-type="other" rid="par-9"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-229378"><name><surname>Bosque Ortiz</surname><given-names>Gabriela M</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="corresp" rid="cor3">*</xref><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-189087"><name><surname>Bampi</surname><given-names>Sérgio</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="corresp" rid="cor4">*</xref><xref ref-type="other" rid="par-8"/><xref ref-type="other" rid="par-9"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-7600"><name><surname>Dietrich</surname><given-names>Marcelo O</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-9781-2221</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="corresp" rid="cor5">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="other" rid="par-3"/><xref ref-type="other" rid="par-4"/><xref ref-type="other" rid="par-5"/><xref ref-type="other" rid="par-6"/><xref ref-type="other" rid="par-7"/><xref ref-type="other" rid="par-8"/><xref ref-type="other" rid="par-9"/><xref ref-type="other" rid="par-10"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">Comparative Medicine</institution>, <institution>Yale University</institution>, <addr-line><named-content content-type="city">New Haven</named-content></addr-line>, <country>United States</country></aff><aff id="aff2"><institution content-type="dept">Comparative Medicine</institution>, <institution>Yale University School of Medicine</institution>, <addr-line><named-content content-type="city">New Haven</named-content></addr-line>, <country>United States</country></aff><aff id="aff3"><institution content-type="dept">Computer Sciences</institution>, <institution>Universidade Federal do Rio Grande do Sul</institution>, <addr-line><named-content content-type="city">Porto Alegre</named-content></addr-line>, <country>Brazil</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-1374"><name><surname>Kimchi</surname><given-names>Tali</given-names></name><role>Reviewing editor</role><aff><institution>Weizmann Institute of Science</institution>, <country>Israel</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>antonio.fonseca@yale.edu</email> (AF);</corresp><corresp id="cor2"><label>*</label>For correspondence: <email>gustavo.santana@yale.edu</email> (GS);</corresp><corresp id="cor3"><label>*</label>For correspondence: <email>gabriela.borque@yale.edu</email> (GB);</corresp><corresp id="cor4"><label>*</label>For correspondence: <email>bampi@inf.ufrgs.br</email> (SB);</corresp><corresp id="cor5"><label>*</label>For correspondence: <email>marcelo.dietrich@yale.edu</email> (MD);</corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>31</day><month>03</month><year>2021</year></pub-date><volume>10</volume><elocation-id>e59161</elocation-id><history><date date-type="received"><day>21</day><month>05</month><year>2020</year></date><date date-type="accepted"><day>30</day><month>03</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Fonseca et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Fonseca et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> permitting unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-59161-v1.pdf"/><abstract><p>Mice emit ultrasonic vocalizations (USV) that communicate socially-relevant information. To detect and classify these USVs, here we describe VocalMat. VocalMat is a software that uses image-processing and differential geometry approaches to detect USVs in audio files, eliminating the need for user-defined parameters. VocalMat also uses computational vision and machine learning methods to classify USVs into distinct categories. In a dataset of &gt;4,000 USVs emitted by mice, VocalMat detected over 98% of manually labeled USVs and accurately classified ~86% of the USVs out of eleven USV categories. We then used dimensionality reduction tools to analyze the probability distribution of USV classification among different experimental groups, providing a robust method to quantify and qualify the vocal repertoire of mice. Thus, VocalMat makes it possible to perform automated, accurate, and quantitative analysis of USVs without the need for user inputs, opening the opportunity for detailed and high-throughput analysis of this behavior.</p></abstract><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000062</institution-id><institution>National Institute of Diabetes and Digestive and Kidney Diseases</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Dietrich</surname><given-names>Marcelo O</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000011</institution-id><institution>Howard Hughes Medical Institute</institution></institution-wrap></funding-source><award-id>Gilliam Fellowship</award-id><principal-award-recipient><name><surname>Bosque Ortiz</surname><given-names>Gabriela M</given-names></name><name><surname>Dietrich</surname><given-names>Marcelo O</given-names></name></principal-award-recipient></award-group><award-group id="par-3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000874</institution-id><institution>Brain and Behavior Research Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Dietrich</surname><given-names>Marcelo O</given-names></name></principal-award-recipient></award-group><award-group id="par-4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100001391</institution-id><institution>Whitehall Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Dietrich</surname><given-names>Marcelo O</given-names></name></principal-award-recipient></award-group><award-group id="par-5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100001680</institution-id><institution>Charles H. Hood Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Dietrich</surname><given-names>Marcelo O</given-names></name></principal-award-recipient></award-group><award-group id="par-6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100002889</institution-id><institution>Foundation for Prader-Willi Research</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Dietrich</surname><given-names>Marcelo O</given-names></name></principal-award-recipient></award-group><award-group id="par-7"><funding-source><institution-wrap><institution>Reginald and Michiko Spector Award in Neuroscience</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Dietrich</surname><given-names>Marcelo O</given-names></name></principal-award-recipient></award-group><award-group id="par-8"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003593</institution-id><institution>Conselho Nacional de Desenvolvimento Científico e Tecnológico</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Bampi</surname><given-names>Sérgio</given-names></name><name><surname>Dietrich</surname><given-names>Marcelo O</given-names></name></principal-award-recipient></award-group><award-group id="par-9"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100002322</institution-id><institution>Coordenação de Aperfeiçoamento de Pessoal de Nível Superior</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Fonseca</surname><given-names>Antonio H O</given-names></name><name><surname>Santana</surname><given-names>Gustavo M</given-names></name><name><surname>Bampi</surname><given-names>Sérgio</given-names></name><name><surname>Dietrich</surname><given-names>Marcelo O</given-names></name></principal-award-recipient></award-group><award-group id="par-10"><funding-source><institution-wrap><institution>Yale Center for Clinical Investigation Scholar Award</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Dietrich</surname><given-names>Marcelo O</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group></article-meta></front><back><sec id="s1" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interest</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: This study was performed in strict accordance with the recommendations in the Guide for the Care and Use of Laboratory Animals of the National Institutes of Health.  The protocol was reviewed and approved by the Yale University Institutional Animal Care and Use Committee (IACUC). All of the animals were handled according to the approved IACUC protocol (#2018-20042) of the Yale University School of Medicine.</p></fn></fn-group></sec><sec id="s2" sec-type="supplementary-material"><title>Additional Files</title><sec id="s3" sec-type="data-availability"><title>Data availability</title><p>All the data and code used in this work is publicly available and can be found in the links below: https://osf.io/bk2uj/https://www.dietrich-lab.org/vocalmatThis information is also present in the manuscript at section 4.12 (Code and data availability).</p><p>The following datasets were generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><collab>Antonio Fonseca Gustavo Madeira Santana Sergio Bampi Marcelo Dietrich</collab></person-group><year iso-8601-date="2020">2020</year><source>USV training set</source><ext-link ext-link-type="uri" xlink:href="https://osf.io/bk2uj/">https://osf.io/bk2uj/</ext-link><comment>OSF, bk2uj</comment></element-citation></p></sec><supplementary-material><ext-link xlink:href="elife-59161-supp-v1.zip">Download zip</ext-link><p>Any figures and tables for this article are included in the PDF. The zip folder contains additional supplemental files.</p></supplementary-material></sec></back></article>