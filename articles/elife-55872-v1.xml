<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">55872</article-id><article-id pub-id-type="doi">10.7554/eLife.55872</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Reinforcement regulates timing variability in thalamus</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-174628"><name><surname>Wang</surname><given-names>Jing</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4761-6748</contrib-id><email>jingwang.physics@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-174629"><name><surname>Hosseini</surname><given-names>Eghbal</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0088-9765</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-174630"><name><surname>Meirhaeghe</surname><given-names>Nicolas</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-3785-0696</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-174631"><name><surname>Akkad</surname><given-names>Adam</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-13702"><name><surname>Jazayeri</surname><given-names>Mehrdad</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9764-6961</contrib-id><email>mjaz@mit.edu</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Department of Bioengineering, University of Missouri</institution><addr-line><named-content content-type="city">Columbia</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>McGovern Institute for Brain Research, Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology</institution><addr-line><named-content content-type="city">Cambridge</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution>Harvard-MIT Division of Health Sciences and Technology</institution><addr-line><named-content content-type="city">Cambridge</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Wei</surname><given-names>Kunlin</given-names></name><role>Reviewing Editor</role><aff><institution>Peking University</institution><country>China</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution>Brown University</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>01</day><month>12</month><year>2020</year></pub-date><pub-date pub-type="collection"><year>2020</year></pub-date><volume>9</volume><elocation-id>e55872</elocation-id><history><date date-type="received" iso-8601-date="2020-02-08"><day>08</day><month>02</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2020-11-06"><day>06</day><month>11</month><year>2020</year></date></history><permissions><copyright-statement>Â© 2020, Wang et al</copyright-statement><copyright-year>2020</copyright-year><copyright-holder>Wang et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-55872-v1.pdf"/><abstract><p>Learning reduces variability but variability can facilitate learning. This paradoxical relationship has made it challenging to tease apart sources of variability that degrade performance from those that improve it. We tackled this question in a context-dependent timing task requiring humans and monkeys to flexibly produce different time intervals with different effectors. We identified two opposing factors contributing to timing variability: slow memory fluctuation that degrades performance and reward-dependent exploratory behavior that improves performance. Signatures of these opposing factors were evident across populations of neurons in the dorsomedial frontal cortex (DMFC), DMFC-projecting neurons in the ventrolateral thalamus, and putative target of DMFC in the caudate. However, only in the thalamus were the performance-optimizing regulation of variability aligned to the slow performance-degrading memory fluctuations. These findings reveal how variability caused by exploratory behavior might help to mitigate other undesirable sources of variability and highlight a potential role for thalamocortical projections in this process.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>reinforcement learning</kwd><kwd>behavioral variability</kwd><kwd>timing</kwd><kwd>Thalamus</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000065</institution-id><institution>National Institute of Neurological Disorders and Stroke</institution></institution-wrap></funding-source><award-id>NINDS-NS078127</award-id><principal-award-recipient><name><surname>Jazayeri</surname><given-names>Mehrdad</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>325542</award-id><principal-award-recipient><name><surname>Jazayeri</surname><given-names>Mehrdad</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>542993SPI</award-id><principal-award-recipient><name><surname>Jazayeri</surname><given-names>Mehrdad</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000872</institution-id><institution>McKnight Endowment Fund for Neuroscience</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Jazayeri</surname><given-names>Mehrdad</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100001207</institution-id><institution>Esther A. and Joseph Klingenstein Fund</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Jazayeri</surname><given-names>Mehrdad</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>When behavioral outcomes are unfavorable, the brain searches for better outcomes by deliberately increasing its internal variability.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>While interacting with a dynamic and uncertain environment, humans and animals routinely rely on trial-and-error learning strategies to optimize their behavior. This type of learning is most rigorously formulated within the framework of reinforcement learning (RL). The key idea behind RL is to compute a value function for all possible actions based on previous outcomes, and use those action-outcome relationships to guide future actions (<xref ref-type="bibr" rid="bib107">Sutton and Barto, 1998</xref>). RL has been extremely valuable in explaining behavior when an agent has to choose among a small number of discrete options, such as classic multi-armed bandit problems (<xref ref-type="bibr" rid="bib20">Daw et al., 2005</xref>). However, learning through trial and error is also critical whenÂ the action space is large and continuous (<xref ref-type="bibr" rid="bib23">Dhawale et al., 2017</xref>). A case in point is when the agent has to adjust the kinematics of its movements based on binary or scalar (unsigned) feedback (<xref ref-type="bibr" rid="bib49">Izawa and Shadmehr, 2011</xref>; <xref ref-type="bibr" rid="bib99">Shmuelof et al., 2012a</xref>; <xref ref-type="bibr" rid="bib19">Dam et al., 2013</xref>; <xref ref-type="bibr" rid="bib124">Wu et al., 2014</xref>; <xref ref-type="bibr" rid="bib84">Nikooyan and Ahmed, 2015</xref>; <xref ref-type="bibr" rid="bib89">Pekny et al., 2015</xref>; <xref ref-type="bibr" rid="bib12">Chen et al., 2017</xref>). In this case, classic RL is not feasible as it requires the agent to compute the value function over an infinitude of parameters (e.g. all the kinematic variablesÂ associated with a reach and grasp movement). Moreover, in a continuous state space, errors, no matter how small, interfereÂ withÂ the agentâs ability to update action-outcome relationships.</p><p>How do humans and animals employ trial-and-error learning strategies when the space of possibilities is continuous? One intriguing hypothesis is that the brain directly regulates variability to facilitate learning (<xref ref-type="bibr" rid="bib54">Kao et al., 2005</xref>; <xref ref-type="bibr" rid="bib85">Ãlveczky et al., 2005</xref>; <xref ref-type="bibr" rid="bib111">Tumer and Brainard, 2007</xref>; <xref ref-type="bibr" rid="bib44">Huang et al., 2011</xref>). The basic idea is that the agent reduces variability when a trial yields reward (i.e. exploit previously rewarded action) and increases variability in the absence of reward (i.e. explore new possibilities). This strategy captures the spirit of RL in moderating exploration versus exploitation without computing a continuous value function. Several indirect lines of evidence support this hypothesis (<xref ref-type="bibr" rid="bib87">Palidis et al., 2019</xref>; <xref ref-type="bibr" rid="bib49">Izawa and Shadmehr, 2011</xref>; <xref ref-type="bibr" rid="bib99">Shmuelof et al., 2012a</xref>; <xref ref-type="bibr" rid="bib100">Shmuelof et al., 2012b</xref>; <xref ref-type="bibr" rid="bib19">Dam et al., 2013</xref>; <xref ref-type="bibr" rid="bib124">Wu et al., 2014</xref>; <xref ref-type="bibr" rid="bib84">Nikooyan and Ahmed, 2015</xref>; <xref ref-type="bibr" rid="bib89">Pekny et al., 2015</xref>; <xref ref-type="bibr" rid="bib114">Vaswani et al., 2015</xref>; <xref ref-type="bibr" rid="bib8">Cashaback et al., 2017</xref>; <xref ref-type="bibr" rid="bib9">Cashaback et al., 2019</xref>; <xref ref-type="bibr" rid="bib12">Chen et al., 2017</xref>; <xref ref-type="bibr" rid="bib24">Dhawale et al., 2019</xref>; <xref ref-type="bibr" rid="bib113">van der Kooij and Smeets, 2019</xref>). For example, humans learn more efficiently if the structure of their natural movement variability aligns with the underlying learning objective (<xref ref-type="bibr" rid="bib124">Wu et al., 2014</xref>), reaching movements become more variable during periods of low success rate (<xref ref-type="bibr" rid="bib49">Izawa and Shadmehr, 2011</xref>; <xref ref-type="bibr" rid="bib89">Pekny et al., 2015</xref>), and saccadesÂ become more variable in the absence of reward (<xref ref-type="bibr" rid="bib108">Takikawa et al., 2002</xref>).</p><p>However, the relationship between variability and learning is nuanced. Although increasing motor variability may play a direct role in the induction of learning (<xref ref-type="bibr" rid="bib23">Dhawale et al., 2017</xref>), one of the primary functions of motor learning is to reduce variability (<xref ref-type="bibr" rid="bib18">Crossman, 1959</xref>; <xref ref-type="bibr" rid="bib39">Harris and Wolpert, 1998</xref>; <xref ref-type="bibr" rid="bib110">Thoroughman and Shadmehr, 2000</xref>; <xref ref-type="bibr" rid="bib102">Smith et al., 2006</xref>; <xref ref-type="bibr" rid="bib105">Sternad and Abe, 2010</xref>; <xref ref-type="bibr" rid="bib115">Verstynen and Sabes, 2011</xref>). This two-sided relationship between learning and variability has made it challenging to tease apart behavioral and neural signatures of variability that degrade performance from those that improve it. A rigorous assessment of the interaction between learning and variability demands two important developments. First, we need a method for teasing apart sources of variability that hinder performance from those that facilitate learning. Second, we need to verify that the underlying neural circuits rely on reinforcement to regulate the variability along task-relevant dimensions. Here, we addressed these problems usingÂ a motor timing task in which monkeys produced different time intervals using different effectors. We first analyzed behavior and found evidence for multiple sources of motor variability, includingÂ memory drift and reward-dependent exploration. We then developed a generative model thatÂ couldÂ explain how reward regulates variability and facilitates learning. Finally, we probed the underlying neural circuits in multiple nodes of the cortico-basal ganglia circuits implicated in motor timing (<xref ref-type="bibr" rid="bib119">Wang et al., 2018</xref>) andÂ foundÂ that the variability across the population of thalamic neurons with projections to the dorsomedial frontal cortex (DMFC) was modulatedÂ by reward along task-relevant dimensions in a context-specific manner.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Cue-Set-Go task</title><p>Two monkeys were trained to perform a Cue-Set-Go (CSG) motor timing task (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). On each trial, animals had to produce either an 800 ms (Short) or a 1500 ms (Long) time interval (<italic>t<sub>t</sub></italic>) either with a saccade (Eye) or with a button press (Hand). The task thus consisted of four randomly interleaved trial types, Eye-Short (ES), Eye-Long (EL), Hand-Short (HS), and Hand-Long (HL). The trial type was cued at the beginning of each trial by a fixation cue (âCueâ). The Cue consisted of a circle and a square: red circle for ES, blue circle for EL, red square for HS, and blue square for HL (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, right). After a random delay, a visual stimulus (âTarâ) was flashed to the left or right of the screen. This stimulus specified the position of the saccadic target for the Eye trials and served no function in the Hand trials. After another random delay, the presentation of a âSetâ flash around the fixation spot indicated the start of the timing period. Animals had to proactively initiate a saccade or press a button such that the produced interval, <italic>t<sub>p</sub></italic>, between Set and movement initiation (âGoâ) would match <italic>t<sub>t</sub></italic>. Reward was provided when the relative error, defined as <italic>e</italic> = (<italic>t<sub>p</sub>-t<sub>t</sub></italic>)/<italic>t<sub>t</sub></italic> (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) was within an experimentally-controlled acceptance window. On rewarded trials, the magnitude of reward decreased linearly with the size of the error. The width of the acceptance window was controlled independently for each trial type using a one-up-one-down staircase procedure (see MaterialsÂ andÂ methods) so that animals received reward on nearly half of the trials (<xref ref-type="fig" rid="fig1">Figure 1C</xref>, inset).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Task, behavior, and reward-dependency of variability.</title><p>(<bold>A</bold>) The Cue-Set-Go task. (<bold>B</bold>) Behavior in a representative session for each of the two animals. For visual clarity, <italic>t<sub>p</sub></italic> values (dots) for different trial types are shown along different abscissae for each trial type. The solid line and shaded area are the mean and standard deviation of <italic>t<sub>p</sub></italic> calculated from a 50-trial sliding window. (<bold>C</bold>) The standard deviation of <italic>t<sub>p</sub></italic> (<italic>Ï</italic>(<italic>t<sub>p</sub></italic>)) as a function of its mean (<italic>Î¼</italic>(<italic>t<sub>p</sub></italic>)) for each trial type in each behavioral session. Each pair of connected dots corresponds to Short and Long of the same effector in a single session. In both animals, the variability was significantly larger for the Long compared to the Short for both effectors (one-tailed paired-sample t test, ***p&lt;&lt;0.001, for monkey A, nÂ =Â 190, t<sub>128</sub>Â =Â 157.4; for monkey D, nÂ =Â 216, t<sub>163</sub>Â =Â 181.7). The solid black lines show the regression line relating <italic>Ï</italic>(<italic>t<sub>p</sub></italic>) to <italic>Î¼</italic>(<italic>t<sub>p</sub></italic>) across all behavioral sessions for each trial type (<italic>Ï</italic>(<italic>t<sub>p</sub></italic>) = <italic>Î²<sub>1</sub> Î¼</italic>(<italic>t<sub>p</sub></italic>)). Regression slopes were positive and significantly different from zero for both effectors (<italic>Î²</italic>Â =Â 0.087Â Â±Â 0.02 meanÂ±std for Eye and 0.096Â Â±Â 0.021 for Hand in Monkey A; <italic>Î²<sub>1</sub></italic>Â =Â 0.10Â Â±Â 0.02 for Eye and 0.12Â Â±Â 0.021 for Hand in Monkey D). Hand trials were more variable than Eye ones (one-tailed paired-sample <italic>t</italic>-test, for monkey A, nÂ =Â 95, t<sub>52</sub>Â =Â 6.92, ***p&lt;&lt;0.001, and for monkey D, nÂ =Â 108, t<sub>61</sub>Â =Â 6.51, ***p&lt;&lt;0.001). Inset: The overall percentage of rewarded trials across sessions for each trial type.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55872-fig1-v1.tif"/></fig><p>Animals learned to use the Cue and flexibly switched between the four trial types on a trial-by-trial basis (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). There were no errors associated with using the wrong effector, and the number of errors with respect to the target interval was extremely small (~0.79% misclassified trials based on fits to a Gaussian mixture model). For both effectors, a robust feature of the behavior was that produced intervals (<italic>t<sub>p</sub></italic>) were more variable for the Long compared to theÂ Short (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). This is consistent with the common observation that timing variability scales with the interval being timed (<xref ref-type="bibr" rid="bib30">Gibbon, 1977</xref>; <xref ref-type="bibr" rid="bib69">Malapani and Fairhurst, 2002</xref>). This <italic>scalar variability</italic> was evident in the linear relationship between mean (<italic>Î¼</italic>) and standard deviation (<italic>Ï</italic>) of <italic>t<sub>p</sub></italic> in each behavioral session (<xref ref-type="fig" rid="fig1">Figure 1C</xref>, the slope of the linear test was significantly positive, one-tailed <italic>t</italic>-test, p&lt;&lt;0.001, for monkey A, dfÂ =Â 128, tÂ =Â 32.12; for monkey D, p&lt;&lt;0.001, dfÂ =Â 163, tÂ =Â 24.06).</p></sec><sec id="s2-2"><title>Deconstructing motor timing variability</title><p>The neurobiological basis of timing variability is not understood. Models of interval timing typically assume that timing variability is stationary and attribute it to various sources such as a noisy internal clock, a noisy accumulator, noisy oscillations, and noisy storage/retrieval mechanisms (<xref ref-type="bibr" rid="bib31">Gibbon et al., 1984</xref>; <xref ref-type="bibr" rid="bib58">Killeen and Fetterman, 1988</xref>; <xref ref-type="bibr" rid="bib34">Grossberg and Schmajuk, 1989</xref>; <xref ref-type="bibr" rid="bib13">Church and Broadbent, 1990</xref>; <xref ref-type="bibr" rid="bib68">Machado, 1997</xref>; <xref ref-type="bibr" rid="bib104">Staddon and Higa, 1999</xref>; <xref ref-type="bibr" rid="bib50">Jazayeri and Shadlen, 2010</xref>; <xref ref-type="bibr" rid="bib101">Simen et al., 2011</xref>; <xref ref-type="bibr" rid="bib86">Oprisan and Buhusi, 2014</xref>). However, behavioral variability is typically nonstationary (<xref ref-type="bibr" rid="bib120">Weiss et al., 1955</xref>; <xref ref-type="bibr" rid="bib75">Merrill and Bennett, 1956</xref>; <xref ref-type="bibr" rid="bib32">Gilden et al., 1995</xref>), especially in the context of movements (<xref ref-type="bibr" rid="bib10">Chaisanguanthum et al., 2014</xref>), reaction times (<xref ref-type="bibr" rid="bib61">Laming, 1979</xref>), and interval timing (<xref ref-type="bibr" rid="bib11">Chen et al., 1997</xref>; <xref ref-type="bibr" rid="bib79">Murakami et al., 2017</xref>). These nonstationarities are particularly important as they can cause long-term drifts, unstable behavior, and poor performance. Therefore, it is important to tease apart the factors that underlie nonstationary variability, and understand how the brain maintains stable performance in spite of such variability.</p><p>We verified the presence of nonstationary behavior in our data by analyzing the serial correlations of <italic>t<sub>p</sub></italic>. In all four trial types, <italic>t<sub>p</sub></italic> exhibited significant serial correlations up to a trial lag of 20 or more (p&lt;0.01, dash lines: 1% and 99% confidence bounds by estimating the null distribution from shuffled series, <xref ref-type="fig" rid="fig2">Figure 2A</xref>) revealing strong slowly fluctuating sources of variability. Importantly, these correlations were stronger between trials with the same effector and same <italic>t<sub>t</sub></italic> compared to trials that were associated with different <italic>t<sub>t</sub></italic> and/or different effectors (<xref ref-type="fig" rid="fig2">Figure 2B</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1AâB</xref>). The context-specificity of these correlations suggests that they were not solely due to non-specific fluctuations of internal states such as the overall level of alertness, which should persist across the four randomly interleaved trial types.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Context-dependent slow fluctuations of timing intervals.</title><p>(<bold>A</bold>) Long-term correlation of <italic>t<sub>p</sub></italic> across trials of the same type (same effector and target interval). For each behavioral session, and each trial type, we computed the partial correlation of <italic>t<sub>p</sub></italic> as a function of trial lag. Each curve shows the average partial correlations across all behavioral sessions. Four types of trials are shown in different colors. Filled circles: correlation values that are larger than the 1% and 99% confidence interval (dashed line). (<bold>B</bold>) Examples showing the Pearson correlation coefficients of <italic>t<sub>p</sub>'s</italic> as a function of trial lag. HL-HL indicates the correlation was averaged across trials transitioning between HL and HL; 1% and 99% confidence intervals were estimated from the null distribution. Serial correlations were stronger between trials with the same effector and interval compared to trials with the same effector but different interval (*** dark gray, paired sample <italic>t</italic>-test on two sets of cross-correlations with less than 20 trial lags and combining four trial types; monkey A: p&lt;&lt;0.001, nÂ =Â 80, t<sub>79</sub>Â =Â 9.8; monkey D: p&lt;&lt;0.001, nÂ =Â 80, t<sub>79</sub>Â =Â 5.8), and trials of the different effector but same interval (*** light gray, monkey A: p&lt;&lt;0.001, nÂ =Â 80, t<sub>79</sub>Â =Â 6.7; monkey D: p&lt;&lt;0.001, nÂ =Â 80, t<sub>79</sub>Â =Â 17.3). See <xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1A</xref> for transitions between other conditions, and <xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1B</xref> for a comparison of context-specificity with respect to saccade direction.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55872-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2âfigure supplement 1.</label><caption><title>Slow fluctuations of timing variability.</title><p>(<bold>A</bold>) Correlation between produced intervals for the two animals and different trial types transitions. (<bold>B</bold>) Same as A between trials shown separately for trials with the same and different saccade directions (Top: monkeys; Bottom: humans). The analysis was performed separately for trials of the same type (i.e. same target interval and same effector), and pooled afterward. The long-term correlations were not significantly different for the same and different directions (Monkeys: paired sample <italic>t</italic>-test, p=0.39, tÂ =Â 0.86, dfÂ =Â 159; Humans: paired sample <italic>t</italic>-test, p=0.55, tÂ =Â 0.60, dfÂ =Â 79). (<bold>C</bold>) Slow fluctuations of timing variability in humans. Correlation was averaged across human subjects (NÂ =Â 5). (<bold>D</bold>) Slow fluctuations of timing variability in the memory control experiment. Partial correlation between produced intervals diminished in the control experiment in which the demand for remembering the target interval was minimized. All plots are in the same format as in <xref ref-type="fig" rid="fig2">Figure 2</xref>. The red shows the high end of the 99%Â confidence intervals, which is approximated in each plot by averaging across bootstrap data across trials and conditions.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55872-fig2-figsupp1-v1.tif"/></fig></fig-group><p>Since performance in CSG depends on an accurate memory of <italic>t<sub>t</sub></italic>, we hypothesized that these fluctuations may be due to slow drifts in memory. To test this hypothesis, we reasoned that the fluctuations should be smaller if the demands on memory were reduced. Therefore, we trained two monkeys, not previously exposed to the CSG task, to perform a control task in which <italic>t<sub>t</sub></italic> was measured on every trial, thereby minimizing the need to rely on memory (see MaterialsÂ andÂ methods). As expected, <italic>t<sub>p</sub></italic> serial correlations diminished significantly in the control task (<xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1D</xref>; p&lt;&lt;0.001, paired sample <italic>t</italic>-test, t<sub>19</sub>Â =Â 4.9, on the partial correlation between CSG and controls, trial lag was limited to 20 trials), suggesting that the slow fluctuations of <italic>t<sub>p</sub></italic> in the CSG task were a signature of drift in memory. Note that our use of the term context (effectors and intervals) and memory (procedural) should not be confused with the notion of context (spatial) in classical studies of episodic memory. For the remainder of our analyses, we will refer to these fluctuations as memory drifts. Note that this drift reflects a random diffusion process with no explicit baseline and is consistent with broadening of the <italic>t<sub>p</sub></italic> distribution.</p></sec><sec id="s2-3"><title>Reward regulates variability in a context-specific manner</title><p>Memory drifts, if left unchecked, could lead to large excursions away from <italic>t<sub>t</sub></italic>, and ruin performance. To maintain a reasonably accurate estimate of <italic>t<sub>t</sub></italic>, another process must counter the drift in memory. In CSG, the only cue that animals can rely on to maintain high performance is the trial outcome. Therefore, we hypothesized that animals rely on the trial outcome to counter memory drifts. In principle, the reward can calibrate behavior through a combination of directed and random explorations. In directed exploration, the agent repeats responses that previouslyÂ ledÂ to better outcomes. In random explorations, the agent simply increases variability to explore responses that might yield better outcomes.</p><p>As a first step toward developing a model for how reward regulates behavior, we did a careful analysis of behavioral variability across trials. Specifically, we defined relative error on trial <italic>n</italic> as <italic>e<sup>n</sup> =</italic> (<italic>t<sub>p</sub><sup>n</sup>- t<sub>t</sub></italic>)/<italic>t<sub>t</sub></italic>, and analyzed the relationship between error mean, <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>), and error variability, <italic>Ï</italic>(<italic>e<sup>n</sup></italic>), as a function of error in the preceding trial (<italic>e<sup>n-1</sup></italic>). Results revealed that these error statistics were highly structured across trials: <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>) increased monotonically with <italic>e<sup>n-1</sup></italic>, and <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) had a U-shaped profile (<xref ref-type="fig" rid="fig3">Figure 3B</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1A</xref>). We confirmed the statistical significance of these observations using linear regression for <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>) and quadratic regression for <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) (<xref ref-type="table" rid="table1">Table 1</xref>, see MaterialsÂ andÂ methods).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Rapid and context-dependent modulation of behavioral variability by reward.</title><p>(<bold>A</bold>) Illustration of the expected effect of serial correlations and reward-dependent variability. Top: Positive serial correlations between produced intervals (<italic>t<sub>p</sub></italic>) creates a positive correlation between consecutive errors, and predicts a monotonic relationship between the mean of error in trial <italic>n</italic>, <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>), and the value of error in trial <italic>n-1</italic> (<italic>e<sup>n-1</sup></italic>). Middle: Variability decreases with reward. This predicts a U-shaped relationship between the standard deviation of <italic>e<sup>n</sup></italic>, <italic>Ï</italic>(<italic>e<sup>n</sup></italic>), and <italic>e<sup>n-1</sup></italic>. Bottom: Reward as a function of <italic>e<sup>n-1</sup></italic>. (<bold>B</bold>) Trial-by-trial changes in the statistics of relative error. Top: <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>) as a function of <italic>e<sup>n-1</sup></italic> in the same format shown in (<bold>A</bold>) top panel. Filled and open circles correspond to consecutive trials of the same and different types, respectively. Middle: <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) as a function of <italic>e<sup>n-1</sup></italic>, sorted similarly to the top panel. Bottom: the reward expectation as a function of <italic>e<sup>n-1</sup></italic>. The reward expectation was computed by averaging the magnitude of reward received across trials. In the same effector, variability increased significantly after an unrewarded trials compared to a rewarded trials (horizontal line, two-sample F-test for equal variances, ***p&lt;&lt;0.001) for both large positive errors (Monkey A: F(11169,10512)Â =Â 1.09, Monkey D: F(18540,13478)Â =Â 1.76) and large negative errors (Monkey A: F(8771,9944)Â =Â 1.40, Monkey D: F(21773,14889)Â =Â 1.62). The variability after an unrewarded trial of the same effector was significantly larger than after an unrewarded trial of the other effector (vertical line, two-sample F-test for equal variances, ***p&lt;&lt;0.001) for both large positive errors (Monkey A: F(11169,8670)Â =Â 1.20, Monkey D: F(18540,7969)Â =Â 1.32) and large negative errors (Monkey A: F(8771,5994)Â =Â 1.26, Monkey D: F(21773,7179)Â =Â 1.27). (<bold>C</bold>) Same as (<bold>B</bold>) for human subjects. In humans, the variability was also significantly larger after a negatively reinforced trial compared to a positively reinforced trial (horizontal line, two-sample F-test for equal variances, ***p&lt;&lt;0.001) for both large positive errors (F(5536,5805)Â =Â 1.19) and large negative errors (F(9366,9444)Â =Â 1.11). The variability after a positively reinforced trial of the same effector was significantly lower than after a positively reinforced trial of the other effector (vertical line, two-sample F-test for equal variances, ***p&lt;&lt;0.001, F(14497,15250)Â =Â 1.10). For humans, the reward expectation was defined as the ratio between the number of trials with positive feedback and total number of trials.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55872-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3âfigure supplement 1.</label><caption><title>The effect of reward on behavioral variability.</title><p>(<bold>A</bold>) Cross-condition relationship between produced interval (<italic>t<sub>p</sub></italic>) in consecutive trials. The results for each animal are organized on a 4 Ã 4 panel covering the full set of 16 possible transitions between four trial types (ES: Eye-Short; EL: Eye-Long; HS: Hand-Short; HL: Hand-Long) with the abscissa and ordinate showing <italic>t<sub>p</sub></italic> at trial <italic>n-1</italic> (<italic>t<sub>p</sub><sup>n-1</sup></italic>) and n (<italic>t<sub>p</sub><sup>n</sup></italic>), respectively. In each panel, the median <italic>t<sub>p</sub><sup>n</sup></italic> as the function of <italic>t<sub>p</sub><sup>n-1</sup></italic> is marked in bold at the center. The 25th and 75th percentile are marked with medium thickness, and the 10th and 90th percentile with thin lines. Bin size was 20 ms. (<bold>B</bold>) Error statistics across sessions. Since our original analysis was based on data combined across sessions, one potential concern we had was that modulation of <italic>t<sub>p</sub></italic> variance with reward was due to differences across (but not within) sessions. To address this, we first removed outlier <italic>t<sub>p</sub></italic> values (more than 3 s.d. away from the mean) and then analyzed z-scored errors within each session (denoted <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>). This normalization ensured that error pairs in every session were drawn from a zero-mean and unit-variance distribution. Results are shown in the same format as in <xref ref-type="fig" rid="fig3">Figure 3BâC</xref>. The variability increased significantly after unrewarded trials compared to that after rewarded trials (horizontal lines, ***p&lt;0.001; monkey A: F(8889,10621)Â =Â 1.15 for negative <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and F(9841,11103)Â =Â 1.09 for positive <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>; monkey D: F(21216,12364)Â =Â 1.25 for negative <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> and F(1600,19293) = 1.38 for positive <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mi>e</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>), and this effect was context specific (vertical lines, for monkey A: F(10621,9841)Â =Â 1.10 and monkey D: F(12364, 16100)=1.11). (<bold>C</bold>) Behavioral variability as a function of the magnitude of reward in the preceding trial. We computed <italic>Ï(e<sup>n</sup>)</italic> and the corresponding averaged reward <italic>r<sup>n-1</sup></italic> from randomly sampled trials without replacement within each bin of <italic>e<sup>n-1</sup></italic>. The dark line and shaded area showed the meanÂ Â±s.d. computed using a sliding window consisting of 50 samples. The <italic>Ï(e<sup>n</sup>)</italic> and reward <italic>r<sup>n-1</sup></italic> were significantly correlated (Spearman's <italic>Ï</italic>Â =Â â0.23, ***p&lt;&lt;1e-3). (<bold>D</bold>) Top: Average error on trial n, <italic>Î¼(e<sup>n</sup>)</italic> as a function of error in trial <italic>n-k</italic> (<italic>e<sup>n-k</sup></italic>) for <italic>k</italic>Â =Â 0, 1, 2, and 20 (different colors). Bottom: Standard deviation of error on trial n, <italic>Ï(e<sup>n</sup>)</italic> as a function of <italic>e<sup>n-k</sup></italic>. Results were computed for each trial type separately averaged afterwards. (<bold>E</bold>) Modulation of variability by reward as a function of trial lagÂ (<italic>k</italic>). Similar to the main paper, we tested the U-shaped profile using quadratic regression. The ordinate shows the coefficient of the square term (<italic>s<sub>2</sub></italic>) of the quadratic regression as a function of trial lag (circles: <italic>s<sub>2</sub></italic> for the <italic>k</italic> values in D; shaded area: [1%â99%] confidence intervals). The reward has no direct bearing on the variability of the current trial (<italic>kÂ =Â 0</italic>), and its effect drops as a function of trial lag.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55872-fig3-figsupp1-v1.tif"/></fig></fig-group><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Quantitative assessment of the dependence of <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>) and <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) on <italic>e<sup>n-1</sup></italic>.</title></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" valign="top">Parameters</th><th valign="top">Monkey A</th><th valign="top">Monkey D</th><th valign="top">Humans</th></tr><tr><th valign="top">Same vs. different effector</th><th valign="top">Same vs. different effector</th><th valign="top">Same vs. different effector</th></tr></thead><tbody><tr><td><italic>m<sub>1</sub></italic> <break/> <italic>m<sub>0</sub></italic></td><td valign="top"><bold>0.16 [0.12, 0.19]&gt;0.04 [0.03, 0.06]</bold> <break/>0.00 [-0.00, 0.01]~0.01 [0.01, 0.01]</td><td valign="top"><bold>0.20 [0.12, 0.28]&gt;â0.00 [-0.05, 0.04]</bold> <break/>â0.00 [-0.02, 0.01]~0.01 [0.00, 0.02]</td><td valign="top"><bold>0.35 [0.27, 0.44]&gt;0.15 [0.09, 0.20]</bold> <break/>â0.03 [-0.08, 0.02]~â0.06 [-0.08,â0.05]</td></tr><tr><td><italic>s<sub>2</sub></italic> <break/> <italic>s<sub>1</sub></italic> <break/> <italic>s<sub>0</sub></italic></td><td valign="top"><bold>0.50 [0.39, 0.60]&gt;0.24 [0.14, 0.33]</bold> <break/>â0.02 [-0.04, 0.01]~0.02 [-0.00, 0.04] <break/>0.09 [0.09, 0.10]~0.08 [0.08, 0.92]</td><td valign="top"><bold>0.48 [0.19, 0.78]&gt;â0.06 [-0.17, 0.05]</bold> <break/>0.03 [-0.03, 0.10]~â0.01 [-0.04, 0.01] <break/>0.11 [0.10, 0.12]~0.12 [0.11, 0.12]</td><td valign="top"><bold>0.31 [0.21, 0.42]&gt;0.06 [-0.03, 0.16]</bold> <break/>0.00 [-0.03, 0.04]~0.03 [-0.00, 0.06] <break/><bold>0.17 [0.16, 0.19]&lt;0.22 [0.22, 0.24]</bold></td></tr></tbody></table></table-wrap><p>The monotonic relationship between <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>) and <italic>e<sup>n-1</sup></italic> is expected given the long-term correlations of <italic>t<sub>p</sub></italic> caused by memory drifts. In contrast, the U-shaped relationship between <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) and <italic>e<sup>n-1</sup></italic> is unexpected and suggests that trial outcome regulates behavior variability. In particular, since smaller errors were associated with higher average rewards, this U-shaped relationship suggests that animals increase their behavioral variability when the reward is low and decrease it when the reward is high.</p><p>We performed a number of additional analyses to further scrutinize the unexpected relationship between <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) and <italic>e<sup>n-1</sup></italic>. For example, we asked whether the modulation of <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) could be due to differences across (as opposed to within) behavioral sessions. Applying the same analysis to different grouping of trials confirmed that the relationship between variability and reward was present within individual behavioral sessions (<xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1B</xref>). Similarly, we asked whether the effect of reward on variability was binary (present/absent) or graded (larger variability for lower reward). A more refined binning of trials based on the magnitude of reward provided evidence that the effect was graded: <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) was significantly correlated with the magnitude of the previous reward <italic>r<sup>n-1</sup></italic> (Spearmanâs correlation, <italic>Ï</italic>Â =Â â0.23, ***p=2e-15, <xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1C</xref>). Finally, the effect of reward was progressively weaker for larger trial lags (<xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1DâE</xref>) revealing the lingering effects of reward (or lack thereof) beyond single trials. These results provide converging evidence in support of the relationship between reward and behavioral variability.</p><p>Our earlier analysis indicated that the slow memory drifts in the behavior were context-specific (<xref ref-type="fig" rid="fig2">Figure 2B</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1AâB</xref>). For the reward modulation of variability to be effective, it must be also context-specific. That is, an increase in variability following a large error should only be present if the subsequent trial is of the same type. Otherwise, reinforcement of one trial type, say ES, may incorrectly adjust variability in the following trials of another type, say HL, and would interfere with the logic of harnessing reward to calibrate the memory of <italic>t<sub>t</sub></italic>. To test this possibility, we analyzed error statistics between pairs of consecutive trials associated with different types (<xref ref-type="fig" rid="fig3">Figure 3B</xref> open circles; <xref ref-type="table" rid="table1">Table 1</xref>). Results indicated that (1) correlations were strongest between pairs of trials of the same type as expected from our previous cross-correlation analysis in (<xref ref-type="fig" rid="fig2">Figure 2B</xref>) and (2) the modulation of variability was most strongly and consistently present across trials of the same type. Together, these results provide strong evidence that animals increase behavioral variability in the next trial in a context-dependent manner to systematically promote exploration.</p></sec><sec id="s2-4"><title>Reward-dependent context-specific regulation of variability in humans</title><p>To ensure that our conclusions were not limited to data collected from highly trained monkeys, we performed a similar experiment in human subjects. In human psychophysical experiment, <italic>t<sub>t</sub></italic> varied from session to session, and subjects had to constantly adjust their <italic>t<sub>p</sub></italic> by trial-and-error. Similar to monkeys, human behavior exhibited long-term serial correlations and these correlations were context (effector) specific (<xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1BâC</xref>). We performed the same analysis as in monkeys to characterize the dependence of <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>) and <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) on <italic>e<sup>n-1</sup></italic>. Results were qualitatively similar: <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>) increased monotonically with <italic>e<sup>n-1</sup></italic> verifying the presence of slow drifts, and <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) had a U-shaped with respect to <italic>e<sup>n-1</sup></italic> indicating that subjects used the feedback to regulate their variability (<xref ref-type="fig" rid="fig3">Figure 3C</xref> and <xref ref-type="table" rid="table1">Table 1</xref>). Finally, similar to monkeys, the effect of reward on variability was context-specific (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). This result suggests that the memory of a time interval is subject to slow drifts and humans and monkeys use reward-dependent regulation of variability as a general strategy to counter these drifts and improve performance.</p><p>We used linear regression (<italic>Î¼</italic>(<italic>e<sup>n</sup></italic>)Â <italic>=Â m<sub>0</sub>+m<sub>1</sub>e<sup>n-1</sup></italic>) to relate <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>) to <italic>e<sup>n-1</sup></italic>, and quadratic regression (<italic>Ï</italic>(<italic>e<sup>n</sup></italic>)Â <italic>=Â s<sub>0</sub>+s<sub>1</sub>e<sup>n-1</sup>+s<sub>2</sub></italic>(<italic>e<sup>n-1</sup></italic>)<italic><sup>2</sup></italic>) to relate <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) to <italic>e<sup>n-1</sup></italic>. Fit parameters and the corresponding confidence intervals [1%, 99%] are tabulated for each monkey and for humans. We compared the magnitude of fit parameters between the same versus different effector conditions (bold: significantly different).</p></sec><sec id="s2-5"><title>Trial outcome causally impacts behavioral variability</title><p>So far, our results establish a relationship between trial outcome and behavioral variability. However, since in our experiment error size and trial outcome were deterministically related (larger error led to reduced reward), it is not possible to determine which of these two factors had a causal impact on behavioral variability. More specifically, our current findings are consistent with two interpretations. In one model, trial outcome regulates behavioral variability (<xref ref-type="fig" rid="fig4">Figure 4A</xref>; âCausalâ). In another, variability is influenced by various upstream factors such as error magnitude, but not by trial outcome (<xref ref-type="fig" rid="fig4">Figure 4A</xref>; âCorrelationalâ). To distinguish between these two models, we carried out a new human psychophysics experiment (<xref ref-type="fig" rid="fig4">Figure 4B</xref>) in which trial outcome was probabilistic (<xref ref-type="fig" rid="fig4">Figure 4C</xref>) so that the presence or absence of a âcorrectâ feedback was not fully determined by the magnitude of the error. This design enabled us to analyze the effect of trial outcome (âcorrectâ versus âincorrectâ) on behavioral variabilityÂ .</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Causal effect of reward on behavioral variability.</title><p>(<bold>A</bold>) Alternative interpretations of the relationship between the outcome of the preceding trial (<italic>Rew<sup>n-1</sup></italic>) and behavioral variability in the current trialÂ denotedÂ <italic>Ï</italic>(<italic>e<sup>n</sup></italic>). Left: A model in which <italic>Rew<sup>n-1</sup></italic>causally controls <italic>Ï</italic>(<italic>e<sup>n</sup></italic>). In this model, various factors (e.g.,memory drift) may determine the size of error (<italic>e<sup>n-1</sup></italic>), <italic>e<sup>n-1</sup></italic> determines <italic>Rew<sup>n-1</sup></italic>, and <italic>Rew<sup>n-1</sup></italic> directly regulates <italic>Ï</italic>(<italic>e<sup>n</sup></italic>). Right: A model in which the relationship between <italic>Rew<sup>n-1</sup></italic> and <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) is correlational. In this model, <italic>Rew<sup>n-1</sup></italic> is determined by <italic>e<sup>n-1</sup></italic>, and <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) may be controlled by various factors (including <italic>e<sup>n-1</sup></italic>) but not directly by <italic>Rew<sup>n-1</sup></italic>. (<bold>B,C</bold>) A time interval production task with probabilistic feedback to distinguish between the two models in (<bold>A</bold>). (<bold>B</bold>) Trial structure. The subject has to press the spacebar to initiate the trial. During the trial, the subject is asked to hold their gaze on a white fixation spot presented at the center of the screen. After a random delay, a visual ring (âSetâ) is flashed briefly around the fixation spot. The subject has to produce a time interval after Set using a delayed key press. After the keypress, the color of the fixation spot changes to red or green to provide the subject with feedback (green: âcorrectâ, red: âincorrectâ). (<bold>C</bold>) Top: A schematic illustration of the distribution of relative error , computed as (<italic>t<sub>p</sub>ât<sub>t</sub></italic>)/<italic>t<sub>t</sub></italic>. Bottom: After each trial, the feedback is determined probabilistically: the subject is given a âcorrectâ feedback with the probability of 0.7 when <italic>t<sub>p</sub></italic> is within a window around <italic>t<sub>t</sub></italic>, and with the probability of 0.3 when errors are outside this window. The window length was adjusted based on the overall behavioral variability so that each subject receives approximately 50% âcorrectâ feedback in each behavioral session. (<bold>D</bold>) The causal effect of the outcome of the preceding trial on behavioral variability in the current trial. Left: Scatter plot shows the behavioral variability after âincorrectâ (ordinate) versus âcorrectâ (abscissa) trials, for all five subjects, after trials in which <italic>e<sup>n-1</sup></italic> was small (inset). Results for the positive and negative errors are shown separately (with â+â and â-â symbols, respectively). Right: Same as the left panel for trials in which <italic>e<sup>n-1</sup></italic> was large (inset). In both panels, the variability across subjects was significantly larger following incorrect compared to correct trials (p&lt;&lt;0.001, paired sample <italic>t</italic>-test, t<sub>199</sub>Â =Â 12.8 for small error, and t<sub>199</sub>Â =Â 13.7 for large error, see MaterialsÂ andÂ methods).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55872-fig4-v1.tif"/></fig><p>We compared behavioral variability after âcorrectâ and âincorrectâ trials separately for small (<xref ref-type="fig" rid="fig4">Figure 4D</xref>, left) and large (<xref ref-type="fig" rid="fig4">Figure 4D</xref>, right) errors. Across subjects and irrespective of the size of error, variability was significantly larger after incorrect compared to correct trials (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). In other words, the presence or absence of reward had a causal impact on behavioral variability that was not mediated through the size of error. This result substantiates our hypothesis and provides evidence against all models that do not account for the direct dependence of behavioral variability on the trial outcome.</p></sec><sec id="s2-6"><title>A generative model linking multiple timescales of variability to reward-based learning</title><p>Our results so far indicate that errors in <italic>t<sub>p</sub></italic> are governed by two key factors: long-term serial correlations creating local and persistent biases in <italic>t<sub>p</sub></italic>, and short-term modulations of <italic>t<sub>p</sub></italic> variability by reward. Intuitively, this could provide the means for an efficient control strategy: when bias due to memory drift increases, error increases, reward drops, and the animal seeks to find the correct target interval by increasing variability. Indeed, several recent behavioral experiments have found evidence that is qualitatively consistent with this control strategy (<xref ref-type="bibr" rid="bib49">Izawa and Shadmehr, 2011</xref>; <xref ref-type="bibr" rid="bib99">Shmuelof et al., 2012a</xref>; <xref ref-type="bibr" rid="bib19">Dam et al., 2013</xref>; <xref ref-type="bibr" rid="bib124">Wu et al., 2014</xref>; <xref ref-type="bibr" rid="bib84">Nikooyan and Ahmed, 2015</xref>; <xref ref-type="bibr" rid="bib89">Pekny et al., 2015</xref>; <xref ref-type="bibr" rid="bib12">Chen et al., 2017</xref>; <xref ref-type="bibr" rid="bib9">Cashaback et al., 2019</xref>).</p><p>To assess this idea rigorously, we aimed to develop a generative model that could emulate this control strategy. We reasoned that the generative process must have two distinct components, one associated with long-term serial correlations due to the memory drift, and another, with the short-term effect of reward on variability. Accordingly, we sought to develop a Gaussian process (GP) model that could capture both effects. This choice was motivated by three factors: (1) GPs automatically describe observations up to their second order statistics, which are the relevant statistics in our data, (2) GPs offer a nonparametric Bayesian fit to long-term serial correlations, and (3) as we will describe, GPs can be readily augmented to regulate variability based on reward.</p><p>GPs are characterized by a covariance matrix â also known as the GP kernel â that specifies the degree of dependence between samples, and thus determines how slowly the samples fluctuate. The most common and mathematically convenient formulation of this kernel is known as the âsquared exponentialâ kernel function, denoted <bold><italic>K</italic></bold><italic><sub>SE</sub></italic> (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, top left):<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>â</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mo>â¡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>â</mml:mo><mml:mfrac><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>l</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></disp-formula></p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>A reward-sensitive Gaussian process model (RSGP) capturing reward-dependent control of variability.</title><p>(<bold>A</bold>) Top: The covariance function for the RSGP model (<bold><italic>K</italic></bold><italic><sub>RSGP</sub></italic>) is the sum of a squared exponential kernel (<bold><italic>K</italic></bold><italic><sub>SE</sub></italic>), a reward-dependent squared exponential kernel (<bold><italic>K</italic></bold><italic><sub>RS</sub></italic>) and an identity matrix (<bold><italic>I</italic></bold>) weighted by <italic>Ï<sub>SE</sub><sup>2</sup></italic>, <italic>Ï<sub>RS</sub><sup>2</sup></italic>, and <italic>Ï<sub>0</sub><sup>2</sup></italic>, respectively. Second row: Simulations of three GP models, one using K<italic><sub>SE</sub></italic> only (left), one using K<italic><sub>RS</sub></italic> only (middle), and one with the full K<italic><sub>RSGP</sub></italic> (right). Third row: Partial correlation of samples from the three GPs in the second row. Fourth and fifth rows: The relationship between the mean (fourth row) and standard deviation (fifth row) of <italic>e<sup>n</sup></italic> as a function of <italic>e<sup>n-1</sup></italic> in the previous trial, shown in the same format as in <xref ref-type="fig" rid="fig3">Figure 3B</xref>. Only the model with full covariance function captures the observed behavioral characteristics. (<bold>B</bold>) Length scales, <italic>l<sub>SE</sub></italic> and <italic>l<sub>RS</sub></italic> associated with K<italic><sub>ES</sub></italic> and K<italic><sub>RS</sub></italic>, respectively, derived from fits of RSGP to behavioral data from monkeys (left) and humans (right). Small and large symbols correspond to individual sessions and the median across sessions, respectively. Different trial types are shown with different colors (same color convention as in <xref ref-type="fig" rid="fig1">Figure 1B</xref>). <italic>l<sub>RS</sub></italic> was significantly smaller than the <italic>l<sub>SE</sub></italic> (monkeys: p&lt;&lt;0.001, one-way ANOVA, F<sub>1, 945</sub> = 463.4; humans: p&lt;&lt;0.001, one-way ANOVA, F<sub>1, 235</sub> = 102.5). (<bold>C</bold>) Statistics of the predicted behavior from the RSGP model fits, shown in the same format as <xref ref-type="fig" rid="fig3">Figure 3B,C</xref>. Data were generated from forward prediction of the RSGP model fitted to behavior (see MaterialsÂ andÂ methods for details). The standard error of the mean computed from nÂ =Â 100 repeats of sampling of trials is shown as a shaded area, but it is small and difficult to discern visually.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55872-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5âfigure supplement 1.</label><caption><title>RSGP model fits.</title><p>(<bold>A</bold>) Simulation results indicated that the likelihood function captures the ground truth and that the error surface is convex for a wide range of initial values. See MaterialsÂ andÂ methods for details. The hyperparameters used for simulation are marked by asterisks and the results of fitting are in <xref ref-type="table" rid="table2">Table 2</xref>. (<bold>B</bold>) Same as <xref ref-type="fig" rid="fig5">Figure 5B</xref> shown for the two animals separately. (<bold>C</bold>) The model fit of variances (<italic>Ï</italic><sub>SE</sub>, <italic>Ï</italic><sub>RS</sub> and <italic>Ï</italic><sub>0</sub>) across sessions for monkeys (left column) and humans (right column).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55872-fig5-figsupp1-v1.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5âfigure supplement 2.</label><caption><title>Analysis of error statistics in the probabilistic reward experiment.</title><p>(<bold>A</bold>) Human behavior. Results were combined for all subjects in <xref ref-type="fig" rid="fig4">Figure 4D</xref> and was plotted in the same format as <xref ref-type="fig" rid="fig3">Figure 3B</xref>. To avoid sampling bias, same number of trials were drawn repeatedly after âincorrectâ (red, â<italic>Rew<sup>n-1</sup></italic>) or âcorrectâ (green, +<italic>Rew<sup>n-1</sup></italic>) trials (Shaded area: standard error of the mean computed from 100 bootstraps). Behavioral variability <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) increased significantly after âincorrectâ trial outcome regardless of the size of error (***p&lt;0.001, two-sample <italic>t</italic>-test on <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) between the two conditions, t<sub>198</sub>Â &gt;6.70 for all bins). The slope of the <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>) as a function of <italic>e<sup>n-1</sup></italic> was larger after âcorrectâ outcome (***p&lt;0.001, two sample <italic>t</italic>-test t<sub>198</sub>Â =Â 16.8) demonstrating stronger behavioral correlation after positive reinforcement. (<bold>B</bold>) RSGP model behavior. Same as (<bold>A</bold>) for the behavior of the RSGP model fit to the subjectâs behavior. (<bold>C</bold>) DS model behavior. Same as (<bold>B</bold>) for the model fit to the subjectâs behavior (slope of the <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>), ***p&lt;0.001, two sample <italic>t</italic>-test t<sub>198</sub>Â =Â 5.11, larger <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) after âincorrectâ: one-sided two-sample <italic>t</italic>-test, p&gt;=0.85).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55872-fig5-figsupp2-v1.tif"/></fig></fig-group><p>In <bold><italic>K</italic></bold><italic><sub>SE</sub></italic>, the covariance between any two samples (indexed by <italic>n</italic> and <italic>n-r</italic>) drops exponentially as a function of temporal distance (<italic>r</italic>) and the rate of drop is specified by the <italic>characteristic length parameter</italic>, <italic>l<sub>SE</sub></italic>. When <italic>l<sub>SE</sub></italic> is small, samples are relatively independent, and when it is large, samples exhibit long-range serial correlations (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, left, second and third rows).</p><p>Using GPs as the backbone of our model, we developed a reward-sensitive GP (RSGP) whose kernel (<bold><italic>K</italic></bold><italic><sub>RSGP</sub></italic>) is the weighted sum of two kernels, a classic squared exponential kernel (<bold><italic>K</italic></bold><italic><sub>SE</sub></italic>) scaled by <italic>Ï<sup>2</sup><sub>SE</sub></italic>, and a reward-sensitive kernel (<bold><italic>K</italic></bold><italic><sub>RS</sub></italic>) scaled by <italic>Ï<sup>2</sup><sub>RS</sub></italic> (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, top middle). A third diagonal matrix (<italic>Ï<sup>2</sup><sub>0</sub><bold>I</bold></italic>) was also added to adjust for baseline variance:<disp-formula id="equ2"><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>S</mml:mi><mml:mi>G</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>â</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msubsup><mml:mi>Ï</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>â</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>Ï</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>S</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>â</mml:mo><mml:mi>r</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msubsup><mml:mi>Ï</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mi>I</mml:mi></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p><bold><italic>K</italic></bold><italic><sub>RSÂ </sub></italic>also has a squared exponential form with a length parameter, <italic>l<sub>RS</sub></italic>. However, the covariance terms were non-zero only for rewarded trials (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, top middle). The reward was a binary variable determined by an acceptance window around <italic>t<sub>t</sub></italic>. This allows rewarded samples to have more leverage on future samples (i.e. larger covariance), and this effect drops exponentially for trials farther in the future.</p><p>Intuitively, RSGP operates as follows: <bold><italic>K</italic></bold><italic><sub>SE</sub></italic> captures the long-term covariance across samples (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, 3rd row, left). <bold><italic>K</italic></bold><italic><sub>RS</sub></italic> regulates shorter-term covariances (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, 3rd row, middle) and allows samples to covary more strongly with recent rewarded trials (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, bottom, middle). Non-zero values in <bold><italic>K</italic></bold><italic><sub>RS</sub></italic> after rewarded trials strengthen the correlation between samples and lead to a reduction of variability, whereas zero terms after unrewarded trials reduce correlations and increase variability. Using simulations of the full model with <bold><italic>K</italic></bold><italic><sub>RSGP</sub></italic> as well as reduced models with only <bold><italic>K</italic></bold><italic><sub>SE</sub></italic> or <bold><italic>K</italic></bold><italic><sub>RS</sub></italic> (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, second row), we verified that both kernels were necessary and that the full RSGP model was capable of capturing the two key features (<xref ref-type="fig" rid="fig5">Figure 5A</xref>, fourth and fifth rows). Moreover, we used simulations to verify that parameters of the model were identifiable, thatÂ is, fits of the model parameters to simulated data robustly recovered the ground truth (<xref ref-type="table" rid="table2">Table 2</xref>).</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Ground truth versus model fits for the hyperparameters used in RSGP simulation in <xref ref-type="fig" rid="fig5">Figure 5A</xref> and <xref ref-type="fig" rid="fig5s1">Figure 5âfigure supplement 1A</xref>.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top"/><th valign="top"><inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></th><th valign="top"><inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Ï</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></th><th valign="top"><inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></th><th valign="top"><inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Ï</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></th><th valign="top"><inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>Ï</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></th></tr></thead><tbody><tr><td valign="top">Ground truth</td><td valign="top">20.0</td><td valign="top">0.141</td><td valign="top">2.0</td><td valign="top">0.141</td><td valign="top">0.10</td></tr><tr><td valign="top">MML fit</td><td valign="top">18.4</td><td valign="top">0.129</td><td valign="top">2.14</td><td valign="top">0.137</td><td valign="top">0.0749</td></tr></tbody></table></table-wrap><p>We fitted the RSGP model to the behavior of both monkeys and humans (<xref ref-type="fig" rid="fig5">Figure 5B</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5âfigure supplement 1</xref>). The recovered characteristic length associated with serial correlations (<italic>l<sub>SE</sub></italic>) were invariably larger than that of the reward-dependent kernel (<italic>l<sub>RS</sub></italic>) (Monkeys: <italic>l<sub>SE</sub></italic>Â =Â 20.6Â Â±Â 21.4, <italic>l<sub>RS</sub></italic>Â =Â 2.0Â Â±Â 0.7; Humans: <italic>l<sub>SE</sub></italic>Â =Â 19.2Â Â±Â 21.8, <italic>l<sub>RS</sub></italic>Â =Â 1.3Â Â±Â 0.4; MedianÂ Â±MAD). The model fit of variances (<italic>Ï</italic><sub>SE</sub>, <italic>Ï</italic><sub>RS</sub> and <italic>Ï</italic><sub>0</sub>) are shown in <xref ref-type="fig" rid="fig5s1">Figure 5âfigure supplement 1C</xref>. In monkeys, <italic>Ï</italic><sub>0</sub> and <italic>Ï</italic><sub>SE</sub> but not <italic>Ï</italic><sub>RS</sub> were significantly different between two effectors (<italic>Ï</italic><sub>0</sub>: p&lt;&lt;0.001, one-tail two sample <italic>t</italic>-test, dfÂ =Â 482, tÂ =Â 5.26; <italic>Ï</italic><sub>SE</sub>: p&lt;&lt;0.001, two sample <italic>t</italic>-test, dfÂ =Â 482, tÂ =Â 5.06; <italic>Ï</italic><sub>RS</sub>: p=0.13, <italic>t-</italic>test, dfÂ =Â 261, tÂ =Â 1.5 for the Short interval, and p=0.26, <italic>t</italic>-test, dtÂ =Â 219, tÂ =Â 1.1 for the Long interval). The dependence of <italic>Ï</italic><sub>0</sub> and <italic>Ï</italic><sub>SE</sub> on effector was consistent with our session-wide analysis of variance (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). In the human subjects, variance terms were not significantly different between effectors (p=0.03 for <italic>Ï</italic><sub>0</sub>, p=0.01 for <italic>Ï</italic><sub>SE</sub>, and p=0.027 for <italic>Ï</italic><sub>RS</sub>, two sample <italic>t</italic>-test, dfÂ =Â 118). Importantly, across both monkeys and humans, the model was able to accurately capture the relationship of <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>) and <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) to <italic>e<sup>n-1</sup></italic> (<xref ref-type="fig" rid="fig5">Figure 5C</xref>, and MaterialsÂ andÂ methods). These results validate the RSGP as a candidate model for simultaneously capturing the slow fluctuations of <italic>t<sub>p</sub></italic> and the effect of reward on <italic>t<sub>p</sub></italic> variability.</p><p>Two aspects of the RSGP model are noteworthy. First, <bold><italic>K</italic></bold><italic><sub>RS</sub></italic> was formulated to capture the effect of reward between trials of the same type, and not transitions between trials associated with different types. The addition of kernels for transitions between effectors was unnecessary because the effect of reward was effector-specific (<xref ref-type="fig" rid="fig3">Figure 3B</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1A</xref>). Second, the RSGP was also able to capture the modulation of behavioral variability in the probabilistic reward experiment (<xref ref-type="fig" rid="fig5s2">Figure 5âfigure supplement 2B</xref>).</p></sec><sec id="s2-7"><title>Alternative models</title><p>To validate our interpretation of behavioral data in terms of the RSGP model, we tested alternative models that might account for the three salient features of the data: (1) long-range <italic>t<sub>p</sub></italic> correlations, (2) the monotonic relationship between <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>) and <italic>e<sup>n-1</sup></italic>, and (3) the U-shaped relationship between <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) and <italic>e<sup>n-1</sup></italic>.Â The first class of alternative models tested the hypothesis that modulations of <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) were controlled by the magnitude of preceding errors, and not by the corresponding rewards (<xref ref-type="fig" rid="fig4">Figure 4A</xref> Right). In this class, we considered several types of GP models without explicit sensitivity to reward, autoregressive models that exhibit serial correlations with no reward-dependency (<xref ref-type="bibr" rid="bib118">Wagenmakers et al., 2004</xref>), and models whose behavior was governed by a mixture of stochastic processes (e.g. Gaussian process mixture models with different variances). None of these models were able to capture all the aforementioned features but we will not discuss these results further since our probabilistic reward control experiment already substantiated the causal role of reward on <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) (<xref ref-type="fig" rid="fig4">Figure 4D</xref>).</p><p>Next, we considered models that took the reward into account explicitly (<xref ref-type="bibr" rid="bib53">Kaelbling et al., 1996</xref>; <xref ref-type="bibr" rid="bib107">Sutton and Barto, 1998</xref>) but whose updating algorithms differed from the RSGP model (<xref ref-type="fig" rid="fig6">Figure 6</xref>). RL models are usually geared toward problems with discrete action spaces such as multi-armed bandit problems (<xref ref-type="bibr" rid="bib22">Dayan and Daw, 2008</xref>). Here, we adapted two such RL-based models to our task and tested whether they could capture the behavioral characteristics of humans (<xref ref-type="fig" rid="fig6">Figure 6A</xref>) and monkeys (<xref ref-type="fig" rid="fig6">Figure 6B</xref>).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Comparison of alternative models to behavioral data and the RSGP model.</title><p>(<bold>A</bold>) Human behavior. Top: Same results as <xref ref-type="fig" rid="fig3">Figure 3</xref> showing the monotonic relationship between the mean of error in trial <italic>n</italic>, <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>), and the value of error in trial <italic>n-1</italic> (<italic>e<sup>n-1</sup></italic>). Middle: Same as <xref ref-type="fig" rid="fig3">Figure 3</xref> showing the U-shaped relationship between the standard deviation of <italic>e<sup>n</sup></italic>, <italic>Ï</italic>(<italic>e<sup>n</sup></italic>), and <italic>e<sup>n-1</sup></italic>. Bottom: Same as <xref ref-type="fig" rid="fig2">Figure 2A</xref> showing partial correlation between produced intervals. (<bold>B</bold>) Same as (<bold>A</bold>) for data pooled across the animals. (<bold>C</bold>) Same as (<bold>A</bold>) for simulations of the RL-based Markov chain Monte Carlo (MCMC) sampling model. The data for humans and monkeys are included in the bottom panel for comparison. (<bold>D</bold>) Same as (<bold>C</bold>) for the RL-based directed search (DS) model based on the subset of simulation that did not exhibit run-away behavior.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55872-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6âfigure supplement 1.</label><caption><title>Example RL-based model behavior.</title><p>(<bold>A</bold>) An example simulation of the RL-based Markov chain Monte Carlo (MCMC) sampling model with parameters fitted to the animalsâ behavior. <italic>t<sub>t</sub>*</italic> is the internal target associated with the highest value. Rewarded trials were in green and unrewarded ones were in black. (<bold>B</bold>) Same as (<bold>A</bold>) for the RL-based directed search (DS) model. Inset: The mean of <italic>Ît<sub>p</sub><sup>n</sup></italic> as a function of <italic>Ît<sub>p</sub><sup>n-1</sup></italic> for different values of <italic>Îr<sup>n-1</sup></italic>. The positive and negative reward gradient has the opposite effect on the relationship. The overall negative correlation between <italic>Ît<sub>p</sub><sup>n</sup></italic> and <italic>Ît<sub>p</sub><sup>n-1</sup></italic> is due to the classic regression to the mean. (<bold>C</bold>) Same as (<bold>A</bold>) for the RSGP model. Each point reflects the trial-by-trial updated posterior mean.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55872-fig6-figsupp1-v1.tif"/></fig></fig-group></sec><sec id="s2-8"><title>RL-based sampling (MCMC model)</title><p>The sampling model, which was proposed byÂ <xref ref-type="bibr" rid="bib36">Haith and Krakauer, 2014</xref> is an adaptation of the epsilon-greedy strategy to a continuous variable. In our implementation, the model uses previous trials to estimate the most rewarding target interval, denoted <italic>t<sub>t</sub>*</italic>, and generates a new target interval for the current trial by sampling from a Gaussian distribution centered at <italic>t<sub>t</sub>*</italic>. The sample is further subjected to scalar noise to produce <italic>t<sub>p</sub></italic>, and the outcome of the current trial is used to update <italic>t<sub>t</sub>*</italic>.</p><p>Using simulations, we verified that this model allows the agent to maintain <italic>t<sub>t</sub>*</italic> close to the actual target interval, <italic>t<sub>t</sub></italic>, despite the stochasticity introduced by sampling and the production noise due to scalar variability (<xref ref-type="fig" rid="fig6">Figure 6C</xref>, <xref ref-type="fig" rid="fig6s1">Figure 6âfigure supplement 1A</xref>). However, when the model was parameterized to capture the monotonic relationship between <italic>Î¼(e<sup>n</sup>)</italic> and <italic>e<sup>n-1</sup></italic>, it could not capture the U-shaped relationship between <italic>Ï(e<sup>n</sup>)</italic> and <italic>e<sup>n-1</sup></italic> (<italic>s<sub>2</sub></italic>Â =Â 0.045 [-0.048 0.14], <xref ref-type="fig" rid="fig6">Figure 6C</xref>, middle). Based on these discrepancies, we concluded that the RL-based sampling is not consistent with how humans and monkeys regulate their timing behavior.</p></sec><sec id="s2-9"><title>RL-based directed search (DS model)</title><p>This model is a variant of RL in which the agent relies on the reward gradient to perform directed exploration. To adapt this model to our task, we built a generative process that adjusts <italic>t<sub>t</sub>*</italic> based on the reward gradient (<italic>Îr</italic>Â =Â <italic>r<sup>n-1</sup> - r<sup>n-2</sup></italic>) and interval gradient (<italic>Ît<sub>t</sub>Â =Â t<sub>t</sub><sup>n-1</sup>* - t<sub>t</sub><sup>n-2</sup>*</italic>) in the two preceding trials using the following algorithm: <italic>t<sub>t</sub></italic><sup>n</sup><italic>*</italic> = <italic>t<sub>t</sub></italic><sup>n-1</sup><italic>* + Î± âÎr âÎt<sub>t</sub> + n</italic><sub>e</sub>, where <italic>Î±</italic> represents the learning rate and <italic>n</italic><sub>e</sub> is the estimation noise (see MaterialsÂ andÂ methods). This algorithm moves <italic>t<sub>t</sub><sup>n</sup>*</italic> in the same direction as the previous trial when <italic>Îr</italic> is positive (reward-increase), reverses direction when <italic>Îr</italic> is negative (reward-decrease), and does not change <italic>t<sub>t</sub><sup>n</sup>*</italic> when there is no change in reward. Finally, <italic>t<sub>p</sub><sup>n</sup></italic> is generated with a scalar production noise.</p><p>We simulated the DS model using a wide range of parameters for both the learning rate and noise. Overall, the model was able to adjust behavior based on reward (<xref ref-type="fig" rid="fig6s1">Figure 6âfigure supplement 1B</xref>). However, upon close examination, we found the behavior of the DS model to be unstable. Specifically, unlike the MCMC and RSGP models (<xref ref-type="fig" rid="fig6s1">Figure 6âfigure supplement 1A,C</xref>), the DS model could easily lose track of the target interval and exhibit ârun-awayâ behavior, thatÂ is, generate <italic>t<sub>p</sub></italic> values that deviated from <italic>t<sub>t</sub></italic> for an extended number of consecutive trials (<xref ref-type="fig" rid="fig6s1">Figure 6âfigure supplement 1B</xref>). Simulating the model with the parameters fit to animalsâ behavior, the probability of run-away behavior in a typical 2000 trial session was 65.1 Â± 1.2% (see MaterialsÂ andÂ methods). This brittleness occurs because the updating rule in the DS model cannot implement the directed search when multiple consecutive trials are unrewarded.</p><p>To further assess the DS model, we focused on the subset of DS simulations that did not exhibit run-away behavior, and asked whether they were able to reproduce the key features in our data. For this subset of DS simulations, the model was able to capture the dependencies between consecutive trials relating <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>) to <italic>e<sup>n-1</sup></italic> (<xref ref-type="fig" rid="fig6">Figure 6D</xref>; <italic>m<sub>1</sub></italic>Â =Â 0.46 [0.44 0.48]), but not the U-shaped relationship between <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) and <italic>e<sup>n-1</sup></italic> (<xref ref-type="fig" rid="fig6">Figure 6D</xref>; <italic>s<sub>2</sub></italic>Â =Â â0.046 [â0.061 â0.03]).</p><p>We also note that both the MCMC and DS models were unable to capture the long-term correlations that were present in the behavioral data and the simulations of the RSGP model (<xref ref-type="fig" rid="fig6">Figure 6</xref>, bottom). This shortcoming can be potentially rectified by adding a slow process to the MCMC and DS models. However, this modification would not be able to rescue the inability of these alternative models in capturing the U-shaped relationship between <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) and <italic>e<sup>n-1</sup></italic>.</p></sec><sec id="s2-10"><title>Directed versus random exploration</title><p>Since RSGP was able to capture the full gamut of behavioral characteristics associated with the animalsâ exploratory behavior, we asked whether these explorations were directed or random. To do so, we performed extensive analyses comparing the behavior of the RSGP model to that of the MCMC and DS models. MCMC and DS can be viewed as autoregressive models whose coefficients depend on past rewards. The MCMC sets all coefficients to zero except a single trial in the past returned by the Metropolis-Hastings sampling algorithm. The DS sets all coefficients to zero except the last two that are determined based on the corresponding reward gradient and a fixed learning rate. The RSGP can also be written in terms of an autoregressive model with nonstationary reward-dependent coefficients and noise. However, the key feature that distinguishes the RSGP is that it performs Bayesian inference over <italic>t<sub>t</sub></italic>. The covariance function (or kernel) of the Gaussian process defines the coefficients and acts as a prior for future samples. The reward-sensitive kernel in the RSGP allows the coefficients to be updated continuously based on the history of past trial outcomes. When the reward rate is high, RSGP implements a strategy that is akin to directed exploration: it increases its reliance on the prior and drives responses toward previously rewarded trials. In contrast, when the reward rate is low, the RSGP relies more on random explorations: it generates samples from a wider distribution. Therefore, RSGP strikes an optimal balance (in the Bayesian sense) between bias (directed exploration) and variance (random exploration) as needed by the history of outcomes.</p><p>The interpretation of the effect of reward in terms of both directed and random explorations predicts that the monotonic relationship between <italic>Î¼(e<sup>n</sup>)</italic> and <italic>e<sup>n-1</sup></italic>, which we originally explained in terms of memory drift, should additionally be sensitive to trial outcome. To test this prediction, we returned to our probabilistic reward experiment in which trial outcome was dissociated from error magnitude, and asked whether the relationship between <italic>Î¼(e<sup>n</sup>)</italic> and <italic>e<sup>n-1</sup></italic> was modulated by feedback. Remarkably, results confirmed this prediction. The monotonic relationship between <italic>Î¼(e<sup>n</sup>)</italic> and <italic>e<sup>n-1</sup></italic> was stronger after trials that subjects received positive feedback (<xref ref-type="fig" rid="fig5s2">Figure 5âfigure supplement 2A</xref>), and this effect was consistent with the behavior of the RSGP model (<xref ref-type="fig" rid="fig5s2">Figure 5âfigure supplement 2B</xref>). These results indicate that humans and monkeys use a combination of directed and random exploration strategies in accordance with the RSGP model that uses past rewards to adjust both the mean and variance of future responses.</p></sec><sec id="s2-11"><title>Slow fluctuations in the cortico-basal ganglia circuits</title><p>Recently, we identified a cortico-basal ganglia circuit that plays a causal role in animalsâ performance during a flexible timing behavior (<xref ref-type="bibr" rid="bib119">Wang et al., 2018</xref>). A combination of population data analysis and modeling revealed that animals control the movement initiation time by adjusting a tonic signal in the thalamus that sets the speed at which activity in the dorsomedial frontal cortex (DMFC) and caudate evolve toward an action-triggering state. Based on these results, we hypothesized that memory drifts in behavior may be accompanied by drifts of neural activity in these areas.</p><p>To test this hypothesis, we recorded separately from populations of neurons in candidate regions of DMFC, caudate and thalamus. Based on previous work suggesting the importance of initial conditions in movement initiation time (<xref ref-type="bibr" rid="bib7">Carpenter and Williams, 1995</xref>; <xref ref-type="bibr" rid="bib14">Churchland et al., 2006</xref>; <xref ref-type="bibr" rid="bib51">Jazayeri and Shadlen, 2015</xref>; <xref ref-type="bibr" rid="bib40">Hauser et al., 2018</xref>; <xref ref-type="bibr" rid="bib62">Lara et al., 2018</xref>; <xref ref-type="bibr" rid="bib92">Remington et al., 2018b</xref>), we asked whether neural activity near the time of Set (i.e. onset of motor timing epoch) could be used to predict the slow fluctuations in error, which we denote by <italic>e</italic><sub>slow</sub> (<xref ref-type="fig" rid="fig7">Figure 7A</xref>, Right, red line). To estimate <italic>e</italic><sub>slow</sub> on a trial-by-trial basis, we relied on the RSGP model, which readily decomposed the <italic>t<sub>p</sub></italic> time series into a slow memory-dependent and a fast reward-dependent component. We fitted the RSGP in a context-specific manner and then inferred the value of <italic>e</italic><sub>slow</sub> for each trial in each session (see Materials and methods).</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Representation of slow fluctuations of behavior in population activity.</title><p>(<bold>A</bold>) The schematics of the analysis for identifying the drift direction across a population of simultaneously recorded neurons. Top left: The rows show spike times (ticks) of 17 simultaneously recorded thalamic neurons in an example trial. From each trial, we measured spike counts within a 250 ms window before Set (gray region). Bottom left: The vector of spike counts from each trial (gray vertical line) was combined providing a matrix containing the spike counts of all neurons across all trials. Middle: The spike counts across trials and neurons were used as the regressor in a multi-dimensional linear regression model with weight vector, <bold><italic>Î²</italic></bold>, to predict the slow component of error (<italic>e<sub>slow</sub></italic>). Right: We fitted the RSGP to errors (black dots, <italic>e</italic>) and then inferred <italic>e<sub>slow</sub></italic>. The plot shows the neural prediction (<italic>z<sup>n</sup></italic>, blue) overlaid on <italic>e<sub>slow</sub></italic> derived from RSGP fit to behavior (red line). (<bold>B</bold>) Top: Parasagittal view of one of the animals (monkey D) with a red ellipse showing the regions targeted for electrophysiology. The corresponding stereotactic coordinates relative to the anterior commissure in each animal (AP: anterior posterior; ML: mediolateral). Recorded thalamic neurons were from a region of the thalamus with monosynaptic connections to DMFC (inset: antidromically activated spikes in the thalamus.) Bottom: Histogram of the correlation coefficients between <italic>e</italic><sub>slow</sub> inferred from the RSGP model and <italic>z<sup>n</sup></italic><sub>Th</sub> (projection of thalamic population activity on drift direction) across recording sessions. Note that some correlations are negative because of cross-validation. Black bars correspond to the sessions in which the correlation was significantly positive (**p&lt;0.01; hypothesis test by shuffling trial orders). The average correlation across all sessions and the average of those with significantly positive correlations are shown by gray and black triangles, respectively. (<bold>C</bold>) Same as B for DMFC. (<bold>D</bold>) Same as B for the caudate.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55872-fig7-v1.tif"/></fig><p>We measured spike counts within a 250 ms window before Set (<xref ref-type="fig" rid="fig7">Figure 7A</xref>, Left), denoted <bold><italic>r</italic></bold>, and formulated a multi-dimensional linear regression model to examine the trial-by-trial relationship between <bold><italic>r</italic></bold> and <italic>e</italic><sub>slow</sub>. We computed the regression weight, <bold><italic>Î²</italic></bold>, that when multiplied by <bold><italic>r</italic></bold>, would provide the best linear fit to <italic>e</italic><sub>slow</sub>. Considering the vector of spike counts in each trial as a point in a coordinate system where each axis corresponds to the activity of one neuron (âstate spaceâ), <bold><italic>Î²</italic></bold> can be viewed as the direction along which modulations of spike counts most strongly correlate with memory drifts. Accordingly, we will refer to the direction associated with <bold><italic>Î²</italic></bold> as the drift direction and will denote the strength of activity along that direction by <italic>z</italic> (<italic>z</italic>Â =Â <bold><italic>rÎ²</italic></bold>, <xref ref-type="fig" rid="fig7">Figure 7A</xref>, Right, blue line).</p><p>To test the hypothesis that memory drifts were accompanied by drifts of neural activity in the thalamus, DMFC, and caudate, we used a cross-validated procedure (see MaterialsÂ andÂ methods) to compute <bold><italic>Î²</italic></bold>, derive a trial-by-trial estimate of <italic>z</italic>, and measure the correlation between <italic>z</italic> and <italic>e</italic><sub>slow</sub> on a session-by-session basis. We found strong evidence that neural activity in all three areas exhibited slow fluctuations in register with memory drifts. In 91%,Â ~79%, andÂ ~45% of sessions, the activity along the drift direction in the thalamus (<italic>z</italic><sub>Th</sub>), DMFC (<italic>z</italic><sub>DMFC</sub>), and caudate (<italic>z</italic><sub>Cd</sub>), respectively, was significantly correlated with <italic>e</italic><sub>slow</sub> (<xref ref-type="fig" rid="fig7">Figure 7BâD</xref>, p&lt;0.01, null hypothesis test by shuffling trials).</p></sec><sec id="s2-12"><title>Reward-dependent regulation of variability in the thalamus</title><p>Next, we analyzed the statistics of neurallyÂ inferred drift (<italic>z</italic>) across pairs of consecutive trials using the same approach we applied to error statistics in behavioral data (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). To do so, we extracted pairs of (<italic>e<sup>n-1</sup></italic>, <italic>z<sup>n</sup></italic>) for consecutive trials of the same type and binned them depending on the value of <italic>e<sup>n-1</sup></italic>. Because all three areas carried a signal reflecting memory drifts, we expected <italic>Î¼</italic>(<italic>z<sup>n</sup></italic>) in all the areas to have a monotonic relationship with <italic>e<sup>n-1</sup></italic>. Results were consistent with this prediction as evidenced by the slope of a linear regression model relating <italic>Î¼</italic>(<italic>z<sup>n</sup></italic>) to <italic>e<sup>n-1</sup></italic> (filled circles in <xref ref-type="fig" rid="fig8">Figure 8BâD</xref> top, <xref ref-type="table" rid="table3">Table 3</xref>). Moreover, this relationship was absent for consecutive trials associated with different effectors (open circles in <xref ref-type="fig" rid="fig8">Figure 8BâD</xref> top, <xref ref-type="table" rid="table3">Table 3</xref>). These results substantiate the presence of context-specific fluctuations of neural activity inÂ register with drifts in animalsâ memory of <italic>t<sub>t</sub></italic> across populations of neurons in the thalamus, DMFC and caudate.</p><fig-group><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Alignment of reward-dependent neural variability and drift in thalamus, but not in DMFC and caudate.</title><p>(<bold>A</bold>) Various hypotheses for how population neural activity could be related to produced intervals (<italic>t<sub>p</sub></italic>) shown schematically in two dimensions (two neurons). Top: The average neural activity (colored circles) is not systematically organized with respect to <italic>t<sub>p</sub></italic>, and the trial-by-trial variability of spike counts for a given <italic>t<sub>p</sub></italic> around the mean (gray area) is not modulated by the size of the error. The inset shows how error increases as <italic>t<sub>p</sub></italic> moves away from the target interval (<italic>t<sub>t</sub></italic>). Middle: Projection of average activity along a specific dimension (dotted line) is systematically ordered with respect to <italic>t<sub>p</sub></italic>, but the variability (small stacked arrows) does not depend on the size of the error. Bottom: Projection of average activity along a specific dimension is systematically ordered with respect to <italic>t<sub>p</sub></italic> and the variability along the same axis increases with the size of error. (<bold>B</bold>) The relationship between neural activity in the thalamus on trial <italic>n</italic> and relative error in the preceding trial (<italic>e<sup>n-1</sup></italic>). Top: Expected mean of population activity on trial <italic>n</italic> (<italic>Î¼</italic>(<italic>z<sup>n</sup></italic>)) along the drift direction (<bold><italic>Î²</italic></bold>) as a function of <italic>e<sup>n-1</sup></italic>. Bottom: Expected standard deviation of population activity along the drift direction on trial <italic>n</italic> (<italic>Ï</italic>(<italic>z<sup>n</sup></italic>)) as a function of <italic>e<sup>n-1</sup></italic>. Results are shown in the same format as in <xref ref-type="fig" rid="fig3">Figure 3B</xref> (thick lines: same effector; thin lines: different effectors). (<bold>C</bold>) and (<bold>D</bold>) Same as (<bold>B</bold>) for population activity in DMFC and caudate. See <xref ref-type="fig" rid="fig8s1">Figure 8âfigure supplement 1</xref> for the result of individual animals. The results in panels B-D were based on spike counts in a fixed 250-ms time window before Set. <xref ref-type="fig" rid="fig8s4">Figure 8âfigure supplement 4</xref> shows that these characteristics were evident throughout the trial. <xref ref-type="fig" rid="fig8">Figure 8</xref> andÂ <xref ref-type="fig" rid="fig8s5">Figure 8âfigure supplement 5</xref> show the effects for each effector and that the effect for different effectors were associated with different patterns of activity across the same population of neurons.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55872-fig8-v1.tif"/></fig><fig id="fig8s1" position="float" specific-use="child-fig"><label>Figure 8âfigure supplement 1.</label><caption><title>The relationship between neural activity on trial <italic>n</italic> to relative error in the preceding trial (<italic>e<sup>n-1</sup></italic>) in three brain areas and two animals.</title><p>(<bold>A</bold>) and (<bold>B</bold>) Same format as in <xref ref-type="fig" rid="fig8">Figure 8BâD</xref>, with the addition of confidence intervals (1â99%;Â shaded region) obtained by randomly sampling a subset of trials in each bin of <italic>e<sup>n-1</sup></italic>. Data shown for the two animals separately.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55872-fig8-figsupp1-v1.tif"/></fig><fig id="fig8s2" position="float" specific-use="child-fig"><label>Figure 8âfigure supplement 2.</label><caption><title>Drift and reward-dependent variability in the three brain areas inferred from comparable numbers of simultaneously recorded neurons.</title><p>(<bold>A</bold>) Histogram of the number of simultaneously recorded neurons in the thalamus, DMFC and caudate across sessions. The averages are shown on top. (<bold>B</bold>) The number of simultaneously recorded neurons in the thalamus subsampled by a factor of 2 to approximately match DMFC. (<bold>C</bold>) Analysis of drift and reward-dependent variability for the sub-sampled thalamic population, shown in the same format as <xref ref-type="fig" rid="fig8">Figure 8B</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55872-fig8-figsupp2-v1.tif"/></fig><fig id="fig8s3" position="float" specific-use="child-fig"><label>Figure 8âfigure supplement 3.</label><caption><title>Drift and variability of spike count along the direction that decodes the produced interval (<italic>t<sub>p</sub></italic>) in the thalamus, DMFC, and caudate.</title><p>(<bold>A</bold>) Histogram of the correlation coefficients between <italic>t<sub>p</sub></italic> and the output of a decoder of <italic>t<sub>p</sub></italic> from neural data, denoted <italic>z</italic> (black: significantly positive). Results are shown with the same format as in <xref ref-type="fig" rid="fig7">Figure 7B</xref>. (<bold>B</bold>) Mean (top; <italic>Î¼(z<sup>n</sup>)</italic>) and standard deviation (bottom; <italic>Ï(z<sup>n</sup>)</italic>) of projected neural activity as a function of error in the preceding trial (<italic>e<sup>n-1</sup></italic>). Results are shown with the same format as in <xref ref-type="fig" rid="fig8">Figure 8B</xref> (thick lines: same effector; thin lines: different effectors).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55872-fig8-figsupp3-v1.tif"/></fig><fig id="fig8s4" position="float" specific-use="child-fig"><label>Figure 8âfigure supplement 4.</label><caption><title>Reward-dependent neural variability throughout the trial.</title><p>(<bold>A</bold>) Average standard deviation of population activity in the thalamus at different points throughout the trial aligned to the Cue, Tar, Set, and Go events. For each time point, we inferred the drift direction using the same analysis shown in <xref ref-type="fig" rid="fig7">Figure 7A</xref>, and projected spike counts onto the drift direction. We denote the projection of trial <italic>n</italic> by <italic>z<sup>n</sup></italic>. Each column shows the standard deviation of <italic>z<sup>n</sup></italic> (<italic>Ï</italic>(<italic>z<sup>n</sup></italic>)) as a function of error in the preceding trial (<italic>e<sup>n-1</sup></italic>) based on spike counts within a 250-ms window centered at a particular time point in the trial. Black square: the time window used for the rest of this paper. We grouped <italic>e<sup>n-1</sup></italic> into 12 bins, 6 for negative <italic>e<sup>n-1</sup></italic> and 6 for positive <italic>e<sup>n-1</sup></italic>. Results are shown separately for conditions in which trials <italic>n-1</italic> and <italic>n</italic> were of the same or different effectors. (***p&lt;0.001, using a two-sample F-test comparing the variance of <italic>z<sup>n</sup></italic> between rewarded and unrewarded trials separately for positive and negative values of <italic>e<sup>n-1</sup></italic>; H0: equal variance for at least one of the comparisons). (<bold>B</bold>) and (<bold>C</bold>) Same as (<bold>A</bold>) for DMFC and caudate. Results are for data combined across two animals.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55872-fig8-figsupp4-v1.tif"/></fig><fig id="fig8s5" position="float" specific-use="child-fig"><label>Figure 8âfigure supplement 5.</label><caption><title>Analysis of neural data in relation to saccade direction.</title><p>(<bold>A</bold>) Error statistics across consecutive trials. <italic>Î¼(e<sup>n</sup>)</italic> (top) and <italic>Ï(e<sup>n</sup>)</italic> (bottom) as a function of <italic>e<sup>n-1</sup></italic>. Similar to the main paper, we tested the U-shaped profile using quadratic regression. The coefficients of the squared term was not significantly different between the two directions (Monkeys: 0.26 [0.17, 0.34] vs 0.27 [0.2, 0.34]; Humans: 0.33 [0.063, 0.59] vs 0.4 [0.24, 0.55]). (<bold>B</bold>) A Venn diagram showing the number of individual neurons in three brain areas whose spiking during a 250 ms time window before Set was significantly different across effectors (Eye/Hand; p&lt;0.01, two-sample <italic>t</italic>-test), target intervals (Short/Long; p&lt;0.01, two-sample <italic>t</italic>-test), saccade directions (Left/Right; p&lt;0.01, two-sample <italic>t</italic>-test), and predictive of the produced interval (p&lt;0.01, shuffling test). The number of neurons in each category is indicated in the diagram. Among the neurons that were predictive of the produced interval (intersection of blue and dark red), 3/320 in the thalamus, 17/191 in DMFC, and 1/85 in the caudate were direction selective.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55872-fig8-figsupp5-v1.tif"/></fig><fig id="fig8s6" position="float" specific-use="child-fig"><label>Figure 8âfigure supplement 6.</label><caption><title>Analysis of speed variability across single trials as a function of reward.</title><p>(<bold>A</bold>) Schematics showing how we estimated the speed of population neural trajectories for single trials (<italic>v</italic><sup>n</sup>). We estimated the average speed for each trial by averaging the Euclidean distance of population spike counts between nearby points (<italic>dt</italic>Â =Â 125 ms) along the trajectory. To minimize the differential contribution of neurons with different average firing rates to speed estimates, spike counts for each neuron was normalized (z-score) across trials and time bins. (<bold>B</bold>) Variability of speed estimates (<inline-formula><mml:math id="inf11"><mml:msqrt><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:msqrt></mml:math></inline-formula>) after rewarded trials (+Rew<sup>n-1</sup>, ordinate) compared to unrewarded trials (-Rew<sup>n-1</sup>, abscissa) for consecutive trials of the same (top row) and different effector (bottom row) in the thalamus (left), DMFC (middle) and caudate (right). In every session, each trial type contributed two points to each panel, one for when the preceding error was positive and one for when it was negative. We treated these two error conditions independently so as to minimize any potential dependence of our estimated <inline-formula><mml:math id="inf12"><mml:msqrt><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mi>v</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:msqrt></mml:math></inline-formula> on average speed <italic>v</italic><sup>n</sup> that may change depending on the sign of error (<xref ref-type="bibr" rid="bib119">Wang et al., 2018</xref>). The scatter plot in each panel shows the distribution of speed variability for trials that succeeded a rewarded trial (ordinate) relative to the distribution of speed variability for trials that succeeded an unrewarded trial (abscissa). To test whether the speed was significantly different between these two conditions, we used a two-tail paired sample <italic>t-</italic>test to determine whether and in which direction the data deviated significantly from the unity line (diagonal). The distribution of the difference between the two conditions is shown on the top right of each panel, and the mean for each distribution is indicated (triangle). p-Values for each test are indicated. (Thalamus: same effector, t<sub>271</sub>Â =Â 0.94, different effector, t<sub>271</sub>Â =Â â0.88, DMFC: same effector, t<sub>313</sub>Â =Â 2.69, different effector, t<sub>313</sub>Â =Â 1.03, Caudate: same effector, t<sub>161</sub>Â =Â 2.67, different effector, t<sub>161</sub>Â =Â 1.47).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-55872-fig8-figsupp6-v1.tif"/></fig></fig-group><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Regression model fits relating spike count along the drift direction on trial <italic>n</italic> (<italic>z<sup>n</sup></italic>) to error in trial <italic>n-1</italic> (<italic>e<sup>n-1</sup></italic>).</title><p> <italic>m<sub>0</sub></italic> and <italic>m<sub>1</sub></italic> are parameters of the linear regression model relating the mean of <italic>z<sup>n</sup></italic> (<italic>Î¼</italic>(<italic>z<sup>n</sup></italic>)) to <italic>e<sup>n-1</sup></italic>, thatÂ is, <italic>Î¼</italic>(<italic>z<sup>n</sup></italic>)Â <italic>=Â m<sub>0</sub>+m<sub>1</sub>e<sup>n-1</sup>. s<sub>0</sub></italic>, <italic>s<sub>1</sub></italic> and <italic>s<sub>2</sub></italic> are parameters of the quadratic regression model relating the standard deviation of <italic>z<sup>n</sup></italic> (<italic>Ï</italic>(<italic>z<sup>n</sup></italic>)) to <italic>e<sup>n-1</sup></italic>, thatÂ is, <italic>Ï</italic>(<italic>z<sup>n</sup></italic>)Â <italic>=Â s<sub>0</sub>+s<sub>1</sub>e<sup>n-1</sup>+s<sub>2</sub></italic>(<italic>e<sup>n-1</sup></italic>)<italic><sup>2</sup></italic>. Fit parameters are shown separately for the thalamus, DMFC and caudate and further separated depending on whether trial <italic>n-1</italic> and <italic>n</italic> were of the same or different effectors. Bold values for <italic>m<sub>1</sub></italic> and <italic>s<sub>2</sub></italic> were significantly positive (** p&lt;0.01, 1% and 99% confidence intervals of the estimation were shown).</p></caption><table frame="hsides" rules="groups"><thead><tr><th><italic>Brain area</italic></th><th colspan="2">Parameters</th><th>Same effector</th><th>Different effector</th></tr></thead><tbody><tr><td rowspan="2"><italic>Thalamus</italic></td><td><italic>Î¼</italic>(<italic>z<sup>n</sup></italic>)</td><td><italic>m<sub>1</sub></italic> <break/> <italic>m<sub>0</sub></italic></td><td><bold>0.13</bold> [0.090 0.18] <break/>0.008 [0.001 0.016]</td><td>0.0038 [-0.025 0.032] <break/>0.0041 [-0.001 0.009]</td></tr><tr><td><italic>Ï</italic>(<italic>z<sup>n</sup></italic>)</td><td><italic>s<sub>2</sub></italic> <break/> <italic>s<sub>1</sub></italic> <break/> <italic>s<sub>0</sub></italic></td><td><bold>0.26</bold> [0.19 0.34] <break/>0.005 [-0.013 0.023] <break/>0.06 [0.052 0.059]</td><td>0.0031 [-0.031 0.037] <break/>â0.001 [-0.01 0.0067] <break/>0.058 [0.057 0.0597]</td></tr><tr><td rowspan="2"><italic>DMFC</italic></td><td><italic>Î¼</italic>(<italic>z<sup>n</sup></italic>)</td><td><italic>m<sub>1</sub></italic> <break/> <italic>m<sub>0</sub></italic></td><td valign="top"><bold>0.11</bold> [0.0334 0.18] <break/>0.012 [-0.0003 0.024]</td><td valign="top">â0.0027 [-0.022 0.017] <break/>0.0069 [0.0036 0.01]</td></tr><tr><td><italic>Ï</italic>(<italic>z<sup>n</sup></italic>)</td><td><italic>s<sub>2</sub></italic> <break/> <italic>s<sub>1</sub></italic> <break/> <italic>s<sub>0</sub></italic></td><td valign="top">0.071 [-0.003 0.12] <break/>0.0085 [-0.0022 0.019] <break/>0.046 [0.044 0.048]</td><td valign="top">0.0051 [-0.037 0.047] <break/>â0.0004 [-0.01 0.009] <break/>0.0487 [0.047 0.051]</td></tr><tr><td rowspan="2"><italic>Caudate</italic></td><td><italic>Î¼</italic>(<italic>z<sup>n</sup></italic>)</td><td><italic>m<sub>1</sub></italic> <break/> <italic>m<sub>0</sub></italic></td><td valign="top"><bold>0.068</bold> [0.016 0.12] <break/>0.0068 [-0.002 0.015]</td><td valign="top">0.007 [-0.016 0.030] <break/>0.018 [0.014 0.022]</td></tr><tr><td><italic>Ï</italic>(<italic>z<sup>n</sup></italic>)</td><td><italic>s<sub>2</sub></italic> <break/> <italic>s<sub>1</sub></italic> <break/> <italic>s<sub>0</sub></italic></td><td valign="top">0.069 [-0.005 0.14] <break/>0.0006 [-0.009 0.011] <break/>0.048 [0.046 0.050]</td><td valign="top">â0.002 [-0.064 0.060] <break/>0.001 [-0.013 0.015] <break/>0.048 [0.045 0.051]</td></tr></tbody></table></table-wrap><p>A critical question was whether, in any of these areas, reward regulates the variability of neural activity. Importantly, the reward-dependent modulation of variability should be restricted to the drift direction in the population activity (<xref ref-type="fig" rid="fig8">Figure 8A</xref>, bottom); otherwise, this strategy will not be able to effectively counter the degrading effect of memory drift in a context-dependent manner. In thalamus, <italic>Ï</italic>(<italic>z<sup>n</sup></italic><sub>Th</sub>) exhibited the characteristic U-shape profile with respect to <italic>e<sup>n-1</sup></italic> (<xref ref-type="fig" rid="fig8">Figure 8B</xref> bottom), which we verified quantitatively by comparing the variance of <italic>z<sup>n</sup></italic><sub>Th</sub> for rewarded and unrewarded trials (p&lt;0.01, two-sample F-test for equal variances on <italic>z<sup>n</sup></italic><sub>Th</sub>, F(5608,4266)Â =Â 1.08 for negative <italic>e<sup>n-1</sup></italic> and p&lt;0.001 for positive <italic>e<sup>n-1</sup></italic>, F(4723,6125)Â =Â 1.28), and by testing the profile using quadratic regression (see MaterialsÂ andÂ methods; <xref ref-type="table" rid="table3">Table 3</xref>).</p><p>As an important control, we performed the same analysis between consecutive trials associated with different effectors and we found no significant relationship between <italic>Ï</italic>(<italic>z<sup>n</sup></italic><sub>Th</sub>) and <italic>e<sup>n-1</sup></italic> (p=0.91, two-sample F-test for equal variances, F(5332,3984)Â =Â 1.0 for the negative <italic>e<sup>n-1</sup></italic>; p=0.97 for the positive <italic>e<sup>n-1</sup></italic>, F(4234,5857)Â =Â 0.99). Results did not change when we repeated these analyses after square-root transformation ofÂ spike counts to accountÂ for Poisson-like variability. Taken together, these results indicate that variability of thalamic responses was modulated by reward, and that this modulation was aligned to the drift direction.</p><p>Unlike the thalamus, in DMFC and caudate, variability along the memory drift was relatively independent of <italic>e<sup>n-1</sup></italic> (<xref ref-type="fig" rid="fig8">Figure 8C</xref> bottom, 8D bottom), thatÂ is, <italic>Ï</italic>(z<italic><sup>n</sup></italic><sub>DMFC</sub>) and <italic>Ï</italic>(z<italic><sup>n</sup></italic><sub>Cd</sub>) were not significantly different after rewarded and unrewarded trials (two-sample F-test for equal variances, F(6244,4818)Â =Â 0.87, p=0.99 for the negative <italic>e<sup>n-1</sup></italic>; F(4825,7572)Â =Â 1.002, p=0.021 for the positive <italic>e<sup>n-1</sup></italic>, see <xref ref-type="fig" rid="fig8s1">Figure 8âfigure supplement 1</xref> for each animal separately). We verified the absence of a U-shape profile using quadratic regression (see MaterialsÂ andÂ methods; <xref ref-type="table" rid="table3">Table 3</xref>) and ensured that the lack of modulation in DMFC and caudate compared to the thalamus was not because of a difference in the number of simultaneously recorded neurons (<xref ref-type="fig" rid="fig8s2">Figure 8âfigure supplement 2</xref>). Together, these results provide evidence that the effect of reward in DMFC and caudate was not aligned to the <bold><italic>Î²</italic></bold> associated with the slow fluctuations. We note, however, that an unconstrained decoding strategy aimed at simultaneously capturing both components of errors could find directions along which the slow fluctuations and the effect of reward are aligned in all three areas (<xref ref-type="fig" rid="fig8s3">Figure 8âfigure supplement 3</xref>, <xref ref-type="table" rid="table4">Table 4</xref>).</p><table-wrap id="table4" position="float"><label>Table 4.</label><caption><title>Regression model fits relating spike count along the direction that predicts produced interval (<italic>t<sub>p</sub></italic>) on trial <italic>n</italic> (<italic>z<sup>n</sup></italic>) to error in trial <italic>n-1</italic> (<italic>e<sup>n-1</sup></italic>).</title><p><italic>m<sub>0</sub></italic> and <italic>m<sub>1</sub></italic> are parameters of the linear regression model relating the mean of <italic>z<sup>n</sup></italic> (<italic>Î¼</italic>(<italic>z<sup>n</sup></italic>)) to <italic>e<sup>n-1</sup></italic>; i.e., <italic>Î¼</italic>(<italic>z<sup>n</sup></italic>)Â <italic>=Â m<sub>0</sub>+m<sub>1</sub>e<sup>n-1</sup>. s<sub>0</sub></italic>, <italic>s<sub>1</sub></italic> and <italic>s<sub>2</sub></italic> are parameters of the quadratic regression model relating the standard deviation of <italic>z<sup>n</sup></italic> (<italic>Ï</italic>(<italic>z<sup>n</sup></italic>)) to <italic>e<sup>n-1</sup></italic>; i.e., <italic>Ï</italic>(<italic>z<sup>n</sup></italic>)Â <italic>=Â s<sub>0</sub>+s<sub>1</sub>e<sup>n-1</sup>+s<sub>2</sub></italic>(<italic>e<sup>n-1</sup></italic>)<italic><sup>2</sup></italic>. Fit parameters are shown separately for the thalamus, DMFC and caudate and further separated depending on whether trial <italic>n-1</italic> and <italic>n</italic> were of the same or different effectors. Bold indicated significantly positive value (p&lt;0.01, 1% and 99% confidence intervals of the estimation were shown).</p></caption><table frame="hsides" rules="groups"><thead><tr><th><italic>Brain area</italic></th><th colspan="2">Parameters</th><th>Same effector</th><th>Different effector</th></tr></thead><tbody><tr><td rowspan="2"><italic>Thalamus</italic></td><td><italic>Î¼</italic>(<italic>z<sup>n</sup></italic>)</td><td><italic>m<sub>1</sub></italic> <break/> <italic>m<sub>0</sub></italic></td><td><bold>0.13</bold> [0.096 0.17] <break/>0.012 [0.005 0.019]</td><td><bold>0.018</bold> [0.002 0.036] <break/>0.006 [0.002 0.01]</td></tr><tr><td><italic>Ï</italic>(<italic>z<sup>n</sup></italic>)</td><td><italic>s<sub>2</sub></italic> <break/> <italic>s<sub>1</sub></italic> <break/> <italic>s<sub>0</sub></italic></td><td><bold>0.32</bold> [0.19 0.44] <break/>0.012 [-0.019 0.046] <break/>0.063 [0.055 0.071]</td><td>â0.019 [-0.07 0.066] <break/>â0.003 [-0.02 0.014] <break/>0.065 [0.061 0.069]</td></tr><tr><td rowspan="2"><italic>DMFC</italic></td><td><italic>Î¼</italic>(<italic>z<sup>n</sup></italic>)</td><td><italic>m<sub>1</sub></italic> <break/> <italic>m<sub>0</sub></italic></td><td valign="top"><bold>0.091</bold> [0.043 0.14] <break/>0.014 [0.0046 0.024]</td><td valign="top">0.011 [-0.0073 0.29] <break/>0.011 [0.0075 0.015]</td></tr><tr><td><italic>Ï</italic>(<italic>z<sup>n</sup></italic>)</td><td><italic>s<sub>2</sub></italic> <break/> <italic>s<sub>1</sub></italic> <break/> <italic>s<sub>0</sub></italic></td><td valign="top"><bold>0.15</bold> [0.087 0.21] <break/>â0.006 [-0.022 0.009] <break/>0.049 [0.045 0.052]</td><td valign="top">â0.017 [-0.071 0.036] <break/>0.001 [-0.0041 0.024] <break/>0.051 [0.047 0.054]</td></tr><tr><td rowspan="2"><italic>Caudate</italic></td><td><italic>Î¼</italic>(<italic>z<sup>n</sup></italic>)</td><td><italic>m<sub>1</sub></italic> <break/> <italic>m<sub>0</sub></italic></td><td valign="top"><bold>0.077</bold> [0.036 0.12] <break/>0.010 [0.0014 0.018]</td><td valign="top">0.007 [-0.012 0.027] <break/>0.015 [0.011 0.019]</td></tr><tr><td><italic>Ï</italic>(<italic>z<sup>n</sup></italic>)</td><td><italic>s<sub>2</sub></italic> <break/> <italic>s<sub>1</sub></italic> <break/> <italic>s<sub>0</sub></italic></td><td valign="top"><bold>0.16</bold> [0.11 0.21] <break/>0.005 [-0.007 0.17] <break/>0.050 [0.047 0.053]</td><td valign="top"><bold>0.044</bold> [0.016 0.072] <break/>â0.0025 [-0.01 0.0047] <break/>0.051 [0.049 0.053]</td></tr></tbody></table></table-wrap></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Variability is a ubiquitous property of behavior that can either degrade performance or promote learning through exploration. Here, we were able to advance our understanding of the function and neurobiology of variability in three directions. First, we found an important role for memory drifts in timing variability and showed that humans and monkeys use reward to calibrate memory against such drifts. Second, using model-based analysis of behavior, we showed how a combination of directed and random explorations promoted by trial outcome can manifest as modulations of behavioral variability. Finally, we characterized the neural underpinnings of variability associated with memory drifts and trial outcome across populations of neurons within the cortical-basal ganglia circuits.</p><sec id="s3-1"><title>Role of memory drift in behavioral variability</title><p>A key feature of the behavioral data was the presence of slow fluctuations in produced intervals leading to serial correlations extending over minutes and across dozens of trials. These fluctuations have been reported in various behavioral tasks (<xref ref-type="bibr" rid="bib32">Gilden et al., 1995</xref>; <xref ref-type="bibr" rid="bib11">Chen et al., 1997</xref>; <xref ref-type="bibr" rid="bib79">Murakami et al., 2017</xref>) and are typically attributed to fatigue, arousal, or other nonspecific factors modulating internal states (<xref ref-type="bibr" rid="bib67">Luck et al., 1997</xref>; <xref ref-type="bibr" rid="bib83">Niell and Stryker, 2010</xref>; <xref ref-type="bibr" rid="bib38">Harris and Thiele, 2011</xref>; <xref ref-type="bibr" rid="bib56">Kato et al., 2012</xref>; <xref ref-type="bibr" rid="bib66">Lee and Dan, 2012</xref>; <xref ref-type="bibr" rid="bib116">Vinck et al., 2015</xref>). Although global internal state modulations are likely present in our experiment, they cannot be the only driver since the serial correlations were strongly context-specific. Based on these observations, we reasoned that these fluctuations may reflect drifts in memory. This interpretation was consistent with the results of our control experiment showing diminished serial correlations when memory demands were reduced (<xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1D</xref>). However, further work is needed to fully characterize the nature of these slow fluctuations. For example, the slow component may be in part a reflection of an active averaging process to maintain a stable memory (<xref ref-type="bibr" rid="bib52">Joiner and Smith, 2008</xref>) as suggested by error-based motor learning studies (<xref ref-type="bibr" rid="bib102">Smith et al., 2006</xref>; <xref ref-type="bibr" rid="bib123">Wolpert et al., 2011</xref>; <xref ref-type="bibr" rid="bib47">Huberdeau et al., 2015</xref>). Indeed, behavioral results in the probabilistic reward experiment (<xref ref-type="fig" rid="fig5s2">Figure 5âfigure supplement 2A</xref>) as well as corresponding fits the RSGP model (<xref ref-type="fig" rid="fig5s2">Figure 5âfigure supplement 2B</xref>) suggest that slow fluctuations may in part be controlled by reward-dependent exploratory behavior.</p><p>A more puzzling observation was the specificity of memory drifts with respect to the target interval for the same effector. We currently do not have a definite explanation for this result, but our previous work in the domain of time interval production (<xref ref-type="bibr" rid="bib119">Wang et al., 2018</xref>) and reproduction (<xref ref-type="bibr" rid="bib92">Remington et al., 2018b</xref>) as well as other studies in the motor system (<xref ref-type="bibr" rid="bib1">Afshar et al., 2011</xref>; <xref ref-type="bibr" rid="bib3">Ames et al., 2014</xref>; <xref ref-type="bibr" rid="bib98">Sheahan et al., 2016</xref>; <xref ref-type="bibr" rid="bib40">Hauser et al., 2018</xref>; <xref ref-type="bibr" rid="bib117">Vyas et al., 2018</xref>) suggest that several aspects of movement control can be understood in terms of adjusting inputs and initial conditions of a dynamical system (<xref ref-type="bibr" rid="bib16">Churchland et al., 2012</xref>; <xref ref-type="bibr" rid="bib91">Remington et al., 2018a</xref>). Accordingly, the interval specificity of the memory drifts suggests that distinct patterns of neural activity set the interval-dependent input and/or initial condition, which is consistent with our previous work (<xref ref-type="bibr" rid="bib119">Wang et al., 2018</xref>).</p></sec><sec id="s3-2"><title>Role of reinforcement in behavioral variability</title><p>In our task, reinforcement is the only information provided experimentally that subjects can use to calibrate their memory of the target interval. Therefore, the computational demands in our task fall squarely within the framework of RL. Most existing RL models have focused on experimental settings in which the agent faces a discrete set of options and/or a limited action space (<xref ref-type="bibr" rid="bib21">Daw et al., 2006</xref>; <xref ref-type="bibr" rid="bib41">Hayden et al., 2011</xref>; <xref ref-type="bibr" rid="bib65">Lee et al., 2011</xref>; <xref ref-type="bibr" rid="bib121">Wilson et al., 2014</xref>). In these situations, RL models posit that the agent keeps track of the value of available options and adopts a suitable policy to choose among them (<xref ref-type="bibr" rid="bib107">Sutton and Barto, 1998</xref>). In our task, subjects have to use reinforcement to choose the correct interval, which is a continuous variable. In theory, RL can be extended to continuous variables, but doing so would require the brain to represent an infinite-dimensional value function, which is implausible. Moreover, in the case of motor timing, produced intervals typically differ from what was intended, and that would interfere with the agentâs ability to correctly evaluate the intended action.</p><p>Due to these complications, recent studies have proposed an alternative explore-exploit strategy for continuous variables in which the agent uses reinforcement to directly regulate behavioral variability (<xref ref-type="bibr" rid="bib111">Tumer and Brainard, 2007</xref>; <xref ref-type="bibr" rid="bib27">Fee and Goldberg, 2011</xref>; <xref ref-type="bibr" rid="bib124">Wu et al., 2014</xref>; <xref ref-type="bibr" rid="bib89">Pekny et al., 2015</xref>; <xref ref-type="bibr" rid="bib95">Santos et al., 2015</xref>; <xref ref-type="bibr" rid="bib23">Dhawale et al., 2017</xref>). Our results were consistent with this view: variability was modulated by reward in a manner that was consistent with an explore-exploit strategy. This hypothesis was strongly supported by the results of our psychophysical experiment using a probabilistic reward schedule, which confirmed that the trial outcome had a causal effect on behavioral variability (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Another key observation was that the effect of reward on behavioral variability was context-specific (<xref ref-type="fig" rid="fig3">Figure 3</xref>), thatÂ is, variability associated with producing a specific interval with a specific effector was most strongly dependent on reward history in trials of the same interval and effector. Given that the memory drifts were also context-specific, this finding indicates that one important function of reward-dependent regulation of variability is to counter memory drifts.</p></sec><sec id="s3-3"><title>Extending RL to continuous variables</title><p>When the action space is discrete as in multi-arm bandit tasks, one can straightforwardly distinguish between exploitation and exploration: exploitation is selecting options that were previously rewarded, and exploration is selecting alternatives about which the agent is uncertain. This distinction, however, is neither straightforward nor helpful when dealing with continuous variables because the state space is too large and all options engender uncertainty. In this scenario, exact exploitation is not possible. Instead, exploitation can be viewed as a form of directed exploration whose objective is to bias responses toward previously rewarded states. This can be contrasted with random explorations that drive responses toward less frequently visited states, and can thus be viewed as increasing variance (<xref ref-type="bibr" rid="bib23">Dhawale et al., 2017</xref>).</p><p>In our experiment, the space of possible responses is continuous and individual responses are inherently variable. Therefore, it is impossible to produce the same exact time interval after a rewarded trial. Accordingly, we formulated the RL problem in terms of moderating directed versus random explorations (<xref ref-type="bibr" rid="bib121">Wilson et al., 2014</xref>). To capture the effect of reward on behavior, we developed a reward-sensitive Gaussian process (RSGP) model that implements a Bayesian updating strategy that simultaneously adjusts the bias and variance. When trial outcomes are better than expected, the RSGP tips the balance toward directed exploration by adjusting the bias, and when the reward drops, it increases variance.</p><p>RSGP was able to capture both the long-term effect of memory drift, and the short-term effect of reward on variability. It also captured behavioral observations in the probabilistic reward experiment where we validated the causal effect of reward on variability (<xref ref-type="fig" rid="fig5s2">Figure 5âfigure supplement 2B</xref>). A recent motor learning study in rodents found that the effect of reward on behavioral variability may last a few trials into the future (<xref ref-type="bibr" rid="bib24">Dhawale et al., 2019</xref>). This was also evident in our data (<xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1DâE</xref>), and RSGP provided a quantitative measure of the temporal extent of this effect (<xref ref-type="fig" rid="fig5">Figure 5B</xref>).</p><p>More generally, the RSGP suggests that categorical distinctions such as exploration versus exploitation or directed versus random explorations might be somewhat arbitrary and ill-defined. Instead, it may be more fruitful to adopt an alternative viewpoint in which the effect of reinforcement is quantified in terms of how trial outcome alters the distribution of future responses (e.g. both the mean and variance). As such, we expect RSGP to help future studies quantify the strength and persistence with which reinforcement guards against ubiquitous non-stationarities in behavior (<xref ref-type="bibr" rid="bib120">Weiss et al., 1955</xref>; <xref ref-type="bibr" rid="bib75">Merrill and Bennett, 1956</xref>; <xref ref-type="bibr" rid="bib61">Laming, 1979</xref>; <xref ref-type="bibr" rid="bib32">Gilden et al., 1995</xref>; <xref ref-type="bibr" rid="bib11">Chen et al., 1997</xref>; <xref ref-type="bibr" rid="bib10">Chaisanguanthum et al., 2014</xref>; <xref ref-type="bibr" rid="bib79">Murakami et al., 2017</xref>).</p></sec><sec id="s3-4"><title>Memory drift in the cortico-basal ganglia circuits</title><p>Behavioral variability in timing tasks is thought to have a multitude of distributed biophysical and synaptic origins (<xref ref-type="bibr" rid="bib31">Gibbon et al., 1984</xref>; <xref ref-type="bibr" rid="bib71">Mauk and Buonomano, 2004</xref>; <xref ref-type="bibr" rid="bib88">Paton and Buonomano, 2018</xref>). Several studies have been able to trace this variability inÂ vivo to spiking activity of neurons in cortico-basal ganglia circuits (<xref ref-type="bibr" rid="bib78">Murakami et al., 2014</xref>; <xref ref-type="bibr" rid="bib79">Murakami et al., 2017</xref>; <xref ref-type="bibr" rid="bib33">GouvÃªa et al., 2015</xref>; <xref ref-type="bibr" rid="bib23">Dhawale et al., 2017</xref>; <xref ref-type="bibr" rid="bib74">Merchant and Averbeck, 2017</xref>; <xref ref-type="bibr" rid="bib119">Wang et al., 2018</xref>). We previously found that a circuit comprised of DMFC, DMFC-projecting thalamus and caudate plays a causal role in the control of movement initiation time (<xref ref-type="bibr" rid="bib119">Wang et al., 2018</xref>) and that certain patterns of activity in each area were correlated with behavioral variability on a trial-by-trial basis. Here, we additionally confirmed that population activity in these areas carries a signal correlated with slow fluctuations of behavior. This finding is broadly consistent with previous studies reporting correlates of internal state changes and/or slow behavioral fluctuations in the thalamus (<xref ref-type="bibr" rid="bib37">Halassa et al., 2014</xref>), the medial frontal cortex (<xref ref-type="bibr" rid="bib81">Narayanan and Laubach, 2008</xref>; <xref ref-type="bibr" rid="bib106">Sul et al., 2010</xref>; <xref ref-type="bibr" rid="bib55">Karlsson et al., 2012</xref>; <xref ref-type="bibr" rid="bib79">Murakami et al., 2017</xref>), and the caudate (<xref ref-type="bibr" rid="bib64">Lauwereyns et al., 2002</xref>; <xref ref-type="bibr" rid="bib63">Lau and Glimcher, 2007</xref>; <xref ref-type="bibr" rid="bib95">Santos et al., 2015</xref>). However, the effector- and interval-dependent nature of these fluctuations in our data suggests that they may partially reflect context-specific memory drifts. The key feature of our task that enabled us to uncover this specificity was the alternation between different contexts on a trial-by-trial basis. Since many previous studies did not include this feature, it is possible that certain aspects of neural variability previously attributed to nonspecific internal state changes were in part caused by memory drifts related to specific task rules and parameters. Indeed, drifts and degradation of instrumental memories may be a key limiting factor in motor skill performance (<xref ref-type="bibr" rid="bib2">Ajemian et al., 2013</xref>).</p><p>Although we found a neural correlate of these drifts in all three brain areas, we cannot make a definitive statement about the loci of the underlying synaptic and biophysical drifts. It is likely that the memory has a distributed representation, in which case the drift may result from stochastic processes distributed across multiple brain areas. It is also possible that different contexts engage specific sub-circuits such as corticostriatal synapses (<xref ref-type="bibr" rid="bib27">Fee and Goldberg, 2011</xref>; <xref ref-type="bibr" rid="bib125">Xiong et al., 2015</xref>), and circuit-level interactions cause these drift to be present in other nodes of the cortico-basal ganglia circuit.</p><p>For different effectors, context-specificity may be attributed to different patterns of activity across the same population of neurons or by distinct populations of neurons. Our results in the cortico-basal ganglia circuits provided evidence for the former (<xref ref-type="fig" rid="fig8">Figure 8</xref>, <xref ref-type="fig" rid="fig8s5">Figure 8âfigure supplement 5</xref>). However, we cannot rule out the possibility that this context-specificity arises partially from execution noise within distinct effector-specific downstream areas (e.g. brainstem) as we did not record from those areas. However, execution noise is generally considered to be irreducible (<xref ref-type="bibr" rid="bib26">Faisal et al., 2008</xref>; <xref ref-type="bibr" rid="bib23">Dhawale et al., 2017</xref>) and is therefore not expected to be influenced by reinforcement. Previous work suggests that central noise (e.g. in the cortico-basal ganglia circuits) plays a significant role in output variability (<xref ref-type="bibr" rid="bib14">Churchland et al., 2006</xref>; <xref ref-type="bibr" rid="bib112">van Beers, 2009</xref>). It is this portion of variability that is likely subject to adjustments through reinforcement.</p></sec><sec id="s3-5"><title>Reinforcement via thalamus</title><p>Next, we asked whether the variability of neural activity in the thalamus, DMFC, and caudate was modulated by reward in the preceding trial in the same context-dependent manner as in the behavior. According to our hypothesis, the key function of the reward-dependent regulation of variability is to counter the memory drifts. This hypothesis makes a specific prediction: reward should modulate the specific pattern of population neural activity that corresponds to memory drifts in the behavior, which we referred to as drift direction. Analysis of neural activity revealed that this effect was present in the thalamus but not in DMFC or caudate. In the thalamus, spike count variability along the drift direction increased after rewarded trials and decreased after unrewarded trials in a context-specific manner. Previous studies have reported that in the thalamus firing rates are modulated on a trial-by-trial basis by attention (<xref ref-type="bibr" rid="bib72">McAlonan et al., 2008</xref>; <xref ref-type="bibr" rid="bib94">Saalmann et al., 2012</xref>; <xref ref-type="bibr" rid="bib127">Zhou et al., 2016</xref>) and rule/context-dependent computations (<xref ref-type="bibr" rid="bib97">Schmitt et al., 2017</xref>; <xref ref-type="bibr" rid="bib119">Wang et al., 2018</xref>). Our work demonstrates that modulation of thalamic activity may additionally subserve reward-based calibration of movement initiation times. It will be important for future studies to investigate whether this finding generalizes to other movement parameters.</p><p>The fact that the same effect was not present in DMFC and caudate serves as a negative control and thus strengthens our conclusions. However, this begs the question of why this regulation was not inherited by DMFC and caudate, especially given that DMFC receives direct input from the region of the thalamus we recorded from. The answer to this question depends on the nature of signal transformations along the thalamocortical pathway. While some experiments have suggested similar response properties for thalamus and their cortical recipients (<xref ref-type="bibr" rid="bib103">Sommer and Wurtz, 2006</xref>; <xref ref-type="bibr" rid="bib35">Guo et al., 2017</xref>), others have found that thalamic signals may undergo specific transformations along the thalamocortical pathway (<xref ref-type="bibr" rid="bib46">Hubel and Wiesel, 1962</xref>; <xref ref-type="bibr" rid="bib5">Berman and Wurtz, 2011</xref>; <xref ref-type="bibr" rid="bib122">Wimmer et al., 2015</xref>; <xref ref-type="bibr" rid="bib97">Schmitt et al., 2017</xref>; <xref ref-type="bibr" rid="bib119">Wang et al., 2018</xref>). Therefore, the extent to which we should expect responses in DMFC and thalamus to have similar properties is unclear.</p><p>Our approach for investigating whether the effect of reinforcement was aligned with memory drift was correlative: we used a cross-validated decoding strategy to infer the response pattern most strongly associated with memory drift and tested whether reinforcement exerted its effect along that pattern. According to this analysis, only in theÂ thalamus the two effects were appropriately aligned. However, we cannot rule out the possibility that behavioral control may be mediated by other patterns of activity in the DMFC. Indeed, with a complementary analysis using an unconstrained decoding approach, we were able to find patterns of activity in all three brain areas that simultaneously reflected the effects of memory drift (<xref ref-type="fig" rid="fig7">Figure 7</xref>) and reinforcement (<xref ref-type="fig" rid="fig8s3">Figure 8âfigure supplement 3</xref>). Therefore, an important consideration for future work is to use perturbation methods to causally verify the direction in the state space associated with memory drift and reinforcement.</p><p>However, other considerations are consistent with thalamus playing a strong role in controlling timing variability. For example, it has been shown that the inactivation of thalamus has a much stronger effect on modulating animalsâ motor timing variability compared to DMFC and caudate (<xref ref-type="bibr" rid="bib119">Wang et al., 2018</xref>). Moreover, the nature of signals in DMFC-projecting thalamus and DMFC during motor timing are different: DMFC neurons have highly heterogeneous response profiles that evolve at different speeds depending on the interval, whereas thalamic neurons carr signals whose strength (i.e. average firing rate) encode the underlying speed. This transformation may provide an explanation for why reward-dependent modulation of firing rates was evident in the thalamus but not in DMFC. As thalamic neurons encode the interval in their average firing rates, it is expected that regulation of timing variability by reward would similarly impact average firing rates. In contrast, in DMFC, the key signal predicting behavior was the speed at which neural trajectories evolved over time â not the neural states along the trajectory. This predicts that reward should alter the variability of the speed of neural trajectories. In principle, it is possible to verify this prediction by estimating the variance of the speed of neural trajectories as a function of reward. However, this estimation is challenging for two reasons. First, speed in a single trial is derived from changes in instantaneous neural states, and the estimation of instantaneous neural states is unreliable unless the number of recorded neurons exceeds the dimensionality of the subspace containing the neural trajectory (<xref ref-type="bibr" rid="bib29">Gao, 2017</xref>). Second, our predictions are about the variance â not mean â of speed, and estimating variance adds another layer of statistical unreliability unless the number of neurons or trials are sufficiently large.</p><p>Nonetheless, we devised a simple analysis to estimate the variance of the speed of neural trajectories across single trials in all three areas (<xref ref-type="fig" rid="fig8s6">Figure 8âfigure supplement 6</xref>). As predicted by our hypothesis, the effect of reward on neural activity in the thalamus was different from that in the DMFC and caudate. In thalamus, the reward adjusted the variance of average firing rates, but not the variance of speed . In contrast, in the DMFC and caudate, the reward modulated the variance of the speed at which neural trajectories evolve. Moreover, these effects were present only for consecutive trials associated with the same effector. These results further substantiate our hypothesis that reward regulates variability by adjusting the average firing rates in thalamus, and that this effect leads to the control of the variance of the speed at which neural trajectories evolve in the DMFC and caudate.</p><p>One open question pertains to which brain areas supply the relevant information for the reward-dependent control of behavioral variability. One salient example where cortical variability is adjusted rapidly and in a behaviorallyÂ relevant fashion is in the domain of attentional control where spatial cueing can lead to a drop of correlated variability in spiking across sensory cortical neurons whose receptive fields correspond to the cued location (<xref ref-type="bibr" rid="bib17">Cohen and Maunsell, 2009</xref>; <xref ref-type="bibr" rid="bib77">Mitchell et al., 2009</xref>; <xref ref-type="bibr" rid="bib93">Ruff and Cohen, 2014</xref>; <xref ref-type="bibr" rid="bib82">Ni et al., 2018</xref>). While we do not know which areas might directly control motor timing variability, we note that the area of thalamus we have recorded from receives information from three major sources, the frontal cortex, the output nuclei of the basal ganglia, and the deep nuclei of the cerebellum (<xref ref-type="bibr" rid="bib76">Middleton and Strick, 2000</xref>; <xref ref-type="bibr" rid="bib59">Kunimatsu et al., 2018</xref>). Modulation of variability prior to movement initiation has been reported in motor and premotor areas (<xref ref-type="bibr" rid="bib14">Churchland et al., 2006</xref>; <xref ref-type="bibr" rid="bib15">Churchland et al., 2010</xref>), and distinct correlates of explore-exploit strategy have been found across multiple nodes of the frontal cortex (<xref ref-type="bibr" rid="bib41">Hayden et al., 2011</xref>; <xref ref-type="bibr" rid="bib109">Tervo et al., 2014</xref>; <xref ref-type="bibr" rid="bib25">Ebitz et al., 2018</xref>; <xref ref-type="bibr" rid="bib70">Massi et al., 2018</xref>; <xref ref-type="bibr" rid="bib96">Sarafyazd and Jazayeri, 2019</xref>). Therefore, it is possible that modulation of variability in thalamus originates from correlated variability in the frontal cortex. To act as an effective learning mechanism, such correlated variability must be additionally sensitive to reward-dependent neuromodulatory signals such as dopamine (<xref ref-type="bibr" rid="bib28">Frank et al., 2009</xref>) possibly by acting on local inhibitory neurons (<xref ref-type="bibr" rid="bib45">Huang et al., 2019</xref>). The basal ganglia could also play a role in reward-dependent control of thalamic firing rates (<xref ref-type="bibr" rid="bib60">Kunimatsu and Tanaka, 2016</xref>; <xref ref-type="bibr" rid="bib59">Kunimatsu et al., 2018</xref>). For example, single neuron responses in substantia nigra pars reticulata that were strongly modulated by reward schedule (<xref ref-type="bibr" rid="bib126">Yasuda and Hikosaka, 2015</xref>) can influence neural responses in the thalamus. Finally, the cerebellum plays a central role in trial-by-trial calibration of motor variables (<xref ref-type="bibr" rid="bib48">Ito, 2002</xref>; <xref ref-type="bibr" rid="bib73">Medina and Lisberger, 2008</xref>; <xref ref-type="bibr" rid="bib42">Herzfeld et al., 2015</xref>) including movement initiation time (<xref ref-type="bibr" rid="bib4">Ashmore and Sommer, 2013</xref>; <xref ref-type="bibr" rid="bib59">Kunimatsu et al., 2018</xref>; <xref ref-type="bibr" rid="bib80">Narain et al., 2018</xref>) and thus is a natural candidate for calibrating firing rates in thalamus, although how such calibration could be made reward-sensitive remains an open question (<xref ref-type="bibr" rid="bib43">Hoshi et al., 2005</xref>). In sum, our work provides behavioral, modeling, and neurophysiological evidence in support of the hypothesis that the brain uses reinforcement to regulate behavioral variability in a context-dependent manner.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><p>Two adult monkeys (<italic>Macaca mulatta</italic>; one female, one male) and five human subjects (18â65 years, two females and three males) participated in the main task. Two additional monkeys (both male) participated in the memory control experiment. In addition, five more human subjects (18â65 years, two females and three males) participated in the probabilistic reward task to test the causal effect of reward on variability. The Committee of Animal Care at Massachusetts Institute of Technology approved all animal experiments. The Committee on the Use of Humans as Experimental Subjects at Massachusetts Institute of Technology approved all human experiments. As per our approved protocol, all human participants provided consent for the use and publication of data prior to data collection. All procedures conformed to the guidelines of the National Institutes of Health.</p><sec id="s4-1"><title>Animal experiments</title><p>Monkeys were seated comfortably in a dark and quiet room. The MWorks software package<ext-link ext-link-type="uri" xlink:href="https://mworks.github.io">Â (https://mworks.github.io</ext-link>) running on a Mac Pro was used to deliver stimuli and to control behavioral contingencies. Visual stimuli were presented on a 23-inch monitor (Acer H236HL, LCD) at a resolution of 1920 Ã 1080, and a refresh rate of 60 Hz. Auditory stimuli were played from the computerâs internal speaker. Eye position was tracked with an infrared camera (Eyelink 1000; SR Research Ltd, Ontario, Canada) and sampled at 1 kHz. A custom-made manual button, equipped with a trigger and a force sensor, was used to register button presses.</p></sec><sec id="s4-2"><title>The Cue-Set-Go task</title><p>Behavioral sessions in the main experiment consisted of four randomly interleaved trial types in which animals had to produce a target interval (<italic>t<sub>t</sub></italic>) of either 800 ms (Short) or 1500 ms (Long) using either a button press (Hand) or a saccade (Eye). The trial structure is described in the main Results (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Here, we only describe the additional details that were not described in the Results. The âCueâ presented at the beginning of each trial consisted of a circle and square. The circle had a radius of 0.2 deg and was presented at the center of the screen. The square had a side of 0.2 deg and was presented 0.5 deg below the circle. For the trial to proceed, the animal had to foveate the circle (i.e. eye fixation) and hold its hand gently on the button (i.e. hand fixation). The animal had to use the hand contralateral to the recorded hemifield. We used an electronic window of 2.5 deg around the circle to evaluate eye fixation, and infrared emitter and detector to evaluate hand fixation. After 500â1500 ms delay period (uniform hazard), a saccade target was flashed eight deg to the left or right of the circle. The saccade target (âTarâ) had a radius of 0.25 deg and was presented for 250 ms. After another 500â1500 ms delay (uniform hazard), an annulus (âSetâ) was flashed around the circle. The Set annulus had an inner and outer radius of 0.7 and 0.75 deg and was flashed for 48 ms. Trials were aborted if the eye moved outside the fixation window or hand fixation was broken before Set.</p><p>For responses made after Set, the produced interval (<italic>t<sub>p</sub></italic>) was measured from the endpoint of Set to the moment the saccade was initiated (eye trial) or the button was triggered (hand trial). Reward was provided if the animal used the correct effector and <italic>t<sub>p</sub></italic> was within an experimentally controlled acceptance window. For saccade responses, reward was not provided if the saccade endpoint was more than 2.5 deg away from the extinguished saccade target, or if the saccade endpoint was not acquired within 33 ms of exiting the fixation window.</p></sec><sec id="s4-3"><title>Reward function for monkeys in the main task</title><p>The reward was determined by a truncated triangular function of error (<italic>t<sub>p</sub>-t<sub>t</sub></italic>). The maximum reward was 0.5 ml of juice when <italic>t<sub>p</sub>Â =Â t<sub>t</sub></italic>. The reward dropped linearly for larger errors so long error was smaller than an acceptance window. For errors larger than the acceptance window, no reward was provided. The acceptance window was adjusted adaptively on a trial-by-trial basis. After each rewarded trial, the acceptance window was made smaller, and after each unrewarded trial, the window was made larger. This so-called one-up-one-down staircase procedure ensured that approximately 50% of the trials were rewarded. The acceptance window for the four trial conditions was set by independent staircases. The change in the size of the acceptance window after each trial was set to 8 and 15 ms for the 800 and 1500 ms target intervals, respectively. As a result of this procedure, animals received reward on nearly half of trials (57% in monkey A and 51% in monkey D). Visual and auditory feedback accompanied rewarded trials. For the visual feedback, either the color of the saccade target (for Eye trials) or the central square (for the Hand trials) turned green. The auditory feedback was one of the computerâs default tones.</p></sec><sec id="s4-4"><title>No-memory control task</title><p>To validate our hypothesis that slow fluctuations in animalsâ behavior arose from memory fluctuations, we performed a control experiment in two naive monkeys. In the control experiment, the animals did not have to remember the target interval <italic>t<sub>t</sub></italic>, but instead measured it on every trial. This was done by presenting an additional flash (âReadyâ) shortly before the Set flash such that the interval between Ready and Set was fixed and equal to <italic>t<sub>t</sub></italic>. This effectively removed the need for the animal to hold the target interval in memory. We limited the control experiment to a single effector (Eye) and a single interval (<italic>t<sub>t</sub></italic>Â =Â 840 ms). The reward was also determined by a truncated triangular function similar to the main task.</p></sec><sec id="s4-5"><title>Electrophysiology</title><p>Recording sessions began with an approximately 10 min warm-up period to allow animals to recalibrate their timing and exhibit stable behavior. We recorded from 932 single- or multi-units in the thalamus, 568 units in the dorsomedial frontal cortex (DMFC), and 509 units in caudate, using 24-channel linear probes with 100 Î¼m or 200 Î¼m interelectrode spacing (V-probe, Plexon Inc). The number of simultaneously recorded neurons across sessions were shown in <xref ref-type="fig" rid="fig8s2">Figure 8âfigure supplement 2A</xref> (meanÂ Â±s.d.; Thalamus: 17.9Â Â±Â 9.0; DMFC: 9.2Â Â±Â 4.3; Caudate: 14.8Â Â±Â 6.5). The DFMC comprises supplementary eye field, dorsal supplementary motor area (i.e. excluding the medial bank), and pre-supplementary motor area. We recorded from the left hemisphere from Monkey A and right from Monkey D, which was contralateral to the preferred hand used in the button press. Recording locations were selected according to stereotaxic coordinates with reference to previous studies as well as each animalâs structural MRI scan. The region of interest targeted in the thalamus was within 1 mm of antidromically identified neurons in the medial portion of the lateral thalamus, also known as Area X. All behavioral and electrophysiological data were timestamped at 30 kHz and streamed to a data acquisition system (OpenEphys). Spiking data were bandpass filtered between 300 Hz and 7 kHz, and spike waveforms were detected at a threshold that was typically set to three times the RMS noise. Single- and multi-units were sorted offline using custom software, MKsort (<xref ref-type="bibr" rid="bib57">Kaufman, 2013</xref>).</p></sec><sec id="s4-6"><title>Antidromic stimulation</title><p>We used antidromic stimulation to localize DMFC-projecting thalamic neurons. Antidromic spikes were recorded in response to a single biphasic pulse of duration 0.2 ms (currentÂ &lt;500 uA) delivered to DMFC via low impedance tungsten microelectrodes (100â500 KÎ©, Microprobes). A stainless-steel cannula guiding the tungsten electrode was used as the return path for the stimulation current. Antidromic activation evoked spikes reliably at a latency ranging from 1.8 to 3 ms, with less than 0.2 ms jitter.</p></sec><sec id="s4-7"><title>Human experiments</title><sec id="s4-7-1"><title>The Cue-Set-Go task</title><p>Each experimental session lasted approximately 60 min. Each subject completed 2â3 sessions per week. Similar to monkeys, experiments were conducted using the MWorks. All stimuli were presented on a black background monitor. Subjects were instructed to hold their gaze on a fixation point and hold a custom-made push button using their dexterous hand, throughout the trial. Subjects viewed the stimuli binocularly from a distance of approximately 67 cm on a 23-inch monitor (Apple, A1082 LCD) driven by a Mac Pro at a refresh rate of 60 Hz in a dark and quiet room. Eye positions were tracked with an infrared camera (Eyelink 1000 plus, SR Research Ltd.) and sampled at 1 kHz. The state of the button was converted and registered as digital TTL through a data acquisition card (National Instruments, USB-6212). The Cue-Set-Go task for humans was similar to monkeys with the following exceptions: (1) in each session, we used a single <italic>t<sub>t</sub></italic> sampled from a normal distribution (mean: 800 ms, std: 80 ms); (2) the saccadic target was 10 deg (instead of 8 deg) away from the fixation point; (3) humans only received visual and auditory feedback (an no physical reward).</p></sec><sec id="s4-7-2"><title>Reward function for humans in the main task</title><p>The feedback contingencies were identical to monkeys with the only difference that humans only received visual and auditory feedback and no reward. The one-up one-down staircase procedures led to an average of 50.2% trials with positive feedback. For the positive feedback, the color of the saccade target (for Eye trials) or the central square (for Hand trials) turned green. The auditory cue used two different tones for positive and negative feedback.</p></sec><sec id="s4-7-3"><title>The probabilistic reward task</title><p>A set of different human subjects performed the same timing interval production task, except that the nature of the feedback was provided probabilistically. Subjects received âcorrectâ feedback with the probability of 0.7 when <italic>t<sub>p</sub></italic> was within a window around <italic>t<sub>t</sub></italic>, and with the probability of 0.3 when errors were outside that window (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). The window length was adjusted based on the overall behavioral variability so that each subject receives approximately 50% âcorrectâ feedback in each behavioral session. Only one effector - hand pressing - was used in this causal experiment, as we have established that both the slow and reward regulated variability were effector specific. All the experimental parameters were set identical to the main experiment.</p></sec></sec><sec id="s4-8"><title>Data analysis</title><p>All offline data processing and analyses were performed in MATLAB (2019b, MathWorks Inc).</p></sec><sec id="s4-9"><title>Analysis of behavior</title><p>Behavioral data for the CSG task comprised of NÂ =Â 203 behavioral sessions consisting of nÂ =Â 167,115 trials in monkeys (NÂ =Â 95, nÂ =Â 71,053 for monkey A and NÂ =Â 108, nÂ =Â 96,062 for monkey D), NÂ =Â 62 sessions and nÂ =Â 59,297 trials in humans, and NÂ =Â 51 sessions and nÂ =Â 30,695 trials in the probabilistic feedback experiment in human subjects. Behavioral data for the no-memory control task was collected in NÂ =Â 26 sessions consisting of nÂ =Â 75,652 trials in two naive monkeys (NÂ =Â 9, nÂ =Â 32,041 for monkey G and NÂ =Â 17, nÂ =Â 43,611 for monkey H).</p><p>We computed the mean and standard deviation of <italic>t<sub>p</sub></italic>, denoted by <italic>Î¼</italic>(<italic>t<sub>p</sub></italic>) and <italic>Ï</italic>(<italic>t<sub>p</sub></italic>), respectively, for each trial type within each session (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). We additionally analyzed local fluctuations of <italic>Î¼</italic>(<italic>t<sub>p</sub></italic>) and <italic>Ï</italic>(<italic>t<sub>p</sub></italic>) by computing these statistics from running blocks of 50 trials within session and averaged across sessions. The mean of <italic>Ï</italic>(<italic>t<sub>p</sub></italic>) for each corresponding <italic>Î¼</italic>(<italic>t<sub>p</sub></italic>) bin and the averaged reward across all trials in each <italic>Î¼</italic>(<italic>t<sub>p</sub></italic>) bin were plotted in <xref ref-type="fig" rid="fig1">Figure 1D</xref>. Results were qualitatively unchanged when the block length was increased or decreased by a factor of 2.</p><p>We also examined the slow fluctuations of <italic>t<sub>p</sub></italic> for pairs of trials that were either of the same type (e.g. Eye-Short versus Eye-Short) or of different types (e.g. Hand-Long versus Eye-Short). For trials of the same type, we computed partial correlation coefficients of <italic>t<sub>p</sub></italic> pairs by fitting a successive autoregressive model with the maximum order of 60 trial lag (<xref ref-type="bibr" rid="bib6">Box, 2015</xref>; <xref ref-type="fig" rid="fig2">Figure 2A</xref>).1 and 99% confidence bounds were estimated at 2.5 times the standard deviation of the null distribution. For trials of different types, we calculated the Pearson correlation coefficient of pairs of <italic>t<sub>p</sub></italic> of various lags. To clarify our analysis, we use an example of how we estimated the cross correlation between pairs of HS-ES with a trial lag of 10: (1) normalize (z-score) two <italic>t<sub>p</sub></italic> vectors associated with HS and ES in each session; (2) take pairs of HS-ES that are 10 trials apart within each session; (3) combine the pairs across sessions; (4) compute Pearson correlation coefficient. We also computed a corresponding null distribution from 100 randomly shuffled trial identity. 1 and 99% confidence intervals were estimated from the null distribution.</p><p>Finally, we quantified the mean and standard deviation of the relative error denoted by <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>) and <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) as a function of error in the previous trial (<italic>e<sup>n-1</sup></italic>) for each pair of trial types (<xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1</xref>). Deriving reliable estimates of <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>) and <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) as a function of <italic>e<sup>n-1</sup></italic> from a non-stationary process requires a large number of trials. Since each trial can be of four different types (ES, EL, HS, HL), consecutive trials comprise 16 distinct conditions (e.g. ES-EH, HL-EL, etc.). The limited number of trials in each session limited the reliability of statistics estimated for each individual condition. To gain more statistical power, we combined results across trial types in two ways. First, for each effector, we combined the Short and Long trial types by normalizing <italic>t<sub>p</sub></italic> values by their respective <italic>t<sub>t</sub></italic>. The resulting variable was defined as relative error <italic>e<sup>n</sup></italic> = (<italic>t<sub>p</sub><sup>n</sup>- t<sub>t</sub></italic>)/<italic>t<sub>t</sub></italic>. This reduced the number of conditions by a factor of four, leaving consecutive trials that were either associated with the same effector or with different effectors (e.g. E-E, E-H, H-E, and H-H). We further combined trials to create a âsame effectorâ condition that combined E-E with H-H, and a âdifferent effectorâ condition that combined E-H with H-E. Animals and human subjects were allowed to take breaks during the experimental sessions. However, the pairs of consecutive trials used in all analyses, regardless of the trial condition, were restricted to the two consequent and completed trials that were no more than 7 s apart.</p><p>We examined the relationship between <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>) and <italic>e<sup>n-1</sup></italic> using a linear regression model of the form <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>)Â <italic>=Â m<sub>0</sub>+m<sub>1</sub>e<sup>n-1</sup></italic>, and the relationship between <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) and <italic>e<sup>n-1</sup></italic> using a quadratic regression model of the form <italic>Ï</italic>(<italic>e<sup>n</sup></italic>)Â <italic>=Â s<sub>0</sub>+s<sub>1</sub>e<sup>n-1</sup>+s<sub>2</sub></italic>(<italic>e<sup>n-1</sup></italic>)<italic><sup>2</sup></italic>. We assessed the significance of the monotonic relationship between <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>) and <italic>e<sup>n-1</sup></italic> by the slope of linear regression (<italic>m<sub>1</sub></italic>), and the significance of the U-shaped profile in <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) by the square term of a quadratic regression (<italic>s<sub>2</sub></italic>). Note that the choice of these models was not theoretically motivated; we simply considered these regression models to be an approximate function for testing the profile of <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>) and <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) as a function of <italic>e<sup>n-1</sup></italic>. The 1 and 99% confidence intervals were defined as <italic>s<sub>2</sub></italic>Â Â±<italic>SE(s<sub>2</sub>),</italic> where s<sub>2</sub> is the estimated coefficientÂ and SE<italic>(s<sub>2</sub>)</italic> is its standard error.Â <italic>t<sub>(.01, N-p)</sub></italic>Â is the 1 percentile of t-distribution withÂ <italic>N-p</italic>Â degrees of freedoms.</p><p>We applied the same analysis to the probabilistic reward experiment in humans after grouping the trials based on whether the feedback in the previous trials was âcorrectâ or âincorrectâ. Before analyzing the variability, we removed outlier trials defined as trials in which <italic>t<sub>p</sub></italic> was more than three standard deviations away from the mean. Since subjects were allowed to initiate the trials, we also excluded pairs of adjacent trials that were more than 7 seconds apart. When combining data across sessions, we normalized the relative error across sessions and subjects. To avoid sampling bias, the same number of trials were drawn repeatedly after âcorrectâ or âincorrectâ. The standard error of the mean was computed from 100 repeats with replacement (<xref ref-type="fig" rid="fig4">Figure 4D</xref>).</p></sec><sec id="s4-10"><title>Reward-sensitive Gaussian process (RSGP) model simulation and fitting</title><p>We constructed a reward-sensitive Gaussian process model whose covariance function, <bold><italic>K</italic></bold><italic><sub>RSGP</sub></italic>, is a weighted sum of two kernels, a traditional squared exponential kernel, for which we used subscript SE (<bold><italic>K</italic></bold><italic><sub>SE</sub></italic>), and a reward-sensitive kernel with subscript RS (<bold><italic>K</italic></bold><italic><sub>RS</sub></italic>). The two kernels contribute to <italic>K<sub>RSGP</sub></italic> through scale factors <italic>Ï<sup>2</sup><sub>SE</sub></italic> and <italic>Ï<sup>2</sup><sub>RS</sub></italic>, respectively. In both kernels, the covariance term between any two trials (trial <italic>n</italic> and <italic>n-r</italic>) drops exponentially as a function of trial lag (<italic>r</italic>). The rates of drop for <bold><italic>K</italic></bold><italic><sub>SE</sub></italic> and <bold><italic>K</italic></bold><italic><sub>RS</sub></italic> are specified by characteristic length parameters, <italic>l<sub>SE</sub></italic> and <italic>l<sub>RS</sub></italic>, respectively. The model also includes a static source of variance, <italic>Ï<sup>2</sup><sub>0</sub><bold>I</bold></italic> (<bold><italic>I</italic></bold> stands for the identity matrix):<disp-formula id="equ3"><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>S</mml:mi><mml:mi>G</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>â</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mi>Ï</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>â</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>Ï</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>S</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>â</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>Ï</mml:mi><mml:mn>0</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mi>I</mml:mi></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ4"><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>â</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mo>â¡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>â</mml:mo><mml:mfrac><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>l</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></disp-formula><disp-formula id="equ5"><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>â</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable columnalign="left left" columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mi>exp</mml:mi><mml:mo>â¡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>â</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:msup><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>l</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>S</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mtext>Â </mml:mtext><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mtext>Â </mml:mtext><mml:mi>n</mml:mi><mml:mo>â</mml:mo><mml:mi>r</mml:mi><mml:mtext>Â </mml:mtext><mml:mrow><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mtext>Â </mml:mtext><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mrow><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mstyle><mml:mo fence="true" stretchy="true" symmetric="true"/></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>Note that <bold><italic>K</italic></bold><italic><sub>RS</sub></italic> values depend on reward history and are thus not necessarily invariant with respect to time; thatÂ is, <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>â</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>â </mml:mo><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>â</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>.Â This formulation allows past rewarded trials to have higher leverage on future trials and this effect drops exponentially for rewarded trials farther in the past.</p><p>We simulated the RSGP by applying GP regression based on the designated covariance function (<xref ref-type="table" rid="table5">Table 5</xref>). To simplify our formulations and without loss of generality, we replaced <italic>Ï<sup>2</sup><sub>SE</sub></italic> and <italic>Ï<sup>2</sup><sub>RS</sub></italic> by <italic>Î±Ï<sup>2</sup></italic> and (1 - <italic>Î±</italic>)<italic>Ï<sup>2</sup></italic>, respectively where <italic>Î±</italic>Â =Â 1.0, 0, and 0.5 for the three examples (<xref ref-type="fig" rid="fig5">Figure 5A</xref>).</p><table-wrap id="table5" position="float"><label>Table 5.</label><caption><title>Algorithm for generating time series based on RSGP model.</title></caption><table frame="hsides" rules="groups"><tbody><tr><td valign="top"><bold>for</bold> <italic>nÂ =Â 1...N</italic> <bold>do</bold> <break/>1. Given the previous value and reward history, infer the mean and <break/>The variance of <italic>t<sub>p</sub><sup>n</sup></italic> from the conditional distribution <break/><inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msubsup><mml:mi>t</mml:mi><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mo>â¯</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow><mml:mo>âº</mml:mo></mml:msup><mml:mo>â¼</mml:mo><mml:mrow><mml:mi mathvariant="script">ð©</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>&gt;</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>Ã</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>Ã</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>Ã</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>n</mml:mi><mml:mo>â</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>Ã</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mtd></mml:mtr></mml:mtable><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mi>K</mml:mi><mml:mo>â¡</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>R</mml:mi><mml:mi>S</mml:mi><mml:mi>G</mml:mi><mml:mi>P</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> <break/>2. Randomly sample <italic>t<sub>p</sub><sup>n</sup></italic> from the inferred mean and variance <break/>3. Update the reward-sensitive covariance, <italic>K<sub>RS</sub></italic>, and the full kernel, <italic>K</italic><sub>RSGP</sub>, based on <italic>t<sub>p</sub><sup>n</sup></italic>. <break/><bold>end</bold></td></tr></tbody></table></table-wrap><p>As both the slow fluctuation and reward regulation were context specific, we fit the model to behavioral data for each trial type (ES, EL, HS, and HL) separately. To do so, we ordered <italic>t<sub>p</sub></italic> values associated with the same trial type within each behavioral session chronologically and treated them as consecutive samples from the model irrespective of the actual trial lag between them. Although this strategy made the model fitting more tractable, the inferred length constants in units of trials are likely smaller than the true values in the data. For the same reason, the temporal distance in the kernel function was different from the actual trial lag (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Methods for fitting behavioral data to the RSGP model were adapted from <italic>Gaussian Processes for Machine Learning</italic> (<xref ref-type="bibr" rid="bib90">Rasmussen and Williams, 2006</xref>). The objective was to maximize the marginal likelihood of the observed data with respect to the hyperparameters (<italic>l<sub>SE</sub></italic>, <italic>Ï<sub>SE</sub></italic>, <italic>l<sub>RS</sub></italic>, <italic>Ï<sub>RS</sub></italic>, <italic>Ï<sub>0</sub></italic>). Using simulations, we found that optimization through searching the entire parameter space was inefficient and hindered convergence. Therefore, we implemented a two-step optimization. We first used the unrewarded trials to estimate <italic>l<sub>SE</sub></italic> and <italic>Ï<sub>SE</sub></italic>, and then used those fits to search for the best fit of the remaining hyperparameters (<italic>l<sub>SE</sub></italic>, <italic>Ï<sub>SE</sub></italic>, <italic>l<sub>RS</sub></italic>, <italic>Ï<sub>RS</sub></italic>, and <italic>Ï<sub>0</sub></italic>) using all trials. The optimization of the multivariate likelihood function was achieved by line searching with quadratic and cubic polynomial approximations. The conjugate gradient was used to compute the search directions (<xref ref-type="bibr" rid="bib90">Rasmussen and Williams, 2006</xref>). The landscape of likelihood indicated that the optimization was convex for a wide range of initial values (<xref ref-type="fig" rid="fig5s1">Figure 5âfigure supplement 1A</xref>, <xref ref-type="table" rid="table2">Table 2</xref>).</p><p>The RSGP model fit to data provides a prediction of the distribution of <italic>t<sub>p</sub></italic> on each trial based on previous trials (<italic>t<sub>p</sub></italic> and reward history). We used this distribution to generate simulated values of <italic>t<sub>p</sub></italic> for each session and repeated this process (nÂ =Â 100) to estimate the distribution of <italic>Î¼</italic>(<italic>e<sup>n</sup></italic>) and <italic>Ï</italic>(<italic>e<sup>n</sup></italic>) in relation to <italic>e<sup>n-1</sup></italic> using the same analysis we applied to behavioral data (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). To derive an estimate of the slow part of error, <italic>e</italic><sub>slow</sub>, we first fitted the RSGP to the behavior, and then used the reduced RSGP that only included the slow kernel (<bold><italic>K</italic></bold><italic><sub>SE</sub></italic>) to predict the expected value of <italic>e</italic><sub>slow</sub>, thatÂ is the mean of a GP process governed by <bold><italic>K</italic></bold><italic><sub>SE</sub></italic>.</p></sec><sec id="s4-11"><title>Markov chain Monte Carlo (MCMC) model</title><p>The MCMC model was proposed by <xref ref-type="bibr" rid="bib36">Haith and Krakauer, 2014</xref>. We adapted this algorithm to our task as shown in <xref ref-type="table" rid="table6">Table 6</xref>:</p><table-wrap id="table6" position="float"><label>Table 6.</label><caption><title>Algorithm for generating time series based on MCMC model.</title></caption><table frame="hsides" rules="groups"><tbody><tr><td valign="top"><bold>for</bold> each trial <bold>do</bold> <break/>1. Keep an internal estimate of target <italic>t<sub>t</sub>*</italic> that is currently associated with the highest reward, <italic>V(t<sub>t</sub>*)</italic>. <break/>2. On every trial, sample a new target, denoted <italic>t<sub>t</sub><sup>+</sup></italic>, from a Gaussian distribution with mean <italic>t<sub>t</sub>*</italic> and standard deviation <bold><italic>We</italic>.</bold> <break/>3. Generate <italic>t<sub>p</sub></italic> by sampling from a Gaussian distribution with mean <italic>t<sub>t</sub><sup>+</sup></italic> and standard deviation <italic>t<sub>t</sub><sup>+</sup></italic>. <bold><italic>Wp</italic></bold> (scalar noise). Assign the reward as the value of new sample <italic>V(t<sub>t</sub><sup>+</sup>)</italic>. <break/>4. Use a probabilistic Metropolis-Hastings rule to accept or reject <italic>t<sub>t</sub></italic><sup>+</sup> as the new target depending on the relative values of <italic>V(t<sub>t</sub><sup>+</sup>)</italic>, <italic>V(t<sub>t</sub>*)</italic>, and a free parameter <bold><italic>Î²</italic></bold> known in RL as the inverse temperature. <break/><inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mtext>Accept</mml:mtext><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>Î²</mml:mi><mml:mo>â</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mo>â </mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>Î²</mml:mi><mml:mo>â</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mo>â </mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>Î²</mml:mi><mml:mo>â</mml:mo><mml:mi>V</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mi>t</mml:mi><mml:mo>â</mml:mo></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula> <break/><bold>end</bold></td></tr></tbody></table></table-wrap><p>We have extensively explored the parameter space of this model. In simulations (<xref ref-type="fig" rid="fig6">Figure 6C</xref>, <xref ref-type="fig" rid="fig6s1">Figure 6âfigure supplement 1A</xref>), we used 0.1*<italic>t<sub>t</sub></italic> and 0.05*<italic>t<sub>t</sub></italic> as the level of sampling noise <bold><italic>We</italic></bold> and execution noise <bold><italic>Wp</italic></bold> in step 2, respectively. The inverse temperature <bold><italic>Î²</italic></bold> was 100.</p></sec><sec id="s4-12"><title>Directed search (DS) model and characterizing the run-away behavior</title><p>The DS model is an RL-based learning scheme that sets the current gradient of the target interval based on the reward gradient in the two preceding trials. <xref ref-type="table" rid="table7">Table 7</xref> shows the underlying algorithm. We set the parameters of the model (<italic>É, We, Wp</italic>) so as to minimize the MSE between monkeysâ behavior and model prediction. With these parameters, the model often exhibited unstable run-away behavior. We defined run-away behavior as when the adaptive reward window reached a threshold (<italic>t<sub>t</sub></italic>Â Â±Â 0.3*<italic>t<sub>t</sub></italic>) and the number of consecutively unrewarded trials was larger than 20 trials (<xref ref-type="fig" rid="fig6s1">Figure 6âfigure supplement 1B</xref>). With the same reward threshold, animalsâ behavior did not exhibit such run-away behavior.</p><table-wrap id="table7" position="float"><label>Table 7.</label><caption><title>Algorithm for simulating the DS model.</title></caption><table frame="hsides" rules="groups"><tbody><tr><td rowspan="4" valign="top"><bold>for</bold> <italic>nÂ =Â 1...N</italic> <bold>do</bold> <break/>1. Generate a new target estimation <italic>t<sub>t</sub><sup>n</sup></italic> using gradients derived from the previous performance and reward <break/><italic>Ît<sub>t</sub> = Î± (t<sub>t</sub><sup>n-1</sup> - t<sub>t</sub><sup>n-2</sup>) * (r<sup>n-1</sup> - r<sup>n-2</sup>)</italic> <break/><italic>t<sub>t</sub><sup>n</sup>Â =Â t<sub>t</sub><sup>n-1</sup> + Ît<sub>t</sub> + n<sub>e</sub></italic>, in which the estimation noise <italic>n<sub>e</sub></italic>Â ~Â <italic>N</italic>(0,<bold><italic>We</italic></bold>) <break/>2. Generate <italic>t<sub>p</sub><sup>n</sup></italic> with the added scalar production noiseÂ ~Â <italic>N</italic>(0,<bold><italic>Wp</italic></bold>) <break/>3. Compute the amplitude of reward <italic>r<sup>n</sup></italic> based on <italic>t<sub>p</sub><sup>n</sup></italic> and reward profile <break/><bold>end</bold></td></tr></tbody></table></table-wrap></sec><sec id="s4-13"><title>Relationship between neural activity and the slow component of behavior</title><p>We used linear regression to examine whether and to what extent the population neural activity could predict the slow component of error (<italic>e</italic><sub>slow</sub>) inferred from the RSGP model fits to behavior (as described in the previous section) using the following regression model:<disp-formula id="equ6"><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>e</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>r</mml:mi><mml:mi mathvariant="bold-italic">Î²</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>Î²</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></disp-formula>where <bold><italic>r</italic></bold> represents a matrix (<italic>nxN</italic>) containing spike counts within a 250 ms of <italic>N</italic> simultaneously recorded neurons across <italic>n</italic> trials, <italic>Î²</italic><sub>0</sub> is a constant, and <bold><italic>Î²</italic></bold> is an <italic>N</italic>-dimensional vector specifying the contribution of each neuron to <italic>e</italic><sub>slow</sub>. We used a random half of trials (training dataset) to find <bold><italic>Î²</italic></bold> and <italic>Î²<sub>0</sub></italic> and the other half (validation dataset) to test the model, and quantify the success of the model by computing the Pearson correlation coefficient (<xref ref-type="fig" rid="fig7">Figure 7BâD</xref>) between the <italic>e</italic><sub>slow</sub> inferred from RSGP model fits to behavior and <italic>e</italic><sub>slow</sub> predicted from the neural data using the regression model.</p><p>We initially tested the regression model using spike counts immediately before Set and later extended the analysis to different time points throughout the trial. To do so, we aligned spike times to various events throughout the trial (Cue, Tar, Set, Go) and tested the regression model every 125 ms around each event (four time points after Cue, three time points before Tar, three time points after Tar, four time points before Set, four time points after Set and four time points before Go).</p><p>To ensure that the model was predictive and not simply overfitting noisy spike counts, we used a cross-validation procedure: for each session, we used a random half of the trials to estimate <bold><italic>Î²</italic></bold><sub>Th</sub>, and the other half to quantify the extent to which <italic>z</italic><sub>Th</sub> could predict <italic>e</italic><sub>slow</sub>. Note that some correlations are negative because of cross-validation (we used a random half of data to estimate the drift direction and the other half for estimation correlations). Otherwise, all correlations should have been non-negative. Note that the number of sessions was combined across all four trial types as shown in <xref ref-type="fig" rid="fig7">Figure 7BâD</xref> bottom.</p></sec><sec id="s4-14"><title>Statistical analysis</title><p>Mean Â± standard deviation (s.d.), Mean Â± standard error of the mean (SEM) or median Â± median absolute deviation (MAD) were used to report statistics. We detailed all the statistics in the Results and figure captions. All hypotheses were tested at a significance level of 0.01 and p-values were reported. We used <italic>t</italic>-tests to perform statistical tests on the following variables: (1) weber fraction (ratio of standard deviation to mean of <italic>t<sub>p</sub></italic>), (2) cross correlation between pairs of trials of different lag and trial type, (3) modulation of the variability by discrete or graded reward (4) variance terms in the RSGP model (<italic>Ï<sup>2</sup><sub>SE</sub></italic>, <italic>Ï<sup>2</sup><sub>RS</sub></italic>, and <italic>Ï<sup>2</sup><sub>0</sub></italic>) which were assumed to be normally distributed. We used one-tailed paired, two-tailed paired or two-sample <italic>t-</italic>tests depending on the nature of data and question. The length scale parameters of the RSGP model (<italic>l<sub>SE</sub></italic> and <italic>l<sub>RS</sub></italic>) were not normally distributed. Therefore, we used a one-way ANOVA to test whether the two were significantly different. We used a two-sample <italic>F</italic>-test to compare the variability of production intervals for different pair-trial conditions (H0: equal variance).</p></sec><sec id="s4-15"><title>Mathematical notation</title><p><table-wrap id="inlinetable1" position="anchor"><table frame="hsides" rules="groups"><thead><tr><th valign="top">Symbol</th><th valign="top">Description</th></tr></thead><tbody><tr><td valign="top"><inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>t</mml:mi><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:msubsup></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">Production time in the n-th trial</td></tr><tr><td valign="top"><inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top"><inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:msubsup><mml:mo>â</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, relative error of production time in the n-th trial</td></tr><tr><td valign="top"><inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Î¼</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">Mean of relative error</td></tr><tr><td valign="top"><inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Ï</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>e</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">Standard deviation of relative error</td></tr><tr><td valign="top"><inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">Covariance between trial <italic>i</italic> and trial <italic>j</italic></td></tr><tr><td valign="top"><inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>Ï</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">Signal variance or noise variance associated with a Gaussian process</td></tr><tr><td valign="top"><italic>l</italic></td><td valign="top">The length scale of the squared-exponential covariance function</td></tr><tr><td valign="top"><inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="normal">r</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">Population spiking at time t in the n-th trial</td></tr><tr><td valign="top"><inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>Î²</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td valign="top">Regression coefficient</td></tr><tr><td valign="top"><italic>z</italic></td><td valign="top">Projection of population spiking activity onto a low dimensional representation</td></tr></tbody></table></table-wrap></p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>MJ is supported by NIH (NINDS-NS078127), the Sloan Foundation, the Klingenstein Foundation, the Simons Foundation, the McKnight Foundation, and the McGovern Institute. NM is supported by the Center for Sensorimotor Neural Engineering.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Visualization, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Data curation, Formal analysis, Validation, Investigation, Visualization, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Data curation, Formal analysis, Writing - review and editing</p></fn><fn fn-type="con" id="con4"><p>Data curation, Writing - review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Supervision, Funding acquisition, Investigation, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: The Committee on the Use of Humans as Experimental Subjects at the Massachusetts Institute of Technology approved the human experiments (Protocol Number: 1304005676). The Committee on the Use of Humans as Experimental Subjects at Massachusetts Institute of Technology approved all human experiments. As per our approved protocol, all human participants provided consent for the use and publication of data prior to data collection.</p></fn><fn fn-type="other"><p>Animal experimentation: All procedures conformed to the guidelines of the National Institutes of Health. All animals were handled according to our protocol (Protocol Number: 0119-002-22) that was approved by the Committee of Animal Care at the Massachusetts Institute of Technology.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-55872-transrepform-v1.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>Matlab codes for RSGP simulation and model fitting are available at <ext-link ext-link-type="uri" xlink:href="https://github.com/wangjing0/RSGP">https://github.com/wangjing0/RSGP</ext-link>. Data are avaible at <ext-link ext-link-type="uri" xlink:href="https://jazlab.org/resources/">https://jazlab.org/resources/</ext-link>.</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Afshar</surname> <given-names>A</given-names></name><name><surname>Santhanam</surname> <given-names>G</given-names></name><name><surname>Yu</surname> <given-names>BM</given-names></name><name><surname>Ryu</surname> <given-names>SI</given-names></name><name><surname>Sahani</surname> <given-names>M</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Single-trial neural correlates of arm movement preparation</article-title><source>Neuron</source><volume>71</volume><fpage>555</fpage><lpage>564</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.05.047</pub-id><pub-id pub-id-type="pmid">21835350</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ajemian</surname> <given-names>R</given-names></name><name><surname>D'Ausilio</surname> <given-names>A</given-names></name><name><surname>Moorman</surname> <given-names>H</given-names></name><name><surname>Bizzi</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A theory for how sensorimotor skills are learned and retained in noisy and nonstationary neural circuits</article-title><source>PNAS</source><volume>110</volume><fpage>E5078</fpage><lpage>E5087</lpage><pub-id pub-id-type="doi">10.1073/pnas.1320116110</pub-id><pub-id pub-id-type="pmid">24324147</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ames</surname> <given-names>KC</given-names></name><name><surname>Ryu</surname> <given-names>SI</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neural dynamics of reaching following incorrect or absent motor preparation</article-title><source>Neuron</source><volume>81</volume><fpage>438</fpage><lpage>451</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.11.003</pub-id><pub-id pub-id-type="pmid">24462104</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ashmore</surname> <given-names>RC</given-names></name><name><surname>Sommer</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Delay activity of saccade-related neurons in the caudal dentate nucleus of the macaque cerebellum</article-title><source>Journal of Neurophysiology</source><volume>109</volume><fpage>2129</fpage><lpage>2144</lpage><pub-id pub-id-type="doi">10.1152/jn.00906.2011</pub-id><pub-id pub-id-type="pmid">23365182</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berman</surname> <given-names>RA</given-names></name><name><surname>Wurtz</surname> <given-names>RH</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Signals conveyed in the pulvinar pathway from superior colliculus to cortical area MT</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>373</fpage><lpage>384</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4738-10.2011</pub-id><pub-id pub-id-type="pmid">21228149</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Box</surname> <given-names>GEP</given-names></name></person-group><year iso-8601-date="2015">2015</year><source>Time Series Analysis: Forecasting and Control</source><publisher-name>John Wiley &amp; Sons</publisher-name><pub-id pub-id-type="doi">10.1002/9781118619193</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carpenter</surname> <given-names>RHS</given-names></name><name><surname>Williams</surname> <given-names>MLL</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Neural computation of log likelihood in control of saccadic eye movements</article-title><source>Nature</source><volume>377</volume><fpage>59</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1038/377059a0</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cashaback</surname> <given-names>JGA</given-names></name><name><surname>McGregor</surname> <given-names>HR</given-names></name><name><surname>Mohatarem</surname> <given-names>A</given-names></name><name><surname>Gribble</surname> <given-names>PL</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dissociating error-based and reinforcement-based loss functions during sensorimotor learning</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005623</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005623</pub-id><pub-id pub-id-type="pmid">28753634</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cashaback</surname> <given-names>JGA</given-names></name><name><surname>Lao</surname> <given-names>CK</given-names></name><name><surname>Palidis</surname> <given-names>DJ</given-names></name><name><surname>Coltman</surname> <given-names>SK</given-names></name><name><surname>McGregor</surname> <given-names>HR</given-names></name><name><surname>Gribble</surname> <given-names>PL</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The gradient of the reinforcement landscape influences sensorimotor learning</article-title><source>PLOS Computational Biology</source><volume>15</volume><elocation-id>e1006839</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006839</pub-id><pub-id pub-id-type="pmid">30830902</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chaisanguanthum</surname> <given-names>KS</given-names></name><name><surname>Shen</surname> <given-names>HH</given-names></name><name><surname>Sabes</surname> <given-names>PN</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Motor variability arises from a slow random walk in neural state</article-title><source>Journal of Neuroscience</source><volume>34</volume><fpage>12071</fpage><lpage>12080</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3001-13.2014</pub-id><pub-id pub-id-type="pmid">25186752</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>Y</given-names></name><name><surname>Ding</surname> <given-names>M</given-names></name><name><surname>Kelso</surname> <given-names>JAS</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Long memory processes (1/f Î± type) in human coordination</article-title><source>Physical Review Letters</source><volume>79</volume><fpage>4501</fpage><lpage>4504</lpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.79.4501</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>X</given-names></name><name><surname>Mohr</surname> <given-names>K</given-names></name><name><surname>Galea</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Predicting explorative motor learning using decision-making and motor noise</article-title><source>PLOS Computational Biology</source><volume>13</volume><elocation-id>e1005503</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1005503</pub-id><pub-id pub-id-type="pmid">28437451</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Church</surname> <given-names>RM</given-names></name><name><surname>Broadbent</surname> <given-names>HA</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Alternative representations of time, number, and rate</article-title><source>Cognition</source><volume>37</volume><fpage>55</fpage><lpage>81</lpage><pub-id pub-id-type="doi">10.1016/0010-0277(90)90018-F</pub-id><pub-id pub-id-type="pmid">2269008</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname> <given-names>MM</given-names></name><name><surname>Afshar</surname> <given-names>A</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A central source of movement variability</article-title><source>Neuron</source><volume>52</volume><fpage>1085</fpage><lpage>1096</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2006.10.034</pub-id><pub-id pub-id-type="pmid">17178410</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname> <given-names>MM</given-names></name><name><surname>Yu</surname> <given-names>BM</given-names></name><name><surname>Cunningham</surname> <given-names>JP</given-names></name><name><surname>Sugrue</surname> <given-names>LP</given-names></name><name><surname>Cohen</surname> <given-names>MR</given-names></name><name><surname>Corrado</surname> <given-names>GS</given-names></name><name><surname>Newsome</surname> <given-names>WT</given-names></name><name><surname>Clark</surname> <given-names>AM</given-names></name><name><surname>Hosseini</surname> <given-names>P</given-names></name><name><surname>Scott</surname> <given-names>BB</given-names></name><name><surname>Bradley</surname> <given-names>DC</given-names></name><name><surname>Smith</surname> <given-names>MA</given-names></name><name><surname>Kohn</surname> <given-names>A</given-names></name><name><surname>Movshon</surname> <given-names>JA</given-names></name><name><surname>Armstrong</surname> <given-names>KM</given-names></name><name><surname>Moore</surname> <given-names>T</given-names></name><name><surname>Chang</surname> <given-names>SW</given-names></name><name><surname>Snyder</surname> <given-names>LH</given-names></name><name><surname>Lisberger</surname> <given-names>SG</given-names></name><name><surname>Priebe</surname> <given-names>NJ</given-names></name><name><surname>Finn</surname> <given-names>IM</given-names></name><name><surname>Ferster</surname> <given-names>D</given-names></name><name><surname>Ryu</surname> <given-names>SI</given-names></name><name><surname>Santhanam</surname> <given-names>G</given-names></name><name><surname>Sahani</surname> <given-names>M</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Stimulus onset quenches neural variability: a widespread cortical phenomenon</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>369</fpage><lpage>378</lpage><pub-id pub-id-type="doi">10.1038/nn.2501</pub-id><pub-id pub-id-type="pmid">20173745</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Churchland</surname> <given-names>MM</given-names></name><name><surname>Cunningham</surname> <given-names>JP</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Foster</surname> <given-names>JD</given-names></name><name><surname>Nuyujukian</surname> <given-names>P</given-names></name><name><surname>Ryu</surname> <given-names>SI</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural population dynamics during reaching</article-title><source>Nature</source><volume>487</volume><fpage>51</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1038/nature11129</pub-id><pub-id pub-id-type="pmid">22722855</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname> <given-names>MR</given-names></name><name><surname>Maunsell</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Attention improves performance primarily by reducing interneuronal correlations</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1594</fpage><lpage>1600</lpage><pub-id pub-id-type="doi">10.1038/nn.2439</pub-id><pub-id pub-id-type="pmid">19915566</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crossman</surname> <given-names>ERFW</given-names></name></person-group><year iso-8601-date="1959">1959</year><article-title>A theory of the acquisition of speed-skillâ</article-title><source>Ergonomics</source><volume>2</volume><fpage>153</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1080/00140135908930419</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dam</surname> <given-names>G</given-names></name><name><surname>Kording</surname> <given-names>K</given-names></name><name><surname>Wei</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Credit assignment during movement reinforcement learning</article-title><source>PLOS ONE</source><volume>8</volume><elocation-id>e55352</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0055352</pub-id><pub-id pub-id-type="pmid">23408972</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>Niv</surname> <given-names>Y</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</article-title><source>Nature Neuroscience</source><volume>8</volume><fpage>1704</fpage><lpage>1711</lpage><pub-id pub-id-type="doi">10.1038/nn1560</pub-id><pub-id pub-id-type="pmid">16286932</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>O'Doherty</surname> <given-names>JP</given-names></name><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Seymour</surname> <given-names>B</given-names></name><name><surname>Dolan</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Cortical substrates for exploratory decisions in humans</article-title><source>Nature</source><volume>441</volume><fpage>876</fpage><lpage>879</lpage><pub-id pub-id-type="doi">10.1038/nature04766</pub-id><pub-id pub-id-type="pmid">16778890</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dayan</surname> <given-names>P</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Decision theory, reinforcement learning, and the brain</article-title><source>Cognitive, Affective, &amp; Behavioral Neuroscience</source><volume>8</volume><fpage>429</fpage><lpage>453</lpage><pub-id pub-id-type="doi">10.3758/CABN.8.4.429</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dhawale</surname> <given-names>AK</given-names></name><name><surname>Smith</surname> <given-names>MA</given-names></name><name><surname>Ãlveczky</surname> <given-names>BP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The role of variability in motor learning</article-title><source>Annual Review of Neuroscience</source><volume>40</volume><fpage>479</fpage><lpage>498</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-072116-031548</pub-id><pub-id pub-id-type="pmid">28489490</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dhawale</surname> <given-names>AK</given-names></name><name><surname>Miyamoto</surname> <given-names>YR</given-names></name><name><surname>Smith</surname> <given-names>MA</given-names></name><name><surname>Ãlveczky</surname> <given-names>BP</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Adaptive regulation of motor variability</article-title><source>Current Biology</source><volume>29</volume><fpage>3551</fpage><lpage>3562</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.08.052</pub-id><pub-id pub-id-type="pmid">31630947</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ebitz</surname> <given-names>RB</given-names></name><name><surname>Albarran</surname> <given-names>E</given-names></name><name><surname>Moore</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Exploration disrupts Choice-Predictive signals and alters dynamics in prefrontal cortex</article-title><source>Neuron</source><volume>97</volume><elocation-id>475</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuron.2018.01.011</pub-id><pub-id pub-id-type="pmid">29346756</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faisal</surname> <given-names>AA</given-names></name><name><surname>Selen</surname> <given-names>LP</given-names></name><name><surname>Wolpert</surname> <given-names>DM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Noise in the nervous system</article-title><source>Nature Reviews Neuroscience</source><volume>9</volume><fpage>292</fpage><lpage>303</lpage><pub-id pub-id-type="doi">10.1038/nrn2258</pub-id><pub-id pub-id-type="pmid">18319728</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fee</surname> <given-names>MS</given-names></name><name><surname>Goldberg</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A hypothesis for basal ganglia-dependent reinforcement learning in the songbird</article-title><source>Neuroscience</source><volume>198</volume><fpage>152</fpage><lpage>170</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2011.09.069</pub-id><pub-id pub-id-type="pmid">22015923</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname> <given-names>MJ</given-names></name><name><surname>Doll</surname> <given-names>BB</given-names></name><name><surname>Oas-Terpstra</surname> <given-names>J</given-names></name><name><surname>Moreno</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Prefrontal and striatal dopaminergic genes predict individual differences in exploration and exploitation</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1062</fpage><lpage>1068</lpage><pub-id pub-id-type="doi">10.1038/nn.2342</pub-id><pub-id pub-id-type="pmid">19620978</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Gao</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A theory of multineuronal dimensionality, dynamics and measurement</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/214262</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gibbon</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="1977">1977</year><article-title>Scalar expectancy theory and Weberâs law in animal timing</article-title><source>Psychological ReviewÂ American Psychological Association</source><volume>84</volume><elocation-id>279</elocation-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gibbon</surname> <given-names>J</given-names></name><name><surname>Church</surname> <given-names>RM</given-names></name><name><surname>Meck</surname> <given-names>WH</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>âScalar Timing in Memoryâ, <italic>Annals of the New York Academy of Sciences</italic></article-title><source>Blackwell Publishing Ltd</source><volume>423</volume><fpage>52</fpage><lpage>77</lpage></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilden</surname> <given-names>DL</given-names></name><name><surname>Thornton</surname> <given-names>T</given-names></name><name><surname>Mallon</surname> <given-names>MW</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>1/f noise in human cognition</article-title><source>Science</source><volume>267</volume><fpage>1837</fpage><lpage>1839</lpage><pub-id pub-id-type="doi">10.1126/science.7892611</pub-id><pub-id pub-id-type="pmid">7892611</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>GouvÃªa</surname> <given-names>TS</given-names></name><name><surname>Monteiro</surname> <given-names>T</given-names></name><name><surname>Motiwala</surname> <given-names>A</given-names></name><name><surname>Soares</surname> <given-names>S</given-names></name><name><surname>Machens</surname> <given-names>C</given-names></name><name><surname>Paton</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Striatal dynamics explain duration judgments</article-title><source>eLife</source><volume>4</volume><elocation-id>e11386</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.11386</pub-id><pub-id pub-id-type="pmid">26641377</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grossberg</surname> <given-names>S</given-names></name><name><surname>Schmajuk</surname> <given-names>NA</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Neural dynamics of adaptive timing and temporal discrimination during associative learning</article-title><source>Neural Networks</source><volume>2</volume><fpage>79</fpage><lpage>102</lpage><pub-id pub-id-type="doi">10.1016/0893-6080(89)90026-9</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname> <given-names>ZV</given-names></name><name><surname>Inagaki</surname> <given-names>HK</given-names></name><name><surname>Daie</surname> <given-names>K</given-names></name><name><surname>Druckmann</surname> <given-names>S</given-names></name><name><surname>Gerfen</surname> <given-names>CR</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Maintenance of persistent activity in a frontal thalamocortical loop</article-title><source>Nature</source><volume>545</volume><fpage>181</fpage><lpage>186</lpage><pub-id pub-id-type="doi">10.1038/nature22324</pub-id><pub-id pub-id-type="pmid">28467817</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haith</surname> <given-names>AM</given-names></name><name><surname>Krakauer</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Motor learning by sequential sampling of actions</article-title><source>Translational and Computational Motor Control</source><volume>9</volume><elocation-id>c170043</elocation-id><pub-id pub-id-type="doi">10.1002/cphy.c170043</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halassa</surname> <given-names>MM</given-names></name><name><surname>Chen</surname> <given-names>Z</given-names></name><name><surname>Wimmer</surname> <given-names>RD</given-names></name><name><surname>Brunetti</surname> <given-names>PM</given-names></name><name><surname>Zhao</surname> <given-names>S</given-names></name><name><surname>Zikopoulos</surname> <given-names>B</given-names></name><name><surname>Wang</surname> <given-names>F</given-names></name><name><surname>Brown</surname> <given-names>EN</given-names></name><name><surname>Wilson</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>State-dependent architecture of thalamic reticular subnetworks</article-title><source>Cell</source><volume>158</volume><fpage>808</fpage><lpage>821</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2014.06.025</pub-id><pub-id pub-id-type="pmid">25126786</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname> <given-names>KD</given-names></name><name><surname>Thiele</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cortical state and attention</article-title><source>Nature Reviews Neuroscience</source><volume>12</volume><fpage>509</fpage><lpage>523</lpage><pub-id pub-id-type="doi">10.1038/nrn3084</pub-id><pub-id pub-id-type="pmid">21829219</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname> <given-names>CM</given-names></name><name><surname>Wolpert</surname> <given-names>DM</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Signal-dependent noise determines motor planning</article-title><source>Nature</source><volume>394</volume><fpage>780</fpage><lpage>784</lpage><pub-id pub-id-type="doi">10.1038/29528</pub-id><pub-id pub-id-type="pmid">9723616</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hauser</surname> <given-names>CK</given-names></name><name><surname>Zhu</surname> <given-names>D</given-names></name><name><surname>Stanford</surname> <given-names>TR</given-names></name><name><surname>Salinas</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Motor selection dynamics in FEF explain the reaction time variance of saccades to single targets</article-title><source>eLife</source><volume>7</volume><elocation-id>e33456</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.33456</pub-id><pub-id pub-id-type="pmid">29652247</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hayden</surname> <given-names>BY</given-names></name><name><surname>Pearson</surname> <given-names>JM</given-names></name><name><surname>Platt</surname> <given-names>ML</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Neuronal basis of sequential foraging decisions in a patchy environment</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>933</fpage><lpage>939</lpage><pub-id pub-id-type="doi">10.1038/nn.2856</pub-id><pub-id pub-id-type="pmid">21642973</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Herzfeld</surname> <given-names>DJ</given-names></name><name><surname>Kojima</surname> <given-names>Y</given-names></name><name><surname>Soetedjo</surname> <given-names>R</given-names></name><name><surname>Shadmehr</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Encoding of action by the Purkinje cells of the cerebellum</article-title><source>Nature</source><volume>526</volume><fpage>439</fpage><lpage>442</lpage><pub-id pub-id-type="doi">10.1038/nature15693</pub-id><pub-id pub-id-type="pmid">26469054</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoshi</surname> <given-names>E</given-names></name><name><surname>Tremblay</surname> <given-names>L</given-names></name><name><surname>FÃ©ger</surname> <given-names>J</given-names></name><name><surname>Carras</surname> <given-names>PL</given-names></name><name><surname>Strick</surname> <given-names>PL</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The cerebellum communicates with the basal ganglia</article-title><source>Nature Neuroscience</source><volume>8</volume><fpage>1491</fpage><lpage>1493</lpage><pub-id pub-id-type="doi">10.1038/nn1544</pub-id><pub-id pub-id-type="pmid">16205719</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname> <given-names>VS</given-names></name><name><surname>Haith</surname> <given-names>A</given-names></name><name><surname>Mazzoni</surname> <given-names>P</given-names></name><name><surname>Krakauer</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Rethinking motor learning and savings in adaptation paradigms: model-free memory for successful actions combines with internal models</article-title><source>Neuron</source><volume>70</volume><fpage>787</fpage><lpage>801</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.04.012</pub-id><pub-id pub-id-type="pmid">21609832</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname> <given-names>C</given-names></name><name><surname>Ruff</surname> <given-names>DA</given-names></name><name><surname>Pyle</surname> <given-names>R</given-names></name><name><surname>Rosenbaum</surname> <given-names>R</given-names></name><name><surname>Cohen</surname> <given-names>MR</given-names></name><name><surname>Doiron</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Circuit models of Low-Dimensional shared variability in cortical networks</article-title><source>Neuron</source><volume>101</volume><fpage>337</fpage><lpage>348</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.11.034</pub-id><pub-id pub-id-type="pmid">30581012</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname> <given-names>DH</given-names></name><name><surname>Wiesel</surname> <given-names>TN</given-names></name></person-group><year iso-8601-date="1962">1962</year><article-title>Receptive fields, binocular interaction and functional architecture in the cat's visual cortex</article-title><source>The Journal of Physiology</source><volume>160</volume><fpage>106</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1962.sp006837</pub-id><pub-id pub-id-type="pmid">14449617</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huberdeau</surname> <given-names>DM</given-names></name><name><surname>Krakauer</surname> <given-names>JW</given-names></name><name><surname>Haith</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Dual-process decomposition in human sensorimotor adaptation</article-title><source>Current Opinion in Neurobiology</source><volume>33</volume><fpage>71</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2015.03.003</pub-id><pub-id pub-id-type="pmid">25827272</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ito</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Historical review of the significance of the cerebellum and the role of purkinje cells in motor learning</article-title><source>Annals of the New York Academy of Sciences</source><volume>978</volume><fpage>273</fpage><lpage>288</lpage><pub-id pub-id-type="doi">10.1111/j.1749-6632.2002.tb07574.x</pub-id><pub-id pub-id-type="pmid">12582060</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Izawa</surname> <given-names>J</given-names></name><name><surname>Shadmehr</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Learning from sensory and reward prediction errors during motor adaptation</article-title><source>PLOS Computational Biology</source><volume>7</volume><elocation-id>e1002012</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002012</pub-id><pub-id pub-id-type="pmid">21423711</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jazayeri</surname> <given-names>M</given-names></name><name><surname>Shadlen</surname> <given-names>MN</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Temporal context calibrates interval timing</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>1020</fpage><lpage>1026</lpage><pub-id pub-id-type="doi">10.1038/nn.2590</pub-id><pub-id pub-id-type="pmid">20581842</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jazayeri</surname> <given-names>M</given-names></name><name><surname>Shadlen</surname> <given-names>MN</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A neural mechanism for sensing and reproducing a time interval</article-title><source>Current Biology</source><volume>25</volume><fpage>2599</fpage><lpage>2609</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.08.038</pub-id><pub-id pub-id-type="pmid">26455307</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joiner</surname> <given-names>WM</given-names></name><name><surname>Smith</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Long-term retention explained by a model of short-term learning in the adaptive control of reaching</article-title><source>Journal of Neurophysiology</source><volume>100</volume><fpage>2948</fpage><lpage>2955</lpage><pub-id pub-id-type="doi">10.1152/jn.90706.2008</pub-id><pub-id pub-id-type="pmid">18784273</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaelbling</surname> <given-names>LP</given-names></name><name><surname>Littman</surname> <given-names>ML</given-names></name><name><surname>Moore</surname> <given-names>AW</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Reinforcement learning: a survey</article-title><source>Journal of Artificial Intelligence Research</source><volume>4</volume><fpage>237</fpage><lpage>285</lpage><pub-id pub-id-type="doi">10.1613/jair.301</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kao</surname> <given-names>MH</given-names></name><name><surname>Doupe</surname> <given-names>AJ</given-names></name><name><surname>Brainard</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Contributions of an avian basal ganglia-forebrain circuit to real-time modulation of song</article-title><source>Nature</source><volume>433</volume><fpage>638</fpage><lpage>643</lpage><pub-id pub-id-type="doi">10.1038/nature03127</pub-id><pub-id pub-id-type="pmid">15703748</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karlsson</surname> <given-names>MP</given-names></name><name><surname>Tervo</surname> <given-names>DG</given-names></name><name><surname>Karpova</surname> <given-names>AY</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Network resets in medial prefrontal cortex mark the onset of behavioral uncertainty</article-title><source>Science</source><volume>338</volume><fpage>135</fpage><lpage>139</lpage><pub-id pub-id-type="doi">10.1126/science.1226518</pub-id><pub-id pub-id-type="pmid">23042898</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kato</surname> <given-names>HK</given-names></name><name><surname>Chu</surname> <given-names>MW</given-names></name><name><surname>Isaacson</surname> <given-names>JS</given-names></name><name><surname>Komiyama</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Dynamic sensory representations in the olfactory bulb: modulation by wakefulness and experience</article-title><source>Neuron</source><volume>76</volume><fpage>962</fpage><lpage>975</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.09.037</pub-id><pub-id pub-id-type="pmid">23217744</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Kaufman</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><source>Github</source><version designator="d760079">d760079</version><ext-link ext-link-type="uri" xlink:href="https://github.com/ripple-neuro/mksort">https://github.com/ripple-neuro/mksort</ext-link></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Killeen</surname> <given-names>PR</given-names></name><name><surname>Fetterman</surname> <given-names>JG</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>A behavioral theory of timing</article-title><source>Psychological Review</source><volume>95</volume><fpage>274</fpage><lpage>295</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.95.2.274</pub-id><pub-id pub-id-type="pmid">3375401</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kunimatsu</surname> <given-names>J</given-names></name><name><surname>Suzuki</surname> <given-names>TW</given-names></name><name><surname>Ohmae</surname> <given-names>S</given-names></name><name><surname>Tanaka</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Different contributions of preparatory activity in the basal ganglia and cerebellum for self-timing</article-title><source>eLife</source><volume>7</volume><elocation-id>e35676</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.35676</pub-id><pub-id pub-id-type="pmid">29963985</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kunimatsu</surname> <given-names>J</given-names></name><name><surname>Tanaka</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Striatal dopamine modulates timing of self-initiated saccades</article-title><source>Neuroscience</source><volume>337</volume><fpage>131</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2016.09.006</pub-id><pub-id pub-id-type="pmid">27651148</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Laming</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Autocorrelation of choice-reaction times</article-title><source>Acta Psychologica</source><volume>43</volume><fpage>381</fpage><lpage>412</lpage><pub-id pub-id-type="doi">10.1016/0001-6918(79)90032-5</pub-id><pub-id pub-id-type="pmid">495175</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lara</surname> <given-names>AH</given-names></name><name><surname>Elsayed</surname> <given-names>GF</given-names></name><name><surname>Zimnik</surname> <given-names>AJ</given-names></name><name><surname>Cunningham</surname> <given-names>JP</given-names></name><name><surname>Churchland</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Conservation of preparatory neural events in monkey motor cortex regardless of how movement is initiated</article-title><source>eLife</source><volume>7</volume><elocation-id>e31826</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.31826</pub-id><pub-id pub-id-type="pmid">30132759</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lau</surname> <given-names>B</given-names></name><name><surname>Glimcher</surname> <given-names>PW</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Action and outcome encoding in the primate caudate nucleus</article-title><source>Journal of Neuroscience</source><volume>27</volume><fpage>14502</fpage><lpage>14514</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3060-07.2007</pub-id><pub-id pub-id-type="pmid">18160658</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lauwereyns</surname> <given-names>J</given-names></name><name><surname>Watanabe</surname> <given-names>K</given-names></name><name><surname>Coe</surname> <given-names>B</given-names></name><name><surname>Hikosaka</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>A neural correlate of response Bias in monkey caudate nucleus</article-title><source>Nature</source><volume>418</volume><fpage>413</fpage><lpage>417</lpage><pub-id pub-id-type="doi">10.1038/nature00892</pub-id><pub-id pub-id-type="pmid">12140557</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>MD</given-names></name><name><surname>Zhang</surname> <given-names>S</given-names></name><name><surname>Munro</surname> <given-names>M</given-names></name><name><surname>Steyvers</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Psychological models of human and optimal performance in bandit problems</article-title><source>Cognitive Systems Research</source><volume>12</volume><fpage>164</fpage><lpage>174</lpage><pub-id pub-id-type="doi">10.1016/j.cogsys.2010.07.007</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>SH</given-names></name><name><surname>Dan</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neuromodulation of brain states</article-title><source>Neuron</source><volume>76</volume><fpage>209</fpage><lpage>222</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.09.012</pub-id><pub-id pub-id-type="pmid">23040816</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luck</surname> <given-names>SJ</given-names></name><name><surname>Chelazzi</surname> <given-names>L</given-names></name><name><surname>Hillyard</surname> <given-names>SA</given-names></name><name><surname>Desimone</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Neural mechanisms of spatial selective attention in Areas V1, V2, and V4 of macaque visual cortex</article-title><source>Journal of Neurophysiology</source><volume>77</volume><fpage>24</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1152/jn.1997.77.1.24</pub-id><pub-id pub-id-type="pmid">9120566</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Machado</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Learning the temporal dynamics of behavior</article-title><source>Psychological Review</source><volume>104</volume><fpage>241</fpage><lpage>265</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.104.2.241</pub-id><pub-id pub-id-type="pmid">9127582</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Malapani</surname> <given-names>C</given-names></name><name><surname>Fairhurst</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Scalar timing in animals and humans</article-title><source>Learning and Motivation</source><volume>33</volume><fpage>156</fpage><lpage>176</lpage><pub-id pub-id-type="doi">10.1006/lmot.2001.1105</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Massi</surname> <given-names>B</given-names></name><name><surname>Donahue</surname> <given-names>CH</given-names></name><name><surname>Lee</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Volatility facilitates value updating in the prefrontal cortex</article-title><source>Neuron</source><volume>99</volume><fpage>598</fpage><lpage>608</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.06.033</pub-id><pub-id pub-id-type="pmid">30033151</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mauk</surname> <given-names>MD</given-names></name><name><surname>Buonomano</surname> <given-names>DV</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>The neural basis of temporal processing</article-title><source>Annual Review of Neuroscience</source><volume>27</volume><fpage>307</fpage><lpage>340</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.27.070203.144247</pub-id><pub-id pub-id-type="pmid">15217335</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McAlonan</surname> <given-names>K</given-names></name><name><surname>Cavanaugh</surname> <given-names>J</given-names></name><name><surname>Wurtz</surname> <given-names>RH</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Guarding the gateway to cortex with attention in visual thalamus</article-title><source>Nature</source><volume>456</volume><fpage>391</fpage><lpage>394</lpage><pub-id pub-id-type="doi">10.1038/nature07382</pub-id><pub-id pub-id-type="pmid">18849967</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Medina</surname> <given-names>JF</given-names></name><name><surname>Lisberger</surname> <given-names>SG</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Links from complex spikes to local plasticity and motor learning in the cerebellum of awake-behaving monkeys</article-title><source>Nature Neuroscience</source><volume>11</volume><fpage>1185</fpage><lpage>1192</lpage><pub-id pub-id-type="doi">10.1038/nn.2197</pub-id><pub-id pub-id-type="pmid">18806784</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merchant</surname> <given-names>H</given-names></name><name><surname>Averbeck</surname> <given-names>BB</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The computational and neural basis of rhythmic timing in medial premotor cortex</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>4552</fpage><lpage>4564</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0367-17.2017</pub-id><pub-id pub-id-type="pmid">28336572</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merrill</surname> <given-names>WJ</given-names></name><name><surname>Bennett</surname> <given-names>CA</given-names></name></person-group><year iso-8601-date="1956">1956</year><article-title>The application of temporal correlation techniques in psychology</article-title><source>Journal of Applied Psychology</source><volume>40</volume><fpage>272</fpage><lpage>280</lpage><pub-id pub-id-type="doi">10.1037/h0043648</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Middleton</surname> <given-names>FA</given-names></name><name><surname>Strick</surname> <given-names>PL</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Basal ganglia and cerebellar loops: motor and cognitive circuits</article-title><source>Brain Research Reviews</source><volume>31</volume><fpage>236</fpage><lpage>250</lpage><pub-id pub-id-type="doi">10.1016/S0165-0173(99)00040-5</pub-id><pub-id pub-id-type="pmid">10719151</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mitchell</surname> <given-names>JF</given-names></name><name><surname>Sundberg</surname> <given-names>KA</given-names></name><name><surname>Reynolds</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Spatial attention decorrelates intrinsic activity fluctuations in macaque area V4</article-title><source>Neuron</source><volume>63</volume><fpage>879</fpage><lpage>888</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.09.013</pub-id><pub-id pub-id-type="pmid">19778515</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murakami</surname> <given-names>M</given-names></name><name><surname>Vicente</surname> <given-names>MI</given-names></name><name><surname>Costa</surname> <given-names>GM</given-names></name><name><surname>Mainen</surname> <given-names>ZF</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Neural antecedents of self-initiated actions in secondary motor cortex</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1574</fpage><lpage>1582</lpage><pub-id pub-id-type="doi">10.1038/nn.3826</pub-id><pub-id pub-id-type="pmid">25262496</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murakami</surname> <given-names>M</given-names></name><name><surname>Shteingart</surname> <given-names>H</given-names></name><name><surname>Loewenstein</surname> <given-names>Y</given-names></name><name><surname>Mainen</surname> <given-names>ZF</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Distinct sources of deterministic and stochastic components of action timing decisions in rodent frontal cortex</article-title><source>Neuron</source><volume>94</volume><fpage>908</fpage><lpage>919</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.04.040</pub-id><pub-id pub-id-type="pmid">28521140</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Narain</surname> <given-names>D</given-names></name><name><surname>Remington</surname> <given-names>ED</given-names></name><name><surname>Zeeuw</surname> <given-names>CI</given-names></name><name><surname>Jazayeri</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A cerebellar mechanism for learning prior distributions of time intervals</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>469</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-017-02516-x</pub-id><pub-id pub-id-type="pmid">29391392</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Narayanan</surname> <given-names>NS</given-names></name><name><surname>Laubach</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Neuronal correlates of post-error slowing in the rat dorsomedial prefrontal cortex</article-title><source>Journal of Neurophysiology</source><volume>100</volume><fpage>520</fpage><lpage>525</lpage><pub-id pub-id-type="doi">10.1152/jn.00035.2008</pub-id><pub-id pub-id-type="pmid">18480374</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ni</surname> <given-names>AM</given-names></name><name><surname>Ruff</surname> <given-names>DA</given-names></name><name><surname>Alberts</surname> <given-names>JJ</given-names></name><name><surname>Symmonds</surname> <given-names>J</given-names></name><name><surname>Cohen</surname> <given-names>MR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Learning and attention reveal a general relationship between population activity and behavior</article-title><source>Science</source><volume>359</volume><fpage>463</fpage><lpage>465</lpage><pub-id pub-id-type="doi">10.1126/science.aao0284</pub-id><pub-id pub-id-type="pmid">29371470</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niell</surname> <given-names>CM</given-names></name><name><surname>Stryker</surname> <given-names>MP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Modulation of visual responses by behavioral state in mouse visual cortex</article-title><source>Neuron</source><volume>65</volume><fpage>472</fpage><lpage>479</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.01.033</pub-id><pub-id pub-id-type="pmid">20188652</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nikooyan</surname> <given-names>AA</given-names></name><name><surname>Ahmed</surname> <given-names>AA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Reward feedback accelerates motor learning</article-title><source>Journal of Neurophysiology</source><volume>113</volume><fpage>633</fpage><lpage>646</lpage><pub-id pub-id-type="doi">10.1152/jn.00032.2014</pub-id><pub-id pub-id-type="pmid">25355957</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ãlveczky</surname> <given-names>BP</given-names></name><name><surname>Andalman</surname> <given-names>AS</given-names></name><name><surname>Fee</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Vocal Experimentation in the Juvenile Songbird Requires a Basal Ganglia Circuit</article-title><source>PLOS Biology</source><volume>3</volume><elocation-id>e153</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0030153</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oprisan</surname> <given-names>SA</given-names></name><name><surname>Buhusi</surname> <given-names>CV</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>What is all the noise about in interval timing?</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>369</volume><elocation-id>20120459</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2012.0459</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palidis</surname> <given-names>DJ</given-names></name><name><surname>Cashaback</surname> <given-names>JGA</given-names></name><name><surname>Gribble</surname> <given-names>PL</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neural signatures of reward and sensory error feedback processing in motor learning</article-title><source>Journal of Neurophysiology</source><volume>121</volume><fpage>1561</fpage><lpage>1574</lpage><pub-id pub-id-type="doi">10.1152/jn.00792.2018</pub-id><pub-id pub-id-type="pmid">30811259</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paton</surname> <given-names>JJ</given-names></name><name><surname>Buonomano</surname> <given-names>DV</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The neural basis of timing: distributed mechanisms for diverse functions</article-title><source>Neuron</source><volume>98</volume><fpage>687</fpage><lpage>705</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.03.045</pub-id><pub-id pub-id-type="pmid">29772201</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pekny</surname> <given-names>SE</given-names></name><name><surname>Izawa</surname> <given-names>J</given-names></name><name><surname>Shadmehr</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Reward-dependent modulation of movement variability</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>4015</fpage><lpage>4024</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3244-14.2015</pub-id><pub-id pub-id-type="pmid">25740529</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Rasmussen</surname> <given-names>CE</given-names></name><name><surname>Williams</surname> <given-names>CK</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>Gaussian Process for Machine Learning</source><publisher-name>MIT press</publisher-name><pub-id pub-id-type="doi">10.1007/978-3-540-28650-9_4</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Remington</surname> <given-names>ED</given-names></name><name><surname>Egger</surname> <given-names>SW</given-names></name><name><surname>Narain</surname> <given-names>D</given-names></name><name><surname>Wang</surname> <given-names>J</given-names></name><name><surname>Jazayeri</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018a</year><article-title>A dynamical systems perspective on flexible motor timing</article-title><source>Trends in Cognitive Sciences</source><volume>22</volume><fpage>938</fpage><lpage>952</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.07.010</pub-id><pub-id pub-id-type="pmid">30266152</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Remington</surname> <given-names>ED</given-names></name><name><surname>Narain</surname> <given-names>D</given-names></name><name><surname>Hosseini</surname> <given-names>EA</given-names></name><name><surname>Jazayeri</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018b</year><article-title>Flexible sensorimotor computations through rapid reconfiguration of cortical dynamics</article-title><source>Neuron</source><volume>98</volume><fpage>1005</fpage><lpage>1019</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.05.020</pub-id><pub-id pub-id-type="pmid">29879384</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruff</surname> <given-names>DA</given-names></name><name><surname>Cohen</surname> <given-names>MR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Attention can either increase or decrease spike count correlations in visual cortex</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1591</fpage><lpage>1597</lpage><pub-id pub-id-type="doi">10.1038/nn.3835</pub-id><pub-id pub-id-type="pmid">25306550</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saalmann</surname> <given-names>YB</given-names></name><name><surname>Pinsk</surname> <given-names>MA</given-names></name><name><surname>Wang</surname> <given-names>L</given-names></name><name><surname>Li</surname> <given-names>X</given-names></name><name><surname>Kastner</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The pulvinar regulates information transmission between cortical Areas based on attention demands</article-title><source>Science</source><volume>337</volume><fpage>753</fpage><lpage>756</lpage><pub-id pub-id-type="doi">10.1126/science.1223082</pub-id><pub-id pub-id-type="pmid">22879517</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Santos</surname> <given-names>FJ</given-names></name><name><surname>Oliveira</surname> <given-names>RF</given-names></name><name><surname>Jin</surname> <given-names>X</given-names></name><name><surname>Costa</surname> <given-names>RM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Corticostriatal dynamics encode the refinement of specific behavioral variability during skill learning</article-title><source>eLife</source><volume>4</volume><elocation-id>e09423</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.09423</pub-id><pub-id pub-id-type="pmid">26417950</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sarafyazd</surname> <given-names>M</given-names></name><name><surname>Jazayeri</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Hierarchical reasoning by neural circuits in the frontal cortex</article-title><source>Science</source><volume>364</volume><elocation-id>eaav8911</elocation-id><pub-id pub-id-type="doi">10.1126/science.aav8911</pub-id><pub-id pub-id-type="pmid">31097640</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmitt</surname> <given-names>LI</given-names></name><name><surname>Wimmer</surname> <given-names>RD</given-names></name><name><surname>Nakajima</surname> <given-names>M</given-names></name><name><surname>Happ</surname> <given-names>M</given-names></name><name><surname>Mofakham</surname> <given-names>S</given-names></name><name><surname>Halassa</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Thalamic amplification of cortical connectivity sustains attentional control</article-title><source>Nature</source><volume>545</volume><fpage>219</fpage><lpage>223</lpage><pub-id pub-id-type="doi">10.1038/nature22073</pub-id><pub-id pub-id-type="pmid">28467827</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheahan</surname> <given-names>HR</given-names></name><name><surname>Franklin</surname> <given-names>DW</given-names></name><name><surname>Wolpert</surname> <given-names>DM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Motor planning, not execution, separates motor memories</article-title><source>Neuron</source><volume>92</volume><fpage>773</fpage><lpage>779</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.10.017</pub-id><pub-id pub-id-type="pmid">27817979</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shmuelof</surname> <given-names>L</given-names></name><name><surname>Huang</surname> <given-names>VS</given-names></name><name><surname>Haith</surname> <given-names>AM</given-names></name><name><surname>Delnicki</surname> <given-names>RJ</given-names></name><name><surname>Mazzoni</surname> <given-names>P</given-names></name><name><surname>Krakauer</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2012">2012a</year><article-title>Overcoming motor &quot;forgetting&quot; through reinforcement of learned actions</article-title><source>Journal of Neuroscience</source><volume>32</volume><fpage>14617</fpage><lpage>14621</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2184-12.2012</pub-id><pub-id pub-id-type="pmid">23077047</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shmuelof</surname> <given-names>L</given-names></name><name><surname>Krakauer</surname> <given-names>JW</given-names></name><name><surname>Mazzoni</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2012">2012b</year><article-title>How is a motor skill learned? change and invariance at the levels of task success and trajectory control</article-title><source>Journal of Neurophysiology</source><volume>108</volume><fpage>578</fpage><lpage>594</lpage><pub-id pub-id-type="doi">10.1152/jn.00856.2011</pub-id><pub-id pub-id-type="pmid">22514286</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simen</surname> <given-names>P</given-names></name><name><surname>Balci</surname> <given-names>F</given-names></name><name><surname>de Souza</surname> <given-names>L</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name><name><surname>Holmes</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A model of interval timing by neural integration</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>9238</fpage><lpage>9253</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3121-10.2011</pub-id><pub-id pub-id-type="pmid">21697374</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname> <given-names>MA</given-names></name><name><surname>Ghazizadeh</surname> <given-names>A</given-names></name><name><surname>Shadmehr</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Interacting adaptive processes with different timescales underlie short-term motor learning</article-title><source>PLOS Biology</source><volume>4</volume><elocation-id>e179</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0040179</pub-id><pub-id pub-id-type="pmid">16700627</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sommer</surname> <given-names>MA</given-names></name><name><surname>Wurtz</surname> <given-names>RH</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Influence of the thalamus on spatial visual processing in frontal cortex</article-title><source>Nature</source><volume>444</volume><fpage>374</fpage><lpage>377</lpage><pub-id pub-id-type="doi">10.1038/nature05279</pub-id><pub-id pub-id-type="pmid">17093408</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Staddon</surname> <given-names>JE</given-names></name><name><surname>Higa</surname> <given-names>JJ</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Time and memory: towards a pacemaker-free theory of interval timing</article-title><source>Journal of the Experimental Analysis of Behavior</source><volume>71</volume><fpage>215</fpage><lpage>251</lpage><pub-id pub-id-type="doi">10.1901/jeab.1999.71-215</pub-id><pub-id pub-id-type="pmid">10220931</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sternad</surname> <given-names>D</given-names></name><name><surname>Abe</surname> <given-names>MO</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Variability, noise, and sensitivity to error in learning a motor task</article-title><source>Motor Control</source><volume>1</volume><elocation-id>12</elocation-id><pub-id pub-id-type="doi">10.1093/acprof:oso/9780195395273.003.0012</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sul</surname> <given-names>JH</given-names></name><name><surname>Kim</surname> <given-names>H</given-names></name><name><surname>Huh</surname> <given-names>N</given-names></name><name><surname>Lee</surname> <given-names>D</given-names></name><name><surname>Jung</surname> <given-names>MW</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Distinct roles of rodent orbitofrontal and medial prefrontal cortex in decision making</article-title><source>Neuron</source><volume>66</volume><fpage>449</fpage><lpage>460</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.03.033</pub-id><pub-id pub-id-type="pmid">20471357</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sutton</surname> <given-names>RS</given-names></name><name><surname>Barto</surname> <given-names>AG</given-names></name></person-group><year iso-8601-date="1998">1998</year><source>Reinforcement Learning: An Introduction</source><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takikawa</surname> <given-names>Y</given-names></name><name><surname>Kawagoe</surname> <given-names>R</given-names></name><name><surname>Hikosaka</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Reward-dependent spatial selectivity of anticipatory activity in monkey caudate neurons</article-title><source>Journal of Neurophysiology</source><volume>87</volume><fpage>508</fpage><lpage>515</lpage><pub-id pub-id-type="doi">10.1152/jn.00288.2001</pub-id><pub-id pub-id-type="pmid">11784766</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tervo</surname> <given-names>DGR</given-names></name><name><surname>Proskurin</surname> <given-names>M</given-names></name><name><surname>Manakov</surname> <given-names>M</given-names></name><name><surname>Kabra</surname> <given-names>M</given-names></name><name><surname>Vollmer</surname> <given-names>A</given-names></name><name><surname>Branson</surname> <given-names>K</given-names></name><name><surname>Karpova</surname> <given-names>AY</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Behavioral variability through stochastic choice and its gating by anterior cingulate cortex</article-title><source>Cell</source><volume>159</volume><fpage>21</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2014.08.037</pub-id><pub-id pub-id-type="pmid">25259917</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thoroughman</surname> <given-names>KA</given-names></name><name><surname>Shadmehr</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Learning of action through adaptive combination of motor primitives</article-title><source>Nature</source><volume>407</volume><fpage>742</fpage><lpage>747</lpage><pub-id pub-id-type="doi">10.1038/35037588</pub-id><pub-id pub-id-type="pmid">11048720</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tumer</surname> <given-names>EC</given-names></name><name><surname>Brainard</surname> <given-names>MS</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Performance variability enables adaptive plasticity of 'crystallized' adult birdsong</article-title><source>Nature</source><volume>450</volume><fpage>1240</fpage><lpage>1244</lpage><pub-id pub-id-type="doi">10.1038/nature06390</pub-id><pub-id pub-id-type="pmid">18097411</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Beers</surname> <given-names>RJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Motor Learning Is Optimally Tuned to the Properties of Motor Noise</article-title><source>Neuron</source><volume>63</volume><fpage>406</fpage><lpage>417</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.06.025</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Kooij</surname> <given-names>K</given-names></name><name><surname>Smeets</surname> <given-names>JBJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Reward-based motor adaptation can generalize across actions</article-title><source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source><volume>45</volume><fpage>71</fpage><lpage>81</lpage><pub-id pub-id-type="doi">10.1037/xlm0000573</pub-id><pub-id pub-id-type="pmid">29698052</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaswani</surname> <given-names>PA</given-names></name><name><surname>Shmuelof</surname> <given-names>L</given-names></name><name><surname>Haith</surname> <given-names>AM</given-names></name><name><surname>Delnicki</surname> <given-names>RJ</given-names></name><name><surname>Huang</surname> <given-names>VS</given-names></name><name><surname>Mazzoni</surname> <given-names>P</given-names></name><name><surname>Shadmehr</surname> <given-names>R</given-names></name><name><surname>Krakauer</surname> <given-names>JW</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Persistent residual errors in motor adaptation tasks: reversion to baseline and exploratory escape</article-title><source>Journal of Neuroscience</source><volume>35</volume><fpage>6969</fpage><lpage>6977</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2656-14.2015</pub-id><pub-id pub-id-type="pmid">25926471</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Verstynen</surname> <given-names>T</given-names></name><name><surname>Sabes</surname> <given-names>PN</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>How each movement changes the next: an experimental and theoretical study of fast adaptive priors in reaching</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>10050</fpage><lpage>10059</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.6525-10.2011</pub-id><pub-id pub-id-type="pmid">21734297</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinck</surname> <given-names>M</given-names></name><name><surname>Batista-Brito</surname> <given-names>R</given-names></name><name><surname>Knoblich</surname> <given-names>U</given-names></name><name><surname>Cardin</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Arousal and locomotion make distinct contributions to cortical activity patterns and visual encoding</article-title><source>Neuron</source><volume>86</volume><fpage>740</fpage><lpage>754</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.028</pub-id><pub-id pub-id-type="pmid">25892300</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vyas</surname> <given-names>S</given-names></name><name><surname>Even-Chen</surname> <given-names>N</given-names></name><name><surname>Stavisky</surname> <given-names>SD</given-names></name><name><surname>Ryu</surname> <given-names>SI</given-names></name><name><surname>Nuyujukian</surname> <given-names>P</given-names></name><name><surname>Shenoy</surname> <given-names>KV</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neural population dynamics underlying motor learning transfer</article-title><source>Neuron</source><volume>97</volume><fpage>1177</fpage><lpage>1186</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.01.040</pub-id><pub-id pub-id-type="pmid">29456026</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagenmakers</surname> <given-names>EJ</given-names></name><name><surname>Farrell</surname> <given-names>S</given-names></name><name><surname>Ratcliff</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Estimation and interpretation of 1/falpha noise in human cognition</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>11</volume><fpage>579</fpage><lpage>615</lpage><pub-id pub-id-type="doi">10.3758/BF03196615</pub-id><pub-id pub-id-type="pmid">15581115</pub-id></element-citation></ref><ref id="bib119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>J</given-names></name><name><surname>Narain</surname> <given-names>D</given-names></name><name><surname>Hosseini</surname> <given-names>EA</given-names></name><name><surname>Jazayeri</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Flexible timing by temporal scaling of cortical responses</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>102</fpage><lpage>110</lpage><pub-id pub-id-type="doi">10.1038/s41593-017-0028-6</pub-id><pub-id pub-id-type="pmid">29203897</pub-id></element-citation></ref><ref id="bib120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Weiss</surname> <given-names>B</given-names></name><name><surname>Coleman</surname> <given-names>PD</given-names></name><name><surname>Green</surname> <given-names>RF</given-names></name></person-group><year iso-8601-date="1955">1955</year><article-title>A stochastic medelfor time-ordered dependencies in continous scale repetitive judgments</article-title><source>Journal of Experimental Psychology</source><volume>50</volume><fpage>237</fpage><lpage>244</lpage><pub-id pub-id-type="doi">10.1037/h0044062</pub-id><pub-id pub-id-type="pmid">13263491</pub-id></element-citation></ref><ref id="bib121"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname> <given-names>RC</given-names></name><name><surname>Geana</surname> <given-names>A</given-names></name><name><surname>White</surname> <given-names>JM</given-names></name><name><surname>Ludvig</surname> <given-names>EA</given-names></name><name><surname>Cohen</surname> <given-names>JD</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Humans use directed and random exploration to solve the explore-exploit dilemma</article-title><source>Journal of Experimental Psychology: General</source><volume>143</volume><fpage>2074</fpage><lpage>2081</lpage><pub-id pub-id-type="doi">10.1037/a0038199</pub-id><pub-id pub-id-type="pmid">25347535</pub-id></element-citation></ref><ref id="bib122"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wimmer</surname> <given-names>RD</given-names></name><name><surname>Schmitt</surname> <given-names>LI</given-names></name><name><surname>Davidson</surname> <given-names>TJ</given-names></name><name><surname>Nakajima</surname> <given-names>M</given-names></name><name><surname>Deisseroth</surname> <given-names>K</given-names></name><name><surname>Halassa</surname> <given-names>MM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Thalamic control of sensory selection in divided attention</article-title><source>Nature</source><volume>526</volume><fpage>705</fpage><lpage>709</lpage><pub-id pub-id-type="doi">10.1038/nature15398</pub-id><pub-id pub-id-type="pmid">26503050</pub-id></element-citation></ref><ref id="bib123"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolpert</surname> <given-names>DM</given-names></name><name><surname>Diedrichsen</surname> <given-names>J</given-names></name><name><surname>Flanagan</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Principles of sensorimotor learning</article-title><source>Nature Reviews Neuroscience</source><volume>12</volume><fpage>739</fpage><lpage>751</lpage><pub-id pub-id-type="doi">10.1038/nrn3112</pub-id><pub-id pub-id-type="pmid">22033537</pub-id></element-citation></ref><ref id="bib124"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname> <given-names>HG</given-names></name><name><surname>Miyamoto</surname> <given-names>YR</given-names></name><name><surname>Gonzalez Castro</surname> <given-names>LN</given-names></name><name><surname>Ãlveczky</surname> <given-names>BP</given-names></name><name><surname>Smith</surname> <given-names>MA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Temporal structure of motor variability is dynamically regulated and predicts motor learning ability</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>312</fpage><lpage>321</lpage><pub-id pub-id-type="doi">10.1038/nn.3616</pub-id><pub-id pub-id-type="pmid">24413700</pub-id></element-citation></ref><ref id="bib125"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xiong</surname> <given-names>Q</given-names></name><name><surname>Znamenskiy</surname> <given-names>P</given-names></name><name><surname>Zador</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Selective corticostriatal plasticity during acquisition of an auditory discrimination task</article-title><source>Nature</source><volume>521</volume><fpage>348</fpage><lpage>351</lpage><pub-id pub-id-type="doi">10.1038/nature14225</pub-id></element-citation></ref><ref id="bib126"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yasuda</surname> <given-names>M</given-names></name><name><surname>Hikosaka</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Functional territories in primate substantia nigra pars reticulata separately signaling stable and flexible values</article-title><source>Journal of Neurophysiology</source><volume>113</volume><fpage>1681</fpage><lpage>1696</lpage><pub-id pub-id-type="doi">10.1152/jn.00674.2014</pub-id></element-citation></ref><ref id="bib127"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname> <given-names>H</given-names></name><name><surname>Schafer</surname> <given-names>RJ</given-names></name><name><surname>Desimone</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Pulvinar-Cortex Interactions in Vision and Attention</article-title><source>Neuron</source><volume>89</volume><fpage>209</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.034</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.55872.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Wei</surname><given-names>Kunlin</given-names></name><role>Reviewing Editor</role><aff><institution>Peking University</institution><country>China</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Wei</surname><given-names>Kunlin</given-names> </name><role>Reviewer</role><aff><institution>Peking University</institution><country>China</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Averbeck</surname><given-names>Bruno B</given-names></name><role>Reviewer</role><aff><institution>NIH/NIMH</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>How variability in motor actions changes with learning is not well understood, and the area is waiting for advances in both computational theorization and related neural underpinnings. The present study contributes by investigating a motor timing task in which reward-dependent learning and timing variability interact. Importantly, the observed behavioral signatures enable new modeling of motor reinforcement learning and characterizing the underlying neural substrate in the cortico-basal ganglia circuit.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Reinforcement regulates timing variability in thalamus&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, including Kunlin Wei as the Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Michael Frank as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Bruno B Averbeck (Reviewer #2).</p><p>The reviewers have discussed the reviews with one another, and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>As the editors have judged that your manuscript is of interest, but as described below that additional experiments/analyses are required before it is published, we would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). First, because many researchers have temporarily lost access to the labs, we will give authors as much time as they need to submit revised manuscripts. We are also offering, if you choose, to post the manuscript to bioRxiv (if it is not already there) along with this decision letter and a formal designation that the manuscript is &quot;in revision at <italic>eLife</italic>&quot;. Please let us know if you would like to pursue this option. (If your work is more suitable for medRxiv, you will need to post the preprint yourself, as the mechanisms for us to do so are still in development.)</p><p>Summary:</p><p>How variability in motor actions changes with learning is not well understood. The present study starts off with a motor timing task where monkeys and human participants were required to produce timing intervals on the scale of hundreds of milliseconds. Two behavioral features emerge: one is strong correlations of timing produced intervals within effectors and intervals, the other is increased timing variability when the produced intervals were away from the target or mean interval. The first feature is interpreted as a slow drift of timing memory, and the second feature is interpreted as from strategic use of exploratory variance to guard against undesirable variability, i.e., the memory drift. The study provided a computational model to incorporate continuous rewards in the framework of reinforcement learning. Furthermore, the study also correlated the direct recording from the thalamus, DMFC, and caudate to the two behavioral findings, and found that the thalamus showed reward-dependent neural activities with clear effector-specificity. The authors conclude that the nervous system strategically regulates the variability based on reinforcement to reduce the detrimental effect of undesirable variability in the system in the exploration-exploitation framework.</p><p>There was agreement among the reviewers that these results will be of interest to the audience of <italic>eLife</italic>. However, there are critical issues that need to be addressed before the paper being considered for acceptance. The first major concern is essential, given that it is about whether the current data can be interpreted as the way it is.</p><p>Essential revisions:</p><p>1) The main message of the paper is to explain the non-stationarity in the timing variance in the exploration-exploitation framework, but this is questionable. As the reward follows a specific function of timing error, the first derivative of the reward feedback could effectively guide the trial-by-trial modulation of timing behaviors. For example, a decrease in reward would signal a departure from the target interval, which can be used to guide an appropriate response in the next trial. In this case, there is no need to crank up noise with a decrease in reward, as the exploration-exploitation framework would predict. Thus, the observed changes in variance can be explained by trial-by-trial learning based on the explicit reinforcement feedback signal, without invoking the idea of random exploration as in the exploration-exploitation framework. Recent theoretical approaches to model exploration-exploitation behaviors have emphasized both random vs. directed exploration (Wilson et al., 2014), but the current study appears to assume that all exploration should be random. Considering that the task has a 1-D continuous reward function, directed exploration is well possible. This is a critical question given that the main implication of the study is about &quot;â¦the nervous system makes strategic use of exploratory varianceâ¦&quot;. In fact, the whole paper is framed as probing reinforcement-guided exploration as opposed to trial-by-trial supervised learning.</p><p>In a similar vein, the non-stationarity in the variance is caused by the reward magnitude (the specific reward function used here), not necessarily a refutation of stationarity of interval time. It has been acknowledged by the author that this is not a rejection of the interval timing model, but the paper continues to imply it in the Abstract and in the Results.</p><p>Did the subjects not use information from the first derivative of the reward to update their produced intervals? It is not even clear that how many produced intervals fell within the rewarded range, and how many were simply unrewarded. The details of the reward magnitude and the monkey's behavioural adaptations to these changes in reward need to be clarified. To make the original claims of the paper hold, the authors need to clarify whether the results can be explained by simple trial-by-trial adjustments based on the first derivative of the reward function.</p><p>2) The human task with a probabilistic reward has not been directly compared with the monkey experiment, though both are displayed in Figure 5. Related to question 1), can the findings with probabilistic rewards suffice to rule out the possibility that the first derivative of reward feedback is the driving force for the observed variance changes?</p><p>3) The asymmetry of interval variance was evident for both monkeys when the target interval of 1500ms was produced (Figure 1D), but it was left unexplained. This asymmetry shows a much higher variance for the shorter intervals, i.e., skewed to the 800ms target interval. Was this caused by a trivial fact that the monkeys were producing the wrong interval? The data from Monkey D (Figure 1B) appear to suggest this is possible (a few intermediate intervals with the 1500ms target interval). This can be further verified by raw data from Monkey A, which is currently absent in Figure 1. Furthermore, if you use decoding on the neural activity, can you predict whether the monkeys are indeed trying to produce long intervals, in the trials in which they produce long intervals that are too short?</p><p>4) Figure 8âfigure supplement 6 shows that speed variability differed between rewarded and unrewarded trials for DMPC and caudate, but not for the thalamus. Does this contradict the implied role of the thalamus in reinforcement learning?</p><p>5) The study highlights the role of the thalamus in reward-based learning; recent studies have hypothesized that fronto-thalamic circuits are necessary for quick processing of complex task-relevant information. Given the task investigated here is also complex (associating reward size to task performance across trials), it is well possible that several areas of frontal cortex are also involved. How to link the current findings to the hypotheses of fronto-thalamic circuits?</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.55872.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) The main message of the paper is to explain the non-stationarity in the timing variance in the exploration-exploitation framework, but this is questionable. As the reward follows a specific function of timing error, the first derivative of the reward feedback could effectively guide the trial-by-trial modulation of timing behaviors. For example, a decrease in reward would signal a departure from the target interval, which can be used to guide an appropriate response in the next trial. In this case, there is no need to crank up noise with a decrease in reward, as the exploration-exploitation framework would predict. Thus, the observed changes in variance can be explained by trial-by-trial learning based on the explicit reinforcement feedback signal, without invoking the idea of random exploration as in the exploration-exploitation framework. Recent theoretical approaches to model exploration-exploitation behaviors have emphasized both random vs. directed exploration (Wilson et al., 2014), but the current study appears to assume that all exploration should be random. Considering that the task has a 1-D continuous reward function, directed exploration is well possible. This is a critical question given that the main implication of the study is about &quot;â¦the nervous system makes strategic use of exploratory varianceâ¦&quot;. In fact, the whole paper is framed as probing reinforcement-guided exploration as opposed to trial-by-trial supervised learning.</p></disp-quote><p>The reviewers are concerned that the observed behavioral effects may be due to directed (as opposed to random) exploration. We are grateful for this comment as it reveals that the emphasis we put on variability caused a serious misunderstanding of the mechanism we proposed. Our findings do not support the notion that the brain simply makes behavior noisy. Indeed, the strategy implemented by our proposed Reward Sensitive Gaussian Process (RSGP) is a combination of directed and random explorations. However, since our original manuscript failed to communicate this point, we have made several revisions throughout the revised manuscript to address this problem.</p><p>The first major revision we made was to add an entire new section and a new figure (Figure 6) where we compare our proposed RSGP model to alternative RL models. In that section, we considered two alternatives, one model that implements an RL sampling algorithm (MCMC, which is more similar to random exploration), and the other, which we refer to as the directed search (DS) model, implements the algorithm suggested by the reviewers: it compares reward in the last two trials; when reward increases, the model moves the estimate in the same direction, and when reward decreases, the model reverses direction. We have provided a detailed explanation of this model in the paper. Both models failed to capture the full gamut of behavioral observations in humans and monkeys. Here, we summarize the failure points of the DS model that was proposed by the reviewers. First, for the same level of behavioral variability and the same reward rate, the DS exhibited runaway behavior (i.e., the modelâs output could move arbitrarily far from the target interval). Second, for the subset of simulated sessions that the behavior remained stable, DS was unable to capture the long-term correlations in behavioral responses present in the data. Third, and perhaps most importantly, DS was unable to exhibit the characteristic U-shaped relationship between variability and preceding error. Therefore, the behavior cannot be explained by the DS model.</p><p>The second major revision we made was to include a new section titled âDirected versus random exploration.â In this new section, we highlighted the importance of both directed and random explorations in our own data. The point that we failed to communicate in the original manuscript was that RSGP is <italic>not</italic>â simply adjusting the variance; RSGP implements Bayesian inference over the desired interval and thus dynamically adjusts both the bias and variance. We noted this point in the original manuscript (âGPs offer a nonparametric Bayesian fit to long-term serial correlationsâ) but should have gone into further detail, which we have done in this new section. The key section added to the revised manuscript is included below for convenience:</p><p>âTo highlight the behavioral characteristics of the RSGP model, it is useful to compare its behavior to that of the MCMC and DS models. MCMC and DS can be viewed as autoregressive models whose coefficients depend on past rewards. The MCMC sets all coefficients to zero except a single trial in the past returned by the Metropolis-Hastings sampling algorithm. The DS sets all coefficients to zero except the last two that are determined based on the corresponding reward gradient and a fixed learning rate. The RSGP can also be written in terms of an autoregressive model with nonstationary reward-dependent coefficients. However, the key feature that distinguishes the RSGP is that it performs Bayesian inference over <italic>t</italic>ââ<sub>â</sub>. The covariance function (or kernel) of the Gaussian process defines the coefficients and acts as a prior for future samples. In the RSGP, the addition of a reward-sensitive kernel allows the coefficients to be updated continuously based on the presence or absence of reward. When the reward rate is high, RSGP implements a strategy that is akin to directed exploration: it increases its reliance on the prior and drives responses toward previously rewarded trials. In contrast, when the reward rate is low, the RSGP relies more on random explorations: it generates samples from a wider distribution. Therefore, RSGP strikes a balance (in the Bayesian sense) between bias (directed exploration) and variance (random exploration) as needed by the history of outcomes.â</p><p>Finally, we revised the Discussion to make sure that the importance of both directed and random explorations, as prescribed by the RSGP model, are highlighted. The revised text in the Discussion is copied here for convenience: âA key challenge in the RL literature is to distinguish between conditions in which reinforcement motivates directed versus random explorations. [â¦] Indeed, the RSGP suggests that the distinction between directed and random explorations is somewhat arbitrary, and advocates an alternative viewpoint in which the effect of reinforcement is quantified in terms of how it alters the full distribution of future responses (e.g., both the mean and variance).â</p><disp-quote content-type="editor-comment"><p>In a similar vein, the non-stationarity in the variance is caused by the reward magnitude (the specific reward function used here), not necessarily a refutation of stationarity of interval time. It has been acknowledged by the author that this is not a rejection of the interval timing model, but the paper continues to imply it in the Abstract and in the Results.</p></disp-quote><p>We respectfully disagree. Despite the assumption of stationarity in dominant models of scalar timing, motor timing is inherently non-stationary. There is a rich and extensive literature showing this nonstationarity. These fluctuations have been reported in many tasks (Weiss, Coleman and Green, 1955; Merrill and Bennett, 1956; Gilden, Thornton and Mallon, 1995) and can be relatively strong in movements (Chaisanguanthum, Shen and Sabes, 2014), reaction times (Laming, 1979), and interval timing (Chen, Ding and Kelso, 1997; Murakami et al., 2017). In fact, we do not know of any paper that has shown stationary behavior associated with time interval production from memory. Therefore, the presence of nonstationary motor timing is not controversial (even though dominant models of interval timing do not account for it).</p><p>We are not the first to report these nonstationarities, but, to our knowledge, our work is the first attempt to dissect the factors that contribute to these nonstationarities. Our results identify two contributing factors: memory drift and trial outcome. Our results do not reject scalar variability but it seeks to explain its underlying biological factors. We have revised the text in the relevant section of the Results further stressing the ubiquity of non-stationarity in memory-based motor timing tasks.</p><disp-quote content-type="editor-comment"><p>Did the subjects not use information from the first derivative of the reward to update their produced intervals? It is not even clear that how many produced intervals fell within the rewarded range, and how many were simply unrewarded. The details of the reward magnitude and the monkey's behavioural adaptations to these changes in reward need to be clarified.</p></disp-quote><p>The reviewers note that âIt is not even clear how many produced intervals fell within the rewarded range, and how many were simply unrewarded.â We apologize for not providing this information more coherently. To address this shortcoming, we have added two new sections in the Materials and methods titled âReward function for monkeys in the main taskâ and âReward function for humans in the main taskâ where we provide a detailed description of reward contingencies. For example, the section related to animals is as follows:</p><p>âThe reward was determined by a truncated triangular function of error (<italic>t</italic>ââ<italic>p</italic><sub>â</sub><italic>-t</italic>â<italic>t</italic><sub>â</sub>). [â¦] The auditory feedback was one of the computerâs default tones.â</p><p>Additionally, we highlighted some of the key points that were cause for confusion in the Results section (e.g., the use of one-up-on-down staircase procedure), as follows:</p><p>âReward was provided when the relative error, defined as <italic>e</italic>â = (<italic>t</italic>ââ<italic>p</italic>â-<italic>t</italic>ââ<italic>t</italic>â)/<italic>t</italic>ââ<italic>t</italic> wasâ within an experimentally-controlled acceptance window. On rewarded trials, the magnitude of reward decreased linearly with the size of the error. The width of the acceptance window was controlled independently for each trial type using a one-up-one-down staircase procedure (see Materials and methods) so that animals received reward on nearly half of the trials (Figure 1C, inset).â</p><disp-quote content-type="editor-comment"><p>To make the original claims of the paper hold, the authors need to clarify whether the results can be explained by simple trial-by-trial adjustments based on the first derivative of the reward function.</p></disp-quote><p>The reviewers ask that we âclarify whether the results can be explained by simple trial-by-trial adjustments based on the first derivative of the reward function.â We can think of two potential interpretations for âthe first derivative of the reward functionâ. One possible interpretation is the change of reward across preceding trials (e.g., the difference of reward in the last two trials). This is exactly the idea behind the alternative DS model that we have tested in the revised manuscript, and discussed in our response to the first major comment (above).</p><p>An alternative interpretation of âthe first derivativeâ is the derivative of the triangular function we used to determine reward magnitude. However, we doubt this is what the reviewers have in mind as this does not provide a coherent explanation of the results. First, the human experiments did not involve a triangular reward function, and yet, behavioral characteristics were similar. Second, it is impossible to infer the derivative of a function from a single sample (e.g., single trial). For example, if on a given trial, the animal receives half the maximum reward, the produced interval could be either slightly longer or slightly shorter than the target interval (due to the symmetry of the reward function), and the animal cannot know which is the case unless it relies on multiple trials (which brings us back to the first interpretation). Third, we found a systematic increase in variability even for the consecutive unrewarded trials (i.e., responses that fall outside the reward triangle) for which the derivative is zero. In sum, we think it is not possible to infer the derivative of a symmetric reward function solely based on the magnitude of the reward in a single trial, and thus the only way to rely on the reward gradient is to rely on more than one preceding trial. In the revised manuscript, we have built such a model (the DS model) and shown that it fails to capture several key features of behavior including the U-shaped relationship between variability and the preceding error. We have also explained that our proposed RSGP model implements a similar strategy but does not suffer from the shortcomings of the DS model because it integrates information on a longer timescale (more than the last two trials).</p><disp-quote content-type="editor-comment"><p>2) The human task with a probabilistic reward has not been directly compared with the monkey experiment, though both are displayed in Figure 5. Related to question 1), can the findings with probabilistic rewards suffice to rule out the possibility that the first derivative of reward feedback is the driving force for the observed variance changes?</p></disp-quote><p>In the original submission, Figure 5 showed the RSGP model fits to behavior in the main experiment â not the probabilistic reward experiment. The results for the probabilistic reward experiment was shown in Figure 4, which did not include any animal experiments. Therefore, we are unsure about which figure and what aspect of the results is being referenced.</p><p>However, we understand the more general question about whether the probabilistic reward experiment can be used to test the DS model. In our response to major comment 1, we listed the multiple reasons why the DS model cannot explain the behavioral results (e.g., does not lead to the U-shaped relationship of variability as a function of the preceding error). In addition, the directed search strategy can move in the wrong direction when the rewards are probabilistic (e.g., when a large error is rewarded by chance). As the reviewers have surmised, the probabilistic reward experiment strengthens the conclusion because the directed search, unlike RSGP, only acts on the mean and not the variance, and thus cannot fully capture the behavioral observation (Figure 5âfigure supplement 2).</p><disp-quote content-type="editor-comment"><p>3) The asymmetry of interval variance was evident for both monkeys when the target interval of 1500ms was produced (Figure 1D), but it was left unexplained. This asymmetry shows a much higher variance for the shorter intervals, i.e., skewed to the 800ms target interval. Was this caused by a trivial fact that the monkeys were producing the wrong interval? The data from Monkey D (Figure 1B) appear to suggest this is possible (a few intermediate intervals with the 1500ms target interval). This can be further verified by raw data from Monkey A, which is currently absent in Figure 1.</p></disp-quote><p>The reviewers point to an observation in Figure 1D that the interval variance was asymmetric for the 1500 ms target interval. This asymmetry is due to a number of inconsequential aspects of the data. First, the distribution of produced intervals with respect to the target 1500 ms interval was shifted to the left of the target 1500 ms (Monkey A: -11.0 ms for Eye-Long and -4.3 ms for Hand-Long; Monkey D: -45.3 ms for Eye-Long, and -11.9 ms for Hand-Long). This caused a sampling bias in the density and magnitude of errors on the two sides of the curve. Second, because of this bias, we were able to estimate the curve further out to the left of the 1500 ms (more bins on the short side), which made the curve appear more asymmetric. Third, the presence of scalar variability causes a slight skew in the distribution of produced intervals that further skews the produced interval distribution toward shorter intervals and intensifies the asymmetry. Since these details are not relevant to our main hypothesis, we removed this panel from Figure 1 and replaced it with an example behavioral session from Monkey A as requested by the reviewers.</p><p>However, as part of this comment, the reviewers express concern that perhaps monkeys made categorical mistakes between the Short and Long trial types. To address this concern, we performed a detailed analysis of the produced intervals asking whether animals mixed up between the two target intervals (âmonkeys were producing the wrong intervalâ). To do so, we applied a Gaussian mixture model (GMM) to the full distribution of produced intervals (for both 800 and 1500 ms) and asked whether any of the produced intervals were in the wrong mode with respect to the desired interval. Results indicated that the animalsâ behavior was highly stable across trials and sessions and made nearly no categorical mistake between trial conditions. We have clarified this point in the relevant section of the Results: âThere were no errors associated with using the wrong effector, and the number of errors with respect to the target interval were extremely small (~0.79% misclassified trials based on fits to a Gaussian mixture model).â</p><disp-quote content-type="editor-comment"><p>Furthermore, if you use decoding on the neural activity, can you predict whether the monkeys are indeed trying to produce long intervals, in the trials in which they produce long intervals that are too short?</p></disp-quote><p>The reviewers also asked that we use a neural classifier to determine which of the two intervals the animalsâ were aiming to produce. We generally are not in favor of this approach, which assumes that a neural classifier of behavior is a more reliable readout of behavior than the behavior itself. However, for completeness, we performed the suggested analysis. We built a classifier of interval type (Short or Long) based on population spiking data. We used the trials that were correctly classified by the GMM for training the classifier, and asked whether the trials that were misclassified by the GMM were also misclassified by the neural classifier. The performance of the classifier was at chance level (55+/-27% in the thalamus, 45+/-31% in DMFC and 60+/-23% in caudate).</p><disp-quote content-type="editor-comment"><p>4) Figure 8âfigure supplement 6 shows that speed variability differed between rewarded and unrewarded trials for DMPC and caudate, but not for the thalamus. Does this contradict the implied role of the thalamus in reinforcement learning?</p></disp-quote><p>We apologize for the lack of clarity. On the contrary, this is a direct prediction of our prior work (Wang et al., 2018). Previously, we found the neurons in the thalamus encode the desired interval by adjusting their tonic firing rate, and not by changing the speed at which firing rates changed over time. In contrast, we found that downstream neurons in DMFC and caudate were largely explained in terms of changing speed. The current results are consistent with and validate those findings.</p><p>In the original manuscript, we had provided an explanation of this point in the Discussion as follows: âMoreover, it has been shown that the nature of signals in DMFC-projecting thalamus and DMFC during motor timing are indeed different: DMFC neurons have highly heterogeneous response profiles that evolved at different speeds depending on the interval, whereas thalamic neurons carried signals whose strength (i.e., average firing rate) encoded the underlying speed.â</p><p>We then went on to explain how this previous finding explains the presence of speed effects in DMFC and not thalamus. We have clarified this in the text as follows: âAs predicted by our hypothesis, the effect of reward on neural activity in the thalamus was different from that in the DMFC and caudate. [â¦] These results further substantiate our hypothesis that reward regulates variability by adjusting the average firing rates in thalamus, and that this effect leads to the control of the variance of the speed at which neural trajectories evolve in the DMFC and caudate.â</p><disp-quote content-type="editor-comment"><p>5) The study highlights the role of the thalamus in reward-based learning; recent studies have hypothesized that fronto-thalamic circuits are necessary for quick processing of complex task-relevant information. Given the task investigated here is also complex (associating reward size to task performance across trials), it is well possible that several areas of frontal cortex are also involved. How to link the current findings to the hypotheses of fronto-thalamic circuits?</p></disp-quote><p>We may have misunderstood this comment but it appears that this point was already addressed extensively in two parts of the Discussion in the original manuscript. We have made some minor revisions to those sections with the hope that the point is now more clearly communicated. We have included these sections here for the reviewersâ convenience.</p><p>First section: âwe cannot rule out the possibility that behavioral control is mediated by other patterns of activity in the thalamus as well as DMFC. Indeed, with a complementary analysis using an unconstrained decoding approach, we were able to find patterns of activity in all three brain areas that simultaneously reflected the effects of memory drift (Figure 7) and reinforcement (Figure 8âfigure supplement 3).â</p><p>Second section: âWhile we do not know which areas might directly control motor timing variability, we note that the area of thalamus we have recorded from receives information from three major sources, the frontal cortex, the output nuclei of the basal ganglia, and the deep nuclei of the cerebellum (Middleton and Strick, 2000; Kunimatsu et al., 2018). [â¦] To act as an effective learning mechanism, such correlated variability must be additionally sensitive to reward-dependent neuromodulatory signals such as dopamine (Frank et al., 2009) possibly by acting on local inhibitory neurons (Huang et al., 2019).â</p><p>We hope that these Discussion points (which are now further revised to clarify the key points) address the reviewersâ comment.</p></body></sub-article></article>