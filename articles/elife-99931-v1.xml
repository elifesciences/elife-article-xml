<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">99931</article-id><article-id pub-id-type="doi">10.7554/eLife.99931</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.99931.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A unifying account of replay as context-driven memory reactivation</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Zhou</surname><given-names>Zhenglong</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4003-7214</contrib-id><email>zzhou34@sas.upenn.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Kahana</surname><given-names>Michael J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8122-9525</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Schapiro</surname><given-names>Anna C</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8086-0331</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00b30xv10</institution-id><institution>Department of Psychology, University of Pennsylvania</institution></institution-wrap><addr-line><named-content content-type="city">Philadelphia</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Liljeholm</surname><given-names>Mimi</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04gyf1771</institution-id><institution>University of California, Irvine</institution></institution-wrap><addr-line><named-content content-type="city">Irvine</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Colgin</surname><given-names>Laura L</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hj54h04</institution-id><institution>University of Texas at Austin</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>14</day><month>01</month><year>2026</year></pub-date><volume>13</volume><elocation-id>RP99931</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-05-29"><day>29</day><month>05</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-05-30"><day>30</day><month>05</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.03.22.533833"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-09-11"><day>11</day><month>09</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.99931.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-12-23"><day>23</day><month>12</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.99931.2"/></event></pub-history><permissions><copyright-statement>© 2024, Zhou et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Zhou et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-99931-v1.pdf"/><abstract><p>During rest and sleep, sequential neural activation patterns corresponding to awake experience re-emerge, and this replay has been shown to benefit subsequent behavior and memory. Whereas some studies show that replay directly recapitulates recent experience, others demonstrate that replay systematically deviates from the temporal structure, the statistics, and even the content of recent experience. Given these disparate characteristics, what is the nature and purpose of replay? Here, we offer a theoretical framework in which replay reflects simple context-guided processes that facilitate memory. We suggest that during awake learning, the brain associates experiences with the contexts in which they are encoded, at encoding rates that vary according to the salience of each experience. During quiescence, replay emerges as the result of a cascade of autonomous bidirectional interactions between contexts and their associated experiences, which in turn facilitates memory consolidation. A computational model instantiating this proposal explains numerous replay phenomena, including findings that existing models fail to account for and observations that have been predominantly construed through the lens of reinforcement learning. Our theory provides a unified, mechanistic framework of how the brain initially encodes and subsequently replays experiences in the service of memory consolidation.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>replay</kwd><kwd>learning and memory</kwd><kwd>computational neuroscience</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/021nxhr62</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>National Graduate Research Fellowship</award-id><principal-award-recipient><name><surname>Zhou</surname><given-names>Zhenglong</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04xeg9z08</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>R01 MH55687</award-id><principal-award-recipient><name><surname>Kahana</surname><given-names>Michael J</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04xeg9z08</institution-id><institution>National Institute of Mental Health</institution></institution-wrap></funding-source><award-id>R01 MH129436</award-id><principal-award-recipient><name><surname>Schapiro</surname><given-names>Anna C</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A context-driven memory model simulates a wide range of characteristics of waking and sleeping hippocampal replay, providing a new account of how and why replay occurs.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Sleep and rest are crucial for learning and memory (<xref ref-type="bibr" rid="bib59">Klinzing et al., 2019</xref>; <xref ref-type="bibr" rid="bib122">Walker and Stickgold, 2004</xref>; <xref ref-type="bibr" rid="bib123">Wamsley, 2019</xref>). A candidate mechanism facilitating these benefits is replay – the offline re-emergence of neural activity associated with awake experience. Over the past several decades, the field of neuroscience has accumulated extensive evidence of replay (<xref ref-type="bibr" rid="bib36">Foster, 2017</xref>; <xref ref-type="bibr" rid="bib68">Liu et al., 2022</xref>; <xref ref-type="bibr" rid="bib90">Ólafsdóttir et al., 2018</xref>; <xref ref-type="bibr" rid="bib109">Sheridan et al., 2024</xref>) and increasing evidence of its utility to behavior (<xref ref-type="bibr" rid="bib30">Dupret et al., 2010</xref>; <xref ref-type="bibr" rid="bib32">Ego-Stengel and Wilson, 2010</xref>; <xref ref-type="bibr" rid="bib66">Liu et al., 2021</xref>; <xref ref-type="bibr" rid="bib38">Girardeau et al., 2009</xref>; <xref ref-type="bibr" rid="bib50">Jadhav et al., 2012</xref>). It is challenging, however, to characterize the principles and functions of replay, because it exhibits disparate characteristics across states and task contexts that are difficult to synthesize under one framework. Early studies showed that replay preserves the correlational structure and the temporal structure of multi-cell spiking patterns that underlie awake experiences (<xref ref-type="bibr" rid="bib127">Wilson and McNaughton, 1994</xref>; <xref ref-type="bibr" rid="bib114">Skaggs and McNaughton, 1996</xref>; <xref ref-type="bibr" rid="bib86">Nádasdy et al., 1999</xref>). Most canonically, the firing of sequences of hippocampal place cells corresponding to traversals through an environment re-emerges with the same sequential firing during rest and sleep. Subsequent studies, however, demonstrated that replay deviates from the temporal structure, statistics, and content of recent experience in myriad ways: Replay activates never-experienced novel trajectories (<xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>), over-represents salient experiences (<xref ref-type="bibr" rid="bib112">Singer and Frank, 2009</xref>; <xref ref-type="bibr" rid="bib88">Ólafsdóttir et al., 2015</xref>; <xref ref-type="bibr" rid="bib131">Wu et al., 2017</xref>), unrolls in the reverse order of a behavioral sequence when an animal consumes reward (<xref ref-type="bibr" rid="bib2">Ambrose et al., 2016</xref>; <xref ref-type="bibr" rid="bib35">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="bib65">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="bib84">Michon et al., 2019</xref>), and sometimes exhibits a bias away from recently experienced trajectories (<xref ref-type="bibr" rid="bib16">Carey et al., 2019</xref>; <xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>). These observations illustrate that replay is not a simple, direct recapitulation of awake experience.</p><p>An influential explanation for why replay exhibits distinctive properties, especially in the presence of reward, is that replay is for learning value predictions in the manner of reinforcement learning (RL) models (<xref ref-type="bibr" rid="bib2">Ambrose et al., 2016</xref>; <xref ref-type="bibr" rid="bib35">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="bib66">Liu et al., 2021</xref>; <xref ref-type="bibr" rid="bib77">Mattar and Daw, 2018</xref>; <xref ref-type="bibr" rid="bib85">Momennejad et al., 2018</xref>). According to this perspective, adaptive behavior depends on identifying actions that lead to rewarding outcomes, which requires predicting the downstream value of actions (i.e. eventual punishment or reward). This perspective argues that replay reactivates memories to update these predictions. For example, many speculate that reverse replay implements a classic method for updating value predictions, which is to propagate information backward from a reward through experienced trajectories to update upstream actions’ value predictions (<xref ref-type="bibr" rid="bib118">Sutton, 1988</xref>). A recent theory extending this perspective (<xref ref-type="bibr" rid="bib77">Mattar and Daw, 2018</xref>) argues that a range of other replay characteristics (<xref ref-type="bibr" rid="bib2">Ambrose et al., 2016</xref>; <xref ref-type="bibr" rid="bib18">Cheng and Frank, 2008</xref>; <xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>; <xref ref-type="bibr" rid="bib131">Wu et al., 2017</xref>; <xref ref-type="bibr" rid="bib88">Ólafsdóttir et al., 2015</xref>) can be explained by assuming that replay prioritizes updates that will most improve future behavior. The model assumes that replay knows in advance which updates will best improve behavior, defined by a quantity called the expected value of backup (EVB). When replay progresses from updates that improve future behavior the most to the least (i.e. highest to lowest EVB), it produces patterns that match a number of empirically observed phenomena. However, knowing the behavioral consequence of replay before it is performed is implausible, and the model makes predictions that are inconsistent with empirical data, including the prediction that replay always prioritizes updates relevant to the present goal (<xref ref-type="bibr" rid="bib16">Carey et al., 2019</xref>; <xref ref-type="bibr" rid="bib37">Gillespie et al., 2021</xref>; <xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>) and that learning reduces the rate of backward more than forward replay (<xref ref-type="bibr" rid="bib49">Igata et al., 2021</xref>; <xref ref-type="bibr" rid="bib111">Shin et al., 2019</xref>). Thus, this RL perspective is unlikely to provide a complete account of the characteristics of replay.</p><p>We offer an alternative theoretical account in which replay reflects simple context-guided memory processes. We hypothesize that, during awake learning, the brain sequentially associates experiences with the contexts in which they are encoded, in a manner modulated by the salience of each experience (more rapid association for more salient experiences). During quiescence – both awake rest periods and sleep, replay arises as the result of a cascade of bidirectional interactions between contexts and their associated experiences. The offline brain continues to learn from this replay, updating associations between reactivated memories and contexts. In this account, replay does not compute the utility of memories for learning value predictions, nor does it track value predictions. Instead, replay arises naturally from a memory-based mechanism operating bidirectionally between contexts and their associated experiences.</p><p>We show that an instantiation of this account – a computational model that builds on established context-based memory encoding and retrieval mechanisms (<xref ref-type="bibr" rid="bib47">Howard and Kahana, 2002</xref>; <xref ref-type="bibr" rid="bib97">Polyn et al., 2009</xref>) – unifies numerous replay phenomena. These include replay patterns often presumed to involve RL computations and findings that existing models do not account for. We focus on the model as a formulation of hippocampal replay, capturing how the hippocampus may replay past experiences through simple and interpretable mechanisms. First, the content and structure of replay sequences in the model vary according to states and task contexts in ways that mirror empirical observations (<xref ref-type="bibr" rid="bib10">Bendor and Wilson, 2012</xref>; <xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>; <xref ref-type="bibr" rid="bib35">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="bib125">Wikenheiser and Redish, 2013</xref>). Second, the model captures prominent effects of reward on replay (<xref ref-type="bibr" rid="bib2">Ambrose et al., 2016</xref>; <xref ref-type="bibr" rid="bib112">Singer and Frank, 2009</xref>; <xref ref-type="bibr" rid="bib88">Ólafsdóttir et al., 2015</xref>) despite not tracking value predictions. Third, in line with a number of findings (<xref ref-type="bibr" rid="bib8">Barron et al., 2020</xref>; <xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>; <xref ref-type="bibr" rid="bib56">Karlsson and Frank, 2009</xref>; <xref ref-type="bibr" rid="bib65">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="bib129">Wimmer et al., 2023</xref>), replay is not restricted to direct recent experience: The model reactivates non-local and never-experienced novel trajectories. Moreover, the model captures a range of experience-dependent replay characteristics (<xref ref-type="bibr" rid="bib11">Berners-Lee et al., 2022</xref>; <xref ref-type="bibr" rid="bib16">Carey et al., 2019</xref>; <xref ref-type="bibr" rid="bib18">Cheng and Frank, 2008</xref>; <xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>; <xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>; <xref ref-type="bibr" rid="bib49">Igata et al., 2021</xref>; <xref ref-type="bibr" rid="bib56">Karlsson and Frank, 2009</xref>; <xref ref-type="bibr" rid="bib111">Shin et al., 2019</xref>). Finally, replay benefits memory consolidation in ways that align with prior observations and theories (<xref ref-type="bibr" rid="bib13">Born and Wilhelm, 2012</xref>; <xref ref-type="bibr" rid="bib17">Carr et al., 2011</xref>; <xref ref-type="bibr" rid="bib58">King et al., 2017</xref>; <xref ref-type="bibr" rid="bib66">Liu et al., 2021</xref>; <xref ref-type="bibr" rid="bib84">Michon et al., 2019</xref>; <xref ref-type="bibr" rid="bib95">Payne and Kensinger, 2010</xref>; <xref ref-type="bibr" rid="bib94">Payne et al., 2008</xref>). As a whole, our framework provides a general, mechanistic account of how the hippocampus initially encodes and subsequently reactivates experiences in the service of memory consolidation.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>A context model of memory replay</title><p>Our proposed model builds on memory encoding and retrieval mechanisms established in retrieved-context models of memory, as exemplified in the context maintenance and retrieval model (CMR; <xref ref-type="bibr" rid="bib47">Howard and Kahana, 2002</xref>; <xref ref-type="bibr" rid="bib97">Polyn et al., 2009</xref>). We refer to the model as CMR-replay (<xref ref-type="fig" rid="fig1">Figure 1b</xref>). We begin with an overview of the model architecture, followed by illustrations of awake learning and replay in the model by considering how it encodes and reactivates sequences of items (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). We provide a detailed walk-through of operations in the model in Methods.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>CMR-replay.</title><p>(<bold>a</bold>) Consider a task of encoding a sequence consisting of four items, each denoted by a shade of blue. (<bold>b</bold>) We propose a model of replay that builds on the CMR, which we refer to as CMR-replay. The model consists of four components: item (<inline-formula><alternatives><mml:math id="inf1"><mml:mi>f</mml:mi></mml:math><tex-math id="inft1">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula>), context (<inline-formula><alternatives><mml:math id="inf2"><mml:mi>c</mml:mi></mml:math><tex-math id="inft2">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula>), item-to-context associations (<inline-formula><alternatives><mml:math id="inf3"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft3">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula>), and context-to-item associations (<inline-formula><alternatives><mml:math id="inf4"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft4">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula>). At each timestep during awake encoding, <inline-formula><alternatives><mml:math id="inf5"><mml:mi>f</mml:mi></mml:math><tex-math id="inft5">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula> represents the current item and <inline-formula><alternatives><mml:math id="inf6"><mml:mi>c</mml:mi></mml:math><tex-math id="inft6">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula> is a recency-weighted average of associated contexts of past and present items. CMR-replay associates <inline-formula><alternatives><mml:math id="inf7"><mml:mi>f</mml:mi></mml:math><tex-math id="inft7">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf8"><mml:mi>c</mml:mi></mml:math><tex-math id="inft8">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula> at each timestep, updating <inline-formula><alternatives><mml:math id="inf9"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft9">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf10"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft10">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> according to a Hebbian learning rule. <inline-formula><alternatives><mml:math id="inf11"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft11">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf12"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft12">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula>, respectively, support the retrieval of an item’s associated context and a context’s associated items. During replay, <inline-formula><alternatives><mml:math id="inf13"><mml:mi>f</mml:mi></mml:math><tex-math id="inft13">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula> represents the current reactivated item, and <inline-formula><alternatives><mml:math id="inf14"><mml:mi>c</mml:mi></mml:math><tex-math id="inft14">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula> is a drifting context representing a recency-weighted average of associated contexts of past and present reactivated items. Here, too, the model updates <inline-formula><alternatives><mml:math id="inf15"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft15">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf16"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft16">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> to associate reactivated <inline-formula><alternatives><mml:math id="inf17"><mml:mi>f</mml:mi></mml:math><tex-math id="inft17">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf18"><mml:mi>c</mml:mi></mml:math><tex-math id="inft18">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula>. The figure illustrates the representations of <inline-formula><alternatives><mml:math id="inf19"><mml:mi>f</mml:mi></mml:math><tex-math id="inft19">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf20"><mml:mi>c</mml:mi></mml:math><tex-math id="inft20">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula>,<inline-formula><alternatives><mml:math id="inf21"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft21">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf22"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft22">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> as the model encodes the third item during learning. Lengths of color bars in <inline-formula><alternatives><mml:math id="inf23"><mml:mi>f</mml:mi></mml:math><tex-math id="inft23">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf24"><mml:mi>c</mml:mi></mml:math><tex-math id="inft24">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula> represent relative magnitudes of different features. Shades of gray illustrate the weights in <inline-formula><alternatives><mml:math id="inf25"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft25">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf26"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft26">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula>. Orange features represent task-irrelevant items, which do not appear as inputs during awake encoding but compete with task-relevant items for reactivation during replay. (<bold>c</bold>) During both awake encoding and replay, context <inline-formula><alternatives><mml:math id="inf27"><mml:mi>c</mml:mi></mml:math><tex-math id="inft27">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula> drifts by incorporating the current item <inline-formula><alternatives><mml:math id="inf28"><mml:mi>f</mml:mi></mml:math><tex-math id="inft28">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula>’s associated context <inline-formula><alternatives><mml:math id="inf29"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft29">\begin{document}$c_{f}$\end{document}</tex-math></alternatives></inline-formula> and downweighting previous items’ associated contexts. The figure illustrates how context drifts during the first time the model encodes the example sequence. (<bold>d</bold>) The figure illustrates <inline-formula><alternatives><mml:math id="inf30"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft30">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf31"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft31">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> updates as the model encodes the third item during the first presentation of the sequence. (<bold>e</bold>) Consider the activation of items at the onset of sleep and awake rest across sessions of learning. At replay onset, an initial probability distribution across items <inline-formula><alternatives><mml:math id="inf32"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft32">\begin{document}$a_{0}$\end{document}</tex-math></alternatives></inline-formula> varies according to the behavioral state (i.e. awake, rest, or sleep). Compared to sleep, during awake rest, <inline-formula><alternatives><mml:math id="inf33"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft33">\begin{document}$a_{0}$\end{document}</tex-math></alternatives></inline-formula> is strongly biased toward features associated with external inputs during awake rest. For awake rest, the figure shows an example of <inline-formula><alternatives><mml:math id="inf34"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft34">\begin{document}$a_{0}$\end{document}</tex-math></alternatives></inline-formula> when the model receives a context cue related to the fourth item. Through repeated exposure to the same task sequence across sessions of learning, activities of the four task-related items (i.e. blue items) become suppressed in <inline-formula><alternatives><mml:math id="inf35"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft35">\begin{document}$a_{0}$\end{document}</tex-math></alternatives></inline-formula> relative to task-irrelevant items (i.e. orange items). (<bold>f</bold>) Each replay period begins by sampling an item <inline-formula><alternatives><mml:math id="inf36"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft36">\begin{document}$f_{t=0}$\end{document}</tex-math></alternatives></inline-formula> according to <inline-formula><alternatives><mml:math id="inf37"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft37">\begin{document}$a_{0}$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf38"><mml:mi>t</mml:mi></mml:math><tex-math id="inft38">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula> denotes the current timestep. If <inline-formula><alternatives><mml:math id="inf39"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft39">\begin{document}$f_{t=0}$\end{document}</tex-math></alternatives></inline-formula> is a task-related item, its associated context <inline-formula><alternatives><mml:math id="inf40"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft40">\begin{document}$c_{f_{t=0}}$\end{document}</tex-math></alternatives></inline-formula> is reinstated as <inline-formula><alternatives><mml:math id="inf41"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft41">\begin{document}$c_{0}$\end{document}</tex-math></alternatives></inline-formula> to enter a recursive process. During this process, at each timestep <inline-formula><alternatives><mml:math id="inf42"><mml:mi>t</mml:mi><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:math><tex-math id="inft42">\begin{document}$t\geq 1$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf43"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft43">\begin{document}$c_{t-1}$\end{document}</tex-math></alternatives></inline-formula> evokes a probability distribution <inline-formula><alternatives><mml:math id="inf44"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft44">\begin{document}$a_{t}$\end{document}</tex-math></alternatives></inline-formula> that excludes previously reactivated items. Given <inline-formula><alternatives><mml:math id="inf45"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft45">\begin{document}$a_{t}$\end{document}</tex-math></alternatives></inline-formula>, the model samples an item <inline-formula><alternatives><mml:math id="inf46"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft46">\begin{document}$f_{t}$\end{document}</tex-math></alternatives></inline-formula> and reinstates <inline-formula><alternatives><mml:math id="inf47"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft47">\begin{document}$f_{t}$\end{document}</tex-math></alternatives></inline-formula>’s associated context <inline-formula><alternatives><mml:math id="inf48"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft48">\begin{document}$c_{f_{t}}$\end{document}</tex-math></alternatives></inline-formula>, which is combined with <inline-formula><alternatives><mml:math id="inf49"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft49">\begin{document}$c_{t-1}$\end{document}</tex-math></alternatives></inline-formula> to form a new context <inline-formula><alternatives><mml:math id="inf50"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft50">\begin{document}$c_{t}$\end{document}</tex-math></alternatives></inline-formula> to guide the ensuing reactivation. The dashed arrow indicates that <inline-formula><alternatives><mml:math id="inf51"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft51">\begin{document}$c_{t}$\end{document}</tex-math></alternatives></inline-formula> becomes <inline-formula><alternatives><mml:math id="inf52"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft52">\begin{document}$c_{t-1}$\end{document}</tex-math></alternatives></inline-formula> for the next timestep. At any <inline-formula><alternatives><mml:math id="inf53"><mml:mi>t</mml:mi></mml:math><tex-math id="inft53">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula>, the replay period ends with a probability of 0.1 or if a task-irrelevant item is reactivated.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99931-fig1-v1.tif"/></fig><p>CMR-replay comprises four elements (<xref ref-type="fig" rid="fig1">Figure 1b</xref>): item (<inline-formula><alternatives><mml:math id="inf54"><mml:mi>f</mml:mi></mml:math><tex-math id="inft54">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula>), context (<inline-formula><alternatives><mml:math id="inf55"><mml:mi>c</mml:mi></mml:math><tex-math id="inft55">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula>), item-to-context associations (<inline-formula><alternatives><mml:math id="inf56"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft56">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula>), and context-to-item associations (<inline-formula><alternatives><mml:math id="inf57"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft57">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula>). The values of the elements of the <inline-formula><alternatives><mml:math id="inf58"><mml:mi>f</mml:mi></mml:math><tex-math id="inft58">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf59"><mml:mi>c</mml:mi></mml:math><tex-math id="inft59">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula> vectors can be considered to correspond abstractly to the firing rate of a neuron or population of neurons, and the values of <inline-formula><alternatives><mml:math id="inf60"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft60">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf61"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft61">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> to the strength of synaptic connections between those neurons. Prior to learning, distinct items (<inline-formula><alternatives><mml:math id="inf62"><mml:mi>f</mml:mi></mml:math><tex-math id="inft62">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula>) are associated with orthogonal context features. As CMR-replay encodes (during awake learning) or reactivates (during replay) a sequence of items, <inline-formula><alternatives><mml:math id="inf63"><mml:mi>f</mml:mi></mml:math><tex-math id="inft63">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula> represents the current item, whereas a drifting context (<inline-formula><alternatives><mml:math id="inf64"><mml:mi>c</mml:mi></mml:math><tex-math id="inft64">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula>) maintains a receding history of present and past items’ associated contexts (<xref ref-type="fig" rid="fig1">Figure 1c</xref>), which resets before the model encodes each sequence. We represent the drifting context during learning and replay with <inline-formula><alternatives><mml:math id="inf65"><mml:mi>c</mml:mi></mml:math><tex-math id="inft65">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula> and an item’s associated context with <inline-formula><alternatives><mml:math id="inf66"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft66">\begin{document}$c_{f}$\end{document}</tex-math></alternatives></inline-formula>. During both awake learning and replay, CMR-replay associates each item with the current drifting context by updating bidirectional associations between them – item-to-context associations (<inline-formula><alternatives><mml:math id="inf67"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft67">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula>), which map each item to its associated context, and context-to-item associations (<inline-formula><alternatives><mml:math id="inf68"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft68">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula>), which map each context to associated items. Prior to learning, these associations are fully orthogonal: <inline-formula><alternatives><mml:math id="inf69"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft69">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> maps each item to a distinct context and <inline-formula><alternatives><mml:math id="inf70"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft70">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> maps each context feature to a distinct item.</p><p>During awake encoding of a sequence of items, for each item <inline-formula><alternatives><mml:math id="inf71"><mml:mi>f</mml:mi></mml:math><tex-math id="inft71">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula>, the model retrieves its associated context <inline-formula><alternatives><mml:math id="inf72"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft72">\begin{document}$c_{f}$\end{document}</tex-math></alternatives></inline-formula> via <inline-formula><alternatives><mml:math id="inf73"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft73">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula>. The drifting context <inline-formula><alternatives><mml:math id="inf74"><mml:mi>c</mml:mi></mml:math><tex-math id="inft74">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula> incorporates the item’s associated context <inline-formula><alternatives><mml:math id="inf75"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft75">\begin{document}$c_{f}$\end{document}</tex-math></alternatives></inline-formula> and downweights its representation of previous items’ associated contexts (<xref ref-type="fig" rid="fig1">Figure 1c</xref>). Thus, the context layer maintains a recency-weighted sum of past and present items’ associated contexts. To perform encoding, CMR-replay updates <inline-formula><alternatives><mml:math id="inf76"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft76">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf77"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft77">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> to strengthen associations between the current item and context (<xref ref-type="fig" rid="fig1">Figure 1d</xref>). The <inline-formula><alternatives><mml:math id="inf78"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft78">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> update adds the current context to the context associated with the item. Because the current context contains contexts associated with previous items, through the <inline-formula><alternatives><mml:math id="inf79"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft79">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> update, the context associated with the item starts to reflect contexts of prior items. For the same reason, through the <inline-formula><alternatives><mml:math id="inf80"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft80">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> update, <inline-formula><alternatives><mml:math id="inf81"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft81">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> learns to map contexts associated with previous items to the current item.</p><p>Building on prior work (<xref ref-type="bibr" rid="bib19">Cohen and Kahana, 2022</xref>; <xref ref-type="bibr" rid="bib119">Talmi et al., 2019</xref>), CMR-replay embraces the simplifying assumption that the salience of each item influences its rate of encoding (i.e. the learning rates at which the model updates <inline-formula><alternatives><mml:math id="inf82"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft82">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf83"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft83">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula>). In particular, the model updates <inline-formula><alternatives><mml:math id="inf84"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft84">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf85"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft85">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> at faster rates for salient items, including those that are novel and rewarding (see Methods), than for others. Higher encoding rates allow salient items to form associations with their encoding contexts more rapidly. In CMR-replay, salience modifies encoding rates only for the current item and context; it does not modify encoding rates for the items that lead up to the salient item.</p><p>During replay, the model generates a cascade of item and context reactivations by operating bidirectionally on <inline-formula><alternatives><mml:math id="inf86"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft86">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf87"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft87">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula>. This process begins with an initial item reactivation. At the onset of each replay period, the model selects this item from an activity distribution that reflects spontaneous activity during awake rest or sleep (<xref ref-type="fig" rid="fig1">Figure 1e</xref>). To capture the near absence of external sensory information during sleep, we initialized this distribution with random activity across all items at sleep onset. In simulations of awake rest, in contrast, we present a cue that represents the external sensory context of where the model is ‘resting’. This cue evokes activities that bias the distribution toward this resting location. As a result, awake replay exhibits an initiation bias – a tendency to initiate at the item most strongly associated with the cue.</p><p>Once CMR-replay reactivates an initial item, this triggers a sequence of autonomous reactivation (<xref ref-type="fig" rid="fig1">Figure 1f</xref>). As in awake encoding, during replay, the model maintains a drifting context – a recency-weighted average of past and present reactivated items’ associated contexts. At each timestep, using the current context as a cue, the model evokes a distribution of activities across items via <inline-formula><alternatives><mml:math id="inf88"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft88">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula>. The model converts these activities into a probability distribution and samples another item without replacement (i.e. by excluding previously reactivated items). This mechanism of sampling without replacement, akin to response suppression in established context memory models (<xref ref-type="bibr" rid="bib47">Howard and Kahana, 2002</xref>), could be implemented by neuronal fatigue or refractory dynamics (<xref ref-type="bibr" rid="bib14">Burgess, 1992</xref>; <xref ref-type="bibr" rid="bib41">Grossberg, 1978</xref>). Non-repetition during reactivation is also a common assumption in replay models that regulate reactivation through inhibition or prioritization (<xref ref-type="bibr" rid="bib28">Diekmann and Cheng, 2023</xref>; <xref ref-type="bibr" rid="bib77">Mattar and Daw, 2018</xref>; <xref ref-type="bibr" rid="bib113">Singh et al., 2022</xref>). In accordance with awake encoding, the model updates context by incorporating the newly reactivated item’s associated context and updates <inline-formula><alternatives><mml:math id="inf89"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft89">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf90"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft90">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> to associate the reactivated item with the updated context, albeit at much slower rates. The updated context then guides item reactivation at the next timestep. At each timestep, a replay event ends with a constant probability or if a task-irrelevant item becomes reactivated.</p><p>In the model, replay tends to preserve the temporal contiguity of awake experience, such that each reactivated item tends to be followed by the item that was encoded immediately after or before it (Figure 6d, left). During awake encoding, because of the way context incrementally drifts, the encoding contexts for adjacent items are more similar than for items that are far apart, except when a distractor intervenes between two adjacent items to demarcate an event boundary. During replay, when the model retrieves a reactivated item’s associated context to guide the next reactivation, it will then favor the reactivation of items that immediately preceded or followed the current item during awake encoding (Figure 6d, left). This behavior is referred to as the model’s contiguity bias, which allows replay to generate coherent sequences despite its stochasticity. Its contiguity bias stems from its use of shared, temporally autocorrelated context to link successive items, despite the orthogonal nature of individual item representations. This bias would be even stronger if items had overlapping representations, as observed in place fields. Following prior work (<xref ref-type="bibr" rid="bib77">Mattar and Daw, 2018</xref>), we consider replay events to be replayed sequences (one per replay period) with consecutive segments of length five or greater that preserve the contiguity of the awake sequence.</p><p>In memory models that reactivate memories for offline learning (<xref ref-type="bibr" rid="bib4">Ans and Rousset, 2000</xref>; <xref ref-type="bibr" rid="bib82">Meeter, 2003</xref>; <xref ref-type="bibr" rid="bib87">Norman et al., 2005</xref>), a common issue is that the most well-learned items are rehearsed most often, leading to additional strengthening of these items, leading in turn to even more rehearsal, and so on. CMRs can exhibit this same rich-get-richer phenomenon. The solution in prior models has been to incorporate a mechanism that balances rehearsal across items (<xref ref-type="bibr" rid="bib82">Meeter, 2003</xref>; <xref ref-type="bibr" rid="bib87">Norman et al., 2005</xref>; <xref ref-type="bibr" rid="bib113">Singh et al., 2022</xref>). CMR-replay has such a mechanism as well, which increasingly downweights task-related items at the onset of replay through repetition in the same task. This process downweights items according to the activity of their retrieved contexts in the preceding awake encoding period. As CMR-replay repeatedly strengthens weights for a sequence of items, the probability that replay begins with its constituent items decreases, allowing alternative items that received less exposure to participate in replay (<xref ref-type="fig" rid="fig1">Figure 1e</xref>). The proposal that a suppression mechanism plays a role in replay aligns with models that regulate place cell reactivation via inhibition (<xref ref-type="bibr" rid="bib73">Malerba et al., 2016</xref>) and with empirical observations of increased hippocampal inhibitory interneuron activity with experience (<xref ref-type="bibr" rid="bib11">Berners-Lee et al., 2022</xref>). Our model assumes the presence of such inhibitory mechanisms but does not explicitly model them. There are multiple possibilities for how a biological process may implement something like our suppression mechanism (<xref ref-type="bibr" rid="bib44">Hasselmo et al., 1996</xref>). Though more empirical investigation is needed to determine the implementation, the need across theoretical perspectives for some form of balancing mechanism motivates the strong prediction that some biological mechanism like this must be at work.</p><p>We simulate awake learning in a number of tasks (<xref ref-type="bibr" rid="bib2">Ambrose et al., 2016</xref>; <xref ref-type="bibr" rid="bib10">Bendor and Wilson, 2012</xref>; <xref ref-type="bibr" rid="bib16">Carey et al., 2019</xref>; <xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>; <xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>; <xref ref-type="bibr" rid="bib65">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="bib66">Liu et al., 2021</xref>; <xref ref-type="bibr" rid="bib88">Ólafsdóttir et al., 2015</xref>) by exposing the model to sequences of items that correspond to trajectories of spatial locations or visual stimuli as experienced by animals in the experiments. In between sessions of wake learning, we simulate quiescence (both awake rest and sleep) as periods of autonomous reactivation. Our objective is to examine whether CMR-replay can capture qualitative aspects of existing replay phenomena, rather than to provide a quantitative fit to the data. Unlike prior work that finds different best-fitting parameters across simulations (<xref ref-type="bibr" rid="bib97">Polyn et al., 2009</xref>; <xref ref-type="bibr" rid="bib70">Lohnas et al., 2015</xref>; <xref ref-type="bibr" rid="bib19">Cohen and Kahana, 2022</xref>), CMR-replay employs one set of model parameters across all simulations. In the following sections, we show that the model accounts for a diverse range of empirical phenomena, including context-dependent variations of replay (Figure 2), effects of reward on replay (Figure 3), replay patterns that go beyond direct recent experience (Figure 4), experience-dependent variations of replay (Figure 5), and ways in which replay facilitates memory (Figure 6).</p></sec><sec id="s2-2"><title>The context dependency of memory replay</title><p>During quiescence, sequential neural firing during sharp-wave ripples (SWRs) recapitulates the temporal pattern of previous waking experience (<xref ref-type="bibr" rid="bib36">Foster, 2017</xref>). We distinguish between forward and backward replay, defined as neural activity that either preserves the order of a prior experience (forward replay) or reverses it (backward replay). In animals and humans, the content and directionality of replay systematically vary according to task contexts and behavioral states (<xref ref-type="bibr" rid="bib10">Bendor and Wilson, 2012</xref>; <xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>; <xref ref-type="bibr" rid="bib65">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="bib125">Wikenheiser and Redish, 2013</xref>). For example, animals tend to shift from forward to backward replay from the beginning to the end of a run (<xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>), exhibit more forward replay during sleep (<xref ref-type="bibr" rid="bib125">Wikenheiser and Redish, 2013</xref>), and show biased replay of memories associated with external cues during sleep (<xref ref-type="bibr" rid="bib10">Bendor and Wilson, 2012</xref>). Some of these observations have led investigators to posit distinct processes underlying forward and backward replay (<xref ref-type="bibr" rid="bib60">Koene and Hasselmo, 2008</xref>; <xref ref-type="bibr" rid="bib2">Ambrose et al., 2016</xref>; <xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>; <xref ref-type="bibr" rid="bib36">Foster, 2017</xref>; <xref ref-type="bibr" rid="bib35">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="bib57">Khamassi and Girard, 2020</xref>; <xref ref-type="bibr" rid="bib77">Mattar and Daw, 2018</xref>; <xref ref-type="bibr" rid="bib111">Shin et al., 2019</xref>), with forward replay supporting planning at choice points (<xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>; <xref ref-type="bibr" rid="bib36">Foster, 2017</xref>; <xref ref-type="bibr" rid="bib77">Mattar and Daw, 2018</xref>; <xref ref-type="bibr" rid="bib111">Shin et al., 2019</xref>) and backward replay encoding value expectations from reward outcomes (<xref ref-type="bibr" rid="bib2">Ambrose et al., 2016</xref>; <xref ref-type="bibr" rid="bib36">Foster, 2017</xref>; <xref ref-type="bibr" rid="bib35">Foster and Wilson, 2006</xref>). Here, we evaluate whether CMR-replay can account for these differential patterns under one framework, with replay always reflecting associations between items and contexts.</p><p>Animals first acquire experience with a linear track by traversing it to collect a reward. Then, during the pre-run rest recording, forward replay predominates (<xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>). In contrast, backward replay predominates during post-run rest, when the animal consumes its reward (see <xref ref-type="fig" rid="fig2">Figure 2a</xref>, left; <xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>). We simulated this task by presenting CMR-replay with a sequence of items (Figure 7a), each representing a distinct location. These item representations can be considered to correspond to place cells in rodents, whose activity is typically used to track replay. During post-run rest, we use the final item’s encoding context as an external cue for rest replay. For pre-run rest, the first item’s encoding context serves as the external cue for rest replay. Because of the external cue, awake rest replay initiates disproportionately at the item most strongly associated with the cue (<xref ref-type="fig" rid="fig1">Figure 1e</xref>), which is consistent with a bias of awake replay to initiate at the resting location (<xref ref-type="bibr" rid="bib22">Davidson et al., 2009</xref>). The conjunction of this initiation bias and the model’s contiguity bias entails that replay tends to unroll successively forward from the first item in pre-run rest and backward from the final item in post-run rest (<xref ref-type="fig" rid="fig2">Figure 2a</xref>, right) as in the data (<xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>). In our model, these patterns are identical to those in our simulation of <xref ref-type="bibr" rid="bib2">Ambrose et al., 2016</xref>, which uses two independent sequences to mimic the two run directions. This is because the drifting context resets before each run sequence is encoded, with the pause between runs acting as an event boundary that prevents the final item of one traversal from associating with the first item of the next, thereby keeping learning in each direction independent. In contrast to the EVB model (<xref ref-type="bibr" rid="bib77">Mattar and Daw, 2018</xref>), CMR-replay captures the graded nature of this phenomenon (<xref ref-type="fig" rid="fig2">Figure 2a</xref>, right): forward and backward replay appear in both conditions (<xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>). All of the differences between conditions observed here, and across all simulations in the paper, are highly reliable (p&lt;0.001 based on two-tailed t-tests, with runs of the model as random effects factor). Levels of significance are indicated in figures.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Context-dependent variations in memory replay.</title><p>(<bold>a</bold>) As observed in rodents (left), replay in CMR-replay (right) is predominantly forward at the start of a run and backward at the end of a run on a linear track. (<bold>b</bold>) Consistent with rodent data (left), in CMR-replay (right), the proportion of forward replay is higher during sleep than during awake rest. (<bold>c</bold>) The presence of external cues during sleep biases replay toward their associated memories both in animals (left) and in CMR-replay (right). Error bars represent ±1 standard error of the mean. *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001. Left image in a adapted from <xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>, Nature Publishing Group; left image in<bold> b</bold> adapted from <xref ref-type="bibr" rid="bib125">Wikenheiser and Redish, 2013</xref>, Wiley.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99931-fig2-v1.tif"/><permissions><copyright-statement>© 2007, Diba and Buzsáki</copyright-statement><copyright-year>2007</copyright-year><copyright-holder>Diba and Buzsáki</copyright-holder><license><ali:license_ref>https://creativecommons.org/licenses/by-nc/4.0/</ali:license_ref><license-p>Panel A was reprinted with permission from Figure 1 of <xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>, which was published under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC</ext-link> license. Further reproductions must adhere to the terms of this license</license-p></license></permissions></fig><p>As with prior retrieved context models (<xref ref-type="bibr" rid="bib47">Howard and Kahana, 2002</xref>; <xref ref-type="bibr" rid="bib97">Polyn et al., 2009</xref>), CMR-replay encodes stronger forward than backward associations. This asymmetry exists because, during the first encoding of a sequence, an item’s associated context contributes only to its ensuing items’ encoding contexts. Therefore, after encoding, bringing back an item’s associated context is more likely to reactivate its ensuing than preceding items, leading to forward asymmetric replay (Figure 6d, left). Absent external cues, sleep replay is less likely to initiate at the final item than rest replay (<xref ref-type="fig" rid="fig1">Figure 1e</xref>), allowing for more forward transitions. This leads to more forward replay during sleep than awake rest (<xref ref-type="fig" rid="fig2">Figure 2b</xref>, right), matching empirical observations (<xref ref-type="bibr" rid="bib36">Foster, 2017</xref>; <xref ref-type="bibr" rid="bib62">Lee and Wilson, 2002</xref>; <xref ref-type="bibr" rid="bib125">Wikenheiser and Redish, 2013</xref>; <xref ref-type="fig" rid="fig2">Figure 2b</xref>, left). In contrast, the EVB model predicts a predominance of reverse replay before behavior stabilizes (<xref ref-type="bibr" rid="bib77">Mattar and Daw, 2018</xref>). Note that the overall proportion of forward replay is higher in the model than these data, but consistent with that found in <xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>. Our model also predicts that deliberation on a specific memory, such as during planning, could serve to elicit an internal context cue that biases replay: actively recalling the first item of a sequence may favor forward replay, while thinking about the last item may promote backward replay, even when the individual is physically distant from the track. While not explored here, this mechanism presents a potential avenue for future modeling and empirical work.</p><p>We next asked whether CMR-replay can simulate targeted memory reactivation (TMR) – the re-presentation of learning-related cues during sleep to encourage reactivation of the associated information. One study employed the TMR paradigm in rodents, associating distinct auditory cues (<inline-formula><alternatives><mml:math id="inf91"><mml:mi>L</mml:mi></mml:math><tex-math id="inft91">\begin{document}$L$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf92"><mml:mi>R</mml:mi></mml:math><tex-math id="inft92">\begin{document}$R$\end{document}</tex-math></alternatives></inline-formula>) with left and right traversal of a linear track (<xref ref-type="bibr" rid="bib10">Bendor and Wilson, 2012</xref>). Playing each auditory cue during sleep elicited biased replay of place cell activity in the cued direction. We simulate these findings by encoding two sequences that share a start item. To simulate TMR, we presented a distinct cue item after each sequence’s start item during learning (Figure 7e) and re-presented each cue item (through its associated context) as an external cue in sleep. Matching (<xref ref-type="bibr" rid="bib10">Bendor and Wilson, 2012</xref>), CMR-replay preferentially replayed each cue’s associated sequence (<xref ref-type="fig" rid="fig2">Figure 2c</xref>, right). <xref ref-type="bibr" rid="bib10">Bendor and Wilson, 2012</xref>, found that sound cues during sleep did not trigger immediate replay, but instead biased reactivation toward the cued sequence over an extended period of time. While the model does exhibit some replay triggered immediately by the cue, it also captures the sustained bias toward the cued sequence over an extended period.</p></sec><sec id="s2-3"><title>Effects of reward</title><p>At first glance, our proposal may seem at odds with extensive evidence of the influence of reward on replay (<xref ref-type="bibr" rid="bib2">Ambrose et al., 2016</xref>; <xref ref-type="bibr" rid="bib35">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="bib49">Igata et al., 2021</xref>; <xref ref-type="bibr" rid="bib65">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="bib66">Liu et al., 2021</xref>; <xref ref-type="bibr" rid="bib84">Michon et al., 2019</xref>; <xref ref-type="bibr" rid="bib112">Singer and Frank, 2009</xref>; <xref ref-type="bibr" rid="bib88">Ólafsdóttir et al., 2015</xref>) because CMR-replay neither maintains nor updates value representations during replay. For example, studies suggest that replay over-represents experiences with rewarded or aversive outcomes (<xref ref-type="bibr" rid="bib49">Igata et al., 2021</xref>; <xref ref-type="bibr" rid="bib112">Singer and Frank, 2009</xref>; <xref ref-type="bibr" rid="bib116">Sterpenich et al., 2021</xref>; <xref ref-type="bibr" rid="bib131">Wu et al., 2017</xref>; <xref ref-type="bibr" rid="bib88">Ólafsdóttir et al., 2015</xref>) and awake reverse replay occurs primarily during reward receipt (<xref ref-type="bibr" rid="bib2">Ambrose et al., 2016</xref>; <xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>; <xref ref-type="bibr" rid="bib35">Foster and Wilson, 2006</xref>). Reverse replay’s unique sensitivity to reward (<xref ref-type="bibr" rid="bib2">Ambrose et al., 2016</xref>; <xref ref-type="bibr" rid="bib84">Michon et al., 2019</xref>) appears to indicate a functional distinction between forward and backward replay, with backward replay specialized for learning value-based predictions (<xref ref-type="bibr" rid="bib2">Ambrose et al., 2016</xref>; <xref ref-type="bibr" rid="bib35">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="bib66">Liu et al., 2021</xref>).</p><p>We suggest that salience governs encoding rates, which aligns with evidence that salient stimuli bind more strongly to their context (<xref ref-type="bibr" rid="bib3">Anderson, 2005</xref>; <xref ref-type="bibr" rid="bib72">Mackay et al., 2005</xref>; <xref ref-type="bibr" rid="bib71">Mackay et al., 2004</xref>; <xref ref-type="bibr" rid="bib76">Mather, 2007</xref>). Building on models that adopt this assumption (<xref ref-type="bibr" rid="bib19">Cohen and Kahana, 2022</xref>; <xref ref-type="bibr" rid="bib119">Talmi et al., 2019</xref>), CMR-replay updates <inline-formula><alternatives><mml:math id="inf93"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft93">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf94"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft94">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> at higher rates for salient items, including those with high valence (reward or punishment) or novelty. In CMR-replay, increasing encoding rates strengthens replay in two distinct ways: Enhancing the <inline-formula><alternatives><mml:math id="inf95"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft95">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> encoding rate facilitates the reactivation of an item given features of its encoding context as cue, while enhancing the <inline-formula><alternatives><mml:math id="inf96"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft96">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> encoding rate facilitates the faithful retrieval of an item’s encoding context. Here, we explore whether these mechanisms allow CMR-replay to account for reward-related phenomena.</p><p>After visually exploring a T-maze with one arm containing reward, animals preferentially activated sequences representing the rewarded arm during sleep (<xref ref-type="bibr" rid="bib88">Ólafsdóttir et al., 2015</xref>; <xref ref-type="fig" rid="fig3">Figure 3a</xref>, left). We simulated this task by presenting CMR-replay with two sequences, one with a rewarded final item and the other with a neutral final item (Figure 7d). Due to the influence of encoding rates, replay over-represents the rewarded item compared to the matched neutral item (<xref ref-type="fig" rid="fig3">Figure 3a</xref>, right) as in empirical observations (<xref ref-type="bibr" rid="bib49">Igata et al., 2021</xref>; <xref ref-type="bibr" rid="bib112">Singer and Frank, 2009</xref>; <xref ref-type="bibr" rid="bib88">Ólafsdóttir et al., 2015</xref>). CMR-replay exhibits this property without the assumption that reward-associated items receive more exposure during encoding (<xref ref-type="bibr" rid="bib28">Diekmann and Cheng, 2023</xref>).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Reward leads to over-representation in sleep and modulates the rate of backward replay.</title><p>(<bold>a</bold>) Sleep over-represents items associated with reward in animals (left) and in CMR-replay (right). Error bars represent ±1 standard error of the mean. (<bold>b</bold>) Varying the magnitude of reward outcome leads to differences in the frequency of backward but not forward replay in animals (left) and CMR-replay (right). In the animal data (left), error bars show 95% confidence intervals. For simulation results (right), error bars show ±1 standard error of the mean. Left image in <bold>a</bold> adapted from <xref ref-type="bibr" rid="bib88">Ólafsdóttir et al., 2015</xref>, eLife; images in the left column adapted from <xref ref-type="bibr" rid="bib2">Ambrose et al., 2016</xref>, Elsevier.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99931-fig3-v1.tif"/></fig><p>Varying the magnitude of reward at the end of a linear track significantly alters the number of backward but not forward replay events (<xref ref-type="bibr" rid="bib2">Ambrose et al., 2016</xref>; <xref ref-type="fig" rid="fig3">Figure 3b</xref>, left). Following <xref ref-type="bibr" rid="bib77">Mattar and Daw, 2018</xref>, to disambiguate each location and the direction of a run, we simulated the task with two distinct input sequences, each with a final rewarded item. We manipulated the encoding rate of one rewarded item to be higher (i.e. high reward), lower (i.e. low reward), or identical to that of the reward item in the other sequence (i.e. normal reward). Since the encoding of the rewarded item primarily influences backward replay in post-run rest, we observed differences in the rate of backward but not forward replay between different reward conditions (<xref ref-type="fig" rid="fig3">Figure 3b</xref>, right), matching empirical observations (<xref ref-type="bibr" rid="bib2">Ambrose et al., 2016</xref>; <xref ref-type="bibr" rid="bib84">Michon et al., 2019</xref>).</p><p>CMR-replay’s ability to account for the effects of reward supports our proposal that reward modulates the initial encoding of memories to shape subsequent replay. After reward exerts its influence during encoding, prioritized replay of rewarded memories can occur even if reward-related activity is absent. Consistent with our proposal that replay itself does not require value-based computations, sleep’s preferential consolidation of reward memories does not seem to require dopaminergic activity (<xref ref-type="bibr" rid="bib7">Asfestani et al., 2020</xref>), and the coordination between reward responsive neurons and replay-related events is absent in sleep (<xref ref-type="bibr" rid="bib40">Gomperts et al., 2015</xref>). Our model treats reward as simply the salient feature of an item, generating the prediction that non-reward-related salient items should exhibit similar characteristics.</p></sec><sec id="s2-4"><title>Replay goes beyond direct recent experience</title><p>We next asked whether CMR-replay can account for findings in which animals replay sequences learned outside of their present context. Several studies have established this so-called ‘remote replay’ phenomenon (<xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>; <xref ref-type="bibr" rid="bib56">Karlsson and Frank, 2009</xref>). Here, we describe one such experiment and show how CMR-replay provides an account of its findings. In <xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>, animals explored both arms of a T-maze during pre-training. During each subsequent recording session, animals traversed only the left or right arm (L- or R- only conditions) or alternated between them (alternation condition). During reward receipt on the just-explored arm, awake rest exhibited remote replay of the opposite, non-local arm (<xref ref-type="fig" rid="fig4">Figure 4a</xref>, left: remote replay) across all conditions (<xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>). This observation challenges models that prioritize items near the resting location (<xref ref-type="bibr" rid="bib77">Mattar and Daw, 2018</xref>) and recently active neurons (<xref ref-type="bibr" rid="bib15">Buzsáki, 1989</xref>; <xref ref-type="bibr" rid="bib21">Csicsvari et al., 2007</xref>; <xref ref-type="bibr" rid="bib35">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="bib91">O’Neill et al., 2008</xref>) throughout replay. To determine whether CMR-replay can reproduce these results, we presented the model with sequences that overlap for the first few items (representing the central arm of the T-maze; Figure 7c). During each of two simulated ‘pre-training’ sessions, the model encoded both sequences. We then ran the model through two conditions in an ensuing ‘experimental’ session, where it encoded either only one (L- or R-only conditions) or both sequences (alternation condition). After encoding the sequences, we simulated reward receipt by presenting CMR-replay with the encoding context of a rewarded item as an external context cue. As in <xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>, CMR-replay is able to generate remote replay of the non-local sequence (<xref ref-type="fig" rid="fig4">Figure 4b</xref>, left; <xref ref-type="fig" rid="fig4">Figure 4c</xref>, right). When CMR reactivates a non-local item by chance, replay context dramatically shifts by incorporating the non-local item’s associated context, thereby triggering a cascade of non-local item reactivation to generate remote replay. Due to its suppression mechanism, CMR-replay is able to capture the higher prevalence of remote replay in L- and R-only conditions (<xref ref-type="fig" rid="fig4">Figure 4c</xref>, right), which we will unpack in a subsequent section. The occurrence of remote replay, however, does not rely on the suppression mechanism, as the model generates remote replay in the alternation condition where suppression is matched across local and non-local items.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Replay activates remote experiences and links temporally separated experiences.</title><p>(<bold>a</bold>) The two panels show examples of remote and novel (shortcut) replay sequences observed in animals. The colored items indicate the temporal order of the sequences (light blue, early; purple, late). The red item denotes the resting position. (<bold>b</bold>) CMR-replay also generates remote and shortcut rest replay, as illustrated in the replay sequences in the two panels. (<bold>c</bold>) Proportion of replay events that contain remote sequences in animals (left) and in CMR-replay (right). Error bars show ±1 standard error of the mean in the data and model. (<bold>d</bold>) In <xref ref-type="bibr" rid="bib65">Liu et al., 2019</xref>, participants encoded scrambled versions of two true sequences <inline-formula><alternatives><mml:math id="inf97"><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft97">\begin{document}$X_{1}X_{2}X_{3}X_{4}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf98"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft98">\begin{document}$Y_{1}Y_{2}Y_{3}Y_{4}$\end{document}</tex-math></alternatives></inline-formula>: <inline-formula><alternatives><mml:math id="inf99"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft99">\begin{document}$X_{1}X_{2}Y_{1}Y_{2},\ X_{2}X_{3}Y_{2}Y_{3}$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf100"><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft100">\begin{document}$X_{3}X_{4}Y_{3}Y_{4}$\end{document}</tex-math></alternatives></inline-formula> (<xref ref-type="fig" rid="fig7">Figure 7g</xref>). After learning, human spontaneous neural activity showed stronger evidence of sequential reactivation of the true sequences (left). CMR-replay encoded scrambled sequences as in the experiment. Consistent with empirical observation, subsequent replay in CMR-replay over-represents the true sequences (right). Error bars show ±1 standard error of the mean in the model. Images in <bold>a </bold>adapted from <xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>, Elsevier; left image in <bold>c</bold> adapted from <xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>, Elsevier; left image in <bold>d</bold> adapted from <xref ref-type="bibr" rid="bib65">Liu et al., 2019</xref>, Elsevier.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99931-fig4-v1.tif"/></fig><p>We next examined whether replay in CMR-replay can link temporally separated experiences to form novel sequences that go beyond direct experience (<xref ref-type="bibr" rid="bib8">Barron et al., 2020</xref>; <xref ref-type="bibr" rid="bib28">Diekmann and Cheng, 2023</xref>; <xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>; <xref ref-type="bibr" rid="bib61">Kumaran and McClelland, 2012</xref>; <xref ref-type="bibr" rid="bib65">Liu et al., 2019</xref>). <xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref> showed the occurrence of novel, shortcut replay sequences. These shortcut sequences cut directly across the choice point and link segments of the two arms of a T-maze during rest (<xref ref-type="fig" rid="fig4">Figure 4a</xref>, right: shortcut replay), even though animals never directly experienced such trajectories (<xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>). In our simulation of the study (<xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>), CMR-replay also generates novel rest replay that links segments of the two sequences (<xref ref-type="fig" rid="fig4">Figure 4b</xref>, right): The reactivation of the juncture of the two sequences (the top middle item of Figure 7c) brings back context common to the two sequences, allowing replay to stitch together segments of the two sequences. In line with <xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>, shortcut replay appeared at very low rates in CMR-replay (the alternation condition: mean proportion of replay events that contain shortcut sequence = 0.0046; L or R conditions: mean proportion = 0.0062).</p><p><xref ref-type="bibr" rid="bib65">Liu et al., 2019</xref>, showed that replay in humans reorganizes temporally -separated wake inputs. In their first experiment, participants encoded sequences that scrambled pairwise transitions of two true sequences <inline-formula><alternatives><mml:math id="inf101"><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft101">\begin{document}$X_{1}X_{2}X_{3}X_{4}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf102"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft102">\begin{document}$Y_{1}Y_{2}Y_{3}Y_{4}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf103"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft103">\begin{document}$X_{1}X_{2}Y_{1}Y_{2},\ X_{2}X_{3}Y_{2}Y_{3}$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf104"><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft104">\begin{document}$X_{3}X_{4}Y_{3}Y_{4}$\end{document}</tex-math></alternatives></inline-formula>. To highlight transitions from the true sequences, the time lag between those transitions (e.g. <inline-formula><alternatives><mml:math id="inf105"><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft105">\begin{document}$X_{2}X_{3}$\end{document}</tex-math></alternatives></inline-formula>) was shorter than others (e.g. <inline-formula><alternatives><mml:math id="inf106"><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft106">\begin{document}$X_{3}Y_{2}$\end{document}</tex-math></alternatives></inline-formula>) during presentation. Analyses revealed preferential replay of the true as opposed to the scrambled sequences (<xref ref-type="bibr" rid="bib65">Liu et al., 2019</xref>; <xref ref-type="fig" rid="fig4">Figure 4d</xref>, left). We simulated the experiment by presenting CMR-replay with sequences of the same structure (Figure 7g), where context drifted more for longer interstimulus intervals. After learning, the model performed replay in the absence of external context cues. The quantification of replay in <xref ref-type="bibr" rid="bib65">Liu et al., 2019</xref>, which reflects statistical evidence of replay decoding based on magnetoencephalography (MEG) data, differs from our measure, where we have direct access to replay without measurement noise. However, qualitatively matching <xref ref-type="bibr" rid="bib65">Liu et al., 2019</xref>, CMR-replay preferentially replays true sequences relative to scrambled sequences (<xref ref-type="fig" rid="fig4">Figure 4d</xref>, right).</p></sec><sec id="s2-5"><title>The influence of experience</title><p>Task exposure influences replay, with replay appearing less frequently in familiar as compared with novel environments (<xref ref-type="bibr" rid="bib18">Cheng and Frank, 2008</xref>; <xref ref-type="bibr" rid="bib39">Giri et al., 2019</xref>; <xref ref-type="bibr" rid="bib48">Huelin Gorriz et al., 2023</xref>; <xref ref-type="bibr" rid="bib91">O’Neill et al., 2008</xref>). Task repetition similarly reduces replay (<xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>; <xref ref-type="bibr" rid="bib111">Shin et al., 2019</xref>). After gaining experience along multiple trajectories, animals and humans can exhibit enhanced replay of non-recently explored trajectories (<xref ref-type="bibr" rid="bib16">Carey et al., 2019</xref>; <xref ref-type="bibr" rid="bib37">Gillespie et al., 2021</xref>; <xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>; <xref ref-type="bibr" rid="bib129">Wimmer et al., 2023</xref>). Overall, these findings demonstrate a negative relationship between the degree and recency of experience and the frequency of replay. This pattern challenges models in which experience monotonically enhances the reactivation of items (<xref ref-type="bibr" rid="bib15">Buzsáki, 1989</xref>; <xref ref-type="bibr" rid="bib21">Csicsvari et al., 2007</xref>; <xref ref-type="bibr" rid="bib28">Diekmann and Cheng, 2023</xref>; <xref ref-type="bibr" rid="bib35">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="bib77">Mattar and Daw, 2018</xref>; <xref ref-type="bibr" rid="bib91">O’Neill et al., 2008</xref>).</p><p>In CMR-replay, experience shapes replay in two opposing ways. First, repetition strengthens <inline-formula><alternatives><mml:math id="inf107"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft107">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf108"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft108">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula>, allowing replay to better preserve the temporal structure of waking inputs. Second, by enhancing <inline-formula><alternatives><mml:math id="inf109"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft109">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula>, repetition increases the activity of contexts associated with items. Since CMR-replay suppresses the activity of items at the onset of replay as a function of their activity during learning, repetition increases the downweighting of the activity of task items, reducing their probability of reactivation. Such a suppression mechanism may be adaptive, allowing replay to benefit not only the most recently or strongly encoded items but also to provide opportunities for the consolidation of weaker or older memories, consistent with empirical evidence (<xref ref-type="bibr" rid="bib103">Schapiro et al., 2018</xref>; <xref ref-type="bibr" rid="bib135">Yu et al., 2024</xref>).</p><p>The next set of simulations illustrates CMR-replay’s account of experience-dependent changes in replay (<xref ref-type="bibr" rid="bib16">Carey et al., 2019</xref>; <xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>; <xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>; <xref ref-type="bibr" rid="bib49">Igata et al., 2021</xref>; <xref ref-type="bibr" rid="bib111">Shin et al., 2019</xref>). We first examined how replay changes through repeated encoding of the same inputs following our linear track simulation illustrated in Figure 7a. Here, CMR-replay encodes the same sequence across learning sessions, with awake rest after each session. Initially, experience increases the prevalence of replay (<xref ref-type="fig" rid="fig5">Figure 5a</xref>, left). As repetition enhances the suppression of task-related items at the onset of replay, replay frequency subsequently decreases in CMR-replay (<xref ref-type="fig" rid="fig5">Figure 5a</xref>, left). Through experience, the average length of replay increases (<xref ref-type="fig" rid="fig5">Figure 5a</xref>, middle), suggesting that repetition strengthens sequence memory in the model. In contrast to the EVB model (<xref ref-type="bibr" rid="bib77">Mattar and Daw, 2018</xref>), which predicts a differential drop in the rate of backward relative to forward replay, the proportion of replay events that are backward does not decrease (<xref ref-type="fig" rid="fig5">Figure 5a</xref>, right) in CMR-replay. This result highlights that, unlike the EVB model, CMR-replay does not employ distinct variables to drive forward vs. backward replay.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Variations in replay as a function of experience.</title><p>(<bold>a</bold>) In CMR-replay, through repeated exposure to the same task, the frequency of replay events decreases (left), the average length of replay events increases (middle), and the proportion of replay events that are backward remains stable (after a slight initial uptick; right). (<bold>b</bold>) With repeated experience in the same task, animals exhibit lower rates of replay (left) and longer replay sequences (middle), while the proportion of replay events that are backward stays relatively stable (right). (<bold>c</bold>) In a T-maze task, where animals display a preference for traversing a particular arm of the maze, replay more frequently reflects the opposite arm (<xref ref-type="bibr" rid="bib16">Carey et al., 2019</xref>) (left). CMR-replay preferentially replays the right arm after exposure to the left arm and vice versa (right). Error bars show ±1 SEM in all panels. Images in <bold>b</bold> adapted from <xref ref-type="bibr" rid="bib111">Shin et al., 2019</xref>, Elsevier; left image in <bold>c </bold>adapted from <xref ref-type="bibr" rid="bib16">Carey et al., 2019</xref>, Nature Publishing Group.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99931-fig5-v1.tif"/></fig><p>In an experiment where animals learned the same task across eight behavioral sessions, <xref ref-type="bibr" rid="bib111">Shin et al., 2019</xref>, observed a similar pattern of results. As shown in <xref ref-type="fig" rid="fig5">Figure 5b</xref>, animals exhibited lower rates of replay but longer replay sequences in later sessions (left, middle). As in our CMR-replay simulations, as the rates of forward and backward replay both decrease, the proportion of forward relative to backward replay events remains relatively stable across sessions (right). Furthermore, consistent with reduced reactivation of task-related units in CMR-replay, the study observed decreased reactivation of task-related place cells through experience. In contrast, item reactivation increases monotonically through repetition in other models (<xref ref-type="bibr" rid="bib28">Diekmann and Cheng, 2023</xref>; <xref ref-type="bibr" rid="bib77">Mattar and Daw, 2018</xref>). <xref ref-type="bibr" rid="bib111">Shin et al., 2019</xref>, performed Bayesian decoding to statistically quantify evidence of replay, whereas our analyses directly compare segments of a behavioral sequence with replay sequences. Despite differences between these measures, the patterns of results in the data and in the model match qualitatively. Several other studies using varied experimental procedures have reported similar effects of repeated experience on replay, including a reduction in the prevalence of replay (<xref ref-type="bibr" rid="bib18">Cheng and Frank, 2008</xref>; <xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>), an increase in replay length (<xref ref-type="bibr" rid="bib11">Berners-Lee et al., 2022</xref>), and no reduction in the proportion of replay events that are backward (<xref ref-type="bibr" rid="bib49">Igata et al., 2021</xref>).</p><p>In CMR-replay, the activity of retrieved contexts associated with items in a learning session modulates the level of item suppression during ensuing quiescence. As a result, items that get more exposure in a session may receive more suppression than others at the onset of replay, facilitating the reactivation of their competitors. In our simulation of <xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>; Figure 7c, in the L- and R-only conditions, since the sequence presented during learning receives more suppression, remote replay is more prevalent than in the alternation condition, where both sequences appear during learning (<xref ref-type="fig" rid="fig4">Figure 4c</xref>). In the L- or R-only conditions, when CMR-replay performs post-learning replay in the absence of external context cues, replay over-represents the alternative sequence (<xref ref-type="fig" rid="fig5">Figure 5c</xref>), which aligns with the observation that replay exhibits a bias away from the arm of a T-maze that animals preferred during behavior (<xref ref-type="bibr" rid="bib16">Carey et al., 2019</xref>). This property is also consonant with recent findings that replay preferentially activates non-recent trajectories (<xref ref-type="bibr" rid="bib37">Gillespie et al., 2021</xref>).</p></sec><sec id="s2-6"><title>The function of replay</title><p>Many have proposed adaptive functions for replay, including for memory consolidation (<xref ref-type="bibr" rid="bib17">Carr et al., 2011</xref>; <xref ref-type="bibr" rid="bib59">Klinzing et al., 2019</xref>; <xref ref-type="bibr" rid="bib79">McClelland et al., 1995</xref>), retrieval (<xref ref-type="bibr" rid="bib17">Carr et al., 2011</xref>; <xref ref-type="bibr" rid="bib50">Jadhav et al., 2012</xref>; <xref ref-type="bibr" rid="bib128">Wimmer et al., 2020</xref>), credit assignment (<xref ref-type="bibr" rid="bib2">Ambrose et al., 2016</xref>; <xref ref-type="bibr" rid="bib35">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="bib85">Momennejad et al., 2018</xref>), and planning (<xref ref-type="bibr" rid="bib78">Mattar and Lengyel, 2022</xref>; <xref ref-type="bibr" rid="bib52">Jensen et al., 2023</xref>; <xref ref-type="bibr" rid="bib96">Pfeiffer and Foster, 2013</xref>). Growing causal evidence suggests that replay benefits memory: TMR enhances memory (<xref ref-type="bibr" rid="bib93">Oudiette and Paller, 2013</xref>), and disrupting SWRs impairs memory (<xref ref-type="bibr" rid="bib32">Ego-Stengel and Wilson, 2010</xref>; <xref ref-type="bibr" rid="bib38">Girardeau et al., 2009</xref>; <xref ref-type="bibr" rid="bib50">Jadhav et al., 2012</xref>). Replay facilitates offline learning in our model by updating <inline-formula><alternatives><mml:math id="inf110"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft110">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf111"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft111">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> according to the internally reactivated items and contexts during replay. In the following set of simulations, we characterize ways in which replay facilitates memory in the model.</p><p>One of the most robust benefits of sleep is on sequence memory, often studied with motor sequence paradigms (<xref ref-type="bibr" rid="bib58">King et al., 2017</xref>). To simulate the impacts of sleep replay on sequence memory, we presented CMR-replay with a five-item sequence and examined whether sleep enhanced memory of the sequence. Before and after sleep, we assessed the proportion of replay sequences that matched the input sequence. The assessment occurred in ‘test’ periods, where learning rates were set to zero and external cues were absent. In the post-sleep test, CMR-replay generated a higher proportion of sequences matching the correct sequence than in the pre-sleep test (<xref ref-type="fig" rid="fig6">Figure 6a</xref>), indicating that sleep enhances sequence memory in the model. This motor memory simulation using a model of hippocampal replay is consistent with evidence that hippocampal replay can contribute to consolidating memories that are not hippocampally dependent at encoding (<xref ref-type="bibr" rid="bib104">Schapiro et al., 2019</xref>; <xref ref-type="bibr" rid="bib102">Sawangjit et al., 2018</xref>). It is possible that replay in other, more domain-specific areas could also contribute (<xref ref-type="bibr" rid="bib33">Eichenlaub et al., 2020</xref>).</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Learning from replay.</title><p>(<bold>a</bold>) Sleep increased the likelihood of reactivating the learned sequence in the correct temporal order in CMR-replay, as seen in an increase in the proportion of replay for learned sequences post-sleep. (<bold>b</bold>) Sleep leads to greater reactivation of rewarded than non-rewarded items, indicating that sleep preferentially strengthens rewarded memories in CMR-replay. (<bold>c</bold>) In the simulation of <xref ref-type="bibr" rid="bib66">Liu et al., 2021</xref>, CMR-replay encoded six sequences, each of which transitioned from one of three start items to one of two end items. After receiving a reward outcome for the end item of a sequence, we simulated a period of rest. After, but not before rest, CMR-replay exhibited a preference for non-local sequences that led to the rewarded item. This preference emerged through rest despite the fact that the model never observed reward in conjunction with those non-local sequences, suggesting that rest replay facilitates non-local learning in the model. (<bold>d</bold>) We trained a ‘teacher’ CMR-replay model on a sequence of items. After encoding the sequence, the teacher generated replay sequences during sleep. We then trained a separate blank-slate ‘student’ CMR-replay model exclusively on the teacher’s sleep replay sequences. To assess knowledge of the original sequence, we collected sleep replay sequences from both models and assessed the probability that each model reactivates the item at position <inline-formula><alternatives><mml:math id="inf112"><mml:mi>i</mml:mi></mml:math><tex-math id="inft112">\begin{document}$i$\end{document}</tex-math></alternatives></inline-formula> + lag of the sequence immediately following the reactivation of the <italic>i</italic>th item of the sequence, conditioned on the availability of the <italic>i</italic>th item for reactivation. Both models demonstrated a tendency to reactivate the item that immediately follows or precedes the just-reactivated item on the original sequence. This result suggests that the student acquired knowledge of the temporal structure of original sequence by encoding only the teacher’s replay sequences. Error bars show ±1 SEM.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99931-fig6-v1.tif"/></fig><p>Replay preferentially enhances rewarded memories (<xref ref-type="bibr" rid="bib84">Michon et al., 2019</xref>), and sleep preferentially consolidates salient experiences (<xref ref-type="bibr" rid="bib95">Payne and Kensinger, 2010</xref>; <xref ref-type="bibr" rid="bib94">Payne et al., 2008</xref>). In our simulation of a T-maze with reward in one of the two arms (<xref ref-type="bibr" rid="bib88">Ólafsdóttir et al., 2015</xref>), we also included pre- and post-sleep test periods to assess how sleep in CMR-replay shapes rewarded vs. non-rewarded memory. Through sleep, CMR-replay exhibited a greater increase in its reactivation of the rewarded item compared to a matched neutral item (<xref ref-type="fig" rid="fig6">Figure 6b</xref>), suggesting that sleep preferentially enhances memory associations for rewarded items in CMR-replay.</p><p>A recent study (<xref ref-type="bibr" rid="bib66">Liu et al., 2021</xref>) presented evidence that replay facilitates non-local value learning. Human participants first learned about the structure of six sequences, each of which begins with one of three start items and terminates with one of two end items. Then, for two sequences that share a start state, participants learned that only one of them leads to reward. After a period of rest during which replay was measured with MEG, among the other four sequences (i.e. the non-local sequences), participants exhibited a behavioral preference for sequences that terminate in the end item associated with reward, despite no direct recent experience with reward in that sequence. The authors suggested that, in accordance with the RL perspective, replay propagates value to associated items, allowing participants to select non-local sequences associated with reward without direct experience. In our simulation of this paradigm, CMR-replay encoded six sequences of the same structure (Figure 7b), with increased encoding rates to simulate reward receipt, as in the simulations above. To simulate awake rest after reward receipt, we presented the encoding context of the rewarded item as an external cue. Before and after rest, we examined the model’s preference among the four non-local sequences, by assessing how much the model activated each non-local start item’s two ensuing items given the start item’s associated context as a cue. After, but not before rest, CMR-replay preferentially activated the item that leads to the rewarded end item (<xref ref-type="fig" rid="fig6">Figure 6c</xref>). This is because the presence of the rewarded item as an external cue evokes the reactivation of its associated non-local items. In CMR-replay, this preference emerged without value updates, suggesting that replay can facilitate non-local learning by re-organizing memory associations.</p><p>There has been much interest in the memory literature in the possibility that hippocampal replay serves to train neocortical systems to represent recent memories (<xref ref-type="bibr" rid="bib1">Alvarez and Squire, 1994</xref>; <xref ref-type="bibr" rid="bib13">Born and Wilhelm, 2012</xref>; <xref ref-type="bibr" rid="bib15">Buzsáki, 1989</xref>; <xref ref-type="bibr" rid="bib17">Carr et al., 2011</xref>; <xref ref-type="bibr" rid="bib44">Hasselmo et al., 1996</xref>; <xref ref-type="bibr" rid="bib79">McClelland et al., 1995</xref>; <xref ref-type="bibr" rid="bib113">Singh et al., 2022</xref>; <xref ref-type="bibr" rid="bib117">Sun et al., 2023</xref>). We explored whether replay in CMR-replay can serve to transfer one model’s knowledge to another. After a ‘teacher’ CMR-replay encodes a sequence, we collected its sleep replay sequences to train a blank-slate ‘student’ CMR-replay at replay’s learning rates. Through this process, the student inherited the contiguity bias of the teacher (<xref ref-type="fig" rid="fig6">Figure 6d</xref>), suggesting it acquired knowledge of the structure of the teacher’s training sequence. This simulation provides a proof of concept that replay in CMR-replay can serve to facilitate memory transfer across systems, in addition to promoting local learning. More broadly, these results resonate with ideas from the Complementary Learning Systems framework (<xref ref-type="bibr" rid="bib79">McClelland et al., 1995</xref>), which proposes that replay allows the neocortex to learn from hippocampal activity by integrating related experiences. We speculate that the offline learning observed in these simulations corresponds to consolidation processes that operate specifically during sleep, when hippocampal-neocortical dynamics are especially tightly coupled (<xref ref-type="bibr" rid="bib59">Klinzing et al., 2019</xref>).</p><p>The results outlined above arise from the model’s assumption that replay strengthens bidirectional associations between items and contexts to benefit memory. This assumption leads to several predictions about differences across replay types. First, the model predicts that sleep yields different memory benefits compared to rest in the task environment: Sleep is less biased toward initiating replay at specific items, resulting in a more uniform benefit across all memories. Second, the model predicts that forward and backward replay contribute to memory in qualitatively similar ways but tend to benefit different memories. This divergence arises because forward and backward replay exhibit distinct item preferences, with backward replay being more likely to include rewarded items, thereby preferentially benefiting those memories.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>What is the nature and function of neural replay? We suggest a simple memory-focused framework that explains a wide array of replay phenomena. First, the brain associates experiences with their encoding contexts at rates that vary according to the salience of each experience. Then, in quiescence, the brain replays by spontaneously reactivating a memory and retrieving its associated context to guide subsequent reactivation. Learning continues to occur during these endogenously generated reactivation events. A model embodying these ideas – CMR-replay – explains many qualitative empirical characteristics of replay and its impacts, including patterns previously interpreted as features of RL computations, and observations that prior models do not explain.</p><p>First, CMR-replay demonstrates basic properties of replay that other models exhibit (or could easily accommodate) (<xref ref-type="bibr" rid="bib28">Diekmann and Cheng, 2023</xref>; <xref ref-type="bibr" rid="bib57">Khamassi and Girard, 2020</xref>; <xref ref-type="bibr" rid="bib61">Kumaran and McClelland, 2012</xref>; <xref ref-type="bibr" rid="bib77">Mattar and Daw, 2018</xref>; <xref ref-type="bibr" rid="bib81">McNamee et al., 2021</xref>), including replay’s recapitulation of the temporal pattern of past experience during rest and sleep (<xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>; <xref ref-type="bibr" rid="bib125">Wikenheiser and Redish, 2013</xref>), bias toward memories associated with external cues (<xref ref-type="bibr" rid="bib10">Bendor and Wilson, 2012</xref>), and ability to stitch together temporally separated experiences to form novel sequences (<xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>; <xref ref-type="bibr" rid="bib65">Liu et al., 2019</xref>). Second, CMR-replay captures findings that have been interpreted as evidence that replay serves value-based RL, including over-representation of memories associated with reward (<xref ref-type="bibr" rid="bib88">Ólafsdóttir et al., 2015</xref>), reverse replay upon reward receipt (<xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>; <xref ref-type="bibr" rid="bib35">Foster and Wilson, 2006</xref>), and the unique sensitivity of reverse replay to reward magnitude (<xref ref-type="bibr" rid="bib2">Ambrose et al., 2016</xref>). Third, CMR-replay accounts for observations that are not naturally accounted for by prior models, including a stable proportion of backward replay through learning (<xref ref-type="bibr" rid="bib111">Shin et al., 2019</xref>), reduced item reactivation and sequential replay with experience (<xref ref-type="bibr" rid="bib111">Shin et al., 2019</xref>; <xref ref-type="bibr" rid="bib18">Cheng and Frank, 2008</xref>), increased prevalence of forward replay in sleep (<xref ref-type="bibr" rid="bib125">Wikenheiser and Redish, 2013</xref>), enhanced replay outside of the current context (<xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>), and a tendency for replay to cover non-behaviorally preferred experiences (<xref ref-type="bibr" rid="bib16">Carey et al., 2019</xref>). Finally, replay facilitates memory in CMR-replay in ways that align with empirical findings (<xref ref-type="bibr" rid="bib58">King et al., 2017</xref>; <xref ref-type="bibr" rid="bib66">Liu et al., 2021</xref>; <xref ref-type="bibr" rid="bib84">Michon et al., 2019</xref>; <xref ref-type="bibr" rid="bib94">Payne et al., 2008</xref>; <xref ref-type="bibr" rid="bib95">Payne and Kensinger, 2010</xref>; <xref ref-type="bibr" rid="bib25">Diamond et al., 2024</xref>). These include the improvement of sequence memory, preferential strengthening of rewarded memories, facilitation of non-local learning, and endogenous training of a separate memory system in the absence of external inputs.</p><p>The EVB model and CMR-replay offer different types of explanation for why replay exhibits its disparate characteristics: The EVB model provides an explicitly normative explanation, whereas CMR-replay offers a mechanistic account. The different levels of explanation raise the possibility that CMR-replay could be considered a mechanistic implementation of EVB. Indeed, there are several shared properties between the models (<xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>; <xref ref-type="bibr" rid="bib88">Ólafsdóttir et al., 2015</xref>; <xref ref-type="bibr" rid="bib35">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="bib2">Ambrose et al., 2016</xref>). However, as discussed above, CMR-replay captures observations that appear inconsistent with the EVB model, including the prevalence of non-local replay, the decoupling of replay from behavioral preference, and similar proportions of forward and backward replay over time. In addition to these existing observations, the two models make distinct predictions that can be tested experimentally. For example, in tasks where the goal is positioned in the middle of an arm rather than at its end, CMR-replay predicts a more balanced ratio of forward and reverse replay, whereas the EVB model still predicts a dominance of reverse replay due to backward gain propagation from the reward. This contrast aligns with empirical findings, showing that when the goal is located in the middle of an arm, replay events are more evenly split between forward and reverse directions (<xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>), whereas placing the goal at the end of a track produces a stronger bias toward reverse replay (<xref ref-type="bibr" rid="bib26">Diba and Buzsáki, 2007</xref>). Moreover, the EVB model predicts that reward only modulates the rate of replay when it informs potential change in behavior, whereas CMR-replay considers reward as a salient feature that enhances replay by facilitating associations between item and context. Thus, in scenarios where animals cannot choose between competing actions (e.g. when there are only deterministic paths), CMR-replay, but not the EVB model, predicts that reward manipulation would lead to changes in the rate of replay. CMR-replay also predicts that salient non-rewarding events should lead to similar patterns of replay as rewarded events. While not explicitly normative, CMR-replay does offer an explanation of the goal of replay, which is to improve memory through offline local learning and systems interactions. CMR-replay posits that replay may facilitate building a stable, unbiased understanding of the environment useful for many different possible future tasks, some of which may be difficult for an animal to predict and therefore optimize in advance (<xref ref-type="bibr" rid="bib100">Sagiv et al., 2025</xref>).</p><p>An ongoing debate concerns to what extent awake replay reflects a process of planning that simulates future scenarios in support of immediate decision-making (<xref ref-type="bibr" rid="bib96">Pfeiffer and Foster, 2013</xref>; <xref ref-type="bibr" rid="bib78">Mattar and Lengyel, 2022</xref>; <xref ref-type="bibr" rid="bib52">Jensen et al., 2023</xref>), vs. to what extent it serves to store, update, and maintain memory without directly guiding behavior (<xref ref-type="bibr" rid="bib30">Dupret et al., 2010</xref>; <xref ref-type="bibr" rid="bib38">Girardeau et al., 2009</xref>; <xref ref-type="bibr" rid="bib54">Joo and Frank, 2018</xref>; <xref ref-type="bibr" rid="bib27">Diba, 2021</xref>). Evidence supporting the planning hypothesis comes from studies that demonstrate enhanced replay of upcoming behavioral trajectories (<xref ref-type="bibr" rid="bib96">Pfeiffer and Foster, 2013</xref>; <xref ref-type="bibr" rid="bib132">Xu et al., 2019</xref>). However, in tasks that track representations of multiple temporally and spatially separated experiences, animals exhibit replay that appears to be decoupled from their behavioral preference (<xref ref-type="bibr" rid="bib16">Carey et al., 2019</xref>; <xref ref-type="bibr" rid="bib37">Gillespie et al., 2021</xref>; <xref ref-type="bibr" rid="bib42">Gupta et al., 2010</xref>). Our model aligns more with the memory perspective, as it is able to capture existing findings without positing that replay serves to optimize behavioral outcome. However, a replay of this kind could at times be read out and used by downstream decision-making systems. For example, recent work argues that the dynamics of the retrieval processes in this class of models could support adaptive choice in sequential decision tasks (<xref ref-type="bibr" rid="bib136">Zhou et al., 2024</xref>). Overall, our framework argues that replay characteristics are primarily driven by memory principles, and that replay serves to strengthen and reorganize memories, which benefits subsequent – but not necessarily immediate – behavior (<xref ref-type="bibr" rid="bib37">Gillespie et al., 2021</xref>; <xref ref-type="bibr" rid="bib54">Joo and Frank, 2018</xref>).</p><p>Many memory consolidation theories are aligned with CMR-replay in suggesting that replay actively strengthens and re-organizes memories (<xref ref-type="bibr" rid="bib6">Antony and Schapiro, 2019</xref>; <xref ref-type="bibr" rid="bib13">Born and Wilhelm, 2012</xref>; <xref ref-type="bibr" rid="bib15">Buzsáki, 1989</xref>; <xref ref-type="bibr" rid="bib20">Cowan et al., 2021</xref>; <xref ref-type="bibr" rid="bib59">Klinzing et al., 2019</xref>; <xref ref-type="bibr" rid="bib79">McClelland et al., 1995</xref>; <xref ref-type="bibr" rid="bib113">Singh et al., 2022</xref>). Contextual binding theory (<xref ref-type="bibr" rid="bib134">Yonelinas et al., 2019</xref>), however, takes a different approach, suggesting that residual encoding-related activity elicits merely epiphenomenal replay as context drifts during quiescence. Our theory echoes this perspective in characterizing replay as an outcome of context-guided processes. However, we diverge from the perspective in suggesting that the emergent replay does significantly benefit memory by strengthening learned associations between items and contexts. Our proposal aligns with a recent TMR study, showing that the recapitulation of items’ associated contexts during sleep drives changes in memory in humans (<xref ref-type="bibr" rid="bib106">Schechtman et al., 2023a</xref>). Our model also captures observations of enhanced replay of infrequent and remote experiences, which are in tension with the perspective that replay is primarily guided by recent activity (<xref ref-type="bibr" rid="bib6">Antony and Schapiro, 2019</xref>).</p><p>Several recent studies have argued for dominance of semantic associations over temporal associations in the process of human sleep-dependent consolidation (<xref ref-type="bibr" rid="bib107">Schechtman et al., 2023b</xref>; <xref ref-type="bibr" rid="bib67">Liu and Ranganath, 2021</xref>; <xref ref-type="bibr" rid="bib110">Sherman et al., 2025</xref>), with one study observing no role at all for temporal associations (<xref ref-type="bibr" rid="bib107">Schechtman et al., 2023b</xref>). At first glance, these findings appear in tension with our model, where temporal associations drive offline consolidation. Indeed, prior models have accounted for these findings by suppressing temporal context during sleep (<xref ref-type="bibr" rid="bib69">Liu et al., 2024</xref>; <xref ref-type="bibr" rid="bib110">Sherman et al., 2025</xref>). However, earlier models in the CMR lineage have successfully captured the joint contributions of semantic and temporal associations to encoding and retrieval (<xref ref-type="bibr" rid="bib97">Polyn et al., 2009</xref>), and these processes could extend naturally to offline replay. In a paradigm where semantic associations are especially salient during awake learning, the model could weight these associations more and account for greater co-reactivation and sleep-dependent memory benefits for semantically related than temporally related items. Consistent with this idea, <xref ref-type="bibr" rid="bib107">Schechtman et al., 2023b</xref> speculated that their null temporal effects likely reflected the task’s emphasis on semantic associations. When temporal associations are more salient and task-relevant, sleep-related benefits for temporally contiguous items are more likely to emerge (<xref ref-type="bibr" rid="bib29">Drosopoulos et al., 2007</xref>; <xref ref-type="bibr" rid="bib58">King et al., 2017</xref>).</p><p>Our model has mainly considered replay occurring during SWRs (<xref ref-type="bibr" rid="bib86">Nádasdy et al., 1999</xref>). During active behavior in rodents, ordered place cell sequences also activate during the theta oscillation (theta sequences) (<xref ref-type="bibr" rid="bib53">Johnson and Redish, 2007</xref>). Similar to ripple-based replay, theta sequences manifest in both forward and reverse order (<xref ref-type="bibr" rid="bib124">Wang et al., 2020</xref>), initiate at the animal’s location, extend further into upcoming locations through experience (<xref ref-type="bibr" rid="bib12">Blum and Abbott, 1996</xref>; <xref ref-type="bibr" rid="bib51">Jensen and Lisman, 2005</xref>; <xref ref-type="bibr" rid="bib83">Mehta et al., 1997</xref>; <xref ref-type="bibr" rid="bib99">Redish and Touretzky, 1998</xref>), cluster around behaviorally relevant items (<xref ref-type="bibr" rid="bib126">Wikenheiser and Redish, 2015</xref>), and have been proposed to correspond to cued memory retrieval (<xref ref-type="bibr" rid="bib64">Lisman and Redish, 2009</xref>). These parallels lead us to speculate that the context-driven mechanisms we have laid out for findings of replay mainly during SWRs may also be relevant in understanding theta sequences, though future work will be needed to extend the model into this domain.</p><p>Our model implements an activity-dependent suppression mechanism that, at the onset of each offline replay event, assigns each item a selection probability inversely proportional to its activation during preceding wakefulness. The brain could implement this by tagging each memory trace in proportion to its recent activation; during consolidation, that tag would then regulate starting replay probability, making highly active items less likely to be reactivated. A recent paper found that replay avoids recently traversed trajectories through awake spike-frequency adaptation (<xref ref-type="bibr" rid="bib74">Mallory et al., 2025</xref>), which could implement this kind of mechanism. In our simulations, this suppression is essential for capturing the inverse relationship between replay frequency and prior experience. Note that, unlike the synaptic homeostasis hypothesis (<xref ref-type="bibr" rid="bib120">Tononi and Cirelli, 2006</xref>), which proposes that the brain globally downscales synaptic weights during sleep, this mechanism leaves synaptic weights unchanged and instead biases the selection process during replay.</p><p>Another important area for future work is to investigate how components of CMR-replay map onto map onto brain areas and their interactions. First, our model employs a series of bidirectional operations between context and item representations to generate replay. These operations might be implemented within the recurrent connections of CA3 in the case of temporally compressed SWR replay. It is possible that these interactions could also play out across the ‘big loop’ of the hippocampus (<xref ref-type="bibr" rid="bib61">Kumaran and McClelland, 2012</xref>) or within cortical circuits (<xref ref-type="bibr" rid="bib34">Euston et al., 2007</xref>; <xref ref-type="bibr" rid="bib92">O’Neill et al., 2017</xref>; <xref ref-type="bibr" rid="bib121">Vaz et al., 2020</xref>; <xref ref-type="bibr" rid="bib130">Wittkuhn and Schuck, 2021</xref>), which could correspond to slower forms of replay (<xref ref-type="bibr" rid="bib66">Liu et al., 2021</xref>; <xref ref-type="bibr" rid="bib23">Denovellis et al., 2021</xref>). Second, in CMR-replay, the key distinction between awake rest and sleep is whether external inputs bias the initial activation state <inline-formula><alternatives><mml:math id="inf113"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft113">\begin{document}$a_{0}$\end{document}</tex-math></alternatives></inline-formula> of the replay process. This simple distinction allows the model to account for key empirical differences between awake and sleep replay. The distinction aligns with the observation that disrupting entorhinal cortex input to the hippocampus affects only awake replay, whereas manipulating hippocampal subfield CA3 activity affects both awake and sleep replay (<xref ref-type="bibr" rid="bib133">Yamamoto and Tonegawa, 2017</xref>). Our view aligns with the theory proposed by <xref ref-type="bibr" rid="bib45">Hasselmo, 1999</xref>, which suggests that the degree of hippocampal activity driven by external inputs differs between waking and sleep states: High acetylcholine levels during wakefulness bias activity into the hippocampus, while low acetylcholine levels during slow-wave sleep allow hippocampal activity to influence other brain regions. Other factors, such as task engagement, may also modulate the influence of external inputs on replay (<xref ref-type="bibr" rid="bib89">Ólafsdóttir et al., 2017</xref>). Third, in quiescence, we posit that the hippocampus can serve as a ‘teacher’ that endogenously samples memory sequences to help establish these associations in neocortical areas, with local context-item loops within the teacher and student areas. This process may be most likely to take place during NREM sleep, when ripples, spindles, and slow oscillations may coordinate replay between the hippocampus and neocortical areas (<xref ref-type="bibr" rid="bib59">Klinzing et al., 2019</xref>).</p><p>Our current simulations have focused on NREM, since the vast majority of electrophysiological studies of sleep replay have identified replay events in this stage. We have proposed in other work that replay during REM sleep may provide a complementary role to NREM sleep, allowing neocortical areas to reinstate remote, already-consolidated memories that need to be integrated with the memories that were recently encoded in the hippocampus and replayed during NREM (<xref ref-type="bibr" rid="bib113">Singh et al., 2022</xref>). An extension of our model could undertake this kind of continual learning setup, where the student, but not teacher, network retains remote memories, and the driver of replay alternates between hippocampus (NREM) and cortex (REM) over the course of a night of simulated sleep. Other differences between stages of sleep and between sleep and wake states are likely to become important for a full account of how replay impacts memory. Our current model parsimoniously explains a range of differences between awake and sleep replay by assuming simple differences in initial conditions, but we expect many more characteristics of these states (e.g. neural activity levels, oscillatory profiles, neurotransmitter levels, etc.) will be useful to incorporate in the future.</p><p>There exists a range of computational models of replay that vary in biological plausibility, from biologically detailed frameworks capturing synaptic and spiking dynamics to more abstract, algorithmic approaches (<xref ref-type="bibr" rid="bib31">Ecker et al., 2022</xref>; <xref ref-type="bibr" rid="bib60">Koene and Hasselmo, 2008</xref>; <xref ref-type="bibr" rid="bib46">Hasselmo, 2008</xref>; <xref ref-type="bibr" rid="bib77">Mattar and Daw, 2018</xref>; <xref ref-type="bibr" rid="bib63">Levenstein et al., 2024</xref>; <xref ref-type="bibr" rid="bib108">Shen and McNaughton, 1996</xref>; <xref ref-type="bibr" rid="bib115">Spens and Burgess, 2024</xref>; <xref ref-type="bibr" rid="bib28">Diekmann and Cheng, 2023</xref>; <xref ref-type="bibr" rid="bib43">Haga and Fukai, 2018</xref>; <xref ref-type="bibr" rid="bib57">Khamassi and Girard, 2020</xref>; <xref ref-type="bibr" rid="bib61">Kumaran and McClelland, 2012</xref>; <xref ref-type="bibr" rid="bib52">Jensen et al., 2023</xref>; <xref ref-type="bibr" rid="bib9">Barry and Love, 2022</xref>; <xref ref-type="bibr" rid="bib55">Káli and Dayan, 2004</xref>; <xref ref-type="bibr" rid="bib79">McClelland et al., 1995</xref>; <xref ref-type="bibr" rid="bib101">Santoro et al., 2016</xref>; <xref ref-type="bibr" rid="bib113">Singh et al., 2022</xref>; <xref ref-type="bibr" rid="bib100">Sagiv et al., 2025</xref>). CMR-replay falls toward the latter end of the spectrum, providing a high-level description of a mechanism that accounts for replay phenomena without simulating realistic spiking, synaptic, or membrane potential mechanisms. Aspects of the model, such as its lack of regulation of the cumulative positive weight changes that can accrue through repeated replay, are biologically implausible (as biological learning results in both increases and decreases in synaptic weights) and limit the ability to engage with certain forms of low-level neural data (e.g. changes in spine density over sleep periods; <xref ref-type="bibr" rid="bib24">de Vivo et al., 2017</xref>; <xref ref-type="bibr" rid="bib75">Maret et al., 2011</xref>). It will be useful for future work to explore model variants with more elements of biological plausibility to help span across these styles of model and levels of analysis.</p><p>Our theory builds on a lineage of memory-focused models, demonstrating the power of this perspective in explaining phenomena that have often been attributed to the optimization of value-based predictions. In this work, we focus on CMR-replay, which exemplifies the memory-centric approach through a set of simple and interpretable mechanisms that we believe are broadly applicable across memory domains. Elements of CMR-replay share similarities with other models that adopt a memory-focused perspective. The model learns distributed context representations whose overlaps encode associations among items, echoing associative learning theories in which overlapping patterns capture stimulus similarity and learned associations (<xref ref-type="bibr" rid="bib80">Mclaren and Mackintosh, 2002</xref>). Context evolves through bidirectional interactions between items and their contextual representations, mirroring the dynamics found in recurrent neural networks (<xref ref-type="bibr" rid="bib43">Haga and Fukai, 2018</xref>; <xref ref-type="bibr" rid="bib63">Levenstein et al., 2024</xref>). These related approaches have not been shown to account for the present set of replay findings and lack mechanisms – such as reward-modulated encoding and experience-dependent suppression – that our simulations suggest are essential for capturing these phenomena, but we believe these mechanisms could be integrated into architectures like recurrent neural networks (<xref ref-type="bibr" rid="bib63">Levenstein et al., 2024</xref>) in the future to support a broader range of replay dynamics. Furthermore, by building on established models of memory retrieval, CMR-replay naturally aligns with recent theories, suggesting that offline reactivation and online retrieval may have similar underlying mechanisms and utility for behavior (<xref ref-type="bibr" rid="bib5">Antony et al., 2017</xref>). In sum, our theory unifies a wide range of empirical findings under a memory-focused account, offering an integrative and mechanistic framework for how the brain initially encodes and later replays memories to support behavior.</p></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Representation and initialization</title><p>CMR-replay comprises four components as in previous retrieved-context models (<xref ref-type="bibr" rid="bib47">Howard and Kahana, 2002</xref>; <xref ref-type="bibr" rid="bib97">Polyn et al., 2009</xref>): item (<inline-formula><alternatives><mml:math id="inf114"><mml:mi>f</mml:mi></mml:math><tex-math id="inft114">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula>), context (<inline-formula><alternatives><mml:math id="inf115"><mml:mi>c</mml:mi></mml:math><tex-math id="inft115">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula>), item-to-context associations (<inline-formula><alternatives><mml:math id="inf116"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft116">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula>), and context-to-item associations (<inline-formula><alternatives><mml:math id="inf117"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft117">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula>). During both awake encoding and replay, <inline-formula><alternatives><mml:math id="inf118"><mml:mi>f</mml:mi></mml:math><tex-math id="inft118">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula> represents the current item (i.e. an external input presented during awake learning or a reactivated item during replay). <inline-formula><alternatives><mml:math id="inf119"><mml:mi>c</mml:mi></mml:math><tex-math id="inft119">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula> represents a recency-weighted sum of contexts associated with past and present items. During both awake encoding and replay, CMR-replay associates each item with its current encoding context by updating two sets of weights <inline-formula><alternatives><mml:math id="inf120"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft120">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf121"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft121">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula>. <inline-formula><alternatives><mml:math id="inf122"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft122">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> represents item-to-context associations that support the retrieval of an item’s associated context. <inline-formula><alternatives><mml:math id="inf123"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft123">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> represents context-to-item associations that enable the retrieval of a context’s associated items.</p><p>CMR-replay employs a one-hot representation of <inline-formula><alternatives><mml:math id="inf124"><mml:mi>f</mml:mi></mml:math><tex-math id="inft124">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula> (i.e. a localist item representation): Each item is represented by a vector of length <inline-formula><alternatives><mml:math id="inf125"><mml:mi>n</mml:mi></mml:math><tex-math id="inft125">\begin{document}$n$\end{document}</tex-math></alternatives></inline-formula> in which only the unit representing the item is on (i.e. has an activity of 1) and all other units are off. As illustrated in <xref ref-type="fig" rid="fig1">Figure 1</xref>, in addition to task-related items shown as inputs during learning, we include task-irrelevant items that do not appear as inputs during awake encoding, but compete with task-relevant items for reactivation during replay, thereby introducing competition during retrieval and reactivation and mimicking memories of items that do not belong to an ongoing experiment. We use <inline-formula><alternatives><mml:math id="inf126"><mml:msub><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft126">\begin{document}$n_{task}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf127"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft127">\begin{document}$n_{non-task}$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf128"><mml:mi>n</mml:mi></mml:math><tex-math id="inft128">\begin{document}$n$\end{document}</tex-math></alternatives></inline-formula> to, respectively, denote the number of task-related items, the number of task-irrelevant items, and the total number of items (i.e. the sum of <inline-formula><alternatives><mml:math id="inf129"><mml:msub><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft129">\begin{document}$n_{task}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf130"><mml:msub><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft130">\begin{document}$n_{non-task}$\end{document}</tex-math></alternatives></inline-formula>). To allow for sufficient competition between task-related and task-irrelevant items, we set <inline-formula><alternatives><mml:math id="inf131"><mml:msub><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft131">\begin{document}$n_{non-task}$\end{document}</tex-math></alternatives></inline-formula> to be roughly one half of <inline-formula><alternatives><mml:math id="inf132"><mml:msub><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft132">\begin{document}$n_{task}$\end{document}</tex-math></alternatives></inline-formula> (i.e. rounded up when <inline-formula><alternatives><mml:math id="inf133"><mml:msub><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft133">\begin{document}$n_{task}$\end{document}</tex-math></alternatives></inline-formula> is odd). We note that the particular ratio of <inline-formula><alternatives><mml:math id="inf134"><mml:msub><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>−</mml:mo><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft134">\begin{document}$n_{non-task}$\end{document}</tex-math></alternatives></inline-formula> to <inline-formula><alternatives><mml:math id="inf135"><mml:msub><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft135">\begin{document}$n_{task}$\end{document}</tex-math></alternatives></inline-formula> is not critical to the pattern of results in our simulations.</p><p>In each simulation, <inline-formula><alternatives><mml:math id="inf136"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft136">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf137"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft137">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> are initialized as identity matrices of rank <inline-formula><alternatives><mml:math id="inf138"><mml:mi>n</mml:mi></mml:math><tex-math id="inft138">\begin{document}$n$\end{document}</tex-math></alternatives></inline-formula>, which are scaled, respectively, by 1.0 and 0.7. These scaling factors were chosen to qualitatively match the empirically observed proportions of forward and backward replay in different conditions (though the forward/backward asymmetry is always observed in the model). Our initialization of these two matrices as identity matrices differs from the initialization strategy in prior work (<xref ref-type="bibr" rid="bib19">Cohen and Kahana, 2022</xref>; <xref ref-type="bibr" rid="bib47">Howard and Kahana, 2002</xref>; <xref ref-type="bibr" rid="bib70">Lohnas et al., 2015</xref>; <xref ref-type="bibr" rid="bib97">Polyn et al., 2009</xref>), where <inline-formula><alternatives><mml:math id="inf139"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft139">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf140"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft140">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> are initialized to reflect pre-experimental similarity among items. Given such initializations, prior to learning, <inline-formula><alternatives><mml:math id="inf141"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft141">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> maps distinct items onto orthogonal context features, and <inline-formula><alternatives><mml:math id="inf142"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft142">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> maps each context feature to a different item. Before the model encodes each input sequence, <inline-formula><alternatives><mml:math id="inf143"><mml:mi>c</mml:mi></mml:math><tex-math id="inft143">\begin{document}$c$\end{document}</tex-math></alternatives></inline-formula> is reset as a zero vector of length <inline-formula><alternatives><mml:math id="inf144"><mml:mi>n</mml:mi></mml:math><tex-math id="inft144">\begin{document}$n$\end{document}</tex-math></alternatives></inline-formula>. Resetting contexts in between sequence presentations demarcates boundaries between discrete events as in prior work (<xref ref-type="bibr" rid="bib98">Pu et al., 2022</xref>).</p></sec><sec id="s4-2"><title>Awake encoding</title><sec id="s4-2-1"><title>Context drift</title><p>During awake encoding, the model encodes a sequence of distinct items by associating them with a drifting context. At each timestep <inline-formula><alternatives><mml:math id="inf145"><mml:mi>t</mml:mi></mml:math><tex-math id="inft145">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula>, CMR-replay retrieves the current item <inline-formula><alternatives><mml:math id="inf146"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft146">\begin{document}$f_{t}$\end{document}</tex-math></alternatives></inline-formula>’s associated context <inline-formula><alternatives><mml:math id="inf147"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft147">\begin{document}$c_{f_{t}}$\end{document}</tex-math></alternatives></inline-formula> via item-to-context matrix <inline-formula><alternatives><mml:math id="inf148"><mml:msubsup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msubsup></mml:math><tex-math id="inft148">\begin{document}$M^{fc}_{t-1}$\end{document}</tex-math></alternatives></inline-formula> (i.e. the <inline-formula><alternatives><mml:math id="inf149"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft149">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> matrix after the previous timestep) according to:<disp-formula id="equ1"><label>(1)</label><alternatives><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo stretchy="false">∥</mml:mo><mml:msubsup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">∥</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:math><tex-math id="t1">\begin{document}$$\displaystyle  c_{f_t}=\frac{M^{fc}_{t-1}f_{t}}{\parallel M^{fc}_{t-1}f_{t} \parallel}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Given <inline-formula><alternatives><mml:math id="inf150"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft150">\begin{document}$c_{f_{t}}$\end{document}</tex-math></alternatives></inline-formula>, the context layer incorporates <inline-formula><alternatives><mml:math id="inf151"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft151">\begin{document}$c_{f_{t}}$\end{document}</tex-math></alternatives></inline-formula> and downweights previous items’ associated contexts according to:<disp-formula id="equ2"><label>(2)</label><alternatives><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>ρ</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="t2">\begin{document}$$\displaystyle  c_{t}=\rho c_{t-1}+ \beta c_{f_t}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf152"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft152">\begin{document}$c_{t-1}$\end{document}</tex-math></alternatives></inline-formula> represents the context before <inline-formula><alternatives><mml:math id="inf153"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft153">\begin{document}$f_{t}$\end{document}</tex-math></alternatives></inline-formula> is presented. <inline-formula><alternatives><mml:math id="inf154"><mml:mi>ρ</mml:mi></mml:math><tex-math id="inft154">\begin{document}$\rho$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf155"><mml:mi>β</mml:mi></mml:math><tex-math id="inft155">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula> determine the relative contribution of <inline-formula><alternatives><mml:math id="inf156"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft156">\begin{document}$c_{t-1}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf157"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft157">\begin{document}$c_{f_{t}}$\end{document}</tex-math></alternatives></inline-formula> to <inline-formula><alternatives><mml:math id="inf158"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft158">\begin{document}$c_{t}$\end{document}</tex-math></alternatives></inline-formula>. To ensure that <inline-formula><alternatives><mml:math id="inf159"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft159">\begin{document}$c_{t}$\end{document}</tex-math></alternatives></inline-formula> has a unit length, <inline-formula><alternatives><mml:math id="inf160"><mml:mi>ρ</mml:mi></mml:math><tex-math id="inft160">\begin{document}$\rho$\end{document}</tex-math></alternatives></inline-formula> is computed according to:<disp-formula id="equ3"><label>(3)</label><alternatives><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>β</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">[</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:msqrt><mml:mo>−</mml:mo><mml:mi>β</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math><tex-math id="t3">\begin{document}$$\displaystyle  \rho=\sqrt{1+\beta^{2}[(c_{t-1}c_{f_t})^{2}-1]}-\beta(c_{t-1}c_{f_t})$$\end{document}</tex-math></alternatives></disp-formula></p><p>Therefore, the context layer is a drifting, recency-weighted average of contexts associated with items presented up to timestep <inline-formula><alternatives><mml:math id="inf161"><mml:mi>t</mml:mi></mml:math><tex-math id="inft161">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula>. Operations that drive context drift in our simulations, including those specified by <xref ref-type="disp-formula" rid="equ1 equ2 equ3">Equations 1–3</xref>, are identical to those in prior work (<xref ref-type="bibr" rid="bib19">Cohen and Kahana, 2022</xref>; <xref ref-type="bibr" rid="bib97">Polyn et al., 2009</xref>; <xref ref-type="bibr" rid="bib70">Lohnas et al., 2015</xref>). In all simulations, <inline-formula><alternatives><mml:math id="inf162"><mml:mi>β</mml:mi></mml:math><tex-math id="inft162">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula> is 0.75 (similar to drift rates for temporal context features reported in <xref ref-type="bibr" rid="bib97">Polyn et al., 2009</xref>), except when distractors cause context drift in the simulation of <xref ref-type="bibr" rid="bib65">Liu et al., 2019</xref>.</p></sec><sec id="s4-2-2"><title>Updating <inline-formula><alternatives><mml:math id="inf163"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft163">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf164"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft164">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula></title><p>Each time the context drifts, CMR-replay updates <inline-formula><alternatives><mml:math id="inf165"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft165">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf166"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft166">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> to strengthen associations between the current item (<inline-formula><alternatives><mml:math id="inf167"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft167">\begin{document}$f_{t}$\end{document}</tex-math></alternatives></inline-formula>) and context (<inline-formula><alternatives><mml:math id="inf168"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft168">\begin{document}$c_{t}$\end{document}</tex-math></alternatives></inline-formula>). The model updates <inline-formula><alternatives><mml:math id="inf169"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft169">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf170"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft170">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> using a standard Hebbian learning rule according to:<disp-formula id="equ4"><label>(4)</label><alternatives><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">△</mml:mi><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math><tex-math id="t4">\begin{document}$$\displaystyle  \triangle M^{fc}=\gamma_{fc}c_{t}f_{t}^{T}$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ5"><label>(5)</label><alternatives><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">△</mml:mi><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:math><tex-math id="t5">\begin{document}$$\displaystyle  \triangle M^{cf}=\gamma_{cf}f_{t}c_{t}^{T}$$\end{document}</tex-math></alternatives></disp-formula></p><p>in which <inline-formula><alternatives><mml:math id="inf171"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft171">\begin{document}$\gamma_{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf172"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft172">\begin{document}$\gamma_{cf}$\end{document}</tex-math></alternatives></inline-formula> control the rates at which <inline-formula><alternatives><mml:math id="inf173"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft173">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf174"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft174">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> are updated.</p></sec><sec id="s4-2-3"><title>Varying awake encoding rates according to salience</title><p>CMR-replay assumes that salience modulates the magnitude of <inline-formula><alternatives><mml:math id="inf175"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft175">\begin{document}$\gamma_{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf176"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft176">\begin{document}$\gamma_{cf}$\end{document}</tex-math></alternatives></inline-formula>. Building on prior work (<xref ref-type="bibr" rid="bib19">Cohen and Kahana, 2022</xref>; <xref ref-type="bibr" rid="bib119">Talmi et al., 2019</xref>), the model assumes that <inline-formula><alternatives><mml:math id="inf177"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft177">\begin{document}$\gamma_{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf178"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft178">\begin{document}$\gamma_{cf}$\end{document}</tex-math></alternatives></inline-formula> for awake encoding are higher for salient items, including those that are rewarding (i.e. directly associated with a reward) or novel (i.e. received less exposure), than for other items. Salience modulates <inline-formula><alternatives><mml:math id="inf179"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft179">\begin{document}$\gamma_{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf180"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft180">\begin{document}$\gamma_{cf}$\end{document}</tex-math></alternatives></inline-formula> only for the current item and context: It does not modify <inline-formula><alternatives><mml:math id="inf181"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft181">\begin{document}$\gamma_{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf182"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft182">\begin{document}$\gamma_{cf}$\end{document}</tex-math></alternatives></inline-formula> for items that precede the salient item. Higher encoding rates allow salient items to associate with their encoding contexts more quickly than other items. This shapes subsequent replay in two distinct ways. First, with a higher <inline-formula><alternatives><mml:math id="inf183"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft183">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> encoding rate for a salient item, the model will more strongly activate the item given its encoding context as a cue after awake encoding. Second, with a higher <inline-formula><alternatives><mml:math id="inf184"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft184">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> encoding rate, the model will be better able to faithfully retrieve the item’s encoding context after awake encoding. For all simulations, the base learning rates <inline-formula><alternatives><mml:math id="inf185"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft185">\begin{document}$\gamma_{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf186"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft186">\begin{document}$\gamma_{cf}$\end{document}</tex-math></alternatives></inline-formula> are 1.0. For rewarded items, learning rates vary according to the magnitude of reward: Learning rates <inline-formula><alternatives><mml:math id="inf187"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">w</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft187">\begin{document}$\gamma_{fc_{\mathrm{low}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf188"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">w</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft188">\begin{document}$\gamma_{cf_{\mathrm{low}}}$\end{document}</tex-math></alternatives></inline-formula> are 1.0 for items associated with low reward, <inline-formula><alternatives><mml:math id="inf189"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft189">\begin{document}$\gamma_{fc_{\mathrm{normal}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf190"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft190">\begin{document}$\gamma_{cf_{\mathrm{normal}}}$\end{document}</tex-math></alternatives></inline-formula> are 1.5 for those with standard reward, and <inline-formula><alternatives><mml:math id="inf191"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft191">\begin{document}$\gamma_{fc_{\mathrm{high}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf192"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft192">\begin{document}$\gamma_{cf_{\mathrm{high}}}$\end{document}</tex-math></alternatives></inline-formula> are 2.0 for those with high reward. These values are chosen to align with prior work (<xref ref-type="bibr" rid="bib19">Cohen and Kahana, 2022</xref>; <xref ref-type="bibr" rid="bib119">Talmi et al., 2019</xref>), in which these scaling factors are 1.0 for items that evoke no arousal (<xref ref-type="bibr" rid="bib19">Cohen and Kahana, 2022</xref>) and greater than 1.0 for those assumed to evoke emotional arousal (<xref ref-type="bibr" rid="bib19">Cohen and Kahana, 2022</xref>; <xref ref-type="bibr" rid="bib119">Talmi et al., 2019</xref>). When an input becomes less novel as it is repeated across sessions, its learning rate in the present session is <inline-formula><alternatives><mml:math id="inf193"><mml:mfrac><mml:mi>γ</mml:mi><mml:mi>i</mml:mi></mml:mfrac></mml:math><tex-math id="inft193">\begin{document}$\frac{\gamma}{i}$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf194"><mml:mi>i</mml:mi></mml:math><tex-math id="inft194">\begin{document}$i$\end{document}</tex-math></alternatives></inline-formula> is the index of the current session and <inline-formula><alternatives><mml:math id="inf195"><mml:mi>γ</mml:mi></mml:math><tex-math id="inft195">\begin{document}$\gamma$\end{document}</tex-math></alternatives></inline-formula> is its initial learning rate. The reduction in learning rates with repetition is important for maintaining a degree of stochasticity in the model’s replay during task repetition, since linearly increasing weights would, through the softmax choice rule, exponentially amplify differences in item reactivation probabilities, sharply reducing variability in replay.</p></sec></sec><sec id="s4-3"><title>Replay</title><p>After each session of awake encoding, CMR-replay autonomously reactivates items during a number of replay periods. For simplicity, we assumed that the number of replay periods is fixed, rather than determined by task-related variables.</p><sec id="s4-3-1"><title>Initial item reactivation</title><p>At the onset (i.e. <inline-formula><alternatives><mml:math id="inf196"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math><tex-math id="inft196">\begin{document}$t=0$\end{document}</tex-math></alternatives></inline-formula>) of each replay period, CMR-replay selects an item from a probability distribution <inline-formula><alternatives><mml:math id="inf197"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft197">\begin{document}$a_{0}$\end{document}</tex-math></alternatives></inline-formula>, which represents spontaneous activities across items during awake rest or sleep (<xref ref-type="fig" rid="fig1">Figure 1e</xref>). To simulate the relative lack of external sensory input in sleep, we fill <inline-formula><alternatives><mml:math id="inf198"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft198">\begin{document}$a_{0}$\end{document}</tex-math></alternatives></inline-formula> with random activities across all items. By contrast, for awake rest simulations, we make available an external context cue <inline-formula><alternatives><mml:math id="inf199"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft199">\begin{document}$c_{external}$\end{document}</tex-math></alternatives></inline-formula> (e.g. the task context of the animal’s current location) representing where the model is ‘resting’, which evokes additional activities that bias <inline-formula><alternatives><mml:math id="inf200"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft200">\begin{document}$a_{0}$\end{document}</tex-math></alternatives></inline-formula> toward the item most strongly associated with the context cue. Concretely, in <inline-formula><alternatives><mml:math id="inf201"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft201">\begin{document}$a_{0}$\end{document}</tex-math></alternatives></inline-formula>, the activity of <italic>i</italic>th unit is:<disp-formula id="equ6"><label>(6)</label><alternatives><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi>o</mml:mi><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi>o</mml:mi><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mstyle></mml:math><tex-math id="t6">\begin{document}$$\displaystyle  [a_{0}]_{i} = \frac{[{a_{0}}^{random}+ \lambda{a_{0}}^{evoked}]_{i}}{\sum_{j=1}^{n}[{a_{0}}^{random}+ \lambda{a_{0}}^{evoked}]_{j}}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf202"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft202">\begin{document}${a_{0}}^{random}$\end{document}</tex-math></alternatives></inline-formula> represents internal activity that we simulated as random noise, <inline-formula><alternatives><mml:math id="inf203"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi>o</mml:mi><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft203">\begin{document}${a_{0}}^{evoked}$\end{document}</tex-math></alternatives></inline-formula> is activity that <inline-formula><alternatives><mml:math id="inf204"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft204">\begin{document}$c_{external}$\end{document}</tex-math></alternatives></inline-formula> evokes according to <xref ref-type="disp-formula" rid="equ7">Equation 7</xref>, and <inline-formula><alternatives><mml:math id="inf205"><mml:mi>n</mml:mi></mml:math><tex-math id="inft205">\begin{document}$n$\end{document}</tex-math></alternatives></inline-formula> is the total number of items in a simulation. <inline-formula><alternatives><mml:math id="inf206"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft206">\begin{document}${a_{0}}^{random}$\end{document}</tex-math></alternatives></inline-formula> is a vector of size <inline-formula><alternatives><mml:math id="inf207"><mml:mi>n</mml:mi></mml:math><tex-math id="inft207">\begin{document}$n$\end{document}</tex-math></alternatives></inline-formula> whose elements are independently and uniformly drawn from the interval [0, 0.001]. CMR-replay samples an item <inline-formula><alternatives><mml:math id="inf208"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft208">\begin{document}$f_{0}$\end{document}</tex-math></alternatives></inline-formula> from <inline-formula><alternatives><mml:math id="inf209"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft209">\begin{document}$a_{0}$\end{document}</tex-math></alternatives></inline-formula> for the initial item reactivation.</p></sec><sec id="s4-3-2"><title>Subsequent reactivations</title><p>Given <inline-formula><alternatives><mml:math id="inf210"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft210">\begin{document}$f_{0}$\end{document}</tex-math></alternatives></inline-formula>, the model reinstates its associated context as <inline-formula><alternatives><mml:math id="inf211"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft211">\begin{document}$c_{0}$\end{document}</tex-math></alternatives></inline-formula> according to <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> (<xref ref-type="fig" rid="fig1">Figure 1f</xref>). This allows the model to engage in a series of autonomous reactivations (<xref ref-type="fig" rid="fig1">Figure 1a</xref>).</p><p>At each timestep <inline-formula><alternatives><mml:math id="inf212"><mml:mi>t</mml:mi><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:math><tex-math id="inft212">\begin{document}$t\geq 1$\end{document}</tex-math></alternatives></inline-formula>, CMR-replay reactivates another item without replacement (i.e. by excluding items reactivated at previous timesteps). In particular, the model uses the previous context <inline-formula><alternatives><mml:math id="inf213"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft213">\begin{document}$c_{t-1}$\end{document}</tex-math></alternatives></inline-formula> as a context cue to evoke a probability distribution <inline-formula><alternatives><mml:math id="inf214"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft214">\begin{document}$a_{t}$\end{document}</tex-math></alternatives></inline-formula> that excludes items reactivated prior to <inline-formula><alternatives><mml:math id="inf215"><mml:mi>t</mml:mi></mml:math><tex-math id="inft215">\begin{document}$t$\end{document}</tex-math></alternatives></inline-formula>. Let <inline-formula><alternatives><mml:math id="inf216"><mml:msub><mml:mi>U</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft216">\begin{document}$U_{t}$\end{document}</tex-math></alternatives></inline-formula> denote the set of items that have not yet been reactivated. The probability of each item in <inline-formula><alternatives><mml:math id="inf217"><mml:msub><mml:mi>U</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft217">\begin{document}$U_{t}$\end{document}</tex-math></alternatives></inline-formula> is:<disp-formula id="equ7"><label>(7)</label><alternatives><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi>o</mml:mi><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">∀</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:msub><mml:mi>U</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munder><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">[</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:math><tex-math id="t7">\begin{document}$$\displaystyle  {[a_{t}^{evoked}}]_{i}= \frac{\exp([{M^{cf}c_{cue}}]_{i}/T_{t})}{\sum_{\forall f_j\in U_{t}}\exp({[M^{cf}c_{cue}}]_{j}/T_{t})}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf218"><mml:msub><mml:mi>T</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft218">\begin{document}$T_{t}$\end{document}</tex-math></alternatives></inline-formula> is a temperature parameter that scales the relative difference of activities in <inline-formula><alternatives><mml:math id="inf219"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msup><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi>o</mml:mi><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft219">\begin{document}${a_{t}}^{evoked}$\end{document}</tex-math></alternatives></inline-formula> is 0.1 and <inline-formula><alternatives><mml:math id="inf220"><mml:msub><mml:mi>T</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft220">\begin{document}$T_{t}$\end{document}</tex-math></alternatives></inline-formula> is 0.14 for all <inline-formula><alternatives><mml:math id="inf221"><mml:mi>t</mml:mi><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:math><tex-math id="inft221">\begin{document}$t\geq 1$\end{document}</tex-math></alternatives></inline-formula>. For <inline-formula><alternatives><mml:math id="inf222"><mml:mi>t</mml:mi><mml:mo>≥</mml:mo><mml:mn>1</mml:mn></mml:math><tex-math id="inft222">\begin{document}$t\geq 1$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf223"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft223">\begin{document}$c_{cue}=c_{t-1}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf224"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi>o</mml:mi><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft224">\begin{document}$a_{t}={a_{t}}^{evoked}$\end{document}</tex-math></alternatives></inline-formula>. In contrast, at <inline-formula><alternatives><mml:math id="inf225"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math><tex-math id="inft225">\begin{document}$t=0$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf226"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft226">\begin{document}$c_{cue}=c_{external}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf227"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft227">\begin{document}$a_{0}$\end{document}</tex-math></alternatives></inline-formula> is a combination of <inline-formula><alternatives><mml:math id="inf228"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft228">\begin{document}${a_{0}}^{random}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf229"><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi>o</mml:mi><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft229">\begin{document}${a_{0}}^{evoked}$\end{document}</tex-math></alternatives></inline-formula>. Based on <xref ref-type="disp-formula" rid="equ7">Equation 7</xref>, all <inline-formula><alternatives><mml:math id="inf230"><mml:msub><mml:mi>U</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft230">\begin{document}$U_{t}$\end{document}</tex-math></alternatives></inline-formula> items have nonzero activity in <inline-formula><alternatives><mml:math id="inf231"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft231">\begin{document}$a_{t}$\end{document}</tex-math></alternatives></inline-formula>. From <inline-formula><alternatives><mml:math id="inf232"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft232">\begin{document}$a_{t}$\end{document}</tex-math></alternatives></inline-formula>, the model samples an item <inline-formula><alternatives><mml:math id="inf233"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft233">\begin{document}$f_{t}$\end{document}</tex-math></alternatives></inline-formula>.</p><p>Given <inline-formula><alternatives><mml:math id="inf234"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft234">\begin{document}$f_{t}$\end{document}</tex-math></alternatives></inline-formula>, the model performs three operations that parallel the operations performed during awake encoding. First, it reinstates <inline-formula><alternatives><mml:math id="inf235"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft235">\begin{document}$f_{t}$\end{document}</tex-math></alternatives></inline-formula>’s associated context <inline-formula><alternatives><mml:math id="inf236"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft236">\begin{document}$c_{f_{t}}$\end{document}</tex-math></alternatives></inline-formula> via <inline-formula><alternatives><mml:math id="inf237"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft237">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> according to <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>. Then, <inline-formula><alternatives><mml:math id="inf238"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft238">\begin{document}$c_{f_{t}}$\end{document}</tex-math></alternatives></inline-formula> induces a drift in context according to <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>, forming a new context <inline-formula><alternatives><mml:math id="inf239"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft239">\begin{document}$c_{t}$\end{document}</tex-math></alternatives></inline-formula>, which will guide the reactivation at the next timestep. Finally, the model strengthens the association between <inline-formula><alternatives><mml:math id="inf240"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft240">\begin{document}$f_{t}$\end{document}</tex-math></alternatives></inline-formula> and the current context <inline-formula><alternatives><mml:math id="inf241"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft241">\begin{document}$c_{t}$\end{document}</tex-math></alternatives></inline-formula> by updating <inline-formula><alternatives><mml:math id="inf242"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft242">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf243"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft243">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> according to <xref ref-type="disp-formula" rid="equ4">Equation 4</xref> and <xref ref-type="disp-formula" rid="equ5">Equation 5</xref>. Compared to awake encoding, the model performs these updates at a slower learning rate <inline-formula><alternatives><mml:math id="inf244"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft244">\begin{document}$\gamma_{replay}$\end{document}</tex-math></alternatives></inline-formula> of 0.001 during replay. This slower learning rate allows replay to preserve and strengthen memories despite the noisy nature of replay sequences.</p><p>At each timestep, the replay period ends either with a stop probability of 0.1, an arbitrary choice made to constrain replay episode length probabilistically, or if a task-irrelevant item becomes reactivated. Future work could explore the implications of varying this parameter more systematically. Following prior work (<xref ref-type="bibr" rid="bib77">Mattar and Daw, 2018</xref>), we consider replayed sequences (one per replay period) with consecutive segments of length five or greater that preserve the contiguity of wake inputs as replay events.</p></sec><sec id="s4-3-3"><title>An experience-dependent suppression mechanism</title><p>CMR-replay employs a mechanism that suppresses the activity of items in <inline-formula><alternatives><mml:math id="inf245"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft245">\begin{document}$a_{0}$\end{document}</tex-math></alternatives></inline-formula> according to the magnitude of context activity in the preceding awake encoding period. This mechanism differs from related mechanisms in prior work (<xref ref-type="bibr" rid="bib70">Lohnas et al., 2015</xref>; <xref ref-type="bibr" rid="bib97">Polyn et al., 2009</xref>), which scale the degree of competition among items during recall. This experience-dependent suppression mechanism is distinct from the reduction of learning rates through repetition; it does not modulate the update of memory associations but exclusively governs which items are most likely to initiate replay. For each item <inline-formula><alternatives><mml:math id="inf246"><mml:mi>f</mml:mi></mml:math><tex-math id="inft246">\begin{document}$f$\end{document}</tex-math></alternatives></inline-formula> presented in a wake learning session, its activity in <inline-formula><alternatives><mml:math id="inf247"><mml:msub><mml:mi>a</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft247">\begin{document}$a_{0}$\end{document}</tex-math></alternatives></inline-formula> is multiplied by:<disp-formula id="equ8"><label>(8)</label><alternatives><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ω</mml:mi><mml:mo>=</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math><tex-math id="t8">\begin{document}$$\displaystyle  \omega=exp(-|| c_{f}||)$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf248"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math><tex-math id="inft248">\begin{document}$||c_{f}||$\end{document}</tex-math></alternatives></inline-formula> is the Euclidean norm of the item’s retrieved context vector <inline-formula><alternatives><mml:math id="inf249"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft249">\begin{document}$c_{f}$\end{document}</tex-math></alternatives></inline-formula> in the recent wake learning session given by:<disp-formula id="equ9"><label>(9)</label><alternatives><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msqrt><mml:munderover><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>m</mml:mi></mml:mrow></mml:munderover><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:msqrt></mml:mstyle></mml:math><tex-math id="t9">\begin{document}$$\displaystyle  || c_{f}|| = \sqrt{\sum_{i=1}^{m}{{c_{f}}_{i}}^{2}}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf250"><mml:mi>m</mml:mi></mml:math><tex-math id="inft250">\begin{document}$m$\end{document}</tex-math></alternatives></inline-formula> is the number of units in <inline-formula><alternatives><mml:math id="inf251"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft251">\begin{document}$c_{f}$\end{document}</tex-math></alternatives></inline-formula>. For items not shown in the wake session, <inline-formula><alternatives><mml:math id="inf252"><mml:mi>C</mml:mi></mml:math><tex-math id="inft252">\begin{document}$C$\end{document}</tex-math></alternatives></inline-formula> is 0.0 and thus <inline-formula><alternatives><mml:math id="inf253"><mml:mi>ω</mml:mi></mml:math><tex-math id="inft253">\begin{document}$\omega$\end{document}</tex-math></alternatives></inline-formula> is 1.0.</p></sec></sec><sec id="s4-4"><title>Task simulations</title><p>During awake learning, CMR-replay encodes sequences of items, representing spatial trajectories or other stimulus sequences (<xref ref-type="fig" rid="fig7">Figure 7</xref>). After awake encoding, the model participates in a number of awake rest or sleep replay periods. In each simulation, for each condition, we ran 100 instantiations of the model with the same initialization. Across these replay periods, each of which produces one reactivated sequence, we compute the proportion of sequences that qualify as significant replay events. As described above, a significant replay event is defined as a reactivated sequence that includes a consecutive segment of five or more items that preserves the contiguity of the wake inputs. For simulations assessing forward vs. backward replay sequences, we further report the proportion of significant replay events occurring in the forward direction (i.e. in the same order as the wake inputs) and the backward direction, where the order is reversed. Variability in replay sequences across models arises from the stochastic nature of the replay process. Due to the variability in replay sequences, different models develop distinct <inline-formula><alternatives><mml:math id="inf254"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft254">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf255"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft255">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> as they learn from replay. Unlike prior work that identified the best-fitting parameters for each simulation (<xref ref-type="bibr" rid="bib97">Polyn et al., 2009</xref>; <xref ref-type="bibr" rid="bib70">Lohnas et al., 2015</xref>; <xref ref-type="bibr" rid="bib19">Cohen and Kahana, 2022</xref>), CMR-replay employs the same set of model parameters across simulations with varying input structures.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Task simulations.</title><p>Each enclosed box corresponds to a unique item. Each arrow represents a valid transition between two items. Each dashed arrow represents a distractor that causes a drift in context between two items. Task sequences initiate at light gray boxes. Dark gray boxes represent salient items in each task. For tasks with multiple valid sequences, the order in which sequences are presented is randomized. (<bold>a</bold>) Simulation of a linear track. (<bold>b</bold>) Simulation of the task in <xref ref-type="bibr" rid="bib66">Liu et al., 2021</xref>. (<bold>c</bold>) Simulation of a two-choice T-maze. (<bold>d</bold>) Simulation of a T-maze. (<bold>e</bold>) Simulation of the task in <xref ref-type="bibr" rid="bib10">Bendor and Wilson, 2012</xref>. (<bold>f</bold>) Simulation of a linear track task with distinct directions of travel. (<bold>g</bold>) Simulation of input sequences in <xref ref-type="bibr" rid="bib65">Liu et al., 2019</xref>. (<bold>h</bold>) Simulation of a fixed-item sequence.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99931-fig7-v1.tif"/></fig><p>In the simulation that examines context-dependent forward and backward replay through experience (<xref ref-type="fig" rid="fig2">Figures 2a</xref> and <xref ref-type="fig" rid="fig5">5a</xref>), CMR-replay encodes an input sequence shown in <xref ref-type="fig" rid="fig7">Figure 7a</xref>, which simulates a linear track run with no ambiguity in the direction of inputs, over eight awake learning sessions (as in <xref ref-type="bibr" rid="bib111">Shin et al., 2019</xref>). In this simulation, learning rates for the rewarded item are <inline-formula><alternatives><mml:math id="inf256"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft256">\begin{document}$\gamma_{fc_{\mathrm{normal}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf257"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft257">\begin{document}$\gamma_{cf_{\mathrm{normal}}}$\end{document}</tex-math></alternatives></inline-formula>. After each wake learning session, we simulate 500 awake rest replay periods at the end of a run followed by another 500 periods at the start of a run. For rest at the end of a run, <inline-formula><alternatives><mml:math id="inf258"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft258">\begin{document}$c_{external}$\end{document}</tex-math></alternatives></inline-formula> is the context associated with the final item in the sequence. For rest at the start of a run, <inline-formula><alternatives><mml:math id="inf259"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft259">\begin{document}$c_{external}$\end{document}</tex-math></alternatives></inline-formula> is the context associated with the start item. In this simulation, the learning rates progressively decrease across sessions, as described above. The proportion of replay shown in <xref ref-type="fig" rid="fig2">Figure 2a</xref> represents the proportion of reactivated sequences categorized as significant forward vs. backward replay sequences. <xref ref-type="fig" rid="fig5">Figure 5a</xref> depicts the mean number of significant replay sequences per replay period.</p><p>In the simulation that contrasts forward and backward replay between rest and sleep (<xref ref-type="fig" rid="fig2">Figure 2b</xref>), the model encodes the input sequence shown in <xref ref-type="fig" rid="fig7">Figure 7a</xref> for a single session. After encoding, each model either participates in 1000 awake rest or sleep replay periods, with 100 models in each condition (i.e. awake rest or sleep). <xref ref-type="fig" rid="fig2">Figure 2b</xref> reports the proportion of significant replay sequences categorized as forward replay.</p><p>In the simulation of TMR (<xref ref-type="fig" rid="fig2">Figure 2c</xref>), each model encodes two sequences shown in <xref ref-type="fig" rid="fig7">Figure 7e</xref> in a randomized order in a session of wake learning. During input presentation, for each sequence, a separate cue item (cue L or cue R) is presented immediately after the start item. The models encode the goal item at rates <inline-formula><alternatives><mml:math id="inf260"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft260">\begin{document}$\gamma_{fc_{\mathrm{normal}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf261"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft261">\begin{document}$\gamma_{cf_{\mathrm{normal}}}$\end{document}</tex-math></alternatives></inline-formula>. After wake learning, each model engages in 500 sleep replay periods. In each replay period, the context associated with cue L or cue R is randomly presented as <inline-formula><alternatives><mml:math id="inf262"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft262">\begin{document}$c_{external}$\end{document}</tex-math></alternatives></inline-formula>. <xref ref-type="fig" rid="fig2">Figure 2c</xref> presents the proportion of significant replay sequences corresponding to the sequence associated with cue L vs. that associated with cue R.</p><p>In the simulation that contrasts replay of rewarded vs. non-rewarded items (<xref ref-type="fig" rid="fig3">Figures 3a</xref> and <xref ref-type="fig" rid="fig6">6b</xref>), each model encodes two sequences shown in <xref ref-type="fig" rid="fig7">Figure 7d</xref> in a randomized order in a session of wake learning. The models encode the goal item at rates <inline-formula><alternatives><mml:math id="inf263"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft263">\begin{document}$\gamma_{fc_{\mathrm{normal}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf264"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft264">\begin{document}$\gamma_{cf_{\mathrm{normal}}}$\end{document}</tex-math></alternatives></inline-formula>. After wake learning, each model engages in an extended phase with 5000 sleep replay periods. To quantify changes in memory through sleep, in each model, we additionally simulated 5000 replay periods before and after extended sleep with no learning (i.e. <inline-formula><alternatives><mml:math id="inf265"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft265">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf266"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft266">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> are not updated) and no <inline-formula><alternatives><mml:math id="inf267"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft267">\begin{document}$c_{external}$\end{document}</tex-math></alternatives></inline-formula>. <xref ref-type="fig" rid="fig3">Figure 3a</xref> presents the proportion of replay periods reactivating the rewarded goal vs. the non-rewarded goal.</p><p>In the simulation of forward and backward replay with different levels of reward (<xref ref-type="fig" rid="fig3">Figure 3b</xref>), the model encodes two sequences (<xref ref-type="fig" rid="fig7">Figure 7f</xref>) in a randomized order in a single session. The inclusion of two disjoint sequences follows the approach in <xref ref-type="bibr" rid="bib77">Mattar and Daw, 2018</xref>, which simulates different directions of travel to distinguish place cells with directional preference for replay decoding in animal studies. The simulation consists of three conditions: normal vs. normal reward, low vs. normal reward, and high vs. normal reward. In the normal vs. normal condition, each model encodes goal locations in both sequences at rates <inline-formula><alternatives><mml:math id="inf268"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft268">\begin{document}$\gamma_{fc_{\mathrm{normal}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf269"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft269">\begin{document}$\gamma_{cf_{\mathrm{normal}}}$\end{document}</tex-math></alternatives></inline-formula>. In the low vs. normal condition, each model encodes the goal location at rates <inline-formula><alternatives><mml:math id="inf270"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">w</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft270">\begin{document}$\gamma_{fc_{\mathrm{low}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf271"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">w</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft271">\begin{document}$\gamma_{cf_{\mathrm{low}}}$\end{document}</tex-math></alternatives></inline-formula> for one sequence and at rates <inline-formula><alternatives><mml:math id="inf272"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft272">\begin{document}$\gamma_{fc_{\mathrm{normal}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf273"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft273">\begin{document}$\gamma_{cf_{\mathrm{normal}}}$\end{document}</tex-math></alternatives></inline-formula> for the other. Finally, in the high vs. normal condition, each model encodes the goal location at rates <inline-formula><alternatives><mml:math id="inf274"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft274">\begin{document}$\gamma_{fc_{\mathrm{high}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf275"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft275">\begin{document}$\gamma_{cf_{\mathrm{high}}}$\end{document}</tex-math></alternatives></inline-formula> for one sequence and at rates <inline-formula><alternatives><mml:math id="inf276"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft276">\begin{document}$\gamma_{fc_{\mathrm{normal}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf277"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft277">\begin{document}$\gamma_{cf_{\mathrm{normal}}}$\end{document}</tex-math></alternatives></inline-formula> for the other. After encoding a sequence, we simulate 500 awake rest replay periods at the end of a run followed by another 500 at the start of a run. <xref ref-type="fig" rid="fig3">Figure 3b</xref> presents relative differences in the proportion of significant replay sequences that are categorized as forward vs. backward.</p><p>In the simulation of remote replay, shortcut replay, and the over-representation of non-behaviorally preferred experiences in replay (<xref ref-type="fig" rid="fig4">Figures 4b, c</xref>, <xref ref-type="fig" rid="fig5">5c</xref>), each model encodes two sequences (<xref ref-type="fig" rid="fig7">Figure 7c</xref>) in a randomized order in a total of three sessions. Learning rates for each goal location are <inline-formula><alternatives><mml:math id="inf278"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft278">\begin{document}$\gamma_{fc_{\mathrm{normal}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf279"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft279">\begin{document}$\gamma_{cf_{\mathrm{normal}}}$\end{document}</tex-math></alternatives></inline-formula>. In these simulations, we treat the first two sessions as the period in which an animal is pre-trained extensively on the task. After wake learning in the third session, for the results shown in <xref ref-type="fig" rid="fig4">Figure 4b</xref>, each model engages in 500 awake rest replay periods at each of the four goal locations in a randomized order. For the results shown in <xref ref-type="fig" rid="fig5">Figure 5c</xref>, to simulate replay away from the task environment, each model engages in 500 replay periods with no external context cue. <xref ref-type="fig" rid="fig4">Figure 4c</xref> presents the proportion of significant replay sequences that are categorized as remote replay.</p><p>In the simulation of <xref ref-type="bibr" rid="bib65">Liu et al., 2019</xref>; <xref ref-type="fig" rid="fig4">Figure 4d</xref>, each model encodes three sequences (<xref ref-type="fig" rid="fig7">Figure 7g</xref>) shown in a randomized order. These three sequences <inline-formula><alternatives><mml:math id="inf280"><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft280">\begin{document}$X_{1}X_{2}Y_{1}Y_{2}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf281"><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft281">\begin{document}$X_{2}X_{3}Y_{2}Y_{3}$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf282"><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>4</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft282">\begin{document}$X_{3}X_{4}Y_{3}Y_{4}$\end{document}</tex-math></alternatives></inline-formula> are scrambled versions of pairwise transitions from true sequences <inline-formula><alternatives><mml:math id="inf283"><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>X</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft283">\begin{document}$X_{1}X_{2}X_{3}X_{4}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf284"><mml:msub><mml:mi>Y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>Y</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>4</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft284">\begin{document}$Y_{1}Y_{2}Y_{3}Y_{4}$\end{document}</tex-math></alternatives></inline-formula>. A distractor item, which is a distinct item that does not participate in replay, induces context drift between successive items. The item induces context drift at a <inline-formula><alternatives><mml:math id="inf285"><mml:mi>β</mml:mi></mml:math><tex-math id="inft285">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula> of 0.3 for transitions that exist in the true sequences and at a <inline-formula><alternatives><mml:math id="inf286"><mml:mi>β</mml:mi></mml:math><tex-math id="inft286">\begin{document}$\beta$\end{document}</tex-math></alternatives></inline-formula> of 0.99 for transitions that do not exist in the true sequences (simulating the longer interstimulus interval between these transitions in the experiment). <xref ref-type="fig" rid="fig4">Figure 4d</xref> shows the proportion of replay sequences categorized as significant replay sequences matching the true vs. scrambled sequences.</p><p>In the simulation that examines sequence memory through sleep (<xref ref-type="fig" rid="fig6">Figure 6a</xref>), each model encodes a five-item sequence (<xref ref-type="fig" rid="fig7">Figure 7h</xref>) in a session. After wake learning, each model participates in an extended period of sleep with 5000 replay periods. In each model, we additionally simulated 5000 replay periods before and after extended sleep with no learning (i.e. <inline-formula><alternatives><mml:math id="inf287"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft287">\begin{document}$M^{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf288"><mml:msup><mml:mi>M</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msup></mml:math><tex-math id="inft288">\begin{document}$M^{cf}$\end{document}</tex-math></alternatives></inline-formula> are not updated) and no <inline-formula><alternatives><mml:math id="inf289"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft289">\begin{document}$c_{external}$\end{document}</tex-math></alternatives></inline-formula>. <xref ref-type="fig" rid="fig6">Figure 6a</xref> shows the proportion of replay sequences categorized as significant replay sequences matching the five-item sequence both prior to and following sleep.</p><p>In the simulation that examines replay’s role in non-local learning (<xref ref-type="fig" rid="fig6">Figure 6c</xref>), each model encodes six sequences (<xref ref-type="fig" rid="fig7">Figure 7b</xref>) in a randomized order in a session. Sequences in this simulation consist of three start states and two end states. Each start state has a unique sequence that connects it to each of the two end states. The model encodes the final item in the final sequence at rates <inline-formula><alternatives><mml:math id="inf290"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft290">\begin{document}$\gamma_{fc_{\mathrm{high}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf291"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft291">\begin{document}$\gamma_{cf_{\mathrm{high}}}$\end{document}</tex-math></alternatives></inline-formula> and encodes all other items at base learning rates <inline-formula><alternatives><mml:math id="inf292"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:mi>c</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft292">\begin{document}$\gamma_{fc}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf293"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft293">\begin{document}$\gamma_{cf}$\end{document}</tex-math></alternatives></inline-formula>. After the encoding of all six sequences, each model participates in 5000 awake rest replay periods with the final item’s associated context as <inline-formula><alternatives><mml:math id="inf294"><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft294">\begin{document}$c_{external}$\end{document}</tex-math></alternatives></inline-formula>. Before and after the rest period, we evaluated the model’s preference for non-local sequence trajectories associated with rewarded items. Specifically, we assessed the model’s activation of each non-local start item’s two ensuing items given the start item’s associated context as a cue. These activations were then normalized into a probability distribution using a softmax transformation, providing a measure of the model’s choice preference between the reward-associated path and the non-rewarded path. <xref ref-type="fig" rid="fig6">Figure 6c</xref> illustrates how these probabilities change through rest.</p><p>In the simulation of teacher and student CMR-replay (<xref ref-type="fig" rid="fig6">Figure 6d</xref>), each teacher model encodes a sequence (<xref ref-type="fig" rid="fig7">Figure 7a</xref>) in a session. Teacher models encode the goal location at learning rates <inline-formula><alternatives><mml:math id="inf295"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>f</mml:mi><mml:msub><mml:mi>c</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft295">\begin{document}$\gamma_{fc_{\mathrm{normal}}}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf296"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>c</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:math><tex-math id="inft296">\begin{document}$\gamma_{cf_{\mathrm{normal}}}$\end{document}</tex-math></alternatives></inline-formula>. After wake learning, we simulate an extended period of sleep with 5000 replay periods in each model. We then present each teacher model’s 5000 replayed sequences as inputs to train a different blank-slate student model with learning rates <inline-formula><alternatives><mml:math id="inf297"><mml:msub><mml:mi>γ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft297">\begin{document}$\gamma_{replay}$\end{document}</tex-math></alternatives></inline-formula>. As described in <xref ref-type="fig" rid="fig6">Figure 6d</xref>, we computed the conditional probability that, following the reactivation of the <italic>i</italic>th item, the model immediately reactivates the item at position <italic>i</italic> + lag, given that the <italic>i</italic>th item was available for reactivation.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Formal analysis, Supervision, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Formal analysis, Supervision, Methodology, Writing – original draft, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-99931-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>This work is a computational modeling study, so no data were generated for this manuscript. The modeling code used to run all simulations in this study is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/schapirolab/CMR-replay">https://github.com/schapirolab/CMR-replay</ext-link> (copy archived at <xref ref-type="bibr" rid="bib105">schapirolab, 2025</xref>).</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alvarez</surname><given-names>P</given-names></name><name><surname>Squire</surname><given-names>LR</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Memory consolidation and the medial temporal lobe: a simple network model</article-title><source>PNAS</source><volume>91</volume><fpage>7041</fpage><lpage>7045</lpage><pub-id pub-id-type="doi">10.1073/pnas.91.15.7041</pub-id><pub-id pub-id-type="pmid">8041742</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ambrose</surname><given-names>RE</given-names></name><name><surname>Pfeiffer</surname><given-names>BE</given-names></name><name><surname>Foster</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Reverse replay of hippocampal place cells is uniquely modulated by changing reward</article-title><source>Neuron</source><volume>91</volume><fpage>1124</fpage><lpage>1136</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.07.047</pub-id><pub-id pub-id-type="pmid">27568518</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Affective influences on the attentional dynamics supporting awareness</article-title><source>Journal of Experimental Psychology. General</source><volume>134</volume><fpage>258</fpage><lpage>281</lpage><pub-id pub-id-type="doi">10.1037/0096-3445.134.2.258</pub-id><pub-id pub-id-type="pmid">15869349</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ans</surname><given-names>B</given-names></name><name><surname>Rousset</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Neural networks with a self-refreshing memory: Knowledge transfer in sequential learning tasks without catastrophic forgetting</article-title><source>Connection Science</source><volume>12</volume><fpage>1</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1080/095400900116177</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Antony</surname><given-names>JW</given-names></name><name><surname>Ferreira</surname><given-names>CS</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Wimber</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Retrieval as a fast route to memory consolidation</article-title><source>Trends in Cognitive Sciences</source><volume>21</volume><fpage>573</fpage><lpage>576</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.05.001</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Antony</surname><given-names>JW</given-names></name><name><surname>Schapiro</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Active and effective replay: systems consolidation reconsidered again</article-title><source>Nature Reviews Neuroscience</source><volume>20</volume><fpage>506</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1038/s41583-019-0191-8</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Asfestani</surname><given-names>MA</given-names></name><name><surname>Brechtmann</surname><given-names>V</given-names></name><name><surname>Santiago</surname><given-names>J</given-names></name><name><surname>Peter</surname><given-names>A</given-names></name><name><surname>Born</surname><given-names>J</given-names></name><name><surname>Feld</surname><given-names>GB</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Consolidation of reward memory during sleep does not require dopaminergic activation</article-title><source>Journal of Cognitive Neuroscience</source><volume>32</volume><fpage>1688</fpage><lpage>1703</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01585</pub-id><pub-id pub-id-type="pmid">32459129</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barron</surname><given-names>HC</given-names></name><name><surname>Reeve</surname><given-names>HM</given-names></name><name><surname>Koolschijn</surname><given-names>RS</given-names></name><name><surname>Perestenko</surname><given-names>PV</given-names></name><name><surname>Shpektor</surname><given-names>A</given-names></name><name><surname>Nili</surname><given-names>H</given-names></name><name><surname>Rothaermel</surname><given-names>R</given-names></name><name><surname>Campo-Urriza</surname><given-names>N</given-names></name><name><surname>O’Reilly</surname><given-names>JX</given-names></name><name><surname>Bannerman</surname><given-names>DM</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Dupret</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neuronal computation underlying inferential reasoning in humans and mice</article-title><source>Cell</source><volume>183</volume><fpage>228</fpage><lpage>243</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.08.035</pub-id><pub-id pub-id-type="pmid">32946810</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barry</surname><given-names>DN</given-names></name><name><surname>Love</surname><given-names>BC</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A neural network account of memory replay and knowledge consolidation</article-title><source>Cerebral Cortex</source><volume>33</volume><fpage>83</fpage><lpage>95</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhac054</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bendor</surname><given-names>D</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Biasing the content of hippocampal replay during sleep</article-title><source>Nature Neuroscience</source><volume>15</volume><fpage>1439</fpage><lpage>1444</lpage><pub-id pub-id-type="doi">10.1038/nn.3203</pub-id><pub-id pub-id-type="pmid">22941111</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berners-Lee</surname><given-names>A</given-names></name><name><surname>Feng</surname><given-names>T</given-names></name><name><surname>Silva</surname><given-names>D</given-names></name><name><surname>Wu</surname><given-names>X</given-names></name><name><surname>Ambrose</surname><given-names>ER</given-names></name><name><surname>Pfeiffer</surname><given-names>BE</given-names></name><name><surname>Foster</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Hippocampal replays appear after a single experience and incorporate greater detail with more experience</article-title><source>Neuron</source><volume>110</volume><fpage>1829</fpage><lpage>1842</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2022.03.010</pub-id><pub-id pub-id-type="pmid">35381188</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blum</surname><given-names>KI</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>A model of spatial map formation in the hippocampus of the rat</article-title><source>Neural Computation</source><volume>8</volume><fpage>85</fpage><lpage>93</lpage><pub-id pub-id-type="doi">10.1162/neco.1996.8.1.85</pub-id><pub-id pub-id-type="pmid">8564805</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Born</surname><given-names>J</given-names></name><name><surname>Wilhelm</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>System consolidation of memory during sleep</article-title><source>Psychological Research</source><volume>76</volume><fpage>192</fpage><lpage>203</lpage><pub-id pub-id-type="doi">10.1007/s00426-011-0335-6</pub-id><pub-id pub-id-type="pmid">21541757</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Toward a network model of the articulatory loop*1</article-title><source>Journal of Memory and Language</source><volume>31</volume><fpage>429</fpage><lpage>460</lpage><pub-id pub-id-type="doi">10.1016/0749-596X(92)90022-P</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Two-stage model of memory trace formation: a role for “noisy” brain states</article-title><source>Neuroscience</source><volume>31</volume><fpage>551</fpage><lpage>570</lpage><pub-id pub-id-type="doi">10.1016/0306-4522(89)90423-5</pub-id><pub-id pub-id-type="pmid">2687720</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carey</surname><given-names>AA</given-names></name><name><surname>Tanaka</surname><given-names>Y</given-names></name><name><surname>van der Meer</surname><given-names>MAA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Reward revaluation biases hippocampal replay content away from the preferred outcome</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1450</fpage><lpage>1459</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0464-6</pub-id><pub-id pub-id-type="pmid">31427771</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carr</surname><given-names>MF</given-names></name><name><surname>Jadhav</surname><given-names>SP</given-names></name><name><surname>Frank</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Hippocampal replay in the awake state: a potential substrate for memory consolidation and retrieval</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>147</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1038/nn.2732</pub-id><pub-id pub-id-type="pmid">21270783</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheng</surname><given-names>S</given-names></name><name><surname>Frank</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>New experiences enhance coordinated neural activity in the hippocampus</article-title><source>Neuron</source><volume>57</volume><fpage>303</fpage><lpage>313</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.11.035</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>RT</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A memory-based theory of emotional disorders</article-title><source>Psychological Review</source><volume>129</volume><fpage>742</fpage><lpage>776</lpage><pub-id pub-id-type="doi">10.1037/rev0000334</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cowan</surname><given-names>ET</given-names></name><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Dunsmoor</surname><given-names>JE</given-names></name><name><surname>Murty</surname><given-names>VP</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Memory consolidation as an adaptive process</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>28</volume><fpage>1796</fpage><lpage>1810</lpage><pub-id pub-id-type="doi">10.3758/s13423-021-01978-x</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Csicsvari</surname><given-names>J</given-names></name><name><surname>O’Neill</surname><given-names>J</given-names></name><name><surname>Allen</surname><given-names>K</given-names></name><name><surname>Senior</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Place-selective firing contributes to the reverse-order reactivation of CA1 pyramidal cells during sharp waves in open-field exploration</article-title><source>The European Journal of Neuroscience</source><volume>26</volume><fpage>704</fpage><lpage>716</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2007.05684.x</pub-id><pub-id pub-id-type="pmid">17651429</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davidson</surname><given-names>TJ</given-names></name><name><surname>Kloosterman</surname><given-names>F</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Hippocampal replay of extended experience</article-title><source>Neuron</source><volume>63</volume><fpage>497</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.07.027</pub-id><pub-id pub-id-type="pmid">19709631</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Denovellis</surname><given-names>EL</given-names></name><name><surname>Gillespie</surname><given-names>AK</given-names></name><name><surname>Coulter</surname><given-names>ME</given-names></name><name><surname>Sosa</surname><given-names>M</given-names></name><name><surname>Chung</surname><given-names>JE</given-names></name><name><surname>Eden</surname><given-names>UT</given-names></name><name><surname>Frank</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Hippocampal replay of experience at real-world speeds</article-title><source>eLife</source><volume>10</volume><elocation-id>e64505</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.64505</pub-id><pub-id pub-id-type="pmid">34570699</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Vivo</surname><given-names>L</given-names></name><name><surname>Bellesi</surname><given-names>M</given-names></name><name><surname>Marshall</surname><given-names>W</given-names></name><name><surname>Bushong</surname><given-names>EA</given-names></name><name><surname>Ellisman</surname><given-names>MH</given-names></name><name><surname>Tononi</surname><given-names>G</given-names></name><name><surname>Cirelli</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Ultrastructural evidence for synaptic scaling across the wake/sleep cycle</article-title><source>Science</source><volume>355</volume><fpage>507</fpage><lpage>510</lpage><pub-id pub-id-type="doi">10.1126/science.aah5982</pub-id><pub-id pub-id-type="pmid">28154076</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Diamond</surname><given-names>NB</given-names></name><name><surname>Simpson</surname><given-names>S</given-names></name><name><surname>Baena Pérez</surname><given-names>D</given-names></name><name><surname>Murray</surname><given-names>B</given-names></name><name><surname>Fogel</surname><given-names>S</given-names></name><name><surname>Levine</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Sleep selectively and durably enhances real-world sequence memory</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2024.01.10.575038</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diba</surname><given-names>K</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Forward and reverse hippocampal place-cell sequences during ripples</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1241</fpage><lpage>1242</lpage><pub-id pub-id-type="doi">10.1038/nn1961</pub-id><pub-id pub-id-type="pmid">17828259</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diba</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Hippocampal sharp-wave ripples in cognitive map maintenance versus episodic simulation</article-title><source>Neuron</source><volume>109</volume><fpage>3071</fpage><lpage>3074</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.09.006</pub-id><pub-id pub-id-type="pmid">34619087</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Diekmann</surname><given-names>N</given-names></name><name><surname>Cheng</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>A model of hippocampal replay driven by experience and environmental structure facilitates spatial learning</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2022.07.26.501588</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drosopoulos</surname><given-names>S</given-names></name><name><surname>Windau</surname><given-names>E</given-names></name><name><surname>Wagner</surname><given-names>U</given-names></name><name><surname>Born</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Sleep enforces the temporal order in memory</article-title><source>PLOS ONE</source><volume>2</volume><elocation-id>e376</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0000376</pub-id><pub-id pub-id-type="pmid">17440612</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dupret</surname><given-names>D</given-names></name><name><surname>O’Neill</surname><given-names>J</given-names></name><name><surname>Pleydell-Bouverie</surname><given-names>B</given-names></name><name><surname>Csicsvari</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The reorganization and reactivation of hippocampal maps predict spatial memory performance</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>995</fpage><lpage>1002</lpage><pub-id pub-id-type="doi">10.1038/nn.2599</pub-id><pub-id pub-id-type="pmid">20639874</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ecker</surname><given-names>A</given-names></name><name><surname>Bagi</surname><given-names>B</given-names></name><name><surname>Vértes</surname><given-names>E</given-names></name><name><surname>Steinbach-Németh</surname><given-names>O</given-names></name><name><surname>Karlócai</surname><given-names>MR</given-names></name><name><surname>Papp</surname><given-names>OI</given-names></name><name><surname>Miklós</surname><given-names>I</given-names></name><name><surname>Hájos</surname><given-names>N</given-names></name><name><surname>Freund</surname><given-names>TF</given-names></name><name><surname>Gulyás</surname><given-names>AI</given-names></name><name><surname>Káli</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Hippocampal sharp wave-ripples and the associated sequence replay emerge from structured synaptic interactions in a network model of area CA3</article-title><source>eLife</source><volume>11</volume><elocation-id>e71850</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.71850</pub-id><pub-id pub-id-type="pmid">35040779</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ego-Stengel</surname><given-names>V</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Disruption of ripple-associated hippocampal activity during rest impairs spatial learning in the rat</article-title><source>Hippocampus</source><volume>20</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1002/hipo.20707</pub-id><pub-id pub-id-type="pmid">19816984</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eichenlaub</surname><given-names>J-B</given-names></name><name><surname>Jarosiewicz</surname><given-names>B</given-names></name><name><surname>Saab</surname><given-names>J</given-names></name><name><surname>Franco</surname><given-names>B</given-names></name><name><surname>Kelemen</surname><given-names>J</given-names></name><name><surname>Halgren</surname><given-names>E</given-names></name><name><surname>Hochberg</surname><given-names>LR</given-names></name><name><surname>Cash</surname><given-names>SS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Replay of learned neural firing sequences during rest in human motor cortex</article-title><source>Cell Reports</source><volume>31</volume><elocation-id>107581</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2020.107581</pub-id><pub-id pub-id-type="pmid">32375031</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Euston</surname><given-names>DR</given-names></name><name><surname>Tatsuno</surname><given-names>M</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Fast-forward playback of recent memory sequences in prefrontal cortex during sleep</article-title><source>Science</source><volume>318</volume><fpage>1147</fpage><lpage>1150</lpage><pub-id pub-id-type="doi">10.1126/science.1148979</pub-id><pub-id pub-id-type="pmid">18006749</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>DJ</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Reverse replay of behavioural sequences in hippocampal place cells during the awake state</article-title><source>Nature</source><volume>440</volume><fpage>680</fpage><lpage>683</lpage><pub-id pub-id-type="doi">10.1038/nature04587</pub-id><pub-id pub-id-type="pmid">16474382</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Replay comes of age</article-title><source>Annual Review of Neuroscience</source><volume>40</volume><fpage>581</fpage><lpage>602</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-072116-031538</pub-id><pub-id pub-id-type="pmid">28772098</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gillespie</surname><given-names>AK</given-names></name><name><surname>Astudillo Maya</surname><given-names>DA</given-names></name><name><surname>Denovellis</surname><given-names>EL</given-names></name><name><surname>Liu</surname><given-names>DF</given-names></name><name><surname>Kastner</surname><given-names>DB</given-names></name><name><surname>Coulter</surname><given-names>ME</given-names></name><name><surname>Roumis</surname><given-names>DK</given-names></name><name><surname>Eden</surname><given-names>UT</given-names></name><name><surname>Frank</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Hippocampal replay reflects specific past experiences rather than a plan for subsequent choice</article-title><source>Neuron</source><volume>109</volume><fpage>3149</fpage><lpage>3163</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.07.029</pub-id><pub-id pub-id-type="pmid">34450026</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Girardeau</surname><given-names>G</given-names></name><name><surname>Benchenane</surname><given-names>K</given-names></name><name><surname>Wiener</surname><given-names>SI</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name><name><surname>Zugaro</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Selective suppression of hippocampal ripples impairs spatial memory</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1222</fpage><lpage>1223</lpage><pub-id pub-id-type="doi">10.1038/nn.2384</pub-id><pub-id pub-id-type="pmid">19749750</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giri</surname><given-names>B</given-names></name><name><surname>Miyawaki</surname><given-names>H</given-names></name><name><surname>Mizuseki</surname><given-names>K</given-names></name><name><surname>Cheng</surname><given-names>S</given-names></name><name><surname>Diba</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Hippocampal reactivation extends for several hours following novel experience</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>866</fpage><lpage>875</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1950-18.2018</pub-id><pub-id pub-id-type="pmid">30530857</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gomperts</surname><given-names>SN</given-names></name><name><surname>Kloosterman</surname><given-names>F</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>VTA neurons coordinate with the hippocampal reactivation of spatial experience</article-title><source>eLife</source><volume>4</volume><elocation-id>e05360</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.05360</pub-id><pub-id pub-id-type="pmid">26465113</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grossberg</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1978">1978</year><article-title>Behavioral contrast in short term memory: Serial binary memory models or parallel continuous memory models?</article-title><source>Journal of Mathematical Psychology</source><volume>17</volume><fpage>199</fpage><lpage>219</lpage><pub-id pub-id-type="doi">10.1016/0022-2496(78)90016-0</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gupta</surname><given-names>AS</given-names></name><name><surname>van der Meer</surname><given-names>MAA</given-names></name><name><surname>Touretzky</surname><given-names>DS</given-names></name><name><surname>Redish</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Hippocampal replay is not a simple function of experience</article-title><source>Neuron</source><volume>65</volume><fpage>695</fpage><lpage>705</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.01.034</pub-id><pub-id pub-id-type="pmid">20223204</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haga</surname><given-names>T</given-names></name><name><surname>Fukai</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Recurrent network model for learning goal-directed sequences through reverse replay</article-title><source>eLife</source><volume>7</volume><elocation-id>e34171</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.34171</pub-id><pub-id pub-id-type="pmid">29969098</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasselmo</surname><given-names>ME</given-names></name><name><surname>Wyble</surname><given-names>BP</given-names></name><name><surname>Wallenstein</surname><given-names>GV</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Encoding and retrieval of episodic memories: Role of cholinergic and GABAergic modulation in the hippocampus</article-title><source>Hippocampus</source><volume>6</volume><fpage>693</fpage><lpage>708</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1098-1063(1996)6:6&lt;693::AID-HIPO12&gt;3.0.CO;2-W</pub-id><pub-id pub-id-type="pmid">9034856</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Neuromodulation: acetylcholine and memory consolidation</article-title><source>Trends in Cognitive Sciences</source><volume>3</volume><fpage>351</fpage><lpage>359</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(99)01365-0</pub-id><pub-id pub-id-type="pmid">10461198</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Temporally structured replay of neural activity in a model of entorhinal cortex, hippocampus and postsubiculum</article-title><source>The European Journal of Neuroscience</source><volume>28</volume><fpage>1301</fpage><lpage>1315</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2008.06437.x</pub-id><pub-id pub-id-type="pmid">18973557</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>MW</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>A distributed representation of temporal context</article-title><source>Journal of Mathematical Psychology</source><volume>46</volume><fpage>269</fpage><lpage>299</lpage><pub-id pub-id-type="doi">10.1006/jmps.2001.1388</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huelin Gorriz</surname><given-names>M</given-names></name><name><surname>Takigawa</surname><given-names>M</given-names></name><name><surname>Bendor</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>The role of experience in prioritizing hippocampal replay</article-title><source>Nature Communications</source><volume>14</volume><elocation-id>8157</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-023-43939-z</pub-id><pub-id pub-id-type="pmid">38071221</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Igata</surname><given-names>H</given-names></name><name><surname>Ikegaya</surname><given-names>Y</given-names></name><name><surname>Sasaki</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Prioritized experience replays on a hippocampal predictive map for learning</article-title><source>PNAS</source><volume>118</volume><elocation-id>e2011266118</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2011266118</pub-id><pub-id pub-id-type="pmid">33443144</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jadhav</surname><given-names>SP</given-names></name><name><surname>Kemere</surname><given-names>C</given-names></name><name><surname>German</surname><given-names>PW</given-names></name><name><surname>Frank</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Awake hippocampal sharp-wave ripples support spatial memory</article-title><source>Science</source><volume>336</volume><fpage>1454</fpage><lpage>1458</lpage><pub-id pub-id-type="doi">10.1126/science.1217230</pub-id><pub-id pub-id-type="pmid">22555434</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jensen</surname><given-names>O</given-names></name><name><surname>Lisman</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Hippocampal sequence-encoding driven by a cortical multi-item working memory buffer</article-title><source>Trends in Neurosciences</source><volume>28</volume><fpage>67</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2004.12.001</pub-id><pub-id pub-id-type="pmid">15667928</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Jensen</surname><given-names>KT</given-names></name><name><surname>Hennequin</surname><given-names>G</given-names></name><name><surname>Mattar</surname><given-names>MG</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>A recurrent network model of planning explains hippocampal replay and human behavior</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.01.16.523429</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>A</given-names></name><name><surname>Redish</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Neural ensembles in CA3 transiently encode paths forward of the animal at a decision point</article-title><source>The Journal of Neuroscience</source><volume>27</volume><fpage>12176</fpage><lpage>12189</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3761-07.2007</pub-id><pub-id pub-id-type="pmid">17989284</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joo</surname><given-names>HR</given-names></name><name><surname>Frank</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The hippocampal sharp wave-ripple in memory retrieval for immediate use and consolidation</article-title><source>Nature Reviews. Neuroscience</source><volume>19</volume><fpage>744</fpage><lpage>757</lpage><pub-id pub-id-type="doi">10.1038/s41583-018-0077-1</pub-id><pub-id pub-id-type="pmid">30356103</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Káli</surname><given-names>S</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Off-line replay maintains declarative memories in a model of hippocampal-neocortical interactions</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>286</fpage><lpage>294</lpage><pub-id pub-id-type="doi">10.1038/nn1202</pub-id><pub-id pub-id-type="pmid">14983183</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karlsson</surname><given-names>MP</given-names></name><name><surname>Frank</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Awake replay of remote experiences in the hippocampus</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>913</fpage><lpage>918</lpage><pub-id pub-id-type="doi">10.1038/nn.2344</pub-id><pub-id pub-id-type="pmid">19525943</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Khamassi</surname><given-names>M</given-names></name><name><surname>Girard</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Modeling awake hippocampal reactivations with model-based bidirectional search</article-title><source>Biological Cybernetics</source><volume>114</volume><fpage>231</fpage><lpage>248</lpage><pub-id pub-id-type="doi">10.1007/s00422-020-00817-x</pub-id><pub-id pub-id-type="pmid">32065253</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>King</surname><given-names>BR</given-names></name><name><surname>Hoedlmoser</surname><given-names>K</given-names></name><name><surname>Hirschauer</surname><given-names>F</given-names></name><name><surname>Dolfen</surname><given-names>N</given-names></name><name><surname>Albouy</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Sleeping on the motor engram: The multifaceted nature of sleep-related motor memory consolidation</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><volume>80</volume><fpage>1</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2017.04.026</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klinzing</surname><given-names>JG</given-names></name><name><surname>Niethard</surname><given-names>N</given-names></name><name><surname>Born</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Mechanisms of systems memory consolidation during sleep</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1598</fpage><lpage>1610</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0467-3</pub-id><pub-id pub-id-type="pmid">31451802</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koene</surname><given-names>RA</given-names></name><name><surname>Hasselmo</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Reversed and forward buffering of behavioral spike sequences enables retrospective and prospective retrieval in hippocampal regions CA3 and CA1</article-title><source>Neural Networks</source><volume>21</volume><fpage>276</fpage><lpage>288</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2007.12.029</pub-id><pub-id pub-id-type="pmid">18242057</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumaran</surname><given-names>D</given-names></name><name><surname>McClelland</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Generalization through the recurrent interaction of episodic memories: a model of the hippocampal system</article-title><source>Psychological Review</source><volume>119</volume><fpage>573</fpage><lpage>616</lpage><pub-id pub-id-type="doi">10.1037/a0028681</pub-id><pub-id pub-id-type="pmid">22775499</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>AK</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Memory of sequential experience in the hippocampus during slow wave sleep</article-title><source>Neuron</source><volume>36</volume><fpage>1183</fpage><lpage>1194</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(02)01096-6</pub-id><pub-id pub-id-type="pmid">12495631</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Levenstein</surname><given-names>D</given-names></name><name><surname>Efremov</surname><given-names>A</given-names></name><name><surname>Eyono</surname><given-names>RH</given-names></name><name><surname>Peyrache</surname><given-names>A</given-names></name><name><surname>Richards</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Sequential predictive learning is a unifying theory for hippocampal representation and replay</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2024.04.28.591528</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lisman</surname><given-names>J</given-names></name><name><surname>Redish</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Prediction, sequences and the hippocampus</article-title><source>Philosophical Transactions of the Royal Society B</source><volume>364</volume><fpage>1193</fpage><lpage>1201</lpage><pub-id pub-id-type="doi">10.1098/rstb.2008.0316</pub-id><pub-id pub-id-type="pmid">19528000</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Human replay spontaneously reorganizes experience</article-title><source>Cell</source><volume>178</volume><fpage>640</fpage><lpage>652</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2019.06.012</pub-id><pub-id pub-id-type="pmid">31280961</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Mattar</surname><given-names>MG</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Experience replay is associated with efficient nonlocal learning</article-title><source>Science</source><volume>372</volume><elocation-id>eabf1357</elocation-id><pub-id pub-id-type="doi">10.1126/science.abf1357</pub-id><pub-id pub-id-type="pmid">34016753</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>XL</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Resurrected memories: Sleep-dependent memory consolidation saves memories from competition induced by retrieval practice</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>28</volume><fpage>2035</fpage><lpage>2044</lpage><pub-id pub-id-type="doi">10.3758/s13423-021-01953-6</pub-id><pub-id pub-id-type="pmid">34173188</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Nour</surname><given-names>MM</given-names></name><name><surname>Schuck</surname><given-names>NW</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Decoding cognition from spontaneous neural activity</article-title><source>Nature Reviews. Neuroscience</source><volume>23</volume><fpage>204</fpage><lpage>214</lpage><pub-id pub-id-type="doi">10.1038/s41583-022-00570-z</pub-id><pub-id pub-id-type="pmid">35260845</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>XL</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name><name><surname>O’Reilly</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>A complementary learning systems model of how sleep moderates retrieval practice effects</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>31</volume><fpage>2022</fpage><lpage>2035</lpage><pub-id pub-id-type="doi">10.3758/s13423-024-02489-1</pub-id><pub-id pub-id-type="pmid">38530592</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lohnas</surname><given-names>LJ</given-names></name><name><surname>Polyn</surname><given-names>SM</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Expanding the scope of memory search: Modeling intralist and interlist effects in free recall</article-title><source>Psychological Review</source><volume>122</volume><fpage>337</fpage><lpage>363</lpage><pub-id pub-id-type="doi">10.1037/a0039036</pub-id><pub-id pub-id-type="pmid">25844876</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mackay</surname><given-names>DG</given-names></name><name><surname>Shafto</surname><given-names>M</given-names></name><name><surname>Taylor</surname><given-names>JK</given-names></name><name><surname>Marian</surname><given-names>DE</given-names></name><name><surname>Abrams</surname><given-names>L</given-names></name><name><surname>Dyer</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Relations between emotion, memory, and attention: Evidence from taboo Stroop, lexical decision, and immediate memory tasks</article-title><source>Memory &amp; Cognition</source><volume>32</volume><fpage>474</fpage><lpage>488</lpage><pub-id pub-id-type="doi">10.3758/BF03195840</pub-id><pub-id pub-id-type="pmid">15285130</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mackay</surname><given-names>DG</given-names></name><name><surname>Hadley</surname><given-names>CB</given-names></name><name><surname>Schwartz</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Relations between emotion, illusory word perception, and orthographic repetition blindness: Tests of binding theory</article-title><source>The Quarterly Journal of Experimental Psychology Section A</source><volume>58</volume><fpage>1514</fpage><lpage>1533</lpage><pub-id pub-id-type="doi">10.1080/02724980443000728</pub-id><pub-id pub-id-type="pmid">16365952</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Malerba</surname><given-names>P</given-names></name><name><surname>Krishnan</surname><given-names>GP</given-names></name><name><surname>Fellous</surname><given-names>JM</given-names></name><name><surname>Bazhenov</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Hippocampal CA1 ripples as inhibitory transients</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1004880</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004880</pub-id><pub-id pub-id-type="pmid">27093059</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mallory</surname><given-names>CS</given-names></name><name><surname>Widloski</surname><given-names>J</given-names></name><name><surname>Foster</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>The time course and organization of hippocampal replay</article-title><source>Science</source><volume>387</volume><fpage>541</fpage><lpage>548</lpage><pub-id pub-id-type="doi">10.1126/science.ads4760</pub-id><pub-id pub-id-type="pmid">39883781</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maret</surname><given-names>S</given-names></name><name><surname>Faraguna</surname><given-names>U</given-names></name><name><surname>Nelson</surname><given-names>AB</given-names></name><name><surname>Cirelli</surname><given-names>C</given-names></name><name><surname>Tononi</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Sleep and waking modulate spine turnover in the adolescent mouse cortex</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1418</fpage><lpage>1420</lpage><pub-id pub-id-type="doi">10.1038/nn.2934</pub-id><pub-id pub-id-type="pmid">21983682</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mather</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Emotional arousal and memory binding: an object-based framework</article-title><source>Perspectives on Psychological Science</source><volume>2</volume><fpage>33</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1111/j.1745-6916.2007.00028.x</pub-id><pub-id pub-id-type="pmid">26151918</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mattar</surname><given-names>MG</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Prioritized memory access explains planning and hippocampal replay</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1609</fpage><lpage>1617</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0232-z</pub-id><pub-id pub-id-type="pmid">30349103</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mattar</surname><given-names>MG</given-names></name><name><surname>Lengyel</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Planning in the brain</article-title><source>Neuron</source><volume>110</volume><fpage>914</fpage><lpage>934</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.12.018</pub-id><pub-id pub-id-type="pmid">35041804</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClelland</surname><given-names>JL</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>O’Reilly</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory</article-title><source>Psychological Review</source><volume>102</volume><fpage>419</fpage><lpage>457</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.102.3.419</pub-id><pub-id pub-id-type="pmid">7624455</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mclaren</surname><given-names>IPL</given-names></name><name><surname>Mackintosh</surname><given-names>NJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Associative learning and elemental representation: II Generalization and discrimination</article-title><source>Animal Learning &amp; Behavior</source><volume>30</volume><fpage>177</fpage><lpage>200</lpage><pub-id pub-id-type="doi">10.3758/BF03192828</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNamee</surname><given-names>DC</given-names></name><name><surname>Stachenfeld</surname><given-names>KL</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Flexible modulation of sequence generation in the entorhinal-hippocampal system</article-title><source>Nature Neuroscience</source><volume>24</volume><fpage>851</fpage><lpage>862</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00831-7</pub-id><pub-id pub-id-type="pmid">33846626</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meeter</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Control of consolidation in neural networks: Avoiding runaway effects</article-title><source>Connection Science</source><volume>15</volume><fpage>45</fpage><lpage>61</lpage><pub-id pub-id-type="doi">10.1080/0954009031000149591</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mehta</surname><given-names>MR</given-names></name><name><surname>Barnes</surname><given-names>CA</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Experience-dependent, asymmetric expansion of hippocampal place fields</article-title><source>PNAS</source><volume>94</volume><fpage>8918</fpage><lpage>8921</lpage><pub-id pub-id-type="doi">10.1073/pnas.94.16.8918</pub-id><pub-id pub-id-type="pmid">9238078</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michon</surname><given-names>F</given-names></name><name><surname>Sun</surname><given-names>JJ</given-names></name><name><surname>Kim</surname><given-names>CY</given-names></name><name><surname>Ciliberti</surname><given-names>D</given-names></name><name><surname>Kloosterman</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Post-learning hippocampal replay selectively reinforces spatial memory for highly rewarded locations</article-title><source>Current Biology</source><volume>29</volume><fpage>1436</fpage><lpage>1444</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.03.048</pub-id><pub-id pub-id-type="pmid">31031113</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Momennejad</surname><given-names>I</given-names></name><name><surname>Otto</surname><given-names>AR</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Offline replay supports planning in human reinforcement learning</article-title><source>eLife</source><volume>7</volume><elocation-id>e32548</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.32548</pub-id><pub-id pub-id-type="pmid">30547886</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nádasdy</surname><given-names>Z</given-names></name><name><surname>Hirase</surname><given-names>H</given-names></name><name><surname>Czurkó</surname><given-names>A</given-names></name><name><surname>Csicsvari</surname><given-names>J</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Replay and time compression of recurring spike sequences in the hippocampus</article-title><source>The Journal of Neuroscience</source><volume>19</volume><fpage>9497</fpage><lpage>9507</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-21-09497.1999</pub-id><pub-id pub-id-type="pmid">10531452</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Newman</surname><given-names>EL</given-names></name><name><surname>Perotte</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Methods for reducing interference in the complementary learning systems model: oscillating inhibition and autonomous memory rehearsal</article-title><source>Neural Networks</source><volume>18</volume><fpage>1212</fpage><lpage>1228</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2005.08.010</pub-id><pub-id pub-id-type="pmid">16260116</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ólafsdóttir</surname><given-names>HF</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Saleem</surname><given-names>AB</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Spiers</surname><given-names>HJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Hippocampal place cells construct reward related sequences through unexplored space</article-title><source>eLife</source><volume>4</volume><elocation-id>e06063</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.06063</pub-id><pub-id pub-id-type="pmid">26112828</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ólafsdóttir</surname><given-names>HF</given-names></name><name><surname>Carpenter</surname><given-names>F</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Task demands predict a dynamic switch in the content of awake hippocampal replay</article-title><source>Neuron</source><volume>96</volume><fpage>925</fpage><lpage>935</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.09.035</pub-id><pub-id pub-id-type="pmid">29056296</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ólafsdóttir</surname><given-names>HF</given-names></name><name><surname>Bush</surname><given-names>D</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The role of hippocampal replay in memory and planning</article-title><source>Current Biology</source><volume>28</volume><fpage>R37</fpage><lpage>R50</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.10.073</pub-id><pub-id pub-id-type="pmid">29316421</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Neill</surname><given-names>J</given-names></name><name><surname>Senior</surname><given-names>TJ</given-names></name><name><surname>Allen</surname><given-names>K</given-names></name><name><surname>Huxter</surname><given-names>JR</given-names></name><name><surname>Csicsvari</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Reactivation of experience-dependent cell assembly patterns in the hippocampus</article-title><source>Nature Neuroscience</source><volume>11</volume><fpage>209</fpage><lpage>215</lpage><pub-id pub-id-type="doi">10.1038/nn2037</pub-id><pub-id pub-id-type="pmid">18193040</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Neill</surname><given-names>J</given-names></name><name><surname>Boccara</surname><given-names>CN</given-names></name><name><surname>Stella</surname><given-names>F</given-names></name><name><surname>Schoenenberger</surname><given-names>P</given-names></name><name><surname>Csicsvari</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Superficial layers of the medial entorhinal cortex replay independently of the hippocampus</article-title><source>Science</source><volume>355</volume><fpage>184</fpage><lpage>188</lpage><pub-id pub-id-type="doi">10.1126/science.aag2787</pub-id><pub-id pub-id-type="pmid">28082591</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oudiette</surname><given-names>D</given-names></name><name><surname>Paller</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Upgrading the sleeping brain with targeted memory reactivation</article-title><source>Trends in Cognitive Sciences</source><volume>17</volume><fpage>142</fpage><lpage>149</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2013.01.006</pub-id><pub-id pub-id-type="pmid">23433937</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Payne</surname><given-names>JD</given-names></name><name><surname>Stickgold</surname><given-names>R</given-names></name><name><surname>Swanberg</surname><given-names>K</given-names></name><name><surname>Kensinger</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Sleep preferentially enhances memory for emotional components of scenes</article-title><source>Psychological Science</source><volume>19</volume><fpage>781</fpage><lpage>788</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.2008.02157.x</pub-id><pub-id pub-id-type="pmid">18816285</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Payne</surname><given-names>JD</given-names></name><name><surname>Kensinger</surname><given-names>EA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Sleep’s role in the consolidation of emotional episodic memories</article-title><source>Current Directions in Psychological Science</source><volume>19</volume><fpage>290</fpage><lpage>295</lpage><pub-id pub-id-type="doi">10.1177/0963721410383978</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfeiffer</surname><given-names>BE</given-names></name><name><surname>Foster</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Hippocampal place-cell sequences depict future paths to remembered goals</article-title><source>Nature</source><volume>497</volume><fpage>74</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1038/nature12112</pub-id><pub-id pub-id-type="pmid">23594744</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Polyn</surname><given-names>SM</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A context maintenance and retrieval model of organizational processes in free recall</article-title><source>Psychological Review</source><volume>116</volume><fpage>129</fpage><lpage>156</lpage><pub-id pub-id-type="doi">10.1037/a0014420</pub-id><pub-id pub-id-type="pmid">19159151</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pu</surname><given-names>Y</given-names></name><name><surname>Kong</surname><given-names>XZ</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name><name><surname>Melloni</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Event boundaries shape temporal organization of memory by resetting temporal context</article-title><source>Nature Communications</source><volume>13</volume><elocation-id>622</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-022-28216-9</pub-id><pub-id pub-id-type="pmid">35110527</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Redish</surname><given-names>AD</given-names></name><name><surname>Touretzky</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>The role of the hippocampus in solving the Morris water maze</article-title><source>Neural Computation</source><volume>10</volume><fpage>73</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.1162/089976698300017908</pub-id><pub-id pub-id-type="pmid">9501505</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Sagiv</surname><given-names>Y</given-names></name><name><surname>Akam</surname><given-names>T</given-names></name><name><surname>Witten</surname><given-names>IB</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>Between planning and map building: Prioritizing replay when future goals are uncertain</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2024.02.29.582822</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Santoro</surname><given-names>A</given-names></name><name><surname>Frankland</surname><given-names>PW</given-names></name><name><surname>Richards</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Memory transformation enhances reinforcement learning in dynamic environments</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>12228</fpage><lpage>12242</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0763-16.2016</pub-id><pub-id pub-id-type="pmid">27903731</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sawangjit</surname><given-names>A</given-names></name><name><surname>Oyanedel</surname><given-names>CN</given-names></name><name><surname>Niethard</surname><given-names>N</given-names></name><name><surname>Salazar</surname><given-names>C</given-names></name><name><surname>Born</surname><given-names>J</given-names></name><name><surname>Inostroza</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The hippocampus is crucial for forming non-hippocampal long-term memory during sleep</article-title><source>Nature</source><volume>564</volume><fpage>109</fpage><lpage>113</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0716-8</pub-id><pub-id pub-id-type="pmid">30429612</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>McDevitt</surname><given-names>EA</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name><name><surname>Mednick</surname><given-names>SC</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Human hippocampal replay during rest prioritizes weakly learned information and predicts memory performance</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>3920</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-06213-1</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Reid</surname><given-names>AG</given-names></name><name><surname>Morgan</surname><given-names>A</given-names></name><name><surname>Manoach</surname><given-names>DS</given-names></name><name><surname>Verfaellie</surname><given-names>M</given-names></name><name><surname>Stickgold</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The hippocampus is necessary for the consolidation of a task that does not require the hippocampus for initial learning</article-title><source>Hippocampus</source><volume>29</volume><fpage>1091</fpage><lpage>1100</lpage><pub-id pub-id-type="doi">10.1002/hipo.23101</pub-id><pub-id pub-id-type="pmid">31157946</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="software"><person-group person-group-type="author"><collab>schapirolab</collab></person-group><year iso-8601-date="2025">2025</year><data-title>CMR-replay</data-title><version designator="swh:1:rev:1567c456a0b2f8eee13682c6622a0090f1de95d8">swh:1:rev:1567c456a0b2f8eee13682c6622a0090f1de95d8</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:5f8b41e64056e01d50847588d326ef7fe1ee415d;origin=https://github.com/schapirolab/CMR-replay;visit=swh:1:snp:dde714fa4cb92e7da74319a1ab7a2c57c8fb08b4;anchor=swh:1:rev:1567c456a0b2f8eee13682c6622a0090f1de95d8">https://archive.softwareheritage.org/swh:1:dir:5f8b41e64056e01d50847588d326ef7fe1ee415d;origin=https://github.com/schapirolab/CMR-replay;visit=swh:1:snp:dde714fa4cb92e7da74319a1ab7a2c57c8fb08b4;anchor=swh:1:rev:1567c456a0b2f8eee13682c6622a0090f1de95d8</ext-link></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schechtman</surname><given-names>E</given-names></name><name><surname>Heilberg</surname><given-names>J</given-names></name><name><surname>Paller</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2023">2023a</year><article-title>Memory consolidation during sleep involves context reinstatement in humans</article-title><source>Cell Reports</source><volume>42</volume><elocation-id>112331</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2023.112331</pub-id><pub-id pub-id-type="pmid">37014750</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schechtman</surname><given-names>E</given-names></name><name><surname>Heilberg</surname><given-names>J</given-names></name><name><surname>Paller</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2023">2023b</year><article-title>Context matters: changes in memory over a period of sleep are driven by encoding context</article-title><source>Learning &amp; Memory</source><volume>30</volume><fpage>36</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1101/lm.053634.122</pub-id><pub-id pub-id-type="pmid">36720637</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shen</surname><given-names>B</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Modeling the spontaneous reactivation of experience-specific hippocampal cell assembles during sleep</article-title><source>Hippocampus</source><volume>6</volume><fpage>685</fpage><lpage>692</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1098-1063(1996)6:6&lt;685::AID-HIPO11&gt;3.0.CO;2-X</pub-id><pub-id pub-id-type="pmid">9034855</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheridan</surname><given-names>CL</given-names></name><name><surname>Lang</surname><given-names>S</given-names></name><name><surname>Knappenberger</surname><given-names>M</given-names></name><name><surname>Albers</surname><given-names>C</given-names></name><name><surname>Loper</surname><given-names>R</given-names></name><name><surname>Tillett</surname><given-names>B</given-names></name><name><surname>Sanchez</surname><given-names>J</given-names></name><name><surname>Wilcox</surname><given-names>A</given-names></name><name><surname>Harrison</surname><given-names>T</given-names></name><name><surname>Panoz-Brown</surname><given-names>D</given-names></name><name><surname>Crystal</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Replay of incidentally encoded episodic memories in the rat</article-title><source>Current Biology</source><volume>34</volume><fpage>641</fpage><lpage>647</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2023.12.043</pub-id><pub-id pub-id-type="pmid">38218186</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Sherman</surname><given-names>B</given-names></name><name><surname>Gonciulea</surname><given-names>C</given-names></name><name><surname>Siefert</surname><given-names>E</given-names></name><name><surname>Schapiro</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>Prior knowledge scaffolds acquisition of new memories but only sleep supports integration</article-title><source>PsyArXiv</source><pub-id pub-id-type="doi">10.31234/osf.io/bj29n_v1</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shin</surname><given-names>JD</given-names></name><name><surname>Tang</surname><given-names>W</given-names></name><name><surname>Jadhav</surname><given-names>SP</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Dynamics of awake hippocampal-prefrontal replay for spatial learning and memory-guided decision making</article-title><source>Neuron</source><volume>104</volume><fpage>1110</fpage><lpage>1125</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.09.012</pub-id><pub-id pub-id-type="pmid">31677957</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singer</surname><given-names>AC</given-names></name><name><surname>Frank</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Rewarded outcomes enhance reactivation of experience in the hippocampus</article-title><source>Neuron</source><volume>64</volume><fpage>910</fpage><lpage>921</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.11.016</pub-id><pub-id pub-id-type="pmid">20064396</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singh</surname><given-names>D</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Schapiro</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A model of autonomous interactions between hippocampus and neocortex driving sleep-dependent memory consolidation</article-title><source>PNAS</source><volume>119</volume><elocation-id>e2123432119</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2123432119</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skaggs</surname><given-names>WE</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Replay of neuronal firing sequences in rat hippocampus during sleep following spatial experience</article-title><source>Science</source><volume>271</volume><fpage>1870</fpage><lpage>1873</lpage><pub-id pub-id-type="doi">10.1126/science.271.5257.1870</pub-id><pub-id pub-id-type="pmid">8596957</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spens</surname><given-names>E</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>A generative model of memory construction and consolidation</article-title><source>Nature Human Behaviour</source><volume>8</volume><fpage>526</fpage><lpage>543</lpage><pub-id pub-id-type="doi">10.1038/s41562-023-01799-z</pub-id><pub-id pub-id-type="pmid">38242925</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sterpenich</surname><given-names>V</given-names></name><name><surname>van Schie</surname><given-names>MKM</given-names></name><name><surname>Catsiyannis</surname><given-names>M</given-names></name><name><surname>Ramyead</surname><given-names>A</given-names></name><name><surname>Perrig</surname><given-names>S</given-names></name><name><surname>Yang</surname><given-names>H-D</given-names></name><name><surname>Van De Ville</surname><given-names>D</given-names></name><name><surname>Schwartz</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Reward biases spontaneous neural reactivation during sleep</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>4162</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-24357-5</pub-id><pub-id pub-id-type="pmid">34230462</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>W</given-names></name><name><surname>Advani</surname><given-names>MS</given-names></name><name><surname>Spruston</surname><given-names>N</given-names></name><name><surname>Saxe</surname><given-names>A</given-names></name><name><surname>Fitzgerald</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Organizing memories for generalization in complementary learning systems</article-title><source>Nature Neuroscience</source><volume>26</volume><fpage>1438</fpage><lpage>1448</lpage><pub-id pub-id-type="doi">10.1038/s41593-023-01382-9</pub-id><pub-id pub-id-type="pmid">37474639</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>RS</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Learning to predict by the methods of temporal differences</article-title><source>Machine Learning</source><volume>3</volume><fpage>9</fpage><lpage>44</lpage><pub-id pub-id-type="doi">10.1023/A:1022633531479</pub-id></element-citation></ref><ref id="bib119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Talmi</surname><given-names>D</given-names></name><name><surname>Lohnas</surname><given-names>LJ</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A retrieved context model of the emotional modulation of memory</article-title><source>Psychological Review</source><volume>126</volume><fpage>455</fpage><lpage>485</lpage><pub-id pub-id-type="doi">10.1037/rev0000132</pub-id><pub-id pub-id-type="pmid">30973247</pub-id></element-citation></ref><ref id="bib120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tononi</surname><given-names>G</given-names></name><name><surname>Cirelli</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Sleep function and synaptic homeostasis</article-title><source>Sleep Medicine Reviews</source><volume>10</volume><fpage>49</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1016/j.smrv.2005.05.002</pub-id><pub-id pub-id-type="pmid">16376591</pub-id></element-citation></ref><ref id="bib121"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vaz</surname><given-names>AP</given-names></name><name><surname>Wittig</surname><given-names>JH</given-names></name><name><surname>Inati</surname><given-names>SK</given-names></name><name><surname>Zaghloul</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Replay of cortical spiking sequences during human memory retrieval</article-title><source>Science</source><volume>367</volume><fpage>1131</fpage><lpage>1134</lpage><pub-id pub-id-type="doi">10.1126/science.aba0672</pub-id><pub-id pub-id-type="pmid">32139543</pub-id></element-citation></ref><ref id="bib122"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker</surname><given-names>MP</given-names></name><name><surname>Stickgold</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Sleep-dependent learning and memory consolidation</article-title><source>Neuron</source><volume>44</volume><fpage>121</fpage><lpage>133</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2004.08.031</pub-id><pub-id pub-id-type="pmid">15450165</pub-id></element-citation></ref><ref id="bib123"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wamsley</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Memory consolidation during waking rest</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>171</fpage><lpage>173</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.12.007</pub-id><pub-id pub-id-type="pmid">30683602</pub-id></element-citation></ref><ref id="bib124"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>M</given-names></name><name><surname>Foster</surname><given-names>DJ</given-names></name><name><surname>Pfeiffer</surname><given-names>BE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Alternating sequences of future and past behavior encoded within hippocampal theta oscillations</article-title><source>Science</source><volume>370</volume><fpage>247</fpage><lpage>250</lpage><pub-id pub-id-type="doi">10.1126/science.abb4151</pub-id><pub-id pub-id-type="pmid">33033222</pub-id></element-citation></ref><ref id="bib125"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wikenheiser</surname><given-names>AM</given-names></name><name><surname>Redish</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The balance of forward and backward hippocampal sequences shifts across behavioral states</article-title><source>Hippocampus</source><volume>23</volume><fpage>22</fpage><lpage>29</lpage><pub-id pub-id-type="doi">10.1002/hipo.22049</pub-id><pub-id pub-id-type="pmid">22736562</pub-id></element-citation></ref><ref id="bib126"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wikenheiser</surname><given-names>AM</given-names></name><name><surname>Redish</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Hippocampal theta sequences reflect current goals</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>289</fpage><lpage>294</lpage><pub-id pub-id-type="doi">10.1038/nn.3909</pub-id><pub-id pub-id-type="pmid">25559082</pub-id></element-citation></ref><ref id="bib127"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>MA</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Reactivation of hippocampal ensemble memories during sleep</article-title><source>Science</source><volume>265</volume><fpage>676</fpage><lpage>679</lpage><pub-id pub-id-type="doi">10.1126/science.8036517</pub-id><pub-id pub-id-type="pmid">8036517</pub-id></element-citation></ref><ref id="bib128"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wimmer</surname><given-names>GE</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Vehar</surname><given-names>N</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Episodic memory retrieval success is associated with rapid replay of episode content</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>1025</fpage><lpage>1033</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-0649-z</pub-id><pub-id pub-id-type="pmid">32514135</pub-id></element-citation></ref><ref id="bib129"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wimmer</surname><given-names>GE</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>McNamee</surname><given-names>DC</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Distinct replay signatures for prospective decision-making and memory preservation</article-title><source>PNAS</source><volume>120</volume><elocation-id>e2205211120</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2205211120</pub-id><pub-id pub-id-type="pmid">36719914</pub-id></element-citation></ref><ref id="bib130"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wittkuhn</surname><given-names>L</given-names></name><name><surname>Schuck</surname><given-names>NW</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Dynamics of fMRI patterns reflect sub-second activation sequences and reveal replay in human visual cortex</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>1795</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-21970-2</pub-id><pub-id pub-id-type="pmid">33741933</pub-id></element-citation></ref><ref id="bib131"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>CT</given-names></name><name><surname>Haggerty</surname><given-names>D</given-names></name><name><surname>Kemere</surname><given-names>C</given-names></name><name><surname>Ji</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Hippocampal awake replay in fear memory retrieval</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>571</fpage><lpage>580</lpage><pub-id pub-id-type="doi">10.1038/nn.4507</pub-id><pub-id pub-id-type="pmid">28218916</pub-id></element-citation></ref><ref id="bib132"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>H</given-names></name><name><surname>Baracskay</surname><given-names>P</given-names></name><name><surname>O’Neill</surname><given-names>J</given-names></name><name><surname>Csicsvari</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Assembly responses of hippocampal CA1 place cells predict learned behavior in goal-directed spatial tasks on the radial eight-arm maze</article-title><source>Neuron</source><volume>101</volume><fpage>119</fpage><lpage>132</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.11.015</pub-id><pub-id pub-id-type="pmid">30503645</pub-id></element-citation></ref><ref id="bib133"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yamamoto</surname><given-names>J</given-names></name><name><surname>Tonegawa</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Direct medial entorhinal cortex input to hippocampal CA1 is crucial for extended quiet awake replay</article-title><source>Neuron</source><volume>96</volume><fpage>217</fpage><lpage>227</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.09.017</pub-id><pub-id pub-id-type="pmid">28957670</pub-id></element-citation></ref><ref id="bib134"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yonelinas</surname><given-names>AP</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name><name><surname>Ekstrom</surname><given-names>AD</given-names></name><name><surname>Wiltgen</surname><given-names>BJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A contextual binding theory of episodic memory: systems consolidation reconsidered</article-title><source>Nature Reviews. Neuroscience</source><volume>20</volume><fpage>364</fpage><lpage>375</lpage><pub-id pub-id-type="doi">10.1038/s41583-019-0150-4</pub-id><pub-id pub-id-type="pmid">30872808</pub-id></element-citation></ref><ref id="bib135"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>W</given-names></name><name><surname>Zadbood</surname><given-names>A</given-names></name><name><surname>Chanales</surname><given-names>AJH</given-names></name><name><surname>Davachi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Repetition dynamically and rapidly increases cortical, but not hippocampal, offline reactivation</article-title><source>PNAS</source><volume>121</volume><elocation-id>e2405929121</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2405929121</pub-id><pub-id pub-id-type="pmid">39316058</pub-id></element-citation></ref><ref id="bib136"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>CY</given-names></name><name><surname>Talmi</surname><given-names>D</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Mattar</surname><given-names>MG</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Episodic retrieval for model-based evaluation in sequential decision tasks</article-title><source>PsyArXiv</source><pub-id pub-id-type="doi">10.31234/osf.io/3sqjh</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.99931.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Liljeholm</surname><given-names>Mimi</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>University of California, Irvine</institution><country>United States</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Compelling</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>This is an <bold>important</bold> account of replay as recency-weighted context-guided memory reactivation that explains a number of empirical findings across human and rodent memory literatures. The evidence is <bold>compelling</bold> and the work is likely to inspire further adaptions to incorporate additional biological and cognitive features.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.99931.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>Zhou and colleagues developed a computational model of replay that heavily builds on cognitive models of memory in context (e.g., the context-maintenance and retrieval model), which have been successfully used to explain memory phenomena in the past. Their model produces results that mirror previous empirical findings in rodents and offers a new computational framework for thinking about replay.</p><p>Strengths:</p><p>The model is compelling and seems to explain a number of findings from the rodent literature. It is commendable that the authors implement commonly used algorithms from wakefulness to model sleep/rest, thereby linking wake and sleep phenomena in a parsimonious way. Additionally, the manuscript's comprehensive perspective on replay, bridging humans and non-human animals, enhanced its theoretical contribution.</p><p>Weaknesses:</p><p>This reviewer is not a computational neuroscientist by training, so some comments may stem from misunderstandings. I hope the authors would see those instances as opportunities to clarify their findings for broader audiences.</p><p>(1) The model predicts that temporally close items will be co-reactivated, yet evidence from humans suggests that temporal context doesn't guide sleep benefits (instead, semantic connections seem to be of more importance; Liu and Ranganath 2021, Schechtman et al 2023). Could these findings be reconciled with the model or is this a limitation of the current framework?</p><p>(2) During replay, the model is set so that the next reactivated item is sampled without replacement (i.e., the model cannot get &quot;stuck&quot; on a single item). I'm not sure what the biological backing behind this is and why the brain can't reactivate the same item consistently. Furthermore, I'm afraid that such a rule may artificially generate sequential reactivation of items regardless of wake training. Could the authors explain this better or show that this isn't the case?</p><p>(3) If I understand correctly, there are two ways in which novelty (i.e., less exposure) is accounted for in the model. The first and more talked about is the suppression mechanism (lines 639-646). The second is a change in learning rates (lines 593-595). It's unclear to me why both procedures are needed, how they differ, and whether these are two different mechanisms that the model implements. Also, since the authors controlled the extent to which each item was experienced during wakefulness, it's not entirely clear to me which of the simulations manipulated novelty on an individual item level, as described in lines 593-595 (if any).</p><p>As to the first mechanism - experience-based suppression - I find it challenging to think of a biological mechanism that would achieve this and is selectively activated immediately before sleep (somehow anticipating its onset). In fact, the prominent synaptic homeostasis hypothesis suggests that such suppression, at least on a synaptic level, is exactly what sleep itself does (i.e., prune or weaken synapses that were enhanced due to learning during the day). This begs the question of whether certain sleep stages (or ultradian cycles) may be involved in pruning, whereas others leverage its results for reactivation (e.g., a sequential hypothesis; Rasch &amp; Born, 2013). That could be a compelling synthesis of this literature. Regardless of whether the authors agree, I believe that this point is a major caveat to the current model. It is addressed in the discussion, but perhaps it would be beneficial to explicitly state to what extent the results rely on the assumption of a pre-sleep suppression mechanism.</p><p>(4) As the manuscript mentions, the only difference between sleep and wake in the model is the initial conditions (a0). This is an obvious simplification, especially given the last author's recent models discussing the very different roles of REM vs NREM. Could the authors suggest how different sleep stages may relate to the model or how it could be developed to interact with other successful models such as the ones the last author has developed (e.g., C-HORSE)? Finally, I wonder how the model would explain findings (including the authors') showing a preference for reactivation of weaker memories. The literature seems to suggest that it isn't just a matter of novelty or exposure, but encoding strength. Can the model explain this? Or would it require additional assumptions or some mechanism for selective endogenous reactivation during sleep and rest?</p><p>(5) Lines 186-200 - Perhaps I'm misunderstanding, but wouldn't it be trivial that an external cue at the end-item of Figure 7a would result in backward replay, simply because there is no potential for forward replay for sequences starting at the last item (there simply aren't any subsequent items)? The opposite is true, of course, for the first-item replay, which can't go backward. More generally, my understanding of the literature on forward vs backward replay is that neither is linked to the rodent's location. Both commonly happen at a resting station that is further away from the track. It seems as though the model's result may not hold if replay occurs away from the track (i.e. if a0 would be equal for both pre- and post-run).</p><p>(6) The manuscript describes a study by Bendor &amp; Wilson (2012) and tightly mimics their results. However, notably, that study did not find triggered replay immediately following sound presentation, but rather a general bias toward reactivation of the cued sequence over longer stretches of time. In other words, it seems that the model's results don't fully mirror the empirical results. One idea that came to mind is that perhaps it is the R/L context - not the first R/L item - that is cued in this study. This is in line with other TMR studies showing what may be seen as contextual reactivation. If the authors think that such a simulation may better mirror the empirical results, I encourage them to try. If not, however, this limitation should be discussed.</p><p>(7) There is some discussion about replay's benefit to memory. One point of interest could be whether this benefit changes between wake and sleep. Relatedly, it would be interesting to see whether the proportion of forward replay, backward replay, or both correlated with memory benefits. I encourage the authors to extend the section on the function of replay and explore these questions.</p><p>(8) Replay has been mostly studied in rodents, with few exceptions, whereas CMR and similar models have mostly been used in humans. Although replay is considered a good model of episodic memory, it is still limited due to limited findings of sequential replay in humans and its reliance on very structured and inherently autocorrelated items (i.e., place fields). I'm wondering if the authors could speak to the implications of those limitations on the generalizability of their model. Relatedly, I wonder if the model could or does lead to generalization to some extent in a way that would align with the complementary learning systems framework.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.99931.3.sa2</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>In this manuscript, Zhou et al. present a computational model of memory replay. Their model (CMR-replay) draws from temporal context models of human memory (e.g., TCM, CMR) and claims replay may be another instance of a context-guided memory process. During awake learning, CMR-replay (like its predecessors) encodes items alongside a drifting mental context that maintains a recency-weighted history of recently encoded contexts/items. In this way, the presently encoded item becomes associated with other recently learned items via their shared context representation - giving rise to typical effects in recall such as primacy, recency and contiguity. Unlike its predecessors, CMR-replay has built in replay periods. These replay periods are designed to approximate sleep or wakeful quiescence, in which an item is spontaneously reactivated, causing a subsequent cascade of item-context reactivations that further update the model's items-context associations.</p><p>Using this model of replay, Zhou et al. were able to reproduce a variety of empirical findings in the replay literature: e.g., greater forward replay at the beginning of a track and more backwards replay at the end; more replay for rewarded events; the occurrence of remote replay; reduced replay for repeated items, etc. Furthermore, the model diverges considerably (in implementation and predictions) from other prominent models of replay that, instead, emphasize replay as a way of predicting value from a reinforcement learning framing (i.e., EVB, expected value backup).</p><p>Overall, I found the manuscript clear and easy to follow, despite not being a computational modeller myself. (Which is pretty commendable, I'd say). The model also was effective at capturing several important empirical results from the replay literature while relying on a concise set of mechanisms - which will have implications for subsequent theory building in the field.</p><p>The authors addressed my concerns with respect to adding methodological detail. I am satisfied with the changes.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.99931.3.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Zhou</surname><given-names>Zhenglong</given-names></name><role specific-use="author">Author</role><aff><institution>University of Pennsylvania</institution><addr-line><named-content content-type="city">Philadelphia</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Kahana</surname><given-names>Michael J</given-names></name><role specific-use="author">Author</role><aff><institution>University of Pennsylvania</institution><addr-line><named-content content-type="city">Philadelphia</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Schapiro</surname><given-names>Anna C</given-names></name><role specific-use="author">Author</role><aff><institution>University of Pennsylvania</institution><addr-line><named-content content-type="city">Philadelphia</named-content></addr-line><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public Review):</bold></p><p>Summary:</p><p>Zhou and colleagues developed a computational model of replay that heavily builds on cognitive models of memory in context (e.g., the context-maintenance and retrieval model), which have been successfully used to explain memory phenomena in the past. Their model produces results that mirror previous empirical findings in rodents and offers a new computational framework for thinking about replay.</p><p>Strengths:</p><p>The model is compelling and seems to explain a number of findings from the rodent literature. It is commendable that the authors implement commonly used algorithms from wakefulness to model sleep/rest, thereby linking wake and sleep phenomena in a parsimonious way. Additionally, the manuscript's comprehensive perspective on replay, bridging humans and non-human animals, enhanced its theoretical contribution.</p><p>Weaknesses:</p><p>This reviewer is not a computational neuroscientist by training, so some comments may stem from misunderstandings. I hope the authors would see those instances as opportunities to clarify their findings for broader audiences.</p><p>(1) The model predicts that temporally close items will be co-reactivated, yet evidence from humans suggests that temporal context doesn't guide sleep benefits (instead, semantic connections seem to be of more importance; Liu and Ranganath 2021, Schechtman et al 2023). Could these findings be reconciled with the model or is this a limitation of the current framework?</p></disp-quote><p>We appreciate the encouragement to discuss this connection. Our framework can accommodate semantic associations as determinants of sleep-dependent consolidation, which can in principle outweigh temporal associations. Indeed, prior models in this lineage have extensively simulated how semantic associations support encoding and retrieval alongside temporal associations. It would therefore be straightforward to extend our model to simulate how semantic associations guide sleep benefits, and to compare their contribution against that conferred by temporal associations across different experimental paradigms. In the revised manuscript, we have added a discussion of how our framework may simulate the role of semantic associations in sleep-dependent consolidation.</p><p>“Several recent studies have argued for dominance of semantic associations over temporal associations in the process of human sleep-dependent consolidation (Schechtman et al., 2023; Liu and Ranganath 2021; Sherman et al., 2025), with one study observing no role at all for temporal associations (Schechtman et al., 2023). At first glance, these findings appear in tension with our model, where temporal associations drive offline consolidation. Indeed, prior models have accounted for these findings by suppressing temporal context during sleep (Liu and Ranganath 2024; Sherman et al., 2025). However, earlier models in the CMR lineage have successfully captured the joint contributions of semantic and temporal associations to encoding and retrieval (Polyn et al., 2009), and these processes could extend naturally to offline replay. In a paradigm where semantic associations are especially salient during awake learning, the model could weight these associations more and account for greater co-reactivation and sleep-dependent memory benefits for semantically related than temporally related items. Consistent with this idea, Schechtman et al. (2023) speculated that their null temporal effects likely reflected the task’s emphasis on semantic associations. When temporal associations are more salient and task-relevant, sleep-related benefits for temporally contiguous items are more likely to emerge (e.g., Drosopoulos et al., 2007; King et al., 2017).”</p><p>The reviewer’s comment points to fruitful directions for future work that could employ our framework to dissect the relative contributions of semantic and temporal associations to memory consolidation.</p><disp-quote content-type="editor-comment"><p>(2) During replay, the model is set so that the next reactivated item is sampled without replacement (i.e., the model cannot get &quot;stuck&quot; on a single item). I'm not sure what the biological backing behind this is and why the brain can't reactivate the same item consistently.</p><p>Furthermore, I'm afraid that such a rule may artificially generate sequential reactivation of items regardless of wake training. Could the authors explain this better or show that this isn't the case?</p></disp-quote><p>We appreciate the opportunity to clarify this aspect of the model. We first note that this mechanism has long been a fundamental component of this class of models (Howard &amp; Kahana 2002). Many classic memory models (Brown et al., 2000; Burgess &amp; Hitch, 1991; Lewandowsky &amp; Murdock 1989) incorporate response suppression, in which activated items are temporarily inhibited. The simplest implementation, which we use here, removes activated items from the pool of candidate items. Alternative implementations achieve this through transient inhibition, often conceptualized as neuronal fatigue (Burgess &amp; Hitch, 1991; Grossberg 1978). Our model adopts a similar perspective, interpreting this mechanism as mimicking a brief refractory period that renders reactivated neurons unlikely to fire again within a short physiological event such as a sharp-wave ripple. Importantly, this approach does not generate spurious sequences. Instead, the model’s ability to preserve the structure of wake experience during replay depends entirely on the learned associations between items (without these associations, item order would be random). Similar assumptions are also common in models of replay. For example, reinforcement learning models of replay incorporate mechanisms such as inhibition to prevent repeated reactivations (e.g., Diekmann &amp; Cheng, 2023) or prioritize reactivation based on ranking to limit items to a single replay (e.g., Mattar &amp; Daw, 2018). We now discuss these points in the section titled “A context model of memory replay”</p><p>“This mechanism of sampling without replacement, akin to response suppression in established context memory models (Howard &amp; Kahana 2002), could be implemented by neuronal fatigue or refractory dynamics (Burgess &amp; Hitch, 1991; Grossberg 1978). Non-repetition during reactivation is also a common assumption in replay models that regulate reactivation through inhibition or prioritization (Diekmann &amp; Cheng 2023; Mattar &amp; Daw 2018; Singh et al., 2022).”</p><disp-quote content-type="editor-comment"><p>(3) If I understand correctly, there are two ways in which novelty (i.e., less exposure) is accounted for in the model. The first and more talked about is the suppression mechanism (lines 639-646). The second is a change in learning rates (lines 593-595). It's unclear to me why both procedures are needed, how they differ, and whether these are two different mechanisms that the model implements. Also, since the authors controlled the extent to which each item was experienced during wakefulness, it's not entirely clear to me which of the simulations manipulated novelty on an individual item level, as described in lines 593-595 (if any).</p></disp-quote><p>We agree that these mechanisms and their relationships would benefit from clarification. As noted, novelty influences learning through two distinct mechanisms. First, the suppression mechanism is essential for capturing the inverse relationship between the amount of wake experience and the frequency of replay, as observed in several studies. This mechanism ensures that items with high wake activity are less likely to dominate replay. Second, the decrease in learning rates with repetition is crucial for preserving the stochasticity of replay. Without this mechanism, the model would increase weights linearly, leading to an exponential increase in the probability of successive wake items being reactivated back-to-back due to the use of a softmax choice rule. This would result in deterministic replay patterns, which are inconsistent with experimental observations.</p><p>We have revised the Methods section to explicitly distinguish these two mechanisms:</p><p>“This experience-dependent suppression mechanism is distinct from the reduction of learning rates through repetition; it does not modulate the update of memory associations but exclusively governs which items are most likely to initiate replay.”</p><p>We have also clarified our rationale for including a learning rate reduction mechanism:</p><p>“The reduction in learning rates with repetition is important for maintaining a degree of stochasticity in the model’s replay during task repetition, since linearly increasing weights would, through the softmax choice rule, exponentially amplify differences in item reactivation probabilities, sharply reducing variability in replay.”</p><p>Finally, we now specify exactly where the learning-rate reduction applied, namely in simulations where sequences are repeated across multiple sessions:</p><p>“In this simulation, the learning rates progressively decrease across sessions, as described above.“</p><disp-quote content-type="editor-comment"><p>As to the first mechanism - experience-based suppression - I find it challenging to think of a biological mechanism that would achieve this and is selectively activated immediately before sleep (somehow anticipating its onset). In fact, the prominent synaptic homeostasis hypothesis suggests that such suppression, at least on a synaptic level, is exactly what sleep itself does (i.e., prune or weaken synapses that were enhanced due to learning during the day). This begs the question of whether certain sleep stages (or ultradian cycles) may be involved in pruning, whereas others leverage its results for reactivation (e.g., a sequential hypothesis; Rasch &amp; Born, 2013). That could be a compelling synthesis of this literature. Regardless of whether the authors agree, I believe that this point is a major caveat to the current model. It is addressed in the discussion, but perhaps it would be beneficial to explicitly state to what extent the results rely on the assumption of a pre-sleep suppression mechanism.</p></disp-quote><p>We appreciate the reviewer raising this important point. Unlike the mechanism proposed by the synaptic homeostasis hypothesis, the suppression mechanism in our model does not suppress items based on synapse strength, nor does it modify synaptic weights. Instead, it determines the level of suppression for each item based on activity during awake experience. The brain could implement such a mechanism by tagging each item according to its activity level during wakefulness. During subsequent consolidation, the initial reactivation of an item during replay would reflect this tag, influencing how easily it can be reactivated.</p><p>A related hypothesis has been proposed in recent work, suggesting that replay avoids recently active trajectories due to spike frequency adaptation in neurons (Mallory et al., 2024). Similarly, the suppression mechanism in our model is critical for explaining the observed negative relationship between the amount of recent wake experience and the degree of replay.</p><p>We discuss the biological plausibility of this mechanism and its relationship with existing models in the Introduction. In the section titled “The influence of experience”, we have added the following:</p><p>“Our model implements an activity‑dependent suppression mechanism that, at the onset of each offline replay event, assigns each item a selection probability inversely proportional to its activation during preceding wakefulness. The brain could implement this by tagging each memory trace in proportion to its recent activation; during consolidation, that tag would then regulate starting replay probability, making highly active items less likely to be reactivated. A recent paper found that replay avoids recently traversed trajectories through awake spike‑frequency adaptation (Mallory et al., 2025), which could implement this kind of mechanism. In our simulations, this suppression is essential for capturing the inverse relationship between replay frequency and prior experience. Note that, unlike the synaptic homeostasis hypothesis (Tononi &amp; Cirelli 2006), which proposes that the brain globally downscales synaptic weights during sleep, this mechanism leaves synaptic weights unchanged and instead biases the selection process during replay.”</p><disp-quote content-type="editor-comment"><p>(4) As the manuscript mentions, the only difference between sleep and wake in the model is the initial conditions (a0). This is an obvious simplification, especially given the last author's recent models discussing the very different roles of REM vs NREM. Could the authors suggest how different sleep stages may relate to the model or how it could be developed to interact with other successful models such as the ones the last author has developed (e.g., C-HORSE)?</p></disp-quote><p>We appreciate the encouragement to comment on the roles of different sleep stages in the manuscript, especially since, as noted, the lab is very interested in this and has explored it in other work. We chose to focus on NREM in this work because the vast majority of electrophysiological studies of sleep replay have identified these events during NREM. In addition, our lab’s theory of the role of REM (Singh et al., 2022, PNAS) is that it is a time for the neocortex to replay remote memories, in complement to the more recent memories replayed during NREM. The experiments we simulate all involve recent memories. Indeed, our view is that part of the reason that there is so little data on REM replay may be that experimenters are almost always looking for traces of recent memories (for good practical and technical reasons).</p><p>Regarding the simplicity of the distinction between simulated wake and sleep replay, we view it as an asset of the model that it can account for many of the different characteristics of awake and NREM replay with very simple assumptions about differences in the initial conditions. There are of course many other differences between the states that could be relevant to the impact of replay, but the current target empirical data did not necessitate us taking those into account. This allows us to argue that differences in initial conditions should play a substantial role in an account of the differences between wake and sleep replay.</p><p>We have added discussion of these ideas and how they might be incorporated into future versions of the model in the Discussion section:</p><p>“Our current simulations have focused on NREM, since the vast majority of electrophysiological studies of sleep replay have identified replay events in this stage. We have proposed in other work that replay during REM sleep may provide a complementary role to NREM sleep, allowing neocortical areas to reinstate remote, already-consolidated memories that need to be integrated with the memories that were recently encoded in the hippocampus and replayed during NREM (Singh et al., 2022). An extension of our model could undertake this kind of continual learning setup, where the student but not teacher network retains remote memories, and the driver of replay alternates between hippocampus (NREM) and cortex (REM) over the course of a night of simulated sleep. Other differences between stages of sleep and between sleep and wake states are likely to become important for a full account of how replay impacts memory. Our current model parsimoniously explains a range of differences between awake and sleep replay by assuming simple differences in initial conditions, but we expect many more characteristics of these states (e.g., neural activity levels, oscillatory profiles, neurotransmitter levels, etc.) will be useful to incorporate in the future.”</p><disp-quote content-type="editor-comment"><p>Finally, I wonder how the model would explain findings (including the authors') showing a preference for reactivation of weaker memories. The literature seems to suggest that it isn't just a matter of novelty or exposure, but encoding strength. Can the model explain this? Or would it require additional assumptions or some mechanism for selective endogenous reactivation during sleep and rest?</p></disp-quote><p>We appreciate the encouragement to discuss this, as we do think the model could explain findings showing a preference for reactivation of weaker memories, as in Schapiro et al. (2018). In our framework, memory strength is reflected in the magnitude of each memory’s associated synaptic weights, so that stronger memories yield higher retrieved‑context activity during wake encoding than weaker ones. Because the model’s suppression mechanism reduces an item’s replay probability in proportion to its retrieved‑context activity, items with larger weights (strong memories) are more heavily suppressed at the onset of replay, while those with smaller weights (weaker memories) receive less suppression. When items have matched reward exposure, this dynamic would bias offline replay toward weaker memories, therefore preferentially reactivating weak memories.</p><p>In the section titled “The influence of experience”, we updated a sentence to discuss this idea more explicitly:</p><p>“Such a suppression mechanism may be adaptive, allowing replay to benefit not only the most recently or strongly encoded items but also to provide opportunities for the consolidation of weaker or older memories, consistent with empirical evidence (e.g., Schapiro et al. 2018; Yu et al., 2024).”</p><disp-quote content-type="editor-comment"><p>(5) Lines 186-200 - Perhaps I'm misunderstanding, but wouldn't it be trivial that an external cue at the end-item of Figure 7a would result in backward replay, simply because there is no potential for forward replay for sequences starting at the last item (there simply aren't any subsequent items)? The opposite is true, of course, for the first-item replay, which can't go backward. More generally, my understanding of the literature on forward vs backward replay is that neither is linked to the rodent's location. Both commonly happen at a resting station that is further away from the track. It seems as though the model's result may not hold if replay occurs away from the track (i.e. if a0 would be equal for both pre- and post-run).</p></disp-quote><p>In studies where animals run back and forth on a linear track, replay events are decoded separately for left and right runs, identifying both forward and reverse sequences for each direction, for example using direction-specific place cell sequence templates. Accordingly, in our simulation of, e.g., Ambrose et al. (2016), we use two independent sequences, one for left runs and one for right runs (an approach that has been taken in prior replay modeling work). Crucially, our model assumes a context reset between running episodes, preventing the final item of one traversal from acquiring contextual associations with the first item of the next. As a result, learning in the two sequences remains independent, and when an external cue is presented at the track’s end, replay predominantly unfolds in the backward direction, only occasionally producing forward segments when the cue briefly reactivates an earlier sequence item before proceeding forward.</p><p>We added a note to the section titled “The context-dependency of memory replay” to clarify this:</p><p>“In our model, these patterns are identical to those in our simulation of Ambrose et al. (2016), which uses two independent sequences to mimic the two run directions. This is because the drifting context resets before each run sequence is encoded, with the pause between runs acting as an event boundary that prevents the final item of one traversal from associating with the first item of the next, thereby keeping learning in each direction independent.”</p><p>To our knowledge, no study has observed a similar asymmetry when animals are fully removed from the track, although both types of replay can be observed when animals are away from the track. For example, Gupta et al. (2010) demonstrated that when animals replay trajectories far from their current location, the ratio of forward vs. backward replay appears more balanced. We now highlight this result in the manuscript and explain how it aligns with the predictions of our model:</p><p>“For example, in tasks where the goal is positioned in the middle of an arm rather than at its end, CMR-replay predicts a more balanced ratio of forward and reverse replay, whereas the EVB model still predicts a dominance of reverse replay due to backward gain propagation from the reward. This contrast aligns with empirical findings showing that when the goal is located in the middle of an arm, replay events are more evenly split between forward and reverse directions (Gupta et al., 2010), whereas placing the goal at the end of a track produces a stronger bias toward reverse replay (Diba &amp; Buzsaki 2007).”</p><p>Although no studies, to our knowledge, have observed a context-dependent asymmetry between forward and backward replay when the animal is away from the track, our model does posit conditions under which it could. Specifically, it predicts that deliberation on a specific memory, such as during planning, could generate an internal context input that biases replay: actively recalling the first item of a sequence may favor forward replay, while thinking about the last item may promote backward replay, even when the individual is physically distant from the track.</p><p>We now discuss this prediction in the section titled “The context-dependency of memory replay”:</p><p>“Our model also predicts that deliberation on a specific memory, such as during planning, could serve to elicit an internal context cue that biases replay: actively recalling the first item of a sequence may favor forward replay, while thinking about the last item may promote backward replay, even when the individual is physically distant from the track. While not explored here, this mechanism presents a potential avenue for future modeling and empirical work.”</p><disp-quote content-type="editor-comment"><p>(6) The manuscript describes a study by Bendor &amp; Wilson (2012) and tightly mimics their results. However, notably, that study did not find triggered replay immediately following sound presentation, but rather a general bias toward reactivation of the cued sequence over longer stretches of time. In other words, it seems that the model's results don't fully mirror the empirical results. One idea that came to mind is that perhaps it is the R/L context - not the first R/L item - that is cued in this study. This is in line with other TMR studies showing what may be seen as contextual reactivation. If the authors think that such a simulation may better mirror the empirical results, I encourage them to try. If not, however, this limitation should be discussed.</p></disp-quote><p>Although our model predicts that replay is triggered immediately by the sound cue, it also predicts a sustained bias toward the cued sequence. Replay in our model unfolds across the rest phase as multiple successive events, so the bias observed in our sleep simulations indeed reflects a prolonged preference for the cued sequence.</p><p>We now discuss this issue, acknowledging the discrepancy:</p><p>“Bendor and Wilson (2012) found that sound cues during sleep did not trigger immediate replay, but instead biased reactivation toward the cued sequence over an extended period of time. While the model does exhibit some replay triggered immediately by the cue, it also captures the sustained bias toward the cued sequence over an extended period.”</p><p>Second, within this framework, context is modeled as a weighted average of the features associated with items. As a result, cueing the model with the first R/L item produces qualitatively similar outcomes as cueing it with a more extended R/L cue that incorporates features of additional items. This is because both approaches ultimately use context features unique to the two sides.</p><disp-quote content-type="editor-comment"><p>(7) There is some discussion about replay's benefit to memory. One point of interest could be whether this benefit changes between wake and sleep. Relatedly, it would be interesting to see whether the proportion of forward replay, backward replay, or both correlated with memory benefits. I encourage the authors to extend the section on the function of replay and explore these questions.</p></disp-quote><p>We thank the reviewer for this suggestion. Regarding differences in the contribution of wake and sleep to memory, our current simulations predict that compared to rest in the task environment, sleep is less biased toward initiating replay at specific items, leading to a more uniform benefit across all memories. Regarding the contributions of forward and backward replay, our model predicts that both strengthen bidirectional associations between items and contexts, benefiting memory in qualitatively similar ways. Furthermore, we suggest that the offline learning captured by our teacher-student simulations reflects consolidation processes that are specific to sleep.</p><p>We have expanded the section titled <bold>“</bold>The influence of experience<bold>”</bold> to discuss these predictions of the model:</p><p>“The results outlined above arise from the model's assumption that replay strengthens bidirectional associations between items and contexts to benefit memory. This assumption leads to several predictions about differences across replay types. First, the model predicts that sleep yields different memory benefits compared to rest in the task environment: Sleep is less biased toward initiating replay at specific items, resulting in a more uniform benefit across all memories. Second, the model predicts that forward and backward replay contribute to memory in qualitatively similar ways but tend to benefit different memories. This divergence arises because forward and backward replay exhibit distinct item preferences, with backward replay being more likely to include rewarded items, thereby preferentially benefiting those memories.”</p><p>We also updated the “The function of replay” section to include our teacher-student speculation:</p><p>“We speculate that the offline learning observed in these simulations corresponds to consolidation processes that operate specifically during sleep, when hippocampal-neocortical dynamics are especially tightly coupled (Klinzing et al., 2019).”</p><disp-quote content-type="editor-comment"><p>(8) Replay has been mostly studied in rodents, with few exceptions, whereas CMR and similar models have mostly been used in humans. Although replay is considered a good model of episodic memory, it is still limited due to limited findings of sequential replay in humans and its reliance on very structured and inherently autocorrelated items (i.e., place fields). I'm wondering if the authors could speak to the implications of those limitations on the generalizability of their model. Relatedly, I wonder if the model could or does lead to generalization to some extent in a way that would align with the complementary learning systems framework.</p></disp-quote><p>We appreciate these insightful comments. Traditionally, replay studies have focused on spatial tasks with autocorrelated item representations (e.g., place fields). However, an increasing number of human studies have demonstrated sequential replay using stimuli with distinct, unrelated representations. Our model is designed to accommodate both scenarios. In our current simulations, we employ orthogonal item representations while leveraging a shared, temporally autocorrelated context to link successive items. We anticipate that incorporating autocorrelated item representations would further enhance sequence memory by increasing the similarity between successive contexts. Overall, we believe that the model generalizes across a broad range of experimental settings, regardless of the degree of autocorrelation between items. Moreover, the underlying framework has been successfully applied to explain sequential memory in both spatial domains, explaining place cell firing properties (e.g., Howard et al., 2004), and in non-spatial domains, such as free recall experiments where items are arbitrarily related.</p><p>In the section titled “A context model of memory replay”, we added this comment to address this point:</p><p>“Its contiguity bias stems from its use of shared, temporally autocorrelated context to link successive items, despite the orthogonal nature of individual item representations. This bias would be even stronger if items had overlapping representations, as observed in place fields.”</p><p>Since CMR-replay learns distributed context representations where overlap across context vectors captures associative structure, and replay helps strengthen that overlap, this could indeed be viewed as consonant with complementary learning systems integration processes.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public Review):</bold></p><p>This manuscript proposes a model of replay that focuses on the relation between an item and its context, without considering the value of the item. The model simulates awake learning, awake replay, and sleep replay, and demonstrates parallels between memory phenomenon driven by encoding strength, replay of sequence learning, and activation of nearest neighbor to infer causality. There is some discussion of the importance of suppression/inhibition to reduce activation of only dominant memories to be replayed, potentially boosting memories that are weakly encoded. Very nice replications of several key replay findings including the effect of reward and remote replay, demonstrating the equally salient cue of context for offline memory consolidation.</p><p>I have no suggestions for the main body of the study, including methods and simulations, as the work is comprehensive, transparent, and well-described. However, I would like to understand how the CMRreplay model fits with the current understanding of the importance of excitation vs inhibition, remembering vs forgetting, activation vs deactivation, strengthening vs elimination of synapses, and even NREM vs REM as Schapiro has modeled. There seems to be a strong association with the efforts of the model to instantiate a memory as well as how that reinstantiation changes across time. But that is not all this is to consolidation. The specific roles of different brain states and how they might change replay is also an important consideration.</p></disp-quote><p>We are gratified that the reviewer appreciated the work, and we agree that the paper would benefit from comment on the connections to these other features of consolidation.</p><p>Excitation vs. inhibition: CMR-replay does not model variations in the excitation-inhibition balance across brain states (as in other models, e.g., Chenkov et al., 2017), since it does not include inhibitory connections. However, we posit that the experience-dependent suppression mechanism in the model might, in the brain, involve inhibitory processes. Supporting this idea, studies have observed increased inhibition with task repetition (Berners-Lee et al., 2022). We hypothesize that such mechanisms may underlie the observed inverse relationship between task experience and replay frequency in many studies. We discuss this in the section titled “A context model of memory replay”:</p><p>“The proposal that a suppression mechanism plays a role in replay aligns with models that regulate place cell reactivation via inhibition (Malerba et al., 2016) and with empirical observations of increased hippocampal inhibitory interneuron activity with experience (Berners-Lee et al., 2022). Our model assumes the presence of such inhibitory mechanisms but does not explicitly model them.”</p><p>Remembering/forgetting, activation/deactivation, and strengthening/elimination of synapses: The model does not simulate synaptic weight reduction or pruning, so it does not forget memories through the weakening of associated weights. However, forgetting can occur when a memory is replayed less frequently than others, leading to reduced activation of that memory compared to its competitors during context-driven retrieval. In the Discussion section, we acknowledge that a biologically implausible aspect of our model is that it implements only synaptic strengthening:</p><p>“Aspects of the model, such as its lack of regulation of the cumulative positive weight changes that can accrue through repeated replay, are biologically implausible (as biological learning results in both increases and decreases in synaptic weights) and limit the ability to engage with certain forms of low level neural data (e.g., changes in spine density over sleep periods; de Vivo et al., 2017; Maret et al., 2011). It will be useful for future work to explore model variants with more elements of biological plausibility.” Different brain states and NREM vs REM: Reviewer 1 also raised this important issue (see above). We have added the following thoughts on differences between these states and the relationship to our prior work to the Discussion section:</p><p>“Our current simulations have focused on NREM, since the vast majority of electrophysiological studies of sleep replay have identified replay events in this stage. We have proposed in other work that replay during REM sleep may provide a complementary role to NREM sleep, allowing neocortical areas to reinstate remote, already-consolidated memories that need to be integrated with the memories that were recently encoded in the hippocampus and replayed during NREM (Singh et al., 2022). An extension of our model could undertake this kind of continual learning setup, where the student but not teacher network retains remote memories, and the driver of replay alternates between hippocampus (NREM) and cortex (REM) over the course of a night of simulated sleep. Other differences between stages of sleep and between sleep and wake states are likely to become important for a full account of how replay impacts memory. Our current model parsimoniously explains a range of differences between awake and sleep replay by assuming simple differences in initial conditions, but we expect many more characteristics of these states (e.g., neural activity levels, oscillatory profiles, neurotransmitter levels, etc.) will be useful to incorporate in the future.”</p><p>We hope these points clarify the model’s scope and its potential for future extensions.</p><disp-quote content-type="editor-comment"><p>Do the authors suggest that these replay systems are more universal to offline processes beyond episodic memory? What about procedural memories and working memory?</p></disp-quote><p>We thank the reviewer for raising this important question. We have clarified in the manuscript:</p><p>“We focus on the model as a formulation of hippocampal replay, capturing how the hippocampus may replay past experiences through simple and interpretable mechanisms.”</p><p>With respect to other forms of memory, we now note that:</p><p>“This motor memory simulation using a model of hippocampal replay is consistent with evidence that hippocampal replay can contribute to consolidating memories that are not hippocampally dependent at encoding (Schapiro et al., 2019; Sawangjit et al., 2018). It is possible that replay in other, more domain-specific areas could also contribute (Eichenlaub et al., 2020).”</p><disp-quote content-type="editor-comment"><p>Though this is not a biophysical model per se, can the authors speak to the neuromodulatory milieus that give rise to the different types of replay?</p></disp-quote><p>Our work aligns with the perspective proposed by Hasselmo (1999), which suggests that waking and sleep states differ in the degree to which hippocampal activity is driven by external inputs. Specifically, high acetylcholine levels during waking bias activity to flow into the hippocampus, while low acetylcholine levels during sleep allow hippocampal activity to influence other brain regions. Consistent with this view, our model posits that wake replay is more biased toward items associated with the current resting location due to the presence of external input during waking states. In the Discussion section, we have added a comment on this point:</p><p>“Our view aligns with the theory proposed by Hasselmo (1999), which suggests that the degree of hippocampal activity driven by external inputs differs between waking and sleep states: High acetylcholine levels during wakefulness bias activity into the hippocampus, while low acetylcholine levels during slow-wave sleep allow hippocampal activity to influence other brain regions.”</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Public Review):</bold></p><p>In this manuscript, Zhou et al. present a computational model of memory replay. Their model (CMR-replay) draws from temporal context models of human memory (e.g., TCM, CMR) and claims replay may be another instance of a context-guided memory process. During awake learning, CMR replay (like its predecessors) encodes items alongside a drifting mental context that maintains a recency-weighted history of recently encoded contexts/items. In this way, the presently encoded item becomes associated with other recently learned items via their shared context representation - giving rise to typical effects in recall such as primacy, recency, and contiguity. Unlike its predecessors, CMR-replay has built-in replay periods. These replay periods are designed to approximate sleep or wakeful quiescence, in which an item is spontaneously reactivated, causing a subsequent cascade of item-context reactivations that further update the model's item-context associations.</p><p>Using this model of replay, Zhou et al. were able to reproduce a variety of empirical findings in the replay literature: e.g., greater forward replay at the beginning of a track and more backward replay at the end; more replay for rewarded events; the occurrence of remote replay; reduced replay for repeated items, etc. Furthermore, the model diverges considerably (in implementation and predictions) from other prominent models of replay that, instead, emphasize replay as a way of predicting value from a reinforcement learning framing (i.e., EVB, expected value backup).</p><p>Overall, I found the manuscript clear and easy to follow, despite not being a computational modeller myself. (Which is pretty commendable, I'd say). The model also was effective at capturing several important empirical results from the replay literature while relying on a concise set of mechanisms - which will have implications for subsequent theory-building in the field.</p><p>With respect to weaknesses, additional details for some of the methods and results would help the readers better evaluate the data presented here (e.g., explicitly defining how the various 'proportion of replay' DVs were calculated).</p><p>For example, for many of the simulations, the y-axis scale differs from the empirical data despite using comparable units, like the proportion of replay events (e.g., Figures 1B and C). Presumably, this was done to emphasize the similarity between the empirical and model data. But, as a reader, I often found myself doing the mental manipulation myself anyway to better evaluate how the model compared to the empirical data. Please consider using comparable y-axis ranges across empirical and simulated data wherever possible.</p></disp-quote><p>We appreciate this point. As in many replay modeling studies, our primary goal is to provide a qualitative fit that demonstrates the general direction of differences between our model and empirical data, without engaging in detailed parameter fitting for a precise quantitative fit. Still, we agree that where possible, it is useful to better match the axes. We have updated figures 2B and 2C so that the y-axis scales are more directly comparable between the empirical and simulated data.</p><disp-quote content-type="editor-comment"><p>In a similar vein to the above point, while the DVs in the simulations/empirical data made intuitive sense, I wasn't always sure precisely how they were calculated. Consider the &quot;proportion of replay&quot; in Figure 1A. In the Methods (perhaps under Task Simulations), it should specify exactly how this proportion was calculated (e.g., proportions of all replay events, both forwards and backwards, combining across all simulations from Pre- and Post-run rest periods). In many of the examples, the proportions seem to possibly sum to 1 (e.g., Figure 1A), but in other cases, this doesn't seem to be true (e.g., Figure 3A). More clarity here is critical to help readers evaluate these data. Furthermore, sometimes the labels themselves are not the most informative. For example, in Figure 1A, the y-axis is &quot;Proportion of replay&quot; and in 1C it is the &quot;Proportion of events&quot;. I presumed those were the same thing - the proportion of replay events - but it would be best if the axis labels were consistent across figures in this manuscript when they reflect the same DV.</p></disp-quote><p>We appreciate these useful suggestions. We have revised the Methods section to explain in detail how DVs are calculated for each simulation. The revisions clarify the differences between related measures, such as those shown in Figures 1A and 1C, so that readers can more easily see how the DVs are defined and interpreted in each case.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #4/Reviewing Editor (Public Review):</bold></p><p>Summary:</p><p>With their 'CMR-replay' model, Zhou et al. demonstrate that the use of spontaneous neural cascades in a context-maintenance and retrieval (CMR) model significantly expands the range of captured memory phenomena.</p><p>Strengths:</p><p>The proposed model compellingly outperforms its CMR predecessor and, thus, makes important strides towards understanding the empirical memory literature, as well as highlighting a cognitive function of replay.</p><p>Weaknesses:</p><p>Competing accounts of replay are acknowledged but there are no formal comparisons and only CMR-replay predictions are visualized. Indeed, other than the CMR model, only one alternative account is given serious consideration: A variant of the 'Dyna-replay' architecture, originally developed in the machine learning literature (Sutton, 1990; Moore &amp; Atkeson, 1993) and modified by Mattar et al (2018) such that previously experienced event-sequences get replayed based on their relevance to future gain. Mattar et al acknowledged that a realistic Dyna-replay mechanism would require a learned representation of transitions between perceptual and motor events, i.e., a 'cognitive map'. While Zhou et al. note that the CMR-replay model might provide such a complementary mechanism, they emphasize that their account captures replay characteristics that Dyna-replay does not (though it is unclear to what extent the reverse is also true).</p></disp-quote><p>We thank the reviewer for these thoughtful comments and appreciate the opportunity to clarify our approach. Our goal in this work is to contrast two dominant perspectives in replay research: replay as a mechanism for learning reward predictions and replay as a process for memory consolidation. These models were chosen as representatives of their classes of models because they use simple and interpretable mechanisms that can simulate a wide range of replay phenomena, making them ideal for contrasting these two perspectives.</p><p>Although we implemented CMR-replay as a straightforward example of the memory-focused view, we believe the proposed mechanisms could be extended to other architectures, such as recurrent neural networks, to produce similar results. We now discuss this possibility in the revised manuscript (see below). However, given our primary goal of providing a broad and qualitative contrast of these two broad perspectives, we decided not to undertake simulations with additional individual models for this paper.</p><p>Regarding the Mattar &amp; Daw model, it is true that a mechanistic implementation would require a mechanism that avoids precomputing priorities before replay. However, the &quot;need&quot; component of their model already incorporates learned expectations of transitions between actions and events. Thus, the model's limitations are not due to the absence of a cognitive map.</p><p>In contrast, while CMR-replay also accumulates memory associations that reflect experienced transitions among events, it generates several qualitatively distinct predictions compared to the Mattar &amp; Daw model. As we note in the manuscript, these distinctions make CMR-replay a contrasting rather than complementary perspective.</p><disp-quote content-type="editor-comment"><p>Another important consideration, however, is how CMR replay compares to alternative mechanistic accounts of cognitive maps. For example, Recurrent Neural Networks are adept at detecting spatial and temporal dependencies in sequential input; these networks are being increasingly used to capture psychological and neuroscientific data (e.g., Zhang et al, 2020; Spoerer et al, 2020), including hippocampal replay specifically (Haga &amp; Fukai, 2018). Another relevant framework is provided by Associative Learning Theory, in which bidirectional associations between static and transient stimulus elements are commonly used to explain contextual and cue-based phenomena, including associative retrieval of absent events (McLaren et al, 1989; Harris, 2006; Kokkola et al, 2019). Without proper integration with these modeling approaches, it is difficult to gauge the innovation and significance of CMR-replay, particularly since the model is applied post hoc to the relatively narrow domain of rodent maze navigation.</p></disp-quote><p>First, we would like to clarify our principal aim in this work is to characterize the nature of replay, rather than to model cognitive maps per se. Accordingly, CMR‑replay is not designed to simulate head‐direction signals, perform path integration, or explain the spatial firing properties of neurons during navigation. Instead, it focuses squarely on sequential replay phenomena, simulating classic rodent maze reactivation studies and human sequence‐learning tasks. These simulations span a broad array of replay experimental paradigms to ensure extensive coverage of the replay findings reported across the literature. As such, the contribution of this work is in explaining the mechanisms and functional roles of replay, and demonstrating that a model that employs simple and interpretable memory mechanisms not only explains replay phenomena traditionally interpreted through a value-based lens but also accounts for findings not addressed by other memory-focused models.</p><p>As the reviewer notes, CMR-replay shares features with other memory-focused models. However, to our knowledge, none of these related approaches have yet captured the full suite of empirical replay phenomena, suggesting the combination of mechanisms employed in CMR-replay is essential for explaining these phenomena. In the Discussion section, we now discuss the similarities between CMR-replay and related memory models and the possibility of integrating these approaches:</p><p>“Our theory builds on a lineage of memory-focused models, demonstrating the power of this perspective in explaining phenomena that have often been attributed to the optimization of value-based predictions. In this work, we focus on CMR-replay, which exemplifies the memory-centric approach through a set of simple and interpretable mechanisms that we believe are broadly applicable across memory domains. Elements of CMR-replay share similarities with other models that adopt a memory-focused perspective. The model learns distributed context representations whose overlaps encodes associations among items, echoing associative learning theories in which overlapping patterns capture stimulus similarity and learned associations (McLaren &amp; Mackintosh 2002). Context evolves through bidirectional interactions between items and their contextual representations, mirroring the dynamics found in recurrent neural networks (Haga &amp; Futai 2018; Levenstein et al., 2024). However, these related approaches have not been shown to account for the present set of replay findings and lack mechanisms—such as reward-modulated encoding and experience-dependent suppression—that our simulations suggest are essential for capturing these phenomena. While not explored here, we believe these mechanisms could be integrated into architectures like recurrent neural networks (Levenstein et al., 2024) to support a broader range of replay dynamics.”</p><disp-quote content-type="editor-comment"><p><bold>Recommendations For The Authors</bold></p><p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p><p>(1) Lines 94-96: These lines may be better positioned earlier in the paragraph.</p></disp-quote><p>We now introduce these lines earlier in the paragraph.</p><disp-quote content-type="editor-comment"><p>(2) Line 103 - It's unclear to me what is meant by the statement that &quot;the current context contains contexts associated with previous items&quot;. I understand why a slowly drifting context will coincide and therefore link with multiple items that progress rapidly in time, so multiple items will be linked to the same context and each item will be linked to multiple contexts. Is that the idea conveyed here or am I missing something? I'm similarly confused by line 129, which mentions that a context is updated by incorporating other items' contexts. How could a context contain other contexts?</p></disp-quote><p>In the model, each item has an associated context that can be retrieved via Mfc. This is true even before learning, since Mfc is initialized as an identity matrix. During learning and replay, we have a drifting context c that is updated each time an item is presented. At each timestep, the model first retrieves the current item’s associated context cf by Mfc, and incorporates it into c. Equation #2 in the Methods section illustrates this procedure in detail. Because of this procedure, the drifting context c is a weighted sum of past items’ associated contexts.</p><p>We recognize that these descriptions can be confusing. We have updated the Results section to better distinguish the drifting context from items’ associated context. For example, we note that:</p><p>“We represent the drifting context during learning and replay with c and an item's associated context with cf.”</p><p>We have also updated our description of the context drift procedure to distinguish these two quantities:</p><p>“During awake encoding of a sequence of items, for each item f, the model retrieves its associated context cf via Mfc. The drifting context c incorporates the item's associated context cf and downweights its representation of previous items' associated contexts (Figure 1c). Thus, the context layer maintains a recency weighted sum of past and present items' associated contexts.”</p><disp-quote content-type="editor-comment"><p>(3) Figure 1b and 1d - please clarify which axis in the association matrices represents the item and the context.</p></disp-quote><p>We have added labels to show what the axes represent in Figure 1.</p><disp-quote content-type="editor-comment"><p>(4) The terms &quot;experience&quot; and &quot;item&quot; are used interchangeably and it may be best to stick to one term.</p></disp-quote><p>We now use the term “item” wherever we describe the model results.</p><disp-quote content-type="editor-comment"><p>(5) The manuscript describes Figure 6 ahead of earlier figures - the authors may want to reorder their figures to improve readability.</p></disp-quote><p>We appreciate this suggestion. We decided to keep the current figure organization since it allows us to group results into different themes and avoid redundancy.</p><disp-quote content-type="editor-comment"><p>(6) Lines 662-664 are repeated with a different ending, this is likely an error.</p></disp-quote><p>We have fixed this error.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3 (Recommendations For The Authors):</bold></p><p>Below, I have outlined some additional points that came to mind in reviewing the manuscript - in no particular order.</p><p>(1) Figure 1: I found the ordering of panels a bit confusing in this figure, as the reading direction changes a couple of times in going from A to F. Would perhaps putting panel C in the bottom left corner and then D at the top right, with E and F below (also on the right) work?</p></disp-quote><p>We agree that this improves the figure. We have restructured the ordering of panels in this figure.</p><disp-quote content-type="editor-comment"><p>(2) Simulation 1: When reading the intro/results for the first simulation (Figure 2a; Diba &amp; Buszaki, 2007; &quot;When animals traverse a linear track...&quot;, page 6, line 186). It wasn't clear to me why pre-run rest would have any forward replay, particularly if pre-run implied that the animal had no experience with the track yet. But in the Methods this becomes clearer, as the model encodes the track eight times prior to the rest periods. Making this explicit in the text would make it easier to follow. Also, was there any reason why specifically eight sessions of awake learning, in particular, were used?</p></disp-quote><p>We now make more explicit that the animals have experience with the track before pre-run rest recording:</p><p>“Animals first acquire experience with a linear track by traversing it to collect a reward. Then, during the pre-run rest recording, forward replay predominates.”</p><p>We included eight sessions of awake learning to match with the number of sessions in Shin et al. (2017), since this simulation attempts to explain data from that study. After each repetition, the model engages in rest. We have revised the Methods section to indicate the motivation for this choice:</p><p>“In the simulation that examines context-dependent forward and backward replay through experience (Figs. 2a and 5a), CMR-replay encodes an input sequence shown in Fig. 7a, which simulates a linear track run with no ambiguity in the direction of inputs, over eight awake learning sessions (as in Shin et al. 2019)”</p><disp-quote content-type="editor-comment"><p>(3) Frequency of remote replay events: In the simulation based on Gupta et al, how frequently overall does remote replay occur? In the main text, the authors mention the mean frequency with which shortcut replay occurs (i.e., the mean proportion of replay events that contain a shortcut sequence = 0.0046), which was helpful. But, it also made me wonder about the likelihood of remote replay events. I would imagine that remote replay events are infrequent as well - given that it is considerably more likely to replay sequences from the local track, given the recency-weighted mental context. Reporting the above mean proportion for remote and local replay events would be helpful context for the reader.</p></disp-quote><p>In Figure 4c, we report the proportion of remote replay in the two experimental conditions of Gupta et al. that we simulate.</p><disp-quote content-type="editor-comment"><p>(4) Point of clarification re: backwards replay: Is backwards replay less likely to occur than forward replay overall because of the forward asymmetry associated with these models? For example, for a backwards replay event to occur, the context would need to drift backwards at least five times in a row, in spite of a higher probability of moving one step forward at each of those steps. Am I getting that right?</p></disp-quote><p>The reviewer’s interpretation is correct: CMR-replay is more likely to produce forward than backward replay in sleep because of its forward asymmetry. We note that this forward asymmetry leads to high likelihood of forward replay in the section titled “The context-dependency of memory replay”:</p><p>“As with prior retrieved context models (Howard &amp; Kahana 2002; Polyn et al., 2009), CMR-replay encodes stronger forward than backward associations. This asymmetry exists because, during the first encoding of a sequence, an item's associated context contributes only to its ensuing items' encoding contexts. Therefore, after encoding, bringing back an item's associated context is more likely to reactivate its ensuing than preceding items, leading to forward asymmetric replay (Fig. 6d left).”</p><disp-quote content-type="editor-comment"><p>(5) On terminating a replay period: &quot;At any t, the replay period ends with a probability of 0.1 or if a task-irrelevant item is reactivated.&quot; (Figure 1 caption; see also pg 18, line 635). How was the 0.1 decided upon? Also, could you please add some detail as to what a 'task-irrelevant item' would be? From what I understood, the model only learns sequences that represent the points in a track - wouldn't all the points in the track be task-relevant?</p></disp-quote><p>This value was arbitrarily chosen as a small value that allows probabilistic stopping. It was not motivated by prior modeling or a systematic search. We have added: “At each timestep, the replay period ends either with a stop probability of 0.1 or if a task-irrelevant item becomes reactivated. (The choice of the value 0.1 was arbitrary; future work could explore the implications of varying this parameter).”</p><p>In addition, we now explain in the paper that task irrelevant items “do not appear as inputs during awake encoding, but compete with task-relevant items for reactivation during replay, simulating the idea that other experiences likely compete with current experiences during periods of retrieval and reactivation.”</p><disp-quote content-type="editor-comment"><p>(6) Minor typos:</p><p>Turn all instances of &quot;nonlocal&quot; into &quot;non-local&quot;, or vice versa</p><p>&quot;For rest at the end of a run, cexternal is the context associated with the final item in the sequence. For rest at the end of a run, cexternal is the context associated with the start item.&quot; (pg 20, line 663) - I believe this is a typo and that the second sentence should begin with &quot;For rest at the START of a run&quot;.</p></disp-quote><p>We have updated the manuscript to correct these typos.</p><disp-quote content-type="editor-comment"><p>(7) Code availability: I may have missed it, but it doesn't seem like the code is currently available for these simulations. Including the commented code in a public repository (Github, OSF) would be very useful in this case.</p></disp-quote><p>We now include a Github link to our simulation code: <ext-link ext-link-type="uri" xlink:href="https://github.com/schapirolab/CMR-replay">https://github.com/schapirolab/CMR-replay</ext-link>.</p></body></sub-article></article>