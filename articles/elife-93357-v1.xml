<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">93357</article-id><article-id pub-id-type="doi">10.7554/eLife.93357</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.93357.4</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Reactivation strength during cued recall is modulated by graph distance within cognitive maps</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-338897"><name><surname>Kern</surname><given-names>Simon</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-9050-9040</contrib-id><email>simon.kern@zi-mannheim.de</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-338899"><name><surname>Nagel</surname><given-names>Juliane</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-338900"><name><surname>Gerchen</surname><given-names>Martin F</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-338901"><name><surname>Gürsoy</surname><given-names>Çağatay</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-242240"><name><surname>Meyer-Lindenberg</surname><given-names>Andreas</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-155598"><name><surname>Kirsch</surname><given-names>Peter</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-19714"><name><surname>Dolan</surname><given-names>Raymond J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9356-761X</contrib-id><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-33513"><name><surname>Gais</surname><given-names>Steffen</given-names></name><xref ref-type="aff" rid="aff8">8</xref><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-256198"><name><surname>Feld</surname><given-names>Gordon B</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1238-9493</contrib-id><email>Gordon.Feld@zi-mannheim.de</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01hynnt93</institution-id><institution>Clinical Psychology, Central Institute of Mental Health, Medical Faculty Mannheim, University of Heidelberg</institution></institution-wrap><addr-line><named-content content-type="city">Mannheim</named-content></addr-line><country>Germany</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01hynnt93</institution-id><institution>Psychiatry and Psychotherapy, Central Institute of Mental Health, Medical Faculty Mannheim, University of Heidelberg</institution></institution-wrap><addr-line><named-content content-type="city">Mannheim</named-content></addr-line><country>Germany</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01hynnt93</institution-id><institution>Addiction Behavior and Addiction Medicine, Central Institute of Mental Health, Medical Faculty Mannheim, University of Heidelberg</institution></institution-wrap><addr-line><named-content content-type="city">Mannheim</named-content></addr-line><country>Germany</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/038t36y30</institution-id><institution>Department of Psychology, Ruprecht Karl University of Heidelberg</institution></institution-wrap><addr-line><named-content content-type="city">Heidelberg</named-content></addr-line><country>Germany</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01qq34m02</institution-id><institution>Bernstein Center for Computational Neuroscience Heidelberg/Mannheim</institution></institution-wrap><addr-line><named-content content-type="city">Mannheim</named-content></addr-line><country>Germany</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>Max Planck UCL Centre for Computational Psychiatry and Ageing Research</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff7"><label>7</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02704qw51</institution-id><institution>Wellcome Centre for Human Neuroimaging, University College London</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff8"><label>8</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03a1kwz48</institution-id><institution>Institute of Medical Psychology and Behavioral Neurobiology, Eberhard-Karls-University Tübingen</institution></institution-wrap><addr-line><named-content content-type="city">Tübingen</named-content></addr-line><country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Schapiro</surname><given-names>Anna C</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00b30xv10</institution-id><institution>University of Pennsylvania</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>29</day><month>05</month><year>2024</year></pub-date><volume>12</volume><elocation-id>RP93357</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-10-12"><day>12</day><month>10</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-10-12"><day>12</day><month>10</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.07.31.551234"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-11-28"><day>28</day><month>11</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.93357.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-04-18"><day>18</day><month>04</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.93357.2"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-05-09"><day>09</day><month>05</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.93357.3"/></event></pub-history><permissions><copyright-statement>© 2023, Kern et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Kern et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-93357-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-93357-figures-v1.pdf"/><abstract><p>Declarative memory retrieval is thought to involve reinstatement of neuronal activity patterns elicited and encoded during a prior learning episode. Furthermore, it is suggested that two mechanisms operate during reinstatement, dependent on task demands: individual memory items can be reactivated simultaneously as a clustered occurrence or, alternatively, replayed sequentially as temporally separate instances. In the current study, participants learned associations between images that were embedded in a directed graph network and retained this information over a brief 8 min consolidation period. During a subsequent cued recall session, participants retrieved the learned information while undergoing magnetoencephalographic recording. Using a trained stimulus decoder, we found evidence for clustered reactivation of learned material. Reactivation strength of individual items during clustered reactivation decreased as a function of increasing graph distance, an ordering present solely for successful retrieval but not for retrieval failure. In line with previous research, we found evidence that sequential replay was dependent on retrieval performance and was most evident in low performers. The results provide evidence for distinct performance-dependent retrieval mechanisms, with graded clustered reactivation emerging as a plausible mechanism to search within abstract cognitive maps.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>MEG</kwd><kwd>brain decoding</kwd><kwd>memory replay</kwd><kwd>memory reactivation</kwd><kwd>retrieval</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004350</institution-id><institution>Studienstiftung des Deutschen Volkes</institution></institution-wrap></funding-source><award-id>PhD Scholarship</award-id><principal-award-recipient><name><surname>Kern</surname><given-names>Simon</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001659</institution-id><institution>Deutsche Forschungsgemeinschaft</institution></institution-wrap></funding-source><award-id>FE1617/2-1</award-id><principal-award-recipient><name><surname>Feld</surname><given-names>Gordon B</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution>German Sleep Research Society</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Kern</surname><given-names>Simon</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Items retrieved from cognitive maps are reactivated simultaneously or sequentially depending on the performance, where in the first case the reactivation strength reflects the distance within the map.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Memory classically relies on three distinct stages: encoding (learning), consolidation (strengthening and transforming), and retrieval (reinstating) of information. New episodic memories are learned by encoding a representation, thought to be realized in a specific spatio-temporal neuronal firing pattern in hippocampal and neocortical networks (<xref ref-type="bibr" rid="bib29">Frank et al., 2000</xref>; <xref ref-type="bibr" rid="bib58">Preston and Eichenbaum, 2013</xref>). These firing patterns are reactivated during subsequent rest or sleep, sometimes in fast sequential sequences, a process linked to memory consolidation (<xref ref-type="bibr" rid="bib8">Born and Wilhelm, 2012</xref>; <xref ref-type="bibr" rid="bib25">Feld and Born, 2017</xref>). Similarly, during retrieval, the same firing patterns seen during encoding are replayed in a manner that predicts retrieval success (<xref ref-type="bibr" rid="bib11">Carr et al., 2011</xref>; <xref ref-type="bibr" rid="bib28">Foster, 2017</xref>). Even though replay has been studied most intensely with respect to the hippocampus, the replay of memory traces in temporal succession is suggested as a general mechanism for planning, consolidation, and retrieval (<xref ref-type="bibr" rid="bib10">Buhry et al., 2011</xref>). While a rich body of evidence exists in rodents (<xref ref-type="bibr" rid="bib2">Ambrose et al., 2016</xref>; <xref ref-type="bibr" rid="bib12">Chen and Wilson, 2023</xref>; <xref ref-type="bibr" rid="bib27">Foster and Knierim, 2012</xref>; <xref ref-type="bibr" rid="bib55">Ólafsdóttir et al., 2018</xref>), the contributions of replay to memory storage and retrieval in humans are only beginning to be examined (<xref ref-type="bibr" rid="bib9">Brunec and Momennejad, 2022</xref>; <xref ref-type="bibr" rid="bib19">Eichenlaub et al., 2020</xref>; <xref ref-type="bibr" rid="bib30">Fuentemilla et al., 2010</xref>; <xref ref-type="bibr" rid="bib76">Wimmer et al., 2020</xref>).</p><p>One obstacle has been the difficulty in measuring sequential replay or general network reactivation in humans (here we follow the definition of <xref ref-type="bibr" rid="bib32">Genzel et al., 2020</xref>, where <italic>reactivation</italic> is used as an umbrella term for any form of reoccurrence of a previously encoded neural pattern related to information-encoding, and <italic>replay</italic> refers to reactivation events with a temporally sequential nature). The most straightforward method is to use intracranial electroencephalography, though this is generally only feasible within individuals undergoing evaluation for the management of epilepsy (<xref ref-type="bibr" rid="bib4">Axmacher et al., 2008</xref>; <xref ref-type="bibr" rid="bib22">Engel et al., 2005</xref>; <xref ref-type="bibr" rid="bib70">Staresina et al., 2015</xref>; <xref ref-type="bibr" rid="bib80">Zhang et al., 2015</xref>). Another approach is to use functional MRI (<xref ref-type="bibr" rid="bib64">Schuck and Niv, 2019</xref>; <xref ref-type="bibr" rid="bib79">Wittkuhn and Schuck, 2021</xref>), though the latter is burdened by the challenge posed by the sluggishness of the hemodynamic response. Researchers have recently started to leverage the spatio-temporal precision of magnetoencephalography (MEG), in combination with machine learning-based brain decoding techniques, to reveal sequential human replay in humans across a range of settings that includes memory, planning, and inference (<xref ref-type="bibr" rid="bib20">Eldar et al., 2018</xref>; <xref ref-type="bibr" rid="bib42">Kurth-Nelson et al., 2016</xref>; <xref ref-type="bibr" rid="bib43">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="bib45">Liu et al., 2021b</xref>; <xref ref-type="bibr" rid="bib50">McFadyen et al., 2023</xref>; <xref ref-type="bibr" rid="bib52">Nour et al., 2021</xref>; <xref ref-type="bibr" rid="bib76">Wimmer et al., 2020</xref>; <xref ref-type="bibr" rid="bib77">Wimmer et al., 2023</xref>; <xref ref-type="bibr" rid="bib78">Wise et al., 2021</xref>). Many of the latter studies deploy a novel statistical analysis technique, temporally delayed linear modeling (TDLM) (<xref ref-type="bibr" rid="bib44">Liu et al., 2021a</xref>). TDLM, and its variants, enables identification of sequential replay for previously experienced material during resting state (<xref ref-type="bibr" rid="bib43">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="bib45">Liu et al., 2021b</xref>), planning of upcoming behavioral output (<xref ref-type="bibr" rid="bib21">Eldar et al., 2020</xref>; <xref ref-type="bibr" rid="bib42">Kurth-Nelson et al., 2016</xref>; <xref ref-type="bibr" rid="bib50">McFadyen et al., 2023</xref>; <xref ref-type="bibr" rid="bib78">Wise et al., 2021</xref>), and memory retrieval (<xref ref-type="bibr" rid="bib76">Wimmer et al., 2020</xref>).</p><p><xref ref-type="bibr" rid="bib76">Wimmer et al., 2020</xref> reported sequential reactivation of episodic content following a single initial exposure during cued recall 1 d post encoding. Specifically, they showed participants eight short, narrated stories, each consisting of four different visual story anchor elements taken from six different categories (faces, buildings, body parts, objects, animals, and cars) and a unique ending element. In a next day recall session, participants were shown two story elements and asked whether both elements were part of the same story and whether the second element appeared before or after the first. At retrieval, they showed stories were replayed in reverse order to the prompt (i.e., when prompting element 3 and element 5, successful retrieval would traverse element 5 through 4 and arrive at element 3). However, this effect was only found in those with regular performance, while in high performers there was no evidence of temporal succession. Instead, the latter group simultaneously reactivated all related story elements in a clustered manner.</p><p>In memory research, declarative tasks often avail of item lists or paired associates (<xref ref-type="bibr" rid="bib5">Barnett and Blackwell, 2023</xref>; <xref ref-type="bibr" rid="bib13">Cho et al., 2020</xref>; <xref ref-type="bibr" rid="bib24">Feld et al., 2013</xref>; <xref ref-type="bibr" rid="bib41">Kolibius et al., 2020</xref>; <xref ref-type="bibr" rid="bib60">Roux et al., 2022</xref>; <xref ref-type="bibr" rid="bib63">Schönauer et al., 2014</xref>; <xref ref-type="bibr" rid="bib68">Stadler et al., 1999</xref>; <xref ref-type="bibr" rid="bib68">Stadler et al., 1999</xref>). When studying sequential replay, the task structure must have a linear element (<xref ref-type="bibr" rid="bib43">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="bib45">Liu et al., 2021b</xref>; <xref ref-type="bibr" rid="bib76">Wimmer et al., 2020</xref>; <xref ref-type="bibr" rid="bib78">Wise et al., 2021</xref>) and such linearity is a defining feature of episodic memory (<xref ref-type="bibr" rid="bib74">Tulving, 1993</xref>). By contrast, semantic memory is rarely organized linearly and instead involves complex and interconnected knowledge networks or cognitive maps (<xref ref-type="bibr" rid="bib6">Behrens et al., 2018</xref>), motivating researchers to ask how memory works when organized into a complex graph structure (<xref ref-type="bibr" rid="bib21">Eldar et al., 2020</xref>; <xref ref-type="bibr" rid="bib26">Feld et al., 2021</xref>; <xref ref-type="bibr" rid="bib31">Garvert et al., 2017</xref>; <xref ref-type="bibr" rid="bib61">Schapiro et al., 2013</xref>; for an overview, see <xref ref-type="bibr" rid="bib51">Momennejad, 2020</xref>). However, little is currently known regarding the contribution of replay to consolidation and retrieval processes for information that is embedded in graph structures. In particular, the question remains how the brain keeps track of graph distances for successful recall and whether the previously found difference between high and low performers also holds true within a more complex graph learning context.</p><p>Here, we examined the relationship between retrieval from a learned graph structure and reactivation and replay in a task where participants learned a directed, cyclic graph, represented by 10 connected images. Eight nodes had exactly one direct predecessor and successor node, two <italic>hub nodes</italic>, each had two direct predecessors and successors (see Figure 5B). The task was arranged such that participants could not rely on simple pair mappings but needed to learn the context of each edge. Additionally, the graph structure was never shown to participants as a ‘birds-eye view’, encouraging implicit learning of the underlying structure. Following a retention period, consisting of 8 min eyes-closed resting state, participants then completed a cued recall task, which is the focus of the current study.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Behavioral</title><p>All but one participant learned the sequence of 10 images embedded into the directed graph with partial overlap (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). On average, participants needed five blocks of learning (range, 2–6, see <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>) and attained a memory performance of 76% during their last block of learning (range, 50–100%). After 8 min of rest, retrieval performance improved marginally to a mean of 82% (<italic>t</italic> = −2.053, p=0.053, effect size <italic>r</italic> = 0.22; <xref ref-type="fig" rid="fig1">Figure 1B</xref>). Note that since the last learning block included feedback, this marginal increase cannot necessarily be attributed to consolidation processes. Additionally, we have included an analysis showing how wrong answers participants provided were random in the first block and biased toward closer graph nodes in later blocks. This is consistent with participants actually learning the underlying graph structure as opposed to independent triplets (see <xref ref-type="fig" rid="fig1s3">Figure 1—figure supplement 3</xref> for details).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Decoder accuracy and learning performance.</title><p>(<bold>A</bold>) Decoding accuracy of the currently displayed item during the localizer task for participants with a decoding accuracy higher than 30% (n = 21). The mean peak time point across all participants corresponded to 210 ms, with an average decoding peak decoding accuracy of 42% (n = 21). Note that the displayed graph combines accuracies across participants, where peak values were computed on an individual level and then averaged. Therefore, the indicated individual mean peak does not match the average at a group level. (<bold>B</bold>) Memory performance of participants after completing the first block of learning, the last block (blocks 2–6, depending on the speed of learning), and the retrieval performance. (<bold>C</bold>) Classifier transfer within the localizer when trained and tested at different time points determined by cross-validation. (<bold>D</bold>) Classifier transfer from the localizer session to the retrieval session when trained at different time points during training and tested at different time points during cue presentation of the first (predecessor) image cue during retrieval. For (<bold>B</bold>) and (<bold>C</bold>), within the white outline, classification was significantly above chance level (cluster permutation testing, α &lt; 0.05).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93357-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Excluded participants based on decoding accuracy and memory performance during retrieval.</title><p>Peak decoding accuracy was determined by a leave-one-per-class-our cross-validation across time for each participant. Memory performance was the percentage of correct responses during the 12 retrieval trials.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93357-fig1-figsupp1-v1.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Number of learning blocks that each participant completed.</title><p>The number of learning blocks was adapted to the speed of the participant such that each participant had a similar performance at their last block. Learning was stopped if participants reached at least 80% memory performance in a block or if they reached six blocks. A minimum of two blocks are shown, even if participants reached above 80% in their first block (by chance).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93357-fig1-figsupp2-v1.tif"/></fig><fig id="fig1s3" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 3.</label><caption><title>During the learning and retrieval blocks, participants were presented two lures next to the correct answer to complete the triplet, one of which was closer to the target and one further away on the graph.</title><p>To show that participants indeed learned the graph structure and not just triplets, the figure shows the ratio of close lures chosen vs lures that were further away on the graph. In the first learning block, the chosen lure is random as participants have not learned the graph structure yet. On the last learning block, many participants exclusively choose the closer lure, indicating that they are aware of approximate distances of the presented stimuli. Note, however, that the analysis relies solely on trials with incorrect responses. Therefore, the apparent (nonsignificant) drop of the ratio from the last block to the retrieval block can be attributed to participants reaching ceiling performance. Additionally, the number of blocks was determined by the learning speed of the participant (with a minimum of two learning blocks), making it hard to compare between participants with different numbers of learning blocks. Therefore, we have decided to plot the first, last, and retrieval blocks as they were defined for each participant. An ANOVA indicated that the three blocks were significantly different (<italic>F</italic> = 7.5, p=0.001), a post hoc <italic>t</italic>-test indicated a significant difference between the first and last (<italic>t</italic> = −4.3, p&lt;0.0001) and the first and retrieval session (<italic>t</italic> = −2.0, p=0.046) and no difference between the last and retrieval block (<italic>t</italic> = 1.4, p=0.16).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93357-fig1-figsupp3-v1.tif"/></fig><fig id="fig1s4" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 4.</label><caption><title>Decoding accuracy across time determined by a leave-one-per-class-out cross-validation per participant.</title><p>For details on decoder training, see ‘Methods’.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93357-fig1-figsupp4-v1.tif"/></fig><fig id="fig1s5" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 5.</label><caption><title>Percentage of rejected trials for each participant.</title><p>Artifacts were detected automatically using AutoReject. If possible, channels were interpolated for the affected time span, else the trial was rejected. The figure displays the ratios as well as the absolute number of rejected epochs for each participant in the study. The analysis is based on the remaining nonrejected epochs. For the retrieval, on average, 11.5 epochs were available, in total 252 across the study.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93357-fig1-figsupp5-v1.tif"/></fig><fig id="fig1s6" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 6.</label><caption><title>Percentage of sensors relevant for each image across all participants (beta weight of sensor location unequal to zero).</title><p>Larger/darker dots indicate more participants' decoders' used information from this sensor. LASSO/L1 regularization forces individual regressor values of the classifier belonging to a specific sensor to 0, such that only a sparse number of sensors contribute information to the decision process. The plot shows the average ratio that a sensor was included across participants, giving a rough estimate for the location of stimulus processing. The largest dot indicates that this sensor was used for all participants for this image. The smallest/lightest dot indicates that almost no participant’s decoder used information from this sensor. Please note that the magnetoencephalographic (MEG) head positioning was not aligned between participants such that the average dots do not indicate a specific location but only a broad region.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93357-fig1-figsupp6-v1.tif"/></fig></fig-group></sec><sec id="s2-2"><title>Decoder training</title><p>We first confirmed we could decode brain activity elicited by the 10 items using a cross-validation approach. Indeed, decoders were able to separate the items presented during the localizer task (see <xref ref-type="fig" rid="fig1">Figure 1A</xref>) well, with an average peak decoding accuracy of ~42% across all participants (range, 32–57%, chance level: 10%, excluding participants with peak accuracy &lt;30%, for all participants; see <xref ref-type="fig" rid="fig1s4">Figure 1—figure supplement 4</xref>). We calculated the time point of the mean peak accuracy for each participant separately and subsequently used the average best time point, across all included participants, at 206 ms (rounded to 210 ms) for training of our final decoders. This value is very close in range to the time points found in previous studies (<xref ref-type="bibr" rid="bib42">Kurth-Nelson et al., 2016</xref>; <xref ref-type="bibr" rid="bib43">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="bib45">Liu et al., 2021b</xref>; <xref ref-type="bibr" rid="bib76">Wimmer et al., 2020</xref>). The decoders also transferred well to stimulus presentation during the retrieval trials and could effectively decode the current prompted image cue with above-chance significance (cluster permutation test, see <xref ref-type="fig" rid="fig1">Figure 1D</xref>).</p></sec><sec id="s2-3"><title>Sequential forward replay in subjects with lower memory performance</title><p>Next, we assessed whether there was evidence for sequential replay of the learned sequences during cued recall. Using TDLM, we asked whether decoded reactivation probabilities followed a sequential temporal pattern, in line with transitions on the directed graph. Here, we focused on all allowable graph transitions and analyzed the entire time window, of 1500 ms, after onset of the retrieval cue (‘current image’). We found positive sequenceness across all time lags for forward sequenceness, with a significant increase at around 40–50 ms state to state lag for forward sequenceness (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). As discussed in <xref ref-type="bibr" rid="bib45">Liu et al., 2021b</xref>, correction for multiple comparisons for this sequenceness measure across time is nontrivial and the maximum of all permutations represents a highly conservative statistic. Due to this complexity, we also report the 95% percentile of sequenceness maxima across time per permutation. Nevertheless, as we did not have a predefined time lag of interest, and to mitigate multiple comparisons, we additionally computed the mean sequenceness across all computed time lags for each participant (similar to that previously proposed in the context of a sliding-window approach in <xref ref-type="bibr" rid="bib78">Wise et al., 2021</xref>). This measure can help reveal an overall tendency for replay of task states that is invariant to a specific time lag. Our results show that across all participants there is a significant increase in task-related forward sequential reactivation of states (p=0.027, two-sided permutation test with 1000 permutations; 95% of permutation maxima reached at 40–50 ms, <xref ref-type="fig" rid="fig2">Figure 2B</xref>). Following up on this, in a second analysis, we asked whether mean sequential replay was associated with memory performance and found a significant negative correlation between retrieval performance and forward replay (forward: <italic>r</italic> = −0.46, p=0.031; backward: <italic>r</italic> = −0.13, p=0.56, see <xref ref-type="fig" rid="fig2">Figure 2C</xref>). In line with previous results (<xref ref-type="bibr" rid="bib76">Wimmer et al., 2020</xref>), low-performing participants had higher forward sequenceness compared to high-performing participants, whose mean sequenceness tended toward zero.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Sequenceness during retrieval.</title><p>(<bold>A</bold>) Strength of forward and backward sequenceness across different time lags up to 250 ms during the 1500 ms window after cue onset. Two significance thresholds are shown: conservative threshold of the maximum of 1000 permutations of classification labels across all time lags and the 95% percentiles (see ‘Methods’ for details). (<bold>B</bold>) Permutation distribution of mean sequenceness values across 1000 state permutations. Observed mean sequenceness is indicated with a red line. (<bold>C</bold>) Association between memory performance and mean sequenceness value computed across all trials, and time lags, for each participant.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93357-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Sequential replay for all learning blocks.</title><p>(<bold>A</bold>) Strength of forward and backward sequenceness across different time lags (see ‘Methods’ and <xref ref-type="fig" rid="fig4">Figure 4</xref> for details). (<bold>B</bold>) Permutation distribution of mean sequenceness values across 1000 state permutations. (<bold>C</bold>) Association between memory performance and mean sequenceness value computed across all trials, and time lags, for each participant. Note: as the paradigm applied criteria learning, participants had different amount of blocks and hence different exposure at different time points (see Figure 2—figure supplement 1), making a block-wise comparison between participants conceptually difficult. Therefore, to alleviate the bias of different learning speeds, we combined all trials of the learning blocks.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93357-fig2-figsupp1-v1.tif"/></fig></fig-group></sec><sec id="s2-4"><title>Closer nodes show stronger reactivation than distant nodes</title><p>Next, in a complementary analysis, we asked whether a nonsequential clustered reactivation of items occurs after onset of a cue image (as shown previously for high performers in <xref ref-type="bibr" rid="bib76">Wimmer et al., 2020</xref>). We compared reactivation strength of the two items following the cue image with all items associated to a distance of more than two steps, subtracting the mean decoded reactivation probabilities from each other. Using this differential reactivation, we found evidence consistent with near items being significantly reactivated compared to items further away within a time window of 220–260 ms after cue onset (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, p&lt;0.05, permutation test with 10000 shuffles).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Clustered reactivation during retrieval.</title><p>(<bold>A</bold>) Decoded raw probabilities for off-screen items that were up to two steps ahead of the current stimulus cue (‘near’) vs. distant items that were more than two steps away on the graph, on trials with correct answers. The median peak decoded probability for near and distant items was at the same time point for both probability categories. Note that the displayed lines reflect the average probability while, to eliminate the influence of outliers, the peak displays the median. (<bold>B</bold>) Differential reactivation probability between off-screen items that were up to two steps ahead of the current stimulus cue vs. distant items that were more than two steps away on the graph for trials with correct answers. Between 220 and 260 ms, the next items are simultaneously reactivated significantly more than the items that are further away (p&lt;0.05; permutation test with 10,000 shuffles). (<bold>C</bold>) Reactivation strength of items after retrieval cue onset by distance of items to the currently on-screen stimulus subdivided into trials in which participants answered correctly (left) and in which participants did not know the correct answer (right). A correlation between reactivation strength and distance can only be seen in case of successful retrieval (but see also limitations for a discussion of the low trial and participant number in this sub-analysis). Mean probability values are marked by black dots. (<bold>D</bold>) Mean differential reactivation at peak time point (220–260 ms) during all learning trials (before consolidation) compared to retrieval trials. (<bold>E</bold>) Example activations of a successful retrieval (left) and a failed retrieval (right), sorted by distance to current cue. Colors indicate probability estimates of the decoders.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93357-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Mean raw probabilities of near vs far item reactivation at peak time point (210–240 ms, see <xref ref-type="fig" rid="fig3">Figure 3B</xref>) during learning and retrieval blocks.</title><p>Reactivation markers increased for near items while it slightly decreased for far items. However, all interactions are nonsignificant. Note that direct comparison of raw probabilities between different recording session parts might be difficult to interpret due to baseline probability shifts (e.g. due to sensor distance or head position changes).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93357-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Reactivation strength of items after retrieval cue onset by distance of items to the currently on-screen stimulus.</title><p>A significant negative correlation between distance on a directional graph and reactivation strength can be seen (p=0.008). The correlation is shown for both correct and incorrect answers. For a sub-analysis of correct and incorrect analysis, see <xref ref-type="fig" rid="fig3">Figure 3C</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93357-fig3-figsupp2-v1.tif"/></fig></fig-group><p>To further explore the relation of reactivation strength and graph distances, we analyzed the mean reactivation strength by item distance at peak classifier probabilities and found reactivation strength significantly related to graph distance (repeated-measures ANOVA, <italic>F</italic>(4, 80) = 2.98, p=0.023; <xref ref-type="fig" rid="fig3">Figure 3B</xref>). When subdividing trials into correct and incorrect responses, we found that this relationship was only significant for trials where a participant successfully retrieved the currently prompted sequence excerpt (repeated-measures ANOVA, <italic>F</italic>(4, 80) = 5.0, p=0.001 for correctly answered trials, <xref ref-type="fig" rid="fig3">Figure 3C</xref>). For incorrect trials, we found no evidence for this relationship (<italic>F</italic>(4, 48) = 1.45, p=0.230 for incorrectly answered trials), albeit we found no interaction between distance and response type (<italic>F</italic>(4, 48) = 1.8, p=0.13). Note that the last two analyses are based on n = 14 since seven participants had no incorrect trials.</p><p>To examine how the 8 min consolidation period affected reactivation, we, post hoc, looked at relevant measures across learning trials in contrast to retrieval trials. For all learning trials, for each participant, we calculated differential reactivation for the same time point we found significant in the previous analysis (220–260 ms). On average, differential reactivation probability increased from pre- to post-resting state; however, the effect was nonsignificant (<italic>t</italic> = –1.78, p=0.08) (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). Raw mean probabilities between learning and retrieval block for far and distant items are shown in <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>.</p></sec><sec id="s2-5"><title>Questionnaire results</title><p>Participants were concentrated and alert as indicated by the Stanford Sleepiness Scale (M = 2.3, SD = 0.6, range, 1–3). Participants’ summed positive affect score was on average 33.2 (SD = 4.5), and their summed negative affect score was on average 12.2 (SD = 1.9) (PANAS). Individual questionnaire answers for each included participants are available in the supplementary download in the code repository at GitHub.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We combined a graph-based learning task with machine learning to study neuronal events linked to memory retrieval. Participants learned triplets of associated images by trial and error, where these were components of a simple directed graph with 10 nodes and 12 edges. Using machine learning decoding of simultaneously recorded MEG data, we asked what brain processes are linked to retrieval of this learned information and how this relates to the underlying graph structure. We show that learned graph items are retrieved by a simultaneous, clustered, reactivation of items and that the associated reactivation strength relates to graph distances.</p><p>Memory retrieval is thought to involve reinstatement of previously evoked item-related neural activity patterns (<xref ref-type="bibr" rid="bib15">Danker and Anderson, 2010</xref>; <xref ref-type="bibr" rid="bib38">Johnson and Rugg, 2007</xref>; <xref ref-type="bibr" rid="bib69">Staresina et al., 2012</xref>). Both spatial and abstract information is purported to be encoded into cognitive maps within the hippocampus and related structures (<xref ref-type="bibr" rid="bib6">Behrens et al., 2018</xref>; <xref ref-type="bibr" rid="bib7">Bellmund et al., 2018</xref>; <xref ref-type="bibr" rid="bib23">Epstein et al., 2017</xref>; <xref ref-type="bibr" rid="bib31">Garvert et al., 2017</xref>; <xref ref-type="bibr" rid="bib54">O’Keefe and Nadel, 1979</xref>; <xref ref-type="bibr" rid="bib57">Peer et al., 2021</xref>). While, for example, spatial distance within cognitive maps is encoded within hippocampal firing patterns (<xref ref-type="bibr" rid="bib73">Theves et al., 2019</xref>), it is unclear how competing, abstract, candidate representations are accessed during retrieval (<xref ref-type="bibr" rid="bib39">Kerrén et al., 2018</xref>; <xref ref-type="bibr" rid="bib40">Kerrén et al., 2022</xref>; <xref ref-type="bibr" rid="bib67">Spiers, 2020</xref>). Two separate mechanisms seem plausible. First, depth-first search might enable inference in not yet fully consolidated cognitive maps by sequential replay of potential candidates (<xref ref-type="bibr" rid="bib47">Mattar and Daw, 2018</xref>; <xref ref-type="bibr" rid="bib53">Nyberg et al., 2022</xref>). Second, breadth-first search could be deployed involving simultaneous activation of candidates when these are sufficiently consolidated within maps that support noninterfering co-reactivation of competing representations (<xref ref-type="bibr" rid="bib48">Mattar and Lengyel, 2022</xref>), or when exhaustive replay would be too expensive computationally. Indeed, consistent with this, <xref ref-type="bibr" rid="bib76">Wimmer et al., 2020</xref> showed that for regular memory performance, sequential and temporally spaced reactivation of items seems to ‘piece together’ individual elements. This contrasted with high performers who showed a clustered, simultaneous, reactivation profile. We replicate this clustered reactivation and show that its strength reflects distance on a graph structure. This complements previous findings of graded pattern similarity during memory search representing distance within the search space (<xref ref-type="bibr" rid="bib46">Manning et al., 2011</xref>; <xref ref-type="bibr" rid="bib71">Tarder-Stoll et al., 2023</xref>). As this effect was evident only for correct choices, the finding points to its importance for task performance.</p><p>According to <xref ref-type="bibr" rid="bib76">Wimmer et al., 2020</xref>, we found that the strength of replay is related to weaker memory performance. This suggests that the expression of sequential replay or simultaneous reactivation depends on the stability of an underlying memory trace. However, we acknowledge that it remains unclear which factors enable recruitment of either of these mechanisms. A crucial step in consolidation encompasses an integration of memory representations into existing networks (<xref ref-type="bibr" rid="bib18">Dudai et al., 2015</xref>; <xref ref-type="bibr" rid="bib65">Sekeres, 2017</xref>). In <xref ref-type="bibr" rid="bib76">Wimmer et al., 2020</xref>, participants had little exposure to the learning material and replay was measured after a substantial retention period that included sleep, where the latter is considered to strengthen and transform memories via repeated replay (<xref ref-type="bibr" rid="bib17">Diekelmann and Born, 2010</xref>; <xref ref-type="bibr" rid="bib25">Feld and Born, 2017</xref>). This contrasts with the current task design, which solely involved several blocks of learning and retrieval and only a relatively brief period of consolidation.</p><p>Intriguingly, it has been speculated that retrieval practice may elicit the same transformation of memory traces as offline replay (<xref ref-type="bibr" rid="bib3">Antony et al., 2017</xref>). In line with this reasoning, it is possible that both consolidation during sleep and repeated practice have similar effects on the transformation of memories, and consequently on mechanisms that support their subsequent retrieval. This possibility is especially interesting in the light of retrieval practice enhancing memory performance more than is the case for restudy (<xref ref-type="bibr" rid="bib49">McDermott, 2021</xref>), a finding also in line with evidence that replay during rest prioritizes weakly learned memories (<xref ref-type="bibr" rid="bib62">Schapiro et al., 2018</xref>). It is known that retrieval practice reduces the pattern similarity of competing memory traces in the hippocampus (<xref ref-type="bibr" rid="bib36">Hulbert and Norman, 2015</xref>) and, as in the case of our graph-based task, may enable clustered reactivation since differences in timing of reactivation are no longer required to distinguish correct from incorrect items. Therefore, we speculate that clustered reactivation may be a physiological correlate of retrieval facilitated either by repeated retrieval testing-based learning (as in our study) or sleep-dependent memory consolidation (as in <xref ref-type="bibr" rid="bib76">Wimmer et al., 2020</xref>). This implies that there may be a switch from sequential replay to clustered reactivation corresponding to when learned material can be accessed simultaneously without interference. This suggestion could be systematically investigated by, for example, manipulating retrieval practice, retention interval, and the difficulty of a graph-based task. Nevertheless, even though our results show a nominal, nonsignificant increase in reactivation from learning to retrieval (see <xref ref-type="fig" rid="fig3">Figure 3D</xref>), due to experimental design features our data do not enable us to test for a hypothesized switch for sequential replay (see also ‘Limitations‘ and <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). Finally, even though we primarily focused on the mean sequenceness scores across time lags, there appears to be a (nonsignificant) peak at 40–60 ms. While simultaneous forward and backward replay is theoretically possible, we acknowledge that it is somewhat surprising and, given our paradigm, could relate to other factors such as autocorrelations (<xref ref-type="bibr" rid="bib44">Liu et al., 2021a</xref>).</p><sec id="s3-1"><title>Limitations</title><p>There are limitations to our study, many of which originate from a suboptimal study design that resulted in a relatively limited number of trials for the retrieval session per participant. Additionally, as we performed criteria learning, a sub-group analysis as in <xref ref-type="bibr" rid="bib76">Wimmer et al., 2020</xref> was not feasible as the median performance in our sample was 83% (mean 81%), with six participants exactly at that threshold, resulting in a very high cutoff. Our design also meant participants had different number of learning blocks (2–6 blocks, see <xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>), making a comparison of learning progress across participants difficult. While we closely follow the analysis approach taken in <xref ref-type="bibr" rid="bib76">Wimmer et al., 2020</xref>, we did not explicitly preregister the confirmatory analysis of the retrieval data as such. We do acknowledge that only a somewhat limited number of trials were available for analysis, affecting especially the analysis of incorrect answers. In addition, the number of low-performing participants was low in our study, which would render a performance-dependent sub-analysis underpowered. Finally, we want to acknowledge that by selecting a time window for the clustered reactivation we cannot distinguish very fast replay events (≤ 30 ms) from clustered reactivation if they are contained exactly within that specific reactivation analysis time window.</p></sec><sec id="s3-2"><title>Conclusion</title><p>Our findings support a role for a clustered reactivation mechanism for well-learned items during memory retrieval. When interconnected semantic information is retrieved, the retrieval process seems to resemble a breadth-first search, with items sorted by neural activation strength. Additionally, we find that the presence of sequential replay is related to low memory performance. The likely coexistence of two types of retrieval process, recruited dependent on the participants’ learning experience, is an important direction for future research. The use of more complex memory tasks, such as explicitly learned associations of graph networks, should enable a more systematic study of this process. Finally, we suggest that accessing information embedded in a knowledge network may benefit from recruitment of either process, replay or reactivation, on the fly.</p></sec></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Participants</title><p>We recruited 30 participants (15 men and 15 women), between 19 and 32 years old (mean age 24.7 y). Inclusion criteria were right-handedness, no claustrophobic tendencies, no current or previously diagnosed mental disorder, nonsmoker, fluency in German or English, age between 18 and 35, and normal or corrected-to-normal vision. Caffeine intake was requested to be restricted for 4 hr before the experiment. Participants were recruited through the institute’s website and mailing list and various local Facebook groups. A single participant was excluded due to a corrupted data file and replaced with another participant. We acquired written informed consent from all participants, including consent to share anonymized raw and processed data in an open-access online repository. The study was approved by the ethics committee of the Medical Faculty Mannheim of Heidelberg University (ID: 2020-609). While we had preregistered the study design and an analysis approach for the resting state data (<ext-link ext-link-type="uri" xlink:href="https://aspredicted.org/kx9xh.pdf">https://aspredicted.org/kx9xh.pdf</ext-link>, #68915), here we report analyses of the retrieval period. The current analysis conceptually replicates the analyses and hypotheses of <xref ref-type="bibr" rid="bib76">Wimmer et al., 2020</xref> focusing on the retrieval period albeit in a much more complex and therefore naturalistic paradigm and are therefore, despite not being preregistered, mainly of confirmatory nature. We wish to maintain transparency by acknowledging that the findings from the preregistered analysis concerning the resting state data are being prepared for publication as part of a distinct submission.</p></sec><sec id="s4-2"><title>Procedure</title><p>Participants came to the laboratory for a single study session of approximately 2.5 hr. After filling out a questionnaire about their general health, their vigilance state (Stanford Sleepiness Scale, <xref ref-type="bibr" rid="bib35">Hoddes et al., 1973</xref>), and mood (PANAS, <xref ref-type="bibr" rid="bib75">Watson et al., 1988</xref>), participants performed five separate tasks while in the MEG scanner. First, an 8 min eyes-closed resting state was recorded. This was followed by a localizer task (~30 min), in which all 10 items were presented 50 times in a pseudo-randomized order, using auditory and visual stimuli. Next, participants learned a sequence of the 10 visual items embedded into a graph structure until they achieved 80% accuracy or reached a maximum of six blocks (7–20 min). Following this, we recorded another 8 min eyes-closed resting state to allow for initial consolidation and, finally, a cued retrieval session (4 min). For an overview see <xref ref-type="fig" rid="fig4">Figure 4</xref>.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Experimental procedure in the magnetoencephalographic (MEG).</title><p>Localizer task: the 10 individual items were repeatedly presented to the participant auditorily and visually to extract multisensory activity patterns. Learning: participants learned pseudo-randomly generated triplets of the 10 items by trial and error. These triplets were determined by an underlying graph structure. Participants were unaware of the exact structure and graph layout. Consolidation: 8 min of resting state activity were recorded. Retrieval: participants’ recall was tested by cueing triplets from a sequence. The letters in the pictograms are placeholders for individual images.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93357-fig4-v1.tif"/></fig></sec><sec id="s4-3"><title>Stimulus material</title><p>Visual stimuli were taken from the colored version (<xref ref-type="bibr" rid="bib59">Rossion and Pourtois, 2001</xref>) of the <xref ref-type="bibr" rid="bib66">Snodgrass and Vanderwart, 1980</xref> stimulus dataset. To increase brain pattern discriminability, images were chosen with a focus on diversity of color, shape, and category (see <xref ref-type="fig" rid="fig5">Figure 5B</xref>) and for having short descriptive words (one or two syllables) both in German and English. Auditory stimuli were created using the Google text-to-speech API, availing of the default male voice (<italic>SsmlVoiceGender.NEUTRAL</italic>) with the image description labels, either in German or English, based on the participants’ language preference. Auditory stimulus length ranged from 0.66 to 0.95 s.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Task structure.</title><p>(<bold>A</bold>) During the localizer task, a word describing the stimulus was played via headphones and the corresponding visual item was then shown to the participant. In 4% of trials, the audio and visual cue did not match, and in this case, participants were instructed to press a button on detection (attention check). (<bold>B</bold>) Graph layout of the task. Two elements could appear in two different triplets. The graph was directed such that each tuple had exactly one successor (e.g., apple→zebra could only be followed by cake and not mug), but individual items could have different successors (zebra alone could be followed by mug or cake). Participants never saw the illustrated birds-eye view. (<bold>C</bold>) During learning, in each trial one node was randomly chosen as the current node. First, its predecessor node was shown, followed by the current node with the participant then given a choice of three items. They were then required to choose the node that followed the displayed cue tuple. Feedback was then provided to the participant. This process was repeated until the participant reached 80% accuracy for any block or reached a maximum of six blocks of learning. (<bold>D</bold>) The retrieval followed the same structure as the learning task, except that no feedback was given.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93357-fig5-v1.tif"/></fig></sec><sec id="s4-4"><title>Task description</title><sec id="s4-4-1"><title>Localizer task</title><p>In the localizer task, the 10 graph stimulus items were shown to participants repeatedly in a pseudo-random order, where a DeBruijn sequence (<xref ref-type="bibr" rid="bib16">DeBruijn, 1946</xref>) ensured the number of transitions between any two stimuli was equal. Two runs of the localizer were performed per participant, comprising 250 trials with 25 item repetitions. Each trial started with a fixation cross followed by an inter-trial interval of 0.75–1.25 s. Next, to encourage a multisensory neural representation, the name of the to-be-shown image was played through in-ear headphones (maximum 0.95 s) followed 1.25–1.75 s later by the corresponding stimulus image, shown for 1.0 s. As an attention check, in ~4% of the trials the auditory stimulus did not match the image and participants were instructed to press a button as fast as possible to indicate detection of an incongruent auditory-visual pair. A short break of maximum 30 s was scheduled every 80 trials. Between the two parts of the localizer task, another short break was allowed. Stimulus order was randomized and balanced between subjects. To familiarize the participant with the task, a short exemplar of the localizer task with dummy images was shown beforehand. All subsequent analyses were performed using the visual stimulus onset as a point of reference.</p></sec><sec id="s4-4-2"><title>Graph-learning</title><p>The exact same images deployed in the localizer task were randomly assigned to the nodes of the graph, as shown in <xref ref-type="fig" rid="fig5">Figure 5B</xref>. Participants were instructed to learn a randomized sequence of elements, with the goal of reaching 80% performance within six blocks of learning. During each block, participants were presented with each of the 12 edges of the graph exactly once, in a balanced, pseudo-randomized order. After a fixation cross of 3.0 s, a first image (predecessor) was shown on the left of the screen. After 1.5 s, the second image (current image) appeared in the middle of the screen. After another 1.5 s, three possible choices were displayed in vertical order to the right of the two other images. One of the three choice options was the correct successor of the cued edge. Of the two distractor stimuli, one was chosen from a distal location on the graph (5–8 positions away from the current item), and one was chosen from a close location (2–4 positions away from the current item). Neither of the latter were directly connected to any of the other elements on-screen. Participants used a three-button controller to indicate their answer. The chosen item was then highlighted for 3.0 s, and the participant’s performance was indicated (‘correct’ or ‘wrong’) (see <xref ref-type="fig" rid="fig5">Figure 5C</xref>). No audio was played during learning. The participant was instructed to learn the sequence transitions by trial-and-error, and also instructed that there was no semantic connection between items (i.e., that the sequence did not follow any specific logic related to image content). Participants completed a minimum of two and a maximum of six blocks of learning. To prevent ceiling effects, learning was discontinued if a participant reached 80% accuracy during any block. To familiarize participants with the task, a short example with dummy images was shown before the learning task. Triplets were shown in a random order and choices were displayed in a pseudo-random position that ensured the on-screen position of the correct item could never be at the same position for more than three consecutive trials. Distractor choices were balanced such that exposure to each individual item was approximately equal.</p></sec><sec id="s4-4-3"><title>Resting state</title><p>After graph learning, participants completed a resting state session of 8 min. Here, they were instructed to close their eyes and ‘to not think of anything particular’. These resting state data are not reported here.</p></sec><sec id="s4-4-4"><title>Retrieval</title><p>After the resting state, we presented subjects with a single retrieval session block, which followed the exact layout of the learning task with the exception that no feedback was provided as to whether the entered choices were correct or incorrect (<xref ref-type="fig" rid="fig5">Figure 5D</xref>).</p></sec></sec><sec id="s4-5"><title>MEG acquisition and preprocessing</title><p>MEG was recorded in a passively shielded room with a MEGIN TRIUX (MEGIN Oy, Helsinki, Finland) with 306 sensors (204 planar gradiometers and 102 magnetometers) at 1000 Hz with a 0.1–330 Hz band-pass acquisition ﬁlter at the ZIPP facility of the Central Institute for Mental Health in Mannheim, Germany. Before each recording, empty room measurements made sure that no ill-functioning sensors were present. Head movement was recorded using five head positioning coils. Bipolar vertical and horizontal electrooculography (EOG) as well as electrocardiography (ECG) was recorded. After recording, the MEGIN proprietary MaxFilter algorithm (version 2.2.14) was run using temporally extended signal space separation and movement correction with the MaxFilter default parameters (<xref ref-type="bibr" rid="bib72">Taulu and Simola, 2006</xref>, raw data buffer length of 10 s, and a subspace correlation limit of 0.98). Bad channels were automatically detected at a detection limit of 7; none had to be excluded. The head movement correction algorithm used 200 ms windows and steps of 10 ms. The HPI coil fit accept limits were set at an error of 5 mm and a g-value of 0.98. Using the head movement correction algorithm, the signals were virtually repositioned to the mean head position during the initial localizer task to ensure compatibility of sensor-level analysis across the recording blocks. The systematic trigger delay of our presentation system was measured and visual stimuli appeared consistently 19 ms after their trigger value was written to the stimulus channel; however, to keep consistency with previous studies that do not report trigger delay, timings in this publication are reported uncorrected (i.e., ‘as is’, not corrected for this delay).</p><p>Data were preprocessed using Python-MNE (version 1.1, <xref ref-type="bibr" rid="bib33">Gramfort et al., 2013</xref>). Data were downsampled to 100 Hz using the MNE function ‘<italic>resample</italic>’ (with default settings, which applies an anti-aliasing filter before resampling with a brick-wall filter at the Nyquist frequency in the frequency domain) and ICA applied using the ‘<italic>picard</italic>’ algorithm (<xref ref-type="bibr" rid="bib1">Ablin et al., 2018</xref>) on a 1 Hz high-pass filtered copy of the signal using 50 components. As recommended, ICA was set to ignore segments that were marked as bad by <italic>Autoreject</italic> (<xref ref-type="bibr" rid="bib37">Jas et al., 2017</xref>) on two-second segments. Components belonging to EOG or ECG and muscle artifacts were identified and removed automatically using MNE functions <italic>‘find_bads_eog’</italic>, <italic>‘find_bads_ecg’,</italic> and <italic>‘find_bads_emg’</italic>, using the EOG and ECG as reference signals. Finally, to reduce noise and drift, data were filtered with a high-pass filter of 0.5 Hz using the MNE filter default settings (hamming window FIR filter, –6 dB cutoff at 0.25 Hz, 53 dB stop-band attenuation, filter length 6.6 s).</p><p>Trials from the localizer and retrieval task were created from –0.1 to 0.5 s relative to visual stimulus onset to train decoders. For the sequenceness analysis related to the retrieval, trials were created from 0 to 1.5 s after onset of the second visual cue image. No baseline correction was applied. To detect artifacts, <italic>Autoreject</italic> was applied using default settings, which repaired segments by interpolation in case artifacts were present in only a limited number of channels and rejected trials otherwise (see <xref ref-type="fig" rid="fig1s5">Figure 1—figure supplement 5</xref>). Finally, to improve numerical stability, signals were rescaled to similar ranges by multiplying values from gradiometers by 1e<sup>10</sup> and from magnetometers by 2e<sup>11</sup>. These values were chosen empirically by matching histograms for both channel types. As outlier values can have a significant influence on the computations, after rescaling, values that were still above 1 or below –1 were ‘cutoff’ and transformed to smaller values by multiplying with 1e<sup>–2</sup>. Anonymized and maxfiltered raw data are openly available at Zenodo (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.8001755">https://doi.org/10.5281/zenodo.8001755</ext-link>), and code is made public on GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/CIMH-Clinical-Psychology/DeSMRRest-clustered-reactivation">https://github.com/CIMH-Clinical-Psychology/DeSMRRest-clustered-reactivation</ext-link>, copy archived at <xref ref-type="bibr" rid="bib14">CIMH-Clinical-Psychology, 2024</xref>).</p></sec><sec id="s4-6"><title>Decoding framework and training</title><p>In line with previous investigations (<xref ref-type="bibr" rid="bib42">Kurth-Nelson et al., 2016</xref>; <xref ref-type="bibr" rid="bib43">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="bib76">Wimmer et al., 2020</xref>), we applied LASSO regularized logistic regression on sensor-level data of localizer trials using the Python package Scikit-Learn (<xref ref-type="bibr" rid="bib56">Pedregosa et al., 2011</xref>). Decoders were trained separately for each participant and each stimulus using <italic>liblinear as</italic> a solver with 1000 maximum iterations and an L1 regularization of C = 6. This value was determined based on it giving the best average cross-validated peak accuracy across all participants when searching within the parameter space of C = 1–20 in steps of 0.5 using the same approach as outlined below (note that Scikit-Learn shows stronger regularization with lower C values, opposite to, e.g., MATLAB). To circumvent class imbalance due to trials removed by <italic>Autoreject</italic>, localizer trials were stratified such that they contained an equal number of trials from each stimulus presentation by randomly removing trials from over-represented classes. Using a cross-validation schema (leaving one trial out for each stimulus per fold, i.e., 10 trials left out per fold), for each participant the decoding accuracy was determined across time (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). During cross-validation, for each fold, decoders were trained on data of each 10 ms time step and tested on leftout data from the same time step. Therefore, decoding accuracy reflects the separability of the stimulus classes by the sensor values for each time step independently. Decoders were trained using a one-vs-all approach, which means that for each class, a separate classifier was trained using positive examples (target class) and negative examples (all other classes) plus null examples (data from before stimulus presentation, see below). This approach allows the decoder to provide independent estimates of detected events for each class.</p><p>For each participant, a final set of decoders (i.e., 10 decoders per participant, for each stimulus one decoder) were trained at 210 ms after stimulus onset, a time point reflecting the average peak decoding time point computed for all participants (for individual decoding accuracy plots, see <xref ref-type="fig" rid="fig1s4">Figure 1—figure supplement 4</xref>). For the final decoders, data from before the auditory stimulus onset was added as a negative class with a ratio of 1:2, based upon results from previous publications reaching better sensitivity with higher negative class ratio (<xref ref-type="bibr" rid="bib44">Liu et al., 2021a</xref>). Adding null data allows decoders to report low probabilities for all classes simultaneously in the absence of a matching signal and reduces false positives while retaining relative probabilities between true classes. Together with the use of a sparsity constraint on the logistic regression coefficients, this increases the sensitivity of sequence detection by reducing spatial correlations of decoder weights (see also <xref ref-type="bibr" rid="bib44">Liu et al., 2021a</xref>). For a visualization of relevant sensor positions, see <xref ref-type="fig" rid="fig1s6">Figure 1—figure supplement 6</xref>.</p><p>Decoders were then applied to trials of the retrieval session, starting from the time point of onset of the second sequence cue (‘current image’) and extending to just prior to onset of the selection prompt (1.5 s). For each trial, this resulted in 10 probability vectors across the trial, one for each item, in steps of 10 ms. These probabilities indicate the similarity of the current sensor-level activity to the activity pattern elicited by exposure to the stimulus and can therefore be used as a proxy for detecting active representations, akin to a representational pattern analysis approach (<xref ref-type="bibr" rid="bib34">Grootswagers et al., 2017</xref>). As a sanity check, we confirmed that we could decode the currently on-screen image by applying the final trained decoders to the first image shown during retrieval (predecessor stimulus, see <xref ref-type="fig" rid="fig1">Figure 1D</xref>). Note that we only included data from the current image cue, and not from the predecessor image cue, as we assume the retrieval processes differ and should not be concatenated.</p></sec><sec id="s4-7"><title>Sequential replay analysis</title><p>To test whether individual items were reactivated in sequence at a particular time lag, we applied TDLM (<xref ref-type="bibr" rid="bib44">Liu et al., 2021a</xref>) on the time span after the stimulus onset of the sequence cue (‘current image’). In brief, this method approximates a time-lagged cross-correlation of the reactivation strength in the context of a particular transition pattern, quantifying the strength of a certain activity transition pattern distributed in time. As input for the sequential analysis, we used the raw probabilities of the 10 classifiers corresponding to the stimuli.</p><p>Using a linear model, we first estimate evidence for sequential activation of the decoded item representations at different time lags. For each item <inline-formula><mml:math id="inf1"><mml:mi>i</mml:mi></mml:math></inline-formula> at each time lag <inline-formula><mml:math id="inf2"><mml:mo>∆</mml:mo><mml:mi>t</mml:mi></mml:math></inline-formula> up to 250 ms, we estimated a linear model of form:<disp-formula id="equ1"><mml:math id="m1"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>Y</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mo>∆</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>×</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mo>∆</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> contains the decoded probability output of the classifier of item <inline-formula><mml:math id="inf4"><mml:mi>i</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf5"><mml:mi>Y</mml:mi><mml:mo>(</mml:mo><mml:mo>∆</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> is simply <inline-formula><mml:math id="inf6"><mml:mi>Y</mml:mi></mml:math></inline-formula> time lagged by <inline-formula><mml:math id="inf7"><mml:mo>∆</mml:mo><mml:mi>t</mml:mi></mml:math></inline-formula>. When solving this equation for <inline-formula><mml:math id="inf8"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mo>∆</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula>, we can estimate the predictive strength of <inline-formula><mml:math id="inf9"><mml:mi>Y</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mo>∆</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> for the occurrence of <inline-formula><mml:math id="inf10"><mml:msub><mml:mrow><mml:mi>Y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> at each time lag <inline-formula><mml:math id="inf11"><mml:mo>∆</mml:mo><mml:mi>t</mml:mi></mml:math></inline-formula>. Calculated for each stimulus <inline-formula><mml:math id="inf12"><mml:mi>i</mml:mi></mml:math></inline-formula>, we then create an empirical transition matrix <inline-formula><mml:math id="inf13"><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mo>∆</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> that indexes evidence for a transition of any item <inline-formula><mml:math id="inf14"><mml:mi>j</mml:mi></mml:math></inline-formula> to item <inline-formula><mml:math id="inf15"><mml:mi>i</mml:mi></mml:math></inline-formula> at time lag <inline-formula><mml:math id="inf16"><mml:mo>∆</mml:mo><mml:mi>t</mml:mi></mml:math></inline-formula> (i.e., a 10 × 10 transition matrix per time lag, each column <inline-formula><mml:math id="inf17"><mml:mi>j</mml:mi></mml:math></inline-formula> contains the predictive strength of <inline-formula><mml:math id="inf18"><mml:mi>j</mml:mi></mml:math></inline-formula> for each item <inline-formula><mml:math id="inf19"><mml:mi>i</mml:mi></mml:math></inline-formula> at time lag <inline-formula><mml:math id="inf20"><mml:mo>∆</mml:mo><mml:mi>t</mml:mi></mml:math></inline-formula>). These matrices are then combined with a ground truth transition matrix <inline-formula><mml:math id="inf21"><mml:mi>T</mml:mi></mml:math></inline-formula> (encoding the valid sequence transitions of interest) by taking the Frobenius inner product. This returns a single value <inline-formula><mml:math id="inf22"><mml:msub><mml:mrow><mml:mi>Z</mml:mi></mml:mrow><mml:mrow><mml:mo>∆</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for each time lag, indicating how strongly the detected transitions in the empirical data follow the expected task transitions, which we term ‘sequenceness’. Using different transition matrices to depict forward (<inline-formula><mml:math id="inf23"><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) and backward (<inline-formula><mml:math id="inf24"><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>) replay, we quantified evidence for replay at different time lags for each trial separately. This process is applied to each trial individually, and resulting sequenceness values are averaged to provide a final sequenceness value per participant for each time lag <inline-formula><mml:math id="inf25"><mml:mo>∆</mml:mo><mml:mi>t</mml:mi></mml:math></inline-formula>. To test for statistical significance, we create a baseline distribution by permuting the rows of the transition matrix 1000 times (creating transition matrices with random transitions; identity-based permutation, <xref ref-type="bibr" rid="bib44">Liu et al., 2021a</xref>) and calculate sequenceness across all time lags for each permutation. The null distribution is then constructed by taking the peak sequenceness across all time lags for each permutation.</p></sec><sec id="s4-8"><title>Differential reactivation analysis</title><p>To test for clustered, nonsequential reactivation, we adopted the approach used in <xref ref-type="bibr" rid="bib76">Wimmer et al., 2020</xref>. Decoders were trained independently for each stimulus, and all decoders reacted to the presentation of any visual stimulus to some extent. By using differences in reactivation between stimuli, this aggregated approach allowed us to examine whether near items are more strongly activated than distant items more closely, thereby quantifying nonsequential reactivation with greater sensitivity. For each trial, the mean probability of the two items following the current on-screen item was contrasted with the mean probability of all items further away by subtraction. We chose to combine the following pairs of items for two reasons: first, this doubled the number of included trials; secondly, using this approach the number of trials for each category (‘near’ and ‘distant’) was more balanced. The two items currently displayed on-screen (i.e., predecessor and current image) were excluded. As only a few trials per participant were available for this analysis, the raw probabilities were noisy. Therefore, to address this we applied a Gaussian smoothing kernel (using scipy.ndimage.gaussian_filter with the default parameter of <inline-formula><mml:math id="inf26"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>, which corresponds approximately to taking the surrounding time steps in both directions with the following weighting: current time step: 40%, ±1 step: 25%, ±2 step: 5%, ±3 step: 0.5%) to the probability vectors across the time dimension. By shuffling the stimulus labels 1000 times, we constructed an empirical permutation distribution to determine at which time points the differential reactivation of close items was significantly above chance (<inline-formula><mml:math id="inf27"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:math></inline-formula>).</p></sec><sec id="s4-9"><title>Graph reactivation analysis</title><p>To detect whether reactivation strength was modulated by the underlying graph structure, we compared the raw reactivation strength of all items by distance on the directed graph. First, we calculated a time point of interest by computing the peak probability estimate of decoders across all trials, that is, the average probability for each time point of all trials, of all distances except the previous on-screen item. Then, for each participant, for each trial we sorted all nodes based on their distance to the current on-screen item on the directed graph. Again, we smoothed probability values with a Gaussian kernel (<inline-formula><mml:math id="inf28"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>) and ignored the predecessor on-screen item. Following this, we evaluated the sorted decoder probabilities at the previously determined peak time point. Using a repeated-measures ANOVA on the mean probability values per distance per participant, we then estimated whether reactivation strength was modulated by graph distance.</p></sec><sec id="s4-10"><title>Exclusions</title><p>Replay analysis relies on a successive detection of stimuli where the chance of detection exponentially decreases with each step (e.g., detecting two successive stimuli with a chance of 30% leaves a 9% chance of detecting a replay event). However, one needs to bear in mind that accuracy is a ‘winner-takes-all’ metric indicating whether the top choice also has the highest probability, disregarding subtle, relative changes in assigned probability. As the methods used in this analysis are performed on probability estimates and not class labels, one can expect that the 30% are a rough lower bound and that the actual sensitivity within the analysis will be higher. Additionally, based on pilot data, we found that attentive participants were able to reach 30% decodability, allowing its use as a data quality check. Therefore, we decided a priori that participants with a peak decoding accuracy of below 30% would be excluded from the analysis (nine participants in all) as obtained from the cross-validation of localizer trials. Additionally, as successful learning was necessary for the paradigm, we ensured all remaining participants had a retrieval performance of at least 50% (see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>).</p></sec><sec id="s4-11"><title>Code availability</title><p>The code of the analysis as well as the experiment paradigm and the stimulus material is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/CIMH-Clinical-Psychology/DeSMRRest-clustered-reactivation">https://github.com/CIMH-Clinical-Psychology/DeSMRRest-clustered-reactivation</ext-link>, copy archived at <xref ref-type="bibr" rid="bib14">CIMH-Clinical-Psychology, 2024</xref>.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Funding acquisition, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Software, Formal analysis, Validation, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Resources, Supervision, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Data curation, Formal analysis</p></fn><fn fn-type="con" id="con5"><p>Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Resources, Writing – review and editing</p></fn><fn fn-type="con" id="con7"><p>Supervision, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con8"><p>Conceptualization, Supervision, Validation, Writing – review and editing</p></fn><fn fn-type="con" id="con9"><p>Conceptualization, Supervision, Funding acquisition, Validation, Methodology, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>We acquired written informed consent from all participants, including consent to share anonymized raw and processed data in an open access online repository. The study was approved by the ethics committee of the Medical Faculty Mannheim of Heidelberg University (ID: 2020-609).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-93357-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>MaxFiltered and anonymized MEG raw data as well as behavioural results are available at Zenodo (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.8001755">https://doi.org/10.5281/zenodo.8001755</ext-link>).All code to replicate the analysis is available on GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/CIMH-Clinical-Psychology/DeSMRRest-clustered-reactivation">https://github.com/CIMH-Clinical-Psychology/DeSMRRest-clustered-reactivation</ext-link>, copy achived at <xref ref-type="bibr" rid="bib14">CIMH-Clinical-Psychology, 2024</xref>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Gerchen</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>Reactivation strength during cued recall is modulated by graph distance within cognitive maps</data-title><source>Zenodo</source><pub-id pub-id-type="doi">10.5281/zenodo.8001755</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This research was supported by an Emmy-Noether research grant awarded to GBF by the DFG (FE1617/2-1) and a project grant by the DGSM as well as a doctoral scholarship of the German Academic Scholarship Foundation, both awarded to SK. Additionally, we want to thank the ZIPP core facility of the Central Institute of Mental Health for their generous support of the study.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ablin</surname><given-names>P</given-names></name><name><surname>Cardoso</surname><given-names>JF</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Faster independent component analysis by preconditioning with hessian approximations</article-title><source>IEEE Transactions on Signal Processing</source><volume>66</volume><fpage>4040</fpage><lpage>4049</lpage><pub-id pub-id-type="doi">10.1109/TSP.2018.2844203</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ambrose</surname><given-names>RE</given-names></name><name><surname>Pfeiffer</surname><given-names>BE</given-names></name><name><surname>Foster</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Reverse replay of hippocampal place cells is uniquely modulated by changing reward</article-title><source>Neuron</source><volume>91</volume><fpage>1124</fpage><lpage>1136</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.07.047</pub-id><pub-id pub-id-type="pmid">27568518</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Antony</surname><given-names>JW</given-names></name><name><surname>Ferreira</surname><given-names>CS</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Wimber</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Retrieval as a fast route to memory consolidation</article-title><source>Trends in Cognitive Sciences</source><volume>21</volume><fpage>573</fpage><lpage>576</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.05.001</pub-id><pub-id pub-id-type="pmid">28583416</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Axmacher</surname><given-names>N</given-names></name><name><surname>Elger</surname><given-names>CE</given-names></name><name><surname>Fell</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Ripples in the medial temporal lobe are relevant for human memory consolidation</article-title><source>Brain</source><volume>131</volume><fpage>1806</fpage><lpage>1817</lpage><pub-id pub-id-type="doi">10.1093/brain/awn103</pub-id><pub-id pub-id-type="pmid">18503077</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Barnett</surname><given-names>JH</given-names></name><name><surname>Blackwell</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2023">2023</year><chapter-title>The paired Associates learning (PAL) test: 30 years of CANTAB Translational Neuroscience from laboratory to bedside in dementia research</chapter-title><person-group person-group-type="editor"><name><surname>Robbins</surname><given-names>TW</given-names></name><name><surname>Sahakian</surname><given-names>BJ</given-names></name></person-group><source>Translational Neuropsychopharmacology</source><publisher-name>Springer International Publishing</publisher-name><fpage>449</fpage><lpage>474</lpage><pub-id pub-id-type="doi">10.1007/7854_2015_5001</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Muller</surname><given-names>TH</given-names></name><name><surname>Whittington</surname><given-names>JCR</given-names></name><name><surname>Mark</surname><given-names>S</given-names></name><name><surname>Baram</surname><given-names>AB</given-names></name><name><surname>Stachenfeld</surname><given-names>KL</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>What is a cognitive map</article-title><source>Organizing Knowledge for Flexible Behavior. Neuron</source><volume>100</volume><fpage>490</fpage><lpage>509</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.002</pub-id><pub-id pub-id-type="pmid">30359611</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellmund</surname><given-names>JLS</given-names></name><name><surname>Gärdenfors</surname><given-names>P</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Navigating cognition: Spatial codes for human thinking</article-title><source>Science</source><volume>362</volume><elocation-id>eaat6766</elocation-id><pub-id pub-id-type="doi">10.1126/science.aat6766</pub-id><pub-id pub-id-type="pmid">30409861</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Born</surname><given-names>J</given-names></name><name><surname>Wilhelm</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>System consolidation of memory during sleep</article-title><source>Psychological Research</source><volume>76</volume><fpage>192</fpage><lpage>203</lpage><pub-id pub-id-type="doi">10.1007/s00426-011-0335-6</pub-id><pub-id pub-id-type="pmid">21541757</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunec</surname><given-names>IK</given-names></name><name><surname>Momennejad</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Predictive representations in hippocampal and prefrontal hierarchies</article-title><source>The Journal of Neuroscience</source><volume>42</volume><fpage>299</fpage><lpage>312</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1327-21.2021</pub-id><pub-id pub-id-type="pmid">34799416</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buhry</surname><given-names>L</given-names></name><name><surname>Azizi</surname><given-names>AH</given-names></name><name><surname>Cheng</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Reactivation, replay, and preplay: how it might all fit together</article-title><source>Neural Plasticity</source><volume>2011</volume><elocation-id>203462</elocation-id><pub-id pub-id-type="doi">10.1155/2011/203462</pub-id><pub-id pub-id-type="pmid">21918724</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Carr</surname><given-names>MF</given-names></name><name><surname>Jadhav</surname><given-names>SP</given-names></name><name><surname>Frank</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Hippocampal replay in the awake state: a potential substrate for memory consolidation and retrieval</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>147</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1038/nn.2732</pub-id><pub-id pub-id-type="pmid">21270783</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>ZS</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>How our understanding of memory replay evolves</article-title><source>Journal of Neurophysiology</source><volume>129</volume><fpage>552</fpage><lpage>580</lpage><pub-id pub-id-type="doi">10.1152/jn.00454.2022</pub-id><pub-id pub-id-type="pmid">36752404</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cho</surname><given-names>KW</given-names></name><name><surname>Tse</surname><given-names>CS</given-names></name><name><surname>Chan</surname><given-names>YL</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Normative data for Chinese-English paired associates</article-title><source>Behavior Research Methods</source><volume>52</volume><fpage>440</fpage><lpage>445</lpage><pub-id pub-id-type="doi">10.3758/s13428-019-01240-2</pub-id><pub-id pub-id-type="pmid">30963462</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="software"><person-group person-group-type="author"><collab>CIMH-Clinical-Psychology</collab></person-group><year iso-8601-date="2024">2024</year><data-title>Desmrrest-clustered-reactivation</data-title><version designator="swh:1:rev:1e58112b54e528f28d7c2b3752d62b5302a45085">swh:1:rev:1e58112b54e528f28d7c2b3752d62b5302a45085</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:e1892b2fff68e1bc3923a1f5cfd1559be050cc32;origin=https://github.com/CIMH-Clinical-Psychology/DeSMRRest-clustered-reactivation;visit=swh:1:snp:01cbfacef99252a4f0d1d43f5354c664e1585cf5;anchor=swh:1:rev:1e58112b54e528f28d7c2b3752d62b5302a45085">https://archive.softwareheritage.org/swh:1:dir:e1892b2fff68e1bc3923a1f5cfd1559be050cc32;origin=https://github.com/CIMH-Clinical-Psychology/DeSMRRest-clustered-reactivation;visit=swh:1:snp:01cbfacef99252a4f0d1d43f5354c664e1585cf5;anchor=swh:1:rev:1e58112b54e528f28d7c2b3752d62b5302a45085</ext-link></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Danker</surname><given-names>JF</given-names></name><name><surname>Anderson</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The ghosts of brain states past: remembering reactivates the brain regions engaged during encoding</article-title><source>Psychological Bulletin</source><volume>136</volume><fpage>87</fpage><lpage>102</lpage><pub-id pub-id-type="doi">10.1037/a0017937</pub-id><pub-id pub-id-type="pmid">20063927</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeBruijn</surname><given-names>NG</given-names></name></person-group><year iso-8601-date="1946">1946</year><article-title>A combinatorial problem</article-title><source>Proceedings of the Section of Sciences of the Koninklijke Nederlandse Akademie van Wetenschappen Te Amsterdam</source><volume>49</volume><fpage>758</fpage><lpage>764</lpage></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diekelmann</surname><given-names>S</given-names></name><name><surname>Born</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The memory function of sleep</article-title><source>Nature Reviews. Neuroscience</source><volume>11</volume><fpage>114</fpage><lpage>126</lpage><pub-id pub-id-type="doi">10.1038/nrn2762</pub-id><pub-id pub-id-type="pmid">20046194</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dudai</surname><given-names>Y</given-names></name><name><surname>Karni</surname><given-names>A</given-names></name><name><surname>Born</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The consolidation and transformation of memory</article-title><source>Neuron</source><volume>88</volume><fpage>20</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.004</pub-id><pub-id pub-id-type="pmid">26447570</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eichenlaub</surname><given-names>JB</given-names></name><name><surname>Jarosiewicz</surname><given-names>B</given-names></name><name><surname>Saab</surname><given-names>J</given-names></name><name><surname>Franco</surname><given-names>B</given-names></name><name><surname>Kelemen</surname><given-names>J</given-names></name><name><surname>Halgren</surname><given-names>E</given-names></name><name><surname>Hochberg</surname><given-names>LR</given-names></name><name><surname>Cash</surname><given-names>SS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Replay of learned neural firing sequences during rest in human motor cortex</article-title><source>Cell Reports</source><volume>31</volume><elocation-id>107581</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2020.107581</pub-id><pub-id pub-id-type="pmid">32375031</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eldar</surname><given-names>E</given-names></name><name><surname>Bae</surname><given-names>GJ</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Magnetoencephalography decoding reveals structural differences within integrative decision processes</article-title><source>Nature Human Behaviour</source><volume>2</volume><fpage>670</fpage><lpage>681</lpage><pub-id pub-id-type="doi">10.1038/s41562-018-0423-3</pub-id><pub-id pub-id-type="pmid">31346283</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eldar</surname><given-names>E</given-names></name><name><surname>Lièvre</surname><given-names>G</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The roles of online and offline replay in planning</article-title><source>eLife</source><volume>9</volume><elocation-id>e56911</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.56911</pub-id><pub-id pub-id-type="pmid">32553110</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engel</surname><given-names>AK</given-names></name><name><surname>Moll</surname><given-names>CKE</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name><name><surname>Ojemann</surname><given-names>GA</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Invasive recordings from the human brain: clinical insights and beyond</article-title><source>Nature Reviews. Neuroscience</source><volume>6</volume><fpage>35</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1038/nrn1585</pub-id><pub-id pub-id-type="pmid">15611725</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Epstein</surname><given-names>RA</given-names></name><name><surname>Patai</surname><given-names>EZ</given-names></name><name><surname>Julian</surname><given-names>JB</given-names></name><name><surname>Spiers</surname><given-names>HJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The cognitive map in humans: spatial navigation and beyond</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1504</fpage><lpage>1513</lpage><pub-id pub-id-type="doi">10.1038/nn.4656</pub-id><pub-id pub-id-type="pmid">29073650</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feld</surname><given-names>GB</given-names></name><name><surname>Lange</surname><given-names>T</given-names></name><name><surname>Gais</surname><given-names>S</given-names></name><name><surname>Born</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Sleep-dependent declarative memory consolidation--unaffected after blocking NMDA or AMPA receptors but enhanced by NMDA coagonist D-cycloserine</article-title><source>Neuropsychopharmacology</source><volume>38</volume><fpage>2688</fpage><lpage>2697</lpage><pub-id pub-id-type="doi">10.1038/npp.2013.179</pub-id><pub-id pub-id-type="pmid">23887151</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feld</surname><given-names>GB</given-names></name><name><surname>Born</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Sculpting memory during sleep: concurrent consolidation and forgetting</article-title><source>Current Opinion in Neurobiology</source><volume>44</volume><fpage>20</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2017.02.012</pub-id><pub-id pub-id-type="pmid">28278432</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Feld</surname><given-names>G</given-names></name><name><surname>Bernard</surname><given-names>M</given-names></name><name><surname>Rawson</surname><given-names>A</given-names></name><name><surname>Spiers</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Learning graph networks: sleep targets highly connected global and local nodes for consolidation</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.08.04.455038</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>DJ</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Sequence learning and the role of the hippocampus in rodent navigation</article-title><source>Current Opinion in Neurobiology</source><volume>22</volume><fpage>294</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2011.12.005</pub-id><pub-id pub-id-type="pmid">22226994</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Replay comes of age</article-title><source>Annual Review of Neuroscience</source><volume>40</volume><fpage>581</fpage><lpage>602</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-072116-031538</pub-id><pub-id pub-id-type="pmid">28772098</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname><given-names>LM</given-names></name><name><surname>Brown</surname><given-names>EN</given-names></name><name><surname>Wilson</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Trajectory encoding in the hippocampus and entorhinal cortex</article-title><source>Neuron</source><volume>27</volume><fpage>169</fpage><lpage>178</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(00)00018-0</pub-id><pub-id pub-id-type="pmid">10939340</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuentemilla</surname><given-names>L</given-names></name><name><surname>Penny</surname><given-names>WD</given-names></name><name><surname>Cashdollar</surname><given-names>N</given-names></name><name><surname>Bunzeck</surname><given-names>N</given-names></name><name><surname>Düzel</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Theta-coupled periodic replay in working memory</article-title><source>Current Biology</source><volume>20</volume><fpage>606</fpage><lpage>612</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2010.01.057</pub-id><pub-id pub-id-type="pmid">20303266</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garvert</surname><given-names>MM</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A map of abstract relational knowledge in the human hippocampal-entorhinal cortex</article-title><source>eLife</source><volume>6</volume><elocation-id>e17086</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.17086</pub-id><pub-id pub-id-type="pmid">28448253</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Genzel</surname><given-names>L</given-names></name><name><surname>Dragoi</surname><given-names>G</given-names></name><name><surname>Frank</surname><given-names>L</given-names></name><name><surname>Ganguly</surname><given-names>K</given-names></name><name><surname>de la Prida</surname><given-names>L</given-names></name><name><surname>Pfeiffer</surname><given-names>B</given-names></name><name><surname>Robertson</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A consensus statement: defining terms for reactivation analysis</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>375</volume><elocation-id>20200001</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2020.0001</pub-id><pub-id pub-id-type="pmid">32248790</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Luessi</surname><given-names>M</given-names></name><name><surname>Larson</surname><given-names>E</given-names></name><name><surname>Engemann</surname><given-names>DA</given-names></name><name><surname>Strohmeier</surname><given-names>D</given-names></name><name><surname>Brodbeck</surname><given-names>C</given-names></name><name><surname>Goj</surname><given-names>R</given-names></name><name><surname>Jas</surname><given-names>M</given-names></name><name><surname>Brooks</surname><given-names>T</given-names></name><name><surname>Parkkonen</surname><given-names>L</given-names></name><name><surname>Hämäläinen</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>MEG and EEG data analysis with MNE-Python</article-title><source>Frontiers in Neuroscience</source><volume>7</volume><elocation-id>267</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2013.00267</pub-id><pub-id pub-id-type="pmid">24431986</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grootswagers</surname><given-names>T</given-names></name><name><surname>Wardle</surname><given-names>SG</given-names></name><name><surname>Carlson</surname><given-names>TA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Decoding dynamic brain patterns from evoked responses: a tutorial on multivariate pattern analysis applied to time series neuroimaging data</article-title><source>Journal of Cognitive Neuroscience</source><volume>29</volume><fpage>677</fpage><lpage>697</lpage><pub-id pub-id-type="doi">10.1162/jocn_a_01068</pub-id><pub-id pub-id-type="pmid">27779910</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoddes</surname><given-names>E</given-names></name><name><surname>Zarcone</surname><given-names>V</given-names></name><name><surname>Smythe</surname><given-names>H</given-names></name><name><surname>Phillips</surname><given-names>R</given-names></name><name><surname>Dement</surname><given-names>WC</given-names></name></person-group><year iso-8601-date="1973">1973</year><article-title>Quantification of sleepiness: a new approach</article-title><source>Psychophysiology</source><volume>10</volume><fpage>431</fpage><lpage>436</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.1973.tb00801.x</pub-id><pub-id pub-id-type="pmid">4719486</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hulbert</surname><given-names>JC</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neural differentiation tracks improved recall of competing memories following interleaved study and retrieval practice</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>3994</fpage><lpage>4008</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu284</pub-id><pub-id pub-id-type="pmid">25477369</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jas</surname><given-names>M</given-names></name><name><surname>Engemann</surname><given-names>DA</given-names></name><name><surname>Bekhti</surname><given-names>Y</given-names></name><name><surname>Raimondo</surname><given-names>F</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Autoreject: Automated artifact rejection for MEG and EEG data</article-title><source>NeuroImage</source><volume>159</volume><fpage>417</fpage><lpage>429</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.06.030</pub-id><pub-id pub-id-type="pmid">28645840</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>JD</given-names></name><name><surname>Rugg</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Recollection and the reinstatement of encoding-related cortical activity</article-title><source>Cerebral Cortex</source><volume>17</volume><fpage>2507</fpage><lpage>2515</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhl156</pub-id><pub-id pub-id-type="pmid">17204822</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kerrén</surname><given-names>C</given-names></name><name><surname>Linde-Domingo</surname><given-names>J</given-names></name><name><surname>Hanslmayr</surname><given-names>S</given-names></name><name><surname>Wimber</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>An optimal oscillatory phase for pattern reactivation during memory retrieval</article-title><source>Current Biology</source><volume>28</volume><fpage>3383</fpage><lpage>3392</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2018.08.065</pub-id><pub-id pub-id-type="pmid">30344116</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kerrén</surname><given-names>C</given-names></name><name><surname>van Bree</surname><given-names>S</given-names></name><name><surname>Griffiths</surname><given-names>BJ</given-names></name><name><surname>Wimber</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Phase separation of competing memories along the human hippocampal theta rhythm</article-title><source>eLife</source><volume>11</volume><elocation-id>e80633</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.80633</pub-id><pub-id pub-id-type="pmid">36394367</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kolibius</surname><given-names>LD</given-names></name><name><surname>Born</surname><given-names>J</given-names></name><name><surname>Feld</surname><given-names>GB</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Vast amounts of encoded items nullify but do not reverse the effect of sleep on declarative memory</article-title><source>Frontiers in Psychology</source><volume>11</volume><elocation-id>607070</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2020.607070</pub-id><pub-id pub-id-type="pmid">33488465</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Economides</surname><given-names>M</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Fast sequences of non-spatial state representations in humans</article-title><source>Neuron</source><volume>91</volume><fpage>194</fpage><lpage>204</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.05.028</pub-id><pub-id pub-id-type="pmid">27321922</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Human replay spontaneously reorganizes experience</article-title><source>Cell</source><volume>178</volume><fpage>640</fpage><lpage>652</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2019.06.012</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Higgins</surname><given-names>C</given-names></name><name><surname>Penagos</surname><given-names>H</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Ólafsdóttir</surname><given-names>HF</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name></person-group><year iso-8601-date="2021">2021a</year><article-title>Temporally delayed linear modelling (TDLM) measures replay in both animals and humans</article-title><source>eLife</source><volume>10</volume><elocation-id>e66917</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.66917</pub-id><pub-id pub-id-type="pmid">34096501</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Mattar</surname><given-names>MG</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2021">2021b</year><article-title>Experience replay is associated with efficient nonlocal learning</article-title><source>Science</source><volume>372</volume><elocation-id>eabf1357</elocation-id><pub-id pub-id-type="doi">10.1126/science.abf1357</pub-id><pub-id pub-id-type="pmid">34016753</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manning</surname><given-names>JR</given-names></name><name><surname>Polyn</surname><given-names>SM</given-names></name><name><surname>Baltuch</surname><given-names>GH</given-names></name><name><surname>Litt</surname><given-names>B</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Oscillatory patterns in temporal lobe reveal context reinstatement during memory search</article-title><source>PNAS</source><volume>108</volume><fpage>12893</fpage><lpage>12897</lpage><pub-id pub-id-type="doi">10.1073/pnas.1015174108</pub-id><pub-id pub-id-type="pmid">21737744</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mattar</surname><given-names>MG</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Prioritized memory access explains planning and hippocampal replay</article-title><source>Nature Neuroscience</source><volume>21</volume><fpage>1609</fpage><lpage>1617</lpage><pub-id pub-id-type="doi">10.1038/s41593-018-0232-z</pub-id><pub-id pub-id-type="pmid">30349103</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mattar</surname><given-names>MG</given-names></name><name><surname>Lengyel</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Planning in the brain</article-title><source>Neuron</source><volume>110</volume><fpage>914</fpage><lpage>934</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.12.018</pub-id><pub-id pub-id-type="pmid">35041804</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDermott</surname><given-names>KB</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Practicing Retrieval Facilitates Learning</article-title><source>Annual Review of Psychology</source><volume>72</volume><fpage>609</fpage><lpage>633</lpage><pub-id pub-id-type="doi">10.1146/annurev-psych-010419-051019</pub-id><pub-id pub-id-type="pmid">33006925</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McFadyen</surname><given-names>J</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Differential replay of reward and punishment paths predicts approach and avoidance</article-title><source>Nature Neuroscience</source><volume>26</volume><fpage>627</fpage><lpage>637</lpage><pub-id pub-id-type="doi">10.1038/s41593-023-01287-7</pub-id><pub-id pub-id-type="pmid">37020116</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Momennejad</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Learning structures: predictive representations, replay, and generalization</article-title><source>Current Opinion in Behavioral Sciences</source><volume>32</volume><fpage>155</fpage><lpage>166</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2020.02.017</pub-id><pub-id pub-id-type="pmid">35419465</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nour</surname><given-names>MM</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Arumuham</surname><given-names>A</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Impaired neural replay of inferred relationships in schizophrenia</article-title><source>Cell</source><volume>184</volume><fpage>4315</fpage><lpage>4328</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2021.06.012</pub-id><pub-id pub-id-type="pmid">34197734</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nyberg</surname><given-names>N</given-names></name><name><surname>Duvelle</surname><given-names>É</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Spiers</surname><given-names>HJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Spatial goal coding in the hippocampal formation</article-title><source>Neuron</source><volume>110</volume><fpage>394</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.12.012</pub-id><pub-id pub-id-type="pmid">35032426</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1979">1979</year><article-title>Précis of O’Keefe &amp; Nadel’s The hippocampus as a cognitive map</article-title><source>Behavioral and Brain Sciences</source><volume>2</volume><fpage>487</fpage><lpage>494</lpage><pub-id pub-id-type="doi">10.1017/S0140525X00063949</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ólafsdóttir</surname><given-names>HF</given-names></name><name><surname>Bush</surname><given-names>D</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The role of hippocampal replay in memory and planning</article-title><source>Current Biology</source><volume>28</volume><fpage>R37</fpage><lpage>R50</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.10.073</pub-id><pub-id pub-id-type="pmid">29316421</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Michel</surname><given-names>V</given-names></name><name><surname>Thirion</surname><given-names>B</given-names></name><name><surname>Grisel</surname><given-names>O</given-names></name><name><surname>Blondel</surname><given-names>M</given-names></name><name><surname>Prettenhofer</surname><given-names>P</given-names></name><name><surname>Weiss</surname><given-names>R</given-names></name><name><surname>Dubourg</surname><given-names>V</given-names></name><name><surname>Vanderplas</surname><given-names>J</given-names></name><name><surname>Passos</surname><given-names>A</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Brucher</surname><given-names>M</given-names></name><name><surname>Perrot</surname><given-names>M</given-names></name><name><surname>Duchesnay</surname><given-names>É</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Scikit-learn: machine learning in python</article-title><source>Journal of Machine Learning Research</source><volume>12</volume><fpage>2825</fpage><lpage>2830</lpage></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peer</surname><given-names>M</given-names></name><name><surname>Brunec</surname><given-names>IK</given-names></name><name><surname>Newcombe</surname><given-names>NS</given-names></name><name><surname>Epstein</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Structuring knowledge with cognitive maps and cognitive graphs</article-title><source>Trends in Cognitive Sciences</source><volume>25</volume><fpage>37</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2020.10.004</pub-id><pub-id pub-id-type="pmid">33248898</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Preston</surname><given-names>AR</given-names></name><name><surname>Eichenbaum</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Interplay of hippocampus and prefrontal cortex in memory</article-title><source>Current Biology</source><volume>23</volume><fpage>R764</fpage><lpage>R773</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.05.041</pub-id><pub-id pub-id-type="pmid">24028960</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossion</surname><given-names>B</given-names></name><name><surname>Pourtois</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Revisiting snodgrass and Vanderwart’s object database: Color and texture improve object recognition</article-title><source>Journal of Vision</source><volume>1</volume><elocation-id>413</elocation-id><pub-id pub-id-type="doi">10.1167/1.3.413</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roux</surname><given-names>F</given-names></name><name><surname>Parish</surname><given-names>G</given-names></name><name><surname>Chelvarajah</surname><given-names>R</given-names></name><name><surname>Rollings</surname><given-names>DT</given-names></name><name><surname>Sawlani</surname><given-names>V</given-names></name><name><surname>Hamer</surname><given-names>H</given-names></name><name><surname>Gollwitzer</surname><given-names>S</given-names></name><name><surname>Kreiselmeyer</surname><given-names>G</given-names></name><name><surname>Ter Wal</surname><given-names>MJ</given-names></name><name><surname>Kolibius</surname><given-names>L</given-names></name><name><surname>Staresina</surname><given-names>BP</given-names></name><name><surname>Wimber</surname><given-names>M</given-names></name><name><surname>Self</surname><given-names>MW</given-names></name><name><surname>Hanslmayr</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Oscillations support short latency co-firing of neurons during human episodic memory formation</article-title><source>eLife</source><volume>11</volume><elocation-id>e78109</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.78109</pub-id><pub-id pub-id-type="pmid">36448671</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name><name><surname>Cordova</surname><given-names>NI</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neural representations of events arise from temporal community structure</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>486</fpage><lpage>492</lpage><pub-id pub-id-type="doi">10.1038/nn.3331</pub-id><pub-id pub-id-type="pmid">23416451</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>McDevitt</surname><given-names>EA</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name><name><surname>Mednick</surname><given-names>SC</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Human hippocampal replay during rest prioritizes weakly learned information and predicts memory performance</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>3920</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-06213-1</pub-id><pub-id pub-id-type="pmid">30254219</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schönauer</surname><given-names>M</given-names></name><name><surname>Pawlizki</surname><given-names>A</given-names></name><name><surname>Köck</surname><given-names>C</given-names></name><name><surname>Gais</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Exploring the effect of sleep and reduced interference on different forms of declarative memory</article-title><source>Sleep</source><volume>37</volume><fpage>1995</fpage><lpage>2007</lpage><pub-id pub-id-type="doi">10.5665/sleep.4258</pub-id><pub-id pub-id-type="pmid">25325490</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schuck</surname><given-names>NW</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Sequential replay of nonspatial task states in the human hippocampus</article-title><source>Science</source><volume>364</volume><elocation-id>eaaw5181</elocation-id><pub-id pub-id-type="doi">10.1126/science.aaw5181</pub-id><pub-id pub-id-type="pmid">31249030</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sekeres</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><chapter-title>Mechanisms of memory consolidation and transformation</chapter-title><person-group person-group-type="editor"><name><surname>Axmacher</surname><given-names>N</given-names></name><name><surname>Rasch</surname><given-names>B</given-names></name></person-group><source>Cognitive Neuroscience of Memory Consolidation</source><publisher-name>Springer International Publishing</publisher-name><fpage>17</fpage><lpage>44</lpage><pub-id pub-id-type="doi">10.1007/978-3-319-45066-7</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Snodgrass</surname><given-names>JG</given-names></name><name><surname>Vanderwart</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>A standardized set of 260 pictures: norms for name agreement, image agreement, familiarity, and visual complexity</article-title><source>Journal of Experimental Psychology. Human Learning and Memory</source><volume>6</volume><fpage>174</fpage><lpage>215</lpage><pub-id pub-id-type="doi">10.1037//0278-7393.6.2.174</pub-id><pub-id pub-id-type="pmid">7373248</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spiers</surname><given-names>HJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The hippocampal cognitive map: one space or many?</article-title><source>Trends in Cognitive Sciences</source><volume>24</volume><fpage>168</fpage><lpage>170</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.12.013</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stadler</surname><given-names>MA</given-names></name><name><surname>Roediger</surname><given-names>HL</given-names></name><name><surname>McDermott</surname><given-names>KB</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Norms for word lists that create false memories</article-title><source>Memory &amp; Cognition</source><volume>27</volume><fpage>494</fpage><lpage>500</lpage><pub-id pub-id-type="doi">10.3758/BF03211543</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Staresina</surname><given-names>BP</given-names></name><name><surname>Henson</surname><given-names>RNA</given-names></name><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Alink</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Episodic reinstatement in the medial temporal lobe</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>18150</fpage><lpage>18156</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4156-12.2012</pub-id><pub-id pub-id-type="pmid">23238729</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Staresina</surname><given-names>BP</given-names></name><name><surname>Bergmann</surname><given-names>TO</given-names></name><name><surname>Bonnefond</surname><given-names>M</given-names></name><name><surname>van der Meij</surname><given-names>R</given-names></name><name><surname>Jensen</surname><given-names>O</given-names></name><name><surname>Deuker</surname><given-names>L</given-names></name><name><surname>Elger</surname><given-names>CE</given-names></name><name><surname>Axmacher</surname><given-names>N</given-names></name><name><surname>Fell</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Hierarchical nesting of slow oscillations, spindles and ripples in the human hippocampus during sleep</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1679</fpage><lpage>1686</lpage><pub-id pub-id-type="doi">10.1038/nn.4119</pub-id><pub-id pub-id-type="pmid">26389842</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Tarder-Stoll</surname><given-names>H</given-names></name><name><surname>Baldassano</surname><given-names>C</given-names></name><name><surname>Aly</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>The brain hierarchically represents the past and future during multistep anticipation</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.07.24.550399</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taulu</surname><given-names>S</given-names></name><name><surname>Simola</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Spatiotemporal signal space separation method for rejecting nearby interference in MEG measurements</article-title><source>Physics in Medicine and Biology</source><volume>51</volume><fpage>1759</fpage><lpage>1768</lpage><pub-id pub-id-type="doi">10.1088/0031-9155/51/7/008</pub-id><pub-id pub-id-type="pmid">16552102</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Theves</surname><given-names>S</given-names></name><name><surname>Fernandez</surname><given-names>G</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The hippocampus encodes distances in multidimensional feature space</article-title><source>Current Biology</source><volume>29</volume><fpage>1226</fpage><lpage>1231</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.02.035</pub-id><pub-id pub-id-type="pmid">30905602</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tulving</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>What is episodic memory?</article-title><source>Current Directions in Psychological Science</source><volume>2</volume><fpage>67</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1111/1467-8721.ep10770899</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watson</surname><given-names>D</given-names></name><name><surname>Clark</surname><given-names>LA</given-names></name><name><surname>Tellegen</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Development and validation of brief measures of positive and negative affect: the PANAS scales</article-title><source>Journal of Personality and Social Psychology</source><volume>54</volume><fpage>1063</fpage><lpage>1070</lpage><pub-id pub-id-type="doi">10.1037//0022-3514.54.6.1063</pub-id><pub-id pub-id-type="pmid">3397865</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wimmer</surname><given-names>GE</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Vehar</surname><given-names>N</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Episodic memory retrieval success is associated with rapid replay of episode content</article-title><source>Nature Neuroscience</source><volume>23</volume><fpage>1025</fpage><lpage>1033</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-0649-z</pub-id><pub-id pub-id-type="pmid">32514135</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wimmer</surname><given-names>GE</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>McNamee</surname><given-names>DC</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Distinct replay signatures for prospective decision-making and memory preservation</article-title><source>PNAS</source><volume>120</volume><elocation-id>e2205211120</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2205211120</pub-id><pub-id pub-id-type="pmid">36719914</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wise</surname><given-names>T</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Chowdhury</surname><given-names>F</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Model-based aversive learning in humans is supported by preferential task state reactivation</article-title><source>Science Advances</source><volume>7</volume><elocation-id>eabf9616</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.abf9616</pub-id><pub-id pub-id-type="pmid">34321205</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wittkuhn</surname><given-names>L</given-names></name><name><surname>Schuck</surname><given-names>NW</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Dynamics of fMRI patterns reflect sub-second activation sequences and reveal replay in human visual cortex</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>1795</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-21970-2</pub-id><pub-id pub-id-type="pmid">33741933</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>Fell</surname><given-names>J</given-names></name><name><surname>Staresina</surname><given-names>BP</given-names></name><name><surname>Weber</surname><given-names>B</given-names></name><name><surname>Elger</surname><given-names>CE</given-names></name><name><surname>Axmacher</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Gamma power reductions accompany stimulus-specific representations of dynamic events</article-title><source>Current Biology</source><volume>25</volume><fpage>635</fpage><lpage>640</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.01.011</pub-id><pub-id pub-id-type="pmid">25683804</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.93357.4.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Schapiro</surname><given-names>Anna C</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>University of Pennsylvania</institution><country>United States</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>This magnetoencephalography study reports <bold>important</bold> new findings regarding the nature of memory reactivation during cued recall. It replicates previous work showing that such reactivation can be sequential or clustered, with sequential reactivation being more prevalent in low performers. It adds <bold>convincing</bold> evidence, even though based on limited amounts of data, that high memory performers tend to show simultaneous (i.e., clustered) reactivation, varying in strength with item distance in the learned graph structure. The study will be of interest to scientists studying memory replay.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.93357.4.sa1</article-id><title-group><article-title>Reviewer #1 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>Previous work in humans and non-human animals suggests that during offline periods following learning, the brain replays newly acquired information in a sequential manner. The present study uses a MEG-based decoding approach to investigate the nature of replay/reactivation during a cued recall task directly following a learning session, where human participants are trained on a new sequence of 10 visual images embedded in a graph structure. During retrieval, participants are then cued with two items from the learned sequence, and neural evidence is obtained for the simultaneous or sequential reactivation of future sequence items. The authors find evidence for both sequential and clustered (i.e., simultaneous) reactivation. Replicating previous work, low-performing participants tend to show sequential, temporally segregated reactivation of future items, whereas high-performing participants show more clustered reactivation. Adding to previous work, the authors show that an image's reactivation strength varies depending on its proximity to the retrieval cue within the graph structure.</p><p>Strengths:</p><p>As the authors point out, work on memory reactivation has largely been limited to the retrieval of single associations. Given the sequential nature of our real-life experiences, there is clearly value in extending this work to structured, sequential information. State-of-the-art decoding approaches for MEG are used to characterize the strength and timing of item reactivation. The manuscript is very well written with helpful and informative figures in the main sections. The task includes an extensive localizer with 50 repetitions per image, allowing for stable training of the decoders and the inclusion of several sanity checks demonstrating that on-screen items can be decoded with high accuracy.</p><p>Weaknesses:</p><p>Of major concern, the experiment is not optimally designed for analysis of the retrieval task phase, where only 4 min of recording time and a single presentation of each cue item are available for the analyses of sequential and non-sequential reactivation. In their revision, the authors include data from the learning blocks in their analysis. These blocks follow the same trial structure as the retrieval task, and apart from adding more data points could also reveal a possible shift from sequential to clustered reactivation as learning of the graph structure progresses. The new analyses are not entirely conclusive, maybe given the variability in the number of learning blocks that participants require to reach the criterion. In principle, they suggest that reactivation strength increases from learning (pre-rest) to final retrieval (post-rest).</p><p>On a more conceptual note, the main narrative of the manuscript implies that sequential and clustered reactivation are mutually exclusive, such that a single participant would show either one or the other type. With the analytic methods used here, however, it seems possible to observe both types of reactivation. For example, the observation that mean reactivation strength (across the entire trial, or in a given time window of interest) varies with graph distance does not exclude the possibility that this reactivation is also sequential. In fact, the approach of defining one peak time window of reactivation may bias towards simultaneous, graded reactivation. It would be helpful if the authors could clarify this conceptual point. A strong claim that the two types of reactivation are mutually exclusive would need to be substantiated by further evidence, for instance, a suitable metric contrasting &quot;sequenceness&quot; vs &quot;clusteredness&quot;.</p><p>On the same point, the non-sequential reactivation analyses use a time window of peak decodability that is determined based on the average reactivation of all future items, irrespective of graph distance. In a sequential forward cascade of reactivations, it could be assumed that the reactivation of near items would peak earlier than the reactivation of far items. In the revised manuscript, the authors now show the &quot;raw&quot; timecourses of item decodability at different graph distances, clearly demonstrating their peak reactivation times, which show convincingly that reactivation for near and far items occurs at very similar time points. The question that remains, therefore, is whether the method of pre-selecting a time window of interest described above could exert a bias towards finding clustered reactivation.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.93357.4.sa2</article-id><title-group><article-title>Reviewer #2 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>The authors investigate replay (defined as sequential reactivation) and clustered reactivation during retrieval of an abstract cognitive map. Replay and clustered reactivation were analysed based on MEG recordings combined with a decoding approach. While the authors state to find evidence for both, replay and clustered reactivation during retrieval, replay was exclusively present in low performers. Further, the authors show that reactivation strength declined with an increasing graph distance.</p><p>Strengths:</p><p>The paper raises interesting research questions, i.e., replay vs. clustered reactivation and how that supports retrieval of cognitive maps. The paper is well written, well structured and easy to follow. The methodological approach is convincing and definitely suited to address the proposed research questions.</p><p>The paper is a great combination between replicating previous findings (Wimmer et al. 2020) with a new experimental approach but at the same time presenting novel evidence (reactivation strength declines as a function of graph distance).</p><p>What I also want to positively highlight is their general transparency. For example, they pre-registered this study but with a focus on a different part of the data and outlined this explicitly in the paper.</p><p>The paper has very interesting findings. However, there are some shortcomings, especially in the experimental design. These are shortly outlined below but are also openly and in detail discussed by the authors.</p><p>Weaknesses:</p><p>The individual findings are interesting. However, due to some shortcomings in the experimental design they cannot be profoundly related to each other. For example, the authors show that replay is present in low but not in high performers with the assumption that high performers tend to simultaneously reactivate items. But then, the authors do not investigate clustered reactivation (=simultaneous reactivation) as a function of performance due to a low number of retrieval trials and ceiling performance in most participants.</p><p>As a consequence of the experimental design, some analyses are underpowered (very low number of trials, n = ~10, and for some analyses, very low number of participants, n = 14).</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.93357.4.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Kern</surname><given-names>Simon</given-names></name><role specific-use="author">Author</role><aff><institution>Central Institute of Mental Health</institution><addr-line><named-content content-type="city">Mannheim</named-content></addr-line><country>Germany</country></aff></contrib><contrib contrib-type="author"><name><surname>Nagel</surname><given-names>Juliane</given-names></name><role specific-use="author">Author</role><aff><institution>Central Institute of Mental Health</institution><addr-line><named-content content-type="city">Mannheim</named-content></addr-line><country>Germany</country></aff></contrib><contrib contrib-type="author"><name><surname>Gerchen</surname><given-names>Martin Fungisai</given-names></name><role specific-use="author">Author</role><aff><institution>Central Institute of Mental Health</institution><addr-line><named-content content-type="city">Mannheim</named-content></addr-line><country>Germany</country></aff></contrib><contrib contrib-type="author"><name><surname>Gürsoy</surname><given-names>Çağatay</given-names></name><role specific-use="author">Author</role><aff><institution>Central Institute of Mental Health</institution><addr-line><named-content content-type="city">Mannheim</named-content></addr-line><country>Germany</country></aff></contrib><contrib contrib-type="author"><name><surname>Meyer-Lindenberg</surname><given-names>Andreas</given-names></name><role specific-use="author">Author</role><aff><institution>Central Institute of Mental Health</institution><addr-line><named-content content-type="city">Mannheim</named-content></addr-line><country>Germany</country></aff></contrib><contrib contrib-type="author"><name><surname>Kirsch</surname><given-names>Peter</given-names></name><role specific-use="author">Author</role><aff><institution>Central Institute of Mental Health</institution><addr-line><named-content content-type="city">Mannheim</named-content></addr-line><country>Germany</country></aff></contrib><contrib contrib-type="author"><name><surname>Dolan</surname><given-names>Raymond J</given-names></name><role specific-use="author">Author</role><aff><institution>University College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Gais</surname><given-names>Steffen</given-names></name><role specific-use="author">Author</role><aff><institution>Eberhard-Karls-University Tübingen</institution><addr-line><named-content content-type="city">Tübingen</named-content></addr-line><country>Germany</country></aff></contrib><contrib contrib-type="author"><name><surname>Feld</surname><given-names>Gordon B</given-names></name><role specific-use="author">Author</role><aff><institution>Central Institute of Mental Health</institution><addr-line><named-content content-type="city">Mannheim</named-content></addr-line><country>Germany</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the previous reviews.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p><p>Results showing reactivation for near and far items separately are now included in Fig. 5 and convincingly suggest a simultaneous reactivation. For me, the open question remaining (see public) review is the degree to which the methods used here to show clustered vs sequential reactivation are mutually exclusive; and if the pre-selection of a time window of peak reactivation (based on all future items) biases the analyses towards clustered reactivation. The discussion would benefit from a brief discussion of these issues.</p></disp-quote><p>We have added a brief discussion of the issues. However, we want to clarify a minor point of the public review: While our interpretation implies that replay and reactivation are probably mutually exclusive within a single retrieval event, it does not imply that strategies cannot vary within different retrieval events of the same participant. Nevertheless, we want to address this raised concern (that is, if we understand correctly, that replay events that are contained within the time window of the reactivation analysis could not be distinguished by the chosen methods) and have added it to the discussion.</p><p>The corresponding sentence reads:</p><p>“[…] Finally, we want to acknowledge that by selecting a time window for the clustered reactivation we cannot distinguish very fast replay events (&lt;=30ms) from clustered reactivation if they are contained exactly within the specific reactivation analysis time window..</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p><p>Figure 5D shows the difference scores between near vs. distant items for learning and retrieval. Similar to Figure 5 from the first version of your paper, the difference score does not show whether reactivation of the near vs. distant items change from learning to retrieval. You could show this change in a 2 (near vs. distant) x 2 (learning vs. retrieval) box plot (corresponding to Figure 5A).</p></disp-quote><p>We have added the requested plot as supplement 9 and referred to it in the figure description. However comparing absolute, raw probabilities between different blocks is tricky, as baseline probabilities are varying over time (e.g. due to shift in distance to sensors), therefore, differential reactivation might be better suited as it is a relative measure to compare between blocks.</p><disp-quote content-type="editor-comment"><p>At the end of the results section, you state: &quot;On average, differential reactivation probability increased from pre to post resting state (Figure 5D).&quot;. I would suggest providing some statistical comparison and the corresponding values.</p></disp-quote><p>We have calculated and added respective p-value statistics of a T-Test and reported that the increase is only descriptive and not statistically significant.</p></body></sub-article></article>