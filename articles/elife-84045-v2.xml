<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">84045</article-id><article-id pub-id-type="doi">10.7554/eLife.84045</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Temporal integration is a robust feature of perceptual decisions</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-21200"><name><surname>Hyafil</surname><given-names>Alexandre</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-0566-651X</contrib-id><email>alexandre.hyafil@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-71469"><name><surname>de la Rocha</surname><given-names>Jaime</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3314-9384</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-295871"><name><surname>Pericas</surname><given-names>Cristina</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-256114"><name><surname>Katz</surname><given-names>Leor N</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-2742-6533</contrib-id><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-295870"><name><surname>Huk</surname><given-names>Alexander C</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1430-6935</contrib-id><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-10627"><name><surname>Pillow</surname><given-names>Jonathan W</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3638-8831</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/020s51w82</institution-id><institution>Centre de Recerca Matemàtica</institution></institution-wrap><addr-line><named-content content-type="city">Bellaterra</named-content></addr-line><country>Spain</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hx57361</institution-id><institution>Princeton Neuroscience Institute, Princeton University</institution></institution-wrap><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution>Institut d’Investigacions Biomèdiques August Pi i Sunyer (IDIBAPS)</institution><addr-line><named-content content-type="city">Barcelona</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01cwqze88</institution-id><institution>Laboratory of Sensorimotor Research, National Eye Institute, National Institutes of Health</institution></institution-wrap><addr-line><named-content content-type="city">Bethesda</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/046rm7j60</institution-id><institution>Fuster Laboratory for Cognitive Neuroscience, Departments of Psychiatry &amp; Biobehavioral Sciences and Ophthalmology, UCLA</institution></institution-wrap><addr-line><named-content content-type="city">Los Angeles</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Salinas</surname><given-names>Emilio</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0207ad724</institution-id><institution>Wake Forest School of Medicine</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>04</day><month>05</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>12</volume><elocation-id>e84045</elocation-id><history><date date-type="received" iso-8601-date="2022-10-08"><day>08</day><month>10</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2023-05-03"><day>03</day><month>05</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2022-10-26"><day>26</day><month>10</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.10.25.513647"/></event></pub-history><permissions><ali:free_to_read/><license xlink:href="http://creativecommons.org/publicdomain/zero/1.0/"><ali:license_ref>http://creativecommons.org/publicdomain/zero/1.0/</ali:license_ref><license-p>This is an open-access article, free of all copyright, and may be freely reproduced, distributed, transmitted, modified, built upon, or otherwise used by anyone for any lawful purpose. The work is made available under the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">Creative Commons CC0 public domain dedication</ext-link>.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-84045-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-84045-figures-v2.pdf"/><abstract><p>Making informed decisions in noisy environments requires integrating sensory information over time. However, recent work has suggested that it may be difficult to determine whether an animal’s decision-making strategy relies on evidence integration or not. In particular, strategies based on extrema-detection or random snapshots of the evidence stream may be difficult or even impossible to distinguish from classic evidence integration. Moreover, such non-integration strategies might be surprisingly common in experiments that aimed to study decisions based on integration. To determine whether temporal integration is central to perceptual decision-making, we developed a new model-based approach for comparing temporal integration against alternative ‘non-integration’ strategies for tasks in which the sensory signal is composed of discrete stimulus samples. We applied these methods to behavioral data from monkeys, rats, and humans performing a variety of sensory decision-making tasks. In all species and tasks, we found converging evidence in favor of temporal integration. First, in all observers across studies, the integration model better accounted for standard behavioral statistics such as psychometric curves and psychophysical kernels. Second, we found that sensory samples with large evidence do not contribute disproportionately to subject choices, as predicted by an extrema-detection strategy. Finally, we provide a direct confirmation of temporal integration by showing that the sum of both early and late evidence contributed to observer decisions. Overall, our results provide experimental evidence suggesting that temporal integration is an ubiquitous feature in mammalian perceptual decision-making. Our study also highlights the benefits of using experimental paradigms where the temporal stream of sensory evidence is controlled explicitly by the experimenter, and known precisely by the analyst, to characterize the temporal properties of the decision process.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>motion perception</kwd><kwd>decision-making</kwd><kwd>accumulation of evidence</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd><kwd>Rat</kwd><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100011033</institution-id><institution>Agencia Estatal de Investigación</institution></institution-wrap></funding-source><award-id>RYC-2017-23231</award-id><principal-award-recipient><name><surname>Hyafil</surname><given-names>Alexandre</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003329</institution-id><institution>Ministerio de Economía y Competitividad</institution></institution-wrap></funding-source><award-id>SAF2015-70324-R</award-id><principal-award-recipient><name><surname>de la Rocha</surname><given-names>Jaime</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000781</institution-id><institution>European Research Council</institution></institution-wrap></funding-source><award-id>ERC-2015-CoG-683209</award-id><principal-award-recipient><name><surname>de la Rocha</surname><given-names>Jaime</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R01EY017366</award-id><principal-award-recipient><name><surname>Huk</surname><given-names>Alexander C</given-names></name><name><surname>Pillow</surname><given-names>Jonathan W</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>NS104899</award-id><principal-award-recipient><name><surname>Pillow</surname><given-names>Jonathan W</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution>Simons Collaboration for the Global Brain</institution></institution-wrap></funding-source><award-id>SCGB AWD543027</award-id><principal-award-recipient><name><surname>Pillow</surname><given-names>Jonathan W</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection, and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Responses of monkeys, rats, and humans performing perceptual discrimination of discrete-sample stimuli rely on accumulation over time of sensory evidence.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Perceptual decision-making is thought to rely on the temporal integration of noisy sensory information on a timescale of hundreds of milliseconds to seconds. Temporal integration corresponds to summing over time the evidence provided by each new sensory stimulus, and optimizes perceptual judgments in face of noise (<xref ref-type="bibr" rid="bib3">Bogacz et al., 2006</xref>; <xref ref-type="bibr" rid="bib14">Gold and Shadlen, 2007</xref>). A perceptual decision can then be made on the basis of this accumulated evidence, either as some threshold on accumulated evidence is reached, or if some internal or external cue signals the need to initiate a response.</p><p>Although many behavioral and neural results are consistent with this integration framework, temporal integration is a feature that has often been taken for granted rather than explicitly tested. Recently, the claim that standard perceptual decision-making tasks rely on (or even frequently elicit) temporal integration has been challenged by theoretical results showing that non-integration strategies can produce behavior that carries superficial signatures of temporal integration (<xref ref-type="bibr" rid="bib41">Stine et al., 2020</xref>). These signatures include the relationship between stimulus difficulty, stimulus duration, and behavioral accuracy, the precise temporal weighting of sensory information on the decisions, and the patterns of reaction times.</p><p>Here, we propose new analytical tools for directly assessing integration and non-integration strategies from fixed- or variable-duration paradigms where, critically, the experimenter controls the fluctuations in perceptual evidence over time within each trial (discrete-sample stimulus, or DSS). By leveraging these controlled fluctuations, our methods allow us to make direct comparisons between integration and non-integration strategies. We apply these tools to assess temporal integration in data from monkeys, humans, and rats that performed a variety of perceptual decision-making tasks with DSS. Applying these analyses to these behavioral datasets yields strong evidence that perceptual decision-making tasks in all three species rely on temporal integration. Temporal integration, a critical element of many major theories of perception at both the neural and behavioral levels, is indeed a robust and pervasive aspect of mammalian behavior. Our results also illuminate the power of targeted stimulus design and statistical analysis to test specific features of behavior.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Integration and non-integration models</title><p>In a typical perceptual evidence-integration experiment (<xref ref-type="fig" rid="fig1">Figure 1A</xref>), an observer is presented in each trial with a time-varying stimulus and must report which of two possible stimulus categories it belongs to. Typical examples include judging whether a dynamic visual stimulus is moving leftwards or rightwards (<xref ref-type="bibr" rid="bib51">Yates et al., 2017</xref>; <xref ref-type="bibr" rid="bib20">Katz et al., 2015</xref>); whether the orientation of a set of gratings is more aligned with cardinal or diagonal directions (<xref ref-type="bibr" rid="bib49">Wyart et al., 2012</xref>) whether a combination of tones is dominated by high or low frequencies (<xref ref-type="bibr" rid="bib29">Morillon et al., 2014</xref>; <xref ref-type="bibr" rid="bib15">Hermoso-Mendizabal et al., 2020</xref>; <xref ref-type="bibr" rid="bib53">Znamenskiy and Zador, 2013</xref>); which of two acoustic streams is more intense or dense (<xref ref-type="bibr" rid="bib6">Brunton et al., 2013</xref>; <xref ref-type="bibr" rid="bib35">Pardo-Vazquez et al., 2019</xref>; <xref ref-type="bibr" rid="bib8">Cisek et al., 2009</xref>). Such paradigms have been used extensively in humans, nonhuman primates, and rodents. Here, we focus on experiments in which observers report their choice at the end of a period whose duration is controlled by the experimenter (<xref ref-type="bibr" rid="bib24">Kiani and Shadlen, 2009</xref>; <xref ref-type="bibr" rid="bib49">Wyart et al., 2012</xref>; <xref ref-type="bibr" rid="bib6">Brunton et al., 2013</xref>; <xref ref-type="bibr" rid="bib38">Raposo et al., 2012</xref>), in contrast to so-called ‘reaction time’ tasks, in which the observer can respond after viewing as brief a portion of the stimulus as they wish (<xref ref-type="bibr" rid="bib39">Roitman and Shadlen, 2002</xref>; <xref ref-type="bibr" rid="bib53">Znamenskiy and Zador, 2013</xref>; <xref ref-type="bibr" rid="bib35">Pardo-Vazquez et al., 2019</xref>; <xref ref-type="bibr" rid="bib15">Hermoso-Mendizabal et al., 2020</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Integration and non-integration models for performing sensory discrimination tasks.</title><p>(<bold>A</bold>) Schematic of a typical fixed-duration perceptual task with discrete-sample stimuli (DSS). A stimulus is composed of a discrete sequence of <italic>n</italic> samples (here, <italic>n</italic> = 8). The subjects must report at the end of the sequence whether one specific quality of the stimulus was ‘overall’ leaning more toward one of two possible categories A or B. Evidence in favor of category A or B varies across samples (blue and orange bars). (<bold>B</bold>) Temporal integration model. The relative evidence in favor of each category is accumulated sequentially as each new sample is presented (black line), resulting in temporal integration of the sequence evidence. The choice is determined by the end point of the accumulation process: here, the overall evidence in favor of category A is positive, so response A is selected. (<bold>C</bold>) Extrema-detection model. A decision is made whenever the instantaneous evidence for a given sample (blue and orange arrows) reaches a certain fixed threshold (dotted lines). The selected choice corresponds to the sign of the evidence of the sample that reaches the threshold (here, response B). Subsequent samples are ignored (gray bars). (<bold>D</bold>) Snapshot model. Here, only one sample is attended. Which sample is attended is determined in each trial by a stochastic policy. The response of the model simply depends on the evidence of the attended sample. Other samples are ignored (gray bars). Variants of the model include attending <italic>K</italic> &gt; 1 sequential samples.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84045-fig1-v2.tif"/></fig><p>Moreover, we focus on experimental paradigms in which the sensory evidence in favor of each category arrives in a sequence of discrete <italic>samples</italic>. Samples can correspond to motion pulses (<xref ref-type="bibr" rid="bib51">Yates et al., 2017</xref>), individual gratings (<xref ref-type="bibr" rid="bib49">Wyart et al., 2012</xref>), acoustic tones (<xref ref-type="bibr" rid="bib29">Morillon et al., 2014</xref>; <xref ref-type="bibr" rid="bib15">Hermoso-Mendizabal et al., 2020</xref>; <xref ref-type="bibr" rid="bib53">Znamenskiy and Zador, 2013</xref>), numbers (<xref ref-type="bibr" rid="bib4">Bronfman et al., 2015</xref>; <xref ref-type="bibr" rid="bib8">Cisek et al., 2009</xref>), or symbols representing category probabilities (<xref ref-type="bibr" rid="bib50">Yang and Shadlen, 2007</xref>). We refer to this configuration as the DSS paradigm. In this paradigm, the perceptual evidence provided by each sample can be controlled independently, allowing for detailed analyses of how different samples contribute to the behavioral response. The DSS framework can be contrasted with experiments in which the experimenter specifies only the mean stimulus strength on each trial, and variations in sensory evidence over time are not finely controlled or are not easily determined from the raw spatio-temporal stimulus.</p><p>Tasks using the DSS paradigm are classically thought to rely on sequential accumulation of the stimulus evidence (<xref ref-type="bibr" rid="bib3">Bogacz et al., 2006</xref>), which we refer to here as temporal integration. <xref ref-type="fig" rid="fig1">Figure 1A</xref> shows an example stimulus sequence composed of <italic>n</italic> samples that provide differing amounts of evidence in favor of one alternative vs. another (‘A’ vs. ‘B’). In the temporal integration model, the accumulated evidence fluctuates as new samples are integrated and finishes at a positive value indicating overall evidence for stimulus category A (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). This integration process can be formalized by defining the decision variable or accumulated evidence <inline-formula><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and its updating dynamics across stimulus samples: <inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> where <inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> represents a noisy version of the true stimulus evidence <inline-formula><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> in the <italic>i</italic>th sample corrupted by sensory noise <inline-formula><mml:math id="inf5"><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> . The binary decision <italic>r</italic> is simply based on the sign of the accumulated evidence <inline-formula><mml:math id="inf6"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi> </mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> at the end of the sample sequence (composed of <italic>n</italic> samples): <inline-formula><mml:math id="inf7"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mi>A</mml:mi></mml:math></inline-formula> if <inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf9"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mi>B</mml:mi></mml:math></inline-formula> if <inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. This procedure corresponds to the normative strategy with uniform weighting that maximizes accuracy. For such perfect integration, <inline-formula><mml:math id="inf11"><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , so that the probability of response A is <inline-formula><mml:math id="inf12"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mo>)</mml:mo><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mi>Φ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>β</mml:mi><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> where <inline-formula><mml:math id="inf13"><mml:mi>Φ</mml:mi></mml:math></inline-formula> is the cumulative normal distribution function (the normative weight for the stimuli <italic>β</italic> depends on the noise variance <inline-formula><mml:math id="inf14"><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo>(</mml:mo><mml:mi>ε</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> and the number of samples through <inline-formula><mml:math id="inf15"><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msqrt><mml:mi>n</mml:mi><mml:mi> </mml:mi><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo>(</mml:mo><mml:mi>ε</mml:mi><mml:mo>)</mml:mo></mml:msqrt></mml:math></inline-formula>). Departures from optimality in the accumulation process such as accumulation leak, categorization dynamics, divisive normalization, sensory adaptation, or sticky boundaries may however yield unequal weighting of the different samples (<xref ref-type="bibr" rid="bib51">Yates et al., 2017</xref>; <xref ref-type="bibr" rid="bib6">Brunton et al., 2013</xref>; <xref ref-type="bibr" rid="bib37">Prat-Ortega et al., 2021</xref>; <xref ref-type="bibr" rid="bib5">Bronfman et al., 2016</xref>; <xref ref-type="bibr" rid="bib21">Keung et al., 2019</xref>; <xref ref-type="bibr" rid="bib22">Keung et al., 2020</xref>). To accommodate for these, we allowed the integration model to take any arbitrary weighting of the samples: <inline-formula><mml:math id="inf16"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mi>A</mml:mi><mml:mo>)</mml:mo><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mi>Φ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> (see Methods for details). The mapping from final accumulated evidence to choice was probabilistic, to account for the effects of noise from different sources in the decision-making process (<xref ref-type="bibr" rid="bib11">Drugowitsch et al., 2016</xref>). Thus, this model represented an approximate statistical description for any generative model relying on temporal integration of the stimulus evidence.</p><p>Although it has been commonly assumed that observers use evidence-integration strategies to perform these psychophysical tasks, recent work has suggested that observers may employ non-integration strategies instead (<xref ref-type="bibr" rid="bib41">Stine et al., 2020</xref>). Here, we consider two specific alternative models. The first non-integration model corresponds to an <italic>extrema-detection</italic> model (<xref ref-type="bibr" rid="bib45">Waskom and Kiani, 2018</xref>; <xref ref-type="bibr" rid="bib41">Stine et al., 2020</xref>; <xref ref-type="bibr" rid="bib9">Ditterich, 2006</xref>). In this model, observers do not integrate evidence across samples but instead base their decision on extreme or salient bits of evidence. More specifically, the observer commits to a decision based on the first sample <italic>i</italic> in the stimulus sequence that exceeds one of the two symmetrical thresholds, that is such that <inline-formula><mml:math id="inf17"><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mo>≥</mml:mo><mml:mi>θ</mml:mi></mml:math></inline-formula>. In our example stimulus, the first sample that reaches this threshold in evidence space is the fifth sample, which points toward stimulus category B, so response B is selected (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). This policy can be viewed as a memoryless decision process with sticky bounds. If the stimulus sequence contains no extreme samples, so that neither threshold is reached, the observer selects a response at random. We also explored an alternative mechanism where in such cases the response is based on the last sample in the sequence, following <xref ref-type="bibr" rid="bib41">Stine et al., 2020</xref>; and a variant of the model where the decision threshold is different on every sample position.</p><p>The second non-integration model corresponds to the <italic>snapshot model</italic> (<xref ref-type="bibr" rid="bib41">Stine et al., 2020</xref>; <xref ref-type="bibr" rid="bib36">Pinto et al., 2018</xref>). In this model, the observer attends to only one sample <italic>i</italic> within the stimulus sequence, and makes a decision based solely on the evidence from the attended sample: <inline-formula><mml:math id="inf18"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mi>A</mml:mi></mml:math></inline-formula> if <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf20"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mi>B</mml:mi></mml:math></inline-formula> if <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. The position in the sequence of the attended sample is randomly selected on each trial. In our example, the fourth sample is randomly selected, and since it contains evidence toward stimulus category A, response A is selected (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). We considered variants of this model that gave it additional flexibility, including: allowing the prior probability over the attended sample to depend on its position in the sequence using a non-parametric probability mass function estimated from the data; allowing for deterministic vs. probabilistic decision-making rule based on the attended evidence; including attentional lapses that were either fixed to 0.02 (split equally between leftward and rightward responses) or estimated from behavioral data. We finally considered a variant of the snapshot model where the decision was made based on a subsequence of <italic>K</italic> consecutive samples within the main stimulus sequence (<inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>K</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>), rather than based on a single sample.</p></sec><sec id="s2-2"><title>Standard behavioral statistics favor integration accounts of pulse-based motion perception in primates</title><p>To compare the three decision-making models defined above (i.e., temporal integration, extrema-detection, snapshots), we first examined behavioral data from two monkeys performing a fixed-duration motion integration task (<xref ref-type="bibr" rid="bib51">Yates et al., 2017</xref>). In this experiment, each stimulus was composed of a sequence of 7 motion samples of 150 ms each where the motion strength toward left or right was manipulated independently for each sample. At the end of the stimulus sequence, monkeys reported with a saccade whether the overall sequence contained more motion toward the left or right direction. The animals performed 72,137 and 33,416 trials for monkey N and monkey P, respectively, allowing for in-depth dissection of their response patterns.</p><p>We fit the three models (and their variants) to the responses for each animal individually (see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref> for estimated parameters for the different models). We then simulated the fitted model and computed, for simulated and experimental data, the psychophysical kernels capturing the weights of the different sensory samples based on their position in the stimulus sequence (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Psychophysical kernels were non-monotonic and differed in shape between the two animals, probably reflecting the complex contributions of various dynamics and suboptimalities along the sensory and decision pathways (<xref ref-type="bibr" rid="bib51">Yates et al., 2017</xref>; <xref ref-type="bibr" rid="bib27">Levi and Huk, 2020</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>The integration model better described monkey behavior than non-integration models.</title><p>(<bold>A</bold>) Difference between Akaike information criterion (AIC) of models (temporal integration: red bar; snapshot model: blue; extrema-detection model: green) and temporal integration model for each monkey. Positive values indicate poorer fit to data. (<bold>B</bold>) Psychophysical kernels for behavioral data (black dots) vs. simulated data from temporal integration model (left panel, red curve), snapshot model (middle panel, blue curve), and extrema-detection model (right panel, green curve) for the two animals (monkey N: top panels; monkey P: bottom panels). Each data point represents the weight of the motion pulse at the corresponding position on the animal/model response. Error bars and shadowed areas represent the standard error of the weights for animal and simulated data, respectively. (<bold>C</bold>) Accuracy of animal responses (black bars) vs. simulated data from fitted models (color bars), for each monkey. Blue and green marks indicate the maximum performance for the snapshot and extrema-detection models, respectively. Error bars represent standard error of the mean. (<bold>D</bold>) Psychometric curves for animal (black dots) and simulated data (color lines) for monkey N, representing the proportion of rightward choices per quantile of weighted stimulus evidence.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84045-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Parameter fits for integration and non-integration models.</title><p>(<bold>A</bold>) Modulation gain <inline-formula><mml:math id="inf23"><mml:mi>γ</mml:mi></mml:math></inline-formula> per session for the integration model, for each animal (green: monkey P; purple: monkey N). (<bold>B</bold>) Mixture coefficients <inline-formula><mml:math id="inf24"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> of the snapshot model estimated for each monkey, representing the prior probability that each sample is attended on each trial. (<bold>C</bold>) Parameters <italic>T</italic> and <inline-formula><mml:math id="inf25"><mml:mi>σ</mml:mi></mml:math></inline-formula> of the extrema-detection model, estimated for each monkey. Error bars correspond to the confidence interval obtained using the Laplace approximation.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84045-fig2-figsupp1-v2.tif"/></fig><fig id="fig2s2" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 2.</label><caption><title>Model fits for variants of the snapshot model.</title><p>(<bold>A</bold>) Predicted accuracy for the snapshot model fitted to monkey data, as a function of memory span <italic>K</italic>, for fixed lapses (dashed lines, <inline-formula><mml:math id="inf26"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:math></inline-formula>) and lapses estimated from the data (full lines). Black curves represent the model with sensory noise (‘probabilistic’), blue curves represent the model without sensory noise (‘non-probabilistic’ or ‘deterministic’). Memory span <italic>K</italic> corresponds to the number of successive samples used to define the decision on each trial (see Methods). The horizontal bar corresponds to the average accuracy of the animal. (<bold>B</bold>) Akaike information criterion (AIC) difference between each of the four variants of the snapshot and the integration model. Legend as in A (full/dashed lines for fixed/free lapse parameters; black/blue curves for probabilistic/deterministic variants). Note that the probabilistic variant with either fixed or free lapses provide virtually indistinguishable values. Positive values indicate that the snapshot model provides a worse fit compared with the integration model. (<bold>C</bold>) Psychometric curve for the snapshot model with span <italic>K =</italic> 3 samples, sensory noise and free lapse parameters (best snapshot model variant according to AIC). (<bold>D</bold>) Psychophysical kernel for the same variant of the model. (<bold>E</bold>) Correlation between data and model integration maps for variants of the snapshot model.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84045-fig2-figsupp2-v2.tif"/></fig><fig id="fig2s3" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 3.</label><caption><title>Model fits for variants of the extrema-detection model.</title><p>(<bold>A</bold>) Predicted accuracy for the extrema-detection model fitted to the monkey data, for random (black curves) and last sample (red curve) default rule, for fixed lapses (<inline-formula><mml:math id="inf27"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:math></inline-formula>) or lapse parameters estimated from the data, and for fixed- or varying-threshold parameter. The horizontal bar indicates animal accuracy. (<bold>B</bold>) Akaike information criterion (AIC) difference between variants of the extrema-detection model and the integration model. Legend as in A. Positive values indicate that the extrema-detection model provides a worse fit. Psychometric curve (<bold>C</bold>) and psychophysical kernel (<bold>D</bold>) for the model variant that provided the best match to behavior in terms of predicted accuracy and AIC: free lapse parameters and last sample rule. (<bold>E</bold>) Correlation between integration maps from animal and simulated data (see <xref ref-type="fig" rid="fig4">Figure 4</xref>) for variants of the extrema-detection model. The horizontal bar marks the correlation between experimental data and the integration model.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84045-fig2-figsupp3-v2.tif"/></fig></fig-group><p>The temporal profile of the kernel was perfectly matched by the integration model, almost by design, as we gave full flexibility to the model to adjust the sample weights. The snapshot model was provided with similar flexibility, as the prior probability of attending each sample could be fully adjusted to the monkey decisions. However, the snapshot model could not match the experimental psychophysical kernel as accurately. It consistently underestimated the magnitude of weighting in monkey P (<xref ref-type="fig" rid="fig2">Figure 2B</xref>, bottom row). The extrema-detection model was not endowed with such flexibility of sensory weighting. On the contrary, since the decision was based on the first sample in the sequence reaching a certain criterion, this inevitably generates a primacy effect in the psychophysical kernels – or at best a flat weighting (<xref ref-type="bibr" rid="bib41">Stine et al., 2020</xref>). The model thus failed to capture the non-monotonic psychophysical kernels from animal data.</p><p>Next, we looked at the psychometric curves and choice accuracy predictions of each fitted model (<xref ref-type="fig" rid="fig2">Figure 2C, D</xref>). <xref ref-type="bibr" rid="bib41">Stine et al., 2020</xref> have argued that integration and non-integration models can capture the psychometric curves equally well. For both animals, the accuracy and psychometric curves were accurately captured by the integration model. In line with Stine et al., we also found that both non-integration models could reproduce the shape of the psychometric curve in monkey N, although the quantitative fit was always better for the integration than non-integration models. By contrast both non-integration models failed to capture the psychometric curve for monkey P (<xref ref-type="fig" rid="fig2">Figure 2B</xref>, bottom row). More systematically, the overall accuracy, which is an aggregate measure of the psychometric curve, clearly differed between models, as the accuracy of the non-integration models systematically deviated from animal data for both animals (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). In other words, all models produce the same type of psychometric curves up to a scaling factor, and this scaling factor (directly linked to the model accuracy) is key to differentiate model fits. For the snapshot model in monkey P, this discrepancy was explained because the model, limited to using one stimulus sample, could not reach the performance of the animal (compare the maximum accuracy of the model indicated by the blue mark with the accuracy of the animal). (This also explains why the psychophysical kernel of the snapshot model underestimated the true kernel in monkey P.) For the extrema-detection model in monkey P and for both non-integration models in the other animal (monkey N), the model accuracy is not bounded below the subject’s accuracy. In such cases, the model can produce better-than-observed accuracy for certain parameter ranges, but these are not the parameters found by the maximum likelihood procedure, probably because they produce a pattern of errors that is inconsistent with the observed pattern of errors. This indicates an inability of the models to match the pattern of errors of the animal (see Discussion).</p><p>Finally, we assessed quantitatively which model provided the best fit, while correcting for model complexity using the Akaike information criterion (AIC, <xref ref-type="fig" rid="fig2">Figure 2A</xref>). In both monkeys, AIC favored the integration model over the two non-integration models by a very large margin. We also explored whether (previously unpublished) elaborations of the extrema-detection and snapshot models could provide a better match to the behavioral metrics considered above (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplements 2</xref> and <xref ref-type="fig" rid="fig2s3">3</xref>). We found using the AIC metric that the integration model was preferred over all variants of both non-integration models, for both monkeys. Moreover, these model variants could not replicate the psychophysical kernels as well as the integration model did (<xref ref-type="fig" rid="fig2s2">Figure 2—figure supplements 2</xref> and <xref ref-type="fig" rid="fig2s3">3</xref>).</p><p>In conclusion, while psychometric curves may not always discriminate between integration and non-integration strategies, other metrics including psychophysical kernels, predicted accuracy and quality of fit (AIC) support temporal integration in monkey perceptual decisions. For one model in one monkey (the snapshot model in monkey P), even the simple metric of overall accuracy compellingly supported temporal integration (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). For the other monkey and/or model, where the distinction was less clear, our model-based approach allowed us to leverage these other metrics to reveal strong support for the temporal integration model (<xref ref-type="fig" rid="fig2">Figure 2A–C</xref>). While these data rely only on two experimental subjects, we show below further evidence supporting the integration model in humans and rats.</p></sec><sec id="s2-3"><title>Temporal integration is more likely than the extrema-detection model: evidence from a unique subset of trials</title><p>While formal model comparison leads us to reject the non-integration models in favor of the integration models, it is informative to examine qualitative features of the animal strategies and identify how non-integration models failed to capture them. We started by designing two analyses aimed at testing whether choices were consistent with the extrema-detection model, namely by testing whether choices were strongly correlated with the largest evidence samples. In the first analysis, we looked at the subset of trials where the evidence provided by the largest evidence sample in the sequence was at odds with the total evidence in the sequence: we show one example in <xref ref-type="fig" rid="fig3">Figure 3B</xref>, where the largest evidence sample points toward response B, while the overall evidence points toward response A. These ‘<italic>disagree trials</italic>’ represent a substantial minority of the whole dataset: 1865 trials (2.6%) in monkey N and 1831 trials (5.5%) in monkey P. If integration is present, the response of the animal should in general be aligned with the total evidence from the sequence (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, red bars). By contrast, if it followed the extrema-detection model (<xref ref-type="fig" rid="fig1">Figure 1C</xref>), it should in general follow the largest evidence sample (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, green bars). In both monkeys, animal choices were more often than not aligned with the integrated evidence (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, black bars), as predicted by the integration model. The responses generated from the extrema-detection model tended to align more with the largest evidence sample, although that behavior was somehow erratic (for monkey N) due to the large estimated decision noise in the model. This rules out that monkey decisions rely on a memoryless strategy of simply detecting large evidence samples, discarding all information provided by lower evidence samples. Our results complement a previous analysis on disagree trials in this task (<xref ref-type="bibr" rid="bib26">Levi et al., 2018</xref>), by explicitly comparing monkey behavior to model predictions.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>The pattern of animal choices is incompatible with extrema-value-based decisions.</title><p>(<bold>A</bold>) Example of an ‘agree trial’ where the total stimulus evidence (accumulated over samples) and the evidence from the largest evidence sample point toward the same response (here, response A). In this case, we expect that temporal integration and extrema-detection will produce similar responses (here, A). (<bold>B</bold>) Example of a ‘disagree trial’, where the total stimulus evidence and evidence from the largest evidence sample point toward opposite responses (here A for the former; B for the latter). In this case, we expect that integration and extrema-detection models will produce opposite responses. (<bold>C</bold>) Proportion of choices out of all <italic>disagree trials</italic> aligned with total evidence, for animal (gray bars), integration (red), and extrema-detection model (green). Error bars denote 95% confidence intervals based on parametric bootstrap (see Methods).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84045-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Subjective weights for animal data and simulated models.</title><p>Impact on decision of individual samples as a function of absolute sample evidence. Shaded area: standard error of the weight. Top row: monkey P; bottom row: monkey N. (<bold>A</bold>) Integration model. (<bold>B</bold>) Extrema-detection model. The vertical dotted line marks the value of the threshold <italic>T</italic> estimated from animal data. (<bold>C</bold>) Impact on decision of individual pulses, estimated from each monkey.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84045-fig3-figsupp1-v2.tif"/></fig></fig-group><p>We reasoned that the extrema-detection would also leave a clear signature in the ‘subjective weight’ of the samples, defined as the impact of each sample on the decision as a function of absolute sample evidence (<xref ref-type="bibr" rid="bib50">Yang and Shadlen, 2007</xref>; <xref ref-type="bibr" rid="bib45">Waskom and Kiani, 2018</xref>; <xref ref-type="bibr" rid="bib31">Nienborg and Cumming, 2007</xref>). The extrema-detection model predicts that, in principle, samples whose evidence is below the threshold have little impact on the decision, while samples whose evidence is above the threshold have full impact on the decision. By contrast, the integration model predicts that subjective weight should grow linearly with sample evidence. We estimated subjective weights from monkey choices using a regression method similar in spirit to previous methods (<xref ref-type="bibr" rid="bib50">Yang and Shadlen, 2007</xref>; <xref ref-type="bibr" rid="bib45">Waskom and Kiani, 2018</xref>), taking the form <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1...</mml:mn><mml:mi>n</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, where σ is a sigmoidal function. Here <italic>f</italic> is a function that captures the subjective weight of the sample as a function of its associated evidence. Whereas previous methods estimated subjective weights assuming a uniform psychophysical kernel, our method estimated simultaneously subjective weights <inline-formula><mml:math id="inf29"><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> and the psychophysical kernel <inline-formula><mml:math id="inf30"><mml:mi>β</mml:mi></mml:math></inline-formula>, thus removing potential estimation biases due to unequal weighting of sample evidence (see Methods). In both monkeys, we indeed found that the subjective weight depends linearly on sample evidence for low to median values of sample evidence (motion pulse lower than 6), in agreement with the integration model (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Counter to our predictions, simulated data of the extrema-detection model displayed the same linear pattern for low to median values of sample evidence. We realized this was due to the very high estimated sensory noise (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>), such that, according to the model, even samples with minimal sample evidence were likely to reach the extrema-detection threshold. In other words, unlike the previous analyses, inferring the subjective weights used by animals was inconclusive as to whether animals deployed the extrema-detection strategy. This somewhat surprising dependency reinforces the importance of validating intuitions by fitting and simulating models (<xref ref-type="bibr" rid="bib46">Wilson and Collins, 2019</xref>).</p></sec><sec id="s2-4"><title>Impact of early and late stimulus evidence onto choice shows direct evidence for temporal integration</title><p>Following model comparisons favoring integration over both snapshot and extrema-detection models, the immediately previous analysis relied on a special subset of trials to provide an additional, and perhaps more intuitive, signature of integration, which ruled out extrema-detection as a possible strategy of either monkey. We next employed another novel analysis specifically designed to tease apart unique signatures of the integration and snapshot models. More specifically, we tested whether decisions were based on the information from only one part of the sequence, as predicted by the snapshot model, or from the full sequence, as predicted by the integration model. To facilitate the analysis, we defined <italic>early evidence E<sub>t</sub></italic> by grouping evidence from the first three samples in the sequence, and <italic>late evidence L<sub>t</sub></italic>, as the grouped evidence from the last four samples. We then displayed the proportion of rightward responses as a function of both early and late evidence in a graphical representation that we call <italic>integration map</italic> (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). A pure integration strategy corresponds to summing early and late evidence equally, which can be formalized as <inline-formula><mml:math id="inf31"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula>, where <inline-formula><mml:math id="inf32"><mml:mi>σ</mml:mi></mml:math></inline-formula> is a sigmoidal function. Because this only depends on the sum <inline-formula><mml:math id="inf33"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , the probability of response is invariant to changes in the <inline-formula><mml:math id="inf34"><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> space along the diagonals, which leave the sum unchanged. These diagonals correspond to isolines of the integration map (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, left; <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2A</xref>). In other words, straight diagonal isolines in the integration map reflect the fact that the decision only depends on the sum of evidence <inline-formula><mml:math id="inf35"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> . Straight isolines thus constitute a specific signature of evidence integration.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Integration of early and late evidence into animal responses is incompatible with the snapshot model.</title><p>(<bold>A</bold>) Integration map representing the probability of rightward responses (orange: high probability; blue: low probability) as a function of early stimulus evidence <inline-formula><mml:math id="inf36"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and late stimulus evidence <inline-formula><mml:math id="inf37"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , illustrated for a toy integration model (where <inline-formula><mml:math id="inf38"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula>; left panel) and a toy non-integration model (<inline-formula><mml:math id="inf39"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mn>0.5</mml:mn><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula>; middle panel), and computed for monkey N responses (right panel). Black lines represent the isolines for p(rightwards) = 0.15, 0.3, 0.5, 0.7, and 0.85. (<bold>B</bold>) Conditional psychometric curves representing the probability for rightward response as a function of early evidence <inline-formula><mml:math id="inf40"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , for different values of late evidence <inline-formula><mml:math id="inf41"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (see inset for <inline-formula><mml:math id="inf42"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> values), for toy models and monkey N. The curves correspond to horizontal cuts in the integration maps at <inline-formula><mml:math id="inf43"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> values marked by color triangles in panel A. (<bold>C</bold>) Illustration of the fits to conditional psychometric curves. The value of the bias <inline-formula><mml:math id="inf44"><mml:mi>β</mml:mi></mml:math></inline-formula>, left lapse <inline-formula><mml:math id="inf45"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and right lapse <inline-formula><mml:math id="inf46"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are estimated from the conditional psychometric curves for each value of late evidence. (<bold>D</bold>) Lateral bias as a function of late evidence for toy models and monkey N. Shaded areas represent standard error of weights for animal data. (<bold>E</bold>) Lapse parameters (blue: left lapse; orange: right lapse) as a function of late evidence for toy models and monkey N. (<bold>F</bold>) Pearson correlation between integration maps for animal data and integration maps for simulated data, for each animal. Red: integration model; blue: snapshot model; green: extrema-detection model.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84045-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Integration of early and late evidence for monkey P.</title><p>(<bold>A</bold>) Integration map. Legend as in <xref ref-type="fig" rid="fig4">Figure 4A</xref>. (<bold>B</bold>) Conditional psychometric curves. Legend as in <xref ref-type="fig" rid="fig4">Figure 4B</xref>. (<bold>C</bold>) Bias and lapse parameters from conditional psychometric curves, as a function of late evidence. Legend as in <xref ref-type="fig" rid="fig4">Figure 4D, E</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84045-fig4-figsupp1-v2.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Integration between early and late evidence for simulated data from integration and non-integration models.</title><p>Data were simulated for each model from parameters estimated from monkey N. Left panels: integration model. Middle panels: snapshot models. Right panels: extrema-detection models. (<bold>A</bold>) Integration maps. (<bold>B</bold>) Conditional psychometric curves. (<bold>C</bold>) Lateral bias and (<bold>D</bold>) lapse parameters estimated from conditional psychometric curves, as a function late evidence. Legend as in <xref ref-type="fig" rid="fig4">Figure 4</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84045-fig4-figsupp2-v2.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>Individual Lateral Intra Parietal (LIP) neurons integrate sensory information over stimulus sequence.</title><p>(<bold>A</bold>) Neural models for temporal integration, extrema-detection, and snapshot model. (<bold>B</bold>) Integration map for LIP neurons, and simulated neurons following either integration, extrema-detection, or snapshot model. Color represents the average normalized spike count per bins of neuron-weighted early and late evidence (see Methods). Isolines represent values of 0.4, 0.6, 1, 1.4, and 1.8.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84045-fig4-figsupp3-v2.tif"/></fig></fig-group><p>We contrasted this integration map with the one obtained from a non-integration strategy (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, middle panel; <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2B</xref>). There we assumed that the decision depends either on the early evidence or on the late evidence, as in the snapshot model, with equal probability. This can be formalized as <inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mn>0.5</mml:mn><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. In this case, if late evidence is null (<inline-formula><mml:math id="inf48"><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:math></inline-formula>) and early evidence is very strong toward the right (<inline-formula><mml:math id="inf49"><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>≃</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>) the overall probability for rightward response is <inline-formula><mml:math id="inf50"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.75</mml:mn></mml:math></inline-formula>. This probability contrasts with that obtained in the integration case where the early evidence would dominate and lead to an overwhelming proportion of rightward responses, that is <inline-formula><mml:math id="inf51"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo><mml:mo>≃</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>. The 25% of leftwards responses yielded by the non-integration model correspond to trials where only the late (uninformative) part of the stimulus is attended and a random response to the left is drawn. More generally, in regions of the space in which either early or late evidence take large absolute values, their corresponding probability of choice saturates to 0 or 1, when that evidence is attended, so the overall response probability becomes only sensitive to the other evidence. As a result, the equiprobable lines bend toward the horizontal and vertical axes (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, middle). Finally, to compare predictions from both integration and non-integration models to monkey behavior, we plotted the integration maps for both monkeys (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, right; <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1A</xref>). The isolines were almost straight diagonal lines and showed no consistent curvature toward the horizontal and vertical axes. This provides direct evidence that monkey responses predominantly depend on the sum of early and late evidence – a clear signature of temporal integration.</p><p>We derived subsequent tests based on the integration map. We computed conditional psychometric curves as the probability for rightward responses as a function of early evidence <inline-formula><mml:math id="inf52"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , conditioned on late evidence value <inline-formula><mml:math id="inf53"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4">Figure 4B</xref>; <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1B</xref>). From the integration formula <inline-formula><mml:math id="inf54"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula>, we see that a change in late evidence value corresponds to a horizontal shift of the conditional psychometric curves. By contrast, according to the non-integration formula <inline-formula><mml:math id="inf55"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mn>0.5</mml:mn><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula>, conditioning on different values of late evidence adds a fixed value to the response probability irrespective of early evidence, a vertical shift akin to that introduced by lapse responses (<xref ref-type="fig" rid="fig4">Figure 4B</xref>, middle panel). The conditional psychometric curves for monkeys (<xref ref-type="fig" rid="fig4">Figure 4B</xref>, right panel; <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> and <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>) displayed horizontal shifts as late evidence was changed, consistently with the integration hypothesis. We sought to quantify these shifts in better detail. To this purpose, we fitted each conditional psychometric curve with the formula <inline-formula><mml:math id="inf56"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mi> </mml:mi><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:mi>α</mml:mi><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , where <inline-formula><mml:math id="inf57"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , <inline-formula><mml:math id="inf58"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , <inline-formula><mml:math id="inf59"><mml:mi>α</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf60"><mml:mi>β</mml:mi></mml:math></inline-formula> correspond to the left lapse, right lapse, sensitivity, and lateral bias parameters, respectively (<xref ref-type="fig" rid="fig4">Figure 4C</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref> and <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). The integration model predicts that the bias parameter <inline-formula><mml:math id="inf61"><mml:mi>β</mml:mi></mml:math></inline-formula> should vary linearly with <italic>L<sub>t</sub></italic>, while lapse parameters should remain null (<xref ref-type="fig" rid="fig4">Figure 4D</xref>, left panel). By contrast, the non-integration model predicts that the horizontal shift parameter <inline-formula><mml:math id="inf62"><mml:mi>β</mml:mi></mml:math></inline-formula> should remain constant while left and right lapse parameters <inline-formula><mml:math id="inf63"><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> should vary (middle panel), as these lapse parameters correspond to the trials where early evidence is not attended and the response depends simply on late evidence. Both monkeys showed a very strong linear dependence between late evidence and the horizontal shift <inline-formula><mml:math id="inf64"><mml:mi>β</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4">Figure 4D</xref>, right panel; see also <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>), further supporting that late evidence is summed to early evidence. By contrast, the lapse parameters showed no consistent relationship with late evidence <inline-formula><mml:math id="inf65"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4">Figure 4E</xref>, right panel). Finally, we directly assessed the similarities between the integration maps from monkey responses and from simulated responses for the three models (integration, snapshot, and extrema-detection). The model-data correlation was larger in the integration model than in the non-integration strategies for both monkeys (<xref ref-type="fig" rid="fig4">Figure 4E</xref>; unpaired <italic>t</italic>-test on bootstrapped <italic>r</italic> values: p <italic>&lt;</italic> 0.001 for each animal and comparison against extrema-detection and against snapshot model). Overall, integration maps allow to dissect how early and late parts of the stimulus sequence are combined to produce a behavioral response. In both monkeys, these maps carried signatures of temporal integration. For monkey N, the integration model and the data look very similar (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). For monkey P, there is still a qualitative dependency that deviates from non-integration, but which is not as uniquely matched to the integration strategy (although the imperfect coverage of the two-dimensional space impedes further investigations; <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>). Thus, complementing the statistical model tests favoring integration, this richer visualization allows the data to show us that some degree of integration is occurring, albeit not perfect.</p></sec><sec id="s2-5"><title>Visual orientation discrimination in humans relies on temporal integration</title><p>Overall, all our analyses converged to support the idea that monkey decisions in a fixed-duration motion discrimination task relied on temporal integration. We explored whether the same results would hold for two other species and perceptual paradigms. We first analyzed the behavioral responses from nine human subjects performing a variable-duration orientation discrimination task (<xref ref-type="bibr" rid="bib7">Cheadle et al., 2014</xref>). In each trial, a sequence of 5–10 gratings with a certain orientation were shown to the subject, and the subject had to report whether they thought the gratings were overall mostly aligned to the left or to the right diagonal. In this task, the experimenter can control the evidence provided by each sample by adjusting the orientation of the grating. We performed the same analyses on the participant responses as on monkey data. As for monkeys, we found that the integration model nicely captured psychometric curves, participant accuracy and psychophysical kernels (<xref ref-type="fig" rid="fig5">Figure 5A–C</xref>, red curves and symbols). By contrast, both non-integration models failed to capture these patterns (<xref ref-type="fig" rid="fig5">Figure 5A–C</xref>, blue and green curves and symbols). The accuracy from both models consistently underestimated participant performance: eight and six out of nine subjects outperformed the maximum performance for the snapshot and extrema-detection models, respectively (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>). This suggests that human participants achieved such accuracy by integrating sensory evidence over successive samples. Moreover, subjects overall weighted more later samples (<xref ref-type="fig" rid="fig5">Figure 5C</xref>), which is inconsistent with the extrema-detection mechanism. A formal model comparison confirmed that in each participant, the integration model provided a far better account of subject responses than either of the non-integration models did (<xref ref-type="fig" rid="fig5">Figure 5D</xref>). We then assessed how subjects combined information from weak and strong evidence samples into their decisions, using the same analyses as for monkeys. As predicted by the integration model, but not by the extrema-detection model, human choices consistently aligned with the total stimulus evidence and not simply with the strongest evidence sample (<xref ref-type="fig" rid="fig5">Figure 5E</xref>). Finally, the average integration map for early and late evidence within the stimulus sequence displayed nearly linear diagonal isolines, showing that both were integrated into the response (<xref ref-type="fig" rid="fig5">Figure 5F</xref>). Integration maps from participants correlated better with maps predicted by the integration model than with maps predicted by either of the alternative non-integration strategies (<xref ref-type="fig" rid="fig5">Figure 5G</xref>; two-tailed <italic>t</italic>-test on bootstrapped <italic>r</italic> values: p &lt; 0.001 for six out of nine participants in the integration vs. snapshot comparison; in all nine participants for the integration vs. extrema-detection comparison). Overall, these analyses provide converging evidence that human decisions in an orientation discrimination task rely on temporal integration.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Behavioral data from orientation discrimination task in humans provide further evidence for temporal integration.</title><p>(<bold>A</bold>) Psychometric curves for human and simulated data, averaged across participants (<italic>n</italic> = 9). Legend as in <xref ref-type="fig" rid="fig2">Figure 2C</xref>. (<bold>B</bold>) Simulated model accuracy (<italic>y</italic>-axis) vs. participant accuracy (<italic>x</italic>-axis) for integration model (red), snapshot model (blue) and extrema-detection model (green). Each symbol corresponds to a participant. (<bold>C</bold>) Psychophysical kernel for human and simulated data, averaged across participants. Legend as in A. (<bold>D</bold>) Difference in Akaike information criterion (AIC) between each model and the integration model. Legend as in B. (<bold>E</bold>) Proportion of choices aligned with total stimulus evidence in disagree trials, for participant data (gray bars) and simulated models, averaged over participants. (<bold>F</bold>) Integration map for early and late stimulus evidence, computed as in <xref ref-type="fig" rid="fig4">Figure 4A</xref>, averaged across participants. (<bold>G</bold>) Correlation between integration map of participants and simulated data for integration, snapshot, and extrema-detection models, averaged across participants. Color code as in B. Error bars represent the standard error of the mean across participants in all panels.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84045-fig5-v2.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Maximum accuracy of the non-integration models vs. human subject accuracy in the orientation discrimination task.</title><p>Left panel: snapshot model (with span <italic>K</italic> = 1). Right panel: extrema-detection. Each symbol represents a subject.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84045-fig5-figsupp1-v2.tif"/></fig></fig-group></sec><sec id="s2-6"><title>Auditory intensity discrimination in rats relies on temporal integration</title><p>Finally, we analyzed data from five rats performing a fixed-duration auditory task where the animals had to discriminate the side with larger acoustic intensity (<xref ref-type="bibr" rid="bib35">Pardo-Vazquez et al., 2019</xref>). The relative intensity of the left and right acoustic signals was modulated in sensory samples of 50ms, so that the stimulus sequence provided time-varying evidence for the rewarded port. The stimulus sequence was composed of either 10 or 20 acoustic samples of 50 ms each, for a total duration of 500 or 1000 ms. We applied the same analysis pipeline as for monkey and human data. The integration model provided a much better account of rat choices than non-integration strategies, based on psychometric curves (<xref ref-type="fig" rid="fig6">Figure 6A</xref>), predicted accuracy (<xref ref-type="fig" rid="fig6">Figure 6B</xref>), psychophysical kernel (<xref ref-type="fig" rid="fig6">Figure 6C</xref>), and model comparison using AIC (<xref ref-type="fig" rid="fig6">Figure 6D</xref>). Similar to humans and monkeys, rats tended to select the side corresponding to the total stimulus evidence and not the largest sample evidence in ‘disagree’ trials, as predicted by the integration model (<xref ref-type="fig" rid="fig6">Figure 6E</xref>). Finally, the integration map was largely consistent with an integration strategy (<xref ref-type="fig" rid="fig6">Figure 6F</xref>), and correlated more strongly with simulated maps from the integration model (unpaired <italic>t</italic>-test on bootstrapped <italic>r</italic> values: p <italic>&lt;</italic> 0.001 for each animal and comparison against extrema-detection and against snapshot model).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Behavioral data from auditory discrimination task in five rats provide further evidence for temporal integration.</title><p>(<bold>A-G</bold>) Legend as in <xref ref-type="fig" rid="fig5">Figure 5</xref>. Rats were rewarded for correctly identifying the auditory sequence of larger intensity (number of samples: 10 or 20; stimulus duration: 500 or 1000 ms). Legend as in <xref ref-type="fig" rid="fig5">Figure 5</xref>. Psychophysical kernels are computed only for 10-sample stimuli (in 4 animals). See <xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref> for psychophysical kernels with 20-sample stimuli.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84045-fig6-v2.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Psychophysical kernels for animals and models in rats (<italic>n</italic> = 3) performing the discrete-sample stimulus (DSS) task with 20-sample stimuli.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84045-fig6-figsupp1-v2.tif"/></fig></fig-group></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>We investigated the presence of temporal integration in perceptual decisions in monkeys, humans, and rats through a series of standard and innovative analyses of response patterns. In all analyses, we contrasted predictions from one integration and two non-integration computational models of behavioral responses (<xref ref-type="fig" rid="fig1">Figure 1</xref>). For each non-integration model, we considered multiple variants to explore the maximal flexibility offered by each framework to capture animal behavior. For our datasets, evidence in favor of integration was easy to achieve using standard model comparison techniques as well as comparing simulated psychometric curves and psychophysical kernels to their experimental counterparts (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Our results are in line with previous evidence for temporal integration in perceptual decisions of humans and mice (<xref ref-type="bibr" rid="bib36">Pinto et al., 2018</xref>; <xref ref-type="bibr" rid="bib41">Stine et al., 2020</xref>; <xref ref-type="bibr" rid="bib45">Waskom and Kiani, 2018</xref>). Importantly, we also put forth new analyses targeted at revealing specific signatures of temporal integration.</p><p>In some cases, we could link the failure of the non-integration model to a fundamental limitation of the model. For example, the extrema-detection model cannot explain the non-monotonic psychophysical kernels of monkeys or the increasing psychophysical kernels in humans. This is because the decision in that mode is based on the first sample to reach a certain fixed criterion, so it will always produce a primacy effect, that is, a decreasing psychophysical kernel. Although this effect can be small, and in practice yields approximately flat kernels (<xref ref-type="bibr" rid="bib41">Stine et al., 2020</xref>), it cannot produce increasing or non-monotonic kernels.</p><p>Another strong limitation of non-integration models (both the extrema-detection and the snapshot model) is that accuracy is limited by the fact that decisions depend on a single sample. We found that that boundary performance (i.e., the maximum performance that a model can reach) was actually lower than subject accuracy for most human participants, de facto ruling out these non-integration strategies for these participants. This is consistent to what was observed in a contrast discrimination DSS task where human subjects had to make judgments about image sequences spanning up to tens of seconds each (<xref ref-type="bibr" rid="bib45">Waskom and Kiani, 2018</xref>). It clearly contrasts however with results from <xref ref-type="bibr" rid="bib41">Stine et al., 2020</xref> where the non-integration strategies matched the accuracy of human subjects performing the classical random-dot-motion task. This discrepancy may be related to the different sources of noise in the two paradigms. In DSS tasks, because the sensory evidence provided by the stimulus at each moment is controlled by the experimenter, the unpredictability of human responses essentially stems from internal noise at the level of sensory processing and temporal integration (<xref ref-type="bibr" rid="bib45">Waskom and Kiani, 2018</xref>; <xref ref-type="bibr" rid="bib11">Drugowitsch et al., 2016</xref>). By contrast, the random dot motion task (<xref ref-type="bibr" rid="bib23">Kiani et al., 2008</xref>), which is a non-DSS task because the experimenter does not typically specify differing amounts of motion in each time epoch within a single trial, typically elicits more variable responses due to the presence of stimulus noise. This overall increased noise level leads to a looser relationship between the stimulus condition and the behavioral responses, which can thus be accounted for by a larger spectrum of computational mechanisms. These issues have been addressed by forcing ‘pulses’ of a certain stimulus strength and/or by performing post hoc analyses to estimate signal and noise (<xref ref-type="bibr" rid="bib23">Kiani et al., 2008</xref>; <xref ref-type="bibr" rid="bib17">Huk and Shadlen, 2005</xref>) but these are partial solutions that DSS paradigms solve by design. This illustrates the benefits of using experimental designs where variability in stimulus information can be fully controlled and parametrized by the experimenter, as these paradigms discriminate more precisely between different models of perceptual decisions (see <xref ref-type="bibr" rid="bib8">Cisek et al., 2009</xref>).</p><p>In at least one monkey, although quantitative metrics such as penalized log-likelihood and fits to psychometric curves clearly pointed to the integration model as the best account to behavior, the qualitative failure modes of the non-integration strategies (especially the snapshot model) was not immediately clear. Although we tried variants for each non-integration model, there remained a possibility that our precise implementation failed to account for monkey behavior but that other possible implementations would. Note that the extrema-detection and snapshot are two of the many possible non-integration strategies. A generic form for non-integration strategies corresponds to a policy that implements position-dependent thresholds on the instantaneous sensory evidence. In this framework, the extrema-dependent model corresponds to the case with a position-independent threshold, while the snapshot model corresponds to a null bound for one sample and infinite bounds for all other samples. To rule out these more complex strategies, we conducted additional analyses that specifically targeted core assumptions of the integration and non-integration strategies.</p><p>First, the extrema-detection model fails to account for the data because it predicts that largest evidence samples should have a disproportionate impact on choices. However, this does not occur, as monkeys and humans tend to respond according to the total evidence and not the single large-evidence sample (<xref ref-type="fig" rid="fig3">Figures 3C</xref> and <xref ref-type="fig" rid="fig5">5E</xref>) – and see <xref ref-type="bibr" rid="bib26">Levi et al., 2018</xref> for a similar analysis. All non-integration strategies share the property that on each trial the decision should only rely either on the early or the late part of the trial. We thus directly examined the assumptions of integration and non-integration models by assessing how the evidence from the early and late parts of each stimulus sequence is combined to produce a decision. We introduced <italic>integration maps</italic> (<xref ref-type="fig" rid="fig4">Figure 4</xref>) to inspect such integration: isolines of the integration maps will be rectilinear if and only if early and late evidence are summed, in other words if and only if temporal integration takes place. Unequal weighting of evidence would still produce rectilinear isolines, albeit with a different angle. By contrast, a non-integration scenario when on each trial only a single piece of evidence contributes to the decision predicts isolines that bend toward the axes. Integration maps from monkey, human, and rat subjects nicely matched the predictions of the integration models, proving that their decisions do rely on temporal integration. Note that this innovative analysis technique could be used to probe integration of evidence not only at temporal level but also between different sources of evidence. Indeed, there has been an intense debate about whether sensory information from different spatial locations or different modalities are integrated prior to reaching a decision, or whether decisions are taken separately for each source before being merged, which can be viewed as extensions to the snapshot model (<xref ref-type="bibr" rid="bib34">Pannunzi et al., 2015</xref>; <xref ref-type="bibr" rid="bib33">Otto and Mamassian, 2012</xref>; <xref ref-type="bibr" rid="bib28">Lorteije et al., 2015</xref>; <xref ref-type="bibr" rid="bib18">Hyafil and Moreno-Bote, 2017</xref>). Our integration analysis could provide new answers to this old debate.</p><p>Integration maps can be computed not only for choice patterns but for any type of behavioral or neural marker of cognition. We computed a neural integration map (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>) by looking at the average spike activity of Lateral Intra Parietal (LIP) neurons as a function of early and late evidence, for neurons recorded while the monkeys performed the motion discrimination experiment (<xref ref-type="bibr" rid="bib51">Yates et al., 2017</xref>). The neural integration map clearly showed rectilinear isolines, as predicted by an integration model of neural spiking. By contrast, neural implementations of the snapshot and extrema-detection predicted strongly curved isolines. The activity of LIP neurons correlates with the evidence accumulated over the presentation of the stimulus in favor of either possible choices (<xref ref-type="bibr" rid="bib14">Gold and Shadlen, 2007</xref>). This result shows that the activity of individual LIP neurons indeed reflects the temporal integration of sensory information that drives animal behavior.</p><p>We have focused in this study on paradigms where the stimulus duration is fixed by the experimenter, and subjects could only respond after stimulus extinction. Stine et al. proposed a method for distinguishing integration from non-integration strategies but the method is based on two experimental conditions: experiments where stimulus duration is controlled by the experimenter and experiments where the stimulus is controlled by the subject (i.e., plays until the subject responds, ‘reaction time paradigms’). Our study puts forth a method to differentiate integration from non-integration strategies that is based on only one experimental condition (i.e., the variable-duration paradigm), and may therefore be applied to existing datasets.</p><p>Other studies have shown how integration and non-integration strategies can be disentangled in free reaction time task paradigms. Specifically, different models make different predictions regarding how the total sample evidence presented before response time should vary with response time (<xref ref-type="bibr" rid="bib13">Glickman and Usher, 2019</xref>; <xref ref-type="bibr" rid="bib54">Zuo and Diamond, 2019</xref>). Glickman and Usher used these predictions to rule out non-integration strategies in a counting task in humans, and <xref ref-type="bibr" rid="bib54">Zuo and Diamond, 2019</xref> found evidence for evidence integration to bound when rats discriminate textures using whisker touches. Under strong urgency constraints, it has been proposed that decisions depend on very limited temporal integration of the stimulus by low-pass filtering of stimulus evidence (<xref ref-type="bibr" rid="bib8">Cisek et al., 2009</xref>; <xref ref-type="bibr" rid="bib42">Thura et al., 2012</xref>). However, this suggestion cannot explain the fact that evidence presented early in the trial influences decisions taken later on <xref ref-type="bibr" rid="bib48">Winkel et al., 2014</xref>; <xref ref-type="bibr" rid="bib42">Thura et al., 2012</xref>. Of note, the absence of integration seems a more viable strategy when the duration of the stimulus is controlled externally and the benefits of integrating in terms of accuracy might not compensate for its cognitive cost. In free reaction time paradigms, waiting for a long sequence of samples and selecting its response based on a single sample does not seem a particularly efficient strategy. If the cognitive cost of integration is high, it is more beneficial to interrupt the stimulus sequence early with a rapid response. Indeed, fast or very fast (under 250 ms) perceptual decisions are very common (<xref ref-type="bibr" rid="bib43">Uchida et al., 2006</xref>; <xref ref-type="bibr" rid="bib52">Zariwala et al., 2013</xref>; <xref ref-type="bibr" rid="bib40">Stanford and Salinas, 2021</xref>; <xref ref-type="bibr" rid="bib35">Pardo-Vazquez et al., 2019</xref>; <xref ref-type="bibr" rid="bib15">Hermoso-Mendizabal et al., 2020</xref>). Such rapid termination of the decision process have been attributed either to urgency signals modulating the integration of stimulus evidence (<xref ref-type="bibr" rid="bib10">Drugowitsch et al., 2012</xref>; <xref ref-type="bibr" rid="bib40">Stanford and Salinas, 2021</xref>) or to action initiation mechanisms that time the response after a specific time (e.g., one or two samples) following stimulus onset (<xref ref-type="bibr" rid="bib16">Hernández-Navarro et al., 2021</xref>). Here, we have shown that even in paradigms where the stimulus duration is controlled by the experimenter, mammals often integrate sensory evidence over the entire stimulus.</p><p>In conclusion, we have found strong evidence for temporal integration in perceptual tasks across species (monkeys, humans, and rats) and perceptual domain (visual motion, visual orientation, and auditory discrimination). Although the timescale of integration can be adapted to the statistics of the environment (<xref ref-type="bibr" rid="bib32">Ossmy et al., 2013</xref>; <xref ref-type="bibr" rid="bib12">Glaze et al., 2015</xref>; <xref ref-type="bibr" rid="bib25">Kilpatrick et al., 2019</xref>), the principle that stimulus evidence is integrated over time appears to be a hallmark of perception. This evidence was gathered by leveraging experimentally controlled sensory evidence at each sensory sample composing a stimulus, and novel model-based statistical analysis. We speculate that temporal integration is a ubiquitous feature of perceptual decisions due to hard-wired neural integrating circuits, such as recurrent stabilizing connectivity in sensory and perceptual areas (<xref ref-type="bibr" rid="bib44">Wang, 2008</xref>; <xref ref-type="bibr" rid="bib47">Wimmer et al., 2015</xref>).</p></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Monkey experiment</title><p>We present here the most relevant features of the behavioral protocol – see <xref ref-type="bibr" rid="bib51">Yates et al., 2017</xref> for further experimental details. Two adult rhesus monkeys performed a motion discrimination task. On each trial, a stimulus consisting of a hexagonal grid (5–7 degrees, scaled by eccentricity) of Gabor patches (0.9 cycle per degree; temporal frequency 5 Hz for Monkey P; 7 Hz for Monkey N) was presented. Monkeys were trained to report the net direction of motion in a field of drifting and flickering Gabor elements with an eye movement to one of two targets. Each trial motion stimulus consisted of seven consecutive motion pulses, each lasting 9 or 10 video samples (150 or 166 ms; pulse duration did not vary within a session), with no interruptions or gaps between the pulses. The strength and direction of each pulse <inline-formula><mml:math id="inf66"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for trial <italic>t</italic> and sample <italic>i</italic> were set by a draw from a Gaussian rounded to the nearest integer value. The difficulty of each trial was modulated by manipulating the mean and variance of the Gaussian distribution. Monkeys were rewarded based on the empirical stimulus and not on the stimulus distribution. We analyzed a total of 112 sessions for monkey N and 60 sessions for monkey P, with a total of 72,137 and 33,416 valid trials, respectively. These sessions correspond to sessions with electrophysiological recordings reported in <xref ref-type="bibr" rid="bib51">Yates et al., 2017</xref> and purely behavioral sessions.</p></sec><sec id="s4-2"><title>Human experiment</title><p>Nine adult subjects performed an orientation discrimination task whereby on each trial they reported in each trial whether a series of gratings were perceived to be mostly tilted clockwise or counterclockwise (<xref ref-type="bibr" rid="bib11">Drugowitsch et al., 2016</xref>). Each DSS consisted of 5–10 gratings. Each grating was a high-contrast Gabor patch (color: blue or purple; spatial frequency = 2 cycles per degree; SD of Gaussian envelope = 1 degree) presented within a circular aperture (4 degrees) against a uniform gray background. Each grating was presented during 100 ms, and the interval between gratings was fixed to 300 ms. The angles of the gratings were sampled from a von Mises distribution centered on the reference angle (<inline-formula><mml:math id="inf67"><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>45</mml:mn></mml:math></inline-formula> degrees for clockwise sequences, 135 degrees for anticlockwise sequences) and with a concentration coefficient <inline-formula><mml:math id="inf68"><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.3</mml:mn></mml:math></inline-formula>. The normative evidence provided by sample <italic>i</italic> in trial <italic>t</italic> in favor of the clockwise category corresponds to how well the grating orientation <inline-formula><mml:math id="inf69"><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi> </mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> aligns with the reference orientation, that is <inline-formula><mml:math id="inf70"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>κ</mml:mi><mml:mi> </mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mn>2</mml:mn><mml:mo>(</mml:mo><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>α</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:math></inline-formula> .</p><p>Each sequence was preceded by a rectangle flashed twice during 100 ms (the interval between the flashes and between the second flash and the first grating varied between 300 and 400 ms). The participants indicated their choice with a button press after the onset of a centrally occurring dot that succeeded the rectangle mask and were made with a button press with the right hand. Failure to provide a response within 1000 ms after central dot onset was classified as invalid trial. Auditory feedback was provided 250 ms after participant response (at latest 1100 ms after end of stimulus sequence). It consisted of an ascending tone (400/800 Hz; 83/167 ms) for correct responses; descending tone (400/400 Hz; 83/167 ms) for incorrect responses; a low tone (400 Hz; 250 ms) for invalid trials.</p><p>Trials were separated by a blank interstimulus interval of 1200–1600 ms (truncated exponential distribution of mean 1333 ms). Experiments consisted of 480 trials in 10 blocks of 48. It was preceded with two blocks of initiation with 36 trials each. In the first initiation block, there was only one grating in the sequence, and it was perfectly aligned with one of the reference angles. In the second initiation block, sequences of gratings were introduced, and the difficulty was gradually increased (the distribution concentration linearly decreased from <inline-formula><mml:math id="inf71"><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>1.2</mml:mn></mml:math></inline-formula> to <inline-formula><mml:math id="inf72"><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.3</mml:mn></mml:math></inline-formula>). Invalid trials (mean 6.9 per participant, std 9.4) were excluded from all regression analyses. The study was approved by the local ethics committee (approval 2013/5435/I from CEIm-Parc de Salut MAR).</p></sec><sec id="s4-3"><title>Rat experiment</title><p>Rat experiments were approved by the local ethics committee of the University of Barcelona (Comité d’Experimentació Animal, Barcelona, Spain, protocol number Ref 390/14). Five male Long-Evans rats (350–650 g), pair-housed and kept on stable conditions of temperature (23°C) and humidity (60%) with a constant light–dark cycle (12:12 hr, experiments were conducted during the light phase). Rats had free access to food, but water was restricted to behavioral sessions. Free water during a limited period was provided on days with no experimental sessions.</p><p>Rats performed a fixed-duration auditory discrimination task where they had to classify noisy stimuli based on the intensity difference between the two lateral speakers (<xref ref-type="bibr" rid="bib35">Pardo-Vazquez et al., 2019</xref>; <xref ref-type="bibr" rid="bib15">Hermoso-Mendizabal et al., 2020</xref>). An LED on the center port indicated that the rat could start the trial by poking in that center port. After this poke, rats had to hold their snouts in the central port during 300 ms (i.e., fixation). Following this period, an acoustic DSS was played. Rats had to remain in the central port during the entire presentation of the stimulus. At stimulus offset, the center LED went off and rats could then come out of the center port and head toward one of the two lateral ports. Entering the lateral port associated with the speaker that generated the larger sound intensity led to a reward of 24 µl of water (correct responses), while entering the opposite port lead to a 5-s timeout accompanied with a bright light during the entire period (incorrect responses). If rats broke fixation during the pre-stimulus fixation period or during the stimulus presentation, the sound was interrupted, the center LED remained on, and the rat had to initiate a new trial starting by center fixation followed by a new stimulus. Fixation breaks were not included in any of the analyses. Stimulus duration was 0.5 s (10 samples) or 1 s (20 samples). Two rats performed 0.5-s stimuli only (77,810 and 54,803 valid trials, respectively); one rat performed 1-s stimuli only (42,474 valid trials); the remaining two rats performed a mixture of 0.5 and 1 s stimuli trials randomly interleaved (5016 trials and 65,212 valid trials, respectively, for one animal; 7374 and 38,829 trials for the other animal). In each trial <italic>k</italic> one stimulus <inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>K</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> was played in each speaker (<italic>X</italic> = R for the Right speaker and <italic>X</italic> = L for the Left speaker). Each stimulus was an amplitude-modulated (AM) broadband noise defined by <inline-formula><mml:math id="inf74"><mml:msubsup><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>φ</mml:mi><mml:mo>)</mml:mo><mml:mo>]</mml:mo><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mi> </mml:mi><mml:msub><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> where <italic>f</italic><sub><italic>AM</italic></sub> = 20 Hz (sensory samples lasted 50 ms), the phase delay <inline-formula><mml:math id="inf75"><mml:mi>φ</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn><mml:mi>π</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:math></inline-formula> and <inline-formula><mml:math id="inf76"><mml:msub><mml:mrow><mml:mi>ξ</mml:mi></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> were broadband noise bursts. The amplitudes of each sound in each frame were <inline-formula><mml:math id="inf77"><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:math></inline-formula> and <inline-formula><mml:math id="inf78"><mml:msubsup><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msubsup><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:math></inline-formula> with <italic>S</italic><sub><italic>k</italic>,<italic>f</italic></sub>(<italic>t</italic>) being the instantaneous evidence that was drawn independently in each frame <italic>f</italic> from a transformed Beta distribution with support [−1,1]. With this parametrization of the two sounds the sum of the two envelopes was constant in all frames <italic>a<sup>L</sup><sub>k</sub></italic>(<italic>t</italic>) + <italic>a<sup>R</sup><sub>k</sub></italic>(<italic>t</italic>) = 1. There were 7 × 5 stimulus conditions, each defined by a Beta distribution, spanning 7 mean values (−1, −0.5, −0.15, 0, 0.15, 0.5, and 1) and 5 different standard deviations (0, 0.11, 0.25, 0.57, and 0.8). In around the first half of the sessions, only sample sequences in which the total stimulus evidence matched the targeted nominal evidence were used. This effectively introduced weak correlations between samples. In the second half of the sessions, this condition was removed and samples in each stimulus were drawn independently from the corresponding Beta distribution.</p></sec><sec id="s4-4"><title>Integration model</title><p>The integration model for human participants corresponds to a logistic regression model, where the probability of selecting the right choice <inline-formula><mml:math id="inf79"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> at trial <italic>t</italic> depends on the weighted sum of the sample evidence: <inline-formula><mml:math id="inf80"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1...</mml:mn><mml:mi>n</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf81"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> is a lateral bias, <inline-formula><mml:math id="inf82"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the signed sample evidence at sample <italic>i</italic>; <inline-formula><mml:math id="inf83"><mml:msub><mml:mrow><mml:mi> </mml:mi><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the sensory weight associated with the <italic>i</italic>th sample in the stimulus sequence; and <inline-formula><mml:math id="inf84"><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> is the logistic function. The vector <inline-formula><mml:math id="inf85"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> ’s allowed to capture different shapes of psychophysical kernels (e.g., primacy effects, recency effects) which can emerge due to a variety of suboptimalities in the integration process (leak, attractor dynamics, sticky bounds, sensory after-effects, etc.) (<xref ref-type="bibr" rid="bib6">Brunton et al., 2013</xref>; <xref ref-type="bibr" rid="bib51">Yates et al., 2017</xref>; <xref ref-type="bibr" rid="bib37">Prat-Ortega et al., 2021</xref>; <xref ref-type="bibr" rid="bib5">Bronfman et al., 2016</xref>; <xref ref-type="bibr" rid="bib21">Keung et al., 2019</xref>; <xref ref-type="bibr" rid="bib22">Keung et al., 2020</xref>). Technically, our statistical approach corresponds to the first-order expansion of the Volterra series used to approximate any integration model (<xref ref-type="bibr" rid="bib30">Neri, 2004</xref>) by a simple and fittable logistic model. In other words, because a more complete description of integration models would be computationally challenging to fit and prone to overfitting, we chose a statistical approximation in the form of the logistic model that captures the essence of any generative model that include temporal integration, that is weighted summation of stimulus evidence.</p><p>For the monkey and rat data, we included a session-dependent modulation gain <inline-formula><mml:math id="inf86"><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> to capture the large variations in performance in monkeys across the course of sessions (see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A</xref>):<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1...</mml:mn><mml:mi>n</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>This model corresponds to a bilinear logistic regression model which pertains to the larger family of Generalized Unrestricted Models (GUMs) (<xref ref-type="bibr" rid="bib1">Adam and Hyafil, 2020</xref>). Parameters (<inline-formula><mml:math id="inf87"><mml:mi>β</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi></mml:math></inline-formula>) were fitted using the Laplace approximation as described in <xref ref-type="bibr" rid="bib1">Adam and Hyafil, 2020</xref>. The modulation gain was omitted when applied to human data, yielding a classical logistic regression model.</p></sec><sec id="s4-5"><title>Snapshot model</title><p>In the snapshot model, decisions are based on each trial based upon a single sample. The model also includes the possibility for left and right lapses. In each trial, the attended sample is drawn from a multinomial distribution of parameters (<inline-formula><mml:math id="inf88"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>), where the first terms <inline-formula><mml:math id="inf89"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi> </mml:mi><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> correspond to the probability of attending sample <italic>i,</italic> and <inline-formula><mml:math id="inf90"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf91"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> correspond to the probability of left and right lapses, respectively. Upon selecting sample <italic>i</italic>, the probability for selecting the right choice is given by the function <inline-formula><mml:math id="inf92"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula>. In the deterministic version of the model, <inline-formula><mml:math id="inf93"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is simply determined by the sign of the <italic>i</italic>th sample evidence: <inline-formula><mml:math id="inf94"><mml:msub><mml:mrow><mml:mi> </mml:mi><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> if <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf96"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula> if <inline-formula><mml:math id="inf97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf98"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:math></inline-formula> if <inline-formula><mml:math id="inf99"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula> (i.e., random guess if the sample has null evidence). We also define similar functions for lapse responses: <inline-formula><mml:math id="inf100"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> and <inline-formula><mml:math id="inf101"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>S</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula>, irrespective of the stimulus. In the non-deterministic version of the model, the probability <inline-formula><mml:math id="inf102"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> is determined by a logistic function of the attended sample evidence <inline-formula><mml:math id="inf103"><mml:msub><mml:mrow><mml:mi>H</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> where <inline-formula><mml:math id="inf104"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> describes a sensitivity parameter. The deterministic case can be viewed as the limit of the non-deterministic case when all sensitivity parameters <inline-formula><mml:math id="inf105"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> diverge to <inline-formula><mml:math id="inf106"><mml:mo>+</mml:mo><mml:mi>∞</mml:mi></mml:math></inline-formula>, that is when sensory and decision noise are negligible.</p><p>The overall probability for selecting right choice (marginalizing over the attended sample, which is a hidden variable) can be captured by a mixture model:<disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1...</mml:mn><mml:mi>n</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1...</mml:mn><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>The mixture coefficients <inline-formula><mml:math id="inf107"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> are constrained to be non-negative and sum up to 1. In the non-deterministic model, the parameters also include sensitivity parameters <inline-formula><mml:math id="inf108"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> .The model is fitted using Expectation-Maximization (<xref ref-type="bibr" rid="bib2">Bishop, 2006</xref>). In the Expectation step, we compute the responsibility <inline-formula><mml:math id="inf109"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , that is the posterior probability that the sample <italic>i</italic> was attended at trial <italic>t</italic> (for <italic>i = L</italic>, <italic>R</italic>, the probability that the trial corresponded to a lapse trial):<disp-formula id="equ3"> <mml:math id="m3"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">h</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">R</mml:mi><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ4"> <mml:math id="m4"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">R</mml:mi><mml:mrow><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>In the Maximization step, we update the value of the parameters by maximizing the Expected Complete Log-Likelihood (ECLL): <inline-formula><mml:math id="inf110"><mml:mi>Q</mml:mi><mml:mo>(</mml:mo><mml:mi>π</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi> </mml:mi><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>;</mml:mo><mml:mi>π</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula>. Maximizing over the mixture coefficients with the unity-sum constraint provides the classical update: <inline-formula><mml:math id="inf111"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:mi>N</mml:mi></mml:math></inline-formula>, where <italic>N</italic> is the total number of trials. In the non-deterministic model, maximizing the ECLL over sensitivity parameters is equivalent to fitting a logistic regression model with weighted coefficients <inline-formula><mml:math id="inf112"><mml:msub><mml:mrow><mml:mi>z</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, which is a convex problem. Best fitting parameters can be found using Newton–Raphson updates on the parameters:<disp-formula id="equ5"> <mml:math id="m5"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>Q</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msubsup><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">h</mml:mi></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>Q</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">d</mml:mi></mml:mrow><mml:mspace width="thinmathspace"/><mml:mspace width="thinmathspace"/><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>Q</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msubsup><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>z</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>To speed up the computations, in each M step, we only performed one Newton–Raphson update for each sensitivity parameter, rather than iterating the updates fully until convergence. The EM procedure was run until convergence, assessed by an increment in the log-likelihood <inline-formula><mml:math id="inf113"><mml:mi>L</mml:mi><mml:mo>(</mml:mo><mml:mi>π</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula> of less than 10<sup>−9</sup> after one EM iteration. The log-likelihood for a given set of parameters is given by <inline-formula><mml:math id="inf114"><mml:mi>L</mml:mi><mml:mo>(</mml:mo><mml:mi>π</mml:mi><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi> </mml:mi><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula>. The EM iterative procedure was repeated with 10 different initializations of the parameters to avoid local minima.</p><p>Note that for monkey and rat data, since we observed large variations in performance across sessions, the model based its choices on session-gain-modulated evidence <inline-formula><mml:math id="inf115"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="normal">S</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> instead of raw evidence <inline-formula><mml:math id="inf116"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (this had no impact for the deterministic variant since <inline-formula><mml:math id="inf117"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="normal">S</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf118"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> always have the same sign). We fitted the model from individual subject responses either with lapses <inline-formula><mml:math id="inf119"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf120"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> as free parameters, or fixed to <inline-formula><mml:math id="inf121"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:math></inline-formula>. Figures in the main manuscript correspond to the deterministic snapshot model with fixed lapses. We also studied variants of the snapshot model where decisions in each trial are based on <italic>K</italic> attended samples, that is depends on <inline-formula><mml:math id="inf122"><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> with <inline-formula><mml:math id="inf123"><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>K</mml:mi><mml:mo>≤</mml:mo><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> and <inline-formula><mml:math id="inf124"><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>n</mml:mi><mml:mo>-</mml:mo><mml:mi>K</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> is the first attended sample. In the deterministic case, the choice is directly determined by the sign of the sum of the signed evidence for the attended samples. In the non-deterministic case, the evidence for the attended samples are weighted and passed through a sigmoid: <inline-formula><mml:math id="inf125"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1...</mml:mn><mml:mi>K</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. The model with a single attended sample presented above is equivalent to this extended model when using <inline-formula><mml:math id="inf126"><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula>. At the other end, using <inline-formula><mml:math id="inf127"><mml:mi>K</mml:mi><mml:mo>=</mml:mo><mml:mi>n</mml:mi></mml:math></inline-formula> corresponds to the temporal integration model (without the lateral bias).</p></sec><sec id="s4-6"><title>Extrema-detection model</title><p>In the extrema-detection model, a choice is selected according to the first sample in the sequence whose absolute evidence value reaches a certain threshold <inline-formula><mml:math id="inf128"><mml:mi>θ</mml:mi></mml:math></inline-formula>, that is <inline-formula><mml:math id="inf129"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>≥</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> for all <inline-formula><mml:math id="inf130"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>j</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> . Here, <inline-formula><mml:math id="inf131"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the sample evidence corrupted by sensory noise <inline-formula><mml:math id="inf132"><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> which is distributed normally with variance <inline-formula><mml:math id="inf133"><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> : <inline-formula><mml:math id="inf134"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> with <inline-formula><mml:math id="inf135"><mml:msub><mml:mrow><mml:mi>ε</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mrow><mml:mi>σ</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:math></inline-formula>. <italic>H</italic> is the step function. If the stimulus sequence ends and no sample has reached the threshold, then the decision is taken at chance. As described in <xref ref-type="bibr" rid="bib45">Waskom and Kiani, 2018</xref>, the probability for a rightward choice at trial <italic>t</italic> can be expressed as:<disp-formula id="equ6"><mml:math id="m6"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">Π</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:mstyle><mml:mspace linebreak="newline"/><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi mathvariant="normal">Π</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf136"><mml:mi>Φ</mml:mi></mml:math></inline-formula> is the cumulative normal distribution. We also included the possibility for left and right lapses with probability <inline-formula><mml:math id="inf137"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf138"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> . Following <xref ref-type="bibr" rid="bib41">Stine et al., 2020</xref>, we explored an alternative default rule called ‘last sample’ rule: if the stimulus extinguishes and the threshold has not been reached, then the decision is based on the (noisy) last sample rather than simply by chance. This changes the equation describing the probability for rightward choices to:<disp-formula id="equ7"><mml:math id="m7"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">Π</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi mathvariant="normal">Π</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi mathvariant="normal">Φ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>We also explored a variant of the model where the threshold changes on every sample, that is the equations above are changed by substituting <inline-formula><mml:math id="inf139"><mml:mi>θ</mml:mi></mml:math></inline-formula> with <inline-formula><mml:math id="inf140"><mml:msub><mml:mrow><mml:mi>θ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> . As for the snapshot model, we used the session-gain-modulated evidence <inline-formula><mml:math id="inf141"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi mathvariant="normal">S</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> instead of raw evidence <inline-formula><mml:math id="inf142"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for fitting the model to monkey and rat data. The four parameters of the model <inline-formula><mml:math id="inf143"><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> were estimated from each subject data by maximizing the log-likelihood with interior-point algorithm (function <italic>fmincon</italic> in Matlab) and 10 different initializations of the parameters. (In the varying-threshold variant, there are <italic>n</italic> + 3 parameters which are estimated similarly.)</p></sec><sec id="s4-7"><title>Model validation and model comparison</title><p>Psychophysical kernels were obtained from subject and simulated data by running a logistic regression model: <inline-formula><mml:math id="inf144"><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mi>σ</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula>. Standard errors of the weights <inline-formula><mml:math id="inf145"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> were obtained from the Laplace approximation. For psychometric curves, we first defined the weighted stimulus evidence <italic>T<sub>t</sub></italic> at trial <italic>t</italic> as the session-modulated weighted sum of signed sample evidence; with the weights obtained from the logistic regression model above <inline-formula><mml:math id="inf146"><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi>Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> . We then divided the total stimulus evidence into 50 quantiles (10 for human subjects) and computed the psychometric curve as the proportion of rightward choices for each quantile.</p><p>The boundary performance for the snapshot and extrema-detection models corresponds to the best choice accuracy out of all the parameterizations for each model. In the snapshot model, the boundary performance corresponds to the deterministic version with no-lapse, where the attended sample is always the sample <inline-formula><mml:math id="inf147"><mml:msup><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> whose sign better predicts the stimulus category over all animal trials, that is <inline-formula><mml:math id="inf148"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math></inline-formula> and <inline-formula><mml:math id="inf149"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula> if <inline-formula><mml:math id="inf150"><mml:msup><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>*</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> . For the extrema-detection model, the boundary performance corresponds to the lapse-free model with no sensory noise (<inline-formula><mml:math id="inf151"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math></inline-formula>) and a certain value for threshold <inline-formula><mml:math id="inf152"><mml:mi>θ</mml:mi></mml:math></inline-formula> that is identified for each subject by simple parameter search.</p><p>Finally, model selection was performed using the AIC <inline-formula><mml:math id="inf153"><mml:mi>A</mml:mi><mml:mi>I</mml:mi><mml:mi>C</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mi>p</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , where <italic>p</italic> is the number of model parameters and <inline-formula><mml:math id="inf154"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the likelihood evaluated at maximum likelihood parameters.</p></sec><sec id="s4-8"><title>Analysis of majority-driven choices</title><p>We selected for each animal the subset of trials corresponding to when the largest evidence sample was at odds with the total stimulus evidence (disagree trials), that is where <inline-formula><mml:math id="inf155"><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>n</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi> </mml:mi><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mo>≥</mml:mo><mml:mo>|</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:mi> </mml:mi><mml:mo>∨</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo><mml:mi> </mml:mi><mml:mo>≠</mml:mo><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>n</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula>. For this subset of trials, we computed the proportion of animal choices that were aligned with the overall stimulus evidence. We repeated the analysis for simulated data from the integration and extrema-detection models. We computed error bars following a parametric bootstrap procedure: for each bootstrap, we simulated the model (integration/extrema-detection) using parameters sampled from their posterior distribution (based on the Laplace approximation). We then applied the analysis on disagree trials for simulated data, and used these bootstrap values to define confidence intervals.</p></sec><sec id="s4-9"><title>Subjective weighting analysis</title><p>In order to estimate the impact of each sample on the animal choice as a function of sample evidence, we built and estimated the following statistical model:<disp-formula id="equ8"><mml:math id="m8"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>A</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>γ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>1...</mml:mn><mml:mi>n</mml:mi></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:msub><mml:msub><mml:mi>β</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mi>f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>As can be seen, this model is equivalent to the temporal integration model under the assumption that <italic>f</italic> is a linear function. Rather, here we wanted to estimate the function <italic>f</italic> (as well as the session gain <inline-formula><mml:math id="inf156"><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , lateral bias <inline-formula><mml:math id="inf157"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>, and sensory weight <inline-formula><mml:math id="inf158"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>). Including the session gain was necessary for estimating <italic>f</italic> accurately from the monkey and rat behavioral data, since the distribution of pulse strength <inline-formula><mml:math id="inf159"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> was varied across sessions and could otherwise induce a confound. We assumed that <italic>f</italic> is an odd function, that is <inline-formula><mml:math id="inf160"><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mo>-</mml:mo><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mo>-</mml:mo><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula>. This equation takes the form of a GUM and was fitted using the Laplace approximation method as described in <xref ref-type="bibr" rid="bib1">Adam and Hyafil, 2020</xref>. In the monkey experiment, sample evidence could take only a finite number of values, so <italic>f</italic> was simply estimated over these values. In the human experiment, sample evidence could take continuous values. In this case, we defined a Gaussian Process prior over <italic>f</italic> with squared exponential kernel with length scale 0.1 and variance 1.</p></sec><sec id="s4-10"><title>Integration of early and late evidence</title><p>We designed a new analysis tool to characterize the statistical mapping from the multidimensional stimulus space <inline-formula><mml:math id="inf161"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi> </mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="fraktur">R</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:math></inline-formula> onto binary choices <inline-formula><mml:math id="inf162"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mo>[</mml:mo><mml:mn>0,1</mml:mn><mml:mo>]</mml:mo></mml:math></inline-formula>. We first collapsed the stimulus sequence <inline-formula><mml:math id="inf163"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi> </mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> onto the two-dimensional space defined by early evidence <inline-formula><mml:math id="inf164"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi> </mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and late evidence <inline-formula><mml:math id="inf165"><mml:msub><mml:mrow><mml:mi mathvariant="bold-italic">L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi> </mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> defined by <inline-formula><mml:math id="inf166"><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi>Σ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mo>[</mml:mo><mml:mi>n</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo>]</mml:mo></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf167"><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mi>Σ</mml:mi></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mi>n</mml:mi><mml:mo>/</mml:mo><mml:mn>2</mml:mn><mml:mo>]</mml:mo><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> , where the weights <inline-formula><mml:math id="inf168"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and session gains <inline-formula><mml:math id="inf169"><mml:msub><mml:mrow><mml:mi>γ</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> correspond to parameters estimated from the temporal integration model (session gains were omitted for human participants). Next we plotted the integration map which represents the probability for rightward choices as a function of <inline-formula><mml:math id="inf170"><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula>. The map was obtained by smoothing data points with a two-dimensional Gaussian kernel. More specifically, for each pair value (<italic>E</italic>,<italic>L</italic>), we selected the trials whose early and late evidence values <inline-formula><mml:math id="inf171"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf172"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> fell within a certain distance to (<italic>E</italic>,<italic>L</italic>), that is <inline-formula><mml:math id="inf173"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>d</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mtext> </mml:mtext><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. We then computed the proportion of rightward choices for the selected trials, with a weight for each trial depending on the distance to the pair value <inline-formula><mml:math id="inf174"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mo>(</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo><mml:mo>;</mml:mo><mml:mo>(</mml:mo><mml:mi>E</mml:mi><mml:mo>,</mml:mo><mml:mi>L</mml:mi><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo>.</mml:mo><mml:msup><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi> </mml:mi><mml:mi>I</mml:mi><mml:mo>)</mml:mo></mml:math></inline-formula>. Because the space (<italic>E</italic>,<italic>L</italic>) was not sampled uniformly during the experiment, we represent the density of trials by brightness. For each subject, we obtained integration maps both from subject data and from model simulations. For each model, we computed the Pearson correlation between the maps obtained from the corresponding simulation and from the subject data. We tested the significance of correlation measures between models by using a bootstrapping procedure: we calculated the correlation measure <italic>r</italic> from 100 bootstraps for each model and participant, and then performed an unpaired <italic>t</italic>-test between bootstrapped <italic>r.</italic></p><p>Next, we analyzed the conditional psychometric curves, that is the psychometric curves for the early evidence conditioned on the value of late evidence, which correspond to vertical cuts in the integration map. To do so, we first binned late evidence <inline-formula><mml:math id="inf175"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> by bins of width 0.5. Conditional psychometric curve represents the probability of rightward choices as a function of early evidence <inline-formula><mml:math id="inf176"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, separately for each late evidence bin. For each late evidence bin, we also estimated the corresponding bias <inline-formula><mml:math id="inf177"><mml:mi>β</mml:mi></mml:math></inline-formula>, left lapse <inline-formula><mml:math id="inf178"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and right lapse <inline-formula><mml:math id="inf179"><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> by fitting the following function on the corresponding subset of trials:<disp-formula id="equ9"><mml:math id="m9"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>π</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>σ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-11"><title>Analysis of LIP neuron activity</title><p>We analyzed the activity of 82 LIP neurons recorded over 43 sessions of the motion discrimination tasks (<xref ref-type="bibr" rid="bib51">Yates et al., 2017</xref>). We applied the following procedure to extract the integration map for LIP neurons. For each neuron <italic>n</italic>, we computed the spike count <inline-formula><mml:math id="inf180"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> in a window of 500 ms width following each stimulus offset, which is where LIP neurons were found to have maximal selectivity to motion evidence from the entire pulse sequence (<xref ref-type="bibr" rid="bib51">Yates et al., 2017</xref>). We then applied a Poisson GLM <inline-formula><mml:math id="inf181"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi><mml:mo>(</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo><mml:mi> </mml:mi><mml:mo>=</mml:mo><mml:mi> </mml:mi><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>Σ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> for each neuron <italic>n</italic> to extract the impact of each sample <italic>i</italic> on the individual neural spike count <inline-formula><mml:math id="inf182"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> . For each trial <italic>t</italic>, we used these weights to compute the neuron-weighted early and late evidence defined by and <inline-formula><mml:math id="inf183"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Σ</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf184"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Σ</mml:mi></mml:mrow><mml:mrow><mml:mn>4</mml:mn><mml:mo>≤</mml:mo><mml:mi>i</mml:mi><mml:mo>≤</mml:mo><mml:mn>7</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> . Note that this weighting converts the evidence onto the space defined by the preferred direction of the neuron, such that positive evidence signals evidence toward the preferred direction and negative evidence signals evidence toward the anti-preferred direction. We then merged the vectors for normalized spike counts <inline-formula><mml:math id="inf185"><mml:msubsup><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mo>-</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>/</mml:mo><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:math></inline-formula>, early evidence <inline-formula><mml:math id="inf186"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> and late evidence <inline-formula><mml:math id="inf187"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> across all neurons. The normalized spike counts were binned by values of early and late evidence (bin width: 0.02), and the average over each bin was computed after convolving with a two-dimensional Gaussian kernel of width 0.1. The neural integration map represents the average normalized activity per bin.</p><p>Simulations of spiking data for the integration and non-integration models were proceeded as follows. First, the neural integration model corresponds to linear summing with neuron-specific weights which are then passed through an exponential nonlinearity; the spike counts for each trial are generated using a Poisson distribution whose rate is equal to the nonlinear output (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3a</xref>, top). This corresponds exactly to the generative process of the Poisson GLM described above. For the extrema-detection model (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3a</xref>, middle), we hypothesized that LIP activity would only be driven by the sample that reaches the threshold (and dictates the animal response). To this end, we first simulated the behavioral extrema-detection model for all trials, using parameters <inline-formula><mml:math id="inf188"><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:math></inline-formula> fitted from the corresponding animal, to identify which sample <italic>i</italic> reaches the subject-specific threshold. We then assumed that the spiking activity of the neuron would follow the stimulus value at sample <italic>i</italic> <inline-formula><mml:math id="inf189"><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> (signed by the preferred direction of the neuron <inline-formula><mml:math id="inf190"><mml:msup><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> through):<disp-formula id="equ10"><mml:math id="m10"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Again the spike count were generated from a Poisson distribution with rate <inline-formula><mml:math id="inf191"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>E</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>)</mml:mo></mml:math></inline-formula>.</p><p>Finally, for the snapshot model (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3a</xref>, bottom), we assumed that the neuron activity would merely reflect the sensory value of the only sample it would attend. We assumed that the probability mass function to attend each of the seven samples would be neuron specific, so we used the normalized weights of the Poisson GLM for that specific neuron as defining such probability (weights were signed by the neuron preferred direction so that the vast majority of weights were positive; negative weights were ignored). For each trial, we thus randomly sampled the attended sample <italic>i</italic> using this probability mass function and then simulated the spike count <inline-formula><mml:math id="inf192"><mml:msup><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> from a Poisson distribution with rate<disp-formula id="equ11">.<mml:math id="m11"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mi>S</mml:mi><mml:mi>n</mml:mi><mml:mi>a</mml:mi><mml:mi>p</mml:mi><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mtext> </mml:mtext><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msup><mml:mi>p</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:msub><mml:mi>S</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mi>w</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>We simulated spiking activity for each neuron and for each integration and non-integration model, and then used simulated data to compute neural integration maps exactly as described above for the actual LIP neuron activity.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Funding acquisition, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Investigation, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Data curation, Investigation</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Data curation, Writing - review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Data curation, Supervision, Funding acquisition, Investigation, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Supervision, Funding acquisition, Investigation, Visualization, Methodology, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Informed consent was obtained from all participants. The experiment with human participants was approved by the UPF ethics committee (approval 654 2013/5435/I from CEIm-Parc de Salut MAR).</p></fn><fn fn-type="other"><p>Rat experiments were approved by the local ethics committee of the University of Barcelona 658 (Comitéd'Experimentació Animal, Barcelona, Spain, protocol number Ref 390/14). Monkey experiment: All experimental protocols were approved by The University of Texas Institutional Animal Care and Use Committee (AUP-2012-00085, AUP-2015-00068) and in accordance with National Institutes of Health standards for care and use of laboratory animals.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-84045-mdarchecklist1-v2.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All experimental data (behavioral and neural data in monkeys, behavioral data in rats and humans) and code to run the analysis are publicly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/ahyafil/TemporalIntegration">https://github.com/ahyafil/TemporalIntegration</ext-link> (copy archieved at <xref ref-type="bibr" rid="bib19">Hyafil, 2023</xref>).</p></sec><ack id="ack"><title>Acknowledgements</title><p>The authors thank Jake Yates for sharing information regarding the monkey experimental data. The authors are supported by the Spanish State Research Agency (RYC-2017-23231 to AH), Spanish Ministry of Economy and Competitiveness together with the European Regional Development Fund grant SAF2015-70324-R (to JR), European Research Council grant ERC-2015-CoG-683209 (to JR), NIH grant R01EY017366 (to ACH and JWP), NIH BRAIN Initiative grant NS104899 (to JWP), and the Simons Collaboration on the Global Brain (SCGB AWD543027, JWP).</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Adam</surname><given-names>V</given-names></name><name><surname>Hyafil</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Non-Linear Regression Models for Behavioral and Neural Data Analysis</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2002.00920">https://arxiv.org/abs/2002.00920</ext-link></element-citation></ref><ref id="bib2"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bishop</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>Pattern Recognition and Machine Learning</source><publisher-name>Springer</publisher-name></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogacz</surname><given-names>R</given-names></name><name><surname>Brown</surname><given-names>E</given-names></name><name><surname>Moehlis</surname><given-names>J</given-names></name><name><surname>Holmes</surname><given-names>P</given-names></name><name><surname>Cohen</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The physics of optimal decision making: a formal analysis of models of performance in two-alternative forced-choice tasks</article-title><source>Psychological Review</source><volume>113</volume><fpage>700</fpage><lpage>765</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.113.4.700</pub-id><pub-id pub-id-type="pmid">17014301</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bronfman</surname><given-names>ZZ</given-names></name><name><surname>Brezis</surname><given-names>N</given-names></name><name><surname>Moran</surname><given-names>R</given-names></name><name><surname>Tsetsos</surname><given-names>K</given-names></name><name><surname>Donner</surname><given-names>T</given-names></name><name><surname>Usher</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Decisions reduce sensitivity to subsequent information</article-title><source>Proceedings. Biological Sciences</source><volume>282</volume><elocation-id>20150228</elocation-id><pub-id pub-id-type="doi">10.1098/rspb.2015.0228</pub-id><pub-id pub-id-type="pmid">26108628</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bronfman</surname><given-names>ZZ</given-names></name><name><surname>Brezis</surname><given-names>N</given-names></name><name><surname>Usher</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Non-monotonic temporal-weighting indicates a dynamically modulated evidence-integration mechanism</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1004667</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004667</pub-id><pub-id pub-id-type="pmid">26866598</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunton</surname><given-names>BW</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Rats and humans can optimally accumulate evidence for decision-making</article-title><source>Science</source><volume>340</volume><fpage>95</fpage><lpage>98</lpage><pub-id pub-id-type="doi">10.1126/science.1233912</pub-id><pub-id pub-id-type="pmid">23559254</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cheadle</surname><given-names>S</given-names></name><name><surname>Wyart</surname><given-names>V</given-names></name><name><surname>Tsetsos</surname><given-names>K</given-names></name><name><surname>Myers</surname><given-names>N</given-names></name><name><surname>de Gardelle</surname><given-names>V</given-names></name><name><surname>Herce Castañón</surname><given-names>S</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Adaptive gain control during human perceptual choice</article-title><source>Neuron</source><volume>81</volume><fpage>1429</fpage><lpage>1441</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2014.01.020</pub-id><pub-id pub-id-type="pmid">24656259</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cisek</surname><given-names>P</given-names></name><name><surname>Puskas</surname><given-names>GA</given-names></name><name><surname>El-Murr</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Decisions in changing conditions: the urgency-gating model</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>11560</fpage><lpage>11571</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1844-09.2009</pub-id><pub-id pub-id-type="pmid">19759303</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ditterich</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Stochastic models of decisions about motion direction: behavior and physiology</article-title><source>Neural Networks</source><volume>19</volume><fpage>981</fpage><lpage>1012</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2006.05.042</pub-id><pub-id pub-id-type="pmid">16952441</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drugowitsch</surname><given-names>J</given-names></name><name><surname>Moreno-Bote</surname><given-names>R</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The cost of accumulating evidence in perceptual decision making</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>3612</fpage><lpage>3628</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4010-11.2012</pub-id><pub-id pub-id-type="pmid">22423085</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drugowitsch</surname><given-names>J</given-names></name><name><surname>Wyart</surname><given-names>V</given-names></name><name><surname>Devauchelle</surname><given-names>A-D</given-names></name><name><surname>Koechlin</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Computational precision of mental inference as critical source of human choice suboptimality</article-title><source>Neuron</source><volume>92</volume><fpage>1398</fpage><lpage>1411</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.11.005</pub-id><pub-id pub-id-type="pmid">27916454</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glaze</surname><given-names>CM</given-names></name><name><surname>Kable</surname><given-names>JW</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Normative evidence accumulation in unpredictable environments</article-title><source>eLife</source><volume>4</volume><elocation-id>e08825</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.08825</pub-id><pub-id pub-id-type="pmid">26322383</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glickman</surname><given-names>M</given-names></name><name><surname>Usher</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Integration to boundary in decisions between numerical sequences</article-title><source>Cognition</source><volume>193</volume><elocation-id>104022</elocation-id><pub-id pub-id-type="doi">10.1016/j.cognition.2019.104022</pub-id><pub-id pub-id-type="pmid">31369923</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname><given-names>JI</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The neural basis of decision making</article-title><source>Annual Review of Neuroscience</source><volume>30</volume><fpage>535</fpage><lpage>574</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.29.051605.113038</pub-id><pub-id pub-id-type="pmid">17600525</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hermoso-Mendizabal</surname><given-names>A</given-names></name><name><surname>Hyafil</surname><given-names>A</given-names></name><name><surname>Rueda-Orozco</surname><given-names>PE</given-names></name><name><surname>Jaramillo</surname><given-names>S</given-names></name><name><surname>Robbe</surname><given-names>D</given-names></name><name><surname>de la Rocha</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Response outcomes gate the impact of expectations on perceptual decisions</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>1057</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-14824-w</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hernández-Navarro</surname><given-names>L</given-names></name><name><surname>Hermoso-Mendizabal</surname><given-names>A</given-names></name><name><surname>Duque</surname><given-names>D</given-names></name><name><surname>de la Rocha</surname><given-names>J</given-names></name><name><surname>Hyafil</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Proactive and reactive accumulation-to-bound processes compete during perceptual decisions</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>7148</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-27302-8</pub-id><pub-id pub-id-type="pmid">34880219</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huk</surname><given-names>AC</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Neural activity in Macaque Parietal cortex reflects temporal integration of visual motion signals during perceptual decision making</article-title><source>The Journal of Neuroscience</source><volume>25</volume><fpage>10420</fpage><lpage>10436</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4684-04.2005</pub-id><pub-id pub-id-type="pmid">16280581</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hyafil</surname><given-names>A</given-names></name><name><surname>Moreno-Bote</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Breaking down hierarchies of decision-making in primates</article-title><source>eLife</source><volume>6</volume><elocation-id>e16650</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.16650</pub-id><pub-id pub-id-type="pmid">28648171</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Hyafil</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>Temporal integration is a robust feature of perceptual decisions</data-title><version designator="swh:1:rev:431db328b1c959a989f30ffb5e7bc80501641df9">swh:1:rev:431db328b1c959a989f30ffb5e7bc80501641df9</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:16612e07ded695381ea1b4c43866acf2d23c4baf;origin=https://github.com/ahyafil/TemporalIntegration;visit=swh:1:snp:f13473496292e1a9044bc2c85542a8232ceaf229;anchor=swh:1:rev:431db328b1c959a989f30ffb5e7bc80501641df9">https://archive.softwareheritage.org/swh:1:dir:16612e07ded695381ea1b4c43866acf2d23c4baf;origin=https://github.com/ahyafil/TemporalIntegration;visit=swh:1:snp:f13473496292e1a9044bc2c85542a8232ceaf229;anchor=swh:1:rev:431db328b1c959a989f30ffb5e7bc80501641df9</ext-link></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Katz</surname><given-names>LN</given-names></name><name><surname>Hennig</surname><given-names>JA</given-names></name><name><surname>Cormack</surname><given-names>LK</given-names></name><name><surname>Huk</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A distinct mechanism of temporal integration for motion through depth</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>10212</fpage><lpage>10216</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0032-15.2015</pub-id><pub-id pub-id-type="pmid">26180197</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keung</surname><given-names>W</given-names></name><name><surname>Hagen</surname><given-names>TA</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Regulation of evidence accumulation by pupil-linked arousal processes</article-title><source>Nature Human Behaviour</source><volume>3</volume><fpage>636</fpage><lpage>645</lpage><pub-id pub-id-type="doi">10.1038/s41562-019-0551-4</pub-id><pub-id pub-id-type="pmid">31190022</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keung</surname><given-names>W</given-names></name><name><surname>Hagen</surname><given-names>TA</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A divisive model of evidence accumulation explains uneven weighting of evidence over time</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>2160</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-15630-0</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Hanks</surname><given-names>TD</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Bounded integration in parietal cortex underlies decisions even when viewing duration is dictated by the environment</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>3017</fpage><lpage>3029</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4761-07.2008</pub-id><pub-id pub-id-type="pmid">18354005</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiani</surname><given-names>R</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Representation of confidence associated with a decision by neurons in the parietal cortex</article-title><source>Science</source><volume>324</volume><fpage>759</fpage><lpage>764</lpage><pub-id pub-id-type="doi">10.1126/science.1169405</pub-id><pub-id pub-id-type="pmid">19423820</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kilpatrick</surname><given-names>ZP</given-names></name><name><surname>Holmes</surname><given-names>WR</given-names></name><name><surname>Eissa</surname><given-names>TL</given-names></name><name><surname>Josić</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Optimal models of decision-making in dynamic environments</article-title><source>Current Opinion in Neurobiology</source><volume>58</volume><fpage>54</fpage><lpage>60</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2019.06.006</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levi</surname><given-names>AJ</given-names></name><name><surname>Yates</surname><given-names>JL</given-names></name><name><surname>Huk</surname><given-names>AC</given-names></name><name><surname>Katz</surname><given-names>LN</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Strategic and dynamic temporal weighting for perceptual decisions in humans and macaques</article-title><source>ENeuro</source><volume>5</volume><elocation-id>ENEURO.0169-18.2018</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0169-18.2018</pub-id><pub-id pub-id-type="pmid">30406190</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levi</surname><given-names>AJ</given-names></name><name><surname>Huk</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Interpreting temporal Dynamics during sensory decision-making</article-title><source>Current Opinion in Physiology</source><volume>16</volume><fpage>27</fpage><lpage>32</lpage><pub-id pub-id-type="doi">10.1016/j.cophys.2020.04.006</pub-id><pub-id pub-id-type="pmid">32864535</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lorteije</surname><given-names>JAM</given-names></name><name><surname>Zylberberg</surname><given-names>A</given-names></name><name><surname>Ouellette</surname><given-names>BG</given-names></name><name><surname>De Zeeuw</surname><given-names>CI</given-names></name><name><surname>Sigman</surname><given-names>M</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The formation of hierarchical decisions in the visual cortex</article-title><source>Neuron</source><volume>87</volume><fpage>1344</fpage><lpage>1356</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.08.015</pub-id><pub-id pub-id-type="pmid">26365766</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morillon</surname><given-names>B</given-names></name><name><surname>Schroeder</surname><given-names>CE</given-names></name><name><surname>Wyart</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Motor contributions to the temporal precision of auditory attention</article-title><source>Nature Communications</source><volume>5</volume><elocation-id>5255</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms6255</pub-id><pub-id pub-id-type="pmid">25314898</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Neri</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Estimation of nonlinear psychophysical kernels</article-title><source>Journal of Vision</source><volume>4</volume><fpage>82</fpage><lpage>91</lpage><pub-id pub-id-type="doi">10.1167/4.2.2</pub-id><pub-id pub-id-type="pmid">15005649</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nienborg</surname><given-names>H</given-names></name><name><surname>Cumming</surname><given-names>BG</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Psychophysically measured task strategy for disparity discrimination is reflected in V2 neurons</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1608</fpage><lpage>1614</lpage><pub-id pub-id-type="doi">10.1038/nn1991</pub-id><pub-id pub-id-type="pmid">17965712</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ossmy</surname><given-names>O</given-names></name><name><surname>Moran</surname><given-names>R</given-names></name><name><surname>Pfeffer</surname><given-names>T</given-names></name><name><surname>Tsetsos</surname><given-names>K</given-names></name><name><surname>Usher</surname><given-names>M</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The timescale of perceptual evidence integration can be adapted to the environment</article-title><source>Current Biology</source><volume>23</volume><fpage>981</fpage><lpage>986</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.04.039</pub-id><pub-id pub-id-type="pmid">23684972</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Otto</surname><given-names>TU</given-names></name><name><surname>Mamassian</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Noise and correlations in parallel perceptual decision making</article-title><source>Current Biology</source><volume>22</volume><fpage>1391</fpage><lpage>1396</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.05.031</pub-id><pub-id pub-id-type="pmid">22771043</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pannunzi</surname><given-names>M</given-names></name><name><surname>Pérez-Bellido</surname><given-names>A</given-names></name><name><surname>Pereda-Baños</surname><given-names>A</given-names></name><name><surname>López-Moliner</surname><given-names>J</given-names></name><name><surname>Deco</surname><given-names>G</given-names></name><name><surname>Soto-Faraco</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Deconstructing multisensory enhancement in detection</article-title><source>Journal of Neurophysiology</source><volume>113</volume><fpage>1800</fpage><lpage>1818</lpage><pub-id pub-id-type="doi">10.1152/jn.00341.2014</pub-id><pub-id pub-id-type="pmid">25520431</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pardo-Vazquez</surname><given-names>JL</given-names></name><name><surname>Castiñeiras-de Saa</surname><given-names>JR</given-names></name><name><surname>Valente</surname><given-names>M</given-names></name><name><surname>Damião</surname><given-names>I</given-names></name><name><surname>Costa</surname><given-names>T</given-names></name><name><surname>Vicente</surname><given-names>MI</given-names></name><name><surname>Mendonça</surname><given-names>AG</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name><name><surname>Renart</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The mechanistic Foundation of Weber’s law</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1493</fpage><lpage>1502</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0439-7</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pinto</surname><given-names>L</given-names></name><name><surname>Koay</surname><given-names>SA</given-names></name><name><surname>Engelhard</surname><given-names>B</given-names></name><name><surname>Yoon</surname><given-names>AM</given-names></name><name><surname>Deverett</surname><given-names>B</given-names></name><name><surname>Thiberge</surname><given-names>SY</given-names></name><name><surname>Witten</surname><given-names>IB</given-names></name><name><surname>Tank</surname><given-names>DW</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>An accumulation-of-evidence task using visual pulses for mice navigating in virtual reality</article-title><source>Frontiers in Behavioral Neuroscience</source><volume>12</volume><elocation-id>36</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2018.00036</pub-id><pub-id pub-id-type="pmid">29559900</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prat-Ortega</surname><given-names>G</given-names></name><name><surname>Wimmer</surname><given-names>K</given-names></name><name><surname>Roxin</surname><given-names>A</given-names></name><name><surname>de la Rocha</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Flexible categorization in perceptual decision making</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>1283</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-21501-z</pub-id><pub-id pub-id-type="pmid">33627643</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raposo</surname><given-names>D</given-names></name><name><surname>Sheppard</surname><given-names>JP</given-names></name><name><surname>Schrater</surname><given-names>PR</given-names></name><name><surname>Churchland</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Multisensory decision-making in rats and humans</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>3726</fpage><lpage>3735</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4998-11.2012</pub-id><pub-id pub-id-type="pmid">22423093</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roitman</surname><given-names>JD</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Response of neurons in the lateral intraparietal area during a combined visual discrimination reaction time task</article-title><source>The Journal of Neuroscience</source><volume>22</volume><fpage>9475</fpage><lpage>9489</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.22-21-09475.2002</pub-id><pub-id pub-id-type="pmid">12417672</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stanford</surname><given-names>TR</given-names></name><name><surname>Salinas</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Urgent decision making: resolving visuomotor interactions at high temporal resolution</article-title><source>Annual Review of Vision Science</source><volume>7</volume><fpage>323</fpage><lpage>348</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-100419-103842</pub-id><pub-id pub-id-type="pmid">34171199</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stine</surname><given-names>GM</given-names></name><name><surname>Zylberberg</surname><given-names>A</given-names></name><name><surname>Ditterich</surname><given-names>J</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Differentiating between integration and non-integration strategies in perceptual decision making</article-title><source>eLife</source><volume>9</volume><elocation-id>e55365</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.55365</pub-id><pub-id pub-id-type="pmid">32338595</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thura</surname><given-names>D</given-names></name><name><surname>Beauregard-Racine</surname><given-names>J</given-names></name><name><surname>Fradet</surname><given-names>C-W</given-names></name><name><surname>Cisek</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Decision making by urgency gating: theory and experimental support</article-title><source>Journal of Neurophysiology</source><volume>108</volume><fpage>2912</fpage><lpage>2930</lpage><pub-id pub-id-type="doi">10.1152/jn.01071.2011</pub-id><pub-id pub-id-type="pmid">22993260</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Seeing at a glance, smelling in a whiff: rapid forms of perceptual decision making</article-title><source>Nature Reviews. Neuroscience</source><volume>7</volume><fpage>485</fpage><lpage>491</lpage><pub-id pub-id-type="doi">10.1038/nrn1933</pub-id><pub-id pub-id-type="pmid">16715056</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Decision making in recurrent neuronal circuits</article-title><source>Neuron</source><volume>60</volume><fpage>215</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.09.034</pub-id><pub-id pub-id-type="pmid">18957215</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Waskom</surname><given-names>ML</given-names></name><name><surname>Kiani</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Decision making through integration of sensory evidence at prolonged timescales</article-title><source>Current Biology</source><volume>28</volume><fpage>3850</fpage><lpage>3856</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2018.10.021</pub-id><pub-id pub-id-type="pmid">30471996</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Collins</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Ten simple rules for the computational modeling of behavioral data</article-title><source>eLife</source><volume>8</volume><elocation-id>e49547</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.49547</pub-id><pub-id pub-id-type="pmid">31769410</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wimmer</surname><given-names>K</given-names></name><name><surname>Compte</surname><given-names>A</given-names></name><name><surname>Roxin</surname><given-names>A</given-names></name><name><surname>Peixoto</surname><given-names>D</given-names></name><name><surname>Renart</surname><given-names>A</given-names></name><name><surname>de la Rocha</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Sensory integration dynamics in a hierarchical network explains choice probabilities in cortical area MT</article-title><source>Nature Communications</source><volume>6</volume><elocation-id>6177</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms7177</pub-id><pub-id pub-id-type="pmid">25649611</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winkel</surname><given-names>J</given-names></name><name><surname>Keuken</surname><given-names>MC</given-names></name><name><surname>van Maanen</surname><given-names>L</given-names></name><name><surname>Wagenmakers</surname><given-names>E-J</given-names></name><name><surname>Forstmann</surname><given-names>BU</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Early evidence affects later decisions: why evidence accumulation is required to explain response time data</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>21</volume><fpage>777</fpage><lpage>784</lpage><pub-id pub-id-type="doi">10.3758/s13423-013-0551-8</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wyart</surname><given-names>V</given-names></name><name><surname>de Gardelle</surname><given-names>V</given-names></name><name><surname>Scholl</surname><given-names>J</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Rhythmic fluctuations in evidence accumulation during decision making in the human brain</article-title><source>Neuron</source><volume>76</volume><fpage>847</fpage><lpage>858</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.09.015</pub-id><pub-id pub-id-type="pmid">23177968</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>T</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Probabilistic Reasoning by neurons</article-title><source>Nature</source><volume>447</volume><fpage>1075</fpage><lpage>1080</lpage><pub-id pub-id-type="doi">10.1038/nature05852</pub-id><pub-id pub-id-type="pmid">17546027</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yates</surname><given-names>JL</given-names></name><name><surname>Park</surname><given-names>IM</given-names></name><name><surname>Katz</surname><given-names>LN</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name><name><surname>Huk</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Functional dissection of signal and noise in MT and lip during decision-making</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1285</fpage><lpage>1292</lpage><pub-id pub-id-type="doi">10.1038/nn.4611</pub-id><pub-id pub-id-type="pmid">28758998</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zariwala</surname><given-names>HA</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name><name><surname>Uchida</surname><given-names>N</given-names></name><name><surname>Hirokawa</surname><given-names>J</given-names></name><name><surname>Mainen</surname><given-names>ZF</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The limits of deliberation in a perceptual decision task</article-title><source>Neuron</source><volume>78</volume><fpage>339</fpage><lpage>351</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.02.010</pub-id><pub-id pub-id-type="pmid">23541901</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Znamenskiy</surname><given-names>P</given-names></name><name><surname>Zador</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Corticostriatal neurons in auditory cortex drive decisions during auditory discrimination</article-title><source>Nature</source><volume>497</volume><fpage>482</fpage><lpage>485</lpage><pub-id pub-id-type="doi">10.1038/nature12077</pub-id><pub-id pub-id-type="pmid">23636333</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zuo</surname><given-names>Y</given-names></name><name><surname>Diamond</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Rats generate vibrissal sensory evidence until boundary crossing triggers a decision</article-title><source>Current Biology</source><volume>29</volume><fpage>1415</fpage><lpage>1424</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.03.016</pub-id><pub-id pub-id-type="pmid">31006570</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.84045.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Salinas</surname><given-names>Emilio</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0207ad724</institution-id><institution>Wake Forest School of Medicine</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2022.10.25.513647" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2022.10.25.513647"/></front-stub><body><p>This manuscript tests an important assumption about how sensory information is processed and used to guide motor choices. The widely held assumption is that sensory-motor circuits are capable of integrating evidence, but the validity and generality of this 'principle' have been recently questioned by studies suggesting that other computational operations may lead to similar psychophysical results, mimicking integration without actually performing it. This study makes a compelling case that the integration assumption was likely correct all along and that the model mimicry can be easily disambiguated by using appropriate sensory stimuli and task designs that permit rigorous analyses.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.84045.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Salinas</surname><given-names>Emilio</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0207ad724</institution-id><institution>Wake Forest School of Medicine</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Salinas</surname><given-names>Emilio</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0207ad724</institution-id><institution>Wake Forest School of Medicine</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2022.10.25.513647">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2022.10.25.513647v1">the preprint</ext-link> for the benefit of readers; ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Temporal integration is a robust feature of perceptual decisions&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, including Emilio Salinas as the Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Michael Frank as the Senior Editor.</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1) Reviewer 2 pointed out that the model used by the authors is one of a broader family of possible models. Consideration of this broader family, at least in the form of some discussion, would strengthen the results, or would at least situate them more clearly in the theoretical landscape. See the full recommendation of Reviewer 2 below.</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>I have one main suggestion. Otherwise, I think this is a great study.</p><p>A very general family of models of integration of a variable &quot;x&quot; in response to a noisy stimulus &quot;s&quot; would be:</p><p>tau. dx/dt = s(t). F(x,t) + G(x,t) where G(x,t) would represent any dynamics in the absence of stimulus and F(x,t) would weight evidence according to time and current level of integrated evidence. It is unclear to this reader if the results have placed any restrictions on the potential forms of G(x,t) – the suggestion is that it should be zero, but this has not been tested I think – nor on whether the function &quot;F()&quot; which they show depends on time, &quot;t&quot; could also depend on the level of integrated evidence, &quot;x&quot;. Since the model only includes an F(t) but then contrasts with very different models, there is an implicit suggestion or assumption that F(x,t) = F(t) and G(x,t) = 0, but this assumption is not tested. It would be nice to see an explicit test or a clear statement on what limits or lack thereof must be present in this integration-like process. For example, a comparison with the urgency-gating model of Cisek (J Neurosci 2009) would be valuable, along with a discussion of whether the authors expect different results in free response paradigms.</p><p>Supp Figure 2: This needs a bit more explaining. Legend in A is different from the caption. In B, with Δ-AIC, shouldn't the AIC be based on the likelihood of the data-given model? So why is there a black curve for &quot;data&quot;? In fact, how are their 3 curves at all as a Δ-AIC is a difference between two values? Confusing. Perhaps this is just &quot;AIC&quot; and the black curve is the integration model, not the experimental data?</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.84045.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>Reviewer #2 (Recommendations for the authors):</p><p>I have one main suggestion. Otherwise, I think this is a great study.</p><p>A very general family of models of integration of a variable &quot;x&quot; in response to a noisy stimulus &quot;s&quot; would be:</p><p>tau. dx/dt = s(t). F(x,t) + G(x,t) where G(x,t) would represent any dynamics in the absence of stimulus and F(x,t) would weight evidence according to time and current level of integrated evidence. It is unclear to this reader if the results have placed any restrictions on the potential forms of G(x,t) – the suggestion is that it should be zero, but this has not been tested I think – nor on whether the function &quot;F()&quot; which they show depends on time, &quot;t&quot; could also depend on the level of integrated evidence, &quot;x&quot;. Since the model only includes an F(t) but then contrasts with very different models, there is an implicit suggestion or assumption that F(x,t) = F(t) and G(x,t) = 0, but this assumption is not tested. It would be nice to see an explicit test or a clear statement on what limits or lack thereof must be present in this integration-like process. For example, a comparison with the urgency-gating model of Cisek (J Neurosci 2009) would be valuable, along with a discussion of whether the authors expect different results in free response paradigms.</p></disp-quote><p>We thank the reviewer for pointing to this very important point. While the two non-integration models were relatively easy to formalize into generic generative models that can later be fitted to experimental data, the same does not hold for the integration model. As rightfully pointed out, the most general generative model of integration should include dependence of the drift term on both time and x, both for the stimulus-sensitive part F(x,t) and G(x,t). This wider class of models could thus accommodate time-varying sticky bounds theta(t) (i.e. F(theta(t),t)=G(theta(t),t)=0), leak or attractive dynamics (G(x,t) = λ*x) and more. Now, fitting such an immense class of models to experimental data becomes very challenging computationally and prone to overfitting (observed values consist of 500-50 000 binary observations). For this reason we decided to restrict to a much high-level description of the computation that does not characterize the functions G() or F(), and that should not be interpreted literally as a generative model of behavior but rather as a (first-order) statistical description for any of the generative integration model corresponding to the larger integration family. Thus, to connect with the reviewer’s public review, we do not claim that the non-monotonic weights of the logistic model correspond genuinely to a non-monotonic sensitivity F(t), but are rather the statistical linear description of more complex nonlinear phenomena. For example, non-monotonic kernels (both bell-shaped and U-shaped) have been described in previous studies and linked theoretically to either attractor dynamics (i.e. double well potential, G(x,t) = a.x^3 + b.x in Prat-Ortega et al., 2021; or time-dependent dynamics in Bronfman, Brezis, and Usher 2016) or divisive normalization (Keung et al. 2019 and 2020). Technically, our statistical approach corresponds to the first-order expansion of the Volterra series used to approximate any integration model (Neri, 2004) by a simple and fittable logistic model.</p><p>Importantly our objective in this paper was not to compare and identify these complex mechanisms at play during evidence integration, but rather to compare non-integration models against <italic>any</italic> integration strategy. We believe that our first-order statistical modelling of integration strategies is suited for this purpose.</p><p>References</p><p>Keung, W., Hagen, T.A. &amp; Wilson, R.C. A divisive model of evidence accumulation explains uneven weighting of evidence over time. <italic>Nat Commun</italic> 11, 2160 (2020). https://doi.org/10.1038/s41467-020-15630-0</p><p>Keung, Waitsang, Todd A. Hagen, and Robert C. Wilson. 2019. “Regulation of Evidence Accumulation by Pupil-Linked Arousal Processes.” <italic>Nature Human Behaviour</italic> 3 (6): 636–45.</p><p>Neri, P. (2004). Estimation of nonlinear psychophysical kernels. <italic>Journal of Vision</italic>, <italic>4</italic>(2), 2. https://doi.org/10.1167/4.2.2</p><p>Prat-Ortega, G., Wimmer, K., Roxin, A. <italic>et al.</italic> Flexible categorization in perceptual decision making. <italic>Nat Commun</italic> 12, 1283 (2021). https://doi.org/10.1038/s41467-021-21501-z</p><p>We have added the following clarifications in the manuscript: “Departures from optimality in the accumulation process such as accumulation leak, categorization dynamics, sensory adaptation or sticky boundaries may however yield unequal weighting of the different samples (Yates et al. 2017; Brunton, Botvinick, and Brody 2013; Prat-Ortega et al. 2021; Bronfman, Brezis, and Usher 2016; Keung, Hagen, and Wilson 2020, 2019). To accommodate for these, we allowed the model to take any arbitrary weighting of the samples: <italic>p</italic>(<italic>r</italic> = <italic>A</italic>) = Φ(β0 + Σ<italic>i</italic>β<italic>i</italic>S<italic>i</italic>) (see Methods for details). The mapping from final accumulated evidence to choice was probabilistic, to account for the effects of noise from different sources in the decision-making process (Drugowitsch et al. 2016). Thus the model represented an approximate statistical description for any generative model relying on temporal integration of the stimulus evidence.” (Results, p7)</p><p>“The vector β<italic>i</italic>’s allowed to capture different shapes of psychophysical kernels (e.g. primacy effects, recency effects) which can emerge due to a variety of suboptimalities in the integration process (leak, attractor dynamics, sticky bounds, sensory after-effects, etc.) (Brunton, Botvinick, and Brody 2013; Yates et al. 2017; Prat-Ortega et al. 2021; Bronfman, Brezis, and Usher 2016; Keung, Hagen, and Wilson 2019, 2020). Technically, our statistical approach corresponds to the first-order expansion of the Volterra series used to approximate any integration model (Neri 2004) by a simple and fittable logistic model. In other words, because a more complete description of integration models would be computationally challenging to fit and prone to overfitting, we chose a statistical approximation in the form of the logistic model that captures the essence of any generative model that include temporal integration, i.e. weighted summation of stimulus evidence.” (Methods, p22).</p><p>Finally, we have expanded the discussion about free-response paradigms in the Discussion to include an explicit comparison with the urgency-gating model of Cisek et al. 2009 (in the previous version, we referred to Thura et al. 2012 which is a more thorough theoretical development of the urgency-gating model):</p><p>“Other studies have shown how integration and non-integration strategies can be disentangled in free reaction-time task paradigms. Specifically, different models make different predictions regarding how the total sample evidence presented before response time should vary with response time (Glickman and Usher 2019; Zuo and Diamond 2019). Glickman and Usher used these predictions to rule out non-integration strategies in a counting task in humans, and Zuo and Diamond found evidence for evidence integration to bound when rats discriminate textures using whisker touches (Zuo and Diamond 2019). Under strong urgency constraints, it has been proposed that decisions depend on very limited temporal integration of the stimulus by low-pass filtering of stimulus evidence (Cisek et al. 2009; Thura et al. 2012). However this suggestion cannot explain the fact that evidence presented early in the trial influences decisions taken later on (Winkel et al. 2014). Of note, the absence of integration seems a more viable strategy when the duration of the stimulus is controlled externally and the benefits of integrating in terms of accuracy might not compensate for its cognitive cost. In free-reaction time paradigms, waiting for a long sequence of samples and selecting its response based on a single sample does not seem a particularly efficient strategy. If the cognitive cost of integration is high, it is more beneficial to interrupt the stimulus sequence early with a rapid response. Indeed, fast or very fast (under 250 ms) perceptual decisions are very common (Uchida, Kepecs, and Mainen 2006; Zariwala et al. 2013; Stanford and Salinas 2021). Such rapid termination of the decision process have can been attributed either to urgency signals modulating the integration of stimulus evidence (Drugowitsch et al. 2012; Stanford and Salinas 2021) or to action initiation mechanisms that time the response after a specific time (e.g. one or two samples) following stimulus onset (Hernández-Navarro et al. 2021). Here, we have shown that even in paradigms where the stimulus duration is controlled by the experimenter, mammals often integrate sensory evidence over the entire stimulus.”</p><disp-quote content-type="editor-comment"><p>Supp Figure 2: This needs a bit more explaining. Legend in A is different from the caption.</p></disp-quote><p>Thank you for spotting multiple problems with this figure caption. Caption for panel A has been corrected and is now in agreement with the legend. (This figure is now labeled ‘Figure 2 figure supplement 2).</p><disp-quote content-type="editor-comment"><p>In B, with Δ-AIC, shouldn't the AIC be based on the likelihood of the data-given model? So why is there a black curve for &quot;data&quot;? In fact, how are their 3 curves at all as a Δ-AIC is a difference between two values? Confusing. Perhaps this is just &quot;AIC&quot; and the black curve is the integration model, not the experimental data?</p></disp-quote><p>There are actually 2x2 = 4 different curves for each of the different variants of the snapshot model (deterministic vs probabilistic, and free vs fixed lapse parameters), but two curves (probabilistic-free and probabilistic free) are virtually identical. Each curve corresponds to Δ-AIC that measures the difference in AIC for this specific variant of the snapshot model w.r.t the integration model (i.e. the integration model always corresponds to Δ-AIC = 0). So in essence the panel compares 4 x 6 = 24 variants of the snapshot model with the integration model, and the integration model always wins (for both animals). We have clarified this point in the caption:</p><p>“AIC difference between each of the four variants of the snapshot model and the integration model. Legend as in A (full/dashed lines for fixed/free lapse parameters; black/blue curves for probabilistic/deterministic variants). Note that the probabilistic variant with either fixed or free lapses provide virtually indistinguishable values. Positive values indicate that the snapshot model provides a worse fit than the integration model.”</p></body></sub-article></article>