<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article article-type="research-article" dtd-version="1.2" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">67304</article-id><article-id pub-id-type="doi">10.7554/eLife.67304</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Population receptive fields in nonhuman primates from whole-brain fMRI and large-scale neurophysiology in visual cortex</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-205069"><name><surname>Klink</surname><given-names>P Christiaan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6784-7842</contrib-id><email>c.klink@nin.knaw.nl</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund5"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-226406"><name><surname>Chen</surname><given-names>Xing</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-3589-1750</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-132413"><name><surname>Vanduffel</surname><given-names>Wim</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-33135"><name><surname>Roelfsema</surname><given-names>Pieter R</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1625-0034</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Netherlands Institute for Neuroscience, Royal Netherlands Academy of Arts and Sciences</institution><addr-line><named-content content-type="city">Amsterdam</named-content></addr-line><country>Netherlands</country></aff><aff id="aff2"><label>2</label><institution>Psychiatry Department, Amsterdam UMC</institution><addr-line><named-content content-type="city">Amsterdam</named-content></addr-line><country>Netherlands</country></aff><aff id="aff3"><label>3</label><institution>Laboratory for Neuro- and Psychophysiology, Department of Neurosciences, KU Leuven Medical School</institution><addr-line><named-content content-type="city">Leuven</named-content></addr-line><country>Belgium</country></aff><aff id="aff4"><label>4</label><institution>Massachusetts General Hospital, Martinos Ctr. for Biomedical Imaging</institution><addr-line><named-content content-type="city">Charlestown</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution>Leuven Brain Institute, KU Leuven</institution><addr-line><named-content content-type="city">Leuven</named-content></addr-line><country>Belgium</country></aff><aff id="aff6"><label>6</label><institution>Harvard Medical School</institution><addr-line><named-content content-type="city">Boston</named-content></addr-line><country>United States</country></aff><aff id="aff7"><label>7</label><institution>Department of Integrative Neurophysiology, Center for Neurogenomics and Cognitive Research, VU University</institution><addr-line><named-content content-type="city">Amsterdam</named-content></addr-line><country>Netherlands</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Krug</surname><given-names>Kristine</given-names></name><role>Reviewing Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Behrens</surname><given-names>Timothy E</given-names></name><role>Senior Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>03</day><month>11</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e67304</elocation-id><history><date date-type="received" iso-8601-date="2021-02-07"><day>07</day><month>02</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2021-10-24"><day>24</day><month>10</month><year>2021</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2020-09-08"><day>08</day><month>09</month><year>2020</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2020.09.05.284133"/></event></pub-history><permissions><copyright-statement>Â© 2021, Klink et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Klink et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-67304-v3.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-67304-figures-v3.pdf"/><related-article ext-link-type="doi" id="ra1" related-article-type="article-reference" xlink:href="10.7554/eLife.75171"/><abstract><p>Population receptive field (pRF) modeling is a popular fMRI method to map the retinotopic organization of the human brain. While fMRI-based pRF maps are qualitatively similar to invasively recorded single-cell receptive fields in animals, it remains unclear what neuronal signal they represent. We addressed this question in awake nonhuman primates comparing whole-brain fMRI and large-scale neurophysiological recordings in areas V1 and V4 of the visual cortex. We examined the fits of several pRF models based on the fMRI blood-oxygen-level-dependent (BOLD) signal, multi-unit spiking activity (MUA), and local field potential (LFP) power in different frequency bands. We found that pRFs derived from BOLD-fMRI were most similar to MUA-pRFs in V1 and V4, while pRFs based on LFP gamma power also gave a good approximation. fMRI-based pRFs thus reliably reflect neuronal receptive field properties in the primate brain. In addition to our results in V1 and V4, the whole-brain fMRI measurements revealed retinotopic tuning in many other cortical and subcortical areas with a consistent increase in pRF size with increasing eccentricity, as well as a retinotopically specific deactivation of default mode network nodes similar to previous observations in humans.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>population receptive field</kwd><kwd>vision</kwd><kwd>nonhuman primate</kwd><kwd>neuroimaging</kwd><kwd>neurophysiology</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003246</institution-id><institution>Nederlandse Organisatie voor Wetenschappelijk Onderzoek</institution></institution-wrap></funding-source><award-id>VENI 451.13.023</award-id><principal-award-recipient><name><surname>Klink</surname><given-names>P Christiaan</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003246</institution-id><institution>Nederlandse Organisatie voor Wetenschappelijk Onderzoek</institution></institution-wrap></funding-source><award-id>STW-Perspectief P15-42 &quot;NESTOR&quot;</award-id><principal-award-recipient><name><surname>Chen</surname><given-names>Xing</given-names></name><name><surname>Roelfsema</surname><given-names>Pieter</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100011199</institution-id><institution>FP7 Ideas: European Research Council</institution></institution-wrap></funding-source><award-id>ERC 339490 &quot;Cortic_al_gorithms&quot;</award-id><principal-award-recipient><name><surname>Roelfsema</surname><given-names>Pieter R</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution>Human Brain Project</institution></institution-wrap></funding-source><award-id>Agreements 720270 and 785907 &quot;Human Brain Project SGA1 and SGA2&quot;</award-id><principal-award-recipient><name><surname>Roelfsema</surname><given-names>Pieter R</given-names></name><name><surname>Vanduffel</surname><given-names>Wim</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100003246</institution-id><institution>Nederlandse Organisatie voor Wetenschappelijk Onderzoek</institution></institution-wrap></funding-source><award-id>Crossover Program 17619 &quot;INTENSE&quot;</award-id><principal-award-recipient><name><surname>Roelfsema</surname><given-names>Pieter R</given-names></name><name><surname>Klink</surname><given-names>P Christiaan</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Within-species comparison of population receptive fields determined with fMRI and electrophysiology in nonhuman primates reveals the neuronal basis of blood-oxygen-level-dependent-based retinotopy.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The concept of a receptive field (RF) is crucial for our understanding of the mechanisms underlying perception, cognition, and action. RFs (<xref ref-type="bibr" rid="bib59">Hartline, 1938</xref>; <xref ref-type="bibr" rid="bib128">Sherrington, 1906</xref>) typically describe stimulus locations that evoke or modulate neuronal responses, but they can be generalized to different stimulus features such as color or spatial frequency. RFs are usually measured by determining the neuronal firing rate elicited by visual stimuli (<xref ref-type="bibr" rid="bib70">Hubel and Wiesel, 1998</xref>; <xref ref-type="bibr" rid="bib68">Hubel and Wiesel, 1968</xref>; <xref ref-type="bibr" rid="bib66">Hubel and Wiesel, 1959</xref>), but they can also be defined based on other neuronal signals such as subthreshold activity (<xref ref-type="bibr" rid="bib111">Priebe, 2008</xref>), properties of the local field potential (LFP; <xref ref-type="bibr" rid="bib144">Victor et al., 1994</xref>), or calcium levels that can, for instance, be measured with fluorescent calcium indicators (<xref ref-type="bibr" rid="bib139">van Beest et al., 2021</xref>; <xref ref-type="bibr" rid="bib16">Bonin et al., 2011</xref>).</p><p>Noninvasive methods lack the spatial resolution to measure the RF properties of single neurons, but they can characterize the RF properties of the aggregate neural signals being measured. The retinotopic organization of the human brain has now been characterized with functional magnetic resonance imaging for decades (<xref ref-type="bibr" rid="bib147">Wandell et al., 2007</xref>; <xref ref-type="bibr" rid="bib148">Wandell and Winawer, 2011</xref>). Early studies used phase-encoding with ârotating wedgeâ and âexpanding or contracting ringâ stimuli to identify RF position (<xref ref-type="bibr" rid="bib41">Engel, 2012</xref>; <xref ref-type="bibr" rid="bib40">Engel et al., 1994</xref>; <xref ref-type="bibr" rid="bib125">Sereno et al., 1995</xref>), while later studies increasingly used the âpopulation receptive fieldâ (pRF) method that estimates RF size in addition to position (<xref ref-type="bibr" rid="bib34">Dumoulin and Wandell, 2008</xref>; <xref ref-type="bibr" rid="bib147">Wandell et al., 2007</xref>; <xref ref-type="bibr" rid="bib149">Wandell and Winawer, 2015</xref>; <xref ref-type="bibr" rid="bib148">Wandell and Winawer, 2011</xref>). The method is popular and has been used to map a range of visual and cognitive functions (<xref ref-type="bibr" rid="bib14">Binda et al., 2018</xref>; <xref ref-type="bibr" rid="bib37">Ekman et al., 2020</xref>; <xref ref-type="bibr" rid="bib62">Harvey et al., 2020</xref>; <xref ref-type="bibr" rid="bib61">Harvey et al., 2015</xref>; <xref ref-type="bibr" rid="bib63">He et al., 2019</xref>; <xref ref-type="bibr" rid="bib71">Hughes et al., 2019</xref>; <xref ref-type="bibr" rid="bib98">Mo et al., 2018</xref>; <xref ref-type="bibr" rid="bib108">Poltoratski et al., 2019</xref>; <xref ref-type="bibr" rid="bib109">Poltoratski and Tong, 2020</xref>; <xref ref-type="bibr" rid="bib112">Puckett et al., 2020</xref>; <xref ref-type="bibr" rid="bib126">Shao et al., 2013</xref>; <xref ref-type="bibr" rid="bib127">Shen et al., 2020</xref>; <xref ref-type="bibr" rid="bib131">Silson et al., 2018</xref>; <xref ref-type="bibr" rid="bib134">Stoll et al., 2020</xref>; <xref ref-type="bibr" rid="bib138">Thomas et al., 2015</xref>; <xref ref-type="bibr" rid="bib151">Welbourne et al., 2018</xref>; <xref ref-type="bibr" rid="bib162">Zuiderbaan et al., 2017</xref>), dysfunctions (<xref ref-type="bibr" rid="bib1">Ahmadi et al., 2020</xref>; <xref ref-type="bibr" rid="bib3">Alvarez et al., 2020</xref>; <xref ref-type="bibr" rid="bib29">de Best et al., 2019</xref>; <xref ref-type="bibr" rid="bib35">Dumoulin and Knapen, 2018</xref>; <xref ref-type="bibr" rid="bib54">Green et al., 2019</xref>; <xref ref-type="bibr" rid="bib123">Schwarzkopf et al., 2014</xref>), mechanisms of brain development (<xref ref-type="bibr" rid="bib30">Dekker et al., 2019</xref>), cortical evolution (<xref ref-type="bibr" rid="bib77">Keliris et al., 2019</xref>; <xref ref-type="bibr" rid="bib83">Kolster et al., 2014</xref>; <xref ref-type="bibr" rid="bib160">Zhu and Vanduffel, 2019</xref>), and information transfer across different brain areas (<xref ref-type="bibr" rid="bib58">Haak et al., 2013</xref>).</p><p>The term âpRFâ highlights the analogy to neuronal RFs. It assumes that the blood-oxygen-level-dependent (BOLD) signal measured with fMRI reflects the aggregate response of a large population of neurons within a voxel. Indeed, pRFs of the human visual cortex are qualitatively similar to the RFs of single neurons or multi-unit activity (MUA) in animals (<xref ref-type="bibr" rid="bib34">Dumoulin and Wandell, 2008</xref>). However, most of the previous comparisons were between species, and between studies that used different techniques to measure pRFs/RFs (<xref ref-type="bibr" rid="bib10">Barlow et al., 1966</xref>; <xref ref-type="bibr" rid="bib68">Hubel and Wiesel, 1968</xref>). Exceptions are pRF studies based on intracranial recordings in human patients (<xref ref-type="bibr" rid="bib60">Harvey et al., 2013</xref>; <xref ref-type="bibr" rid="bib152">Winawer et al., 2013</xref>), which used a limited number of surface electrodes to measure ECoG or intracranial EEG, but not spiking activity. The pRFs derived from the LFP exhibited similar properties to pRFs derived from BOLD signals, including similar spatial summation characteristics (<xref ref-type="bibr" rid="bib152">Winawer et al., 2013</xref>). Another study compared BOLD-based pRFs in monkeys to the RF properties of single units in published work (<xref ref-type="bibr" rid="bib83">Kolster et al., 2014</xref>). Furthermore, <xref ref-type="bibr" rid="bib77">Keliris et al., 2019</xref> found that single-unit RFs in one of their monkeys were smaller than pRFs measured with BOLD and proposed another method to estimate RF sizes. Their study included MUA but not the LFP. A systematic within-species comparison of pRFs derived from BOLD, MUA, and LFP has however never been carried out.</p><p>Here, we fill that gap with extensive pRF modeling based on BOLD, MUA, and LFP signals in macaque monkeys. The question that neuronal signal forms the basis of the fMRI-BOLD signal has far-reaching consequences for the interpretation of human neuroimaging results and is therefore a topic of ongoing debate and rigorous investigation (<xref ref-type="bibr" rid="bib9">Arthurs and Boniface, 2002</xref>; <xref ref-type="bibr" rid="bib11">Bartels et al., 2008</xref>; <xref ref-type="bibr" rid="bib17">Boynton, 2011</xref>; <xref ref-type="bibr" rid="bib32">Drew, 2019</xref>; <xref ref-type="bibr" rid="bib39">Ekstrom, 2010</xref>; <xref ref-type="bibr" rid="bib52">Goense and Logothetis, 2008</xref>; <xref ref-type="bibr" rid="bib93">Logothetis, 2010</xref>; <xref ref-type="bibr" rid="bib91">Logothetis, 2003</xref>; <xref ref-type="bibr" rid="bib90">Logothetis et al., 2001</xref>; <xref ref-type="bibr" rid="bib92">Logothetis and Wandell, 2004</xref>; <xref ref-type="bibr" rid="bib94">Maier et al., 2008</xref>; <xref ref-type="bibr" rid="bib122">SchÃ¶lvinck et al., 2010</xref>; <xref ref-type="bibr" rid="bib132">Sirotin and Das, 2009</xref>; <xref ref-type="bibr" rid="bib152">Winawer et al., 2013</xref>; <xref ref-type="bibr" rid="bib153">Winder et al., 2017</xref>). Some studies reported that properties of the BOLD signal resemble features of both neuronal spiking and the LFP (<xref ref-type="bibr" rid="bib99">Mukamel et al., 2005</xref>; <xref ref-type="bibr" rid="bib103">Nir et al., 2007</xref>; <xref ref-type="bibr" rid="bib113">Rees et al., 2000</xref>), others that they resemble the LFP but not spiking (<xref ref-type="bibr" rid="bib12">Bartolo et al., 2011</xref>; <xref ref-type="bibr" rid="bib94">Maier et al., 2008</xref>; <xref ref-type="bibr" rid="bib102">Niessing et al., 2005</xref>; <xref ref-type="bibr" rid="bib146">Viswanathan and Freeman, 2007</xref>), and yet others that they resemble spiking rather than the LFP (<xref ref-type="bibr" rid="bib89">Lima et al., 2014</xref>). Here, we examine the degree to which pRFs based on the BOLD signal resemble pRFs based on spiking activity and distinct frequency bands of the LFP (<xref ref-type="bibr" rid="bib22">BuzsÃ¡ki, 2006</xref>; <xref ref-type="bibr" rid="bib21">BuzsÃ¡ki and Draguhn, 2004</xref>; <xref ref-type="bibr" rid="bib36">Einevoll et al., 2013</xref>; <xref ref-type="bibr" rid="bib142">van Kerkoerle et al., 2014</xref>). In nonhuman primates, we measured BOLD-pRFs using whole-brain fMRI and determined neuronal pRFs with large-scale neurophysiological recordings in V1 and V4 (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Besides showing the presence of retinotopic information throughout the brain based on the fMRI data, we could directly compare V1 and V4 pRFs obtained with fMRI and electrophysiology. This intraspecies comparison provides new insight into the neurophysiological basis of the BOLD-defined pRFs and offers a benchmark for visual field maps obtained with fMRI.</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Experimental setup and study design.</title><p>(<bold>A</bold>) Monkeys maintained fixation on a red dot while bars with high-contrast-moving checkerboards moved across the screen in eight different directions behind a virtual aperture (dashed line, not visible in the real stimulus). (<bold>B</bold>) Two animals performed the task in the MRI scanner. Two other animals were each implanted with 16 Utah arrays (1024 electrodes/animal) in the left visual cortex. The approximate locations of 14 V1 arrays (red) and 2 V4 arrays (blue) for one animal are depicted on the NMT standard macaque brain. For more detailed array configurations, see <xref ref-type="bibr" rid="bib25">Chen et al., 2020</xref>. (<bold>C</bold>) Four population receptive field (pRF) models were fit to the data, differing in their pRF parameters (location: x, y; size: Ï) and spatial summation characteristics. The difference-of-Gaussians (DoG) pRFs are described by an excitatory center and an inhibitory surround (both 2D Gaussians with Ï<sub>1</sub> and Ï<sub>2</sub> as size parameters; dark and light gray circles in the left panel, respectively). Other models fitted single Gaussians that were either constrained to be positive (second panel: solid line) or allowed to be negative (unconstrained linear U-LIN, dashed line). The compressive spatial summation (CSS) model implemented nonlinear spatial summation across the receptive field (RF) (fourth panel: dashed line), while all other models implemented linear summation (solid line). (<bold>D</bold>) The pRF model fitting procedure. A model pRF is multiplied with an âaperture versionâ of the bar stimulus to generate a predicted response. For fMRI data, this prediction was convolved with a monkey-specific hemodynamic response function (HRF). The difference between the recorded neural signal (blood-oxygen-level-dependent [BOLD], multi-unit activity [MUA], local field potential [LFP]) and the predicted response was minimized by adjusting the pRF model parameters. (<bold>E</bold>) Examples of data and model fits for a V1 voxel (top panel) and a V1 electrode (middle and bottom panels). Average activity (gray data points) depicts the BOLD signal (top), MUA (middle), and LFP power in the low gamma band (bottom). Black lines are the model fits for a P-LIN pRF model. Light and dark gray areas depict visual stimulation periods (bar sweeps as indicated by the icons above). In the white epochs, the animals viewed a uniform gray background to allow the BOLD signal to return to baseline (these epochs were not necessary in the electrophysiology recordings). Note that that in MRI trials the bar stimuli had a lower speed (1 TR or 2.5 s per stimulus location) than during electrophysiology (500 ms per stimulus location).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig1-v3.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1âfigure supplement 1.</label><caption><title>Comparison of hemodynamic response functions (HRFs).</title><p>(<bold>A</bold>) Population receptive field (pRF) models were fit to the blood-oxygen-level-dependent (BOLD) response with a monkey-specific (see Materials and methods) and a canonical HRF provided by the analyzePRF toolbox. The monkey HRF (black line) had a faster decay and more pronounced negative component than the canonical HRF (gray line). (<bold>B</bold>) The choice of HRF had a relatively small effect on the R<sup>2</sup> of the models. The color map in this binned scatterplot (1 Ã 1% bins) indicates the number of voxels. For the P-LIN and compressive spatial summation (CSS) models, there was a small but significant advantage of using the specific monkey HRF over a canonical HRF in terms of the percentage of variance explained (Wilcoxon signed-rank, P-LIN: z = 8.41, p&lt;0.0001; CSS: z = 16.39, p&lt;0.0001). For the difference-of-Gaussians (DoG) model, the canonical HRF fits were consistently better in all areas except for the early visual areas, resulting in a significant advantage across all voxels overall (z = â29.79, p&lt;0.0001). For the U-LIN model, the difference between HRFs was not significant for the analysis across all voxels (z = 0.97, p=0.33). In all cases, however, the effect sizes were very small (mean<sub>(mHRF-dHRF)</sub> Â± standard deviation, P-LIN: 0.09% Â± 1.92%; U-LIN: 0.04% Â± 2.01%; CSS: 0.16% Â± 1.83%; DoG: â0.11 Â± 2.12%) and the estimated pRF sizes and locations were highly comparable across HRFs (Size<sub>(mHRF-dHRF)</sub>, P-LIN: â0.07 Â± 1.10 dva; U-LIN: â0.05 Â± 1.68 dva; CSS: â0.19 Â± 7.66 dva; DoG: â0.19 Â± 1.68 dva; Eccentricity<sub>(mHRF-dHRF)</sub>, P-LIN: â0.07 Â± 2.13 dva; U-LIN: â0.09 Â± 2.30 dva; CSS: â0.02 Â± 1.93 dva; DoG: â0.08 Â± 2.43 dva). For this reason, we only included the results obtained with the faster monkey-specific HRF in post-fit analyses of the MRI results. (<bold>C</bold>) Mean difference in R<sup>2</sup> value between the HRFs for all models and regions of interest (ROIs). The monkey HRF produced slightly better fits in early visual areas for all models. For the DoG model, the canonical HRF fit slightly better in higher cortical areas. Number in lower-left corner is the mean R<sup>2</sup> difference (HRF<sub>monkey</sub> - HRF<sub>canonical</sub>) Â± standard deviation.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig1-figsupp1-v3.tif"/></fig></fig-group><p>The original method of estimating pRFs from BOLD responses (<xref ref-type="bibr" rid="bib34">Dumoulin and Wandell, 2008</xref>) uses a forward modeling approach to fit the location and size of a symmetrical two-dimensional Gaussian to the BOLD responses. This approach is often used to predict neuronal activity elicited by moving bar-shaped stimuli. The RF model minimizes the difference between measured and predicted responses by multiplying the pRF with the stimulus and convolving the result with a hemodynamic response function (HRF), which accounts for the time course of neurovascular coupling (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Later refinements implemented a difference-of-Gaussians pRF profile (DoG) to account for center-surround interactions (<xref ref-type="bibr" rid="bib161">Zuiderbaan et al., 2012</xref>; <xref ref-type="fig" rid="fig1">Figure 1C</xref>), with substantial improvements in early visual cortex. Another refinement is the introduction of a static nonlinearity that models nonlinear spatial summation across RFs (<xref ref-type="bibr" rid="bib19">Britten and Heuer, 1999</xref>; <xref ref-type="bibr" rid="bib76">Kay et al., 2013</xref>; <xref ref-type="bibr" rid="bib104">Oleksiak et al., 2011</xref>; <xref ref-type="bibr" rid="bib152">Winawer et al., 2013</xref>). In such a model, the best parameters indicate subadditive spatial summation in all visual areas (<xref ref-type="bibr" rid="bib76">Kay et al., 2013</xref>). This means that if stimulus S<sub>1</sub> elicits a response R<sub>1</sub> and a nonoverlapping stimulus S<sub>2</sub> elicits response R<sub>2</sub>, the response to the combined stimulus, S<sub>1</sub> + S<sub>2</sub>, is smaller than the sum, R<sub>1</sub> + R<sub>2</sub>. For this reason, the nonlinear spatial summation model has also been called the âcompressive spatial summationâ (CSS) model. A third extension has been the modeling of negative pRFs. Standard approaches tend to only include voxels that show increases in the BOLD signal in response to a stimulus. The inclusion of ânegativeâ pRFs with decreased BOLD activity has revealed the retinotopic organization of a number of areas in the so-called default mode network (DMN) (<xref ref-type="bibr" rid="bib136">Szinte and Knapen, 2020</xref>). In our analysis of pRFs based on BOLD, MUA, and LFPs, we explored several pRF models, allowing us to investigate the potential presence of nonlinear spatial summation and negative pRFs.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>Four macaque monkeys (<italic>Macaca mulatta</italic>) participated in this study. They were rewarded with fluid for maintaining their gaze inside a 1.5Â° window around a fixation point that was presented at the center of a frontoparallel screen. While they fixated, a 2Â° wide bar containing full-contrast moving checkerboards traversed the screen in eight different directions (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Two animals performed this task in a 3T horizontal bore MRI scanner. Two other monkeys were each implanted with 1024 electrodes in the visual cortex (V1, V4). They performed the same task while neuronal activity (MUA and LFP) was recorded simultaneously from all electrodes. In the MRI setup, the stimulus covered 16Â° of the visual field, which was the maximum possible with the monitor located just outside of the scanner bore. The bar traveled across this screen in 20 steps of 2.5 s (1 TR). In the electrophysiology setup, the monitor was closer to the animal, allowing a visual field coverage of 28Â°. The stimulus bar moved across this aperture in 30 steps of 500 ms. For both the MRI and electrophysiology recordings, we only included data from epochs when the animals maintained fixation for &gt;80% of the time.</p><p>After preprocessing (see Materials and methods), we independently fit four pRF models to the average BOLD time courses. These models were (1) a linear pRF model constrained to have positive responses (P-LIN) (<xref ref-type="bibr" rid="bib34">Dumoulin and Wandell, 2008</xref>), (2) an unconstrained version of the linear pRF model that can also model negative responses (U-LIN), (3) a DoG pRF model (<xref ref-type="bibr" rid="bib161">Zuiderbaan et al., 2012</xref>), and (4) a nonlinear CSS pRF model (<xref ref-type="bibr" rid="bib76">Kay et al., 2013</xref>; <xref ref-type="fig" rid="fig1">Figure 1</xref>). We used the fitting method to determine pRF size, shape, and location. A cross-validated goodness of fit (R<sup>2</sup>) was determined by fitting the model to one half of the data and calculating R<sup>2</sup> using the other half of the data. Cross-validation allows the comparison of fit quality between models with different numbers of parameters.</p><sec id="s2-1"><title>pRFs measured with BOLD-fMRI</title><p>All models provided good fits to the BOLD time courses in a range of cortical and subcortical areas known to be involved in visual processing. For both monkeys (M1 and M2), we found robust retinotopic information in occipital, temporal, and parietal cortex (<xref ref-type="fig" rid="fig2">Figure 2</xref>). pRFs in all these areas were in the contralateral visual field and retinotopic maps were consistent with previous reports (<xref ref-type="fig" rid="fig2">Figure 2B</xref>), some of which were more extensive (<xref ref-type="bibr" rid="bib6">Arcaro et al., 2011</xref>; <xref ref-type="bibr" rid="bib7">Arcaro and Livingstone, 2017</xref>; <xref ref-type="bibr" rid="bib18">Brewer et al., 2002</xref>; <xref ref-type="bibr" rid="bib72">Janssens et al., 2014</xref>; <xref ref-type="bibr" rid="bib83">Kolster et al., 2014</xref>; <xref ref-type="bibr" rid="bib115">Rima et al., 2020</xref>; <xref ref-type="bibr" rid="bib160">Zhu and Vanduffel, 2019</xref>). Weaker and sparser retinotopic information was also observed in the frontal cortex, for example, around the arcuate sulcus (area 8, including the frontal eye fields [FEF]) and in the ventrolateral prefrontal cortex (VLPFC). Throughout this study, we will use a voxel inclusion criterion of R<sup>2</sup> &gt; 5% unless otherwise noted. While R<sup>2</sup> was generally much higher in visual areas (<xref ref-type="fig" rid="fig2">Figure 2A</xref>, bottom panel), this relatively low threshold also reveals retinotopic information in more frontal areas and some subcortical regions (where the signal picked up by surface coils has a lower signal-to-noise ratio [SNR]). <xref ref-type="fig" rid="fig2">Figure 2C</xref> shows the number of voxels within a range of areas for which the models explained more than 5% of the variance (<xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1</xref> shows the proportion per region of interest [ROI]). The functional parcellation of visual areas based on field sign inversions around horizontal and vertical meridians lined up well with a probabilistic atlas, co-registered to the individual animalâs anatomy (D99, <xref ref-type="bibr" rid="bib114">Reveley et al., 2017</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Population receptive field (pRF) model fits and retinotopic maps.</title><p>(<bold>A</bold>) R<sup>2</sup> value map of the compressive spatial summation (CSS) pRF model projected on the surface rendering of the brains of two monkeys (M1, M2). The lower panel illustrates that the R<sup>2</sup> value in the visual cortex is generally much higher than 5% (going up to ~90%). The color range in the upper panels also reveals the weaker retinotopic information elsewhere in the cortex. AS, arcuate sulcus; CS, central sulcus; IPS, intraparietal sulcus; LatS, lateral sulcus; LuS, lunate sulcus; STS, superior temporal sulcus. (<bold>B</bold>) Polar angle maps for both subjects from the CSS model, thresholded at R<sup>2</sup> &gt; 5%, displayed on the inflated cortical surfaces. Functional delineation of several visual areas is superimposed. FEF, frontal eye fields. (<bold>C</bold>) Number of (resampled) voxels with R<sup>2</sup> &gt; 5% per brain area and subject for each model. Note the logarithmic scale. See <xref ref-type="fig" rid="fig2s1">Figure 2âfigure supplement 1</xref> for proportions per region of interest (ROI), and <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref> for a table with all ROI abbreviations.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig2-v3.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2âfigure supplement 1.</label><caption><title>Proportion of voxels with R<sup>2</sup> &gt; 5% per region of interest (ROI).</title><p>For both animals (M1, M2) and all four population receptive field (pRF) models. This is supplement to <xref ref-type="fig" rid="fig2">Figure 2C</xref> that reports absolute numbers of voxels per area.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig2-figsupp1-v3.tif"/></fig></fig-group><p>Subcortically, we could segregate the lateral geniculate nucleus (LGN), pulvinar and some striatal regions from their surrounding areas on the basis of a higher R<sup>2</sup>. In both monkeys, the LGN of both hemispheres contained clear retinotopic maps (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). Retinotopic information was also evident in the bilateral pulvinar of M1, but some of the pRFs in the pulvinar of M2 were large and crossed the vertical meridian, resulting in noisy polar angle maps (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). Striatal retinotopy was less pronounced in M1 and even more variable in terms of polar angle maps (<xref ref-type="fig" rid="fig3s1">Figure 3âfigure supplement 1</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Retinotopy in the thalamus.</title><p>Thalamic population receptive fields (pRFs) in M1 (<bold>A</bold>) and M2 (<bold>B</bold>). The lateral geniculate nucleus (LGN, top rows) contained retinotopic maps of the contralateral visual field in both monkeys (M1: 38/38; M2: 73/80 voxels with contralateral pRFs). Retinotopic information was also present in the pulvinar (PULV, bottom rows), but its organization was much less structured, especially in M2 (M1: 23/32; M2: 61/131 voxels with contralateral pRFs). Voxels were thresholded at R<sup>2</sup> &gt; 3% for these polar angle visualizations due to the generally poorer fits in subcortex compared to visual cortex. Results from the compressive spatial summation (CSS) model are masked by region of interest (ROI) and shown both in a âglassâ representation of the individual animalsâ brains (left), and on selected sagittal and coronal slices (monkey-specific T1-weighted images, cross-hairs indicate slice positions). Dashed lines indicate the boundaries of the LGN and pulvinar.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig3-v3.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3âfigure supplement 1.</label><caption><title>Striatal population receptive fields (pRFs).</title><p>(<bold>A</bold>) In M2, the head of the caudate nucleus in the striatum contained retinotopic maps of the lower contralateral visual field. Neurons in the head of the caudate have long been known to play a role in processing visual information in a reward-related context (<xref ref-type="bibr" rid="bib64">Hikosaka et al., 1989a</xref>; <xref ref-type="bibr" rid="bib65">Hikosaka et al., 1989b</xref>; <xref ref-type="bibr" rid="bib116">Rolls et al., 1983</xref>). (<bold>B</bold>) In the more posterior striatum of M2, retinotopic information was also present. While spatial preferences were more mixed here, there was a dominant representation of the ipsilateral visual field. (<bold>C</bold>) Voxels in the right nucleus accumbens (NAc) have ipsilateral pRFs. The right NAc in the ventral striatum (green outline) is retinotopically tuned in both monkeys (only M2 shown). Although R<sup>2</sup> values are lower than in the cortex or thalamus, they stand out from the surrounding regions. Polar angle maps of the fitted pRFs indicate that the right NAc is tuned to visual information in the right (ipsilateral) visual field.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig3-figsupp1-v3.tif"/></fig></fig-group><p>We calculated cross-validated R<sup>2</sup> values to compare the four pRF models: P-LIN, U-LIN, DoG, and CSS (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). A comparison of model performance pooled over subjects and voxels confirmed that there were significant differences across models, with the CSS model outperforming the P-LIN model (KruskalâWallis test on all four models, H = 21.33, df = 3, p&lt;0.0001; post-hoc Tukeyâs HSD multiple comparisons of mean rank, R<sup>2</sup><sub>CSS</sub> &gt; R<sup>2</sup><sub>P-LIN</sub>, p&lt;0.0001). Indeed, the CSS model fit was better than that of P-LIN in all ROIs in M1 and in 38 out of 39 ROIs in M2 (Wilcoxon signed-rank, p&lt;0.05; no difference in premotor area F7 in M2) (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Since the CSS model also provided the best fits for the neurophysiological signals (described later), we report results from this model and only extend the analysis to other models where this is useful (e.g., in the case of negative gain values). The advantage of the CSS model over the P-LIN model generally increased in higher visual areas (<xref ref-type="fig" rid="fig4s1">Figure 4âfigure supplement 1</xref>).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Comparison of the four population receptive field (pRF) models.</title><p>(<bold>A</bold>) Comparison across pRF models. R<sup>2</sup> data are in bins of 1% Ã 1%, and color indicates the number of voxels per bin. The compressive spatial summation (CSS) model fits the data best, while U-LIN and difference-of-Gaussians (DoG) models give better fits for voxels that are poorly characterized by the P-LIN model (arrows). Dashed triangle, voxels for which R<sup>2</sup> of the U-LIN/DoG models was at least 5% higher than that of the P-LIN model. (<bold>B</bold>) Gain values of the U-LIN pRF fits for all voxels (black) and the voxels in the gray triangle in (<bold>A</bold>.) The negative gain values indicate visual suppression of the blood-oxygen-level-dependent (BOLD) signal. Arrows, medians. (<bold>C</bold>) Clusters of voxels for which the U-LIN model fit better than the P-LIN model were located in the medial occipital lobe (left panel). The pRFs of these voxels had a high eccentricity according to the P-LIN model, beyond the stimulated visual field. (<bold>D</bold>) Clusters of voxels with negative pRFs in the U-LIN model (without positive pRFs in the P-LIN model) were present around the lateral sulcus (LatS), in the medial occipital parietal cortex (mOP) and in the lateral occipital parietal cortex (lOP).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig4-v3.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4âfigure supplement 1.</label><caption><title>Comparison of fit performance across pRF models.</title><p>(<bold>A, B</bold>) Fit accuracy advantage of compressive spatial summation (CSS) and difference-of-Gaussians (DoG) models across brain areas. Both the CSS (<bold>A</bold>) and DoG (<bold>B</bold>) models had better fits (cross-validated R<sup>2</sup>) than the P-LIN model across virtually all brain regions with retinotopic information in both monkeys. (<bold>C</bold>) Comparison of R<sup>2</sup> across population receptive field (pRF) models for both monkeys. Data are in R<sup>2</sup> bins of 1% Ã 1%. Colors represent number of voxels per bin. The CSS model fits best across the board. The U-LIN and DoG models give good fits for voxels that are poorly characterized by the P-LIN model (arrows). Voxels for which the cross-validated R<sup>2</sup> of the U-LIN or DoG models was &gt;5% and at least 5% higher than that of the P-LIN or CSS are indicated by the dashed triangle.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig4-figsupp1-v3.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4âfigure supplement 2.</label><caption><title>Location of negative pRFs.</title><p>(<bold>A</bold>) Normalized amplitude of the suppressive surround Gaussian of difference-of-Gaussians (DoG) model fits (R<sup>2</sup> &gt; 5%). Values larger than 1 (blue tints) indicate that the amplitude of suppressive surround was larger than that of the excitatory center. The right hemisphere of M1 is shown as an example. Voxels with a strong suppressive component were in the medial occipital and parietal cortices, and around the lateral sulcus. (<bold>B</bold>) Gain value of the of U-LIN fits for voxels with R<sup>2</sup> &gt; 5%. Green tints represent positive gain values, blue tints indicate suppressive blood-oxygen-level-dependent (BOLD) responses. Negative gain values occur for the same voxels that have a strong suppressive surround in (<bold>A</bold>), indicating that the activity of these voxels is suppressed by visual stimuli.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig4-figsupp2-v3.tif"/></fig></fig-group><p>The static nonlinearity parameter, or âpRF exponentâ that models the nonlinearity of spatial summation (Materials and methods: <xref ref-type="disp-formula" rid="equ4">Equation 4</xref>), was in the range of 0.2â0.4 and significantly below 1 in all areas (Wilcoxon signed-rank, one-tailed, all ROIs with more than four voxels R<sup>2</sup> &gt; 5%, p&lt;0.001). These values of the pRF exponent represent subadditive (compressive) spatial summation, in accordance with observations in the human visual cortex (<xref ref-type="bibr" rid="bib76">Kay et al., 2013</xref>; <xref ref-type="bibr" rid="bib152">Winawer et al., 2013</xref>). The pRF exponent in early visual cortex is comparable to previously reported values for human V1. The exponent value in higher visual areas was similar to that in early visual cortex of the two monkeys, and higher than previously observed in human extrastriate cortex, which suggests that spatial suppression is less pronounced in higher areas of the monkey visual cortex than in higher areas of the human visual cortex.</p><p>Both the U-LIN model and the DoG model also performed better than the standard P-LIN model (KruskalâWallis, Tukeyâs HSD, both ps&lt;0.0001). The DoG had slightly better fits across all pooled voxels than the U-LIN model (KruskalâWallis, Tukeyâs HSD, p&lt;0.0001). The advantage of the DoG model over the P-LIN model was most pronounced in V1 and decreased in higher visual areas.</p></sec><sec id="s2-2"><title>Negative pRFs from suppressed BOLD responses</title><p>There was a subset of voxels with negative BOLD responses for which both the U-LIN and DoG models provided much better pRF fits than the P-LIN and CSS models (arrows in <xref ref-type="fig" rid="fig4">Figure 4A</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4âfigure supplement 1C</xref>). We inspected the voxels for which the R<sup>2</sup> in the U-LIN/DOG models was at least 5% higher than in the P-LIN model (gray, dashed triangles in <xref ref-type="fig" rid="fig4">Figure 4A</xref>). The U-LIN model estimated a negative gain for these voxels (median gain = â0.31, Wilcoxon signed-rank, one-tailed, z = â43.9, p&lt;0.0001) (<xref ref-type="fig" rid="fig4">Figure 4B</xref>) and the DoG model returned a high level of inhibition (median normalized suppressive amplitude = 1.14, interquartile range [IQR], 0.98â1.29).</p><p>There were two categories of voxels with negative responses (<xref ref-type="fig" rid="fig4s2">Figure 4âfigure supplement 2</xref>). For the first category of voxels, the P-LIN model estimated pRFs outside the boundaries of the stimulated visual field. This result suggests that the negative response represents surround suppression that is particularly strong around the fovea (<xref ref-type="bibr" rid="bib125">Sereno et al., 1995</xref>; <xref ref-type="bibr" rid="bib129">Shmuel et al., 2006</xref>; <xref ref-type="bibr" rid="bib133">Smith et al., 2004</xref>). The retinotopy of these voxels is consistent with this explanation. In V1, for instance, the voxels were on the medial side of the occipital pole, which represents the peripheral visual field (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). The second category of voxels with negative pRFs appeared to be different. Here, P-LIN and CSS models could not fit any pRF, suggesting purely negative BOLD responses. These voxels were primarily located in the medial occipital parietal cortex (mOP), at the superior border of the superior temporal sulcus in the lateral occipital parietal cortex (lOP) and around the lateral sulcus (LatS), which includes parts of the insula, cingulate, parietal, and premotor cortices (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). These areas have all previously been identified as being part of the monkey DMN (<xref ref-type="bibr" rid="bib95">Mantini et al., 2011</xref>). This finding aligns with recent research in humans that revealed similar negatively tuned pRFs in corresponding nodes of the human DMN (<xref ref-type="bibr" rid="bib136">Szinte and Knapen, 2020</xref>).</p></sec><sec id="s2-3"><title>pRF size as a function of eccentricity</title><p>As expected, pRF sizes were larger at higher eccentricities. This relationship was evident in all areas with larger numbers of well-fit voxels. pRFs were also larger in higher areas, which exhibited a steeper slope of the eccentricity-size relationship (<xref ref-type="fig" rid="fig5">Figure 5</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5âfigure supplements 1</xref> and <xref ref-type="fig" rid="fig5s2">2</xref>). The differences between the slopes in V1 and V2 are smaller than expected based on previous electrophysiological studies, but this is not uncommon with fMRI (<xref ref-type="bibr" rid="bib76">Kay et al., 2013</xref>). In one animal, we also unexpectedly observed retinotopy in a number of higher areas, such as the anterior cingulate cortex (<xref ref-type="fig" rid="fig5s1">Figure 5âfigure supplements 1</xref> and <xref ref-type="fig" rid="fig5s2">2</xref>). This brain region has been studied predominantly in the context of decision-making (<xref ref-type="bibr" rid="bib5">Amiez et al., 2006</xref>; <xref ref-type="bibr" rid="bib45">Fouragnan et al., 2019</xref>), but it does have resting state correlations with V1 (<xref ref-type="bibr" rid="bib56">Griffis et al., 2017</xref>). Our design lacked the power for a more detailed investigation of this retinotopic organization, but this result may inspire future work on brain-wide retinotopic tuning.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Population receptive field (pRF) size as a function of eccentricity according to the compressive spatial summation (CSS) model.</title><p>(<bold>A</bold>) Eccentricity-size relationship for early and mid-level visual areas. (<bold>B</bold>) Eccentricity-size relationship for areas in the temporal and parietal lobes. (<bold>C</bold>) Eccentricity-size relationship for subcortical areas. (<bold>D</bold>) Eccentricity-size relationship for frontal cortical areas. Data points are pRF sizes binned in 2-dva-eccentricity bins; error bars denote SEM. Lines are linear fits with a significant slope (p&lt;0.01). Slope values are shown between square brackets in the legend. The dashed line that separates the white and gray areas indicates the extent of the visual stimulus used to estimate pRFs. Data points in the gray regions come for pRFs that fell partially outside the region with a visual stimulus. The small panels show the same data for individual areas and include confidence intervals of the linear fit (shaded red area). Numbers denote the number of voxels per animal. The displayed areas were selected based on the presence of at least 20 voxels in each animal, with R<sup>2</sup> &gt; 5% for (<bold>A, B</bold>) and R<sup>2</sup> &gt; 3% for (<bold>C, D</bold>) due to the generally lower fit quality in the subcortex and frontal lobe. <xref ref-type="fig" rid="fig5s1">Figure 5âfigure supplements 1</xref> and <xref ref-type="fig" rid="fig5s2">2</xref> plot all suprathreshold voxels.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig5-v3.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5âfigure supplement 1.</label><caption><title>Eccentricity-size relationship for all regions of interest (ROIs).</title><p>Linear fits (intercept and slope) to the eccentricity-size relationship per brain area. Shaded areas indicate the 95% confidence interval of the fit, <italic>n</italic> denotes the number of voxels (R<sup>2</sup> &gt; 5%). Linear fits in red have a significant slope (p&lt;0.05). Small data points indicate population receptive fields (pRFs) for individual voxels (M1 in blue, M2 in black) while larger data points with error bars indicate binned averages (2 dva bins) over all voxels. The dotted vertical line indicates the extent of the visual stimulus.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig5-figsupp1-v3.tif"/></fig><fig id="fig5s2" position="float" specific-use="child-fig"><label>Figure 5âfigure supplement 2.</label><caption><title>Eccentricity-size relationship for all regions of interest (ROIs).</title><p>Linear fits (intercept and slope) to the eccentricity-size relationship per brain area. Shaded areas indicate the 95% confidence interval of the fit, <italic>n</italic> denotes the number of voxels (R<sup>2</sup> &gt; 3%). Linear fits in red have a significant slope (p&lt;0.05). Small data points indicate population receptive fields (pRFs) for individual voxels (M1 in blue, M2 in black) while larger data points with error bars indicate binned averages (2 dva bins) over all voxels. The dotted vertical line indicates the extent of the visual stimulus.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig5-figsupp2-v3.tif"/></fig></fig-group></sec><sec id="s2-4"><title>Multi-unit spiking activity RFs</title><p>We determined the RFs of MUA recorded with chronically implanted electrode arrays (Utah arrays) in areas V1 and V4 in two additional monkeys (M3 and M4) that did not participate in the fMRI experiments. We used a 1024-channel cortical implant, consisting of a titanium pedestal that was connected to 16 Utah arrays (<xref ref-type="bibr" rid="bib119">Rousche and Normann, 1998</xref>). Each Utah array had 8 Ã 8 shanks with a length of 1.5 mm. In both monkeys, 14 arrays were placed in V1 and 2 in V4 of the left hemisphere (<xref ref-type="fig" rid="fig6">Figure 6</xref>). The stimulus was similar to that used in the fMRI experiments with some small differences due to constraints of the two setups (in the electrophysiology setup, the stimulus covered a larger portion of the visual field because the screen was closer to the animal) and the intrinsic nature of the recorded signals (stimulus steps were faster in the electrophysiology experiments because the electrophysiology signals are much faster than the BOLD response). We fit the four pRF models to the MUA responses and to the LFP power in five distinct frequency bands. We compared the MUA pRFs to a more conventional MUA RF-mapping method (cRFs). For this cRF method, we selected channels with an SNR larger than 3 (i.e., visual responses that were more than three times larger than the standard deviation of the spontaneous activity) and derived the RF borders from the onset and offset of the neuronal activity elicited by a smoothly moving light bar (see Materials and methods). Whenever both methods were able to estimate a pRF and cRF (R<sup>2</sup> &gt; 25% for the pRF method, SNR &gt; 3 and R<sup>2</sup> &gt; 25% for the cRF method), the estimated locations were highly similar (median distance between pRF and cRF center, V1: 0.34, IQR 0.18â0.49 dva; V4: 0.90, IQR 0.40â1.41 dva). Compared to the P-LIN pRF model, the moving bar method estimated smaller cRFs (median size difference <italic>pRF<sub>sz</sub>-cRF<sub>sz</sub></italic>: 0.50, IQR: 0.08â0.92) (<xref ref-type="fig" rid="fig7">Figure 7</xref>). The CSS model, however, returned pRF size estimates that were very similar to the cRF sizes or even a little bit smaller (median size difference <italic>pRF<sub>sz</sub>-cRF<sub>sz</sub></italic>: â0.13; IQR: â0.41â0.14), suggesting that nonlinear spatial summation might indeed be better at capturing the RF properties of a small population of neurons than linear summation.</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Visual field coverage of population receptive fields (pRFs) with Utah arrays.</title><p>(<bold>A</bold>) In both monkeys (M3, M4), 14 Utah arrays were implanted on the left operculum that is partly V1. Different colors represent the center of multi-unit activity (MUA)-based pRFs for the individual arrays. Only electrodes with R<sup>2</sup> &gt; 50% in the compressive spatial summation (CSS) model are shown. (<bold>B</bold>) Same as in (<bold>A</bold>), but for V4 electrodes. Note the different scale in the lower-right panel, with the gray arc indicating the extent of the visual stimulus. See <xref ref-type="fig" rid="fig6s1">Figure 6âfigure supplement 1</xref> for pRF sizes.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig6-v3.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6âfigure supplement 1.</label><caption><title>Heatmaps of visual field coverage of the Utah arrays.</title><p>We reconstructed the multi-unit activity (MUA) population receptive fields (pRFs) with R<sup>2</sup> &gt; 50% in the compressive spatial summation (CSS) model in the visual field, normalized them to their peak value, and then summed them across recording sites. The resulting heatmap represents the visual field coverage of V1 and V4 recording sites. The color scale represents the number of pRFs. See <xref ref-type="fig" rid="fig6">Figure 6</xref> for individual pRF locations.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig6-figsupp1-v3.tif"/></fig></fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Comparison of multi-unit activity (MUA) population receptive field (pRF) sizes with conventionally determined RF (cRF) sizes (moving bar stimulus).</title><p>Data points represent recording sites of individual animals (black: M3; blue: M4) and brain areas (closed circles: V1; open circles: V4). (<bold>A</bold>) pRF sizes estimated with the P-LIN model (X-axis in left panel) are larger than cRF sizes obtained with a thin moving luminance bar (Y-axis in left panel). The median difference between pRF and cRF sizes across all electrodes (pooled across animals and areas) was 0.50 (interquartile range [IQR]: 0.08â0.92) and the median ratio was 1.41 (IQR: 0.99â1.83), as shown in the top and bottom-right panels, respectively. (<bold>B</bold>) As in (<bold>A</bold>), but for pRF sizes estimated with the compressive spatial summation (CSS) model, which are slightly smaller than the cRFs (median difference: â0.13, IQR: â0.41â0.14; median ratio 0.90, IQR: 0.67â1.12).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig7-v3.tif"/></fig><p>The pRF models that were used in this study are all based on circular (symmetric) RFs. A recent study (<xref ref-type="bibr" rid="bib131">Silson et al., 2018</xref>) suggested that pRFs in human early visual cortex might be elliptical rather than circular, although this suggestion goes against previous work (<xref ref-type="bibr" rid="bib55">Greene et al., 2014</xref>; <xref ref-type="bibr" rid="bib96">Merkel et al., 2018</xref>; <xref ref-type="bibr" rid="bib159">Zeidman et al., 2018</xref>). A later study demonstrated that the elliptical fits were an artifact of the software that had been used in the analysis (<xref ref-type="bibr" rid="bib86">Lerma-Usabiaga et al., 2021</xref>). The cRF method separately estimates the width and height of the RF, and can thus be used to calculate a simplified RF aspect ratio to investigate RF symmetry. While this measure differs from RF ellipticity (a 45Â° tilted ellipse has the same aspect ratio as a circle), it does provide some insight into the symmetry of the MUA RFs. We did observe a few cRFs with aspect ratios (Ï<sub>large</sub>/Ï<sub>small</sub>) that were larger than 2 (M3: 18/753; M4: 10/527; together 2.2% of all cRFS), but the vast majority of cRFs in both animals had aspect ratios close to 1 (M3 median: 1.12, IQR: 1.04â1.20; M4 median 1.13, IQR: 1.03â1.22) indicating near-symmetric RFs.</p><p>We obtained excellent fits to the MUA for all pRF models (see <xref ref-type="fig" rid="fig1">Figure 1E</xref> for an example fit). These pRFs covered a large proportion of the lower-right visual field (<xref ref-type="fig" rid="fig6">Figure 6</xref>, <xref ref-type="fig" rid="fig6s1">Figure 6âfigure supplement 1</xref>). As expected, the pRFs from electrodes of the same arrays (shown in the same color in <xref ref-type="fig" rid="fig6">Figure 6</xref>) were clustered in space, and their locations were in accordance with established retinotopy (e.g., <xref ref-type="bibr" rid="bib69">Hubel and Wiesel, 1974</xref>). The average R<sup>2</sup> (over all electrodes with R<sup>2</sup> &gt; 0) was 64% in V1 (M3: 54%; M4: 73%) and 53% in V4 (M3: 37%; M4: 68%), which is substantially higher than the average R<sup>2</sup> of 11% in both V1 and V4 for the MRI data (all voxels with R<sup>2</sup> &gt; 0; V1 M1: 14%, M2: 8%; V4 M1: 14%, M2: 8%).</p><p>Cross-validated comparisons revealed significant differences between the four models (KruskalâWallis test on all four models: H<sub>V1</sub> = 204, df<sub>V1</sub> = 3, p<sub>V1</sub> &lt; 0.0001; H<sub>V4</sub> = 13.4, df<sub>V4</sub> = 3, p<sub>V4</sub> &lt; 0.01) (<xref ref-type="fig" rid="fig8">Figure 8</xref>; similar patterns were present in each individual animal). Post-hoc pairwise comparisons (Tukeyâs HSD) revealed that the CSS and DoG models provided a better fit than the linear models, although for V4 the advantage of the CSS model over the P-LIN model was only significant when electrodes with a poor fit (R<sup>2</sup> &lt; 25%) were excluded (V1, all electrodes: CSS vs. P-LIN, p&lt;0.001, DoG vs. P-LIN, p&lt;0.001; V4, all electrodes: CSS vs. P-LIN, p=0.16, DoG vs. P-LIN, p&lt;0.001; V1, electrodes with R<sup>2</sup> &gt; 25%: CSS vs. P-LIN, p&lt;0.001, DoG vs. P-LIN, p&lt;0.001; V4, electrodes with R<sup>2</sup> &gt; 25%: CSS vs. P-LIN, p&lt;0.02, DoG vs. P-LIN, p&lt;0.01) (<xref ref-type="fig" rid="fig8">Figure 8</xref>). The improved fit of the DoG model was caused by the suppressive surround (median normalized suppressive amplitude = 0.71, IQR 0.56â0.86).</p><fig-group><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Comparison of multi-unit activity (MUA)-based fit results from the four population receptive field (pRF) models.</title><p>Scatterplots compare R<sup>2</sup> of pRF models. Each dot represents an electrode (black: V1; green: V4).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig8-v3.tif"/></fig><fig id="fig8s1" position="float" specific-use="child-fig"><label>Figure 8âfigure supplement 1.</label><caption><title>Comparison of local field potential (LFP) fits for the four population receptive field (pRF) models in V1.</title><p>Scatterplots compare R<sup>2</sup> across pRF models and LFP frequency bands. Each dot represents an electrode. For a subset of electrodes, the pRF models that can capture negative responses (difference-of-Gaussians [DoG], U-LIN) fit better to the lower frequency components of the LFP (Î±, Î²) (e.g., arrows in leftmost column comparing P-LIN and U-LIN fits).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig8-figsupp1-v3.tif"/></fig><fig id="fig8s2" position="float" specific-use="child-fig"><label>Figure 8âfigure supplement 2.</label><caption><title>Comparison of local field potential (LFP)-based fit results from the four population receptive field (pRF) models in V4.</title><p>Scatterplots comparing R<sup>2</sup> across pRF models and LFP frequency bands. Each data point represents an electrode.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig8-figsupp2-v3.tif"/></fig><fig id="fig8s3" position="float" specific-use="child-fig"><label>Figure 8âfigure supplement 3.</label><caption><title>Comparison of population receptive field (pRF) fit accuracies for multi-unit activity (MUA) and local field potential (LFP) signals at the same recording sites.</title><p>(<bold>A</bold>) Comparison of R<sup>2</sup> values from the compressive spatial summation (CSS) model across electrophysiological signals. Colors indicate the number of recording sites in 4 Ã 4% bins (logarithmic scale). Asterisks denote significance (KruskalâWallis, with post-hoc Tukeyâs HSD multiple comparisons of mean rank, *p&lt;0.05, **p&lt;0.001). (<bold>BâD</bold>) Same as in (<bold>A</bold>) but for the P-LIN (<bold>B</bold>), U-LIN (<bold>C</bold>), and difference-of-Gaussians (DoG) models (<bold>D</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig8-figsupp3-v3.tif"/></fig></fig-group><p>The pRF exponent of the CSS model was 0.38 Â± 0.23 in V1 (mean Â± SD; 1358 electrodes with R<sup>2</sup> &gt; 25%), which was significantly smaller than 1 (Wilcoxon signed-rank, one-tailed, z = â31.59, p&lt;0.0001) and similar to the MRI-based values, which had a mean of 0.34 Â± 0.19 (6341 voxels). Likewise, in V4, MUA pRF exponent values were significantly smaller than 1 (0.33 Â± 0.19; z = 11.13, p&lt;0.0001; n = 165), and comparable to MRI-based values in the same area (0.30 Â± 0.16; n = 2324). The similarity in the values of the pRF exponent indicates that subadditive spatial summation is a prominent feature in these areas.</p><p>The size of the estimated MUA pRFs increased with eccentricity (<xref ref-type="fig" rid="fig9">Figure 9</xref>). However, the pRF sizes for two of the V1 arrays in both monkeys were approximately three times smaller than expected when compared to the data from the other arrays. These outlying arrays were located on the posterior-medial side of the surface of V1 in both monkeys where the gray matter is relatively thin (<xref ref-type="fig" rid="fig9">Figure 9A</xref>). We therefore suspect that the 1.5-mm-long shanks of the Utah arrays were pushed into the white matter, where they picked up activity of thalamic afferents (i.e., the geniculostriate pathway). We therefore excluded these electrodes from the analyses of pRF sizes. The remaining MUA pRF sizes and eccentricities were highly similar to RFs reported in previous electrophysiology studies at similar eccentricities (<xref ref-type="bibr" rid="bib49">Gattass et al., 1987</xref>; <xref ref-type="bibr" rid="bib48">Gattass et al., 1981</xref>; <xref ref-type="bibr" rid="bib141">Van Essen et al., 1984</xref>; <xref ref-type="bibr" rid="bib144">Victor et al., 1994</xref>). Next, we compared pRFs between the electrophysiological signals and the fMRI-BOLD signal.</p><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>V1 arrays with outlying population receptive field (pRF) sizes.</title><p>(<bold>A</bold>) Schematic representation of the location of the craniotomy made during surgery (dashed line) and the implanted electrode arrays (rectangles) depicted on the NMT standard brain. The color map indicates the thickness of the cortical gray matter of the NMT. (<bold>B</bold>) For both monkeys, the estimated pRF sizes of V1 electrode arrays in the posterior medial corner of the craniotomy (red and orange data points correspond to red and orange rectangles in panel <bold>A</bold>) were surprisingly small for their eccentricity compared to the size-eccentricity relationship seen in the other arrays (gray circles, linear fit with 95% CI as black line and gray area). Given the length of the electrodes (1.5 mm), the typical thickness of the striate cortex, and these small pRF sizes, it is likely that the outlying pRFs do not reflect the tuning of V1 neurons, but that of the geniculostriate pathway in the white matter. The pRF sizes were estimated by the compressive spatial summation (CSS) model (recording sites shown have R<sup>2</sup> &gt; 70%).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig9-v3.tif"/></fig></sec><sec id="s2-5"><title>Local field potential pRFs</title><p>The LFP was split into five frequency bands: Î¸ (4â8 Hz), Î± (8â16 Hz), Î² (16â30 Hz), Î³<sub>low</sub> (30â60 Hz), and Î³<sub>high</sub> (60â120 Hz). We fit the four models to estimate pRFs for each frequency band. The results for Î³<sub>low</sub> and Î³<sub>high</sub> resembled those for the MUA with high R<sup>2</sup> values for a large proportion of the electrodes (especially in V1). The CSS model again outperformed the other models, and we did not observe negative pRFs in these V1 and V4 regions (<xref ref-type="fig" rid="fig8s1">Figure 8âfigure supplements 1</xref> and <xref ref-type="fig" rid="fig8s2">2</xref>). Electrodes with good MUA-pRF fits usually also had good LFP-pRFs, but the opposite was not always true (<xref ref-type="fig" rid="fig8s3">Figure 8âfigure supplement 3</xref>). The pRFs in lower frequency bands differed. Whereas Î¸ generally yielded low R<sup>2</sup> values, Î± and Î² yielded good fits for a substantial number of electrodes. Interestingly, there were two classes of electrodes in these frequency bands. For the first class, the power increased with visual stimulation and CSS model fits were best. In contrast, the second class of electrodes had negative pRFs, that is, the stimulus suppressed power (<xref ref-type="fig" rid="fig8s1">Figure 8âfigure supplement 1</xref>). Given the few electrodes with good low-frequency LFP-pRFs in V4, we focused our analysis on the positive and negative responses on V1 (the split into positive/negative pRF was based on the parameters of the U-LIN model; <xref ref-type="fig" rid="fig10">Figure 10</xref>, <xref ref-type="fig" rid="fig10s1">Figure 10âfigure supplement 1</xref>).</p><fig-group><fig id="fig10" position="float"><label>Figure 10.</label><caption><title>Characteristics of local field potential (LFP)-Î± population receptive fields (pRFs) in V1 split by positive and negative gain values.</title><p>(<bold>A</bold>) Distribution of gain values for LFP-Î± pRFs of V1 electrodes estimated with the U-LIN model. Electrodes with positive gain pRFs are classified as Î±+, electrodes with negative gain pRFs as Î±-. (<bold>B, C</bold>) pRF eccentricities (<bold>B</bold>) and size (<bold>C</bold>) for Î±- and <italic>Î±</italic>+ electrodes (yellow shades). Colored boxes indicate interquartile range (IQR), and the median is shown as a thick horizontal line. Wilcoxon rank-sum tests were used for comparisons between Î±- and <italic>Î±</italic>+ electrodes. (<bold>D</bold>) Distance between the centers of LFP-Î± and LFP-Î³ pRFs from the same electrode, divided by the sum of their respective sizes. Values smaller than 1 indicate overlapping receptive fields. Nonshaded boxes are comparisons with LFP-Î³<sub>low</sub> pRFs, shaded boxes are comparisons with LFP-Î³<sub>high</sub> pRFs. (<bold>E</bold>) Difference in eccentricity between LFP-Î³ and LFP-Î± pRFs from the same electrodes (calculated as Ecc<sub>Î³</sub>-Ecc<sub>Î±</sub>). Positive values indicate that LFP-Î± pRFs are closer to fixation than LFP-Î³ pRFs. Wilcoxon signed-rank, one-tailed test (ÎEcc &gt; 0), for individual cases; Wilcoxon rank-sum test for comparisons between Î±- and <italic>Î±</italic>+ electrodes. See <xref ref-type="fig" rid="fig10s2">Figure 10âfigure supplement 2</xref> for a visualization of the shifts per recording site. (<bold>F</bold>) Eccentricity-size relationship for Î±- (left) and Î±+ (right) electrodes. Dots indicate individual electrodes. <xref ref-type="fig" rid="fig10s1">Figure 10âfigure supplement 1</xref> shows the same pattern of results for the LFP-Î² pRFs.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig10-v3.tif"/></fig><fig id="fig10s1" position="float" specific-use="child-fig"><label>Figure 10âfigure supplement 1.</label><caption><title>Characteristics of local field potential (LFP)-Î² population receptive fields (pRFs) in V1 split by positive and negative gain values.</title><p>(<bold>A</bold>) Distribution of gain values for LFP-Î² pRFs of V1 electrodes estimated with the U-LIN model. Recording sites with positive gain pRFs are classified as Î²+, sites with negative gain pRFs as Î²-. (<bold>B, C</bold>) pRF eccentricities (<bold>B</bold>) and size (<bold>C</bold>) for Î²- and Î²+ electrodes (yellow shades). Colored boxes indicate interquartile range (IQR), and the median is shown as a thick horizontal line. Wilcoxon rank-sum tests were used for comparisons between Î²- and Î²+ electrodes. (<bold>D</bold>) Distance between the centers of LFP-Î² and LFP-Î³ pRFs from the same electrode, divided by the sum of their respective sizes. Values smaller than 1 indicate overlapping receptive fields. Nonshaded boxes are comparisons with LFP-Î³<sub>low</sub> pRFs, shaded boxes are comparisons with LFP-Î³<sub>high</sub> pRFs. (<bold>E</bold>) Difference in eccentricity between LFP-Î³ and LFP- Î² pRFs from the same sites (calculated as Ecc<sub>Î³</sub>-Ecc<sub>Î±</sub>). Positive values indicate that LFP- Î² pRFs are closer to fixation than LFP-Î³ pRFs. Wilcoxon signed-rank, one-tailed test (ÎEcc &gt; 0), for individual cases; Wilcoxon rank-sum test for comparisons between Î²- and Î²+ electrodes. See <xref ref-type="fig" rid="fig10s2">Figure 10âfigure supplement 2</xref> for a visualization of the shifts per recording site. (<bold>F</bold>) Eccentricity-size relationship for Î²- (left) and Î²+ (right) electrodes. Dots indicate individual electrodes.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig10-figsupp1-v3.tif"/></fig><fig id="fig10s2" position="float" specific-use="child-fig"><label>Figure 10âfigure supplement 2.</label><caption><title>Negative population receptive fields (pRFs) based on low-frequency local field potential (LFP) components are shifted toward the fixation point compared to the positive pRFs based on the high-frequency LFP at the same recording site.</title><p>(<bold>A</bold>) Relative locations of pRFs derived from LFP-Î± (yellow) and LFP-Î³<sub>l</sub> (blue) of the same recording sites. (<bold>B</bold>) Relative locations of pRFs derived from LFP-Î² (green) and LFP-Î³<sub>l</sub> (blue) of the same recording sites. Data points from the same sites are connected with a gray line. The location of the fixation point is indicated with a black dot. The mean shift size Â± SEM is listed in each panel. The same data were used to calculate the eccentricity shifts that are summarized in <xref ref-type="fig" rid="fig10">Figure 10E</xref> and <xref ref-type="fig" rid="fig10s1">Figure 10âfigure supplement 1E</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig10-figsupp2-v3.tif"/></fig></fig-group><p>We observed a number of remarkable differences between the positive and negative pRFs. First, negative pRFs generally had lower eccentricities than positive pRFs (<xref ref-type="fig" rid="fig10">Figure 10B</xref>, <xref ref-type="fig" rid="fig10s1">Figure 10âfigure supplement 1B</xref>). Second, negative pRFs were larger than positive pRFs (<xref ref-type="fig" rid="fig10">Figure 10C</xref>, <xref ref-type="fig" rid="fig10s1">Figure 10âfigure supplement 1C</xref>). Third, there was a systematic difference in the distance from the Î³-pRF of the same electrode. Specifically, we calculated a âseparation indexâ by dividing the distance between the centers of the low- and high-frequency LFP-pRFs by their summed size estimates (SI = Distance/(Ï<sub>lf</sub> + Ï<sub>hf</sub>)). A separation index of less than 1 indicates pRF overlap. For both Î± and Î² power, the negative pRFs were farther from the Î³-pRFs than the positive pRFs (<xref ref-type="fig" rid="fig10">Figure 10D</xref>, <xref ref-type="fig" rid="fig10s1">Figure 10âfigure supplement 1D</xref>) and generally shifted in the direction of fixation (<xref ref-type="fig" rid="fig10">Figure 10E</xref>, <xref ref-type="fig" rid="fig10s1">Figure 10âfigure supplements 1E</xref> and <xref ref-type="fig" rid="fig10s2">2</xref>). These results suggest that the positive pRFs represent visually driven activity, whereas the negative pRFs signal a form of suppression that is strongest at smaller eccentricities, close to the fixation point. One possible explanation is that the monkeys directed attention to the fixation point, which may have caused a ring of suppression closely surrounding it. Another possibility is that the negative pRFs might be a consequence of small eye movements around the fixation point. The size of Î±-pRFs did not depend on eccentricity (<xref ref-type="fig" rid="fig10">Figure 10F</xref>), whereas the size of Î²-pRFs increased with eccentricity, although this relation was very weak for positive pRFs (<xref ref-type="fig" rid="fig10s1">Figure 10âfigure supplement 1F</xref>).</p><p>The pRFs derived from all electrophysiology signals on the same electrode had similar locations, with less than 1 dva between their centers on average (CSS model, <xref ref-type="fig" rid="fig11">Figure 11A</xref>). We next analyzed RF sizes, normalizing the size estimates to the MUA-cRF. All LFP-pRFs estimates were larger than MUA-pRFs, and lower frequency LFP components yielded larger pRFs than the higher frequencies (<xref ref-type="fig" rid="fig11">Figure 11B</xref>; we observed the same pattern present in each animal). The pRF exponent was well below 1 for all LFP components (V1 and V4 electrodes with R<sup>2</sup> &gt; 25%; Wilcoxon signed-rank, one-tailed &lt;1, p&lt;0.001) and smaller at lower frequencies, indicative of stronger CSS. We also compared the exponents to those of the MRI-pRFs. The exponent of the MRI was not significantly different from that of Î³<sub>low</sub> in V1, and both Î³<sub>low</sub> and Î³<sub>high</sub> in V4 (p&gt;0.05, <xref ref-type="fig" rid="fig11">Figure 11C</xref>). Differences between the MRI exponent and those of the other LFP bands were significant (V1: KruskalâWallis, H = 505.49, df = 6, p&lt;0.0001; V4: KruskalâWallis, H = 21.65, df = 3, p&lt;0.001; Tukeyâs HSD for multiple comparisons).</p><fig id="fig11" position="float"><label>Figure 11.</label><caption><title>Comparison of population receptive field (pRF) location and size of different electrophysiological signals at the same electrode, estimated by the compressive spatial summation (CSS) model.</title><p>(<bold>A</bold>) Median distance between receptive field (RF) estimates. Electrodes were only included if R<sup>2</sup> &gt; 25% (multi-unit activity [MUA], local field potential [LFP]) or signal-to-noise ratio (SNR) &gt; 3 (MUA-cRF). (<bold>B</bold>) RF size for the electrodes of (<bold>A</bold>), normalized to the MUA-cRF (dashed line). Horizontal lines indicate the median, colored rectangles depict the interquartile range (IQR). (<bold>C</bold>) pRF exponent from the CSS model (indicating nonlinearity of spatial summation). The horizontal dashed line indicates linear summation. The exponent was significantly lower than 1 for all signals. Gray arrows indicate signals for which the exponent did not significantly differ from that of the MRI pRFs. A similar pattern was present in the electrophysiological data of each animal.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig11-v3.tif"/></fig></sec><sec id="s2-6"><title>Comparison of pRF eccentricity-size relationship between fMRI and electrophysiology signals</title><p>We next compared the eccentricity-size relationship of the electrophysiological signals to that of the BOLD-fMRI pRFs using linear mixed models (LMMs) to evaluate the pRF estimates of the CSS model, separately for V1 and V4 (electrodes with R<sup>2</sup> &gt; 50% and R<sup>2</sup> &gt; 5% for MRI). We included voxels for which the pRF was in the lower-right visual quadrant where we had electrode coverage. In V1, positive eccentricity-size relationships existed for MRI, MUA, Î², Î³<sub>low</sub>, and Î³<sub>high</sub> (<xref ref-type="fig" rid="fig12">Figure 12A</xref>). We compared these signals with a single LMM, revealing an interaction between signal type and eccentricity (<italic>F</italic> = 14.44, df = 4, p&lt;0.0001), which indicated that the slopes differed. We further used pairwise LMMs to compare the slope of the MRI-pRFs to the electrophysiological signals with a significant eccentricity-size relationship. The fMRI eccentricity-size relationship was similar to that of MUA (<italic>F</italic> = 0.38, df = 1, p=0.54), whereas it was significantly different from all LFP signals (Î²: <italic>F</italic> = 7.97, df = 1, p&lt;0.01; Î³<sub>low</sub>, <italic>F</italic> = 20.02, df = 1, p&lt;0.001; Î³<sub>high</sub>, <italic>F</italic> = 20.05, df = 1, p&lt;0.001) (<xref ref-type="fig" rid="fig12">Figure 12C</xref>). We repeated this analysis in V4 (<xref ref-type="fig" rid="fig12">Figure 12B</xref>) where we had fewer electrodes. We obtained positive eccentricity-size slopes for MUA, Î³<sub>low</sub>, and Î³<sub>high</sub> but did not obtain fits of sufficient quality for the Î¸, Î±, and Î² bands. In contrast to V1, there was no clear difference across these signals (<italic>F</italic> = 1.11, df = 3, p=0.24). Pairwise comparisons with the MRI size-eccentricity relationship did not reveal a difference between those for Î³<sub>low</sub> (<italic>F</italic> = 0.36, df = 1, p=0.55), Î³<sub>high</sub> (<italic>F</italic> = 0.28, df = 1, p=0.60), or MUA (<italic>F</italic> = 2.40, df = 1, p=0.12). Because the visual field coverage in V4 differed between the two animals that were used for electrophysiology, we repeated the analysis in both individuals and observed similar results (not shown).</p><fig-group><fig id="fig12" position="float"><label>Figure 12.</label><caption><title>Eccentricity-size relationship for population receptive fields (pRFs) across signal types.</title><p>(<bold>A</bold>) The pRF size-eccentricity relation for V1 electrodes (compressive spatial summation [CSS] model, R<sup>2</sup> &gt; 50%). Dots are individual electrodes, colored lines represent the slope of the eccentricity-size relationship. The dashed black line represents the relationship for V1 MRI voxels with a pRF in the lower-right visual quadrant and an R<sup>2</sup> &gt; 5%. We only included signals with &gt;25 electrodes meeting the R<sup>2</sup> threshold. (<bold>B</bold>) Same as in (<bold>A</bold>), but now for the V4 electrodes and voxels. (<bold>C</bold>) Eccentricity-size slopes (left: V1; right: V4). The dashed line represents the slope for MRI-based pRFs with the 95% confidence interval depicted in gray shading. Colored rectangles indicate the 95% confidence intervals for the electrophysiological signals and the horizontal black line the slope estimate. The lower bound of the 95% confidence interval of the LFP-Î¸ is not visible. Asterisks indicate significant difference with the size-eccentricity relation of the MRI-based pRFs.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig12-v3.tif"/></fig><fig id="fig12s1" position="float" specific-use="child-fig"><label>Figure 12âfigure supplement 1.</label><caption><title>Cross-signal comparisons of population receptive field (pRF) eccentricity-size relationship.</title><p>(<bold>A</bold>) The results of the cross-signal comparisons of compressive spatial summation (CSS)-pRF-based eccentricity-size slopes for different data inclusion criteria. For the top row, we only included V1 and V4 voxels with pRFs in the lower-right visual field where we had electrode coverage. For the middle row, we only included voxels corresponding to the location of the electrode arrays. For the bottom row, we included all V1 and V4 voxels. Columns indicate different combinations of R<sup>2</sup> threshold level for inclusion of selected voxels and electrodes. The black dashed line and gray area indicate the slope and 95% CI for the MRI-based pRFs; black horizontal lines and colored boxes denote the estimated slope for electrophysiology signals and their 95% CI. Asterisks indicate a significant difference of the eccentricity-size relation between MRI and electrophysiology. (<bold>B</bold>) Summary table of the results in (<bold>A</bold>), for all electrophysiology signals. Blue dots indicate the inclusion criterion for which the eccentricity-size slope of the pRFs from an electrophysiology signal was not significantly different from that of the MRI signal.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-67304-fig12-figsupp1-v3.tif"/></fig></fig-group><p>To further investigate the robustness of these results, we repeated the analysis (1) with the inclusion of either all V1 and V4 voxels or a subset of the voxels in approximately the same anatomical location as the electrode arrays and (2) by varying the R<sup>2</sup>-based inclusion criteria for electrodes and voxels (<xref ref-type="fig" rid="fig12s1">Figure 12âfigure supplement 1</xref>). MUA-pRFs in V1 and V4 were generally similar to the BOLD-pRFs, although in V4 Î³<sub>low</sub> and Î³<sub>high</sub> also approximated the fMRI results in some of the comparisons.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>The current study conducted a systematic comparison of pRFs obtained with fMRI and electrophysiological recordings in V1 and V4 of awake behaving macaque monkeys. Within the same species, we fit several pRF models to seven different signal types (BOLD, MUA, and the power in five LFP frequency bands) to gain insight into the neuronal basis of MRI-BOLD-pRF measurements (<xref ref-type="bibr" rid="bib149">Wandell and Winawer, 2015</xref>). Our results demonstrate retinotopic tuning in many brain regions and the presence of negative pRFs in areas of the DMN. We found that subadditive spatial summation is a prominent feature of many measures of brain activity. Furthermore, the results establish a clear relationship between BOLD-pRFs and electrophysiologically determined pRFs, with MUA-pRFs being most similar to BOLD-pRFs (as discussed below).</p><sec id="s3-1"><title>Cortical and subcortical retinotopic tuning of the BOLD signal</title><p>Retinotopic information was present in occipital, temporal, parietal, and frontal cortex as well as in a subcortical areas. We could differentiate the LGN and pulvinar from their surrounding areas based on their higher R<sup>2</sup>. Retinotopic maps in the LGN were roughly in line with previously published retinotopic organization of the macaque LGN (<xref ref-type="bibr" rid="bib42">Erwin et al., 1999</xref>), but they comprised few voxels and the variability across animals prohibited detailed inferences. In the pulvinar, the organization of the retinotopic information was even more variable across animals. In humans, subcortical retinotopic maps have been observed in LGN, pulvinar, superior colliculus (SC), thalamic reticular nucleus (TRN), and substantia nigra (SN) (<xref ref-type="bibr" rid="bib27">Cotton and Smith, 2007</xref>; <xref ref-type="bibr" rid="bib31">DeSimone et al., 2015</xref>; <xref ref-type="bibr" rid="bib121">Schneider et al., 2004</xref>). Here, we also observed voxels with pRFs located lateral and medial to the pulvinar, but more targeted investigations are necessary for detailed individual-subject segmentation of the thalamus (<xref ref-type="bibr" rid="bib31">DeSimone et al., 2015</xref>; <xref ref-type="bibr" rid="bib137">Tani et al., 2011</xref>).</p><p>We obtained good pRF fits in the occipital, temporal, and parietal cortical areas, regions for which previous studies demonstrated retinotopic organization with phase-encoded retinotopic mapping (<xref ref-type="bibr" rid="bib6">Arcaro et al., 2011</xref>; <xref ref-type="bibr" rid="bib72">Janssens et al., 2014</xref>; <xref ref-type="bibr" rid="bib83">Kolster et al., 2014</xref>; <xref ref-type="bibr" rid="bib82">Kolster et al., 2010</xref>; <xref ref-type="bibr" rid="bib81">Kolster et al., 2009</xref>; <xref ref-type="bibr" rid="bib107">Patel et al., 2010</xref>). Despite the fact that checkerboard stimuli may not be ideal for the activation of frontal areas, which are better driven by more complex stimuli (<xref ref-type="bibr" rid="bib72">Janssens et al., 2014</xref>; <xref ref-type="bibr" rid="bib120">Saygin and Sereno, 2008</xref>), we also observed retinotopy in several frontal areas, including the insula, cingulate cortex, FEFs (area 8), orbitofrontal cortex, ventromedial prefrontal cortex, and dorsolateral prefrontal cortex. These areas are thought to be involved in visual processing and visual attention. Retinotopic maps have previously been reported in the cerebellum in humans (<xref ref-type="bibr" rid="bib140">van Es et al., 2019</xref>). We did not detect such maps, likely because of a lower SNR in the cerebellum due to lower field strength, a less optimal coil placement, and the sphinx position of the monkeys.</p></sec><sec id="s3-2"><title>Negative pRFs</title><p>We observed negative pRFs in the MRI data and in the low-frequency LFP, but they were of a different nature. We identified two classes of negative pRFs in the MRI data. Negative pRFs in the visual cortex were usually accompanied by positive responses at peripheral visual field locations, close the boundaries of the visual display. Similar negative visual BOLD responses have been reported in human visual cortex (<xref ref-type="bibr" rid="bib133">Smith et al., 2004</xref>) and are presumably caused by surround suppression (<xref ref-type="bibr" rid="bib2">Allman et al., 1985</xref>; <xref ref-type="bibr" rid="bib23">Cavanaugh et al., 2002</xref>; <xref ref-type="bibr" rid="bib67">Hubel and Wiesel, 1962</xref>; <xref ref-type="bibr" rid="bib80">Knierim and van Essen, 1992</xref>). We found a second class of negative pRFs around the LatS, in the mOP, and at the superior border of the superior temporal sulcus in the IOP, all areas previously implicated in the monkeyâs DMN (<xref ref-type="bibr" rid="bib95">Mantini et al., 2011</xref>). A similar retinotopy of negative responses was recently found in the human DMN (<xref ref-type="bibr" rid="bib136">Szinte and Knapen, 2020</xref>). The retinotopy of nodes of the DMN in humans and monkeys implies a sensory-based organization of this part of the DMN, which could play a role in visual cognition (<xref ref-type="bibr" rid="bib8">Arsenault et al., 2018</xref>).</p><p>Negative pRFs were also observed for a subset of the electrodes in the Î± and Î² range of the LFP, although pRF fits were generally of lower quality than those for the Î³-LFP or MUA signals. It is conceivable that these negative pRFS reflect shifts of attention, which are known to modulate Î± and Î² power (<xref ref-type="bibr" rid="bib57">Griffiths et al., 2019</xref>; <xref ref-type="bibr" rid="bib130">Siegel et al., 2008</xref>; <xref ref-type="bibr" rid="bib154">Womelsdorf and Fries, 2007</xref>; <xref ref-type="bibr" rid="bib156">Worden et al., 2000</xref>). In accordance with this idea, negative Î±/Î² pRFs were larger than their positive counterparts and shifted towards the fixation point. Future studies are needed for a closer examination of this phenomenon.</p></sec><sec id="s3-3"><title>The relation between BOLD-based pRFs and electrophysiologically determined pRFs</title><p>We compared BOLD-based pRFs to electrophysiological measures in terms of their spatial summation characteristics, size, and the relationship between eccentricity and size (<xref ref-type="bibr" rid="bib4">Amano et al., 2009</xref>; <xref ref-type="bibr" rid="bib34">Dumoulin and Wandell, 2008</xref>; <xref ref-type="bibr" rid="bib43">Felleman and Van Essen, 1987</xref>; <xref ref-type="bibr" rid="bib51">Gattass et al., 2005</xref>; <xref ref-type="bibr" rid="bib76">Kay et al., 2013</xref>; <xref ref-type="bibr" rid="bib85">Larsson and Heeger, 2006</xref>; <xref ref-type="bibr" rid="bib141">Van Essen et al., 1984</xref>; <xref ref-type="bibr" rid="bib144">Victor et al., 1994</xref>). Eye movements can have an effect on the pRF size estimates, and it is therefore important to note that (1) we only included data from recordings where the animals maintained a high fixation performance (IQR-span of the horizontal and vertical eye position, M1: 0.23, 0.34 dva; M2: 0.36, 0.49 dva; M3: 0.18, 0.38 dva; M4: 0.37, 0.60 dva), and (2) we averaged across multiple stimulus presentations to obtain robust response profiles. Hence, variations in eye position can have had only minor effects on the present results.</p></sec><sec id="s3-4"><title>Compressive spatial summation</title><p>The CSS pRF model includes nonlinear spatial summation (<xref ref-type="bibr" rid="bib76">Kay et al., 2013</xref>). Previous studies observed subadditive spatial summation, also known as spatial compression, throughout the human visual cortex in BOLD-based pRFs, with stronger compression in higher visual areas than in V1 (<xref ref-type="bibr" rid="bib76">Kay et al., 2013</xref>; <xref ref-type="bibr" rid="bib152">Winawer et al., 2013</xref>). In the present study, spatial compression was present in subcortical and cortical areas with good BOLD-pRF fits, indicating that it is a widespread, if not universal, characteristic of the primate visual system. The strength of compression did not differ much across areas, and it was similar to that in human V1. For the MUA data, the CSS model estimated pRF sizes that were very similar to RF size estimates derived from conventional methods that use moving luminance bars, whereas the P-LIN model systematically returned larger pRF estimates. This difference might indicate that spatial compression indeed better captures the neuronal RF properties, at least in V1 and V4.</p><p>In human iEEG recordings, spatial compression in the broadband iEEG signal was reported to be similar in strength to that of the BOLD signal (<xref ref-type="bibr" rid="bib152">Winawer et al., 2013</xref>). We also observed CSS in both the MUA-pRFs and in all frequency bands of the LFP, and the pRF exponent tended to be smaller for lower-frequency components, indicative of stronger compression. The lower frequencies also exhibited stronger suppression than the BOLD signal. In contrast, the pRF exponent of MUA and Î³<sub>low</sub> was similar to that of BOLD-fMRI in both V1 and V4, but in V1 the exponent for Î³<sub>high</sub> was larger. Hence, MUA and Î³<sub>low</sub> were the two electrophysiological markers for which spatial compression resembled that of BOLD-fMRI most.</p></sec><sec id="s3-5"><title>pRF size and the eccentricity-size relationship</title><p>As expected, pRFs were larger at higher eccentricities, with a larger slope in higher visual cortical areas. The pRF sizes and the eccentricity-size relationships that we found in visual cortex were in line with previous results from human and monkey neuroimaging studies (<xref ref-type="bibr" rid="bib4">Amano et al., 2009</xref>; <xref ref-type="bibr" rid="bib31">DeSimone et al., 2015</xref>; <xref ref-type="bibr" rid="bib34">Dumoulin and Wandell, 2008</xref>; <xref ref-type="bibr" rid="bib76">Kay et al., 2013</xref>; <xref ref-type="bibr" rid="bib77">Keliris et al., 2019</xref>; <xref ref-type="bibr" rid="bib83">Kolster et al., 2014</xref>; <xref ref-type="bibr" rid="bib82">Kolster et al., 2010</xref>; <xref ref-type="bibr" rid="bib151">Welbourne et al., 2018</xref>; <xref ref-type="bibr" rid="bib160">Zhu and Vanduffel, 2019</xref>; <xref ref-type="bibr" rid="bib161">Zuiderbaan et al., 2012</xref>). Furthermore, the results are in keeping with previous electrophysiological recordings of single units and MUA in early visual areas such as V1 (<xref ref-type="bibr" rid="bib49">Gattass et al., 1987</xref>; <xref ref-type="bibr" rid="bib48">Gattass et al., 1981</xref>; <xref ref-type="bibr" rid="bib141">Van Essen et al., 1984</xref>; <xref ref-type="bibr" rid="bib144">Victor et al., 1994</xref>), V2 (<xref ref-type="bibr" rid="bib20">Burkhalter and Van Essen, 1986</xref>; <xref ref-type="bibr" rid="bib48">Gattass et al., 1981</xref>; <xref ref-type="bibr" rid="bib117">Rosa et al., 1988</xref>), V3 (<xref ref-type="bibr" rid="bib20">Burkhalter and Van Essen, 1986</xref>; <xref ref-type="bibr" rid="bib43">Felleman and Van Essen, 1987</xref>; <xref ref-type="bibr" rid="bib101">Newsome et al., 1986</xref>; <xref ref-type="bibr" rid="bib118">Rosa et al., 2000</xref>), and V4 (<xref ref-type="bibr" rid="bib50">Gattass et al., 1988</xref>). Finally, they also match the results of human electrophysiology with subdural electrodes (<xref ref-type="bibr" rid="bib60">Harvey et al., 2013</xref>; <xref ref-type="bibr" rid="bib158">Yoshor et al., 2007</xref>).</p></sec><sec id="s3-6"><title>The spatial scope of fMRI-BOLD, MUA, and LFP</title><p>The spatial scale of recorded neural signals depends both on the nature of the signal and the recording method. For extracellular electrophysiology recordings, the impedance and size of an electrode determine its sensitivity for single-unit spiking activity or MUA. This relationship is complex (<xref ref-type="bibr" rid="bib145">Viswam et al., 2019</xref>; <xref ref-type="bibr" rid="bib150">Ward et al., 2009</xref>), but high-impedance (~1 MÎ©) electrodes are generally better suited for the detection of spiking activity, with smaller contact sites and higher impedance thought to sample from smaller neural populations and being more likely to pick up single-neuron activity. The spatial range of the MUA signal is ~140 Âµm (<xref ref-type="bibr" rid="bib21">BuzsÃ¡ki and Draguhn, 2004</xref>). Electrode impedance, size, and shape are less important for LFP recordings, at least within commonly used ranges (<xref ref-type="bibr" rid="bib100">Nelson and Pouget, 2010</xref>; <xref ref-type="bibr" rid="bib145">Viswam et al., 2019</xref>). The spatial extent of the LFP signal is a topic of ongoing debate (<xref ref-type="bibr" rid="bib74">Kajikawa and Schroeder, 2011</xref>) with some authors estimating it as low as 120â250 Âµm in visual cortex (<xref ref-type="bibr" rid="bib75">Katzner et al., 2009</xref>; <xref ref-type="bibr" rid="bib157">Xing et al., 2009</xref>), while others suggest it may stretch up to several millimeters (<xref ref-type="bibr" rid="bib13">Berens et al., 2008</xref>; <xref ref-type="bibr" rid="bib75">Katzner et al., 2009</xref>; <xref ref-type="bibr" rid="bib84">Kreiman et al., 2006</xref>), and may even be detected more than a centimeter away from the source (<xref ref-type="bibr" rid="bib74">Kajikawa and Schroeder, 2011</xref>). The hypothesis that low-frequency components of the LFP have a larger spatial reach than high-frequency components is supported by computational modeling (<xref ref-type="bibr" rid="bib87">Leski et al., 2013</xref>), although it has also been challenged (<xref ref-type="bibr" rid="bib33">Dubey and Ray, 2016</xref>). Yet, the exact origin of the LFP and its relationship to spiking remain to be completely understood (<xref ref-type="bibr" rid="bib36">Einevoll et al., 2013</xref>).</p><p>Given the larger spatial spread of the LFP compared to MUA, one would expect pRFs based on LFPs to be larger than those based on MUA. This is indeed what we found. The size of LFP-pRFs furthermore depended on the frequency component of the LFP, with lower frequencies yielding larger pRFs, suggesting a frequency-dependent spread of visual information in the LFP signal. In fMRI, there is a trade-off between spatial and temporal resolution. While higher magnetic field strengths and specialized acquisition methods are continuously increasing spatiotemporal resolution, studies with voxel sizes on the order of 1â2 mm isotropic and a repetition time of 2â3 s at 3T field strengths are still common. Due to the complex relationship between the hemodynamic BOLD signal and the underlying neural activity, it is difficult to predict its stimulus sensitivity from neuroimaging parameters such as voxel size. Nonetheless, a comparison of the eccentricity-size relationship between MRI and electrophysiology in V1 revealed that the BOLD-based pRFs resembled MUA in V1 and V4. In V4, however, the BOLD slope was also very similar to that of the LFP gamma power (<xref ref-type="fig" rid="fig12s1">Figure 12âfigure supplement 1</xref>). One possible reason for this difference between areas is that V4 is smaller and more heterogeneous (<xref ref-type="bibr" rid="bib83">Kolster et al., 2014</xref>; <xref ref-type="bibr" rid="bib160">Zhu and Vanduffel, 2019</xref>) than V1. A V4 voxel; therefore, samples from a neuronal population with more heterogeneous spatial tuning than an equally sized V1 voxel may therefore reflect the activity of a larger population of neurons, which is better approximated by gamma power. Other factors that might play a role are potential differences in the quality of the recorded signal across areas or partial volume effects that are likely to be more prevalent in V4 than in V1.</p></sec><sec id="s3-7"><title>Conclusions</title><p>Our comparison of fMRI with large-scale neurophysiological recordings in visual cortex revealed that pRFs derived from the BOLD signal resemble MUA RFs. Subadditive spatial summation is a general feature of many brain areas and occurs for BOLD, MUA, and LFP. We observed negative pRFs in the monkey DMN and as part of center-surround organization of pRFs in early visual areas. The spatial compression and the eccentricity-size relationship of BOLD resembles that of MUA, but also bears a resemblance to gamma power. We conclude that BOLD-pRFs accurately represent the spatial tuning of the underlying neuronal populations.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Reagent type (species) or resource</th><th align="left" valign="bottom">Designation</th><th align="left" valign="bottom">Source or reference</th><th align="left" valign="bottom">Identifiers</th><th align="left" valign="bottom">Additional information</th></tr></thead><tbody><tr><td align="left" valign="bottom">Biological sample(<italic>Macaca mulatta</italic>)</td><td align="left" valign="bottom">Rhesus macaque (<italic>Macaca mulatta</italic>), male</td><td align="left" valign="bottom">Biomedical Primate <break/>Research Center, <break/>the Netherlands</td><td align="left" valign="bottom">n/a</td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">Philips Ingenia 3.0T MR system</td><td align="left" valign="bottom">Philips</td><td align="left" valign="bottom">n/a</td><td align="left" valign="bottom">At Spinoza Centre for Neuroimaging, Amsterdam, the Netherlands</td></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">8-channel phased array receive MR coil system</td><td align="left" valign="bottom">KU Leuven</td><td align="left" valign="bottom">n/a</td><td align="left" valign="bottom">Custom-built</td></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">16-channel MR pre-amplifier</td><td align="left" valign="bottom">MR Coils BV</td><td align="left" valign="bottom">n/a</td><td align="left" valign="bottom">Custom-built</td></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">ETL-200</td><td align="left" valign="bottom">ISCAN</td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_021044">SCR_021044</ext-link></td><td align="left" valign="bottom">MR-compatible eye tracker</td></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">E3X-NH</td><td align="left" valign="bottom">Omron</td><td align="left" valign="bottom">n/a</td><td align="left" valign="bottom">Fiber optic amplifiers</td></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">5-RLD-E1 Liquid Reward System</td><td align="left" valign="bottom">Crist Instrument <break/>Company, Inc</td><td align="left" valign="bottom">n/a</td><td align="left" valign="bottom">Juice reward system</td></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">BOLDscreen 32 LCD for fMRI</td><td align="left" valign="bottom">Cambridge <break/>Research <break/>Systems</td><td align="left" valign="bottom">n/a</td><td align="left" valign="bottom">MR-compatible display</td></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">Utah array (electrodes)</td><td align="left" valign="bottom">Blackrock <break/>Microsystems</td><td align="left" valign="bottom">n/a</td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">128-channel CerePlex M head-stages</td><td align="left" valign="bottom">Blackrock <break/>Microsystems</td><td align="left" valign="bottom">n/a</td><td align="left" valign="bottom">Data acquisition</td></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">128-channel CerePlex M head-stages</td><td align="left" valign="bottom">Blackrock<break/> Microsystems</td><td align="left" valign="bottom">n/a</td><td align="left" valign="bottom">Data acquisition</td></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">128-channel Digital Hub</td><td align="left" valign="bottom">Blackrock <break/>Microsystems</td><td align="left" valign="bottom">n/a</td><td align="left" valign="bottom">Data acquisition</td></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">128-channel Neural Signal Processor (NSP)</td><td align="left" valign="bottom">Blackrock <break/>Microsystems</td><td align="left" valign="bottom">n/a</td><td align="left" valign="bottom">Data acquisition</td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">Blackrock Central Software Suite</td><td align="left" valign="bottom">Blackrock <break/>Microsystems</td><td align="left" valign="bottom">n/a</td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">ET-49C</td><td align="left" valign="bottom">Tomas <break/>Recording</td><td align="left" valign="bottom">n/a</td><td align="left" valign="bottom">Eye tracker</td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">MATLAB</td><td align="left" valign="bottom">MathWorks</td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_001622">SCR_001622</ext-link></td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">LISA cluster</td><td align="left" valign="bottom">SURFsara</td><td align="left" valign="bottom">n/a</td><td align="left" valign="bottom">Computing cluster</td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">dcm2niix</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://github.com/rordenlab/dcm2niix">https://github.com/rordenlab/dcm2niix</ext-link></td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_01409">SCR_01409</ext-link></td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">Nipype</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="http://nipy.org/nipype/">http://nipy.org/nipype/</ext-link></td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_002502">SCR_002502</ext-link></td><td align="left" valign="bottom">Used as the basis of the custom NHP-BIDS pipeline</td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">NHP-BIDS</td><td align="left" valign="bottom">Netherlands <break/>Institute for <break/>Neuroscience</td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_021813">SCR_021813</ext-link></td><td align="left" valign="bottom">In-house developed, available via: <ext-link ext-link-type="uri" xlink:href="https://github.com/VisionandCognition/NHP-BIDS">https://github.com/VisionandCognition/NHP-BIDS</ext-link></td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">FreeSurfer</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="http://surfer.nmr.mgh.harvard.edu/">http://surfer.nmr.mgh.harvard.edu/</ext-link></td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_001847">SCR_001847</ext-link></td><td align="left" valign="bottom">Used as the basis of the custom NHP-Freesurfer</td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">NHP-Freesurfer</td><td align="left" valign="bottom">Netherlands <break/>Institute for <break/>Neuroscience</td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_021814">SCR_021814</ext-link></td><td align="left" valign="bottom">In-house developed, available via: <ext-link ext-link-type="uri" xlink:href="https://github.com/VisionandCognition/NHP-Freesurfer">https://github.com/VisionandCognition/NHP-Freesurfer</ext-link></td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">Pycortex</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://gallantlab.github.io/pycortex/">https://gallantlab.github.io/pycortex/</ext-link></td><td align="left" valign="bottom">n/a</td><td align="left" valign="bottom">Used as the basis of the customized NHP-Pycortex</td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">NHP-Pycortex</td><td align="left" valign="bottom">Netherlands <break/>Institute for <break/>Neuroscience</td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_021815">SCR_021815</ext-link></td><td align="left" valign="bottom">In-house developed, available via: <ext-link ext-link-type="uri" xlink:href="https://github.com/VisionandCognition/NHP-pycortex">https://github.com/VisionandCognition/NHP-pycortex</ext-link></td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">analyzePRF</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://kendrickkay.net/analyzePRF/">https://kendrickkay.net/analyzePRF/</ext-link></td><td align="left" valign="bottom">n/a</td><td align="left" valign="bottom">Toolbox was edited for this study and made available with the code and data</td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">Jupyter Notebook</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://jupyter.org/">https://jupyter.org/</ext-link></td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_018315">SCR_018315</ext-link></td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">FSL</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="http://www.fmrib.ox.ac.uk/fsl/">http://www.fmrib.ox.ac.uk/fsl/</ext-link></td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_002823">SCR_002823</ext-link></td><td align="left" valign="bottom">-</td></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">Tracker-MRI: Experiment control software</td><td align="left" valign="bottom">Netherlands <break/>Institute for <break/>Neuroscience</td><td align="left" valign="bottom">RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_021816">SCR_021816</ext-link></td><td align="left" valign="bottom">In-house developed, available via: <ext-link ext-link-type="uri" xlink:href="https://github.com/VisionandCognition/Tracker-MRI">https://github.com/VisionandCognition/Tracker-MRI</ext-link></td></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">NMT v1.3</td><td align="left" valign="bottom">NIH, AFNI <break/><ext-link ext-link-type="uri" xlink:href="https://afni.nimh.nih.gov/pub/dist/doc/htmldoc/nonhuman/macaque/template_nmtv1.html#nmt-v1-3">https://afni.nimh.nih.gov/pub/dist/doc/htmldoc/nonhuman/macaque/template_nmtv1.html#nmt-v1-3</ext-link></td><td align="left" valign="bottom">n/a</td><td align="left" valign="bottom">Macaque Brain Template and Atlas</td></tr></tbody></table></table-wrap><sec id="s4-1"><title>Subject details</title><p>Four male macaques (<italic>M. mulatta;</italic> 7â12 kg, 5â8 years old) participated in this study. Animal care and experimental procedures were in accordance with the ILARâs Guide for the Care and Use of Laboratory Animals, the European legislation (Directive 2010/63/EU), and approved by the Institutional Animal Care and Use Committee of the Royal Netherlands Academy of Arts and Sciences and the Central Authority for Scientific Procedures on Animals (CCD) in the Netherlands (license numbers AVD8010020173789 and AVD8010020171046). The animals were socially housed in an enriched specialized primate facility with natural daylight, controlled temperature and humidity, and fed with standard primate chow, supplemented with raisins, fresh fruits, and vegetables. Their access to fluid was controlled, according to a carefully designed regime for fluid uptake. During weekdays, the animals received diluted fruit juice in the experimental setup. We ensured that the animals drank sufficient fluid in the setup and received extra fluid after experimental sessions if needed. On the weekends, animals received at least 700 ml of water in the home cage. The animals were regularly checked by veterinary staff and animal caretakers, and their weight and general appearance were recorded in an electronic logbook on a daily basis during fluid-control periods.</p></sec><sec id="s4-2"><title>Surgical procedures</title><p>Two animals (M1 and M2) participated in the MRI experiments and were implanted with an MRI-compatible plastic (PEEK) head-post, fixed to the skull with ceramic bone screws and acrylic (<xref ref-type="bibr" rid="bib106">Papageorgiou et al., 2014</xref>; <xref ref-type="bibr" rid="bib143">Vanduffel et al., 2001</xref>). Anesthetics, analgesics, and monitoring procedures were similar to previous surgical procedures in our laboratory and are described in detail elsewhere (<xref ref-type="bibr" rid="bib78">Klink et al., 2017</xref>; <xref ref-type="bibr" rid="bib110">Poort et al., 2012</xref>; <xref ref-type="bibr" rid="bib135">SupÃ¨r and Roelfsema, 2005</xref>). Two other animals (M3 and M4) participated in the electrophysiology experiments. They were implanted with a custom 3D-printed titanium head-post that was designed in-house based on a CT scan of the skull, aligned to a T1-weighted anatomical MRI scan of the brain (<xref ref-type="bibr" rid="bib25">Chen et al., 2020</xref>; <xref ref-type="bibr" rid="bib24">Chen et al., 2017</xref>). The titanium head-post was attached to the skull with titanium bone screws, and the skin was closed around the implant without the use of any acrylic. In a second surgery, each animal was additionally implanted with a total of 1024 electrodes in 16 Utah electrode arrays (Blackrock Microsystems) in their visual cortices (14 arrays in V1, 2 arrays in V4; <xref ref-type="fig" rid="fig1">Figure 1B</xref>). Each array contained an 8-by-8 grid of 64 iridium oxide electrodes with a length of 1.5 mm spaced at a distance of 400 Î¼m from each other. Pre-implantation electrode impedances ranged from 6 to 12 kÎ©. A custom-designed 1024-channel pedestal was attached to the skull with titanium bone screws, and the skin was closed around it. More details on the surgical procedures have been published elsewhere (<xref ref-type="bibr" rid="bib25">Chen et al., 2020</xref>; <xref ref-type="bibr" rid="bib24">Chen et al., 2017</xref>).</p></sec><sec id="s4-3"><title>Visual stimuli and procedures</title><p>In the MRI experiment, animals were head-fixed, sitting in the sphinx position (<xref ref-type="bibr" rid="bib106">Papageorgiou et al., 2014</xref>; <xref ref-type="bibr" rid="bib143">Vanduffel et al., 2001</xref>), and viewing a 32â³ screen (1920 Ã 1080 pixels, 100 Hz) (Cambridge Research Systems) at the end of the bore, 130 cm away. pRFs were measured using conventional moving bar stimuli that traversed the screen in eight different directions behind a large virtual circular aperture (<xref ref-type="fig" rid="fig1">Figure 1</xref>). The borders of this virtual aperture were invisible because both the foreground and background had the same gray level (22.3 cd/m<sup>2</sup>) (<xref ref-type="bibr" rid="bib34">Dumoulin and Wandell, 2008</xref>). In the MRI experiments, the bar sweep spanned 16Â° (diameter) in 20 steps (<xref ref-type="bibr" rid="bib34">Dumoulin and Wandell, 2008</xref>). The moving bars were 2Â° wide and contained a checkerboard pattern (100% contrast; 0.5Â° checkers; luminance of white checkers: 106.8 cd/m<sup>2</sup>; luminance of black checkers: 0.2 cd/m<sup>2</sup>) that moved parallel to the barâs orientation. Each bar position was on the screen for 2.5 s (1 TR), making one full bar sweep last 50 s. Bar sweep series (all directions presented once) were preceded and followed by 37.5 s (15 TRs) of neutral gray background. Each horizontal or vertical bar sweep was followed by a neutral gray background period of 25 s. The order of the bar sweep directions was 270Â°, 315Â°, 180Â°, 225Â°, 90Â°, 135Â°, 0Â°, 45Â° on most runs, but for one animal we inverted the directions to 90Â°, 135Â°, 0Â°, 45Â°, 270Â°, 315Â°, 180Â°, 225Â° on some runs to compensate for the animalâs tendency to fall asleep near the end of runs. We included data from 8 scanning sessions for monkey M1 (34 runs, 268 bar sweeps) and 10 sessions for monkey M2 (66 runs, 406 bar sweeps). During stimulus presentation, the animals received fluid rewards (Crist Instruments, Hagerstown, MD) for maintaining fixation within a circular fixation window with a diameter of 2Â°, centered on a 0.15Â° red fixation dot, surrounded by a 0.75Â° (diameter) aperture of neutral gray background color. In the electrophysiology experiments, the stimulus and task were very similar, but bar sweeps now spanned 28Â°, which was possible because the animals were closer to the monitor (luminance values of this monitor were black: 0 cd/m<sup>2</sup>; white: 92.1 cd/m<sup>2</sup>, neutral gray: 14.8 cd/m<sup>2</sup>). Bars traveled along this path in 30 steps of 500 ms, and the neutral gray luminance intervals were reduced to 2.5 s due to the much faster neuronal responses (compared to the BOLD signal). The fixation window in the electrophysiology experiments was slightly smaller with a diameter of 1.5Â°. In the MRI experiment, eye position and pupil diameter were tracked with an MRI-compatible infrared eye-tracking system at 120 Hz (ISCAN ETL-200). Hand positions were also monitored using fiber optic amplifiers (Omron E3X-NH) and optic fibers. To reduce body movement-related imaging artifacts, the animals were trained to maintain their hands inside a response box by making reward delivery contingent on both eye and hand position. In the electrophysiology experiments, animals were head-fixed in a conventional vertical primate chair and viewed a 21â³ CRT monitor (1024 Ã 768, 85 Hz) at a distance of 64 cm while their eye position and pupil diameters were tracked at 230 Hz using an infrared eye tracker (TREC ET-49B, Thomas Recording GmbH).</p></sec><sec id="s4-4"><title>MRI acquisition</title><p>MRI was performed in a standard Philips Ingenia 3.0T horizontal bore full-body scanner (Spinoza Center for Neuroimaging, Amsterdam, the Netherlands). We used a custom-built eight-channel phased array receive coil system (<xref ref-type="bibr" rid="bib38">Ekstrom et al., 2008</xref>; <xref ref-type="bibr" rid="bib81">Kolster et al., 2009</xref>) (KU Leuven) and the scannerâs full-body transmit coil. Functional images were obtained using a gradient-echo T2* echo-planar sequence (44 horizontal slices, in-plane 72 Ã 68 matrix, TR = 2500 ms, TE = 20 ms, flip angle = 77.2Â°, 1.25 Ã 1.25 Ã 1.25 mm isotropic voxels, SENSE-factor of 2 in the AP direction, and phase-encoding in the AP direction).</p></sec><sec id="s4-5"><title>fMRI preprocessing</title><p>All fMRI data were preprocessed with a custom-written Nipype pipeline that we have made available online (RRID:021813; <ext-link ext-link-type="uri" xlink:href="https://github.com/visionandcognition/NHP-BIDS">https://github.com/visionandcognition/NHP-BIDS</ext-link>). In short, MRI scans were exported from the scanner as DICOM images and converted to NIFTI files with the dcm2niix tool (<xref ref-type="bibr" rid="bib88">Li et al., 2016</xref>). The volumes were then reoriented to correct for the animal being in the sphinx position and resampled to 1 mm<sup>3</sup> isotropic voxels. The resulting images were realigned using a nonrigid slice-by-slice registration algorithm based on AFNI tools (<xref ref-type="bibr" rid="bib28">Cox, 1996</xref>) followed by an FSL-based motion correction procedure MCFLIRT (<xref ref-type="bibr" rid="bib73">Jenkinson et al., 2002</xref>). Functional volumes were linearly aligned to the individual high-resolution anatomical volumes, which were in turn nonlinearly registered to the NMT standard space (<xref ref-type="bibr" rid="bib124">Seidlitz et al., 2018</xref>). Preprocessed data were further processed with a combination of custom-written MATLAB (MathWorks, Natick, MA) and shell scripts (<ext-link ext-link-type="uri" xlink:href="https://gin.g-node.org/ChrisKlink/NHP-PRF">https://gin.g-node.org/ChrisKlink/NHP-PRF</ext-link>). BOLD time courses for each voxel were normalized to percentage signal change and averaged across runs (or parts of runs) for which fixation was maintained at 80% of the time or more. We averaged odd and even runs separately to allow for a cross-validation approach in the evaluation of the pRF model fits. Anatomical ROIs were defined based on a probabilistic atlas (<xref ref-type="bibr" rid="bib114">Reveley et al., 2017</xref>; <xref ref-type="bibr" rid="bib124">Seidlitz et al., 2018</xref>) and refined using individual retinotopic maps.</p><p>Post-fit comparisons across pRF models, HRFs, and ROIs were performed in MATLAB based on the volumetric results. For visualization of the fMRI data, volumetric results were also projected to the individual cortical surfaces. To create these surfaces, we averaged multiple anatomical scans (T1-weighted, 3D-FFE, TE = 6 ms, TR = 13 ms, TI = 900 ms, flip angle = 8Â°, 100 horizontal slices, in-plane 224 Ã 224 matrix, 0.6 Ã 0.6 Ã 0.6 mm isotropic voxels, and phase-encoding in the AP direction) and processed the result with customized tools based on FreeSurfer (<xref ref-type="bibr" rid="bib44">Fischl, 2012</xref>) and Pycortex (<xref ref-type="bibr" rid="bib47">Gao et al., 2015</xref>) that were adjusted to handle our NHP data. These tools and their documentation can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/VisionandCognition/NHP-Freesurfer">https://github.com/VisionandCognition/NHP-Freesurfer</ext-link>; (<xref ref-type="bibr" rid="bib79">Klink, 2021</xref>; copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:d8a1a76a4f91921900b4f0ede328f5acdeb03c37;origin=https://github.com/VisionandCognition/NHP-Freesurfer;visit=swh:1:snp:7b5338bc3ee68190df2c473e45629d3ce2640840;anchor=swh:1:rev:8d4b89337b865fb194e196cf1b2af4967e14d607">swh:1:rev:8d4b89337b865fb194e196cf1b2af4967e14d607</ext-link>) and <ext-link ext-link-type="uri" xlink:href="https://github.com/VisionandCognition/NHP-pycortex">https://github.com/VisionandCognition/NHP-pycortex</ext-link>, respectively (<xref ref-type="bibr" rid="bib97">Messinger et al., 2021</xref>).</p></sec><sec id="s4-6"><title>Electrophysiology acquisition</title><p>Neuronal activity was acquired from 1024 channels simultaneously at a 30 kHz sampling rate. The 1024-channel pedestal was connected to eight 128-channel CerePlex M head-stages through an electronic interface board. Each head-stage processed signals from two 64-channel electrode arrays with a 0.3â7500 Hz analog filter at unity gain (i.e., no amplification). After analog-to-digital conversion, the signal from each head-stage was sent to a 128-channel Digital Hub (Blackrock Microsystems) where it was converted into an optical output signal and sent to a 128-channel Neural Signal Processor (NSP, Blackrock Microsystems) for storage and further processing. The eight NSPs were controlled with eight simultaneously running instances of the Blackrock Central Software Suite (Blackrock Microsystems) distributed over two computers (four instances each) (<xref ref-type="bibr" rid="bib25">Chen et al., 2020</xref>).</p></sec><sec id="s4-7"><title>Electrophysiology data preprocessing</title><p>The neuronal signal that was acquired using different software instances was temporally aligned using common TTL pulses sent by the stimulus computer. The data were then separated in (1) envelope MUA and (2) broadband LFP. MUA represents the spiking activity of a local population of neurons around the electrode (<xref ref-type="bibr" rid="bib26">Cohen and Maunsell, 2009</xref>; <xref ref-type="bibr" rid="bib105">Palmer et al., 2007</xref>; <xref ref-type="bibr" rid="bib135">SupÃ¨r and Roelfsema, 2005</xref>). To extract MUA, we amplified the raw neuronal signal, band-pass filtered it between 500 Hz and 9 kHz, full-wave rectified it, and applied a low-pass filter of 200 Hz. The resulting time series were downsampled to 1 kHz. We subtracted the baseline MUA activity in a 1000 ms prestimulus time window. Baseline-corrected MUA responses were then averaged, first across runs and then within a 50â500 ms time window for each stimulus position. The broadband LFP signal was generated by low-pass filtering the raw signal at 150 Hz and downsampling it to 500 Hz. The LFP signal was further processed with a multi-taper method using the Chronux toolbox (<xref ref-type="bibr" rid="bib15">Bokil et al., 2010</xref>). Power spectra were calculated in a 500 ms moving window (step size 50 ms), using a time bandwidth product of five and nine tapers. LFP power was averaged within five distinct frequency bands: 4â8 Hz (theta), 8â16 Hz (alpha), 16â30 Hz (beta), 30â60 Hz (low gamma), and 60â120 Hz (high gamma). Baseline power in a 1000 ms prestimulus period was subtracted and the power for each recording site was averaged across runs, within a 50â500 ms time window during each stimulus position.</p></sec><sec id="s4-8"><title>pRF models and fitting procedure</title><p>We fit four pRF models to all the data (voxels and electrode channels) using a customized version of the analyzePRF toolbox (<xref ref-type="bibr" rid="bib76">Kay et al., 2013</xref>) for MATLAB. In the fitting procedure, the stimuli were spatially downsampled to a resolution of 10 pixels per dva and converted to âeffective stimuli,â consisting of binary representations that encode stimulus position. Response predictions were calculated as the product of the effective stimulus and the pRF shape (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>). This method also yields a prediction for pRFs that are only partially stimulated, and the best-fitting pRF can have a center location outside of the stimulus aperture. Because pRF estimates are generally more reliable for pRF that are strongly driven by a visual stimulus, we include indications of the directly stimulated visual field in our figures. The four pRF models differed in the pRF shape. Linear models (<xref ref-type="disp-formula" rid="equ1">Equations 1</xref>â<xref ref-type="disp-formula" rid="equ3">3</xref>) describe a single isotropic 2D Gaussian-shaped pRF and assume linear spatial summation across the visual field (<xref ref-type="bibr" rid="bib34">Dumoulin and Wandell, 2008</xref>). We implemented two linear model versions. For the first model, responses were constrained to be positively related to the visual stimuli (P-LIN). A second version lacked this constraint and also allowed negative responses, that is, stimulus-driven activity reductions (U-LIN). Negative BOLD responses have been demonstrated in some brain areas (<xref ref-type="bibr" rid="bib129">Shmuel et al., 2006</xref>; <xref ref-type="bibr" rid="bib136">Szinte and Knapen, 2020</xref>). The nonlinear spatial summation model (<xref ref-type="bibr" rid="bib76">Kay et al., 2013</xref>) expands the linear model by capturing nonlinear summation of signals across the visual field. It has previously been shown that the value of the exponent is generally smaller than 1 in human visual cortex, indicating subadditive spatial summation or CSS (<xref ref-type="bibr" rid="bib76">Kay et al., 2013</xref>). This model is therefore generally referred to as the CSS model. Because the pRF size and static nonlinearity interact in the nonlinear model, the pRF size is defined as the standard deviation of the predicted Gaussian response profile to a point stimulus for all models (Equation 3; <xref ref-type="bibr" rid="bib76">Kay et al., 2013</xref>). The mathematical descriptions of the linear and nonlinear pRF models are in <xref ref-type="disp-formula" rid="equ1">Equations 1</xref>â<xref ref-type="disp-formula" rid="equ3">3</xref>, where <italic>Resp</italic><sub>pred</sub> indicates the predicted response, <italic>g</italic> is a gain factor to scale the response, <italic>S(x,y</italic>) is the effective stimulus, <italic>G(x,y</italic>) is the Gaussian pRF profile, and <italic>n</italic> is the exponent that determines the static spatial nonlinearity. For the P-LIN model, the gain <italic>g</italic> was constrained to positive values, while for the U-LIN model, gain values could be negative as well. Negative gain factors imply stimulus-induced reductions of activity. In both linear models, the exponent <italic>n</italic> was fixed to be 1. In the definition of the Gaussian, (<italic>x<sub>0</sub>,y<sub>0</sub></italic>) defines the center and <italic>Ï</italic> the standard deviation of the pRF.</p><p>Linear and nonlinear spatial summation pRF models:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mtext>pred</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mo>â</mml:mo><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:munder><mml:mo>â</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:munder><mml:mi>S</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>G</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mtable columnspacing="1em" rowspacing="4pt"><mml:mtr><mml:mtd><mml:mtext>P</mml:mtext><mml:mtext>-</mml:mtext><mml:mtext>L</mml:mtext><mml:mtext>I</mml:mtext><mml:mtext>N</mml:mtext><mml:mo>,</mml:mo><mml:mtext>U</mml:mtext><mml:mtext>-</mml:mtext><mml:mtext>L</mml:mtext><mml:mtext>I</mml:mtext><mml:mtext>N</mml:mtext><mml:mo>:</mml:mo><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>P</mml:mtext><mml:mtext>-</mml:mtext><mml:mtext>L</mml:mtext><mml:mtext>I</mml:mtext><mml:mtext>N</mml:mtext><mml:mo>,</mml:mo><mml:mtext>C</mml:mtext><mml:mtext>S</mml:mtext><mml:mtext>S</mml:mtext><mml:mo>:</mml:mo><mml:mi>g</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula><disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mi>G</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:mo>-</mml:mo><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>y</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mrow><mml:mi>Ï</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup></mml:math></disp-formula><disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:msub><mml:mrow><mml:mi>p</mml:mi><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mtext>size</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>Ï</mml:mi></mml:mrow><mml:mrow><mml:msqrt><mml:mi>n</mml:mi></mml:msqrt></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>The DoG model uses a standard linear Gaussian (<italic>G</italic><sub>1</sub> in <xref ref-type="disp-formula" rid="equ4">Equation 4</xref>) to describe the excitatory center of a pRF and subtracts a second Gaussian profile (<italic>G</italic><sub>2</sub>) to model an inhibitory surround component (<xref ref-type="bibr" rid="bib161">Zuiderbaan et al., 2012</xref>). This second Gaussian is by definition broader than the one describing the center. The size <italic>Ï</italic><sub>2</sub> and amplitude <italic>a</italic> of the surround Gaussian are additional parameters (<xref ref-type="disp-formula" rid="equ4">Equations 4</xref>â<xref ref-type="disp-formula" rid="equ6">6</xref>).</p><p>DoG pRF model:<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:msub><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mtext>pred</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mo>â</mml:mo><mml:msup><mml:mrow><mml:mfenced close="]" open="[" separators="|"><mml:mrow><mml:mrow><mml:msub><mml:mo>â</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow></mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:mi>a</mml:mi><mml:mo>â</mml:mo><mml:msub><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msup></mml:math></disp-formula><disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mo>â</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>â</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>â</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>Ï</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:msub><mml:mi>G</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mo>â</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>â</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>â</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>Ï</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:msup><mml:mo>;</mml:mo><mml:msub><mml:mi>Ï</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>Ï</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>The models assume a near-instantaneous link between the stimulus and the response dynamics, which holds for the electrophysiological signals. For these signals, the stimulus changes position every 500 ms, much slower than the onset or decay of activity. The BOLD response is much slower than the speed with which the stimulus traverses the screen in the fMRI experiments (2500 ms per position). We therefore convolved the predicted response with an HRF at a resolution of 1.25 s per sample (twice the acquisition rate of TR = 2.5 s). We used both a canonical human HRF and a standard monkey HRF that we derived from separate scanning sessions (<xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1</xref>). In short, we presented the animals with brief (0.1 s) full-contrast and full-screen checkerboard stimuli. We then used FMRIBâs Linear Optimal Basis Sets (FLOBS) (<xref ref-type="bibr" rid="bib155">Woolrich et al., 2004</xref>) toolkit from the FSL software package to estimate the relative contributions of a set of basis functions for those voxels in the primary visual cortex that were activated by the stimulus. We then calculated a single weighted average HRF function based on these basis functions and used it as the standard monkey HRF. The monkey HRF was narrower than the canonical human HRF. It had a faster time-to-peak (4.2 s vs. 4.8 s) and peak-to-fall time (6.2 s vs. 12.6 s). The fits with the monkey HRF were slightly better, especially in the lower visual areas (<xref ref-type="fig" rid="fig1s1">Figure 1âfigure supplement 1</xref>). However, size and location estimates were highly similar for the two HRFs for all models, and we only report results from model fits based on the monkey HRF.</p><p>Model fitting was performed on a cluster computer (LISA, SURFsara) using nonlinear optimization (MATLAB Optimization Toolbox). The accuracy of the different model fits was quantified as the cross-validated percentage of variance (<italic>R</italic><sup>2</sup>) explained of the BOLD response (<xref ref-type="disp-formula" rid="equ6">Equation 6</xref>: <italic>DATA</italic>) by the model prediction (<xref ref-type="disp-formula" rid="equ6">Equation 6</xref>: <italic>MODEL</italic>). For cross-validation, we divided the data into two nonoverlapping sets (odd and even runs) and tested the prediction of a model that was fit one data set against the time series of the other data set and vice versa. This yielded two <italic>R</italic><sup>2</sup> values per voxel or electrode that were averaged. The cross-validated comparison of model performance is valid for models with different numbers of parameters and prevents overfitting. Fit results are available as voxel-based maps warped to the NMT template space on <ext-link ext-link-type="uri" xlink:href="https://neurovault.org/">Neurovault.org</ext-link> (<xref ref-type="bibr" rid="bib46">Fox et al., 2021</xref>; <xref ref-type="bibr" rid="bib53">Gorgolewski et al., 2015</xref>) at <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/neurovault.collection:8082">https://identifiers.org/neurovault.collection:8082</ext-link>.</p><p>Model accuracy:<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:msub><mml:mrow><mml:mi>p</mml:mi><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mtext>center-size</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Ï</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mtext>surr-size</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>Ï</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></disp-formula></p></sec><sec id="s4-9"><title>Comparison of pRF (and cRF) estimates</title><p>After fitting the pRF models to all voxels and recording sites, we compared the pRF estimates both within and across recording modalities. We pooled voxels and recording sites across subjects and used nonparametric statistical tests (Wilcoxon signed-rank, Wilcoxon rank-sum, or KruskalâWallis) with post-hoc Tukeyâs HSD tests to correct for multiple comparisons. For the fMRI data, we compared R<sup>2</sup> across models and HRFs. We constructed retinotopic maps using the best pRF model and HRF and investigated the relationship between pRF eccentricity and size for a subset of ROIs with good model fits (R<sup>2</sup> &gt; 5%). For the electrophysiological data, we compared model accuracy and pRF estimates across MUA and LFP components to unravel to which extent retinotopic information is available in the different neuronal signals. We also compared the pRF estimates to a more conventional RF mapping technique for MUA based on responses to thin, moving bar stimuli (cRF). For recording sites with an SNR larger than 3 (i.e., visual responses that were more than three times larger than the standard deviation of the spontaneous activity), we fitted a Gaussian to the averaged MUA traces and determined the onset and offset of the visual response as the mean of this Gaussian plus or minus its standard deviation (SD). Horizontal and vertical RF boundaries were then derived from the onset and offset times for stimuli moving in opposite directions (<xref ref-type="bibr" rid="bib135">SupÃ¨r and Roelfsema, 2005</xref>). RF centers were defined as the midpoint between the horizontal and vertical borders. For comparison with the pRFs, we calculated RF sizes as half the diagonal of the rectangular area between the horizontal and vertical cRF borders (<inline-formula><mml:math id="inf1"><mml:msub><mml:mrow><mml:mi>c</mml:mi><mml:mi>R</mml:mi><mml:mi>F</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msqrt><mml:mfenced separators="|"><mml:mrow><mml:msup><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>h</mml:mi><mml:mi>e</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfenced></mml:msqrt></mml:mrow><mml:mo>/</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). This measure approximates the RF radius based on the SD of a Gaussian response profile and can be directly compared to the sigma estimated by pRF models (<xref ref-type="fig" rid="fig7">Figure 7</xref>). It is smaller than cRF sizes typically reported in electrophysiological studies because neurons are activated by stimuli farther than 1 SD from their RF center (our lab usually defines cRF diameter as 3.3 * SD).</p><p>To compare pRFs based on fMRI-BOLD and electrophysiology, we combined data from individual animals to create one pool of BOLD-based voxel pRFs and six pools of electrophysiology-based electrode pRFs (MUA, and the different frequency bands of the LFP) for V1 and V4 data. We compared the relationship between RF eccentricity and size with a set of LMMs. We first tested for a correlation between eccentricity and size for the different signal types. Signal types with a significant correlation were subsequently tested together in a single LMM to determine whether the eccentricity-size relationship differed between signal types (interaction SIGNAL Ã ECC). Finally, we compared electrophysiological signals with the MRI results. For this analysis, we only selected V1 and V4 voxels with pRFs falling within the eccentricity range of the electrode arrays and voxels and electrodes with a fit accuracy above a predetermined threshold (fMRI threshold: R<sup>2</sup> &gt; 5%, electrophysiology threshold: R<sup>2</sup> &gt; 50%). To test the robustness of the results for this analysis, we repeated it with different combinations of criteria for initial voxel inclusion (i.e., including only voxels that roughly correspond to the location of the electrode arrays, or including all V1 and V4 voxels) and fit quality (fMRI threshold: R<sup>2</sup> &gt; 5% or 10%, electrophysiology threshold: R<sup>2</sup> &gt; 25% or 50%; <xref ref-type="fig" rid="fig12s1">Figure 12âfigure supplement 1</xref>).</p></sec></sec></body><back><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Funding acquisition, Investigation, Methodology, Project administration, Resources, Software, Visualization, Writing â original draft, Writing â review and editing</p></fn><fn fn-type="con" id="con2"><p>Formal analysis, Funding acquisition, Investigation, Writing â review and editing</p></fn><fn fn-type="con" id="con3"><p>Methodology, Writing â review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Funding acquisition, Resources, Supervision, Writing â review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal care and experimental procedures were in accordance with the ILAR's Guide for the Care and Use of Laboratory Animals, the European legislation (Directive 2010/63/EU) and approved by the institutional animal care and use committee of the Royal Netherlands Academy of Arts and Sciences and the Central Authority for Scientific Procedures on Animals (CCD) in the Netherlands (License numbers AVD8010020173789 and AVD8010020171046).</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Table with region of interest (ROI) abbreviations.</title><p>List of ROI abbreviations, color coded by where in the brain they are located.</p></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-67304-supp1-v3.docx"/></supplementary-material><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-67304-transrepform1-v3.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All data and code are available on GIN: <ext-link ext-link-type="uri" xlink:href="https://doi.gin.g-node.org/10.12751/g-node.2j01af">https://doi.gin.g-node.org/10.12751/g-node.2j01af</ext-link>. Unthresholded fMRI model fitting results are available on Neurovault: <ext-link ext-link-type="uri" xlink:href="https://identifiers.org/neurovault.collection:8082">https://identifiers.org/neurovault.collection:8082</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Klink</surname><given-names>PC</given-names></name><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Vanduffel</surname><given-names>W</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Visual population receptive fields - macaque fMRI</data-title><source>NeuroVault</source><pub-id pub-id-type="accession" xlink:href="https://identifiers.org/neurovault.collection:8082">8082</pub-id></element-citation></p><p><element-citation id="dataset2" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Klink</surname><given-names>PC</given-names></name><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Vanduffel</surname><given-names>W</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Population receptive fields in non-human primates from whole-brain fMRI and large-scale neurophysiology in visual cortex.</data-title><source>GIN</source><pub-id pub-id-type="doi">10.12751/g-node.2j01af</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Jonathan Williford for his contributions to the fMRI preprocessing pipeline; Pieter Buur, Wietske van der Zwaag, Diederick Stoffers, and the Laboratory of Neuro- and Psychophysiology of KU Leuven for technical assistance in setting up the nonhuman primate MR infrastructure; Kor Brandsma, Anneke Ditewig, and Lex Beekman for animal care and biotechnical assistance; Feng Wang for help with electrophysiology data collection; Chris van der Togt for help with data management; and Tomas Knapen and Serge Dumoulin for fruitful discussion and comments on an earlier version of the manuscript. This work was supported by NWO (Crossover Program 17619 'INTENSE'; STW-Perspectief P15-42 'NESTOR'; VENI 451.13.023), the European Union FP7 (ERC 339490 'Cortic_al_gorithms'), the Human Brain Project (agreements 720270 and 785907, 'Human Brain Project SGA1 and SGA2'), and the Friends Foundation of the Netherlands Institute for Neuroscience.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahmadi</surname><given-names>K</given-names></name><name><surname>Fracasso</surname><given-names>A</given-names></name><name><surname>Puzniak</surname><given-names>RJ</given-names></name><name><surname>Gouws</surname><given-names>AD</given-names></name><name><surname>Yakupov</surname><given-names>R</given-names></name><name><surname>Speck</surname><given-names>O</given-names></name><name><surname>Kaufmann</surname><given-names>J</given-names></name><name><surname>Pestilli</surname><given-names>F</given-names></name><name><surname>Dumoulin</surname><given-names>SO</given-names></name><name><surname>Morland</surname><given-names>AB</given-names></name><name><surname>Hoffmann</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Triple visual hemifield maps in a case of optic chiasm hypoplasia</article-title><source>NeuroImage</source><volume>215</volume><elocation-id>116822</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116822</pub-id><pub-id pub-id-type="pmid">32276070</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allman</surname><given-names>JM</given-names></name><name><surname>Miezin</surname><given-names>F</given-names></name><name><surname>McGuinness</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1985">1985</year><article-title>Stimulus specific responses from beyond the classical receptive field: neurophysiological mechanisms for local-global comparisons in visual neurons</article-title><source>Annual Review of Neuroscience</source><volume>8</volume><fpage>407</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1146/annurev.ne.08.030185.002203</pub-id><pub-id pub-id-type="pmid">3885829</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alvarez</surname><given-names>I</given-names></name><name><surname>Smittenaar</surname><given-names>R</given-names></name><name><surname>Handley</surname><given-names>SE</given-names></name><name><surname>Liasis</surname><given-names>A</given-names></name><name><surname>Sereno</surname><given-names>MI</given-names></name><name><surname>Schwarzkopf</surname><given-names>DS</given-names></name><name><surname>Clark</surname><given-names>CA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Altered visual population receptive fields in human albinism</article-title><source>Cortex</source><volume>128</volume><fpage>107</fpage><lpage>123</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2020.03.016</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amano</surname><given-names>K</given-names></name><name><surname>Wandell</surname><given-names>BA</given-names></name><name><surname>Dumoulin</surname><given-names>SO</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Visual Field Maps, Population Receptive Field Sizes, and Visual Field Coverage in the Human MT+ Complex</article-title><source>Journal of Neurophysiology</source><volume>102</volume><fpage>2704</fpage><lpage>2718</lpage><pub-id pub-id-type="doi">10.1152/jn.00102.2009</pub-id><pub-id pub-id-type="pmid">19587323</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amiez</surname><given-names>C</given-names></name><name><surname>Joseph</surname><given-names>JP</given-names></name><name><surname>Procyk</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Reward Encoding in the Monkey Anterior Cingulate Cortex</article-title><source>Cerebral Cortex</source><volume>16</volume><fpage>1040</fpage><lpage>1055</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhj046</pub-id><pub-id pub-id-type="pmid">16207931</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arcaro</surname><given-names>MJ</given-names></name><name><surname>Pinsk</surname><given-names>MA</given-names></name><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Visuotopic Organization of Macaque Posterior Parietal Cortex: A Functional Magnetic Resonance Imaging Study</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>2064</fpage><lpage>2078</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3334-10.2011</pub-id><pub-id pub-id-type="pmid">21307244</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arcaro</surname><given-names>MJ</given-names></name><name><surname>Livingstone</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Retinotopic Organization of Scene Areas in Macaque Inferior Temporal Cortex</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>7373</fpage><lpage>7389</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0569-17.2017</pub-id><pub-id pub-id-type="pmid">28674177</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arsenault</surname><given-names>JT</given-names></name><name><surname>Caspari</surname><given-names>N</given-names></name><name><surname>Vandenberghe</surname><given-names>R</given-names></name><name><surname>Vanduffel</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Attention Shifts Recruit the Monkey Default Mode Network</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>1202</fpage><lpage>1217</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1111-17.2017</pub-id><pub-id pub-id-type="pmid">29263238</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arthurs</surname><given-names>OJ</given-names></name><name><surname>Boniface</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>How well do we understand the neural origins of the fMRI BOLD signal?</article-title><source>Trends in Neurosciences</source><volume>25</volume><fpage>27</fpage><lpage>31</lpage><pub-id pub-id-type="doi">10.1016/s0166-2236(00)01995-0</pub-id><pub-id pub-id-type="pmid">11801335</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barlow</surname><given-names>HB</given-names></name><name><surname>Levick</surname><given-names>WR</given-names></name><name><surname>Westheimer</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1966">1966</year><article-title>Computer-plotted receptive fields</article-title><source>Science</source><volume>154</volume><elocation-id>920</elocation-id><pub-id pub-id-type="doi">10.1126/science.154.3751.920-a</pub-id><pub-id pub-id-type="pmid">6003542</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bartels</surname><given-names>A</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Moutoussis</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>fMRI and its interpretations: an illustration on directional selectivity in area V5/MT</article-title><source>Trends in Neurosciences</source><volume>31</volume><fpage>444</fpage><lpage>453</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2008.06.004</pub-id><pub-id pub-id-type="pmid">18676033</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bartolo</surname><given-names>MJ</given-names></name><name><surname>Gieselmann</surname><given-names>MA</given-names></name><name><surname>Vuksanovic</surname><given-names>V</given-names></name><name><surname>Hunter</surname><given-names>D</given-names></name><name><surname>Sun</surname><given-names>L</given-names></name><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Delicato</surname><given-names>LS</given-names></name><name><surname>Thiele</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Stimulus-induced dissociation of neuronal firing rates and local field potential gamma power and its relationship to the resonance blood oxygen level-dependent signal in macaque primary visual cortex</article-title><source>The European Journal of Neuroscience</source><volume>34</volume><fpage>1857</fpage><lpage>1870</lpage><pub-id pub-id-type="doi">10.1111/j.1460-9568.2011.07877.x</pub-id><pub-id pub-id-type="pmid">22081989</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berens</surname><given-names>P</given-names></name><name><surname>Keliris</surname><given-names>GA</given-names></name><name><surname>Ecker</surname><given-names>AS</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Feature selectivity of the gamma-band of the local field potential in primate primary visual cortex</article-title><source>Frontiers in Neuroscience</source><volume>2</volume><fpage>199</fpage><lpage>207</lpage><pub-id pub-id-type="doi">10.3389/neuro.01.037.2008</pub-id><pub-id pub-id-type="pmid">19225593</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binda</surname><given-names>P</given-names></name><name><surname>Kurzawski</surname><given-names>JW</given-names></name><name><surname>Lunghi</surname><given-names>C</given-names></name><name><surname>Biagi</surname><given-names>L</given-names></name><name><surname>Tosetti</surname><given-names>M</given-names></name><name><surname>Morrone</surname><given-names>MC</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Response to short-term deprivation of the human adult visual cortex measured with 7T BOLD</article-title><source>eLife</source><volume>7</volume><elocation-id>e40014</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.40014</pub-id><pub-id pub-id-type="pmid">30475210</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bokil</surname><given-names>H</given-names></name><name><surname>Andrews</surname><given-names>P</given-names></name><name><surname>Kulkarni</surname><given-names>JE</given-names></name><name><surname>Mehta</surname><given-names>S</given-names></name><name><surname>Mitra</surname><given-names>PP</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Chronux: A platform for analyzing neural signals</article-title><source>Journal of Neuroscience Methods</source><volume>192</volume><fpage>146</fpage><lpage>151</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2010.06.020</pub-id><pub-id pub-id-type="pmid">20637804</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonin</surname><given-names>V</given-names></name><name><surname>Histed</surname><given-names>MH</given-names></name><name><surname>Yurgenson</surname><given-names>S</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Local diversity and fine-scale organization of receptive fields in mouse visual cortex</article-title><source>Journal of Neuroscience</source><volume>31</volume><fpage>18506</fpage><lpage>18521</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2974-11.2011</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boynton</surname><given-names>GM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Spikes, BOLD, Attention, and Awareness: A comparison of electrophysiological and fMRI signals in V1</article-title><source>Journal of Vision</source><volume>11</volume><elocation-id>12</elocation-id><pub-id pub-id-type="doi">10.1167/11.5.12</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brewer</surname><given-names>AA</given-names></name><name><surname>Press</surname><given-names>WA</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Wandell</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Visual Areas in Macaque Cortex Measured Using Functional Magnetic Resonance Imaging</article-title><source>The Journal of Neuroscience</source><volume>22</volume><fpage>10416</fpage><lpage>10426</lpage></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Britten</surname><given-names>KH</given-names></name><name><surname>Heuer</surname><given-names>HW</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Spatial summation in the receptive fields of MT neurons</article-title><source>The Journal of Neuroscience</source><volume>19</volume><fpage>5074</fpage><lpage>5084</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.19-12-05074.1999</pub-id><pub-id pub-id-type="pmid">10366640</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burkhalter</surname><given-names>A</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Processing of color, form and disparity information in visual areas VP and V2 of ventral extrastriate cortex in the macaque monkey</article-title><source>The Journal of Neuroscience</source><volume>6</volume><fpage>2327</fpage><lpage>2351</lpage></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>BuzsÃ¡ki</surname><given-names>G</given-names></name><name><surname>Draguhn</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Neuronal Oscillations in Cortical Networks</article-title><source>Science</source><volume>304</volume><fpage>1926</fpage><lpage>1929</lpage><pub-id pub-id-type="doi">10.1126/science.1099745</pub-id><pub-id pub-id-type="pmid">15218136</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>BuzsÃ¡ki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2006">2006</year><source>Rhythms of the Brain</source><publisher-name>Oxford University Press</publisher-name><pub-id pub-id-type="doi">10.1093/acprof:oso/9780195301069.001.0001</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cavanaugh</surname><given-names>JR</given-names></name><name><surname>Bair</surname><given-names>W</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Nature and interaction of signals from the receptive field center and surround in macaque V1 neurons</article-title><source>Journal of Neurophysiology</source><volume>88</volume><fpage>2530</fpage><lpage>2546</lpage><pub-id pub-id-type="doi">10.1152/jn.00692.2001</pub-id><pub-id pub-id-type="pmid">12424292</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Possel</surname><given-names>JK</given-names></name><name><surname>Wacongne</surname><given-names>C</given-names></name><name><surname>van Ham</surname><given-names>AF</given-names></name><name><surname>Klink</surname><given-names>PC</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>3D printing and modelling of customized implants and surgical guides for non-human primates</article-title><source>Journal of Neuroscience Methods</source><volume>286</volume><fpage>38</fpage><lpage>55</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2017.05.013</pub-id><pub-id pub-id-type="pmid">28512008</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>F</given-names></name><name><surname>Fernandez</surname><given-names>E</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Shape perception via a high-channel-count neuroprosthesis in monkey visual cortex</article-title><source>Science</source><volume>370</volume><fpage>1191</fpage><lpage>1196</lpage><pub-id pub-id-type="doi">10.1126/science.abd7435</pub-id><pub-id pub-id-type="pmid">33273097</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>MR</given-names></name><name><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Attention improves performance primarily by reducing interneuronal correlations</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1594</fpage><lpage>1600</lpage><pub-id pub-id-type="doi">10.1038/nn.2439</pub-id><pub-id pub-id-type="pmid">19915566</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cotton</surname><given-names>PL</given-names></name><name><surname>Smith</surname><given-names>AT</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Contralateral Visual Hemifield Representations in the Human Pulvinar Nucleus</article-title><source>Journal of Neurophysiology</source><volume>98</volume><fpage>1600</fpage><lpage>1609</lpage><pub-id pub-id-type="doi">10.1152/jn.00419.2007</pub-id><pub-id pub-id-type="pmid">17615131</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname><given-names>RW</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>AFNI: Software for Analysis and Visualization of Functional Magnetic Resonance Neuroimages</article-title><source>Computers and Biomedical Research, an International Journal</source><volume>29</volume><fpage>162</fpage><lpage>173</lpage><pub-id pub-id-type="doi">10.1006/cbmr.1996.0014</pub-id><pub-id pub-id-type="pmid">8812068</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Best</surname><given-names>PB</given-names></name><name><surname>Raz</surname><given-names>N</given-names></name><name><surname>Guy</surname><given-names>N</given-names></name><name><surname>Ben-Hur</surname><given-names>T</given-names></name><name><surname>Dumoulin</surname><given-names>SO</given-names></name><name><surname>Pertzov</surname><given-names>Y</given-names></name><name><surname>Levin</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Role of Population Receptive Field Size in Complex Visual Dysfunctions: A Posterior Cortical Atrophy Model</article-title><source>JAMA Neurology</source><volume>76</volume><fpage>1391</fpage><lpage>1396</lpage><pub-id pub-id-type="doi">10.1001/jamaneurol.2019.2447</pub-id><pub-id pub-id-type="pmid">31403655</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dekker</surname><given-names>TM</given-names></name><name><surname>Schwarzkopf</surname><given-names>DS</given-names></name><name><surname>de Haas</surname><given-names>B</given-names></name><name><surname>Nardini</surname><given-names>M</given-names></name><name><surname>Sereno</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Population receptive field tuning properties of visual cortex during childhood</article-title><source>Developmental Cognitive Neuroscience</source><volume>37</volume><elocation-id>100614</elocation-id><pub-id pub-id-type="doi">10.1016/j.dcn.2019.01.001</pub-id><pub-id pub-id-type="pmid">30777677</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeSimone</surname><given-names>K</given-names></name><name><surname>Viviano</surname><given-names>JD</given-names></name><name><surname>Schneider</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Population Receptive Field Estimation Reveals New Retinotopic Maps in Human Subcortex</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>9836</fpage><lpage>9847</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3840-14.2015</pub-id><pub-id pub-id-type="pmid">26156986</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drew</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Vascular and neural basis of the BOLD signal</article-title><source>Current Opinion in Neurobiology</source><volume>58</volume><fpage>61</fpage><lpage>69</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2019.06.004</pub-id><pub-id pub-id-type="pmid">31336326</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dubey</surname><given-names>A</given-names></name><name><surname>Ray</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Spatial spread of local field potential is band-pass in the primary visual cortex</article-title><source>Journal of Neurophysiology</source><volume>116</volume><fpage>1986</fpage><lpage>1999</lpage><pub-id pub-id-type="doi">10.1152/jn.00443.2016</pub-id><pub-id pub-id-type="pmid">27489369</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dumoulin</surname><given-names>SO</given-names></name><name><surname>Wandell</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Population receptive field estimates in human visual cortex</article-title><source>NeuroImage</source><volume>39</volume><fpage>647</fpage><lpage>660</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.09.034</pub-id><pub-id pub-id-type="pmid">17977024</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dumoulin</surname><given-names>SO</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>How Visual Cortical Organization Is Altered by Ophthalmologic and Neurologic Disorders</article-title><source>Annual Review of Vision Science</source><volume>4</volume><fpage>357</fpage><lpage>379</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-091517-033948</pub-id><pub-id pub-id-type="pmid">29889657</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Einevoll</surname><given-names>GT</given-names></name><name><surname>Kayser</surname><given-names>C</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Modelling and analysis of local field potentials for studying the function of cortical circuits</article-title><source>Nature Reviews. Neuroscience</source><volume>14</volume><fpage>770</fpage><lpage>785</lpage><pub-id pub-id-type="doi">10.1038/nrn3599</pub-id><pub-id pub-id-type="pmid">24135696</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ekman</surname><given-names>M</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name><name><surname>de</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Object selection by automatic spreading of top-down attentional signals in V1</article-title><source>The Journal of Neuroscience</source><volume>40</volume><fpage>9250</fpage><lpage>9259</lpage><pub-id pub-id-type="doi">10.1523/jneurosci.0438-20.2020</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ekstrom</surname><given-names>LB</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name><name><surname>Arsenault</surname><given-names>JT</given-names></name><name><surname>Bonmassar</surname><given-names>G</given-names></name><name><surname>Vanduffel</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Bottom-Up Dependent Gating of Frontal Signals in Early Visual Cortex</article-title><source>Science</source><volume>321</volume><fpage>414</fpage><lpage>417</lpage><pub-id pub-id-type="doi">10.1126/science.1153276</pub-id><pub-id pub-id-type="pmid">18635806</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ekstrom</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>How and when the fMRI BOLD signal relates to underlying neural activity: The danger in dissociation</article-title><source>Brain Research Reviews</source><volume>62</volume><fpage>233</fpage><lpage>244</lpage><pub-id pub-id-type="doi">10.1016/j.brainresrev.2009.12.004</pub-id><pub-id pub-id-type="pmid">20026191</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engel</surname><given-names>SA</given-names></name><name><surname>Rumelhart</surname><given-names>DE</given-names></name><name><surname>Wandell</surname><given-names>BA</given-names></name><name><surname>Lee</surname><given-names>AT</given-names></name><name><surname>Glover</surname><given-names>GH</given-names></name><name><surname>Chichilnisky</surname><given-names>EJ</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>fMRI of human visual cortex</article-title><source>Nature</source><volume>369</volume><elocation-id>525</elocation-id><pub-id pub-id-type="doi">10.1038/369525a0</pub-id><pub-id pub-id-type="pmid">8031403</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engel</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The development and use of phase-encoded functional MRI designs</article-title><source>NeuroImage</source><volume>62</volume><fpage>1195</fpage><lpage>1200</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.09.059</pub-id><pub-id pub-id-type="pmid">21985909</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erwin</surname><given-names>E</given-names></name><name><surname>Baker</surname><given-names>FH</given-names></name><name><surname>Busen</surname><given-names>WF</given-names></name><name><surname>Malpeli</surname><given-names>JG</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Relationship between laminar topology and retinotopy in the rhesus lateral geniculate nucleus: Results from a functional atlas</article-title><source>The Journal of Comparative Neurology</source><volume>407</volume><fpage>92</fpage><lpage>102</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1096-9861(19990428)407:13.0.CO;2-1</pub-id><pub-id pub-id-type="pmid">10213190</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Felleman</surname><given-names>DJ</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Receptive field properties of neurons in area V3 of macaque monkey extrastriate cortex</article-title><source>Journal of Neurophysiology</source><volume>57</volume><fpage>889</fpage><lpage>920</lpage><pub-id pub-id-type="doi">10.1152/jn.1987.57.4.889</pub-id><pub-id pub-id-type="pmid">3585463</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fischl</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>FreeSurfer</article-title><source>NeuroImage</source><volume>62</volume><fpage>774</fpage><lpage>781</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.01.021</pub-id><pub-id pub-id-type="pmid">22248573</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fouragnan</surname><given-names>EF</given-names></name><name><surname>Chau</surname><given-names>BKH</given-names></name><name><surname>Folloni</surname><given-names>D</given-names></name><name><surname>Kolling</surname><given-names>N</given-names></name><name><surname>Verhagen</surname><given-names>L</given-names></name><name><surname>Klein-FlÃ¼gge</surname><given-names>M</given-names></name><name><surname>Tankelevitch</surname><given-names>L</given-names></name><name><surname>Papageorgiou</surname><given-names>GK</given-names></name><name><surname>Aubry</surname><given-names>J-F</given-names></name><name><surname>Sallet</surname><given-names>J</given-names></name><name><surname>Rushworth</surname><given-names>MFS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The macaque anterior cingulate cortex translates counterfactual choice value into actual behavioral change</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>797</fpage><lpage>808</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0375-6</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fox</surname><given-names>AS</given-names></name><name><surname>Holley</surname><given-names>D</given-names></name><name><surname>Klink</surname><given-names>PC</given-names></name><name><surname>Arbuckle</surname><given-names>SA</given-names></name><name><surname>Barnes</surname><given-names>CA</given-names></name><name><surname>Diedrichsen</surname><given-names>J</given-names></name><name><surname>Kwok</surname><given-names>SC</given-names></name><name><surname>Kyle</surname><given-names>C</given-names></name><name><surname>Pruszynski</surname><given-names>JA</given-names></name><name><surname>Seidlitz</surname><given-names>J</given-names></name><name><surname>Zhou</surname><given-names>X</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name><name><surname>Gorgolewski</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Sharing voxelwise neuroimaging results from rhesus monkeys and other species with Neurovault</article-title><source>NeuroImage</source><volume>225</volume><elocation-id>117518</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117518</pub-id><pub-id pub-id-type="pmid">33137472</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname><given-names>JS</given-names></name><name><surname>Huth</surname><given-names>AG</given-names></name><name><surname>Lescroart</surname><given-names>MD</given-names></name><name><surname>Gallant</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Pycortex: an interactive surface visualizer for fMRI</article-title><source>Frontiers in Neuroinformatics</source><volume>9</volume><elocation-id>23</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2015.00023</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gattass</surname><given-names>R</given-names></name><name><surname>Gross</surname><given-names>CG</given-names></name><name><surname>Sandell</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="1981">1981</year><article-title>Visual topography of V2 in the macaque</article-title><source>The Journal of Comparative Neurology</source><volume>201</volume><fpage>519</fpage><lpage>539</lpage><pub-id pub-id-type="doi">10.1002/cne.902010405</pub-id><pub-id pub-id-type="pmid">7287933</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gattass</surname><given-names>R</given-names></name><name><surname>Sousa</surname><given-names>AP</given-names></name><name><surname>Rosa</surname><given-names>MG</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Visual topography of V1 in the Cebus monkey</article-title><source>The Journal of Comparative Neurology</source><volume>259</volume><fpage>529</fpage><lpage>548</lpage><pub-id pub-id-type="doi">10.1002/cne.902590404</pub-id><pub-id pub-id-type="pmid">3597827</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gattass</surname><given-names>R</given-names></name><name><surname>Sousa</surname><given-names>AP</given-names></name><name><surname>Gross</surname><given-names>CG</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Visuotopic organization and extent of V3 and V4 of the macaque</article-title><source>The Journal of Neuroscience</source><volume>8</volume><fpage>1831</fpage><lpage>1845</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.08-06-01831.1988</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gattass</surname><given-names>R</given-names></name><name><surname>Nascimento-Silva</surname><given-names>S</given-names></name><name><surname>Soares</surname><given-names>JGM</given-names></name><name><surname>Lima</surname><given-names>B</given-names></name><name><surname>Jansen</surname><given-names>AK</given-names></name><name><surname>Diogo</surname><given-names>ACM</given-names></name><name><surname>Farias</surname><given-names>MF</given-names></name><name><surname>Botelho</surname><given-names>M</given-names></name><name><surname>Mariani</surname><given-names>OS</given-names></name><name><surname>Azzi</surname><given-names>J</given-names></name><name><surname>Fiorani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Cortical visual areas in monkeys: location, topography, connections, columns, plasticity and cortical dynamics</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>360</volume><fpage>709</fpage><lpage>731</lpage><pub-id pub-id-type="doi">10.1098/rstb.2005.1629</pub-id><pub-id pub-id-type="pmid">15937009</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goense</surname><given-names>JBM</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Neurophysiology of the BOLD fMRI signal in awake monkeys</article-title><source>Current Biology</source><volume>18</volume><fpage>631</fpage><lpage>640</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2008.03.054</pub-id><pub-id pub-id-type="pmid">18439825</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorgolewski</surname><given-names>KJ</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name><name><surname>Rivera</surname><given-names>G</given-names></name><name><surname>Schwarz</surname><given-names>Y</given-names></name><name><surname>Ghosh</surname><given-names>SS</given-names></name><name><surname>Maumet</surname><given-names>C</given-names></name><name><surname>Sochat</surname><given-names>VV</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name><name><surname>Poline</surname><given-names>JB</given-names></name><name><surname>Yarkoni</surname><given-names>T</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>NeuroVault.org: a web-based repository for collecting and sharing unthresholded statistical maps of the human brain</article-title><source>Frontiers in Neuroinformatics</source><volume>9</volume><elocation-id>8</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2015.00008</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Green</surname><given-names>T</given-names></name><name><surname>Hosseini</surname><given-names>H</given-names></name><name><surname>Piccirilli</surname><given-names>A</given-names></name><name><surname>Ishak</surname><given-names>A</given-names></name><name><surname>Grill-Spector</surname><given-names>K</given-names></name><name><surname>Reiss</surname><given-names>AL</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>X-Chromosome Insufficiency Alters Receptive Fields across the Human Early Visual Cortex</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>8079</fpage><lpage>8088</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2745-18.2019</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greene</surname><given-names>CA</given-names></name><name><surname>Dumoulin</surname><given-names>SO</given-names></name><name><surname>Harvey</surname><given-names>BM</given-names></name><name><surname>Ress</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Measurement of population receptive fields in human early visual cortex using back-projection tomography</article-title><source>Journal of Vision</source><volume>14</volume><elocation-id>17</elocation-id><pub-id pub-id-type="doi">10.1167/14.1.17</pub-id><pub-id pub-id-type="pmid">24453343</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffis</surname><given-names>JC</given-names></name><name><surname>Elkhetali</surname><given-names>AS</given-names></name><name><surname>Burge</surname><given-names>WK</given-names></name><name><surname>Chen</surname><given-names>RH</given-names></name><name><surname>Bowman</surname><given-names>AD</given-names></name><name><surname>Szaflarski</surname><given-names>JP</given-names></name><name><surname>Visscher</surname><given-names>KM</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Retinotopic patterns of functional connectivity between V1 and large-scale brain networks during resting fixation</article-title><source>NeuroImage</source><volume>146</volume><fpage>1071</fpage><lpage>1083</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.08.035</pub-id><pub-id pub-id-type="pmid">27554527</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Griffiths</surname><given-names>BJ</given-names></name><name><surname>Mayhew</surname><given-names>SD</given-names></name><name><surname>Mullinger</surname><given-names>KJ</given-names></name><name><surname>Jorge</surname><given-names>J</given-names></name><name><surname>Charest</surname><given-names>I</given-names></name><name><surname>Wimber</surname><given-names>M</given-names></name><name><surname>Hanslmayr</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Alpha/beta power decreases track the fidelity of stimulus-specific information</article-title><source>eLife</source><volume>8</volume><elocation-id>e49562</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.49562</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haak</surname><given-names>KV</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name><name><surname>Harvey</surname><given-names>BM</given-names></name><name><surname>Renken</surname><given-names>R</given-names></name><name><surname>Dumoulin</surname><given-names>SO</given-names></name><name><surname>Wandell</surname><given-names>BA</given-names></name><name><surname>Cornelissen</surname><given-names>FW</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Connective field modeling</article-title><source>NeuroImage</source><volume>66</volume><fpage>376</fpage><lpage>384</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.10.037</pub-id><pub-id pub-id-type="pmid">23110879</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hartline</surname><given-names>HK</given-names></name></person-group><year iso-8601-date="1938">1938</year><article-title>The response of single optic nerve fibers of the vertebrate eye to illumination of the retina</article-title><source>American Journal of Physiology-Legacy Content</source><volume>121</volume><fpage>400</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1152/ajplegacy.1938.121.2.400</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname><given-names>BM</given-names></name><name><surname>Vansteensel</surname><given-names>MJ</given-names></name><name><surname>Ferrier</surname><given-names>CH</given-names></name><name><surname>Petridou</surname><given-names>N</given-names></name><name><surname>Zuiderbaan</surname><given-names>W</given-names></name><name><surname>Aarnoutse</surname><given-names>EJ</given-names></name><name><surname>Bleichner</surname><given-names>MG</given-names></name><name><surname>Dijkerman</surname><given-names>HC</given-names></name><name><surname>van Zandvoort</surname><given-names>MJE</given-names></name><name><surname>Leijten</surname><given-names>FSS</given-names></name><name><surname>Ramsey</surname><given-names>NF</given-names></name><name><surname>Dumoulin</surname><given-names>SO</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Frequency specific spatial interactions in human electrocorticography: V1 alpha oscillations reflect surround suppression</article-title><source>NeuroImage</source><volume>65</volume><fpage>424</fpage><lpage>432</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2012.10.020</pub-id><pub-id pub-id-type="pmid">23085107</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname><given-names>BM</given-names></name><name><surname>Fracasso</surname><given-names>A</given-names></name><name><surname>Petridou</surname><given-names>N</given-names></name><name><surname>Dumoulin</surname><given-names>SO</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Topographic representations of object size and relationships with numerosity reveal generalized quantity processing in human parietal cortex</article-title><source>PNAS</source><volume>112</volume><fpage>13525</fpage><lpage>13530</lpage><pub-id pub-id-type="doi">10.1073/pnas.1515414112</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harvey</surname><given-names>BM</given-names></name><name><surname>Dumoulin</surname><given-names>SO</given-names></name><name><surname>Fracasso</surname><given-names>A</given-names></name><name><surname>Paul</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A Network of Topographic Maps in Human Association Cortex Hierarchically Transforms Visual Timing-Selective Responses</article-title><source>Current Biology</source><volume>30</volume><fpage>1424</fpage><lpage>1434</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2020.01.090</pub-id><pub-id pub-id-type="pmid">32142704</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>He</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Fang</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The Critical Role of V2 Population Receptive Fields in Visual Orientation Crowding</article-title><source>Current Biology</source><volume>29</volume><fpage>2229</fpage><lpage>2236</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.05.068</pub-id><pub-id pub-id-type="pmid">31231052</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hikosaka</surname><given-names>O</given-names></name><name><surname>Sakamoto</surname><given-names>M</given-names></name><name><surname>Usui</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1989">1989a</year><article-title>Functional properties of monkey caudate neurons. II. Visual and auditory responses</article-title><source>Journal of Neurophysiology</source><volume>61</volume><fpage>799</fpage><lpage>813</lpage><pub-id pub-id-type="doi">10.1152/jn.1989.61.4.799</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hikosaka</surname><given-names>O</given-names></name><name><surname>Sakamoto</surname><given-names>M</given-names></name><name><surname>Usui</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1989">1989b</year><article-title>Functional properties of monkey caudate neurons. III. Activities related to expectation of target and reward</article-title><source>Journal of Neurophysiology</source><volume>61</volume><fpage>814</fpage><lpage>832</lpage><pub-id pub-id-type="doi">10.1152/jn.1989.61.4.814</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><year iso-8601-date="1959">1959</year><article-title>Receptive fields of single neurones in the catâs striate cortex</article-title><source>The Journal of Physiology</source><volume>148</volume><fpage>574</fpage><lpage>591</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1959.sp006308</pub-id><pub-id pub-id-type="pmid">14403679</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><year iso-8601-date="1962">1962</year><article-title>Receptive fields, binocular interaction and functional architecture in the catâs visual cortex</article-title><source>The Journal of Physiology</source><volume>160</volume><fpage>106</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1962.sp006837</pub-id><pub-id pub-id-type="pmid">14449617</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><year iso-8601-date="1968">1968</year><article-title>Receptive fields and functional architecture of monkey striate cortex</article-title><source>The Journal of Physiology</source><volume>195</volume><fpage>215</fpage><lpage>243</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1968.sp008455</pub-id><pub-id pub-id-type="pmid">4966457</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>Uniformity of monkey striate cortex: a parallel relationship between field size, scatter, and magnification factor</article-title><source>The Journal of Comparative Neurology</source><volume>158</volume><fpage>295</fpage><lpage>305</lpage><pub-id pub-id-type="doi">10.1002/cne.901580305</pub-id><pub-id pub-id-type="pmid">4436457</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Early exploration of the visual cortex</article-title><source>Neuron</source><volume>20</volume><fpage>401</fpage><lpage>412</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(00)80984-8</pub-id><pub-id pub-id-type="pmid">9539118</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hughes</surname><given-names>AE</given-names></name><name><surname>Greenwood</surname><given-names>JA</given-names></name><name><surname>Finlayson</surname><given-names>NJ</given-names></name><name><surname>Schwarzkopf</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Population receptive field estimates for motion-defined stimuli</article-title><source>NeuroImage</source><volume>199</volume><fpage>245</fpage><lpage>260</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.05.068</pub-id><pub-id pub-id-type="pmid">31158480</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Janssens</surname><given-names>T</given-names></name><name><surname>Zhu</surname><given-names>Q</given-names></name><name><surname>Popivanov</surname><given-names>ID</given-names></name><name><surname>Vanduffel</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Probabilistic and Single-Subject Retinotopic Maps Reveal the Topographic Organization of Face Patches in the Macaque Cortex</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>10156</fpage><lpage>10167</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2914-13.2013</pub-id><pub-id pub-id-type="pmid">25080579</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jenkinson</surname><given-names>M</given-names></name><name><surname>Bannister</surname><given-names>P</given-names></name><name><surname>Brady</surname><given-names>M</given-names></name><name><surname>Smith</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Improved Optimization for the Robust and Accurate Linear Registration and Motion Correction of Brain Images</article-title><source>NeuroImage</source><volume>17</volume><fpage>825</fpage><lpage>841</lpage><pub-id pub-id-type="doi">10.1016/s1053-8119(02)91132-8</pub-id><pub-id pub-id-type="pmid">12377157</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kajikawa</surname><given-names>Y</given-names></name><name><surname>Schroeder</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>How local is the local field potential?</article-title><source>Neuron</source><volume>72</volume><fpage>847</fpage><lpage>858</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.09.029</pub-id><pub-id pub-id-type="pmid">22153379</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Katzner</surname><given-names>S</given-names></name><name><surname>Nauhaus</surname><given-names>I</given-names></name><name><surname>Benucci</surname><given-names>A</given-names></name><name><surname>Bonin</surname><given-names>V</given-names></name><name><surname>Ringach</surname><given-names>DL</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Local origin of field potentials in visual cortex</article-title><source>Neuron</source><volume>61</volume><fpage>35</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.11.016</pub-id><pub-id pub-id-type="pmid">19146811</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kay</surname><given-names>KN</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name><name><surname>Mezer</surname><given-names>A</given-names></name><name><surname>Wandell</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Compressive spatial summation in human visual cortex</article-title><source>Journal of Neurophysiology</source><volume>110</volume><fpage>481</fpage><lpage>494</lpage><pub-id pub-id-type="doi">10.1152/jn.00105.2013</pub-id><pub-id pub-id-type="pmid">23615546</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keliris</surname><given-names>GA</given-names></name><name><surname>Li</surname><given-names>Q</given-names></name><name><surname>Papanikolaou</surname><given-names>A</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Smirnakis</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Estimating average single-neuron visual receptive field sizes by fMRI</article-title><source>PNAS</source><volume>116</volume><fpage>6425</fpage><lpage>6434</lpage><pub-id pub-id-type="doi">10.1073/pnas.1809612116</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klink</surname><given-names>PC</given-names></name><name><surname>Dagnino</surname><given-names>B</given-names></name><name><surname>Gariel-Mathis</surname><given-names>MA</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Distinct Feedforward and Feedback Effects of Microstimulation in Visual Cortex Reveal Neural Mechanisms of Texture Segregation</article-title><source>Neuron</source><volume>95</volume><fpage>209</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.05.033</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Klink</surname><given-names>PC</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>NHP_Freesurfer</data-title><version designator="swh:1:rev:8d4b89337b865fb194e196cf1b2af4967e14d607">swh:1:rev:8d4b89337b865fb194e196cf1b2af4967e14d607</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:d8a1a76a4f91921900b4f0ede328f5acdeb03c37;origin=https://github.com/VisionandCognition/NHP-Freesurfer;visit=swh:1:snp:7b5338bc3ee68190df2c473e45629d3ce2640840;anchor=swh:1:rev:8d4b89337b865fb194e196cf1b2af4967e14d607">https://archive.softwareheritage.org/swh:1:dir:d8a1a76a4f91921900b4f0ede328f5acdeb03c37;origin=https://github.com/VisionandCognition/NHP-Freesurfer;visit=swh:1:snp:7b5338bc3ee68190df2c473e45629d3ce2640840;anchor=swh:1:rev:8d4b89337b865fb194e196cf1b2af4967e14d607</ext-link></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Knierim</surname><given-names>JJ</given-names></name><name><surname>van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Neuronal responses to static texture patterns in area V1 of the alert macaque monkey</article-title><source>Journal of Neurophysiology</source><volume>67</volume><fpage>961</fpage><lpage>980</lpage><pub-id pub-id-type="doi">10.1152/jn.1992.67.4.961</pub-id><pub-id pub-id-type="pmid">1588394</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kolster</surname><given-names>H</given-names></name><name><surname>Mandeville</surname><given-names>JB</given-names></name><name><surname>Arsenault</surname><given-names>JT</given-names></name><name><surname>Ekstrom</surname><given-names>LB</given-names></name><name><surname>Wald</surname><given-names>LL</given-names></name><name><surname>Vanduffel</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Visual field map clusters in macaque extrastriate visual cortex</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>7031</fpage><lpage>7039</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0518-09.2009</pub-id><pub-id pub-id-type="pmid">19474330</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kolster</surname><given-names>H</given-names></name><name><surname>Peeters</surname><given-names>R</given-names></name><name><surname>Orban</surname><given-names>GA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The retinotopic organization of the human middle temporal area MT/V5 and its cortical neighbors</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>9801</fpage><lpage>9820</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2069-10.2010</pub-id><pub-id pub-id-type="pmid">20660263</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kolster</surname><given-names>H</given-names></name><name><surname>Janssens</surname><given-names>T</given-names></name><name><surname>Orban</surname><given-names>GA</given-names></name><name><surname>Vanduffel</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The retinotopic organization of macaque occipitotemporal cortex anterior to V4 and caudoventral to the middle temporal (MT) cluster</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>10168</fpage><lpage>10191</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3288-13.2014</pub-id><pub-id pub-id-type="pmid">25080580</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kreiman</surname><given-names>G</given-names></name><name><surname>Hung</surname><given-names>CP</given-names></name><name><surname>Kraskov</surname><given-names>A</given-names></name><name><surname>Quiroga</surname><given-names>RQ</given-names></name><name><surname>Poggio</surname><given-names>T</given-names></name><name><surname>DiCarlo</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Object selectivity of local field potentials and spikes in the macaque inferior temporal cortex</article-title><source>Neuron</source><volume>49</volume><fpage>433</fpage><lpage>445</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2005.12.019</pub-id><pub-id pub-id-type="pmid">16446146</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larsson</surname><given-names>J</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Two retinotopic visual areas in human lateral occipital cortex</article-title><source>The Journal of Neuroscience</source><volume>26</volume><fpage>13128</fpage><lpage>13142</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1657-06.2006</pub-id><pub-id pub-id-type="pmid">17182764</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lerma-Usabiaga</surname><given-names>G</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name><name><surname>Wandell</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Population Receptive Field Shapes in Early Visual Cortex Are Nearly Circular</article-title><source>The Journal of Neuroscience</source><volume>41</volume><fpage>2420</fpage><lpage>2427</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3052-20.2021</pub-id><pub-id pub-id-type="pmid">33531414</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leski</surname><given-names>S</given-names></name><name><surname>LindÃ©n</surname><given-names>H</given-names></name><name><surname>Tetzlaff</surname><given-names>T</given-names></name><name><surname>Pettersen</surname><given-names>KH</given-names></name><name><surname>Einevoll</surname><given-names>GT</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Frequency Dependence of Signal Power and Spatial Reach of the Local Field Potential</article-title><source>PLOS Computational Biology</source><volume>9</volume><elocation-id>e1003137</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003137</pub-id><pub-id pub-id-type="pmid">23874180</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>X</given-names></name><name><surname>Morgan</surname><given-names>PS</given-names></name><name><surname>Ashburner</surname><given-names>J</given-names></name><name><surname>Smith</surname><given-names>J</given-names></name><name><surname>Rorden</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The first step for neuroimaging data analysis: DICOM to NIfTI conversion</article-title><source>Journal of Neuroscience Methods</source><volume>264</volume><fpage>47</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2016.03.001</pub-id><pub-id pub-id-type="pmid">26945974</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lima</surname><given-names>B</given-names></name><name><surname>Cardoso</surname><given-names>MMB</given-names></name><name><surname>Sirotin</surname><given-names>YB</given-names></name><name><surname>Das</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Stimulus-Related Neuroimaging in Task-Engaged Subjects Is Best Predicted by Concurrent Spiking</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>13878</fpage><lpage>13891</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1595-14.2014</pub-id><pub-id pub-id-type="pmid">25319685</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Pauls</surname><given-names>J</given-names></name><name><surname>Augath</surname><given-names>MA</given-names></name><name><surname>Trinath</surname><given-names>T</given-names></name><name><surname>Oeltermann</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Neurophysiological investigation of the basis of the fMRI signal</article-title><source>Nature</source><volume>412</volume><fpage>150</fpage><lpage>157</lpage><pub-id pub-id-type="doi">10.1038/35084005</pub-id><pub-id pub-id-type="pmid">11449264</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Logothetis</surname><given-names>NK</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>The underpinnings of the BOLD functional magnetic resonance imaging signal</article-title><source>The Journal of Neuroscience</source><volume>23</volume><fpage>3963</fpage><lpage>3971</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.23-10-03963.2003</pub-id><pub-id pub-id-type="pmid">12764080</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Wandell</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Interpreting the BOLD Signal</article-title><source>Annual Review of Physiology</source><volume>66</volume><fpage>735</fpage><lpage>769</lpage><pub-id pub-id-type="doi">10.1146/annurev.physiol.66.082602.092845</pub-id><pub-id pub-id-type="pmid">14977420</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Logothetis</surname><given-names>NK</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Neurovascular uncoupling: Much ado about nothing</article-title><source>Frontiers in Neuroenergetics</source><volume>2</volume><elocation-id>2</elocation-id><pub-id pub-id-type="doi">10.3389/fnene.2010.00002</pub-id><pub-id pub-id-type="pmid">20725519</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maier</surname><given-names>A</given-names></name><name><surname>Wilke</surname><given-names>M</given-names></name><name><surname>Aura</surname><given-names>C</given-names></name><name><surname>Zhu</surname><given-names>C</given-names></name><name><surname>Ye</surname><given-names>FQ</given-names></name><name><surname>Leopold</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Divergence of fMRI and neural signals in V1 during perceptual suppression in the awake monkey</article-title><source>Nature Neuroscience</source><volume>11</volume><fpage>1193</fpage><lpage>1200</lpage><pub-id pub-id-type="doi">10.1038/nn.2173</pub-id><pub-id pub-id-type="pmid">18711393</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mantini</surname><given-names>D</given-names></name><name><surname>Gerits</surname><given-names>A</given-names></name><name><surname>Nelissen</surname><given-names>K</given-names></name><name><surname>Durand</surname><given-names>JB</given-names></name><name><surname>Joly</surname><given-names>O</given-names></name><name><surname>Simone</surname><given-names>L</given-names></name><name><surname>Sawamura</surname><given-names>H</given-names></name><name><surname>Wardak</surname><given-names>C</given-names></name><name><surname>Orban</surname><given-names>GA</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name><name><surname>Vanduffel</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Default mode of brain function in monkeys</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>12954</fpage><lpage>12962</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2318-11.2011</pub-id><pub-id pub-id-type="pmid">21900574</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Merkel</surname><given-names>C</given-names></name><name><surname>Hopf</surname><given-names>JM</given-names></name><name><surname>Schoenfeld</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Spatial elongation of population receptive field profiles revealed by model-free fMRI back-projection</article-title><source>Human Brain Mapping</source><volume>39</volume><fpage>2472</fpage><lpage>2481</lpage><pub-id pub-id-type="doi">10.1002/hbm.24015</pub-id><pub-id pub-id-type="pmid">29464880</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Messinger</surname><given-names>A</given-names></name><name><surname>Sirmpilatze</surname><given-names>N</given-names></name><name><surname>Heuer</surname><given-names>K</given-names></name><name><surname>Loh</surname><given-names>KK</given-names></name><name><surname>Mars</surname><given-names>RB</given-names></name><name><surname>Sein</surname><given-names>J</given-names></name><name><surname>Xu</surname><given-names>T</given-names></name><name><surname>Glen</surname><given-names>D</given-names></name><name><surname>Jung</surname><given-names>B</given-names></name><name><surname>Seidlitz</surname><given-names>J</given-names></name><name><surname>Taylor</surname><given-names>P</given-names></name><name><surname>Toro</surname><given-names>R</given-names></name><name><surname>Garza-Villarreal</surname><given-names>EA</given-names></name><name><surname>Sponheim</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Benn</surname><given-names>RA</given-names></name><name><surname>Cagna</surname><given-names>B</given-names></name><name><surname>Dadarwal</surname><given-names>R</given-names></name><name><surname>Evrard</surname><given-names>HC</given-names></name><name><surname>Garcia-Saldivar</surname><given-names>P</given-names></name><name><surname>Giavasis</surname><given-names>S</given-names></name><name><surname>Hartig</surname><given-names>R</given-names></name><name><surname>Lepage</surname><given-names>C</given-names></name><name><surname>Liu</surname><given-names>C</given-names></name><name><surname>Majka</surname><given-names>P</given-names></name><name><surname>Merchant</surname><given-names>H</given-names></name><name><surname>Milham</surname><given-names>MP</given-names></name><name><surname>Rosa</surname><given-names>MGP</given-names></name><name><surname>Tasserie</surname><given-names>J</given-names></name><name><surname>Uhrig</surname><given-names>L</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Klink</surname><given-names>PC</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>A collaborative resource platform for non-human primate neuroimaging</article-title><source>NeuroImage</source><volume>226</volume><elocation-id>117519</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.117519</pub-id><pub-id pub-id-type="pmid">33227425</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mo</surname><given-names>C</given-names></name><name><surname>He</surname><given-names>D</given-names></name><name><surname>Fang</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Attention priority map of face images in human early visual cortex</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>149</fpage><lpage>157</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1206-17.2017</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mukamel</surname><given-names>R</given-names></name><name><surname>Gelbard</surname><given-names>H</given-names></name><name><surname>Arieli</surname><given-names>A</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name><name><surname>Malach</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Coupling between neuronal firing, field potentials, and FMRI in human auditory cortex</article-title><source>Science</source><volume>309</volume><fpage>951</fpage><lpage>954</lpage><pub-id pub-id-type="doi">10.1126/science.1110913</pub-id><pub-id pub-id-type="pmid">16081741</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nelson</surname><given-names>MJ</given-names></name><name><surname>Pouget</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Do electrode properties create a problem in interpreting local field potential recordings?</article-title><source>Journal of Neurophysiology</source><volume>103</volume><fpage>2315</fpage><lpage>2317</lpage><pub-id pub-id-type="doi">10.1152/jn.00157.2010</pub-id><pub-id pub-id-type="pmid">20220081</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Maunsell</surname><given-names>JH</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Ventral posterior visual area of the macaque: visual topography and areal boundaries</article-title><source>The Journal of Comparative Neurology</source><volume>252</volume><fpage>139</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1002/cne.902520202</pub-id><pub-id pub-id-type="pmid">3782504</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niessing</surname><given-names>J</given-names></name><name><surname>Ebisch</surname><given-names>B</given-names></name><name><surname>Schmidt</surname><given-names>KE</given-names></name><name><surname>Niessing</surname><given-names>M</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name><name><surname>Galuske</surname><given-names>RAW</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Hemodynamic Signals Correlate Tightly with Synchronized Gamma Oscillations</article-title><source>Science</source><volume>309</volume><fpage>948</fpage><lpage>951</lpage><pub-id pub-id-type="doi">10.1126/science.1110948</pub-id><pub-id pub-id-type="pmid">16081740</pub-id></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nir</surname><given-names>Y</given-names></name><name><surname>Fisch</surname><given-names>L</given-names></name><name><surname>Mukamel</surname><given-names>R</given-names></name><name><surname>Gelbard-Sagiv</surname><given-names>H</given-names></name><name><surname>Arieli</surname><given-names>A</given-names></name><name><surname>Fried</surname><given-names>I</given-names></name><name><surname>Malach</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Coupling between Neuronal Firing Rate, Gamma LFP, and BOLD fMRI Is Related to Interneuronal Correlations</article-title><source>Current Biology</source><volume>17</volume><fpage>1275</fpage><lpage>1285</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2007.06.066</pub-id><pub-id pub-id-type="pmid">17686438</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oleksiak</surname><given-names>A</given-names></name><name><surname>Klink</surname><given-names>PC</given-names></name><name><surname>Postma</surname><given-names>A</given-names></name><name><surname>van der Ham</surname><given-names>IJM</given-names></name><name><surname>Lankheet</surname><given-names>MJ</given-names></name><name><surname>van Wezel</surname><given-names>RJA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Spatial summation in macaque parietal area 7a follows a winner-take-all rule</article-title><source>Journal of Neurophysiology</source><volume>105</volume><fpage>1150</fpage><lpage>1158</lpage><pub-id pub-id-type="doi">10.1152/jn.00907.2010</pub-id><pub-id pub-id-type="pmid">21177995</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palmer</surname><given-names>C</given-names></name><name><surname>Cheng</surname><given-names>S-Y</given-names></name><name><surname>Seidemann</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Linking neuronal and behavioral performance in a reaction-time visual detection task</article-title><source>The Journal of Neuroscience</source><volume>27</volume><fpage>8122</fpage><lpage>8137</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1940-07.2007</pub-id><pub-id pub-id-type="pmid">17652603</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Papageorgiou</surname><given-names>TD</given-names></name><name><surname>Christopoulos</surname><given-names>GI</given-names></name><name><surname>Smirnakis</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2014">2014</year><source>Advanced Brain Neuroimaging Topics in Health and Disease</source><publisher-name>Methods and Applications</publisher-name><pub-id pub-id-type="doi">10.5772/58256</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patel</surname><given-names>GH</given-names></name><name><surname>Shulman</surname><given-names>GL</given-names></name><name><surname>Baker</surname><given-names>JT</given-names></name><name><surname>Akbudak</surname><given-names>E</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Snyder</surname><given-names>LH</given-names></name><name><surname>Corbetta</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Topographic organization of macaque area LIP</article-title><source>PNAS</source><volume>107</volume><fpage>4728</fpage><lpage>4733</lpage><pub-id pub-id-type="doi">10.1073/pnas.0908092107</pub-id><pub-id pub-id-type="pmid">20173093</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poltoratski</surname><given-names>S</given-names></name><name><surname>Maier</surname><given-names>A</given-names></name><name><surname>Newton</surname><given-names>AT</given-names></name><name><surname>Tong</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Figure-Ground Modulation in the Human Lateral Geniculate Nucleus Is Distinguishable from Top-Down Attention</article-title><source>Current Biology</source><volume>29</volume><fpage>2051</fpage><lpage>2057</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.04.068</pub-id></element-citation></ref><ref id="bib109"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poltoratski</surname><given-names>S</given-names></name><name><surname>Tong</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Resolving the spatial profile of figure enhancement in human V1 through population receptive field modeling</article-title><source>The Journal of Neuroscience</source><volume>40</volume><fpage>3292</fpage><lpage>3303</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2377-19.2020</pub-id></element-citation></ref><ref id="bib110"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poort</surname><given-names>J</given-names></name><name><surname>Raudies</surname><given-names>F</given-names></name><name><surname>Wannig</surname><given-names>A</given-names></name><name><surname>Lamme</surname><given-names>VAF</given-names></name><name><surname>Neumann</surname><given-names>H</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The role of attention in figure-ground segregation in areas v1 and v4 of the visual cortex</article-title><source>Neuron</source><volume>75</volume><fpage>143</fpage><lpage>156</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2012.04.032</pub-id><pub-id pub-id-type="pmid">22794268</pub-id></element-citation></ref><ref id="bib111"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Priebe</surname><given-names>NJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The relationship between subthreshold and suprathreshold ocular dominance in cat primary visual cortex</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>8553</fpage><lpage>8559</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2182-08.2008</pub-id><pub-id pub-id-type="pmid">18716214</pub-id></element-citation></ref><ref id="bib112"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Puckett</surname><given-names>AM</given-names></name><name><surname>Bollmann</surname><given-names>S</given-names></name><name><surname>Junday</surname><given-names>K</given-names></name><name><surname>Barth</surname><given-names>M</given-names></name><name><surname>Cunnington</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Bayesian population receptive field modeling in human somatosensory cortex</article-title><source>NeuroImage</source><volume>208</volume><elocation-id>116465</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116465</pub-id><pub-id pub-id-type="pmid">31863915</pub-id></element-citation></ref><ref id="bib113"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rees</surname><given-names>G</given-names></name><name><surname>Friston</surname><given-names>K</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>A direct quantitative relationship between the functional properties of human and macaque V5</article-title><source>Nature Neuroscience</source><volume>3</volume><fpage>716</fpage><lpage>723</lpage><pub-id pub-id-type="doi">10.1038/76673</pub-id><pub-id pub-id-type="pmid">10862705</pub-id></element-citation></ref><ref id="bib114"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reveley</surname><given-names>C</given-names></name><name><surname>Gruslys</surname><given-names>A</given-names></name><name><surname>Ye</surname><given-names>FQ</given-names></name><name><surname>Glen</surname><given-names>D</given-names></name><name><surname>Samaha</surname><given-names>J</given-names></name><name><surname>E Russ</surname><given-names>B</given-names></name><name><surname>Saad</surname><given-names>Z</given-names></name><name><surname>K Seth</surname><given-names>A</given-names></name><name><surname>Leopold</surname><given-names>DA</given-names></name><name><surname>Saleem</surname><given-names>KS</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Three-Dimensional Digital Template Atlas of the Macaque Brain</article-title><source>Cerebral Cortex</source><volume>27</volume><fpage>4463</fpage><lpage>4477</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw248</pub-id><pub-id pub-id-type="pmid">27566980</pub-id></element-citation></ref><ref id="bib115"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rima</surname><given-names>S</given-names></name><name><surname>Cottereau</surname><given-names>BR</given-names></name><name><surname>HÃ©jja-Brichard</surname><given-names>Y</given-names></name><name><surname>Trotter</surname><given-names>Y</given-names></name><name><surname>Durand</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Wide-field retinotopy reveals a new visuotopic cluster in macaque posterior parietal cortex</article-title><source>Brain Structure &amp; Function</source><volume>225</volume><fpage>2447</fpage><lpage>2461</lpage><pub-id pub-id-type="doi">10.1007/s00429-020-02134-2</pub-id><pub-id pub-id-type="pmid">32875354</pub-id></element-citation></ref><ref id="bib116"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname><given-names>ET</given-names></name><name><surname>Thorpe</surname><given-names>SJ</given-names></name><name><surname>Maddison</surname><given-names>SP</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Responses of striatal neurons in the behaving monkey. 1. Head of the caudate nucleus</article-title><source>Behavioural Brain Research</source><volume>7</volume><fpage>179</fpage><lpage>210</lpage><pub-id pub-id-type="doi">10.1016/0166-4328(83)90191-2</pub-id></element-citation></ref><ref id="bib117"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosa</surname><given-names>MGP</given-names></name><name><surname>Sousa</surname><given-names>APB</given-names></name><name><surname>Gattass</surname><given-names>R</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Representation of the visual field in the second visual area in the Cebus monkey</article-title><source>The Journal of Comparative Neurology</source><volume>275</volume><fpage>326</fpage><lpage>345</lpage><pub-id pub-id-type="doi">10.1002/cne.902750303</pub-id><pub-id pub-id-type="pmid">3225342</pub-id></element-citation></ref><ref id="bib118"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosa</surname><given-names>MGP</given-names></name><name><surname>PiÃ±on</surname><given-names>MC</given-names></name><name><surname>Gattass</surname><given-names>R</given-names></name><name><surname>Sousa</surname><given-names>APB</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>âThird tierâ ventral extrastriate cortex in the New World monkey, Cebus apella</article-title><source>Experimental Brain Research</source><volume>132</volume><fpage>287</fpage><lpage>305</lpage><pub-id pub-id-type="doi">10.1007/s002210000344</pub-id><pub-id pub-id-type="pmid">10883378</pub-id></element-citation></ref><ref id="bib119"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rousche</surname><given-names>PJ</given-names></name><name><surname>Normann</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Chronic recording capability of the Utah Intracortical Electrode Array in cat sensory cortex</article-title><source>Journal of Neuroscience Methods</source><volume>82</volume><fpage>1</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1016/s0165-0270(98)00031-4</pub-id><pub-id pub-id-type="pmid">10223510</pub-id></element-citation></ref><ref id="bib120"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saygin</surname><given-names>AP</given-names></name><name><surname>Sereno</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Retinotopy and Attention in Human Occipital, Temporal, Parietal, and Frontal Cortex</article-title><source>Cerebral Cortex</source><volume>18</volume><fpage>2158</fpage><lpage>2168</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhm242</pub-id><pub-id pub-id-type="pmid">18234687</pub-id></element-citation></ref><ref id="bib121"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>KA</given-names></name><name><surname>Richter</surname><given-names>MC</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Retinotopic Organization and Functional Subdivisions of the Human Lateral Geniculate Nucleus: A High-Resolution Functional Magnetic Resonance Imaging Study</article-title><source>The Journal of Neuroscience</source><volume>24</volume><fpage>8975</fpage><lpage>8985</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2413-04.2004</pub-id><pub-id pub-id-type="pmid">15483116</pub-id></element-citation></ref><ref id="bib122"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>SchÃ¶lvinck</surname><given-names>ML</given-names></name><name><surname>Maier</surname><given-names>A</given-names></name><name><surname>Ye</surname><given-names>FQ</given-names></name><name><surname>Duyn</surname><given-names>JH</given-names></name><name><surname>Leopold</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Neural basis of global resting-state fMRI activity</article-title><source>PNAS</source><volume>107</volume><fpage>10238</fpage><lpage>10243</lpage><pub-id pub-id-type="doi">10.1073/pnas.0913110107</pub-id><pub-id pub-id-type="pmid">20439733</pub-id></element-citation></ref><ref id="bib123"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwarzkopf</surname><given-names>DS</given-names></name><name><surname>Anderson</surname><given-names>EJ</given-names></name><name><surname>de Haas</surname><given-names>B</given-names></name><name><surname>White</surname><given-names>SJ</given-names></name><name><surname>Rees</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Larger Extrastriate Population Receptive Fields in Autism Spectrum Disorders</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>2713</fpage><lpage>2724</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4416-13.2014</pub-id><pub-id pub-id-type="pmid">24523560</pub-id></element-citation></ref><ref id="bib124"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seidlitz</surname><given-names>J</given-names></name><name><surname>Sponheim</surname><given-names>C</given-names></name><name><surname>Glen</surname><given-names>D</given-names></name><name><surname>Ye</surname><given-names>FQ</given-names></name><name><surname>Saleem</surname><given-names>KS</given-names></name><name><surname>Leopold</surname><given-names>DA</given-names></name><name><surname>Ungerleider</surname><given-names>L</given-names></name><name><surname>Messinger</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A population MRI brain template and analysis tools for the macaque</article-title><source>NeuroImage</source><volume>170</volume><fpage>121</fpage><lpage>131</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.04.063</pub-id><pub-id pub-id-type="pmid">28461058</pub-id></element-citation></ref><ref id="bib125"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sereno</surname><given-names>MI</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Reppas</surname><given-names>JB</given-names></name><name><surname>Kwong</surname><given-names>KK</given-names></name><name><surname>Belliveau</surname><given-names>JW</given-names></name><name><surname>Brady</surname><given-names>TJ</given-names></name><name><surname>Rosen</surname><given-names>BR</given-names></name><name><surname>Tootell</surname><given-names>RB</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Borders of multiple visual areas in humans revealed by functional magnetic resonance imaging</article-title><source>Science</source><volume>268</volume><fpage>889</fpage><lpage>893</lpage><pub-id pub-id-type="doi">10.1126/science.7754376</pub-id><pub-id pub-id-type="pmid">7754376</pub-id></element-citation></ref><ref id="bib126"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shao</surname><given-names>Y</given-names></name><name><surname>Keliris</surname><given-names>GA</given-names></name><name><surname>Papanikolaou</surname><given-names>A</given-names></name><name><surname>Fischer</surname><given-names>MD</given-names></name><name><surname>Zobor</surname><given-names>D</given-names></name><name><surname>JÃ¤gle</surname><given-names>H</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name><name><surname>Smirnakis</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Visual cortex organisation in a macaque monkey with macular degeneration</article-title><source>The European Journal of Neuroscience</source><volume>38</volume><fpage>3456</fpage><lpage>3464</lpage><pub-id pub-id-type="doi">10.1111/ejn.12349</pub-id><pub-id pub-id-type="pmid">24033706</pub-id></element-citation></ref><ref id="bib127"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shen</surname><given-names>L</given-names></name><name><surname>Han</surname><given-names>B</given-names></name><name><surname>de Lange</surname><given-names>FP</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Apparent motion induces activity suppression in early visual cortex and impairs visual detection</article-title><source>The Journal of Neuroscience</source><volume>40</volume><fpage>5471</fpage><lpage>5479</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0563-20.2020</pub-id><pub-id pub-id-type="pmid">32513825</pub-id></element-citation></ref><ref id="bib128"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sherrington</surname><given-names>CS</given-names></name></person-group><year iso-8601-date="1906">1906</year><article-title>Observations on the scratch-reflex in the spinal dog</article-title><source>The Journal of Physiology</source><volume>34</volume><fpage>1</fpage><lpage>50</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1906.sp001139</pub-id><pub-id pub-id-type="pmid">16992835</pub-id></element-citation></ref><ref id="bib129"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shmuel</surname><given-names>A</given-names></name><name><surname>Augath</surname><given-names>M</given-names></name><name><surname>Oeltermann</surname><given-names>A</given-names></name><name><surname>Logothetis</surname><given-names>NK</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Negative functional MRI response correlates with decreases in neuronal activity in monkey visual area V1</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>569</fpage><lpage>577</lpage><pub-id pub-id-type="doi">10.1038/nn1675</pub-id><pub-id pub-id-type="pmid">16547508</pub-id></element-citation></ref><ref id="bib130"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siegel</surname><given-names>M</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name><name><surname>Oostenveld</surname><given-names>R</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Engel</surname><given-names>AK</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Neuronal synchronization along the dorsal visual pathway reflects the focus of spatial attention</article-title><source>Neuron</source><volume>60</volume><fpage>709</fpage><lpage>719</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.09.010</pub-id><pub-id pub-id-type="pmid">19038226</pub-id></element-citation></ref><ref id="bib131"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silson</surname><given-names>EH</given-names></name><name><surname>Reynolds</surname><given-names>RC</given-names></name><name><surname>Kravitz</surname><given-names>DJ</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Differential Sampling of Visual Space in Ventral and Dorsal Early Visual Cortex</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>2294</fpage><lpage>2303</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2717-17.2018</pub-id><pub-id pub-id-type="pmid">29382711</pub-id></element-citation></ref><ref id="bib132"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sirotin</surname><given-names>YB</given-names></name><name><surname>Das</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Anticipatory haemodynamic signals in sensory cortex not predicted by local neuronal activity</article-title><source>Nature</source><volume>457</volume><fpage>475</fpage><lpage>479</lpage><pub-id pub-id-type="doi">10.1038/nature07664</pub-id><pub-id pub-id-type="pmid">19158795</pub-id></element-citation></ref><ref id="bib133"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>AT</given-names></name><name><surname>Williams</surname><given-names>AL</given-names></name><name><surname>Singh</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Negative BOLD in the visual cortex: Evidence against blood stealing</article-title><source>Human Brain Mapping</source><volume>21</volume><fpage>213</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1002/hbm.20017</pub-id><pub-id pub-id-type="pmid">15038003</pub-id></element-citation></ref><ref id="bib134"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stoll</surname><given-names>S</given-names></name><name><surname>Finlayson</surname><given-names>NJ</given-names></name><name><surname>Schwarzkopf</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Topographic signatures of global object perception in human visual cortex</article-title><source>NeuroImage</source><volume>220</volume><elocation-id>116926</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116926</pub-id></element-citation></ref><ref id="bib135"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>SupÃ¨r</surname><given-names>H</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Chronic multiunit recordings in behaving animals: advantages and limitations</article-title><source>Progress in Brain Research</source><volume>147</volume><fpage>263</fpage><lpage>282</lpage><pub-id pub-id-type="doi">10.1016/S0079-6123(04)47020-4</pub-id><pub-id pub-id-type="pmid">15581712</pub-id></element-citation></ref><ref id="bib136"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Szinte</surname><given-names>M</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Visual Organization of the Default Network</article-title><source>Cerebral Cortex</source><volume>30</volume><fpage>3518</fpage><lpage>3527</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhz323</pub-id></element-citation></ref><ref id="bib137"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tani</surname><given-names>N</given-names></name><name><surname>Joly</surname><given-names>O</given-names></name><name><surname>Iwamuro</surname><given-names>H</given-names></name><name><surname>Uhrig</surname><given-names>L</given-names></name><name><surname>Wiggins</surname><given-names>CJ</given-names></name><name><surname>Poupon</surname><given-names>C</given-names></name><name><surname>Kolster</surname><given-names>H</given-names></name><name><surname>Vanduffel</surname><given-names>W</given-names></name><name><surname>Le Bihan</surname><given-names>D</given-names></name><name><surname>Palfi</surname><given-names>S</given-names></name><name><surname>Jarraya</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Direct visualization of non-human primate subcortical nuclei with contrast-enhanced high field MRI</article-title><source>NeuroImage</source><volume>58</volume><fpage>60</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.06.019</pub-id><pub-id pub-id-type="pmid">21704174</pub-id></element-citation></ref><ref id="bib138"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thomas</surname><given-names>JM</given-names></name><name><surname>Huber</surname><given-names>E</given-names></name><name><surname>Stecker</surname><given-names>GC</given-names></name><name><surname>Boynton</surname><given-names>GM</given-names></name><name><surname>Saenz</surname><given-names>M</given-names></name><name><surname>Fine</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Population receptive field estimates of human auditory cortex</article-title><source>NeuroImage</source><volume>105</volume><fpage>428</fpage><lpage>439</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.10.060</pub-id><pub-id pub-id-type="pmid">25449742</pub-id></element-citation></ref><ref id="bib139"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Beest</surname><given-names>EH</given-names></name><name><surname>Mukherjee</surname><given-names>S</given-names></name><name><surname>Kirchberger</surname><given-names>L</given-names></name><name><surname>Schnabel</surname><given-names>UH</given-names></name><name><surname>van der Togt</surname><given-names>C</given-names></name><name><surname>Teeuwen</surname><given-names>RRM</given-names></name><name><surname>Barsegyan</surname><given-names>A</given-names></name><name><surname>Meyer</surname><given-names>AF</given-names></name><name><surname>Poort</surname><given-names>J</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name><name><surname>Self</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Mouse visual cortex contains a region of enhanced spatial resolution</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>4029</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-24311-5</pub-id><pub-id pub-id-type="pmid">34188047</pub-id></element-citation></ref><ref id="bib140"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Es</surname><given-names>DM</given-names></name><name><surname>van der Zwaag</surname><given-names>W</given-names></name><name><surname>Knapen</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Topographic Maps of Visual Space in the Human Cerebellum</article-title><source>Current Biology</source><volume>29</volume><fpage>1689</fpage><lpage>1694</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.04.012</pub-id></element-citation></ref><ref id="bib141"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group><year iso-8601-date="1984">1984</year><article-title>The visual field representation in striate cortex of the macaque monkey: Asymmetries, anisotropies, and individual variability</article-title><source>Vision Research</source><volume>24</volume><fpage>429</fpage><lpage>448</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(84)90041-5</pub-id><pub-id pub-id-type="pmid">6740964</pub-id></element-citation></ref><ref id="bib142"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Kerkoerle</surname><given-names>T</given-names></name><name><surname>Self</surname><given-names>MW</given-names></name><name><surname>Dagnino</surname><given-names>B</given-names></name><name><surname>Gariel-Mathis</surname><given-names>MA</given-names></name><name><surname>Poort</surname><given-names>J</given-names></name><name><surname>van der Togt</surname><given-names>C</given-names></name><name><surname>Roelfsema</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Alpha and gamma oscillations characterize feedback and feedforward processing in monkey visual cortex</article-title><source>PNAS</source><volume>111</volume><fpage>14332</fpage><lpage>14341</lpage><pub-id pub-id-type="doi">10.1073/pnas.1402773111</pub-id><pub-id pub-id-type="pmid">25205811</pub-id></element-citation></ref><ref id="bib143"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vanduffel</surname><given-names>W</given-names></name><name><surname>Fize</surname><given-names>D</given-names></name><name><surname>Mandeville</surname><given-names>JB</given-names></name><name><surname>Nelissen</surname><given-names>K</given-names></name><name><surname>Van Hecke</surname><given-names>P</given-names></name><name><surname>Rosen</surname><given-names>BR</given-names></name><name><surname>Tootell</surname><given-names>RB</given-names></name><name><surname>Orban</surname><given-names>GA</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Visual motion processing investigated using contrast agent-enhanced fMRI in awake behaving monkeys</article-title><source>Neuron</source><volume>32</volume><fpage>565</fpage><lpage>577</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(01)00502-5</pub-id><pub-id pub-id-type="pmid">11719199</pub-id></element-citation></ref><ref id="bib144"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Victor</surname><given-names>JD</given-names></name><name><surname>Purpura</surname><given-names>K</given-names></name><name><surname>Katz</surname><given-names>E</given-names></name><name><surname>Mao</surname><given-names>B</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Population encoding of spatial frequency, orientation, and color in macaque V1</article-title><source>Journal of Neurophysiology</source><volume>72</volume><fpage>2151</fpage><lpage>2166</lpage><pub-id pub-id-type="doi">10.1152/jn.1994.72.5.2151</pub-id><pub-id pub-id-type="pmid">7884450</pub-id></element-citation></ref><ref id="bib145"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Viswam</surname><given-names>V</given-names></name><name><surname>Obien</surname><given-names>MEJ</given-names></name><name><surname>Franke</surname><given-names>F</given-names></name><name><surname>Frey</surname><given-names>U</given-names></name><name><surname>Hierlemann</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Optimal Electrode Size for Multi-Scale Extracellular-Potential Recording From Neuronal Assemblies</article-title><source>Frontiers in Neuroscience</source><volume>13</volume><elocation-id>385</elocation-id><pub-id pub-id-type="doi">10.3389/fnins.2019.00385</pub-id><pub-id pub-id-type="pmid">31105515</pub-id></element-citation></ref><ref id="bib146"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Viswanathan</surname><given-names>A</given-names></name><name><surname>Freeman</surname><given-names>RD</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Neurometabolic coupling in cerebral cortex reflects synaptic more than spiking activity</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1308</fpage><lpage>1312</lpage><pub-id pub-id-type="doi">10.1038/nn1977</pub-id><pub-id pub-id-type="pmid">17828254</pub-id></element-citation></ref><ref id="bib147"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wandell</surname><given-names>BA</given-names></name><name><surname>Dumoulin</surname><given-names>SO</given-names></name><name><surname>Brewer</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Visual field maps in human cortex</article-title><source>Neuron</source><volume>56</volume><fpage>366</fpage><lpage>383</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.10.012</pub-id><pub-id pub-id-type="pmid">17964252</pub-id></element-citation></ref><ref id="bib148"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wandell</surname><given-names>BA</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Imaging retinotopic maps in the human brain</article-title><source>Vision Research</source><volume>51</volume><fpage>718</fpage><lpage>737</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2010.08.004</pub-id><pub-id pub-id-type="pmid">20692278</pub-id></element-citation></ref><ref id="bib149"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wandell</surname><given-names>BA</given-names></name><name><surname>Winawer</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Computational neuroimaging and population receptive fields</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>349</fpage><lpage>357</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.03.009</pub-id><pub-id pub-id-type="pmid">25850730</pub-id></element-citation></ref><ref id="bib150"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ward</surname><given-names>MP</given-names></name><name><surname>Rajdev</surname><given-names>P</given-names></name><name><surname>Ellison</surname><given-names>C</given-names></name><name><surname>Irazoqui</surname><given-names>PP</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Toward a comparison of microelectrodes for acute and chronic recordings</article-title><source>Brain Research</source><volume>1282</volume><fpage>183</fpage><lpage>200</lpage><pub-id pub-id-type="doi">10.1016/j.brainres.2009.05.052</pub-id><pub-id pub-id-type="pmid">19486899</pub-id></element-citation></ref><ref id="bib151"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Welbourne</surname><given-names>LE</given-names></name><name><surname>Morland</surname><given-names>AB</given-names></name><name><surname>Wade</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Population receptive field (pRF) measurements of chromatic responses in human visual cortex using fMRI</article-title><source>NeuroImage</source><volume>167</volume><fpage>84</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.11.022</pub-id><pub-id pub-id-type="pmid">29155081</pub-id></element-citation></ref><ref id="bib152"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winawer</surname><given-names>J</given-names></name><name><surname>Kay</surname><given-names>KN</given-names></name><name><surname>Foster</surname><given-names>BL</given-names></name><name><surname>Rauschecker</surname><given-names>AM</given-names></name><name><surname>Parvizi</surname><given-names>J</given-names></name><name><surname>Wandell</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Asynchronous Broadband Signals Are the Principal Source of the BOLD Response in Human Visual Cortex</article-title><source>Current Biology</source><volume>23</volume><fpage>1145</fpage><lpage>1153</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2013.05.001</pub-id><pub-id pub-id-type="pmid">23770184</pub-id></element-citation></ref><ref id="bib153"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winder</surname><given-names>AT</given-names></name><name><surname>Echagarruga</surname><given-names>C</given-names></name><name><surname>Zhang</surname><given-names>Q</given-names></name><name><surname>Drew</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Weak correlations between hemodynamic signals and ongoing neural activity during the resting state</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>1761</fpage><lpage>1769</lpage><pub-id pub-id-type="doi">10.1038/s41593-017-0007-y</pub-id></element-citation></ref><ref id="bib154"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Womelsdorf</surname><given-names>T</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The role of neuronal synchronization in selective attention</article-title><source>Current Opinion in Neurobiology</source><volume>17</volume><fpage>154</fpage><lpage>160</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2007.02.002</pub-id><pub-id pub-id-type="pmid">17306527</pub-id></element-citation></ref><ref id="bib155"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Constrained linear basis sets for HRF modelling using Variational Bayes</article-title><source>NeuroImage</source><volume>21</volume><fpage>1748</fpage><lpage>1761</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2003.12.024</pub-id><pub-id pub-id-type="pmid">15050595</pub-id></element-citation></ref><ref id="bib156"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Worden</surname><given-names>MS</given-names></name><name><surname>Foxe</surname><given-names>JJ</given-names></name><name><surname>Wang</surname><given-names>N</given-names></name><name><surname>Simpson</surname><given-names>GV</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Anticipatory Biasing of Visuospatial Attention Indexed by Retinotopically Specific Î±-Bank Electroencephalography Increases over Occipital Cortex</article-title><source>The Journal of Neuroscience</source><volume>20</volume><elocation-id>RC63</elocation-id><pub-id pub-id-type="doi">10.1523/JNEUROSCI.20-06-j0002.2000</pub-id></element-citation></ref><ref id="bib157"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xing</surname><given-names>D</given-names></name><name><surname>Yeh</surname><given-names>CI</given-names></name><name><surname>Shapley</surname><given-names>RM</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Spatial spread of the local field potential and its laminar variation in visual cortex</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>11540</fpage><lpage>11549</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2573-09.2009</pub-id><pub-id pub-id-type="pmid">19759301</pub-id></element-citation></ref><ref id="bib158"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yoshor</surname><given-names>D</given-names></name><name><surname>Bosking</surname><given-names>WH</given-names></name><name><surname>Ghose</surname><given-names>GM</given-names></name><name><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Receptive Fields in Human Visual Cortex Mapped with Surface Electrodes</article-title><source>Cerebral Cortex</source><volume>17</volume><fpage>2293</fpage><lpage>2302</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhl138</pub-id><pub-id pub-id-type="pmid">17172632</pub-id></element-citation></ref><ref id="bib159"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeidman</surname><given-names>P</given-names></name><name><surname>Silson</surname><given-names>EH</given-names></name><name><surname>Schwarzkopf</surname><given-names>DS</given-names></name><name><surname>Baker</surname><given-names>CI</given-names></name><name><surname>Penny</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Bayesian population receptive field modelling</article-title><source>NeuroImage</source><volume>180</volume><fpage>173</fpage><lpage>187</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.09.008</pub-id></element-citation></ref><ref id="bib160"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>Q</given-names></name><name><surname>Vanduffel</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Submillimeter fMRI reveals a layout of dorsal visual cortex in macaques, remarkably similar to New World monkeys</article-title><source>PNAS</source><volume>116</volume><fpage>2306</fpage><lpage>2311</lpage><pub-id pub-id-type="doi">10.1073/pnas.1805561116</pub-id></element-citation></ref><ref id="bib161"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zuiderbaan</surname><given-names>W</given-names></name><name><surname>Harvey</surname><given-names>BM</given-names></name><name><surname>Dumoulin</surname><given-names>SO</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Modeling center-surround configurations in population receptive fields using fMRI</article-title><source>Journal of Vision</source><volume>12</volume><elocation-id>10</elocation-id><pub-id pub-id-type="doi">10.1167/12.3.10</pub-id><pub-id pub-id-type="pmid">22408041</pub-id></element-citation></ref><ref id="bib162"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zuiderbaan</surname><given-names>W</given-names></name><name><surname>Harvey</surname><given-names>BM</given-names></name><name><surname>Dumoulin</surname><given-names>SO</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Image identification from brain activity using the population receptive field model</article-title><source>PLOS ONE</source><volume>12</volume><elocation-id>e0183295</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0183295</pub-id><pub-id pub-id-type="pmid">28922355</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.67304.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Krug</surname><given-names>Kristine</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><p>This study is a detailed, systematic comparison of visually evoked population receptive fields (pRFs) measured non-invasively with MRI and invasively with electrophysiology in the same primate species. The authors show that MRI pRFs provide a good estimate of receptive fields based on multi-unit spiking activity in early visual areas. These results make an important contribution to our understanding of human imaging data in research and in the clinic.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.67304.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Krug</surname><given-names>Kristine</given-names></name><role>Reviewing Editor</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Bridge</surname><given-names>Holly</given-names></name><role>Reviewer</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="box1"><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;A comparison of population receptive fields from fMRI and large-scale neurophysiology recordings in non-human primates&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Timothy Behrens as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Holly Bridge (Reviewer #2).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>1) Framing of the study:</p><p>â Title and Abstract should differentiate more clearly that the direct comparison between neuronal activity and MRI pRFs was done only for V1 and V4 only. The wider MRI dataset was used for assessment of pRF models. The abstract felt somewhat misleading because it suggests there is neurophysiological data from areas other than V1 and V4. It should be made clear from the outset that neurophysiological data are only available in these areas. The statement 'We found that pRFs derived from BOLD-fMRI were most similar to MUA-pRFs in areas V1 and V4â¦..' makes it sounds like they were compared in other areas, but were most similar in those ones.</p><p>â In terms of improvement in the manuscript, we had difficulty determining the precise hypothesis or aim of the manuscript because there seem to be 3 different ideas (1) the relationship of pRF with eccentricity across many cortical and subcortical areas (2) 4 different models for fitting the pRF model and (3) the comparison of BOLD pRF with MUA and LFP in areas V1 and V4. It would therefore be helpful to understand better from the manuscript what the authors intend to be the major question.</p><p>2) In some cases, pRFs from higher areas in the frontal lobe etc appear to be coming from just one animal and the number of voxels meeting the R2 criterion is very low. We would suggest that analyses are limited to regions where pRF can be fit in both animals (and with a threshold for the minimum number of voxels). The entry criteria used should be reported in the Results.</p><p>3) Figure 3. LGN and Pulvinar:</p><p>a) The legend states that both areas have retinotopic maps of the contralateral visual field. We would definitely agree with this assertion for the LGN, but this does not appear to be the case for the pulvinar. Is this quantified somewhere?</p><p>b) Figures 3A and 3B suggest that M1 and M2 had inverted retinotopic maps in the LGN in one hemisphere between the two animals. M1 shows upper visual field (yellow) dorsally and M2 shows upper visual field ventrally (yellow; sagittal view). The LGN retinotopic maps do not look consistent between the two monkeys, which suggests that they might not as reliable as stated in the results.</p><p>4) Figure 5 really needs some data points rather than just the fits. We realise all the voxels are shown in the supplementary materials, but showing binned data with errorbars would be very helpful. It would also be more transparent, given the considerable differences in voxel numbers (mentioned above), to have the saturation of the data and fits reflect the voxel counts. That would also remove the issue with the lines intersecting the y-axis at or below zero as this is difficult to explain.</p><p>5) For the neurophysiology and MRI comparisons, we wonder whether the authors could provide a more direct comparison of the data considering only the pRF data from the regions contributing to the neurophysiological recordings.</p><p>6) The discussion of the pulvinar seems out of place in this manuscript as it does not seem to be the point of the paper and there is little analysis of the data from this area (noted above that representation does not appear to be consistently contralateral).</p><p>7) Some critical details are missing in the methods with regards to the assessed visual field and the stimulus used:</p><p>a) In the results and in methods, the covered visual field is described as 16 degrees (MRI) and 28 degrees (neurophysiology). Since this critically limits the RF size-eccentricity relationship that can be assessed, the authors should clearly state whether this is the diameter or radius of the visual field and whether (and how) horizontal and vertical dimensions of the available visual field differed. We assume that the stimulated visual field is only up to 8 degrees eccentricity for the MRI data â this needs to be clearly stated and in every data figure with actual data points and fits/extrapolations distinguished.</p><p>b) If partially stimulated receptive fields are extrapolated, then these need also to be indicated where applicable in the results, their generation explained in the methods, and the implications discussed, as the precise shape of these depends on the assumptions made.</p><p>c) Also, the results (line 130) refer to a &quot;large circular aperture&quot; behind which the stimulus was shown and the results refer here to Figure 1. The stimulus in Figure 1 shows no such aperture. Details of this (size, position, contrast) should be provided.</p><p>d) Mean luminance of the monitors used and the stimulus contrast should be provided for both set ups in the Methods.</p><p>8) Following on from 7), given the methods descriptions, it is not clear how some foveal or more eccentric RFs were assessed.</p><p>a) The results state clearly that the animals fixated the screen centrally. If the visual field refers to the diameter, this means that RFs more eccentric than 8 degrees (MRI) and 14 degrees (neurophysiology) could not be assessed.</p><p>This potentially affects the results in Figures 5 and 6B (M4). In Figure 5, the authors should distinguish between the range based on available data and extrapolation for each area.</p><p>b) Conversely, according to the methods around the fixation dot there was mask of mean background colour (aperture of 0.75 degrees â we assume radius?). But in Figure 6A, B and C, there are RF centres within 0.5 degrees of the fixation point. The authors should add an explanation to the methods how they assessed the RFs in these position, if they did not fully stimulate this part of the visual field.</p><p>9) Figure 7 suggests a systematic overestimation of pRF size over cRF? It would be good to compare both measures quantitatively to the neurophysiological literature, so the readers can understand what &quot;the different definitions of RF size&quot; refer to (p11, l246-247; p13, l281-283). The comparison as is in results and discussion remains vague as to RF definition and systematic differences across neurophysiology â MRI literature in estimated RF sizes.</p><p>10) Could the authors provide measures about the mean, range and variance in eye position for the MRI and neurophysiology experiments, as this would have potentially affected the size estimates of the smaller RFs. It would be good to discuss this issue.</p><p>11) Figure 6B suggests that the neurophysiology data for V4 samples two separate parts of the visual field in the two monkeys.</p><p>(a) Could the authors state in the paper whether there is in any of their analyses a significant difference in the data from the two monkeys and whether this could have affected the comparison with the MRI?</p><p>(b) Figure 6B suggests that in M4, by far the more eccentric visual field positions were sampled. However, Figure 7B suggests that most of the measured RF sizes are the same or smaller than in M3. Is this correct? And how does this relate to the literature on V4 RF sizes?</p><p><italic>Reviewer #1:</italic></p><p>This study provides a systematic assessment of visual population receptive fields (pRF) obtained with functional magnetic resonance imaging (MRI) in primates.</p><p>Critically, pRFs from early visual areas V1 and V4 are compared to systematic neurophysiological measurements obtained in individuals from the same primate species (but not the same individual animals) across a range of visual field positions. This allows at a direct comparison to &quot;ground truth&quot;.</p><p>Furthermore, the paper provides an assessment of four different models for generating receptive fields from imaging and neurophysiological data, including linear and non-linear models, and investigates multi-unit (MUA) and local field potential (LFP) data. The authors show the greatest correspondence of pRFs between MUA and fMRI data, but the reasons for this could be more fully explored.</p><p>The paper could situate the results more clearly in the wealth of data we have about neurophysiological measures of receptive fields and retinotopy for the macaque visual system. The presented results could differentiate more clearly between data for which MRI and neurophysiological data are available (central visual field representations for areas V1 and V4), data for which extrapolation partially stimulated RFs was included and results that depend on MRI data only. Also, outside the early visual cortical areas the MRI retinotopic maps appear potentially less reliable and with this the pRF measurements.</p><p>These results are are equally important for research and clinical assessments of the neuronal basis of visual functional and perception.</p><p><italic>Reviewer #2:</italic></p><p>This paper by Klink and colleagues investigates the relationship between visual receptive fields defined with non-invasive magnetic resonance imaging (MRI) and neurophysiology in the non-human primate. Population receptive field mapping (pRF) is a non-invasive imaging technique designed to estimate the area of the visual field to which particular visual brain areas respond. Since these pRFs are derived from MRI data, they have provided a window into human visual brain function. In contrast, using invasive neurophysiology, it is possible to measure the receptive field from a group of nearby neurons (multi-unit activity; MUA) or the local field potential (LFP).</p><p>Data from four animals are presented, with pRF MRI data acquired from two animals and neurophysiological measurement of both MUA and LFP in the other two with some comparison between the measurements.</p><p>Strengths of the study:</p><p>1. The comprehensive analysis of the pRF mapping, which compares the results of four different models. The data are of very high quality due to the relatively high resolution of the imaging and the large quantity of data acquired. This allowed the identification of many areas in the occipital lobe, along with parietal, temporal and even some frontal regions. It was also possible to map pRFs in both LGN and pulvinar.</p><p>2. The finding that negative BOLD signals were due to two different sources â (i) being outside of the region that was visually stimulated and (ii) regions that are part of the default mode network â is an elegant finding and is consistent with previously published human data.</p><p>3. Recording both MUA and LFP power at different frequency bands provides a number of different measures of receptive field size that can be compared to the pRF data, and indeed the correspondence seems high.</p><p>4. Number of recording sites in V1 is good giving a good range of eccentricities over which to measure receptive fields.</p><p>Weaknesses of the study:</p><p>1. The authors are not clear about the main message of the paper. The title suggests that it is the comparison of the pRF and neurophysiological findings, but the neurophysiological recordings are (understandably) predominantly in V1, with some also in V4. This means that the majority of the pRF data cannot be compared to the neurophysiological recordings. Additionally, that the data were acquired in different animals is unfortunate as it would have been particularly valuable to measure the neurophysiological data from cortical tissue where pRFs have been measured non-invasively.</p><p>2. Four different methods for measuring pRFs were used, but the authors do not draw strong conclusions about which model may be the most successful to use in the discussion. Having this information would be very valuable for other researchers.</p><p>3. The discussion could be more focussed and does not really provide the reader with an answer to the question of how well the pRF compares to the neurophysiological data. Much of the data on pRF size and eccentricity has been published many times in the human and there is already some data in the non-human primate, so it is important to emphasise the novel findings of the current data. I would expect some more in-depth explanation of the MUA and LFP relationship with pRF and why MUA appears better.</p><p>4. Since data are from 2 animals, it would be helpful to see which animal each datapoint comes from to ensure that there are no major biases due to the contribution of each animal.</p><p>While the conclusions are supported to a certain extent, the key point that is critical to highlight is that the neurophysiological data are predominantly from V1. It is too general to state that MRI-based pRF measurements reliably reflect receptive field properties of the primate brain.</p><p><italic>Reviewer #3:</italic></p><p>The authors present fMRI data from 2 macaques and neural electrophysiology data from 2 different macaques implanted with 16*64 electrodes covering the lower right visual field quadrant of V1, and V4. Stimuli consisted of a traveling bar that systematically stimulated the retina while awake animals fixated centrally. pRFs fit to BOLD signals evoked by these stimuli, were compared with pRFs fit to time courses from multi unit activity (MUA) as well LPF theta, Î±, Î², low Î³ and high Î³ frequency power.</p><p>This is an impressive study that offers a first systematic and very thorough comparison of pRFs estimated from FMRI versus from LFP as well as MUA electrophysiology measures. It thereby contributes to validation and interpretation of an increasing body of human pRF mapping research. The analyses are thorough and conclusions drawn are well supported by the data in my view (though note that I am not an expert on electrophysiological recording methods). A particular strength of the approach taken, is that the authors have fit 4 different pRF models to all these data using a robust cross-validation approach, which allows them to capture and compare various types of deactivation and spatial summation dynamics, and make inferences about parallels and differences in spatial information processing across brain regions and neural activity signatures. Most crucially, results convincingly reveal accuracy of fMRI pRFs with electrophysiology-recordings of MUA and Î³ LFP, in terms of similar relationships between pRF size, eccentricity, and the best-fitting pRF model parameters (a 'compressive spatial summation' model). Another strength includes the investigation of wide-spread retinotopy with fMRI, confirming recent findings of retinotopic selectivity in brain regions not classically considered visual or even sensory, such as the default mode network, in humans.</p><p>In terms of weaknesses, I see no major issues, although there are some aspects of the work that could be clarified. First, it would be helpful if the authors could elaborate on how pRF size estimated from MUA and LPF measures depend on the size or sensitivity of the electrodes to various neural signals, and what this means for expected comparability of pRF parameter estimates across these measures and to MRI. Second, there were a few points I felt lacked some detail needed to understand the results: one intriguing finding, is that for some electrodes in V1, pRFs can be derived from Î± and Î² frequencies in LFP signal that differ from those in the Î³ frequency. Interestingly, there are negative or 'deactivating' pRFs measurable in Î± and Î² LFP signals, which are substantially shifted in position with respect to 'activating' pRFs derived from the Î³ frequency LFP at the same electrode. The authors speculate this reflects foveally-directed shifts due to attention or eye-movement, each of likely relevance to studies mapping near-foveal regions. However, I found the relevant plots collapsing across electrodes (Figure 10) quite hard to interpret, and wondered whether differences in pRF fit across the two data types (Supplementary Figure 7) may contribute to these shifts. Similarly, in another very interesting analysis the authors show that pRF sizes fit to the MUA response evoked by the mapping stimulus, correlates well with RF size estimates obtained with the 'classic' approach of recording the MUA response to a thin moving light bar. Data reveal a clear linear relationship in RF size estimates across measures, but an analysis of expected vs. observed differences in size and shape (i.e., the true identity line) that would be useful for assessing methodological biases is not provided.</p><p>So, barring some minor points of clarification, I believe this work offers a wealth of data and analyses that provide important validation of commonly used pRF mapping methods, and will without doubt spark many further investigations into population receptive field dynamics across the primate and human brain. This will be hugely facilitated by the free availability of data and code for this study, made accessible via a link in the paper.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.67304.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) Framing of the study:</p><p>â Title and Abstract should differentiate more clearly that the direct comparison between neuronal activity and MRI pRFs was done only for V1 and V4 only. The wider MRI dataset was used for assessment of pRF models. The abstract felt somewhat misleading because it suggests there is neurophysiological data from areas other than V1 and V4. It should be made clear from the outset that neurophysiological data are only available in these areas. The statement 'We found that pRFs derived from BOLD-fMRI were most similar to MUA-pRFs in areas V1 and V4â¦..' makes it sounds like they were compared in other areas, but were most similar in those ones.</p><p>â In terms of improvement in the manuscript, we had difficulty determining the precise hypothesis or aim of the manuscript because there seem to be 3 different ideas (1) the relationship of pRF with eccentricity across many cortical and subcortical areas (2) 4 different models for fitting the pRF model and (3) the comparison of BOLD pRF with MUA and LFP in areas V1 and V4. It would therefore be helpful to understand better from the manuscript what the authors intend to be the major question.</p></disp-quote><p>Thank you for pointing this out. Our main objective was to compare BOLD-pRFs and neurophysiology pRFs. However, because the data-set is rich, we also explored it by fitting different pRF models and looking at brain areas beyond V1 and V4 in the fMRI results. While we feel that all these aspects of the data yield interesting insights, we agree that this broadening of the scope may have obscured the main question a bit.</p><p>We changed the title of the revised manuscript to âPopulation receptive fields in non-human primates from whole-brain fMRI and large-scale neurophysiology in visual cortexâ and more clearly differentiate the main question of the BOLD-ephys comparison from the complementary findings in the revised abstract. The title is succinct as prescribed by <italic>eLife</italic>, while also explicitly mentioning the scope of neurophysiological and neuroimaging recordings. The abstract now also clarifies that direct comparisons were made only for visual areas V1 and V4. It now also makes clear that this comparison was our main question, but that additional insights were derived from the broader scope of the fMRI data. This distinction is now also properly specified in the introduction.</p><disp-quote content-type="editor-comment"><p>2) In some cases, pRFs from higher areas in the frontal lobe etc appear to be coming from just one animal and the number of voxels meeting the R2 criterion is very low. We would suggest that analyses are limited to regions where pRF can be fit in both animals (and with a threshold for the minimum number of voxels). The entry criteria used should be reported in the Results.</p></disp-quote><p>This assertion is correct. Selecting data with a stricter criterion primarily affects Figure 5, which we have now changed to address this and other reviewer suggestions. As suggested by the reviewers, we now only show areas for which at least 20 voxels reach the R<sup>2</sup> threshold in both animals and explicitly mention how many voxels meet this threshold in each individual. This inclusion criterion is also explicitly mentioned in the caption of the new Figure 5. For more details see point 4.</p><disp-quote content-type="editor-comment"><p>3) Figure 3. LGN and Pulvinar:</p><p>a) The legend states that both areas have retinotopic maps of the contralateral visual field. We would definitely agree with this assertion for the LGN, but this does not appear to be the case for the pulvinar. Is this quantified somewhere?</p></disp-quote><p>We thank the reviewers for these observations and agree with them that the pulvinar results are not very consistent across animals. We have changed our phrasing in the legend to reflect this better. We also added a quantification of the proportion of voxels with significant contralateral pRFs (n<sub>contra</sub>/n<sub>total</sub>). The new text in the legend reads:</p><p>âThe lateral geniculate nucleus (LGN, top rows) contained retinotopic maps of the contralateral visual field in both monkeys (M1: 38/38; M2: 73/80 voxels with contralateral pRFs). Retinotopic information was also present in the pulvinar (PULV, bottom rows), but its organization was much less structured, especially in M2 (M1: 23/32; M2: 61/131 voxels with contralateral pRFs).â</p><disp-quote content-type="editor-comment"><p>b) Figures 3A and 3B suggest that M1 and M2 had inverted retinotopic maps in the LGN in one hemisphere between the two animals. M1 shows upper visual field (yellow) dorsally and M2 shows upper visual field ventrally (yellow; sagittal view). The LGN retinotopic maps do not look consistent between the two monkeys, which suggests that they might not as reliable as stated in the results.</p></disp-quote><p>We did not perform a detailed analysis of the LGN and pulvinar maps, as we considered the resolution of our data to be unsuitable for such inferences. When we compared our results to previously published retinotopic maps of the LGN (e.g. Erwin et al., 1999; Schneider et al., 2004; DeSimone et al., 2015), we confirm the representation of the upper visual field in more anterior-ventral LGN, and of the lower visual field in posterior-dorsal LGN. This is less clear in M2 where fewer voxels could be fit, and while a similar pattern might be present in some sagittal slices, others appear to show the opposite pattern. Whereas pRF model fits revealed retinotopic information for the pulvinar as well, these did not really constitute a clear âmapâ. We added a brief discussion about the reliability of the subcortical results to the Discussion (p19, ln 387-390):</p><p>âRetinotopic maps in the LGN were roughly in line with previously published retinotopic organization of the macaque LGN (Erwin et al., 1999), but they comprised few voxels and the variability across animals prohibited detailed inferences. In the pulvinar, the organization of the retinotopic information was even more variable across animals.â</p><disp-quote content-type="editor-comment"><p>4) Figure 5 really needs some data points rather than just the fits. We realise all the voxels are shown in the supplementary materials, but showing binned data with errorbars would be very helpful. It would also be more transparent, given the considerable differences in voxel numbers (mentioned above), to have the saturation of the data and fits reflect the voxel counts. That would also remove the issue with the lines intersecting the y-axis at or below zero as this is difficult to explain.</p></disp-quote><p>We have re-plotted the results in a revised version of Figure 5 to address both this point and point 2 above. Visualizing the number of voxels with saturation in addition to indicating the visual area with different colors did not work very well, but we found a way to represent the requested information. In revised Figure 5, we (1) only show areas for which both animals contribute at least 20 voxels, (2) mention the voxel-counts per area per animal, (3) plot binned data with error bars, (4) show linear fits for multiple areas in different colors in the same panel without confidence intervals, (5) show linear fits with confidence intervals for separate areas in smaller panels on the side, and (6) indicate the extent of the visual stimulus to clarify which pRFs were only partially stimulated (those in the gray areas). We also added these binned data-points to the corresponding Figure 5âfigure supplement 1, which we expanded with a version of Figure 5âfigure supplement 2 in which we lowered the R<sup>2</sup> threshold to 3%. Since we make all data and scripts available online, interested readers will be able to investigate the effect of different voxel selection criteria on the results.</p><disp-quote content-type="editor-comment"><p>5) For the neurophysiology and MRI comparisons, we wonder whether the authors could provide a more direct comparison of the data considering only the pRF data from the regions contributing to the neurophysiological recordings.</p></disp-quote><p>Ideally, one would like to compare the BOLD-pRFs and ephys-pRFs from identical brain locations. However, because the recordings come from different individuals, the comparison depends on the precision with which we can estimate the correspondence of voxels in M1 and M2 with the location of electrodes in M3 and M4. We chose to approach this comparison from a functional angle: as the ephys-pRFs were located in the lower right visual field, we only included V1 and V4 voxels for which the BOLD-pRFs were also located in the lower right visual field. We have now expanded the analysis with the subset of V1 and V4 voxels in the left hemisphere that roughly corresponded to the location of the electrodes implanted in M3 and M4. Data from these three different voxel inclusion criteria were furthermore analyzed with four different combinations of R<sup>2</sup>-based thresholds for the MRI and electrophysiology results. As a consequence, the analysis was run on 12 different combinations of inclusion criteria, yielding similar results. This approach is described on p18 ln 369-373 and an overview of the results is presented in the revised Figure 12âfigure supplement 1:</p><p>âTo further investigate the robustness of these results, we repeated the analysis, (1) with the inclusion of either all V1 and V4 voxels or a subset of the voxels in approximately the same anatomical location as the electrode arrays, and (2) by varying the R2-based inclusion criteria for electrodes and voxels (Figure 12âfigure supplement 1). MUA-pRFs in V1 and V4 were generally similar to the BOLD-pRFs, although in V4 Î³<sub>low</sub> and Î³<sub>high</sub> also approximated the fMRI results in some of the comparisons.â</p><disp-quote content-type="editor-comment"><p>6) The discussion of the pulvinar seems out of place in this manuscript as it does not seem to be the point of the paper and there is little analysis of the data from this area (noted above that representation does not appear to be consistently contralateral).</p></disp-quote><p>We agree that the discussion of the (noisy) pulvinar could distract from the manuscriptâs main points and have removed it. In addition, we extended the discussion of the subcortical results (as mentioned above in A3b).</p><disp-quote content-type="editor-comment"><p>7) Some critical details are missing in the methods with regards to the assessed visual field and the stimulus used:</p><p>a) In the results and in methods, the covered visual field is described as 16 degrees (MRI) and 28 degrees (neurophysiology). Since this critically limits the RF size-eccentricity relationship that can be assessed, the authors should clearly state whether this is the diameter or radius of the visual field and whether (and how) horizontal and vertical dimensions of the available visual field differed. We assume that the stimulated visual field is only up to 8 degrees eccentricity for the MRI data â this needs to be clearly stated and in every data figure with actual data points and fits/extrapolations distinguished.</p></disp-quote><p>Yes, the assumption is correct and we have clarified the methods description accordingly (p25 ln 542-546). We have also added an indication of the extent of the visual stimulus in Figures 5,6 and Figure 5âfigure supplements 1,2.</p><disp-quote content-type="editor-comment"><p>b) If partially stimulated receptive fields are extrapolated, then these need also to be indicated where applicable in the results, their generation explained in the methods, and the implications discussed, as the precise shape of these depends on the assumptions made.</p></disp-quote><p>The fitting procedure is indeed capable of estimating partially stimulated pRFs and all reported pRF estimates are fully data-driven and not extrapolated. Especially for larger pRFs just outside the visually stimulated region this works well. We have added an explanation of how the method deals with partially stimulated pRFs to the description of the methods (p28 ln 632-635).</p><p>âThis method also yields a prediction for pRFs that are only partially stimulated, and the best fitting pRF can have a center location outside of the stimulus aperture. Because pRF estimates are generally more reliable for pRF that are strongly driven by a visual stimulus, we include indications of the directly stimulated visual field in our figures.â</p><disp-quote content-type="editor-comment"><p>c) Also, the results (line 130) refer to a &quot;large circular aperture&quot; behind which the stimulus was shown and the results refer here to Figure 1. The stimulus in Figure 1 shows no such aperture. Details of this (size, position, contrast) should be provided.</p></disp-quote><p>We have improved the description. The foreground and background of this aperture had the same color, which makes the aperture âvirtualâ. It clipped the bar stimuli, but its edges were not visible on the screen. We have now added a dashed line to the revised Figure 1A to indicate the virtual aperture, removed the mentioning of the aperture from the main text of the Results section to avoid confusion, and described the stimulus better in the Methods section:</p><p>âPopulation receptive fields were measured using conventional moving bar stimuli that traversed the screen in eight different directions behind a large virtual circular aperture (Figure 1). The borders of this virtual aperture were invisible, because both the foreground and background had the same gray level (22.3 cd/m2) (Dumoulin and Wandell, 2008).â</p><disp-quote content-type="editor-comment"><p>d) Mean luminance of the monitors used and the stimulus contrast should be provided for both set ups in the Methods.</p></disp-quote><p>We have added this information to the Methods.</p><disp-quote content-type="editor-comment"><p>8) Following on from 7), given the methods descriptions, it is not clear how some foveal or more eccentric RFs were assessed.</p><p>a) The results state clearly that the animals fixated the screen centrally. If the visual field refers to the diameter, this means that RFs more eccentric than 8 degrees (MRI) and 14 degrees (neurophysiology) could not be assessed.</p><p>This potentially affects the results in Figures 5 and 6B (M4). In Figure 5, the authors should distinguish between the range based on available data and extrapolation for each area.</p><p>b) Conversely, according to the methods around the fixation dot there was mask of mean background colour (aperture of 0.75 degrees â we assume radius?). But in Figure 6A, B and C, there are RF centres within 0.5 degrees of the fixation point. The authors should add an explanation to the methods how they assessed the RFs in these position, if they did not fully stimulate this part of the visual field.</p></disp-quote><p>We have improved the methods description. The pRF fitting method is a forward modeling approach that predicts the responses to a visual stimulus for a hypothesized pRF (location and size) and minimizes the difference between the observed and predicted activity by changing the parameters of the hypothesized pRF. This means that (1) all estimated pRFs are data-driven, and (2) pRFs can be estimated even if their center is not stimulated. This holds for both the foveal (0.75 deg aperture was defined in diameter, which has been added to the Methods) and eccentric pRFs. Moreover, while we take the Ï of the estimated pRF as a description of its size, the 2D Gaussians are larger than one Ï, and a response occurs if a visual stimulus is farther from the center of the pRF. Figure 5 has been revised in light of other comments (see A4). In the new figure (as well as in other figures that deal with eccentricity), we added an indication of the extent of the visual stimulus to all figures that deal with eccentricity. We also added a few lines about cRF and pRF size definitions to the Methods section that will hopefully clarify this issue as well (p31 ln 718-722):</p><p>âThis measure approximates the RF radius based on the SD of a Gaussian response profile, and can be directly compared to the Ï estimated by pRF-models (Figure 7). It is smaller than cRF sizes typically reported in electrophysiological studies, because neurons are activated by stimuli farther than one SD from their RF center (our lab usually defines cRF diameter as 3.3*SD).â</p><disp-quote content-type="editor-comment"><p>9) Figure 7 suggests a systematic overestimation of pRF size over cRF? It would be good to compare both measures quantitatively to the neurophysiological literature, so the readers can understand what &quot;the different definitions of RF size&quot; refer to (p11, l246-247; p13, l281-283). The comparison as is in results and discussion remains vague as to RF definition and systematic differences across neurophysiology â MRI literature in estimated RF sizes.</p></disp-quote><p>This comment inspired us to recalculate the cRFs with a measure that is more comparable to the pRFs. In the previously submitted version of the manuscript, we took the position of a horizontally or vertically moving bar stimulus at visual field positions that included 95% of the area under a Gaussian fit to the MUA traces as the borders of the receptive field. Now we use the standard deviation of this Gaussian as a more direct analog to the pRF-size which is also quantified as 1 standard deviation. Interestingly, the cRFs calculated this way are smaller than pRFs estimated with the traditional P-LIN model (median difference 0.50 dva). This difference largely disappears when pRFs are calculated with the CSS model. Now, pRFs are slightly smaller than cRFs (median difference -0.13 dva). We have revised Figure 7 to show this direct comparison and changed the text where appropriate (p11 ln 247-251; p20 ln 439-443; p31 ln 714-722).</p><p>[p11 ln 247-251]âFor this cRF method, we selected channels with a signal-to-noise ratio (SNR) larger than three (i.e., visual responses that were more than three times larger than the standard deviation of the spontaneous activity) and derived the RF borders from the onset and offset of the neuronal activity elicited by a smoothly moving light bar (see Materials and methods).â</p><p>[p20 ln 439-443]âFor the MUA data, the CSS model estimated pRF sizes that were very similar to RF size estimates derived from conventional methods that use moving luminance bars, whereas the P-LIN model systematically returned larger pRF estimates. This difference might indicate that spatial compression indeed better captures the neuronal RF properties, at least in V1 and V4.â</p><p>[p31 ln 714-722]âHorizontal and vertical receptive field boundaries were then derived from the onset and offset times for stimuli moving in opposite directions (SupÃ¨r and Roelfsema, 2005). Receptive field centers were defined as the midpoint between the horizontal and vertical borders. For comparison with the pRFs, we calculated RF sizes as half the diagonal of the rectangular area between the horizontal and vertical cRF borders (<inline-formula><mml:math id="sa2m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mtext>cRF</mml:mtext><mml:mrow><mml:mtext>sz</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:msqrt><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mtext>width</mml:mtext><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mtext>height</mml:mtext><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msqrt><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula>). This measure approximates the RF radius based on the SD of a Gaussian response profile, and can be directly compared to the Ï estimated by pRF-models (Figure 7). It is smaller than cRF sizes typically reported in electrophysiological studies, because neurons are activated by stimuli farther than one SD from their RF center (our lab usually defines cRF diameter as 3.3*SD).â</p><p>Various methods exist for the determination of RFs from spiking data, making comparisons across different labs somewhat difficult. The method we describe here is a procedure in use in our lab. To facilitate the comparison with the Ï of pRFs we here use the Ï value of a fitted Gaussian as measure for cRF size. However, we and other labs typically define the RF border at a multiple of this value (e.g., 1.65*Ï) since neurons are activated by stimuli well beyond one Ï from the center of their RF. In many of the papers we cite, RFs were manually marked based on subjective criteria derived from listening to neural activity (Gattass et al., 1987, 1981; Van Essen et al., 1994; Burkhalter and Van Essen, 1986; Rosa et al., 1988; Felleman and Van Essen, 1987; Newsome et al., 1986; Rosa et al., 2000; Gattass et al., 1988). Conversely, it is common in pRF studies to report the Ï of the fitted Gaussian as measure of pRF size, but some studies also report pRF sizes as FWHM.</p><disp-quote content-type="editor-comment"><p>10) Could the authors provide measures about the mean, range and variance in eye position for the MRI and neurophysiology experiments, as this would have potentially affected the size estimates of the smaller RFs. It would be good to discuss this issue.</p></disp-quote><p>We used eye-trackers to monitor eye position and fixation performance determined reward delivery. We excluded epochs with insufficient fixation performance (&lt;80%) from the subsequent model-fits and analysis. For all the recordings that were included in our pRF modeling pipeline, the monkeys had their gaze predominantly inside a fixation window that was slightly smaller in the electrophysiology recordings (0.75Â° radius) compared to the MRI experiments (1Â° radius) for practical reasons (vibrations from the scanner add a bit of noise to the eye position signal). We now determined the median eye position and the span of the IQR (in X and Y direction separately) for each animal across all sessions in both the MRI and electrophysiology experiments. The median eye positions for all animals was within 0.2Â° from the center of fixation, while the maximum IQR we observed was 0.6Â° for M4 in the electrophysiology recordings. Importantly, the IQR for eye position were similar for MRI and electrophysiology (MRI M1: IQRx = 0.2Â°, IQRy = 0.3Â°; M2: IQRx = 0.4Â°, IQRy = 0.5Â°; Electrophysiology M3: IQRx = 0.2Â°, IQRy = 0.4Â°; M4: IQRx = 0.4Â°, IQRy = 0.6Â°).</p><p>Brief and occasional eye-movements outside the fixation window and small residual eye-movements within the fixation window are unlikely to substantially affect the slow BOLD signal and BOLD-pRF estimates. Furthermore, they are likely to average out over stimulus set repetitions. Small residual eye-movements could cause a slight over-estimation of pRF-size. Moreover, the comparison of pRF size estimates across the various electrophysiology signals are unlikely to be influenced by eye movements, because the signals on which they are based were recorded at the same time (i.e., during the same eye-position variations).</p><p>Combining all of the above considerations, we consider it unlikely that eye movements play a significant role in our findings. In the discussion of the comparison of pRFs across signal types, we now briefly mention the potential effect of eye movements (p20, ln 427-432):</p><p>âEye-movements can have an effect on the pRF size estimates and it is therefore important to note that (1) we only included data from recordings where the animals maintained a high fixation performance (IQR-span of the horizontal and vertical eye position, M1: 0.23, 0.34 dva; M2: 0.36, 0.49 dva; M3: 0.18, 0.38 dva; M4: 0.37, 0.60 dva), and (2) we averaged across multiple stimulus presentations to obtain robust response profiles. Hence, variations in eye position can have had only minor effects on the present results.â</p><disp-quote content-type="editor-comment"><p>11) Figure 6B suggests that the neurophysiology data for V4 samples two separate parts of the visual field in the two monkeys.</p><p>(a) Could the authors state in the paper whether there is in any of their analyses a significant difference in the data from the two monkeys and whether this could have affected the comparison with the MRI?</p></disp-quote><p>We ran the underlying analysis separately for M3 and M4 and found the same qualitative pattern of results in both animals. This is now also mentioned in the paper (p11 ln279, p16 ln345). In the comparison with fMRI, V4 differs from V1 since the eccentricity-size relationship of the Î³ LFP signals are sometimes not significantly different from the MRI results. We also ran the comparison with fMRI separately including either only the electrophysiology pRFs from M3 or M4. The results of these analyses were consistent with the original results based on the data from both animals (p18 ln 367-368).</p><p>âBecause the visual field coverage in V4 differed between the two animals that were used for electrophysiology, we repeated the analysis in both individuals and observed similar results (not shown).â</p><disp-quote content-type="editor-comment"><p>(b) Figure 6B suggests that in M4, by far the more eccentric visual field positions were sampled. However, Figure 7B suggests that most of the measured RF sizes are the same or smaller than in M3. Is this correct? And how does this relate to the literature on V4 RF sizes?</p></disp-quote><p>We thank the reviewers for catching this inconsistency. The labels for M3 and M4 were flipped in the legend of Figure 7. We corrected this in the revised version of the figure that now makes a more direct comparison between cRF and pRF (see also point 9).</p></body></sub-article></article>