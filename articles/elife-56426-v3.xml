<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">56426</article-id><article-id pub-id-type="doi">10.7554/eLife.56426</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group><subj-group subj-group-type="heading"><subject>Physics of Living Systems</subject></subj-group></article-categories><title-group><article-title>Random access parallel microscopy</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-178541"><name><surname>Ashraf</surname><given-names>Mishal</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-178542"><name><surname>Mohanan</surname><given-names>Sharika</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-178543"><name><surname>Sim</surname><given-names>Byu Ri</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-178544"><name><surname>Tam</surname><given-names>Anthony</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-213236"><name><surname>Rahemipour</surname><given-names>Kiamehr</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-178546"><name><surname>Brousseau</surname><given-names>Denis</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-178545"><name><surname>Thibault</surname><given-names>Simon</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-178547"><name><surname>Corbett</surname><given-names>Alexander D</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1645-5475</contrib-id><email>A.Corbett@exeter.ac.uk</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-176887"><name><surname>Bub</surname><given-names>Gil</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5304-0036</contrib-id><email>gil.bub@mcgill.ca</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Department of Physiology, MGill University</institution><addr-line><named-content content-type="city">Montreal</named-content></addr-line><country>Canada</country></aff><aff id="aff2"><label>2</label><institution>Department of Physics and Astronomy, University of Exeter</institution><addr-line><named-content content-type="city">Exeter</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff3"><label>3</label><institution>Department of Physics, Engineering Physics and Optics, Université Laval</institution><addr-line><named-content content-type="city">Laval</named-content></addr-line><country>Canada</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Ewbank</surname><given-names>Jonathan</given-names></name><role>Reviewing Editor</role><aff><institution>Aix Marseille Université, INSERM, CNRS</institution><country>France</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Stainier</surname><given-names>Didier YR</given-names></name><role>Senior Editor</role><aff><institution>Max Planck Institute for Heart and Lung Research</institution><country>Germany</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date date-type="publication" publication-format="electronic"><day>12</day><month>01</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e56426</elocation-id><history><date date-type="received" iso-8601-date="2020-02-27"><day>27</day><month>02</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-01-11"><day>11</day><month>01</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Ashraf et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Ashraf et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-56426-v3.pdf"/><abstract><p>We introduce a random-access parallel (RAP) imaging modality that uses a novel design inspired by a Newtonian telescope to image multiple spatially separated samples without moving parts or robotics. This scheme enables near-simultaneous image capture of multiple petri dishes and random-access imaging with sub-millisecond switching times at the full resolution of the camera. This enables the RAP system to capture long-duration records from different samples in parallel, which is not possible using conventional automated microscopes. The system is demonstrated by continuously imaging multiple cardiac monolayer and <italic>Caenorhabditis elegans</italic> preparations.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>optics</kwd><kwd>high-throughput</kwd><kwd>brightfield</kwd><kwd>cardiac</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd><italic>C. elegans</italic></kwd><kwd>Chicken</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution>National Science and Engineering Research Council of Canada</institution></institution-wrap></funding-source><award-id>RGPIN-2018-05346</award-id><principal-award-recipient><name><surname>Bub</surname><given-names>Gil</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution>National Science and Engineering Research Council of Canada</institution></institution-wrap></funding-source><award-id>RGPIN-2016-05962</award-id><principal-award-recipient><name><surname>Thibault</surname><given-names>Simon</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100004411</institution-id><institution>Heart and Stroke Foundation of Canada</institution></institution-wrap></funding-source><award-id>HSFC G-18-0022123</award-id><principal-award-recipient><name><surname>Bub</surname><given-names>Gil</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A new imaging modality is described that can simultaneously record from several dishes without using robotics, which enables researchers to perform high-throughput, continuous measurements on biological samples.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Conventional multi-sample imaging modalities either require movement of the sample to the focal plane of the imaging system (<xref ref-type="bibr" rid="bib16">Klimas et al., 2016</xref>; <xref ref-type="bibr" rid="bib33">Yemini et al., 2013</xref>; <xref ref-type="bibr" rid="bib17">Kopljar et al., 2017</xref>; <xref ref-type="bibr" rid="bib14">Hortigon-Vinagre et al., 2018</xref>), movement of the imaging system itself (<xref ref-type="bibr" rid="bib21">Likitlersuang et al., 2012</xref>; <xref ref-type="bibr" rid="bib12">Hansen et al., 2010</xref>), or use a wide-field approach to capture several samples in one frame (<xref ref-type="bibr" rid="bib19">Larsch et al., 2013</xref>; <xref ref-type="bibr" rid="bib28">Taute et al., 2015</xref>). Schemes that move the sample or the imaging system can be mechanically complex and are inherently slow, while wide-field imaging systems have poor light collection efficiency and resolution compared to systems that image a single sample at a given time point. An important limitation of current imaging modalities is that they cannot continuously monitor several samples unless they are in the same field of view. As many experiments require continuous long-term records in spatially separated samples, they cannot benefit from these high-throughput techniques.</p><p>The random-access parallel (RAP) system uses a large parabolic reflector and objective lenses positioned at their focal distances above each sample. A fast light-emitting diode (LED) array sequentially illuminates samples to generate images that are captured with a single camera placed at the focal point of the reflector. This optical configuration allows each sample to fill a sensor’s field of view. Since each LED illuminates a single sample and LED switch times are very fast, images from spatially separated samples can be captured at rates limited only by the camera’s frame rate or the system’s ability to store data. RAP enables effectively simultaneous continuous recordings of different samples by switching LEDs at very fast rates. We demonstrate the system in two low-magnification, low-resolution settings using single-element lenses and other easily sourced components.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>Our current prototypes (<xref ref-type="fig" rid="fig1">Figure 1A</xref>) use fast machine vision complementary metal-oxide semiconductor cameras and commercially available LED arrays controlled by Arduino microcontrollers, which can rapidly switch between LEDs at kHz rates. A single-element plano-convex lens is placed above each sample, so that collimated light is projected to a 100 mm focal length parabolic reflector, which then creates an image on the detector. The bright-field nature of the illumination used in this design allows images to be captured with sub-millisecond exposure times. The camera is synchronized with the LED array via a transistor–transistor logic (TTL) signal from the microcontroller, so that a single frame is captured when any LED is on. This setup can rapidly switch to image any dish under the parabolic reflector without moving the sample or camera. In addition, the system can acquire data from several dishes near-simultaneously by trading-off the number of samples for frame rate: for example, if a 500 fps camera is used, 50 dishes can be captured at 10 fps, or any two dishes can be recorded at 250 fps (<xref ref-type="fig" rid="fig1">Figure 1B</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Random-access parallel (RAP) imaging principle and magnification properties.</title><p>(<bold>A</bold>) The random-access imaging system uses a parabolic reflector to image samples directly on a fast machine vision camera located at the focal point of the mirror (<italic>f</italic> <sub>M</sub>). Single-element plano-convex lenses are used as objectives, with samples positioned at their focal point (<italic>f</italic> <sub>L</sub>). Samples are sequentially illuminated using a LED array controlled by an Arduino microcontroller: a sample is only projected on the sensor when its corresponding LED is ‘on’. See <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> and <xref ref-type="table" rid="table1">Table 1</xref> for details. (<bold>B</bold>) (top) Sample <italic>s</italic>, is captured at time <italic>t</italic>, on frame <italic>f</italic>. For a total of <italic>n</italic> samples, each sample is captured once every <italic>n</italic> frames; (bottom) a smaller subset of samples can be imaged at higher temporal resolution by reducing the number of LEDs activated by the microcontroller. (<bold>C</bold>) Image magnification: the chief ray (dashed line) arrives at the detector plane at an incidence angle θ which increases with lateral displacement, <italic>y</italic>. The image is stretched in the direction parallel to <italic>y</italic> by a factor of <italic>L/l</italic>. (<bold>D</bold>) The image is isotopically magnified as the distance between the mirror and the image increases (<italic>V2&gt;V1</italic>) as <italic>y</italic> increases. (<bold>E</bold>) The combined magnification, <italic>M<sub>C</sub></italic>, shows the impact of the combined transformation on the magnification in both image dimensions (<italic>y'</italic> parallel to <italic>y</italic>, and <italic>x'</italic> orthogonal to <italic>y</italic>). Red dots (measured) and dashes (predicted) show magnification in <italic>y'</italic>, and blue dots (measured) and dashes (predicted) show magnification in <italic>x'</italic>, inset shows Images of a grid (200 μm pitch) taken with y = 70 mm, left is the uncorrected image and right shows the correct image using <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56426-fig1-v3.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Configurations used for data collection.</title><p>Two configurations, constructed from a combination of Thorlabs optical components (Thorlabs ER series 6 mm rods) and 3D printed parts, were used to collect the data. Both configurations use the same parabolic reflector held at three points by optical rails (Thorlabs XE25) attached to a breadboard. Configuration 1 allows for adjustable focus for each sample by sliding a 3D printed lens holder along 6 mm diameter rods; Configuration 2 has an array of lenses at a fixed vertical position and focus is achieved by moving the samples (here a single 96-well plate).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56426-fig1-figsupp1-v3.tif"/></fig><fig id="fig1s2" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 2.</label><caption><title>Comparison of conventional and RAP images.</title><p>USAF targets (clear pattern on a chrome background) imaged using 25 mm, 100 mm focal length plano-convex lens positioned 100 mm above the sample as an objective and the 100 mm focal length parabolic mirror to refocus the image (<bold>A</bold>, with a zoomed and flipped version of the same image shown in <bold>B</bold>) or a second 25 mm diameter, 100 mm focal length lens to refocus the image on the sensor (<bold>C</bold>, shown at same scale as <bold>B</bold>). The axial distance of the objective to the centre of the parabolic reflector is 40 mm (images <bold>A</bold> and <bold>B</bold>). The large square in the centre right in both close-up images is 140 × 140 μm. The sensor used is a 640 × 480 pixel camera with 4.8 × 4.8 μm pixels.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56426-fig1-figsupp2-v3.tif"/></fig></fig-group><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Configuration details.</title><p>See <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> for additional details.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top"/><th valign="top">Configuration 1</th><th valign="top">Configuration 2</th></tr></thead><tbody><tr><td valign="top">Camera</td><td valign="top">Basler acA640-750um, 750 maximum fps, with 640 × 480, 4.8 × 4.8 μm pixels</td><td valign="top">Basler acA1300-200um, 202 maximum fps, with 1280 × 1024, 4.8 × 4.8 μm pixels</td></tr><tr><td valign="top">Lenses</td><td valign="top">Edmund Optics 25 mm diameter, 100 mm focal length (NA = 0.124)</td><td valign="top">Edmund Optics 6 mm diameter, 72 mm focal length (NA = 0.04)</td></tr><tr><td valign="top">LED array</td><td valign="top">Adafruit DotStar 8 × 32 LED matrix</td><td valign="top">2× Adafruit NeoPixel 40 LED Shields</td></tr><tr><td valign="top">Sample location</td><td valign="top">Four samples equidistant (~40 mm) from the optical axis.</td><td valign="top">Up to 76 wells in a 96-well plate (<xref ref-type="fig" rid="fig3">Figure 3A</xref>).</td></tr><tr><td valign="top">Frame rate</td><td valign="top">Images captured at 160 fps for four sample (<xref ref-type="fig" rid="fig2">Figure 2A–C</xref> and 40.0 fps/sample) or 60 fps for four samples (<xref ref-type="fig" rid="fig2">Figure 2D–F</xref> and 15 fps/sample).</td><td valign="top">Images captured at 120 fps for eight samples (<xref ref-type="fig" rid="fig3">Figure 3</xref> and 15 fps/sample). Different sampling rates are shown in <xref ref-type="video" rid="video1">Video 1</xref>.</td></tr><tr><td valign="top">Usage notes</td><td colspan="2" valign="top">Vibrations in cardiac experiments were damped by using Sorbothane isolators (Thorlabs AV5), and room light was blocked using black aluminium foil (Thorlabs BFK12). We use a 640 × 512 pixel ROI for the camera in Configuration 2 as the illumination spot is smaller than the camera FOV. Camera placement obscures 12 wells in the 96-well plate imaged in Configuration 2 (see <xref ref-type="fig" rid="fig3">Figure 3A</xref>), and the use of two commercial 40 element LED arrays precludes imaging all wells in a 96-well plate as the LEDs are permanently mounted on a board that is too large to be tiled without leaving gaps. In addition, some wells (marked in <xref ref-type="fig" rid="fig3">Figure 3A</xref>) were inadvertently obscured by hardware between the sample and objective lenses for the motion quantification experiment in <xref ref-type="fig" rid="fig3">Figure 3</xref>; however, the number of imaged wells was considered to be sufficient to demonstrate the utility of the RAP system.</td></tr></tbody></table></table-wrap><p>The high NA and large field of view offered by parabolic mirrors have made them very attractive to imaging applications beyond the field of astronomy. However, parabolic mirrors introduce off-axis aberrations, which corrupt any widefield image formed (<xref ref-type="bibr" rid="bib24">Rumsey, 1971</xref>; <xref ref-type="bibr" rid="bib31">Wynne, 1972</xref>). This has resulted in compromises, such as restricting imaging to the focal region and then stage scanning the sample (<xref ref-type="bibr" rid="bib20">Lieb and Meixner, 2001</xref>), which have limited its use to niche applications. In our design, transillumination from LEDs far from the sample and collimation from the objective lens results in mostly collimated light being refocused by the parabolic mirror, avoiding the introduction of significant aberrations. The illumination of the sample by a partially spatially coherent source (<xref ref-type="bibr" rid="bib7">Deng and Chu, 2017</xref>) produces greyscale images, and in our studies, it is the change in this intensity that is of interest.</p><p>Propagation-based phase contrast in our imaging system is generated when collimated light from the LED is diffracted by the sample. Light that remains in the collection cone of the objective lens is then refocused on the sensor by the parabolic reflector at an oblique angle (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). As a result of this angle, the image moves through focus from one side of the detector plane to the other. The region over which the image is in focus is determined by the depth of focus of the parabolic mirror. The distance along the chief ray (<inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>) between the image at either side of the detector is given by <inline-formula><mml:math id="inf2"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">sin</mml:mi></mml:mrow><mml:mo>⁡</mml:mo><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:mi>θ</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the width of the sensor and <inline-formula><mml:math id="inf4"><mml:mi>θ</mml:mi></mml:math></inline-formula> is the angle of the chief ray. For our system, <inline-formula><mml:math id="inf5"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is 2.4 mm, and <inline-formula><mml:math id="inf6"><mml:mi>θ</mml:mi></mml:math></inline-formula> is always less than 60 degrees, so <inline-formula><mml:math id="inf7"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>f</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is always less than 2 mm and the entire image therefore remains inside the Rayleigh length of the parabolic focus.</p><p>Images are subject to two transformations: (1) a stretch due to the image meeting the camera plane obliquely and (2) a small variation in magnification as a function of the separation between the optical axes of the objective lens and the parabolic reflector. These image transformations can be compensated by post-processing the captured images using equations derived from geometric optics as described below.</p><p>Light from the sample arrives at the detector plane at an incidence angle θ, which increases with lateral displacement between objective and mirror axes, <italic>y</italic> (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). As the image itself is formed normal to the chief ray, the detector plane captures a geometric projection of the image which is stretched in the direction of <italic>y</italic>. The magnitude of the stretch is given by<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mtext> </mml:mtext><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:msup><mml:mi>n</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mi>y</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula>where <italic>S</italic> is the magnitude of the stretch in one axis, <italic>y</italic> is the lateral displacement, and <italic>f<sub>M</sub></italic> is the focal length of the parabolic mirror. In addition, there is also a small variation in magnification, which is the same in both image dimensions (<italic>y'</italic> parallel to displacement <italic>y</italic>, and <italic>x'</italic> orthogonal to <italic>y</italic>) due to the distance between the parabolic mirror surface and the focal point (<italic>V</italic>) increasing as a function of <italic>y</italic> (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). The magnification is then given by the ratio of <italic>V</italic> to the focal length of the objective lens, <italic>f<sub>L</sub></italic>. As <italic>V</italic>(<italic>y</italic>) can be calculated precisely for a parabola, the magnification <italic>M</italic> can be written as function of <italic>y</italic>, <italic>f<sub>L</sub></italic>, and mirror focal length, <italic>f</italic><sub>M</sub>:<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:msup><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:msup><mml:mi>y</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mn>4</mml:mn><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:msup></mml:mrow></mml:mstyle></mml:math></disp-formula></p><p>The combined magnification (<italic>M<sub>C </sub></italic>= <italic>M × S</italic>) from global scaling and geometric projection along the <italic>x'</italic> and <italic>y'</italic> dimensions is shown together with measured results in <xref ref-type="fig" rid="fig1">Figure 1E</xref>.</p><p>We demonstrate the system using two popular biological models that may benefit from capturing images in parallel. Cultured cardiac monolayer preparations (<xref ref-type="bibr" rid="bib29">Tung and Zhang, 2006</xref>; <xref ref-type="bibr" rid="bib26">Shaheen et al., 2017</xref>) are used to study arrhythmogenesis in controlled settings and are subject to intense research due to their potential for screening compounds for personalized medicine. <italic>Caenorhabditis elegans</italic> are used as model organisms to study the genetics of aging and biological clocks (<xref ref-type="bibr" rid="bib13">Hekimi and Guarente, 2003</xref>) and, due to highly conserved neurological pathways between mammals and invertebrates, are now used for neuroprotective compound screening (<xref ref-type="bibr" rid="bib19">Larsch et al., 2013</xref>). Both model systems are ideally imaged continuously over long periods to capture dynamics (<xref ref-type="bibr" rid="bib19">Larsch et al., 2013</xref>; <xref ref-type="bibr" rid="bib18">Kucera et al., 2000</xref>), which is not possible in automated microscopy platforms that move samples or the optical path. The preparations were imaged using four 25 mm diameter, 100 mm focal length lenses (see Materials and methods: Configuration 1). <xref ref-type="fig" rid="fig2">Figure 2A</xref> shows recordings from four dishes imaged in parallel containing monolayer cultures of neonatal cardiac cells at 40 fps per dish. Here, motion is tracked by measuring the absolute value of intensity changes for each pixel over a six-frame window (<xref ref-type="bibr" rid="bib5">Burton et al., 2015</xref>). Intensity vs time plots (<xref ref-type="fig" rid="fig2">Figure 2B</xref>) highlight different temporal dynamics in each preparation, and an activation map from one of the dishes shows conduction velocity and wave direction data (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). <italic>C. elegans</italic> can similarly be imaged, here at 15 fps for four dishes over a period of 5 min (<xref ref-type="fig" rid="fig2">Figure 2D–F</xref>). <italic>C. elegans</italic> motion paths (<xref ref-type="fig" rid="fig2">Figure 2D</xref>), which are often used to quantify worm behaviour, can be extracted from each image series using open-source software packages.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>RAP imaging of cardiac monolayer and <italic>C. elegans</italic> preparations.</title><p>(<bold>A</bold>) Four cardiac monolayer preparations in four separate petri dishes are imaged in parallel at 40 fps/dish. (<bold>B</bold>) Activity vs time plots obtained from the four dishes show different temporal dynamics, where double peaks in each trace correspond to contraction and relaxation within a 20 × 20 pixel ROI (see Materials and methods); (<bold>C</bold>) an activation map from the second dish (blue trace in <bold>B</bold>) can be used to determine wave velocity and speed; (<bold>D</bold>) four <italic>C. elegans</italic> dishes imaged in parallel at 15 fps/dish; (<bold>E</bold>) images from one dish every 30 frames (2 s intervals) shows <italic>C. elegans</italic> motion; (<bold>F</bold>) the location of five worms in each dish was tracked from data recorded at 15 fps over 250 frames using open-source wrMTrck (<xref ref-type="bibr" rid="bib22">Nussbaum-Krammer et al., 2015</xref>) software. Dots in different colours (blue, cyan, green, and red) show the tracked positions from plates 1–4, respectively. Each image in (<bold>A</bold>), (<bold>D</bold>), and (<bold>E</bold>) shows a 2 × 2 mm field of view.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56426-fig2-v3.tif"/></fig><p>We validate the potential for RAP to be used in a higher-throughput imaging application by measuring motion in <italic>C. elegans</italic> mitochondrial mutant <italic>nuo-6(qm200</italic>) (<xref ref-type="bibr" rid="bib32">Yang and Hekimi, 2010</xref>), which have a slower swimming rate (frequency of thrashing) than that of the wild-type <italic>C. elegans</italic>. Mutant and wild-type <italic>C. elegans</italic> were loaded into a 96-well plate containing liquid media and imaged by using an array of 76 6 mm diameter, 72 mm focal length lenses positioned above each well (see Materials and methods: Configuration 2). Instead of measuring thrashing frequency directly, motion was quantified by measuring the fraction of pixels per frame that display a change in intensity of over 25% for 100 sequential frames captured at 15 fps/well (see Materials and methods: Image processing). In this experiment, the frame rate of the camera is limited to 120 fps (see Materials and methods: Practical considerations and <xref ref-type="video" rid="video1">Video 1</xref>), allowing us to image eight wells in parallel at 15 fps/well. Eighty wells (76 active and four blank wells – see <xref ref-type="fig" rid="fig3">Figure 3A</xref>) are imaged by measuring 100 frames from each well in a row of eight wells in parallel (800 frames/row) before moving to the next row, until all 80 wells are imaged (a total of 8000 frames). The system quantified decreased activity in <italic>nuo-6(qm200)</italic>, which is consistent with published results (<xref ref-type="bibr" rid="bib32">Yang and Hekimi, 2010</xref>; <xref ref-type="fig" rid="fig3">Figure 3B</xref>). The time needed to perform this assay is just over 1 min (8000 frames/120 fps = 67 s).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>High-throughput estimates of <italic>C. elegans</italic> motion in liquid media.</title><p>Images are captured at 120 fps, which is split over multiple wells as shown in <xref ref-type="video" rid="video1">Video 1</xref>. (<bold>A</bold>) The position of the active detection sites (magenta) relative to the camera (green), which obscures a portion of the 96-well plate: Wells obscured by hardware are denoted by an ‘X’ symbol (see Materials and methods: <xref ref-type="table" rid="table1">Table 1</xref>), wells with wild-type <italic>C. elegans</italic> (WT, ‘+’ symbol) and mutant (<italic>nuo-6(qm200)</italic>, ‘−’ symbol). (<bold>B</bold>) Motion analysis comparing wild type (magenta dots) to mitochondrial mutant <italic>nuo-6(qm200)</italic> (blue dots): wells in each row are imaged in parallel (eight wells at 15 fps per well), and net motion is estimated in each well by summing absolute differences in pixel intensities in sequential frames (see Materials and methods: Image analysis). This estimate confirms that the imaging system can detect significant differences between the two strains (averages shown by diamond and square symbols, two-tailed t-test p=0.01), which is consistent with published results (<xref ref-type="bibr" rid="bib32">Yang and Hekimi, 2010</xref>). (<bold>C</bold>) Focal plane wavelength dependence: details from two fields of view (dashed green and orange squares) in the same image appear in or out of focus depending on whether imaged using a red or blue LED (see <xref ref-type="video" rid="video2">Video 2</xref> and <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56426-fig3-v3.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Focal plane wavelength dependence.</title><p>Images from all wells(<bold>A–H</bold>) for row 10, illuminated using a blue and red LEDs for Configuration 2 imaging <italic>C. elegans</italic> in liquid media. Images are in better focus when illuminated with the red LED for wells (<bold>G</bold>), (<bold>F</bold>), and (<bold>E</bold>) and the blue LED for wells (<bold>H</bold>), (<bold>D</bold>), (<bold>C</bold>), (<bold>B</bold>), and (<bold>A</bold>). Images for each channel are taken 8.3 ms apart, and the 16 images from eight wells are sampled at 7.5 fps. Each image is 512 × 512 pixels and is not transformed other than brightness adjustment in wells (<bold>B</bold>) and (<bold>A</bold>) for clarity. The inset in (<bold>H</bold>) shows a close up to highlight the focal plane difference between the two channels.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56426-fig3-figsupp1-v3.tif"/></fig></fig-group><media id="video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-56426-video1.mp4"><label>Video 1.</label><caption><title>RAP recordings from a 96-well plate, showing recordings at different temporal resolutions.</title></caption></media><p>A limitation of our current implementations of RAP is that focusing individual wells is impractical when there are more than few (i.e. four as in <xref ref-type="fig" rid="fig2">Figure 2</xref>) active samples. For System 2 (76 wells), the objective lenses had a depth of focus of 1 mm, which is sufficient tolerance to accommodate most of the wells imaged. Small variations in lens focal length, variability in printed parts, and variations in tissue culture plates result in well-to-well variations in image quality as samples may not be perfectly in focus. While we were able to resolve <italic>C. elegans</italic> and measure activity in all wells, images are noticeably blurred in about half of the wells, and in some cases, some objects in a single well are better focused than others. This situation can be mitigated by changing the LED colour, as the single-element lenses used in our system show variations in focal length as a function of wavelength (<xref ref-type="fig" rid="fig3">Figure 3C</xref> and <xref ref-type="video" rid="video2">Video 2</xref>). Optical simulations using ray tracing software Configuration 2 confirm that the focal plane can be shifted by 0.981 μm by switching LED colour from red to blue (see Materials and methods). Rapid colour switching (i.e. alternating image capture between red and blue LEDs) may be used to increase data set quality at the expense of decreasing the framerate per well (as was done in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>) or the number of wells that can be imaged in parallel, as twice the number of images per well are required.</p><media id="video2" mime-subtype="mp4" mimetype="video" xlink:href="elife-56426-video2.mp4"><label>Video 2.</label><caption><title>RAP recordings using different colours (red and blue LEDs) focus at different planes in the sample.</title></caption></media></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>The push to develop new high-throughput screening modalities (<xref ref-type="bibr" rid="bib1">Abraham et al., 2004</xref>; <xref ref-type="bibr" rid="bib23">Oheim, 2007</xref>) has resulted in several innovative approaches, ranging from the use of flatbed scanners for slowly varying preparations (<xref ref-type="bibr" rid="bib27">Stroustrup et al., 2013</xref>), to wide-field methods that incorporate computational image reconstruction (<xref ref-type="bibr" rid="bib28">Taute et al., 2015</xref>; <xref ref-type="bibr" rid="bib35">Zheng et al., 2013</xref>), to ‘on-chip’ imaging systems that plate samples directly on a sensor (<xref ref-type="bibr" rid="bib34">Zheng et al., 2011</xref>; <xref ref-type="bibr" rid="bib9">Göröcs and Ozcan, 2013</xref>; <xref ref-type="bibr" rid="bib6">Cui et al., 2008</xref>; <xref ref-type="bibr" rid="bib10">Greenbaum et al., 2012</xref>; <xref ref-type="bibr" rid="bib11">Greenbaum et al., 2013</xref>). Despite these advances, methods that accommodate a biologists’ typical workflow – for example comparing multiple experimental samples plated in different petri dishes – depend on automation of conventional microscopes.</p><p>Automated microscopes excel at applications where data can be acquired from samples sequentially as a single high-numerical-aperture (NA) objective is used. While a RAP system could be built using high-NA, high-magnification optics, this likely would require that each objective lens is independently actuatable in order to achieve focus which poses practical limits on the number of imaged wells. RAP systems can be used to speed up conventional imaging tasks in low-magnification settings by capturing data from different samples in parallel (as was done in <xref ref-type="fig" rid="fig3">Figure 3</xref>). However, here the speed increase afforded by RAP must be weighed against the many benefits of using a mature technology such as the automated widefield microscope (see <xref ref-type="table" rid="table2">Table 2</xref> for a comparison between these systems). RAP systems are better suited for dynamic experiments where multiple continuous long-duration recordings are the primary requirement. For example, rhythms in cultured cardiac tissue evolve over hours (<xref ref-type="bibr" rid="bib15">Kim et al., 2009</xref>) or even days (<xref ref-type="bibr" rid="bib30">Woo et al., 2008</xref>; <xref ref-type="bibr" rid="bib4">Burridge et al., 2016</xref>), but display fast transitions between states (e.g. initiation or termination of re-entry <xref ref-type="bibr" rid="bib3">Bub et al., 1998</xref>), necessitating continuous measurement. In these experiments, moving between samples would result in missed data. RAP overcomes these constraints by reducing transit times between samples to less than a millisecond without the use of automation or relying on a widefield imaging approach, while allowing for an optimized field of view.</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Comparison between conventional and RAP imaging systems.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top"/><th valign="top">Conventional microscope</th><th valign="top">RAP microscope</th></tr></thead><tbody><tr><td valign="top">Resolution</td><td valign="top">NA = 0.025 (1×) to 0.95 (40×)</td><td valign="top">NA = 0.04 and 0.124 (1.4× and 1×)</td></tr><tr><td valign="top">Image quality</td><td valign="top">Optimal <break/>(multi-element objectives correct for most aberrations)</td><td valign="top">Moderate <break/>(single-element lenses used as objectives display spherical and other aberrations)</td></tr><tr><td valign="top">Modalities</td><td valign="top">Bright-field, phase contrast, DIC, fluorescence</td><td valign="top">Bright-field, multi-sample</td></tr><tr><td valign="top">Scan time*</td><td valign="top">~8 min (no autofocus) <break/>~11 min (with autofocus)<sup>†</sup></td><td valign="top">1 min (no focus) <break/>2 min (LED colour switching)</td></tr><tr><td valign="top">Focal drift</td><td valign="top">Moderate to low (due to the use of a heavy machined platform, with further improvements afforded to autofocus systems)</td><td valign="top">Moderate to high (focal plane drift is expected due to light, 3D printed parts, but its impact can be mitigated by LED colour switching)</td></tr><tr><td valign="top">Cost</td><td valign="top">High (~$30,000 with automated x,y,z stages)</td><td valign="top">Low ($1750–$3250)<sup>‡</sup></td></tr><tr><td valign="top">Automation<sup>§</sup></td><td valign="top">Good (many automated microscopes are fully programmable)</td><td valign="top">Unknown (fully programmable, but not validated as part of a conventional high-throughput workflow)</td></tr></tbody></table><table-wrap-foot><fn><p><sup>*</sup>Scan time is estimated for measuring the 72 unobstructed wells in a 96-well plate to allow direct comparison to the data in <xref ref-type="fig" rid="fig3">Figure 3</xref>. The estimate is based on moving serially between wells with a transit time of 0.5 s and imaging 100 frames at 15 fps. Examples from the literature vary considerably (e.g. up to one hour using 3D printed automation technologies, due to limitations in hardware communication speeds: see <xref ref-type="bibr" rid="bib25">Schneidereit et al., 2017</xref>).</p><p><sup>†</sup>We assume the autofocus algorithm takes on average 2.5 s (see <xref ref-type="bibr" rid="bib8">Geusebroek et al., 2000</xref>).</p></fn><fn><p><sup>‡</sup>The cost for the RAP system depends on the number of objective lenses used: Configuration 1 costs approximately $1750, while Configuration 2 (with 76 wells) costs approximately $3,250, as the cost for the cameras in both configurations are similar (~$400). Costs are in USD.</p><p><sup>§</sup>‘Automation’ refers to a system’s ability to be integrated into robotic workflows. Conventional automated microscopes are core components of high-throughput screening platforms with sample and drug delivery capabilities. While our system is in principle compatible with these technologies (e.g. by leveraging existing open-source software, see <xref ref-type="bibr" rid="bib2">Booth et al., 2018</xref>), it has not been tested in these settings.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Sample preparation and imaging</title><p>Wild-type <italic>C. elegans</italic> were maintained in standard 35 mm petri dishes in 5–8 mm of agar seeded with <italic>E. coli</italic> for the data in <xref ref-type="fig" rid="fig2">Figure 2</xref>. For <xref ref-type="fig" rid="fig3">Figure 3</xref>, the mitochondrial mutant <italic>nuo-6(qm200)</italic> (<xref ref-type="bibr" rid="bib32">Yang and Hekimi, 2010</xref>) was used along with wild-type <italic>C. elegans</italic>. Here, <italic>C. elegans</italic> were transferred to 96-well plates by washing adults off NGM plates in M9 buffer, washed once to remove <italic>E. coli</italic>, and resuspended in fresh M9 buffer. Fifty microlitres of this worm suspension was loaded into a 96-well, flat-bottom assay plate (Corning, Costar), excluding half of row five and all wells in rows 6 and 7 as shown in <xref ref-type="fig" rid="fig3">Figure 3A</xref>, as these wells were either obscured by sensor hardware or not illuminated by the two 40-element LED arrays (see Configuration 2 in <xref ref-type="table" rid="table1">Table 1</xref> below). Wells are filled with M9 buffer and covered with a glass coverslip to reduce refraction artefacts at the meniscus interface at well borders. For additional details, see <xref ref-type="bibr" rid="bib13">Hekimi and Guarente, 2003</xref>. All experiments involving <italic>C. elegans</italic> were imaged at room temperature. Cardiac monolayer cultures were prepared from ventricular cells isolated from 7 day old chick embryos: cells were plated within 1 cm glass rings in 35 mm petri dishes as described in <xref ref-type="bibr" rid="bib3">Bub et al., 1998</xref>. Cardiac monolayers were imaged in a stage top incubator (Okolabs) at 36°C and at 5% CO<sub>2</sub> in maintenance media.</p></sec><sec id="s4-2"><title>Optical setup</title><p>A parabolic reflector (220 mm diameter, 100 mm focal length, Edmund Optics) was mounted 300 mm above a breadboard. The camera sensor and electronics (acA640-750um for data collection in <xref ref-type="fig" rid="fig2">Figure 2</xref>, acA1300-200um for data collection in <xref ref-type="fig" rid="fig3">Figure 3</xref>, Basler AG) were mounted in a PLA (polylactic acid) housing without a c-mount thread to allow image formation from light at oblique angles and positioned at the focal point of the parabola. Biological samples were positioned 50 mm above a LED array (DotStar 8 × 32 LED matrix for <xref ref-type="fig" rid="fig2">Figure 2</xref> or two NeoPixel 40 LED Shields for <xref ref-type="fig" rid="fig3">Figure 3</xref>, Adafruit Industries). Plano-convex lenses (25 mm diameter, 100 mm focal length for <xref ref-type="fig" rid="fig2">Figure 2</xref>, 6 mm diameter, 72 mm focal length for <xref ref-type="fig" rid="fig3">Figure 3</xref>, Edmund Optics) were positioned at their focal lengths above each sample. Axial alignment tolerances were set by the depth of field (<inline-formula><mml:math id="inf8"><mml:mi>D</mml:mi><mml:mi>O</mml:mi><mml:mi>F</mml:mi></mml:math></inline-formula>) of the lenses, calculated to be 0.9 mm using the approximation: <inline-formula><mml:math id="inf9"><mml:mi>D</mml:mi><mml:mi>O</mml:mi><mml:mi>F</mml:mi><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:msup><mml:mrow><mml:mi>u</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>N</mml:mi><mml:mi>c</mml:mi><mml:mo>)</mml:mo><mml:mo>/</mml:mo><mml:msup><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></inline-formula> where the subject distance, <italic>u</italic>=<italic>f</italic>, the f-number, <italic>N</italic>=12, and the circle of confusion c, was set to be twice the lateral resolution (18 μm). The LED array was controlled by an ATmega328P microcontroller (Arduino Uno, Arduino.cc) using the FastLED 3.2 open-source library and custom code (<xref ref-type="supplementary-material" rid="scode1">Source code 1</xref> and <xref ref-type="supplementary-material" rid="scode2">2</xref>, in conjunction with free Basler Pylon Viewer software) to synchronize the camera with each LED via a TTL trigger pulse. Custom parts were printed with a Prusa I3 MK2S printer; STL files with an image of the setup showing their use is provided in ‘stl_files.zip’. Table 1 summarizes features of the two systems.</p></sec><sec id="s4-3"><title>Image processing</title><p>We find that image brightness drops with increased objective lateral distance and that images are subject to aberrations at the edges. To offset these effects, captured images shown in <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig3">3</xref> are cropped (480 × 480 pixels for Configuration 1, and 640 × 512 for Configuration 2) and rescaled (so that maximum and minimum pixel intensity values fall between 0 and 255). Dye-free visualization of cardiac activity (<xref ref-type="fig" rid="fig2">Figure 2B</xref>) is carried out by applying a running background subtraction followed by an absolute value operation on each pixel:<disp-formula id="equ3"><mml:math id="m3"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mo>|</mml:mo> <mml:mi/><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mfenced><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mfenced><mml:mo>|</mml:mo></mml:math></disp-formula>where <inline-formula><mml:math id="inf10"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mfenced> <mml:mi/></mml:math></inline-formula> is the value of pixel p at location <italic>i,j</italic> at time <italic>t</italic> and <inline-formula><mml:math id="inf11"><mml:msub><mml:mrow><mml:mi>P</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:mfenced> <mml:mi/></mml:math></inline-formula> is the value of the same pixel at an earlier frame (typically six frames apart: see <xref ref-type="bibr" rid="bib5">Burton et al., 2015</xref>) for details on this technique). Intensity vs time plots of averaged pixels in a 20 × 20 pixel region of interest show double spikes corresponding to contraction followed by relaxation (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Activation maps (<xref ref-type="fig" rid="fig2">Figure 2C</xref>) are generated as previously described (<xref ref-type="bibr" rid="bib5">Burton et al., 2015</xref>). Motion (<xref ref-type="fig" rid="fig3">Figure 3B</xref>) is quantified by finding the magnitude of the intensity change between co-localized pixels in sequential images, counting the number of pixels where the magnitude of the change is over 65 intensity units (25% of the intensity range of the image), and dividing the total by the number of analysed frames. We note that while this algorithm yields results that are consistent with published manual measurements of thrashing frequency (see figure 2j in <xref ref-type="bibr" rid="bib32">Yang and Hekimi, 2010</xref>), there is no direct correspondence between this metric and specific behaviours (head movement, posture changes, etc.). However, the documented difference in the activity of the two strains we use would predict the difference in the metric that we observe and can be used as a validation of the imaging method to track movement over time.</p></sec><sec id="s4-4"><title>Practical considerations</title><p>The camera used in <xref ref-type="fig" rid="fig2">Figure 2</xref> was chosen for its high frame rate as we were interested in imaging cardiac activity, which in our experience requires 40 fps acquisition speeds. The small field of view imposed by the sensor (640 × 480 pixels at 4.8 microns per pixel giving a 3 × 2.3 mm FOV for the 1× imaging scheme used in <xref ref-type="fig" rid="fig2">Figure 2</xref>) was considered reasonable as the field imaged by the 25 mm lens was larger than the sensor, ensuring that the sensor will always capture useful data. In contrast, the system used in <xref ref-type="fig" rid="fig3">Figure 3</xref> used smaller 6 mm lenses, and a relatively small 4 mm diameter spot was projected on the sensor. Small changes in lens angle and position (which proved to be hard to control using our consumer grade desktop 3D printer) result in up to a millimetre well-to-well variation for position of the image on the sensor. We therefore opted to use a higher resolution camera with a larger sensor to ensure that the image would reliably fall on the sensor. While this choice lowers the number of frames that can be continuously saved to disk, we considered this to be an acceptable trade-off as the frame rate needed to image <italic>C. elegans</italic> motion is relatively modest. Future designs will use precision (e.g.CNC (computer numerical control) machined) lens holders that would reduce these variations by an order of magnitude.</p><p>The imaging scheme captures data at a maximum rate that depends on the camera as well as the system’s ability to save data continuously to disk. Our system’s hard drive is capable of continuously saving to disk at 150 MB/second. The camera used in Configuration 2 has a resolution of 1280 × 1024 pixels, which generates 1.25-MB images: the 150 MB/second limit therefore imposes a sustained base frame rate of 120 fps (150 MB/second/1.25MB = 120 fps). <italic>C. elegans</italic> motion can be adequately quantified when imaging at 15 fps, allowing us to image eight wells (120 fps/15 fps) in parallel. A faster hard drive (e.g. an SSD) or RAID array would significantly increase throughput.</p><p>We note that RAP has been validated in low-magnification, bright-field settings that have relaxed constraints relative to microscopy applications that may require high magnification with optimized resolution and high light throughput (e.g. fluorescence microscopy). Rather, our designs aim to maximize the number of independent samples that can be imaged in parallel. We therefore opt to use inexpensive components and minimize the device’s footprint, allowing us to either increase the number of samples captured by a single system or alternatively – as large parabolic reflectors may not be practical in a lab setting – duplicate the system to increase total capacity.</p><p>The use of low-magnification optics in our current implementation is not a defining property of RAP, as higher NA, high-magnification optics could be used. In the same way that the objective lens is not limited by the tube lens in a conventional microscope, the choice of the objective lenses in the RAP microscope is not limited by the parabolic mirror. The NA (and resolving power) of the implementations described above to demonstrate RAP microscopy are consistent with other low-magnification systems. Conventional bright-field 1× microscope objective lenses have NAs close to that of Configuration 2 (e.g. the Zeiss 1× Plan Neofluar commercial objective has an NA of 0.025, and the Thorlabs TL1X-SAP 1× objective has an NA of 0.03), and research stereo macroscopes have NAs close to that of Configuration 1 (e.g. the NA is 0.11 for an Olympus SZX10 at 1×), but can be higher in specialized macroscope systems. As is the case with conventional microscope designs, a high-magnification RAP system would likely require a mechanism for finely adjusting objective heights to keep each sample in focus, as the depth of field of the objective lenses would be reduced. While the resolution of a RAP system is similar to conventional microscopes, RAP systems differ from conventional microscopes in several respects. <xref ref-type="table" rid="table2">Table 2</xref> summarizes some key differences between a conventional automated widefield imaging microscope and the two RAP systems implemented in this publication. We note that higher performance RAP systems (e.g. faster disks, a faster camera, corrected optics) would display improved performance.</p></sec><sec id="s4-5"><title>Optical model validation</title><p>To validate the optical model of the imaging system (<xref ref-type="disp-formula" rid="equ1 equ2">Equations 1 and 2</xref>), an opaque grid with a 200 μm pitch (#58607, Edmund Optics) was used as a test sample. Images of grid sample were captured using an objective lens with its optic axis separated from that of the mirror by distances shown in <xref ref-type="fig" rid="fig1">Figure 1E</xref>. Rescaling the images by the factor given in <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> recovers the image of the square grid.</p></sec><sec id="s4-6"><title>Optical resolution comparison</title><p>To compare the performance of RAP (Configuration 1) to a conventional on-axis imaging system, the parabolic mirror was replaced by a plano-convex lens with the same 100 mm focal length and aligned co-axially with the objective lens and sample. A qualitative comparison of images of a US Air Force chart showed that image resolution degradation in the RAP system, caused by off-axis aberrations in the parabolic mirror, is relatively modest for small (&lt;40 mm) axial distances (<xref ref-type="fig" rid="fig1s2">Figure 1—figure supplement 2</xref>).</p><p>In addition, images of an optically opaque grid were captured on the Configuration 2 system for a variety of off-axis distances. The intensity contrast (the ratio of the darkest region in the gridline to the intensity in the adjacent transmissive region) was used to infer the lateral extent of the optical point spread function (PSF) by comparison to a computational model. The model calculated the anticipated contrast as a function of PSF width (PSF FWHM, see below) using a simple convolution. As the original width of the gridline was known (20 μm, equivalent to 25 line pairs/mm), this relationship could then be used to estimate the lateral PSF width for a given intensity contrast (<xref ref-type="table" rid="table3">Table 3</xref>). The theoretical lateral resolution of a 6 mm diameter, 72 mm focal length lens was calculated to be: <inline-formula><mml:math id="inf12"><mml:mi>P</mml:mi><mml:mi>S</mml:mi><mml:mi>F</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>X</mml:mi><mml:mi>Y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mn>0.6</mml:mn><mml:mi>*</mml:mi><mml:mi>λ</mml:mi><mml:mo>/</mml:mo><mml:mi>N</mml:mi><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mn>9.1</mml:mn> <mml:mi/><mml:mi>μ</mml:mi><mml:mi>m</mml:mi> <mml:mi/></mml:math></inline-formula> when using the centre emission wavelength of 622.5 nm from the Adafruit Neopixel red LEDs. Estimated lateral PSF widths varied from 13.4 to 21.6 microns over the full range of axial distances used in the 96-well experiment, with performance falling as a function of axial distance.</p><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Comparison of image quality (intensity contrast and estimated lateral width of the point spread function) for varying distances from the optic axis.</title></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top">Off-axis distance (mm)</th><th valign="top">Contrast at 25 lp/mm</th><th valign="top">Estimated FWHM (μm)</th></tr></thead><tbody><tr><td valign="top"> 22.16</td><td valign="top">4.50</td><td valign="top">14.9</td></tr><tr><td valign="top"> 29.96</td><td valign="top">6.52</td><td valign="top">13.4</td></tr><tr><td valign="top"> 38.48</td><td valign="top">6.06</td><td valign="top">13.7</td></tr><tr><td valign="top"> 45.04</td><td valign="top">3.62</td><td valign="top">16.0</td></tr><tr><td valign="top"> 53.90</td><td valign="top">3.27</td><td valign="top">16.6</td></tr><tr><td valign="top"> 60.46</td><td valign="top">2.101</td><td valign="top">20.3</td></tr><tr><td valign="top"> 66.84</td><td valign="top">1.88</td><td valign="top">21.6</td></tr></tbody></table></table-wrap></sec><sec id="s4-7"><title>Optical simulations</title><p>The chromatic focal shift observed in the experiments was confirmed using optical simulations (Zemax OpticStudio 18.1). The shift in the back focal plane, solved for marginal rays at a particular wavelength, was calculated. For the plano-convex lens used in Configuration 2 (Edmund Optics #45–696), this focal shift was found to be 981 μm when switching from a red (622 nm) to blue (469 nm) LED.</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank RS Branicky and S Hekimi for the <italic>C. elegans</italic> preparation, A Caldwell for sample preparation, and C Sprigings for programming assistance.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Investigation, Writing - original draft</p></fn><fn fn-type="con" id="con2"><p>Software, Formal analysis, Investigation</p></fn><fn fn-type="con" id="con3"><p>Investigation</p></fn><fn fn-type="con" id="con4"><p>Software, Investigation</p></fn><fn fn-type="con" id="con5"><p>Investigation</p></fn><fn fn-type="con" id="con6"><p>Investigation, Writing - review and editing</p></fn><fn fn-type="con" id="con7"><p>Investigation, Writing - review and editing</p></fn><fn fn-type="con" id="con8"><p>Supervision, Investigation, Methodology, Writing - review and editing</p></fn><fn fn-type="con" id="con9"><p>Conceptualization, Resources, Software, Supervision, Investigation, Methodology, Writing - original draft, Writing - review and editing</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="scode1"><label>Source code 1.</label><caption><title>Arduino code for controlling the camera and LED array for Configuration 1.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-56426-code1-v3.zip"/></supplementary-material><supplementary-material id="scode2"><label>Source code 2.</label><caption><title>Python code for sorting images for each sample into unique directories.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-56426-code2-v3.zip"/></supplementary-material><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>STL files and instructions for assembling RAP Configurations 1 and 2.</title></caption><media mime-subtype="zip" mimetype="application" xlink:href="elife-56426-supp1-v3.zip"/></supplementary-material><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="pdf" mimetype="application" xlink:href="elife-56426-transrepform-v3.pdf"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All data generated during this study are included in the manuscript and supporting files.</p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abraham</surname> <given-names>VC</given-names></name><name><surname>Taylor</surname> <given-names>DL</given-names></name><name><surname>Haskins</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>High content screening applied to large-scale cell biology</article-title><source>Trends in Biotechnology</source><volume>22</volume><fpage>15</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1016/j.tibtech.2003.10.012</pub-id><pub-id pub-id-type="pmid">14690618</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Booth</surname> <given-names>BW</given-names></name><name><surname>McParland</surname> <given-names>C</given-names></name><name><surname>Beattie</surname> <given-names>K</given-names></name><name><surname>Fisher</surname> <given-names>WW</given-names></name><name><surname>Hammonds</surname> <given-names>AS</given-names></name><name><surname>Celniker</surname> <given-names>SE</given-names></name><name><surname>Frise</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>OpenHiCAMM: high-content screening software for complex microscope imaging workflows</article-title><source>iScience</source><volume>2</volume><fpage>136</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1016/j.isci.2018.03.017</pub-id><pub-id pub-id-type="pmid">29888763</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bub</surname> <given-names>G</given-names></name><name><surname>Glass</surname> <given-names>L</given-names></name><name><surname>Publicover</surname> <given-names>NG</given-names></name><name><surname>Shrier</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Bursting calcium rotors in cultured cardiac myocyte monolayers</article-title><source>PNAS</source><volume>95</volume><fpage>10283</fpage><lpage>10287</lpage><pub-id pub-id-type="doi">10.1073/pnas.95.17.10283</pub-id><pub-id pub-id-type="pmid">9707639</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burridge</surname> <given-names>PW</given-names></name><name><surname>Li</surname> <given-names>YF</given-names></name><name><surname>Matsa</surname> <given-names>E</given-names></name><name><surname>Wu</surname> <given-names>H</given-names></name><name><surname>Ong</surname> <given-names>SG</given-names></name><name><surname>Sharma</surname> <given-names>A</given-names></name><name><surname>Holmström</surname> <given-names>A</given-names></name><name><surname>Chang</surname> <given-names>AC</given-names></name><name><surname>Coronado</surname> <given-names>MJ</given-names></name><name><surname>Ebert</surname> <given-names>AD</given-names></name><name><surname>Knowles</surname> <given-names>JW</given-names></name><name><surname>Telli</surname> <given-names>ML</given-names></name><name><surname>Witteles</surname> <given-names>RM</given-names></name><name><surname>Blau</surname> <given-names>HM</given-names></name><name><surname>Bernstein</surname> <given-names>D</given-names></name><name><surname>Altman</surname> <given-names>RB</given-names></name><name><surname>Wu</surname> <given-names>JC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Human induced pluripotent stem cell-derived cardiomyocytes recapitulate the predilection of breast Cancer patients to doxorubicin-induced cardiotoxicity</article-title><source>Nature Medicine</source><volume>22</volume><fpage>547</fpage><lpage>556</lpage><pub-id pub-id-type="doi">10.1038/nm.4087</pub-id><pub-id pub-id-type="pmid">27089514</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burton</surname> <given-names>RA</given-names></name><name><surname>Klimas</surname> <given-names>A</given-names></name><name><surname>Ambrosi</surname> <given-names>CM</given-names></name><name><surname>Tomek</surname> <given-names>J</given-names></name><name><surname>Corbett</surname> <given-names>A</given-names></name><name><surname>Entcheva</surname> <given-names>E</given-names></name><name><surname>Bub</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Optical control of excitation waves in cardiac tissue</article-title><source>Nature Photonics</source><volume>9</volume><fpage>813</fpage><lpage>816</lpage><pub-id pub-id-type="doi">10.1038/nphoton.2015.196</pub-id><pub-id pub-id-type="pmid">27057206</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cui</surname> <given-names>X</given-names></name><name><surname>Lee</surname> <given-names>LM</given-names></name><name><surname>Heng</surname> <given-names>X</given-names></name><name><surname>Zhong</surname> <given-names>W</given-names></name><name><surname>Sternberg</surname> <given-names>PW</given-names></name><name><surname>Psaltis</surname> <given-names>D</given-names></name><name><surname>Yang</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Lensless high-resolution on-chip optofluidic microscopes for <italic>Caenorhabditis elegans</italic> and cell imaging</article-title><source>PNAS</source><volume>105</volume><fpage>10670</fpage><lpage>10675</lpage><pub-id pub-id-type="doi">10.1073/pnas.0804612105</pub-id><pub-id pub-id-type="pmid">18663227</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deng</surname> <given-names>Y</given-names></name><name><surname>Chu</surname> <given-names>D</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Coherence properties of different light sources and their effect on the image sharpness and speckle of holographic displays</article-title><source>Scientific Reports</source><volume>7</volume><elocation-id>5893</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-017-06215-x</pub-id><pub-id pub-id-type="pmid">28724961</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geusebroek</surname> <given-names>JM</given-names></name><name><surname>Cornelissen</surname> <given-names>F</given-names></name><name><surname>Smeulders</surname> <given-names>AW</given-names></name><name><surname>Geerts</surname> <given-names>H</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Robust autofocusing in microscopy</article-title><source>Cytometry</source><volume>39</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1097-0320(20000101)39:1&lt;1::AID-CYTO2&gt;3.0.CO;2-J</pub-id><pub-id pub-id-type="pmid">10655557</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Göröcs</surname> <given-names>Z</given-names></name><name><surname>Ozcan</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>On-chip biomedical imaging</article-title><source>IEEE Reviews in Biomedical Engineering</source><volume>6</volume><fpage>29</fpage><lpage>46</lpage><pub-id pub-id-type="doi">10.1109/RBME.2012.2215847</pub-id><pub-id pub-id-type="pmid">23558399</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greenbaum</surname> <given-names>A</given-names></name><name><surname>Luo</surname> <given-names>W</given-names></name><name><surname>Su</surname> <given-names>TW</given-names></name><name><surname>Göröcs</surname> <given-names>Z</given-names></name><name><surname>Xue</surname> <given-names>L</given-names></name><name><surname>Isikman</surname> <given-names>SO</given-names></name><name><surname>Coskun</surname> <given-names>AF</given-names></name><name><surname>Mudanyali</surname> <given-names>O</given-names></name><name><surname>Ozcan</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Imaging without lenses: achievements and remaining challenges of wide-field on-chip microscopy</article-title><source>Nature Methods</source><volume>9</volume><fpage>889</fpage><lpage>895</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2114</pub-id><pub-id pub-id-type="pmid">22936170</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greenbaum</surname> <given-names>A</given-names></name><name><surname>Luo</surname> <given-names>W</given-names></name><name><surname>Khademhosseinieh</surname> <given-names>B</given-names></name><name><surname>Su</surname> <given-names>T-W</given-names></name><name><surname>Coskun</surname> <given-names>AF</given-names></name><name><surname>Ozcan</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Increased space-bandwidth product in pixel super-resolved lensfree on-chip microscopy</article-title><source>Scientific Reports</source><volume>3</volume><elocation-id>1717</elocation-id><pub-id pub-id-type="doi">10.1038/srep01717</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hansen</surname> <given-names>A</given-names></name><name><surname>Eder</surname> <given-names>A</given-names></name><name><surname>Bönstrup</surname> <given-names>M</given-names></name><name><surname>Flato</surname> <given-names>M</given-names></name><name><surname>Mewe</surname> <given-names>M</given-names></name><name><surname>Schaaf</surname> <given-names>S</given-names></name><name><surname>Aksehirlioglu</surname> <given-names>B</given-names></name><name><surname>Schwoerer</surname> <given-names>AP</given-names></name><name><surname>Schwörer</surname> <given-names>A</given-names></name><name><surname>Uebeler</surname> <given-names>J</given-names></name><name><surname>Eschenhagen</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Development of a drug screening platform based on engineered heart tissue</article-title><source>Circulation Research</source><volume>107</volume><fpage>35</fpage><lpage>44</lpage><pub-id pub-id-type="doi">10.1161/CIRCRESAHA.109.211458</pub-id><pub-id pub-id-type="pmid">20448218</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hekimi</surname> <given-names>S</given-names></name><name><surname>Guarente</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Genetics and the specificity of the aging process</article-title><source>Science</source><volume>299</volume><fpage>1351</fpage><lpage>1354</lpage><pub-id pub-id-type="doi">10.1126/science.1082358</pub-id><pub-id pub-id-type="pmid">12610295</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hortigon-Vinagre</surname> <given-names>M</given-names></name><name><surname>Zamora</surname> <given-names>V</given-names></name><name><surname>Burton</surname> <given-names>F</given-names></name><name><surname>Butler</surname> <given-names>P</given-names></name><name><surname>Smith</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Measurements of voltage, intracellular Ca2+ and contraction from spontaneous iPSC-derived cardiomyocytes using CellOPTIQ platform reveals complex effects from drugs that parallel in vivo cardiac effects</article-title><source>Journal of Pharmacological and Toxicological Methods</source><volume>1</volume><fpage>119</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.1016/j.vascn.2018.01.407</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname> <given-names>MY</given-names></name><name><surname>Aguilar</surname> <given-names>M</given-names></name><name><surname>Hodge</surname> <given-names>A</given-names></name><name><surname>Vigmond</surname> <given-names>E</given-names></name><name><surname>Shrier</surname> <given-names>A</given-names></name><name><surname>Glass</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Stochastic and spatial influences on drug-induced bifurcations in cardiac tissue culture</article-title><source>Physical Review Letters</source><volume>103</volume><elocation-id>058101</elocation-id><pub-id pub-id-type="doi">10.1103/PhysRevLett.103.058101</pub-id><pub-id pub-id-type="pmid">19792536</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klimas</surname> <given-names>A</given-names></name><name><surname>Ambrosi</surname> <given-names>CM</given-names></name><name><surname>Yu</surname> <given-names>J</given-names></name><name><surname>Williams</surname> <given-names>JC</given-names></name><name><surname>Bien</surname> <given-names>H</given-names></name><name><surname>Entcheva</surname> <given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>OptoDyCE as an automated system for high-throughput all-optical dynamic cardiac electrophysiology</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>11542</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms11542</pub-id><pub-id pub-id-type="pmid">27161419</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kopljar</surname> <given-names>I</given-names></name><name><surname>De Bondt</surname> <given-names>A</given-names></name><name><surname>Vinken</surname> <given-names>P</given-names></name><name><surname>Teisman</surname> <given-names>A</given-names></name><name><surname>Damiano</surname> <given-names>B</given-names></name><name><surname>Goeminne</surname> <given-names>N</given-names></name><name><surname>den Wyngaert</surname> <given-names>IV</given-names></name><name><surname>Gallacher</surname> <given-names>D</given-names></name><name><surname>Lu</surname> <given-names>HR</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Combining video microscopy motion analysis and detection of cardiac injury biomarkers to evaluate chronic cardiotoxicity in hiPS cardiomyocytes</article-title><source>Journal of Pharmacological and Toxicological Methods</source><volume>88</volume><fpage>239</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1016/j.vascn.2017.09.233</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kucera</surname> <given-names>JP</given-names></name><name><surname>Heuschkel</surname> <given-names>MO</given-names></name><name><surname>Renaud</surname> <given-names>P</given-names></name><name><surname>Rohr</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Power-law behavior of beat-rate variability in monolayer cultures of neonatal rat ventricular myocytes</article-title><source>Circulation Research</source><volume>86</volume><fpage>1140</fpage><lpage>1145</lpage><pub-id pub-id-type="doi">10.1161/01.RES.86.11.1140</pub-id><pub-id pub-id-type="pmid">10850965</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Larsch</surname> <given-names>J</given-names></name><name><surname>Ventimiglia</surname> <given-names>D</given-names></name><name><surname>Bargmann</surname> <given-names>CI</given-names></name><name><surname>Albrecht</surname> <given-names>DR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>High-throughput imaging of neuronal activity in <italic>Caenorhabditis elegans</italic></article-title><source>PNAS</source><volume>110</volume><fpage>E4266</fpage><lpage>E4273</lpage><pub-id pub-id-type="doi">10.1073/pnas.1318325110</pub-id><pub-id pub-id-type="pmid">24145415</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lieb</surname> <given-names>M</given-names></name><name><surname>Meixner</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A high numerical aperture parabolic mirror as imaging device for confocal microscopy</article-title><source>Optics Express</source><volume>8</volume><elocation-id>458</elocation-id><pub-id pub-id-type="doi">10.1364/oe.8.000458</pub-id><pub-id pub-id-type="pmid">19417842</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Likitlersuang</surname> <given-names>J</given-names></name><name><surname>Stephens</surname> <given-names>G</given-names></name><name><surname>Palanski</surname> <given-names>K</given-names></name><name><surname>Ryu</surname> <given-names>WS</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Elegan stracking and behavioral measurement</article-title><source>Journal of Visualized Experiments : JoVE</source><volume>17</volume><elocation-id>e4094</elocation-id><pub-id pub-id-type="doi">10.3791/4094</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nussbaum-Krammer</surname> <given-names>CI</given-names></name><name><surname>Neto</surname> <given-names>MF</given-names></name><name><surname>Brielmann</surname> <given-names>RM</given-names></name><name><surname>Pedersen</surname> <given-names>JS</given-names></name><name><surname>Morimoto</surname> <given-names>RI</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Investigating the spreading and toxicity of Prion-like proteins using the metazoan model organism <italic>C. elegans</italic></article-title><source>Journal of Visualized Experiments</source><volume>8</volume><elocation-id>e52321</elocation-id><pub-id pub-id-type="doi">10.3791/52321</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oheim</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>High-throughput microscopy must re-invent the microscope rather than speed up its functions</article-title><source>British Journal of Pharmacology</source><volume>152</volume><fpage>1</fpage><lpage>4</lpage><pub-id pub-id-type="doi">10.1038/sj.bjp.0707348</pub-id><pub-id pub-id-type="pmid">17603553</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rumsey</surname> <given-names>NJ</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>Pairs of spherical mirrors as field correctors for paraboloid mirrors</article-title><source>Publications of the Astronomical Society of Australia</source><volume>2</volume><fpage>22</fpage><lpage>23</lpage><pub-id pub-id-type="doi">10.1017/S1323358000012595</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneidereit</surname> <given-names>D</given-names></name><name><surname>Kraus</surname> <given-names>L</given-names></name><name><surname>Meier</surname> <given-names>JC</given-names></name><name><surname>Friedrich</surname> <given-names>O</given-names></name><name><surname>Gilbert</surname> <given-names>DF</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Step-by-step guide to building an inexpensive 3D printed motorized positioning stage for automated high-content screening microscopy</article-title><source>Biosensors and Bioelectronics</source><volume>92</volume><fpage>472</fpage><lpage>481</lpage><pub-id pub-id-type="doi">10.1016/j.bios.2016.10.078</pub-id><pub-id pub-id-type="pmid">27840039</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shaheen</surname> <given-names>N</given-names></name><name><surname>Shiti</surname> <given-names>A</given-names></name><name><surname>Gepstein</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Pluripotent stem Cell-Based platforms in cardiac disease modeling and drug testing</article-title><source>Clinical Pharmacology &amp; Therapeutics</source><volume>102</volume><fpage>203</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1002/cpt.722</pub-id><pub-id pub-id-type="pmid">28718902</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stroustrup</surname> <given-names>N</given-names></name><name><surname>Ulmschneider</surname> <given-names>BE</given-names></name><name><surname>Nash</surname> <given-names>ZM</given-names></name><name><surname>López-Moyado</surname> <given-names>IF</given-names></name><name><surname>Apfeld</surname> <given-names>J</given-names></name><name><surname>Fontana</surname> <given-names>W</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The <italic>Caenorhabditis elegans</italic> lifespan machine</article-title><source>Nature Methods</source><volume>10</volume><fpage>665</fpage><lpage>670</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2475</pub-id><pub-id pub-id-type="pmid">23666410</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taute</surname> <given-names>KM</given-names></name><name><surname>Gude</surname> <given-names>S</given-names></name><name><surname>Tans</surname> <given-names>SJ</given-names></name><name><surname>Shimizu</surname> <given-names>TS</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>High-throughput 3D tracking of Bacteria on a standard phase contrast microscope</article-title><source>Nature Communications</source><volume>6</volume><fpage>1</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1038/ncomms9776</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tung</surname> <given-names>L</given-names></name><name><surname>Zhang</surname> <given-names>Y</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Optical imaging of arrhythmias in tissue culture</article-title><source>Journal of Electrocardiology</source><volume>39</volume><fpage>S2</fpage><lpage>S6</lpage><pub-id pub-id-type="doi">10.1016/j.jelectrocard.2006.04.010</pub-id><pub-id pub-id-type="pmid">17015066</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woo</surname> <given-names>S-J</given-names></name><name><surname>Hong</surname> <given-names>JH</given-names></name><name><surname>Kim</surname> <given-names>TY</given-names></name><name><surname>Wook Bae</surname> <given-names>B</given-names></name><name><surname>Lee</surname> <given-names>KJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Spiral wave drift and complex-oscillatory spiral waves caused by heterogeneities in two-dimensional <italic>in vitro</italic> cardiac tissues</article-title><source>New Journal of Physics</source><volume>10</volume><elocation-id>015005</elocation-id><pub-id pub-id-type="doi">10.1088/1367-2630/10/1/015005</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wynne</surname> <given-names>CG</given-names></name></person-group><year iso-8601-date="1972">1972</year><article-title>IV field correctors for astronomical telescopes</article-title><source>Prog. Opt</source><volume>10</volume><fpage>137</fpage><lpage>164</lpage><pub-id pub-id-type="doi">10.1016/S0079-6638(08)70059-3</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname> <given-names>W</given-names></name><name><surname>Hekimi</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Two modes of mitochondrial dysfunction lead independently to lifespan extension in <italic>Caenorhabditis elegans</italic></article-title><source>Aging Cell</source><volume>9</volume><fpage>433</fpage><lpage>447</lpage><pub-id pub-id-type="doi">10.1111/j.1474-9726.2010.00571.x</pub-id><pub-id pub-id-type="pmid">20346072</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yemini</surname> <given-names>E</given-names></name><name><surname>Jucikas</surname> <given-names>T</given-names></name><name><surname>Grundy</surname> <given-names>LJ</given-names></name><name><surname>Brown</surname> <given-names>AE</given-names></name><name><surname>Schafer</surname> <given-names>WR</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A database of <italic>Caenorhabditis elegans</italic> behavioral phenotypes</article-title><source>Nature Methods</source><volume>10</volume><fpage>877</fpage><lpage>879</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2560</pub-id><pub-id pub-id-type="pmid">23852451</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname> <given-names>G</given-names></name><name><surname>Lee</surname> <given-names>SA</given-names></name><name><surname>Antebi</surname> <given-names>Y</given-names></name><name><surname>Elowitz</surname> <given-names>MB</given-names></name><name><surname>Yang</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The ePetri dish, an on-chip cell imaging platform based on subpixel perspective sweeping microscopy (SPSM)</article-title><source>PNAS</source><volume>108</volume><fpage>16889</fpage><lpage>16894</lpage><pub-id pub-id-type="doi">10.1073/pnas.1110681108</pub-id><pub-id pub-id-type="pmid">21969539</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname> <given-names>G</given-names></name><name><surname>Horstmeyer</surname> <given-names>R</given-names></name><name><surname>Yang</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Wide-field, high-resolution fourier ptychographic microscopy</article-title><source>Nature Photonics</source><volume>7</volume><fpage>739</fpage><lpage>745</lpage><pub-id pub-id-type="doi">10.1038/nphoton.2013.187</pub-id><pub-id pub-id-type="pmid">25243016</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.56426.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Ewbank</surname><given-names>Jonathan</given-names></name><role>Reviewing Editor</role><aff><institution>Aix Marseille Université, INSERM, CNRS</institution><country>France</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Marguet</surname><given-names>Didier</given-names> </name><role>Reviewer</role><aff><institution>Aix Marseille University</institution><country>France</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>The clarifications that you have made now allow readers to judge for themselves the utility of this novel imaging modality. While the current system falls short of providing truly continuous high-speed (i.e. &gt; 10 fps) imaging of 80-96 wells, it clearly has great potential for multiple applications.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Solid state high throughput screening microscopy&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, and the evaluation has been overseen by a Reviewing Editor and Didier Stainier as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Didier Marguet (Reviewer #1).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>As the editors have judged that your manuscript is of interest, but as described below that additional experiments are required before it is published, we would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). First, because many researchers have temporarily lost access to the labs, we will give authors as much time as they need to submit revised manuscripts. We are also offering, if you choose, to post the manuscript to bioRxiv (if it is not already there) along with this decision letter and a formal designation that the manuscript is “in revision at <italic>eLifeeLife</italic>”. Please let us know if you would like to pursue this option.</p><p>The reviewers all recognised the originality of your solution to perform high throughput imaging without moving parts. They do have some serious reservations, primarily regarding the evaluation of the quality and utility of the technique and in addition to the other points raised, consider it essential that you address the following:</p><p>– The standard topics for any new microscope paper: &quot;objective&quot; numerical aperture, image resolution, optical aberration, and camera sensor size, together with the specific aspects related to this technique, including dependence on homogeneous illumination, and sensitivity to maintenance of F2 distance.</p><p>– A substantial expansion of the scope of the data presented, to provide readers with sufficient evidence with which to evaluate the quality of the technique, including proof of principal with a 96-well plate assay.</p><p>– A direct quantitative comparison with existing HTS imaging solutions.</p><p><italic>Reviewer #1:</italic></p><p>Ashraf and colleagues describe an approach to perform high throughput screening imaging without moving parts. The setup is original and offers to experimentalists the flexibility to record quasi-simultaneously stacks of images of multiple samples at the full field of resolution of the camera. The optical aberration inherent to the use of a parabolic mirror are mostly overcome by collimating light from the objective lens. The images require a post-processing in two steps for taking into account the image stretching on the detector and the variation in magnification due to the variation of the distance between the mirror and the image. Two applications illustrate the potential of the solid-state HTS.</p><p>To my opinion, the following points need to be clarified:</p><p>– How homogeneous is the field of illumination with a single LED? Especially for a large field of illumination, a non-homogeneous illumination would compromise the quantifications.</p><p>– The accuracy of this ssHTS is related to the robustness at keeping the distance F2 constant between samples. In other words, how sensitive is the image acquisition to the potential variation in the F2 distance between samples as well as within a single large field of view?</p><p>– The magnification Mc must be explained.</p><p>– Is the post-processing compensation applied only in the y-direction?</p><p>Assuming that such publication aims to disseminate the use of an ssHTS setup to a wide scientific community, I find the description of the setup as well as the applied image post-processing rather succinct, even with the 3D printing and source codes information.</p><p><italic>Reviewer #2:</italic></p><p>Astronomers have spent centuries learning how to image the night sky with limited sensor hardware. Ashraf et al. present an ingenious adaptation of a technology developed for telescopes-parabolic reflectors-for imaging biological samples. In principle, the approach seems like it could be incredibly useful across a wide range of applications where multiple samples must be imaged in tandem. By placing multiple samples under a single parabolic reflector, multiplexing of samples and imaging hardware can be accomplished without sample-handling robots or moving cameras. The authors highlight two applications: cardiac cells in culture and free-moving nematodes.</p><p>The authors explain the theory behind their technique in a clear and convincing way. However, the biggest challenge in most imaging projects is making the theory work in practice. In its current form, the manuscript falls far short of demonstrating the practical usefulness of parabolic mirrors for imaging biological samples. The authors include only a small amount of image data-for the nematode work, this consists of eight images collected from two plate regions. Data of this scope cannot provide readers or reviewers with sufficient evidence with which to evaluate the quality of the technique.</p><p>1) The images shown-are they typical or are they the best possible images that can be collected from the device? The authors do not provide any quantitative evaluation of the quality of their images, in absolute terms or relative to existing methods, with which to understand the practical performance of parabolic mirrors. The authors should estimate the spatial resolution and dynamic range that can be obtained in practice with the devices, and evaluate how such image quality metrics vary across the entire field of view. Does performance degrade towards the edge of the mirror? Does performance degrade over time, as devices become de-calibrated with use?</p><p>2) The manuscript is additionally weakened by the absence of a non-trivial measurement made with the device. Pilot experiments are included, demonstrating that images can be collected. However, no evidence is provided to show that these images can be used to compare samples and draw biological conclusions from them. A more convincing proof-of-principle would involve the measurement of some non-trivial biological difference between samples measured with the device, either confirming previous work or discovering something new.</p><p>3) The authors highlight the comparative simplicity of their method: it eliminates the need for motorized samples or cameras. However, this simplicity must come at some: for example a substantially increased use of space or perhaps an increase in delicate calibration required, or equipment price. If a 0.25 meter mirror is required to measure four <italic>C. elegans</italic> plates, how large a mirror would be required to measure 16 plates-the number that can typically be measured using a flatbed scanner? The authors could also expand greatly on other practical issues: for example, is a dedicated imaging table required to align mirrors and samples? Readers would benefit from a clearer evaluation of the practical trade-offs in deploying parabolic mirrors in a laboratory setting relative to other imaging approaches.</p><p><italic>Reviewer #3:</italic></p><p>The authors present a cool new idea: using a large parabolic reflector in combination with a macroscopic lens array and rapidly modulated LED array to enable fast image multiplexing between spatially separated samples. I believe that there may be interesting applications that would benefit from this capability, although the authors have not clearly demonstrated one. The paper is short, and light on discussion, details, and data.</p><p>1) The manuscript does not discuss several standard, key topics for any new microscope paper: &quot;objective&quot; numerical aperture, image resolution, optical aberration (other than distortion, which is discussed), and camera sensor size.</p><p>2) Why was an array of low-performance singlet lenses used? With that selection, the image quality cannot be good. Can the system not be paired with an array of objectives or higher performance multielement lenses?</p><p>3) Fluorescence imaging is not discussed or demonstrated but would obviously increase the impact of the microscope. At least some discussion would be helpful.</p><p>4) Actual HTS applications are almost always implemented in microtiter plates (e.g. a 96-well plate) to reduce reagent costs and enable automated pipetting, etc. I do not believe anyone would implement HTS in thousands of petri dishes. The paper would be strengthened substantially by a demonstration of simultaneous recording from all (or a large subset) of the wells in a 96-well plate. It's not clear whether this is possible due to the blind spot in the center of the parabolic mirror's field of view that is blocked by the camera.</p><p>5) One of the primary motivations for this approach is given in the first paragraph as: &quot;wide-field imaging systems [which capture multiple samples in one frame] have poor light collection efficiency and resolution compared to systems that image a single sample at a given time point.&quot; With a f = 100 mm singlet lens, the light collection efficiency of the demonstrated microscope is also low (estimated NA = 0.12) and the resolution is unimpressive with the high-aberration lens and 1x magnification. They demonstrated only trans-illumination applications (e.g. phase contrast), where light collection efficiency is not important. I believe a fancy photography lens mounted directly on a many-megapixel camera set to image all or part of a microtiter plate could likely outperform their system in throughput and simplicity, at least for the demonstrated applications of cardiomyocytes and <italic>C. elegans</italic>.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Solid state high throughput screening microscopy&quot; for further consideration by <italic>eLife</italic>. Your revised article has been evaluated by Didier Stainier (Senior Editor) and a Reviewing Editor following review and discussion by the three original reviewers.</p><p>Overall, the reviewers recognised that this setup could be useful for readers looking for an inexpensive bright-field imaging setup for multi-well imaging without fluorescence. They agree that you have provided substantial additional data and analysis that support your claim that parabolic reflectors can be useful for studying many samples in a parallel. The new images and videos of a 96-well plate were judged compelling. In particular, the prospect of focusing samples simply by adjusting the wavelength of illumination was thought an important step towards the goal of designing a &quot;solid-state&quot; imaging apparatus with no moving parts.</p><p>Nevertheless, although the reviewers were satisfied that you had addressed most or all of the material points, they had considerable reservations about the way in which these improvements were presented and could not support publication of the manuscript in its present form. Indeed, there are numerous lacunae and parts where the writing is not at all clear and leads to confusion about how the system functions and what its limits are. Please find below a summary of their most important comments and a series of points made by individual reviewers, all of which would need to be addressed in a revised manuscript. If this would require a further round of experimental work, then I am afraid that we will not be able to consider your work for publication.</p><p>The description of the 96-well plate data was considered both terse and vague, leaving unclear several aspects of experimental design and interpretation.</p><p>– If no samples were loaded into columns 6 and 7 of the 96 well plate because of the use of 40 LED arrays, this should be stated explicitly.</p><p>– What was the exact reason for not imaging in column 4 of row E or row 1F.</p><p>These discrepancies between the theoretically predicted function of the device and its practical performance must be clarified.</p><p>If these issues do not reflect technical limitation of the device, you would need to demonstrate that these columns/wells can be imaged just like the others (i.e. this is a criterion for rejection).</p><p>The details about acquisition are so poorly described that one reviewer wrote, &quot;why not leverage those capabilities to scan 33 wells in parallel at 15 Hz rather than one well at a time at 15 Hz?&quot;. This illustrates how you have failed to convey clearly that the system captures data from multiple wells in parallel at 120-500 fps. One video does show how 120 fps can be divided up across 80 wells, and it is illustrated in Figure 1, but these details need to be explicitly stated in the text. In Figure 2, a faster (500 fps) camera of lower resolution is used. As well as making all acquisition details clearer, you will need to provide an explicit discussion of camera choice, and any trade-off between image resolution and speed. Additionally, you need to address another technical limitation and trade-off, namely rates of acquisition and data transfer so that the possibility (and cost) of implementation in a HTS setting (see below) is clear.</p><p>The center of the optical system is intrinsically blind since space is required to position the detector. This point is implicit and must be documented as a function of the magnification.</p><p>The microscope resolution in the 15 – 20 µm range is poor relative to the sub-micron resolution of a traditional microscope. It is probably not good enough, for example, to tell individual mammalian cells apart in a confluent monolayer. This will limit the range of potential applications. Thus the spatial resolution needs to be stated in the Abstract or Introduction, not buried deep in the Materials and methods. Further, you will need to include a detailed comparison with a standard commercial widefield microscope with a scanning stage (resolution, imaging modalities, scan time, defocusing over time, cost, integration into robotic workflows). If you wish to claim HTS capacity, the comparison should also include a dedicated commercial HCS/HTS system, and the many other features needed for HTS (e.g. see https://www.ncbi.nlm.nih.gov/books/NBK558077/).</p><p>Alternatively, in the absence of easy incorporation of the system in an automated setting, at a time when HTS can mean &gt;50,000 tests/day, &quot;High Throughput&quot; should be removed from the title (&quot;multi-sample&quot; or &quot;multi-well&quot; would be better), and any suggestion in the text that your system is HTS-compatible seriously toned down. Equally, given the very different uses in optics or electronics of the term &quot;solid-state&quot;, you should avoid it in the title, replacing it, for example by, &quot;with no moving parts&quot;.</p><p>There was also a general consensus that your design is not a Newtonian telescope, which has two mirrors instead of a single mirror as in this design. The reviewers recommend changing &quot;novel Newtonian telescope design&quot; to &quot;large on-axis parabolic mirror design&quot;, &quot;parabolic reflector&quot;, or something similar that is clearer and more accurate. Including a phrase like &quot;inspired by a Newtonian telescope&quot; would be acceptable.</p><p>Further points made by individual reviewers:</p><p>1) The authors compare wild-type <italic>C. elegans</italic> to nuo-6 mutants. The authors are vague and qualitative in their descriptions of movement. Nuo-6 mutants are predicted to &quot;move less frequently&quot; than wildtype. This is confusing, as <italic>C. elegans</italic> generally exhibit some degree of continuous movement as long as they remain alive, involving body postural changes, head movements, or pharyngeal pumping. Are the authors referring to the frequency of a particular type of movement? For the purposes of this paper, the authors probably do not need to alter their imaging pipeline, but they should be substantially more specific about which behavior their method is measuring.</p><p>2) Many nematode behaviors change in response to stimulation with light, physical stimulus, or immersion in liquid. Other behaviors are suppressed by long periods spent immersed in un-mixed liquids. It remains difficult to interpret the authors' results without additional information describing how the light and culturing conditions they are use influences nematode behavior and how this influences their results. In particular, the behavioral difference observed between day 1, 2 and 3 could be expected as a technical artifact (i.e., in the absence of any underlying aging process) if nematodes remained in the same wells for multiple days.</p><p>3) The authors observe a difference in activity between nuo-6 and wild-type animals, and also between young animals and old animals. However, discussion of this is surprisingly qualitative given the quantitative thinking found elsewhere in the paper. Are the observed differences in movement approximately the same magnitude as what would be expected given previous results? Why is a significant difference between the two strains observed only on day one and three, but not day two?</p><p>4) The Figure 1 caption uses fM and fL while Figure 1 uses F1 and F2. Please make consistent.</p><p>5) Equation 2 is not fully displayed.</p><p>6) Introduction: Please give some concrete examples of experiments that require continuous long-term recording where low-resolution brightfield imaging would be the appropriate readout modality.</p><p>7) Introduction: The phrase &quot;high resolution&quot; is misleading, as the 15-22 µm resolution of this microscope would be considered very low resolution by most microscopists. Please insert the actual resolution here.</p><p>8) Results: I would not call this a high light collection efficiency design, as most standard microscopes have higher efficiency. Light collection efficiency is not very important here, so please change the language to be less contentious.</p><p>9) Results: Calling an LED source spatially coherent is really straining the definition. Please use different language.</p><p>10) Materials and methods: Something is wrong or confusing about the depth of focus discussion. Please cite a source for the equations and clearly define all variables. If u = f as you indicate in the text, then DOF=2c≠0.9 mm, which was stated in the text. The f-number does not appear in the equation you have, but the discussion seems to indicate that it is important (as would be expected).</p><p>11) Figure 2 legend: should be &quot;(blue trace in B)&quot;</p><p>12) Figure 3 legend: duplicated text &quot;C) Focal plane….&quot;</p><p>13) The authors limit their discussion of statistical analysis of animal movement to the legend of Figure three. This analysis would seem more natural to include either in the main text or in a dedicated statistical methods section</p><p>14) Provide more precise references to allow others to set up an ssHTS system; see for example the references for LEDs.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><p>Thank you for resubmitting your work entitled &quot;Random Access Parallel Microscopy&quot; for further consideration by <italic>eLife</italic>. Your revised article has been evaluated by Didier Stainier (Senior Editor) and a Reviewing Editor.</p><p>The manuscript has been improved but there are some remaining issues that need to be addressed before acceptance, as outlined below:</p><p>The authors stress that one of the principal interests of the system is the capacity for rapid and continuous imaging. They write, &quot;captures data 15 fps/well by measuring groups of eight wells in parallel&quot;. Then they write, &quot;As the system captures data from multiple wells in quick succession at a rate of 120 fps, the time needed to acquire 100 frames for each of the 76 wells for this assay is just over one minute&quot;. They need to be more explicit. When they are capturing data from 76 wells, then are they imaging each well at ca. 1.5 fps? As it stands, a reader might understand that they are switching between groups of eight wells, imaging one group at 15 fps/well, then moving to the next group after capturing 100 frames (6.7 seconds). If this were the case, then they would return to image the first group after a minute, so their system would not be continuous. This clearly requires clarification.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.56426.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>The reviewers all recognised the originality of your solution to perform high throughput imaging without moving parts. They do have some serious reservations, primarily regarding the evaluation of the quality and utility of the technique and in addition to the other points raised, consider it essential that you address the following:</p><p>– The standard topics for any new microscope paper: &quot;objective&quot; numerical aperture, image resolution, optical aberration, and camera sensor size, together with the specific aspects related to this technique, including dependence on homogeneous illumination, and sensitivity to maintenance of F2 distance.</p></disp-quote><p>We have addressed these issues by making several improvements to the paper. First, the system is now better described, with figure supplements (Figure 1—figure supplement 1) and tables (Materials and methods: Table 1) The resolution of the system has been quantified, both qualitatively (Figure 1—figure supplement 2) and quantitatively (Materials and methods: Table 2). In addition, we found that we can move the F2 distance dynamically by almost a millimeter by switching LED wavelength, which greatly simplifies focal plane issues (Figure 3C, Figure 3—figure supplement 1, and Video 2). The text also now includes details relating to specific issues raised by the reviewers (discussed below).</p><disp-quote content-type="editor-comment"><p>– A substantial expansion of the scope of the data presented, to provide readers with sufficient evidence with which to evaluate the quality of the technique, including proof of principal with a 96-well plate assay.</p></disp-quote><p>We have implemented a multiwell imaging system based on imaging most of the wells in a 96-well plate (See Video 1) and used this to perform a proof of principle study on C-elegans mutants with reduced activity (Figure 3A and B).</p><disp-quote content-type="editor-comment"><p>– A direct quantitative comparison with existing HTS imaging solutions.</p></disp-quote><p>As there are many HTS systems, we decided to address this issue by comparing the images collected using our platform to those collected using a standard on-axis optical path, which most microscopes and HTS systems use (Figure 1—figure supplement 2, and new section “Image quality quantification” in Materials and methods). We compare the performance both to a theoretical calculated maximum as well as to a setup that uses the same lenses but in a more standard configuration.</p><disp-quote content-type="editor-comment"><p>Reviewer #1:</p><p>Ashraf and colleagues describe an approach to perform high throughput screening imaging without moving parts. The setup is original and offers to experimentalists the flexibility to record quasi-simultaneously stacks of images of multiple samples at the full field of resolution of the camera. The optical aberration inherent to the use of a parabolic mirror are mostly overcome by collimating light from the objective lens. The images require a post-processing in two steps for taking into account the image stretching on the detector and the variation in magnification due to the variation of the distance between the mirror and the image. Two applications illustrate the potential of the solid-state HTS.</p><p>To my opinion, the following points need to be clarified:</p><p>– How homogeneous is the field of illumination with a single LED? Especially for a large field of illumination, a non-homogeneous illumination would compromise the quantifications.</p></disp-quote><p>As the reviewer correctly points out, the illumination field is not particularly homogeneous as we do not use any collimating optics above the LED. We find, however, that field flatness is not essential for the biological studies we typically conduct, as our examples involve looking at the differences between images. The intensity of a pixel in any one frame is effectively normalized in these measurements (either by background subtraction or rescaling based on the maximum and minimum values of that pixel’s intensity over the duration of the recording). This has been made clearer in the text: “The illumination of the sample by a spatially coherent source produces grey scale images, and in our studies, it is the change in this intensity that is of interest.”</p><p>We should note that if field flatness was indeed needed, collimating optics could be added over each LED but this would increase system cost.</p><disp-quote content-type="editor-comment"><p>– The accuracy of this ssHTS is related to the robustness at keeping the distance F2 constant between samples. In other words, how sensitive is the image acquisition to the potential variation in the F2 distance between samples as well as within a single large field of view?</p></disp-quote><p>Sensitivity to variations in the sample-objective separations are determined by the Rayleigh length of the objective lenses. As long as the samples remain within the Rayleigh length (approx. 1 mm for a 100 mm focal length lens), a sharp image of the sample will be formed. In addition, we observe a strong dependence of focal plane location on LED wavelength which we confirmed using Zemax optical simulations: red and blue LED illumination result in images from planes that are roughly 1mm apart. As alignment is maintained to &lt;2 mm by the Thorlabs cage system, we find that most of wells are sufficiently in focus to resolve samples. Figure 3C now has an example of an image that has samples (<italic>C. elegans</italic>) at slightly different planes and shows how this can be corrected by changing LED colour. Video 2 gives an example where LED colour is switched rapidly to obtain pairs of images, allowing selection of the best image for analysis. Figure 3—figure supplement 1 shows all wells from a single row of a 96 well plate, which can be used to assess sensitivity to small variations in F2 distance (i.e. by wells captured at a single LED colour).</p><disp-quote content-type="editor-comment"><p>– The magnification Mc must be explained.</p></disp-quote><p>We thank the reviewer for catching this. Mc is now defined on : “The combined magnification (<italic>M<sub>C</sub></italic>=<italic>M</italic>*<italic>S</italic>)”.</p><disp-quote content-type="editor-comment"><p>– Is the post-processing compensation applied only in the y-direction?</p><p>Assuming that such publication aims to disseminate the use of an ssHTS setup to a wide scientific community, I find the description of the setup as well as the applied image post-processing rather succinct, even with the 3D printing and source codes information.</p></disp-quote><p>We agree that our original submission was missing needed details. We’ve expanded the paper, including images of the setup (Figure 1—figure supplement 1), and a table in the Materials and methods section that give additional details (Table 1, Materials and methods). Post-processing compensation is applied in both x and y directions, as described in the caption of Figure 1. The small amount of residual geometric correction has been applied in both axes. The distortion correction algorithm is a generic algorithm that does not take into account the specific geometry of the mirror.</p><disp-quote content-type="editor-comment"><p>Reviewer #2:</p><p>Astronomers have spent centuries learning how to image the night sky with limited sensor hardware. Ashraf et al. present an ingenious adaptation of a technology developed for telescopes-parabolic reflectors-for imaging biological samples. In principle, the approach seems like it could be incredibly useful across a wide range of applications where multiple samples must be imaged in tandem. By placing multiple samples under a single parabolic reflector, multiplexing of samples and imaging hardware can be accomplished without sample-handling robots or moving cameras. The authors highlight two applications: cardiac cells in culture and free-moving nematodes.</p><p>The authors explain the theory behind their technique in a clear and convincing way. However, the biggest challenge in most imaging projects is making the theory work in practice. In its current form, the manuscript falls far short of demonstrating the practical usefulness of parabolic mirrors for imaging biological samples. The authors include only a small amount of image data-for the nematode work, this consists of eight images collected from two plate regions. Data of this scope cannot provide readers or reviewers with sufficient evidence with which to evaluate the quality of the technique.</p><p>1) The images shown-are they typical or are they the best possible images that can be collected from the device? The authors do not provide any quantitative evaluation of the quality of their images, in absolute terms or relative to existing methods, with which to understand the practical performance of parabolic mirrors. The authors should estimate the spatial resolution and dynamic range that can be obtained in practice with the devices, and evaluate how such image quality metrics vary across the entire field of view. Does performance degrade towards the edge of the mirror? Does performance degrade over time, as devices become de-calibrated with use?</p></disp-quote><p>We’ve added several components to the paper that help address the reviewer’s concerns. First, videos with additional examples are now included (Video 1), as well as images of resolution charts (Figure 1—figure supplement 2). Figure 3—figure supplement 1 has images from 8 adjacent wells (a single row) in a 96 well plate, which should give the reader a sense of how images quality and focus can vary. As the reviewer notes, image quality does degrade toward the edge of the mirror – this has now been quantified in Materials and methods: Table 2, which gives information on contrast ratio and resolution as a function distance from the optical axis. As with any system, it can be decalibrated with use, but given that we are working at relatively low magnification we have not found this to be a significant concern.</p><disp-quote content-type="editor-comment"><p>2) The manuscript is additionally weakened by the absence of a non-trivial measurement made with the device. Pilot experiments are included, demonstrating that images can be collected. However, no evidence is provided to show that these images can be used to compare samples and draw biological conclusions from them. A more convincing proof-of-principle would involve the measurement of some non-trivial biological difference between samples measured with the device, either confirming previous work or discovering something new.</p></disp-quote><p>We agree that our original submission was missing a substantive example. We constructed a new imaging system to address this concern and now have a convincing proof-of-principle study (see Figure 3).</p><disp-quote content-type="editor-comment"><p>3) The authors highlight the comparative simplicity of their method: it eliminates the need for motorized samples or cameras. However, this simplicity must come at some: for example a substantially increased use of space or perhaps an increase in delicate calibration required, or equipment price. If a 0.25 meter mirror is required to measure four <italic>C. elegans</italic> plates, how large a mirror would be required to measure 16 plates-the number that can typically be measured using a flatbed scanner? The authors could also expand greatly on other practical issues: for example, is a dedicated imaging table required to align mirrors and samples? Readers would benefit from a clearer evaluation of the practical trade-offs in deploying parabolic mirrors in a laboratory setting relative to other imaging approaches.</p></disp-quote><p>We thank the reviewer for this suggestion. A new section (Materials and methods: Practical considerations) has been added that addresses their concerns, and details regarding vibration isolation was added to Table 1 (we used small Sorbothane pads to reduce vibrations when needed, which is inexpensive). As we discuss in the “Practical considerations” section, the systems we designed have a small footprint and are low cost. Rather than scale the mirror, the number of systems could be scaled as total cost primarily depends on the number of imaging objectives used. Multiple systems may well be preferable as this would allow slower cameras to be used, and optical distortions introduced by large axial distances would be less evident.</p><disp-quote content-type="editor-comment"><p>Reviewer #3:</p><p>The authors present a cool new idea: using a large parabolic reflector in combination with a macroscopic lens array and rapidly modulated LED array to enable fast image multiplexing between spatially separated samples. I believe that there may be interesting applications that would benefit from this capability, although the authors have not clearly demonstrated one. The paper is short, and light on discussion, details, and data.</p><p>1) The manuscript does not discuss several standard, key topics for any new microscope paper: &quot;objective&quot; numerical aperture, image resolution, optical aberration (other than distortion, which is discussed), and camera sensor size.</p></disp-quote><p>We thank the reviewer for pointing out this omission on our part. We’ve included the details in Table 1.</p><disp-quote content-type="editor-comment"><p>2) Why was an array of low-performance singlet lenses used? With that selection, the image quality cannot be good. Can the system not be paired with an array of objectives or higher performance multielement lenses?</p></disp-quote><p>It is certainly true that the architecture could incorporate higher specification imaging objectives. However, for the 96 well systems and higher there are no commercial multi-element lenses available. Also, in terms of practicality, one of our aims was to keep costs down to a level where these systems would see widespread use and be easy to duplicate to increase total capacity. We now address this in section “Practical considerations”</p><disp-quote content-type="editor-comment"><p>3) Fluorescence imaging is not discussed or demonstrated but would obviously increase the impact of the microscope. At least some discussion would be helpful.</p></disp-quote><p>We agree that fluorescence would increase the impact of the microscope. However, this system is designed to be used for brightfield imaging applications. This allows us to achieve high frame rates without compromising signal to noise. Fluorescence imaging may be possible, but the low NA of the imaging objectives would severely limit the SNR and /or the rate of image capture. This issue is now also addressed in “Practical considerations”.</p><disp-quote content-type="editor-comment"><p>4) Actual HTS applications are almost always implemented in microtiter plates (e.g. a 96-well plate) to reduce reagent costs and enable automated pipetting, etc. I do not believe anyone would implement HTS in thousands of petri dishes. The paper would be strengthened substantially by a demonstration of simultaneous recording from all (or a large subset) of the wells in a 96-well plate. It's not clear whether this is possible due to the blind spot in the center of the parabolic mirror's field of view that is blocked by the camera.</p></disp-quote><p>We thank the reviewer for this suggestion. We now have a study that meets this criterion (Configuration 2 in Table 1, and data in Figure 3 and its corresponding video).</p><disp-quote content-type="editor-comment"><p>5) One of the primary motivations for this approach is given in the first paragraph as: &quot;wide-field imaging systems [which capture multiple samples in one frame] have poor light collection efficiency and resolution compared to systems that image a single sample at a given time point.&quot; With a f = 100 mm singlet lens, the light collection efficiency of the demonstrated microscope is also low (estimated NA = 0.12) and the resolution is unimpressive with the high-aberration lens and 1x magnification. They demonstrated only trans-illumination applications (e.g. phase contrast), where light collection efficiency is not important. I believe a fancy photography lens mounted directly on a many-megapixel camera set to image all or part of a microtiter plate could likely outperform their system in throughput and simplicity, at least for the demonstrated applications of cardiomyocytes and <italic>C. elegans</italic>.</p></disp-quote><p>We agree that the alternative suggested by the reviewer may be viable. However, while a single-lens system could achieve similar light collection efficiency, the system would necessarily be very large (and considerably more expensive, as telecentric optics may be needed to image off-axis wells). The increased size would prohibit the use of incubators for exploring a range of sample environments. Finally, the frame rate of the machine vision camera is much higher than that of a high-resolution camera: the ssHTS system allows for fast random access capture for any sample under the parabolic mirror, allowing comparison between samples at high frame rates, which something that a conventional setup can’t do.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>Overall, the reviewers recognised that this setup could be useful for readers looking for an inexpensive bright-field imaging setup for multi-well imaging without fluorescence. They agree that you have provided substantial additional data and analysis that support your claim that parabolic reflectors can be useful for studying many samples in a parallel. The new images and videos of a 96-well plate were judged compelling. In particular, the prospect of focusing samples simply by adjusting the wavelength of illumination was thought an important step towards the goal of designing a &quot;solid-state&quot; imaging apparatus with no moving parts.</p><p>Nevertheless, although the reviewers were satisfied that you had addressed most or all of the material points, they had considerable reservations about the way in which these improvements were presented and could not support publication of the manuscript in its present form. Indeed, there are numerous lacunae and parts where the writing is not at all clear and leads to confusion about how the system functions and what its limits are. Please find below a summary of their most important comments and a series of points made by individual reviewers, all of which would need to be addressed in a revised manuscript. If this would require a further round of experimental work, then I am afraid that we will not be able to consider your work for publication.</p><p>The description of the 96-well plate data was considered both terse and vague, leaving unclear several aspects of experimental design and interpretation.</p><p>– If no samples were loaded into columns 6 and 7 of the 96 well plate because of the use of 40 LED arrays, this should be stated explicitly.</p></disp-quote><p>We have added the following lines to the document:</p><p>In Materials and methods, Sample Preparation and Imaging:</p><p>“50 µL of this worm suspension was loaded into a 96-well, flat-bottom assay plate (Corning, Costar), excluding half of row 5 and all wells in rows 6 and 7 as shown in Figure 3A, as these wells were either obscured by sensor hardware or not illuminated by the two 40-element LED arrays (see Configuration 2 in Table 1).”</p><p>And, in Materials and methods: Optical Setup, Table 1:</p><p>“Camera placement obscures 12 wells in the 96 well plate imaged in configuration 2 (see Figure 3A), and the use of two commercial 40 element LED arrays precludes imaging all wells in a 96 well plate as the LEDs are permanently mounted on a board that is too large to be tiled without leaving gaps.”</p><disp-quote content-type="editor-comment"><p>– What was the exact reason for not imaging in column 4 of row E or row 1F.</p><p>These discrepancies between the theoretically predicted function of the device and its practical performance must be clarified.</p><p>If these issues do not reflect technical limitation of the device, you would need to demonstrate that these columns/wells can be imaged just like the others (i.e. this is a criterion for rejection).</p></disp-quote><p>In order to demonstrate to the reviewer that all wells that aren’t obscured by the camera are imageable, we present the above composite calibration image (of an overhead sheet printed with random characters with a 1.1 mm height font) which was generated by moving a single 40 element LED array and lenses to cover all locations corresponding to wells in a 96 well plate.</p><p>The system described in the paper uses two commercial 40 element LED arrays. The arrays cannot be placed side by side without gaps (see <xref ref-type="fig" rid="respfig1">Author response image 1B</xref> – parts the board reserved for input pads are highlighted in yellow), so the use of these particular arrays precludes complete coverage of a 96 well plate without moving the array or the 96 well plate. This would not be an issue with a different array (e.g. a custom-built LED array or an LED array from another manufacturer), and we consider this a practical instead of a technical limitation. These LED arrays were chosen as they were easily sourced during the university shutdown from a Canadian supplier.</p><p>In the paper, wells E4 and F1 were obscured by a cable running from the camera. This wasn’t noticed until after the first images for the experiment shown in Figure 3 were collected, and was left in place in order to avoid moving the sample and reorienting the camera (which would have involved partial disassembly of the microscope). The orientation of the camera and cable was such so that this was not an issue when collecting the calibration image. The orientation of the cable for the experiment in Figure 3 and orientation of the cable the calibration measurement (<xref ref-type="fig" rid="respfig1">Author response image 1A</xref>) are shown in <xref ref-type="fig" rid="respfig1">Author response image 1C</xref>. As you can see, the black cable (indicated by the large red arrow) is angled so that it passes between the sample and the lenses in the left panel. As a result, the cable partially obscured wells E4 and F1 (indicated by small red arrows) in the experiments.</p><fig id="respfig1"><label>Author response image 1.</label><caption><title>(<bold>A</bold>) composite image showing images from all wells aside from those under the camera housing, with wells obscured by cabling in Figure 3 highlighted in yellow.</title><p>(<bold>B</bold>) Image of one of the LED arrays with region reserved for electrical connections highlighted in yellow; the size of these regions prevents tiling the array and complete coverage of the 96 well plate (<bold>C</bold>) images of the system showing the location of the cable (red arrows) that obscured the wells in Figure 3, and its orientation for the image collected in the top panel of this figure (panel A).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56426-resp-fig1-v3.tif"/></fig><p>We have amended the text to clarify the missing wells in Figure 3 with the following three changes:</p><p>i) In the previous submission, we originally indicated that the wells were obscured in the legend of Figure 3 with the statement: “Wells obscured by hardware are denoted by an “X” symbol.”</p><p>We have changed this to read: “Wells obscured by hardware are denoted by an “X” symbol (see Materials and methods: Table 1)”</p><p>ii) And in Materials and methods: Table 1, we have added the following clarification:</p><p><bold>“</bold>In addition, some wells (marked with an “X” in Figure 3a) were inadvertently obscured by hardware between the sample and objective lenses for the motion quantification experiment in Figure 3, however the number of imaged wells was considered to be sufficient to demonstrate the utility of the RAP system.”</p><p>iii) As the calibration image is useful in the context of building the same RAP system that was used to capture data in Figure 3, we include this image as part of a zip file which also includes images of the LED array and 3D printed parts with associated STL files. We also note that since author response images and text are available to <italic>eLife</italic> readers, the information about wells E4 and F1 will be presented in the context of the reviewer’s question and remain accessible.</p><disp-quote content-type="editor-comment"><p>The details about acquisition are so poorly described that one reviewer wrote, &quot;why not leverage those capabilities to scan 33 wells in parallel at 15 Hz rather than one well at a time at 15 Hz?&quot;. This illustrates how you have failed to convey clearly that the system captures data from multiple wells in parallel at 120-500 fps. One video does show how 120 fps can be divided up across 80 wells, and it is illustrated in Figure 1, but these details need to be explicitly stated in the text. In Figure 2, a faster (500 fps) camera of lower resolution is used. As well as making all acquisition details clearer, you will need to provide an explicit discussion of camera choice, and any trade-off between image resolution and speed. Additionally, you need to address another technical limitation and trade-off, namely rates of acquisition and data transfer so that the possibility (and cost) of implementation in a HTS setting (see below) is clear.</p></disp-quote><p>We regret the confusion caused by our previous submission, and fully agree that the wording was not clear. We have amended the text in several places to make these details clear.</p><p>In the main text, the description of data acquisition was changed from:</p><p>“Motion was quantified by measuring the fraction of pixels per frame that display a change in intensity of over 25% for 100 sequential frames captured at 15 fps for each well (Figure 3A and B; Video 1).” to “… motion was quantified by measuring the fraction of pixels per frame that display a change in intensity of over 25% for 100 sequential frames captured at 15 fps/well by measuring groups of eight wells in parallel (see Figure 3A and B; Video 1, and Materials and methods: Image processing).”</p><p>The last sentence of the same paragraph has been changed from:</p><p>“As the system captures data from multiple wells in parallel, the time needed to measure activity in 76 wells for this assay is just over one minute.” to “As the system captures data from multiple wells in quick succession at a rate of 120 fps, the time needed to acquire 100 frames for each of the 76 wells for this assay is just over one minute.”</p><p>The relevant sentence in the legend in Figure 3 was changed from:</p><p>“Motion is estimated by summing absolute differences in pixel intensities in sequential frames imaged at 15 Hz.” to “wells in each row are imaged in parallel (8 wells at 15 fps per well), and net motion is estimated in each well by summing absolute differences in pixel intensities in sequential frames (see Materials and methods: Image analysis).”</p><p>We have also gone into greater details on camera choice and limitations associated with data throughput in the Materials and methods section. The following section was added:</p><p>“The camera used in Figure 2 was chosen for its high frame rate as we were interested in imaging cardiac activity, which in our experience requires 40fps acquisition speeds. […] A faster hard drive (e.g. an SSD) or RAID array would significantly increase throughput.”</p><disp-quote content-type="editor-comment"><p>The center of the optical system is intrinsically blind since space is required to position the detector. This point is implicit and must be documented as a function of the magnification.</p></disp-quote><p>The following sentence was added to Table 1: “Camera placement obscures 12 wells in the 96 well plate imaged in configuration 2 (see Figure 3A).”</p><p>However, we note the number of obscured wells depends only on the physical size of the camera and is independent of optical magnification.</p><disp-quote content-type="editor-comment"><p>The microscope resolution in the 15 – 20 µm range is poor relative to the sub-micron resolution of a traditional microscope. It is probably not good enough, for example, to tell individual mammalian cells apart in a confluent monolayer. This will limit the range of potential applications. Thus the spatial resolution needs to be stated in the Abstract or Introduction, not buried deep in the Materials and methods.</p></disp-quote><p>We have added the following line to the Introduction:</p><p>“We demonstrate the system in two low-magnification, low resolution settings using single element lenses and other easily sourced components. “</p><p>However, the use of low magnification, low NA lenses is not a defining limitation of our method. We have added the following paragraph to the Materials and methods section to clarify this point and make the reader aware of potential issues with moving to higher magnification:</p><p>“The use of low magnification optics in our current implementation is not a defining property of RAP, as higher NA, high magnification optics could be used. […] As is the case with conventional microscope designs, a high magnification RAP system would likely require a mechanism for finely adjusting objective heights to keep each sample in focus, as the depth of field of the objective lenses would be reduced.”</p><disp-quote content-type="editor-comment"><p>Further, you will need to include a detailed comparison with a standard commercial widefield microscope with a scanning stage (resolution, imaging modalities, scan time, defocusing over time, cost, integration into robotic workflows).</p></disp-quote><p>We have added the following text and table to the Materials and methods section, and included three additional references to support the comparison:</p><p>“While the resolution of a RAP system is similar to conventional microscopes, RAP systems differ from conventional microscopes in several respects. Table 2 summarizes some key differences between a conventional automated widefield imaging microscope and the two RAP systems implemented in this publication. We note that higher performance RAP systems (e.g. faster disks, a faster camera, corrected optics) would display improved performance.”</p><p>In addition, we have added the following to the discussion to ensure that readers are aware of the differences between our system and a conventional automated microscope:</p><p>“Automated microscopes excel at applications where data can be acquired from samples sequentially as a single high numerical aperture (NA) objective is used. […] Here, the speed increase afforded by RAP must be weighed against the many benefits of using a mature technology such as the automated widefield microscope (see Table 2 for a comparison between these systems).”</p><disp-quote content-type="editor-comment"><p>If you wish to claim HTS capacity, the comparison should also include a dedicated commercial HCS/HTS system, and the many other features needed for HTS (e.g. see https://www.ncbi.nlm.nih.gov/books/NBK558077/).</p><p>Alternatively, in the absence of easy incorporation of the system in an automated setting, at a time when HTS can mean &gt;50,000 tests/day, &quot;High Throughput&quot; should be removed from the title (&quot;multi-sample&quot; or &quot;multi-well&quot; would be better), and any suggestion in the text that your system is HTS-compatible seriously toned down.</p></disp-quote><p>We have removed high throughput from the title and removed the majority of references to high-throughput in the paper. For example, the lead sentence in the Introduction now reads:</p><p>“Conventional multi-sample imaging modalities either require movement of the sample to the focal plane of the imaging system <sup>1–4</sup>, movement of the imaging system itself <sup>5,6</sup>, or use a widefield approach to capture several samples in one frame <sup>7,8</sup>.”</p><p>The term “high-throughput” is still occasionally used, but its context is limited to imaging multiple samples rapidly, or when discussing other platforms. Table 2 also states that the RAP system hasn’t been validated as part of a conventional high-throughput workflow.</p><disp-quote content-type="editor-comment"><p>Equally, given the very different uses in optics or electronics of the term &quot;solid-state&quot;, you should avoid it in the title, replacing it, for example by, &quot;with no moving parts&quot;.</p></disp-quote><p>We have removed the term solid-state from the title as requested.</p><disp-quote content-type="editor-comment"><p>There was also a general consensus that your design is not a Newtonian telescope, which has two mirrors instead of a single mirror as in this design. The reviewers recommend changing &quot;novel Newtonian telescope design&quot; to &quot;large on-axis parabolic mirror design&quot;, &quot;parabolic reflector&quot;, or something similar that is clearer and more accurate. Including a phrase like &quot;inspired by a Newtonian telescope&quot; would be acceptable.</p></disp-quote><p>We now use the phrase “inspired by Newtonian telescope” instead of “modified Newtonian telescope” as requested.</p><disp-quote content-type="editor-comment"><p>Further points made by individual reviewers:</p><p>1) The authors compare wild-type <italic>C. elegans</italic> to nuo-6 mutants. The authors are vague and qualitative in their descriptions of movement. Nuo-6 mutants are predicted to &quot;move less frequently&quot; than wildtype. This is confusing, as <italic>C. elegans</italic> generally exhibit some degree of continuous movement as long as they remain alive, involving body postural changes, head movements, or pharyngeal pumping. Are the authors referring to the frequency of a particular type of movement? For the purposes of this paper, the authors probably do not need to alter their imaging pipeline, but they should be substantially more specific about which behavior their method is measuring.</p></disp-quote><p>We regret the confusion and have amended the text as follows:</p><p>“We validate the potential for RAP to be used in a higher-throughput imaging application by measuring motion in <italic>C. elegans</italic> mitochondrial mutant nuo-6(qm200)18, which have a slower swimming rate (frequency of thrashing) than that of the wild type <italic>C. elegans</italic>. […] As the system captures data from multiple wells in quick succession at a rate of 120 fps, the time needed to acquire 100 frames for each of the 76 wells for this assay is just over one minute. “</p><p>The motion estimate we use is not based on the conventional method used to quantify thrashing frequency in <italic>C. elegans</italic>, but rather quantifies pixel intensity changes between frames.</p><p>We stress that our intention was not to measure thrashing frequency differences in <italic>C. elegans</italic> wild type and mutant strains, as this is already known. Rather, we leverage the fact that the documented difference in thrashing frequency will generate a measurable difference when quantifying pixel intensity changes in wells containing these two strains. Our aim was (only) to use these strains to demonstrate that the system can quantify differences in activity multiple, simultaneously imaged wells.</p><p>We have added the following statement (in Materials and methods: Image processing) in order to further clarify our intent:</p><p>“We note that while this algorithm yields results which are consistent with published manual measurements of thrashing frequency (see Figure 2j in Yang and Hekimi<sup>18</sup>), there is no direct correspondence between this metric and specific behaviours (head movement, posture changes etc.). However, the documented difference in the activity of the two strains we use would predict the difference in the metric that we observe and can be used as a validation of the imaging method to track movement over time.”</p><disp-quote content-type="editor-comment"><p>2) Many nematode behaviors change in response to stimulation with light, physical stimulus, or immersion in liquid. Other behaviors are suppressed by long periods spent immersed in un-mixed liquids. It remains difficult to interpret the authors' results without additional information describing how the light and culturing conditions they are use influences nematode behavior and how this influences their results. In particular, the behavioral difference observed between day 1, 2 and 3 could be expected as a technical artifact (i.e., in the absence of any underlying aging process) if nematodes remained in the same wells for multiple days.</p><p>3) The authors observe a difference in activity between nuo-6 and wild-type animals, and also between young animals and old animals. However, discussion of this is surprisingly qualitative given the quantitative thinking found elsewhere in the paper. Are the observed differences in movement approximately the same magnitude as what would be expected given previous results? Why is a significant difference between the two strains observed only on day one and three, but not day two?</p></disp-quote><p>We agree that the inclusion of the two extra imaging days is a potential source of confusion as animals are impacted by multiple inputs, and so we have opted to remove the data for days 2 and 3. The remaining data (on day 1), along with the included video examples are sufficient to demonstrate that we can use the system to collect data from multiple wells, which is the focus of the submitted paper.</p><disp-quote content-type="editor-comment"><p>4) The Figure 1 caption uses fM and fL while Figure 1 uses F1 and F2. Please make consistent.</p></disp-quote><p>We thank the reviewer for pointing this out. We have edited the figure to be consistent.</p><disp-quote content-type="editor-comment"><p>5) Equation 2 is not fully displayed.</p></disp-quote><p>We thank the reviewer for pointing this out. It was cropped during the pdf conversion process, and we will ensure that it is displayed properly in the submitted version.</p><disp-quote content-type="editor-comment"><p>6) Introduction: Please give some concrete examples of experiments that require continuous long-term recording where low-resolution brightfield imaging would be the appropriate readout modality.</p></disp-quote><p>We have added the following text to the discussion, as well as four references:</p><p>“RAP systems are better suited for dynamic experiments in relatively macroscopic samples where multiple continuous long-duration recordings are the primary requirement. For example, rhythms in cultured cardiac tissue evolve over hours<sup>28</sup> or even days<sup>29,30</sup>, but display fast transitions between states (e.g. initiation or termination of re-entry<sup>31</sup>), necessitating continuous measurement. In these experiments, moving between samples would result in missed data.”</p><disp-quote content-type="editor-comment"><p>7) Introduction: The phrase &quot;high resolution&quot; is misleading, as the 15-22 µm resolution of this microscope would be considered very low resolution by most microscopists. Please insert the actual resolution here.</p></disp-quote><p>We originally intended for high resolution to refer to pixel count not numerical aperture but agree that this is confusing. We have removed the term.</p><disp-quote content-type="editor-comment"><p>8) Results: I would not call this a high light collection efficiency design, as most standard microscopes have higher efficiency. Light collection efficiency is not very important here, so please change the language to be less contentious.</p></disp-quote><p>The language has been changed to: “The brightfield nature of the illumination used in this design allows images to be captured with sub millisecond exposure times. “</p><disp-quote content-type="editor-comment"><p>9) Results: Calling an LED source spatially coherent is really straining the definition. Please use different language.</p></disp-quote><p>While the reviewer is right to state that LEDs are not normally coherent sources, they can be coherent if the emitting area is small. The following images (<xref ref-type="fig" rid="respfig2">Author response image 2</xref>), taken at the same magnification, demonstrate that the emitting areas of these LEDs is approximately 200 x 200 um. This provides a spatial coherence value &gt; 0.5 compared to a spatial coherence value of 0.88 for a DPSS laser (e.g. see DOI:10.1038/s41598-017-06215-x). It is therefore safe to assume that these emitters have a high degree of spatial coherence.</p><fig id="respfig2"><label>Author response image 2.</label><caption><title>LED emitting area is approximately 200x200 microns.</title></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-56426-resp-fig2-v3.tif"/></fig><p>We have added the reference to the paper. We have also changed the text from</p><p>“coherent” to “partially coherent” to avoid confusion:</p><p>“The illumination of the sample by a spatially partially coherent source<sup>12</sup> produces grey scale images, and in our studies, it is the change in this intensity that is of interest. “</p><disp-quote content-type="editor-comment"><p>10) Materials and methods: Something is wrong or confusing about the depth of focus discussion. Please cite a source for the equations and clearly define all variables. If u = f as you indicate in the text, then DOF=2c≠0.9 mm, which was stated in the text. The f-number does not appear in the equation you have, but the discussion seems to indicate that it is important (as would be expected).</p></disp-quote><p>We thank the reviewer for spotting this error. There was a typo in the equation, and the f-number is now included.</p><disp-quote content-type="editor-comment"><p>11) Figure 2 legend: should be &quot;(blue trace in B)&quot;</p></disp-quote><p>We thank the reviewer for spotting this typo. The legend has been changed.</p><disp-quote content-type="editor-comment"><p>12) Figure 3 legend: duplicated text &quot;C) Focal plane….&quot;</p></disp-quote><p>We thank the reviewer for spotting the duplicate text- it has been removed.</p><disp-quote content-type="editor-comment"><p>13) The authors limit their discussion of statistical analysis of animal movement to the legend of Figure three. This analysis would seem more natural to include either in the main text or in a dedicated statistical methods section</p></disp-quote><p>The following line is now in the main text:</p><p>“Instead of measuring thrashing frequency directly, motion was quantified by measuring the fraction of pixels per frame that display a change in intensity of over 25% for 100 sequential frames captured at 15 fps/well by measuring groups of eight wells in parallel (see Figure 3A and B; Video 1, and Materials and methods: Image processing).”</p><p>In addition, there is now new section (Image Processing) in Materials and methods with added details:</p><p>“Image processing: We find that image brightness drops with increased objective lateral distance and that images are subject to aberrations at the edges. […] The values are plotted as a percentage.”</p><disp-quote content-type="editor-comment"><p>14) Provide more precise references to allow others to set up an ssHTS system; see for example the references for LEDs.</p></disp-quote><p>We thank the reviewer for this suggestion. The LED array used (manufacturer and part name) is now in Table 1. In addition, as mentioned earlier in this response, we now include a zip file with additional details (including part numbers and stl files) targeted to readers interested in building their own device.</p><p>[Editors' note: further revisions were suggested prior to acceptance, as described below.]</p><disp-quote content-type="editor-comment"><p>The manuscript has been improved but there are some remaining issues that need to be addressed before acceptance, as outlined below:</p><p>The authors stress that one of the principal interests of the system is the capacity for rapid and continuous imaging. They write, &quot;captures data 15 fps/well by measuring groups of eight wells in parallel&quot;. Then they write, &quot;As the system captures data from multiple wells in quick succession at a rate of 120 fps, the time needed to acquire 100 frames for each of the 76 wells for this assay is just over one minute&quot;. They need to be more explicit. When they are capturing data from 76 wells, then are they imaging each well at ca. 1.5 fps? As it stands, a reader might understand that they are switching between groups of eight wells, imaging one group at 15 fps/well, then moving to the next group after capturing 100 frames (6.7 seconds). If this were the case, then they would return to image the first group after a minute, so their system would not be continuous. This clearly requires clarification.</p></disp-quote><p>We apologize for the confusion. As shown in Video 1, we can indeed image all wells in parallel continuously at 1.5 fps/well. However, for Figure 3, in order to capture 15 fps per well (which was needed to visualize <italic>C. elegans</italic> thrashing behaviour) we capture a subset of wells in parallel and switch to different subsets (every 6.7 seconds) until all the wells are imaged. The entire data set is 100 sequential frames for each well, so we do not return to the first group for this particular assay. We have changed the text in that paragraph as follows:</p><p>In this experiment, the frame rate of the camera is limited to 120 fps (see Materials and methods: Practical considerations and Video 1), allowing us to image 8 wells in parallel at 15 fps/well. 80 wells (76 active and 4 blank wells – see Figure 3A) are imaged by measuring 100 frames from each well in a row of 8 wells in parallel (800 frames/row) before moving to the next row, until all 80 wells are imaged (a total of 8000 frames). The system quantified decreased activity in <italic>nuo-6(qm200)</italic> which is consistent with published results18 (Figure 3B). The time needed to perform this assay is just over one minute (8000 frames/120 fps = 67 seconds).</p><p>We also note that relationship between framerate, data throughput and the number of samples that can be imaged continuously in parallel is discussed in more detail in “Materials and methods: Practical considerations.”</p></body></sub-article></article>