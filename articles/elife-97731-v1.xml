<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">97731</article-id><article-id pub-id-type="doi">10.7554/eLife.97731</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.97731.4</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Mapping patterns of thought onto brain activity during movie-watching</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Wallace</surname><given-names>Raven Star</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0003-0414-0254</contrib-id><email>raven.wallace@queensu.ca</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Mckeown</surname><given-names>Bronte</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Goodall-Halliwell</surname><given-names>Ian</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Chitiz</surname><given-names>Louis</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Forest</surname><given-names>Philippe</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Karapanagiotidis</surname><given-names>Theodoros</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Mulholland</surname><given-names>Bridget</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Turnbull</surname><given-names>Adam</given-names></name><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Vanderwal</surname><given-names>Tamara</given-names></name><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Hardikar</surname><given-names>Samyogita</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4380-5055</contrib-id><xref ref-type="aff" rid="aff6">6</xref><xref ref-type="aff" rid="aff7">7</xref><xref ref-type="fn" rid="con10"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Gonzalez Alam</surname><given-names>Tirso RJ</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4510-2441</contrib-id><xref ref-type="aff" rid="aff8">8</xref><xref ref-type="fn" rid="con11"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Bernhardt</surname><given-names>Boris C</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9256-6041</contrib-id><xref ref-type="aff" rid="aff9">9</xref><xref ref-type="fn" rid="con12"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Hao-Ting</given-names></name><xref ref-type="aff" rid="aff10">10</xref><xref ref-type="fn" rid="con13"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Strawson</surname><given-names>Will</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con14"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Milham</surname><given-names>Michael</given-names></name><xref ref-type="aff" rid="aff11">11</xref><xref ref-type="fn" rid="con15"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Xu</surname><given-names>Ting</given-names></name><xref ref-type="aff" rid="aff11">11</xref><xref ref-type="fn" rid="con16"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Margulies</surname><given-names>Daniel S</given-names></name><xref ref-type="aff" rid="aff12">12</xref><xref ref-type="fn" rid="con17"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Poerio</surname><given-names>Giulia L</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con18"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Jefferies</surname><given-names>Elizabeth</given-names></name><xref ref-type="aff" rid="aff13">13</xref><xref ref-type="fn" rid="con19"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Skipper</surname><given-names>Jeremy I</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5503-764X</contrib-id><xref ref-type="aff" rid="aff14">14</xref><xref ref-type="fn" rid="con20"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Wammes</surname><given-names>Jeffrey D</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8923-5441</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con21"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Leech</surname><given-names>Robert</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5801-6318</contrib-id><xref ref-type="aff" rid="aff15">15</xref><xref ref-type="fn" rid="con22"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Smallwood</surname><given-names>Jonathan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-7298-2459</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con23"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02y72wh86</institution-id><institution>Department of Psychology, Queens University</institution></institution-wrap><addr-line><named-content content-type="city">Kingston</named-content></addr-line><country>Canada</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0220mzb33</institution-id><institution>Institute of Psychiatry, Psychology &amp; Neuroscience, King’s College London</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff3"><label>3</label><institution>School of Psychology, University of Sussex</institution><addr-line><named-content content-type="city">Nantes</named-content></addr-line><country>France</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00f54p054</institution-id><institution>Department of Psychology, Stanford University</institution></institution-wrap><addr-line><named-content content-type="city">Stanford</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03rmrcq20</institution-id><institution>Faculty of Medicine, University of British Columbia</institution></institution-wrap><addr-line><named-content content-type="city">British Columbia</named-content></addr-line><country>Canada</country></aff><aff id="aff6"><label>6</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0387jng26</institution-id><institution>Department of Neurology, Max Planck Institute for Human Cognitive and Brain Sciences</institution></institution-wrap><addr-line><named-content content-type="city">Leipzig</named-content></addr-line><country>Germany</country></aff><aff id="aff7"><label>7</label><institution>Max Planck School of Cognition</institution><addr-line><named-content content-type="city">Leipzig</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff8"><label>8</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/006jb1a24</institution-id><institution>School of Psychology and Sport Science, Bangor University</institution></institution-wrap><addr-line><named-content content-type="city">Gwynedd</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff9"><label>9</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05ghs6f64</institution-id><institution>Montreal Neurological Institute-Hospital, McGill University</institution></institution-wrap><addr-line><named-content content-type="city">Montreal</named-content></addr-line><country>Canada</country></aff><aff id="aff10"><label>10</label><institution>Centre de Recherche de l'Institut Universitaire de Geriatrie de Montreal</institution><addr-line><named-content content-type="city">Quebec</named-content></addr-line><country>Canada</country></aff><aff id="aff11"><label>11</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01bfgxw09</institution-id><institution>Child Mind Institute</institution></institution-wrap><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff><aff id="aff12"><label>12</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02fgakj19</institution-id><institution>Integrative Neuroscience and Cognition Center, University of Paris</institution></institution-wrap><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff><aff id="aff13"><label>13</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/04m01e293</institution-id><institution>Department of Psychology, University of York</institution></institution-wrap><addr-line><named-content content-type="city">York</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff14"><label>14</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>Division of Psychology &amp; Language Sciences, University College London</institution></institution-wrap><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff><aff id="aff15"><label>15</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/030hj3061</institution-id><institution>Mathematical and Electrical Engineering Department, IMT Atlantique</institution></institution-wrap><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Obleser</surname><given-names>Jonas</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00t3r8h32</institution-id><institution>University of Lübeck</institution></institution-wrap><country>Germany</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Bi</surname><given-names>Yanchao</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/022k4wk35</institution-id><institution>Beijing Normal University</institution></institution-wrap><country>China</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>10</day><month>01</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP97731</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-04-15"><day>15</day><month>04</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-03-09"><day>09</day><month>03</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.01.31.578244"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-07-08"><day>08</day><month>07</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.97731.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-10-18"><day>18</day><month>10</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.97731.2"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-11-27"><day>27</day><month>11</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.97731.3"/></event></pub-history><permissions><copyright-statement>© 2024, Wallace et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Wallace et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-97731-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-97731-figures-v1.pdf"/><abstract><p>Movie-watching is a central aspect of our lives and an important paradigm for understanding the brain mechanisms behind cognition as it occurs in daily life. Contemporary views of ongoing thought argue that the ability to make sense of events in the ‘here and now’ depend on the neural processing of incoming sensory information by auditory and visual cortex, which are kept in check by systems in association cortex. However, we currently lack an understanding of how patterns of ongoing thoughts map onto the different brain systems when we watch a film, partly because methods of sampling experience disrupt the dynamics of brain activity and the experience of movie-watching. Our study established a novel method for mapping thought patterns onto the brain activity that occurs at different moments of a film, which does not disrupt the time course of brain activity or the movie-watching experience. We found moments when experience sampling highlighted engagement with multi-sensory features of the film or highlighted thoughts with episodic features, regions of sensory cortex were more active and subsequent memory for events in the movie was better—on the other hand, periods of intrusive distraction emerged when activity in regions of association cortex within the frontoparietal system was reduced. These results highlight the critical role sensory systems play in the multi-modal experience of movie-watching and provide evidence for the role of association cortex in reducing distraction when we watch films.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>experience sampling</kwd><kwd>fMRI</kwd><kwd>naturalistic stimuli</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100000038</institution-id><institution>Natural Sciences and Engineering Research Council of Canada</institution></institution-wrap></funding-source><award-id>#RGPIN 2023-03496</award-id><principal-award-recipient><name><surname>Smallwood</surname><given-names>Jonathan</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Decoding brain activity using a novel paradigm unveils distinct neural signatures of subjective experiences during movie-watching.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>A core goal of cognitive neuroscience is to understand how sensory input describing events in the external world is translated into the patterns of thoughts we experience in our lives. Complex naturalistic states, such as movie-watching, are important paradigms to understand this process because they allow cognition and brain dynamics to be understood in a situation that maps directly onto experiences in the real world (<xref ref-type="bibr" rid="bib16">Finn and Bandettini, 2021</xref>; <xref ref-type="bibr" rid="bib25">Hasson et al., 2008b</xref>; <xref ref-type="bibr" rid="bib26">Haxby et al., 2020</xref>; <xref ref-type="bibr" rid="bib63">Vanderwal et al., 2019</xref>; <xref ref-type="bibr" rid="bib34">Matusz, 2019</xref>). Developments in cognitive neuroscience, leveraging state-of-the-art brain imaging techniques such as functional magnetic resonance imaging (fMRI), have established core features of neural patterns that emerge across participants during movie-watching tasks (<xref ref-type="bibr" rid="bib25">Hasson et al., 2008b</xref>), highlighting their similarity across individuals (<xref ref-type="bibr" rid="bib44">Nastase et al., 2019</xref>) and their links to memory for information in the films (<xref ref-type="bibr" rid="bib24">Hasson et al., 2008a</xref>). However, it is more difficult to reliably map ongoing thought patterns in this context since experiential sampling, the gold-standard for tracking thought patterns (<xref ref-type="bibr" rid="bib57">Smallwood et al., 2021b</xref>), has the potential to disrupt the natural unfolding of brain activity during movie-watching. The goal of our study was to minimize the disruptive impact of sampling ongoing experience by using a novel approach that allows us to explicitly link patterns of ongoing thought to brain activity during movie-watching at specific moments in a film.</p><p>Contemporary theories of ongoing thought suggest that a primary dimension to differentiate subjective experiences is the extent to which they depend on immediate sensory input (<xref ref-type="bibr" rid="bib57">Smallwood et al., 2021b</xref>; <xref ref-type="bibr" rid="bib52">Smallwood, 2013a</xref>). Cognitive states that are ‘coupled’ to events in the immediate environment are assumed to be linked to greater cortical processing of sensory input (<xref ref-type="bibr" rid="bib50">Smallwood et al., 2008a</xref>), better task performance, and memory for events in narrative comprehension tasks like reading (<xref ref-type="bibr" rid="bib53">Smallwood and Andrews-Hanna, 2013</xref>; <xref ref-type="bibr" rid="bib51">Smallwood et al., 2008b</xref>; <xref ref-type="bibr" rid="bib72">Zhang et al., 2022</xref>). In contrast, perceptually ‘decoupled’ states from sensory input, such as the experience of mind-wandering (<xref ref-type="bibr" rid="bib49">Smallwood and Schooler, 2006</xref>; <xref ref-type="bibr" rid="bib55">Smallwood and Schooler, 2015</xref>), provide an opportunity to pursue thoughts derived from memory (<xref ref-type="bibr" rid="bib72">Zhang et al., 2022</xref>; <xref ref-type="bibr" rid="bib40">Medea et al., 2018</xref>) but can be linked to compromised task performance and worse memory for events (<xref ref-type="bibr" rid="bib47">Schooler et al., 2011</xref>). Moreover, in situations where comprehension is important, states of distraction are hypothesized to be linked to poor executive control (<xref ref-type="bibr" rid="bib53">Smallwood and Andrews-Hanna, 2013</xref>; <xref ref-type="bibr" rid="bib55">Smallwood and Schooler, 2015</xref>; <xref ref-type="bibr" rid="bib38">McVay and Kane, 2010</xref>). Given that movie-watching provides a situation where dynamic changes in visual and auditory input drive a complex multi-sensory narrative, movie-watching provides an ecologically valid opportunity to understand how ongoing thought patterns map onto neural activation patterns in a naturalistic context. Recent work has shown that high-order regions, such as the ventromedial prefrontal cortex (vmPFC), are crucial in processing affective experiences during naturalistic stimuli, with distinct brain regions associated with different emotional expressions (<xref ref-type="bibr" rid="bib7">Chang et al., 2021</xref>). These findings suggest that the brain undergoes continuous reorganization in naturalistic paradigms like movie-watching, and is sensitive to changes in psychological states, in this case affect. Our study aims to complement these approaches through the development of a novel experience sampling approach with which to understand how the changing patterns of brain activity that emerge during movie-watching relate to the different types of psychological experience that emerge in these moments of a film. In our study, we acquired experiential data in one group of participants while watching a movie clip and used these data to understand brain activity recorded in a second set of participants who watched the same clip and for whom no experiential data was recorded. This approach is similar to what is known as ‘collaborative filtering’ (<xref ref-type="bibr" rid="bib7">Chang et al., 2021</xref>).</p><p>Consistent with the notion that movie-watching is a perceptually coupled state, recent work in cognitive neuroscience suggests an important role for primary systems, such as visual and auditory cortices (<xref ref-type="bibr" rid="bib15">Finn, 2021</xref>). However, studies also hypothesize a role for regions of association cortex linked to higher order thought, such as the default mode network (DMN) or the frontoparietal network (FPN; <xref ref-type="bibr" rid="bib25">Hasson et al., 2008b</xref>; <xref ref-type="bibr" rid="bib63">Vanderwal et al., 2019</xref>; <xref ref-type="bibr" rid="bib68">Yang et al., 2023</xref>). For example, the DMN is hypothesized to be important in social cognition, episodic memory, and conceptual knowledge — all of which are likely important for understanding the narrative of the film (for a review of the broad role the DMN plays in cognition, see <xref ref-type="bibr" rid="bib56">Smallwood et al., 2021a</xref>). However, the DMN has also been implicated in perceptually decoupled states, such as mind-wandering, that are likely antagonistic to movie-watching (<xref ref-type="bibr" rid="bib72">Zhang et al., 2022</xref>; <xref ref-type="bibr" rid="bib9">Christoff et al., 2009</xref>; <xref ref-type="bibr" rid="bib31">Konu et al., 2020</xref>; <xref ref-type="bibr" rid="bib71">Zhang et al., 2019</xref>).</p><p>Similarly, the FPN is important for multiple tasks, including those superficially different from movies, such as working memory maintenance, reflecting these networks' hypothesized role in goal maintenance (<xref ref-type="bibr" rid="bib13">D’Esposito and Postle, 2015</xref>; <xref ref-type="bibr" rid="bib8">Chenot et al., 2021</xref>). Contemporary views of ongoing thought argue that the FPN is likely important in suppressing distraction, including reductions in self-generated states like mind-wandering (<xref ref-type="bibr" rid="bib62">Vago and Zeidan, 2016</xref>). Although studies have highlighted the role of both primary sensory and higher-order systems in movie-watching (<xref ref-type="bibr" rid="bib63">Vanderwal et al., 2019</xref>; <xref ref-type="bibr" rid="bib46">Rohr et al., 2018</xref>), our lack of a formal understanding of the mapping between thought patterns when we watch films and associated patterns of brain activity means the specific role that different brain systems play in the experience of movie-watching remains largely a matter of speculation (<xref ref-type="bibr" rid="bib12">Demertzi et al., 2019</xref>).</p><p>Our experiment was designed to better understand how the changing patterns of brain activity at different moments during a film map onto the ongoing thoughts accompanying them. Previous work has shown that shared conscious experiences can be linked to common neural codes, suggesting that when individuals engage in movie-watching, their brains may exhibit synchronized activity (<xref ref-type="bibr" rid="bib7">Chang et al., 2021</xref>; <xref ref-type="bibr" rid="bib43">Naci et al., 2014</xref>). Given that brain activity is synchronized across individuals, it could also be the case that there are shared thought patterns that also emerge (i.e. shared patterns of experience) and if they do, these may also show links to common changes in brain activity. In our study, we used multi-dimensional experience sampling (mDES) to describe ongoing thought patterns during the movie-watching experience (<xref ref-type="bibr" rid="bib57">Smallwood et al., 2021b</xref>). mDES is an experience sampling method that identifies different features of thought by probing participants about multiple dimensions of their experiences. mDES can provide a description of a person’s thoughts, generating reliable thought patterns across laboratory cognitive tasks (<xref ref-type="bibr" rid="bib56">Smallwood et al., 2021a</xref>; <xref ref-type="bibr" rid="bib32">Konu et al., 2021</xref>; <xref ref-type="bibr" rid="bib61">Turnbull et al., 2021</xref>) and in daily life (<xref ref-type="bibr" rid="bib35">Mckeown et al., 2021</xref>; <xref ref-type="bibr" rid="bib41">Mulholland et al., 2023</xref>), and is sensitive to accompanying changes in brain activity when reports are gained during scanning (<xref ref-type="bibr" rid="bib31">Konu et al., 2020</xref>; <xref ref-type="bibr" rid="bib58">Turnbull et al., 2019a</xref>). Studies that use mDES to describe experience ask participants to provide experiential reports by answering a set of questions about different features of their thought on a continuous scale from 1 (Not at all) to 10 (Completely; <xref ref-type="bibr" rid="bib31">Konu et al., 2020</xref>; <xref ref-type="bibr" rid="bib32">Konu et al., 2021</xref>; <xref ref-type="bibr" rid="bib61">Turnbull et al., 2021</xref>; <xref ref-type="bibr" rid="bib35">Mckeown et al., 2021</xref>; <xref ref-type="bibr" rid="bib41">Mulholland et al., 2023</xref>; <xref ref-type="bibr" rid="bib58">Turnbull et al., 2019a</xref>; <xref ref-type="bibr" rid="bib27">Ho et al., 2020</xref>; <xref ref-type="bibr" rid="bib30">Karapanagiotidis et al., 2017</xref>; <xref ref-type="bibr" rid="bib36">Mckeown et al., 2023</xref>; <xref ref-type="bibr" rid="bib65">Vatansever et al., 2020</xref>; <xref ref-type="bibr" rid="bib66">Wang et al., 2018</xref>). Each question describes a different feature of experience, such as if their thoughts are oriented in the future or the past, about oneself or other people, deliberate or intrusive in nature, and more (see Methods for a full list of questions used in the current study).</p><p>One challenge that arises when attempting to map the dynamics of thought onto brain activity during movie-watching is accounting for the inherently disruptive nature of experience sampling: to measure experience with sufficient frequency to map experiential reports during movies would inherently disrupt the natural processes of the brain and alter the viewer’s experience (for example, by pausing the film at a moment of suspense). Therefore, if we periodically interrupt viewers to acquire a description of their thoughts while recording brain activity, this could impact capturing important dynamic features of the brain. On the other hand, if we measured fMRI activity continuously over movie-watching (as is usually the case), we would lack the capacity to directly relate brain signals to the corresponding experiential states. Thus, to overcome this obstacle, we developed a novel methodological approach using two independent samples of participants. In the current study, one set of 120 participants was probed with mDES five times across the three ten-minute movie clips (11 min total, no sampling in the first minute). We used a jittered sampling technique where probes were delivered at different intervals across the film for different people depending on the condition they were assigned. Probe orders were also counterbalanced to minimize the systematic impact of prior and later probes at any given sampling moment. We used these data to construct a precise description of the dynamics of experience for every 15 s of three 10-min movie clips. These data were then combined with fMRI data from a different sample of 44 participants who had already watched these clips without experience sampling (<xref ref-type="bibr" rid="bib3">Aliko et al., 2020</xref>). By combining data from two different groups of participants, our method allows us to describe the time series of different experiential states (as defined by mDES) and relate these to the time series of brain activity in another set of participants who watched the same films with no interruptions. In this way, our study set out to explicitly understand how the patterns of thoughts that dominate different moments in a film in one group of participants relate to the brain activity at these time points in a second set of participants and, therefore, better understand the contribution of different neural systems to the movie-watching experience.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Analytic goal</title><p>The goal of our study, therefore, was to understand the association between patterns of brain activity over time during movie clips in one group of participants and the patterns of thought that participants reported at the corresponding moment in a different set of participants (see <xref ref-type="fig" rid="fig1">Figure 1</xref>). This can be conceptualized as identifying the mapping between two multi-dimensional spaces, one reflecting the time series of brain activity and the other describing the time series of ongoing experience (see <xref ref-type="fig" rid="fig1">Figure 1</xref> right-hand panel). In our study, we selected three 11 mine clips from movies (<italic>Citizenfour</italic>, <italic>Little Miss Sunshine</italic> and <italic>500 Days of Summer</italic>) for which recordings of brain data in fMRI already existed (n=44) (<xref ref-type="bibr" rid="bib3">Aliko et al., 2020</xref>; <xref ref-type="fig" rid="fig1">Figure 1</xref>, Sample 1). A second set of participants (n=120) viewed the same movie clips, providing intermittent reports on their thought patterns using mDES (<xref ref-type="fig" rid="fig1">Figure 1</xref>, Sample 2). Our goal was to understand the mapping between the patterns of brain activity at each moment of the film and the reports of ongoing thought recorded at the same point in the movies. We first applied Principal Components Analysis (PCA) to the mDES data to reduce these data to a set of four simple dimensions that explained the reported thought pattern. These are represented as word clouds in <xref ref-type="fig" rid="fig1">Figure 1</xref>. We performed two analyses to understand the associations between the reported thought patterns and brain activity at each point in the film. Our first analysis computed the mean time series of experience for each of the four thought pattern components (averaged across participants in Sample 2) and used this as a regressor of interest in a model predicting brain activity recorded from each participant from Sample 1. We refer to this as a <italic>voxel-space</italic> analysis, and it allowed us to perform a whole-brain search of the mapping between activity in each region to each dimension of ongoing thought. In our second analysis, we projected the grand mean of brain activity for each volume of each film against the first five dimensions of brain activity from a decomposition of the Human Connectome Project (HCP) resting state date to form a 5D ‘brain space’ that describes the trajectory of the brain during each movie (<xref ref-type="fig" rid="fig1">Figure 1</xref>, <italic>note</italic> only the first four dimensions are shown; <xref ref-type="bibr" rid="bib33">Margulies et al., 2016</xref>). We used the results of this analysis to produce coordinates for each TR of each movie, which were used as explanatory variables in a linear mixed model (LMM) in which the location of each mDES probe in the ‘thought space’ described by the PCA dimensions were the dependent variables. We refer to this second analysis as a <italic>state-space</italic> analysis (see <xref ref-type="bibr" rid="bib30">Karapanagiotidis et al., 2017</xref>; <xref ref-type="bibr" rid="bib36">Mckeown et al., 2023</xref>; <xref ref-type="bibr" rid="bib60">Turnbull et al., 2020</xref> for prior examples of this approach).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Using fMRI data and experience sampling data to map ongoing thought patterns onto brain activity during movie-watching.</title><p><italic>Left to Right -</italic> One sample of participants was scanned while watching movies (Sample 1), and a different set of participants responded to experience sampling probes (Sample 2) while watching the same movies in the laboratory. Decomposition of mDES data into low-dimension experiential patterns using principal component analysis (PCA) produced a set of dimensions that describe experience during movie-watching (a ‘thought space’ within which the dynamics of the movie-watching experience unfold). Word clouds illustrate how the experience sampling questions map onto each dimension that describes this space. In these word clouds, the font size describes their importance (bigger = more important), and the colour describes their polarity (red = positive, blue = negative). Similarly, we created a brain space to describe the movie-watching experience by comparing each moment in the film to validated dimensions of brain variation. For this purpose, we used the dimensions defined from the resting states of the HCP conducted by Margulies (<xref ref-type="bibr" rid="bib33">Margulies et al., 2016</xref>) (often referred to as gradients): Gradient 1 (Association to Primary cortex), Gradient 2 (Visual to Motor cortex), Gradient 3 (Frontoparietal to Default Mode Networks), and Gradient 4 (Dorsal Attention Network (DAN)/Visual to Default Mode Networks) of brain variation dimensions illustrated by colour to map activity in state space analysis (purple = low, yellow = high) (not shown: Gradient 5 Lateral Default Mode to Primary sensory cortex) (<xref ref-type="bibr" rid="bib33">Margulies et al., 2016</xref>). Two 3D scatter plots illustrating two examples from our data of how the movie-watching can be seen as two complimentary trajectories through a ‘Brain Space’ (focusing on Gradients 1, 2, and 3, shown at the top) and a ‘Thought Space’ (focusing on ‘Episodic Knowledge’, ‘Verbal Detail’, and ‘Sensory Engagement’, shown at the bottom). The cooler (blue) points occur earlier in the movie clip and the warmer (red) points occur later.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97731-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Scree plot of mDES thought data.</title><p>The scree plot illustrates the eigenvalues of principal components obtained from a PCA analysis. Each point on the plot represents a principal component, and the y-axis displays the corresponding eigenvalues. The eigen value threshold of 1 and the ‘elbow’ of the plot, where eigenvalues start to level off, is indicative of the optimal number of components to retain. In this case, the analysis suggests a four-component solution. The scree plot aids in determining the most meaningful components for capturing variance in the data, facilitating a more parsimonious representation of the underlying structure.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97731-fig1-figsupp1-v1.tif"/></fig></fig-group></sec><sec id="s2-2"><title>Generation of the thought space</title><p>The first step in our analysis was to decompose the mDES data using PCA to produce the dimensions that comprise the ‘thought space’ used for our subsequent analyses (<xref ref-type="fig" rid="fig1">Figure 1</xref>, see Methods). Based on the scree plot (see <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>), the data best fit a four-component solution, and the resulting components are displayed as word clouds (see Methods for further details). In these word clouds, items with similar colours are related, and the font size indicates their importance. Component 1 contributed 26.1% of the variance explained and loaded positively on terms ‘past’, ‘self’, and ‘knowledge’, and negatively on ‘words’ and ‘sounds’, and is referred to as ‘Episodic Knowledge’. Component 2 explained 10.5% of the variance and loaded positively on the items ‘intrusive’ and ‘distracting’ and negatively on ‘deliberateness’, and is referred to as ‘Intrusive Distraction’. Component 3 loaded positively on ‘words’, ‘detail’, and ‘deliberateness’, explaining 7.7% of the variance, and is called ‘Verbal Detail’. Finally, Component 4 contributed 6.8% of the explained variance, loaded positively on ‘emotion’, ‘images’, ‘sounds’, and ‘people’, and was named ‘Sensory Engagement’. See <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1a</xref> for a description of the mDES questionnaire and <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1b</xref> for the percentage of variance explained by principal components overall and in each movie.</p></sec><sec id="s2-3"><title>Split-half reliability results</title><p>A bootstrapped split-half reliability analysis was conducted to confirm that the four-component solution provided a reasonable description of our data. This analysis repeatedly divided the mDES data into two random samples and evaluated the correlation between the two halves’ components. The reliability analysis supported that the four-component solution was reproducible because it had a strong homologue similarity score (<italic>r</italic>=0.96, 95% CI [0.93, 1.00]; see Methods for further details).</p></sec><sec id="s2-4"><title>Variation in thought patterns</title><p>Next, we examined how these dimensions describe experience within each movie (see <xref ref-type="fig" rid="fig2">Figure 2</xref>). We performed four linear mixed models (LMM), one for each thought component (‘Episodic Knowledge’, ‘Intrusive Distraction’, ‘Verbal Detail’, and ‘Sensory Engagement’), in which the movie was the explanatory variable of interest, and participants were included as a random effect. The significance threshold was adjusted using the False Discovery Rate (FDR) to control for family-wise error (FWE) within the model (controlling for the three movies). The four-model analyses found significant differences in overall thought pattern scores across the three movies, including reported thoughts resembling ‘Episodic Knowledge’, <italic>F</italic>(2, 2015.3)=5.41, p=0.005, η2=0.01, ‘Intrusive Distraction’, <italic>F</italic>(2, 2015.3)=77.84, p&lt;0.001, η2=0.07, ‘Verbal Detail’, <italic>F</italic>(2, 2015.4)=13.90, p&lt;0.001, η2=0.01, and ‘Sensory Engagement’, <italic>F</italic>(2, 2015.7)=82.69, p&lt;0.001. η2=0.08. This suggests that within each model, there was a significantly different score for the reported thought pattern in at least one of the movies. Post-hoc pairwise comparisons using the least-squares means (lsmeans) were conducted for each model to investigate how thought component scores differ in each movie, adjusting significance thresholds using the Tukey method to control for FWE within the model. The first model suggests patterns of responses in <italic>Little Miss Sunshine</italic> showed less similarity to ‘Episodic Knowledge’ (<italic>M</italic>=–0.12, SE = 0.10) than did patterns of thoughts reported in <italic>500 Days of Summer</italic> (<italic>M</italic>=0.11, SE = 0.10), <italic>t</italic>(2016)=–3.27, p=0.003. However, there were no significant differences in ‘Episodic Knowledge’ thoughts reported during <italic>Citizenfour</italic> (<italic>M</italic>=–0.02, SE = 0.10) compared to <italic>Little Miss Sunshine</italic>, <italic>t</italic>(2015)=1.31, p=0.392, or <italic>500 Days of Summer</italic>, <italic>t</italic>(2016)=–1.97, p=0.121. The second model identified self-reported thoughts that were more similar to the pattern of ‘Intrusive Distraction’ during <italic>Citizenfour</italic> (<italic>M</italic>=0.41, SE = 0.09) than during <italic>Little Miss Sunshine</italic> (<italic>M</italic>=–0.15, SE = 0.09), <italic>t</italic>(2015)=9.66, p&lt;0.001, or during <italic>500 Days of Summer</italic> (<italic>M</italic>=–0.27, SE = 0.09), <italic>t</italic>(2015)=11.66, p&lt;0.001. There was no difference in how similar reported thoughts scores were to ‘Intrusive Distraction’ between <italic>Little Miss Sunshine</italic> and <italic>500 Days of Summer</italic>, <italic>t</italic>(2016)=2.03, p=0.106. Model three found self-reported thoughts resemble patterns of ‘Verbal Detail’ more for <italic>Citizenfour</italic> (<italic>M</italic>=0.17, SE = 0.09) than for <italic>Little Miss Sunshine</italic> (<italic>M</italic>=–0.14, SE = 0.09), <italic>t</italic>(2015)=5.14, p&lt;0.001, or <italic>500 Days of Summer</italic> (<italic>M</italic>=–0.04, SE = 0.09), <italic>t</italic>(2016)=3.58, p=0.001. Again, there were no significant differences in reported ‘Verbal Detail’ scores between <italic>Little Miss Sunshine</italic> and <italic>500 Days of Summer</italic>, <italic>t</italic>(2016)=–1.54, p=0.271. Lastly, model four found reported thoughts during <italic>Citizenfour</italic> resembled patterns of ‘Sensory Engagement’ (<italic>M</italic>=–0.32, SE = 0.07) significantly less than for either <italic>Little Miss Sunshine</italic> (<italic>M</italic>=–0.01, SE = 0.07), <italic>t</italic>(2015)=–6.07, p&lt;0.001, or <italic>500 Days of Summer</italic> (<italic>M</italic>=0.33, SE = 0.07), <italic>t</italic>(2016)=–12.85, p&lt;0.001. Additionally, reported thoughts during <italic>Little Miss Sunshine</italic> resembled patterns of ‘Sensory Engagement’ less than reported thoughts during <italic>500 Days of Summer</italic>, <italic>t</italic>(2016)=–6.81, p&lt;0.001. The results are presented visually in <xref ref-type="fig" rid="fig2">Figure 2</xref>, and further details of the LMM are presented in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1c</xref>.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>The relationship between how patterns differ across movie clips and relate to comprehension.</title><p><italic>Left to Right</italic> – The 3D scatterplot shows the average location of each film on three of the four PCA dimensions, ‘Episodic Knowledge’, ‘Verbal Detail’, and ‘Sensory Engagement’. The bar graphs show the average loading on each dimension, with the error bars showing the 95% Confidence Interval. The plots on the right illustrate the relationship between the mDES dimensions and memory for information in the film. The top barplot shows the average comprehension score on each film with 95% Confidence Intervals error bars. The scatter plots below show the association between mDES components and comprehension. The scatter plot on the left shows the negative linear relationship between the ‘Intrusive Distraction’ thought and memory. The plot on the right shows a positive association with ‘Sensory Engagement’. The blue line represents the best-fit line, and the shaded area shows the 95% Confidence Intervals.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97731-fig2-v1.tif"/></fig></sec><sec id="s2-5"><title>Time series of experience across movie clips</title><p>Next, we examined how each pattern of thought changes across each movie clip. For this analysis, we conducted separate ANOVAs for each film clip for the four components (see <xref ref-type="table" rid="table1">Table 1</xref> and <xref ref-type="fig" rid="fig3">Figure 3</xref>). Clear dynamic changes were observed in several components for different films. First, there was a significant change in ‘Episodic Social Cognition’ scores across <italic>Little Miss Sunshine</italic>, <italic>F</italic>(1, 712)=10.80, p=0.001, η2=0.03, and <italic>Citizenfour</italic>, <italic>F</italic>(1, 712)=5.23, p=0.023, η2=0.02. There was also a significant change in ‘Verbal Detail’ scores across <italic>Little Miss Sunshine</italic>, <italic>F</italic>(1, 712)=31.79, p&lt;0.001, η2=0.09. Lastly, there were significant changes in ‘Sensory Engagement’ scores for both <italic>Citizenfour</italic>, <italic>F</italic>(1, 712)=6.22, p=0.013, η2=0.02, and <italic>500 Days of Summer</italic>, <italic>F</italic>(1, 706)=80.41, p&lt;0.001, η2=0.18. These time series are plotted in <xref ref-type="fig" rid="fig3">Figure 3</xref> and highlight how mDES can capture the dynamics of different types of experience across the three movie clips. Moreover, in several of these time series plots, it is clear that reported thought patterns extend beyond adjacent time periods (e.g. scores above zero between time periods 150–400 for Sensory Engagement in <italic>500 Days of Summer</italic> and for time periods between 175 and 225 for Verbal Detail in <italic>Little Miss Sunshine</italic>). It is important to note that no participant completed experience sampling reports during adjacent sampling points (see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>), so the length of these intervals indicates agreement in how specific scenes within a film were experienced and conserved across different individuals. Notably, the component with the least evidence for temporal dynamics was ‘Intrusive Distraction’.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>ANOVA across sampling bins of each Movie of each Thought Component score.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"><italic>Little Miss Sunshine</italic></th><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/></tr></thead><tbody><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Df</td><td align="left" valign="bottom">Sum Sq</td><td align="left" valign="bottom">Mean Sq</td><td align="left" valign="bottom"><italic>F</italic>-value</td><td align="left" valign="bottom">p<italic>-</italic>value</td></tr><tr><td align="left" valign="bottom">PCA_1</td><td align="left" valign="bottom">Sampling bin</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">24.30</td><td align="left" valign="bottom">24.29</td><td align="left" valign="bottom">10.80</td><td align="left" valign="bottom">0.001 **</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Residuals</td><td align="left" valign="bottom">712.00</td><td align="left" valign="bottom">1601.80</td><td align="left" valign="bottom">2.25</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">PCA_2</td><td align="left" valign="bottom">Sampling bin</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">3.60</td><td align="left" valign="bottom">3.64</td><td align="left" valign="bottom">1.97</td><td align="left" valign="bottom">0.161</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Residuals</td><td align="left" valign="bottom">712.00</td><td align="left" valign="bottom">1219.50</td><td align="left" valign="bottom">1.85</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">PCA_3</td><td align="left" valign="bottom">Sampling bin</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">63.50</td><td align="left" valign="bottom">63.54</td><td align="left" valign="bottom">31.79</td><td align="left" valign="bottom">&lt;0.001 ***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Residuals</td><td align="left" valign="bottom">712.00</td><td align="left" valign="bottom">1423.00</td><td align="left" valign="bottom">2.00</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">PCA_4</td><td align="left" valign="bottom">Sampling bin</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">5.10</td><td align="left" valign="bottom">5.06</td><td align="left" valign="bottom">3.43</td><td align="left" valign="bottom">0.064</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Residuals</td><td align="left" valign="bottom">712.00</td><td align="left" valign="bottom">1048.20</td><td align="left" valign="bottom">1.47</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"><italic>Citizenfour</italic></td><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Df</td><td align="left" valign="bottom">Sum Sq</td><td align="left" valign="bottom">Mean Sq</td><td align="left" valign="bottom"><italic>F</italic>-value</td><td align="left" valign="bottom">p<italic>-</italic>value</td></tr><tr><td align="left" valign="bottom">PCA_1</td><td align="left" valign="bottom">Sampling bin</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">12.00</td><td align="left" valign="bottom">12.01</td><td align="left" valign="bottom">5.23</td><td align="left" valign="bottom">0.023 *</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Residuals</td><td align="left" valign="bottom">712.00</td><td align="left" valign="bottom">1637.00</td><td align="left" valign="bottom">2.30</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">PCA_2</td><td align="left" valign="bottom">Sampling bin</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">2.00</td><td align="left" valign="bottom">1.95</td><td align="left" valign="bottom">0.87</td><td align="left" valign="bottom">0.350</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Residuals</td><td align="left" valign="bottom">712.00</td><td align="left" valign="bottom">1593.00</td><td align="left" valign="bottom">2.24</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">PCA_3</td><td align="left" valign="bottom">Sampling bin</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">0.10</td><td align="left" valign="bottom">0.07</td><td align="left" valign="bottom">0.04</td><td align="left" valign="bottom">0.847</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Residuals</td><td align="left" valign="bottom">712.00</td><td align="left" valign="bottom">1425.30</td><td align="left" valign="bottom">2.00</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">PCA_4</td><td align="left" valign="bottom">Sampling bin</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">7.40</td><td align="left" valign="bottom">7.40</td><td align="left" valign="bottom">6.22</td><td align="left" valign="bottom">0.013 *</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Residuals</td><td align="left" valign="bottom">712.00</td><td align="left" valign="bottom">847.80</td><td align="left" valign="bottom">1.19</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"><italic>500 Days of Summer</italic></td><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom">Df</td><td align="left" valign="bottom">Sum Sq</td><td align="left" valign="bottom">Mean Sq</td><td align="left" valign="bottom"><italic>F</italic>-value</td><td align="left" valign="bottom">p<italic>-</italic>value</td></tr><tr><td align="left" valign="bottom">PCA_1</td><td align="left" valign="bottom">Sampling bin</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">7.30</td><td align="left" valign="bottom">7.34</td><td align="left" valign="bottom">2.51</td><td align="left" valign="bottom">0.114</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Residuals</td><td align="left" valign="bottom">706.00</td><td align="left" valign="bottom">2068.50</td><td align="left" valign="bottom">2.93</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">PCA_2</td><td align="left" valign="bottom">Sampling bin</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">0.20</td><td align="left" valign="bottom">0.22</td><td align="left" valign="bottom">0.13</td><td align="left" valign="bottom">0.719</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Residuals</td><td align="left" valign="bottom">706.00</td><td align="left" valign="bottom">1219.10</td><td align="left" valign="bottom">1.73</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">PCA_3</td><td align="left" valign="bottom">Sampling bin</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">7.80</td><td align="left" valign="bottom">7.85</td><td align="left" valign="bottom">3.86</td><td align="left" valign="bottom">0.049 *</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Residuals</td><td align="left" valign="bottom">712.00</td><td align="left" valign="bottom">1425.30</td><td align="left" valign="bottom">2.00</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">PCA_4</td><td align="left" valign="bottom">Sampling bin</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">114.20</td><td align="left" valign="bottom">114.15</td><td align="left" valign="bottom">80.41</td><td align="left" valign="bottom">&lt;0.001 ***</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">Residuals</td><td align="left" valign="bottom">706.00</td><td align="left" valign="bottom">1002.30</td><td align="left" valign="bottom">1.42</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr></tbody></table><table-wrap-foot><fn><p>Note. Results of each ANOVA test assessing if each PCA thought component score differs across each of the 15 s sampling bins (Sampling bin) for the three movies Little <italic>Miss Sunshine</italic>, <italic>Citizenfour</italic> and <italic>500 Days of Summer</italic>. The table consists of the degrees of freedom (Df), sum of squares (Sum Sq), mean squares (Mean Sq), F-value, and p-value for each component and movie. Significant p-value (p&lt;0.05) indicates a significant difference in the respective PCA component score across the sampling bins.</p></fn></table-wrap-foot></table-wrap><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>The application of multi-dimensional experience sampling (mDES) method and relevant time series produced from decomposed mDES thought patterns.</title><p><italic>Left to Right</italic> – The first panel illustrates the mDES method in the laboratory to demonstrate how participants respond to the sixteen items about their thoughts while watching the film on the laboratory computers. The plots on the right summarize the average thought pattern score at each 15 s sampling window across the three movies. The first time series plot illustrates the trajectory of the ‘Episodic Knowledge’ across <italic>Little Miss Sunshine</italic>, followed by the time course of ‘Verbal Detail’ also across <italic>Little Miss Sunshine</italic>, with distinct peaks in scores within the 150–250 s range and particularly low scores between the 400 and 500 s interval. The third plot demonstrates the relatively low and negative scores on ‘Sensory Engagement’ across <italic>Citizenfour</italic>. Lastly, the final plot highlights the relatively high scores on ‘Sensory Engagement’ throughout <italic>500 Days of Summer</italic>, especially across the 150–400 s interval.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97731-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Probe order matrix for Sample 2.</title><p>Visual representation of probe order conditions assigned to participants with timestamps of each delivered probe. Participants were randomly assigned to a different probe order condition for each movie clip. Probe orders 1-8 share no overlapping probes. Probe orders 9-16 have overlapping probes from the former probe orders, corresponding to their cell colours, to control for ordering effects across participants. Probes began at 1 minute and 15 seconds until the 11-minute mark (end of the movie clip).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97731-fig3-figsupp1-v1.tif"/></fig></fig-group></sec><sec id="s2-6"><title>Comprehension</title><p>Next, we examined how the thought patterns relate to the participants’ memory of information from the movies (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Participants answered four comprehension questions for each film (12 total) related to relevant information in the clip they just watched (see <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1d</xref> for the comprehension questionnaire). We performed an LMM for which the movies, each thought pattern, and their interaction were explanatory variables of interest. Comprehension score was the dependent variable, and participant was included as a random effect. FDR was used to control for FWE, consisting of nine comparisons. The analysis revealed three significant main effects and a significant interaction. First, there was a significant main effect of movie on memory, <italic>F</italic>(2, 254.12)=49.33, p&lt;0.001, η2=0.28. Post-hoc pairwise comparisons using the lsmeans were conducted to investigate the effect of memory performance across the different films. Significance thresholds for the post-hoc comparisons were adjusted using the Tukey method to control FWE within the model. Comprehension scores were significantly lower for questions related to information in <italic>Citizenfour</italic> (<italic>M</italic>=2.42, SE = 0.09) compared to <italic>Little Miss Sunshine</italic> (<italic>M</italic>=3.35, SE = 0.08), <italic>t</italic>(249) = –9.16, p&lt;0.001, as well as <italic>500 Days of Summer</italic> (<italic>M</italic>=3.33, SE = 0.08), <italic>t</italic>(273) = –8.33, p&lt;0.001. Notably, there was no significant difference in comprehension performance between <italic>Little Miss Sunshine</italic> and <italic>500 Days of Summer</italic>, <italic>t</italic>(242) = –0.18, p=0.982. There were also two significant main effects of thought patterns — ‘Intrusive Distraction’ was significantly associated with worse comprehension across the three movies, <italic>F</italic>(1, 324.41)=9.27, p=0.011, η2=0.03, whereas ‘Sensory Engagement’ was associated with better overall comprehension, <italic>F</italic>(1, 341.44)=8.30, p=0.013, η2=0.02. Finally, there was a significant movie by thought pattern interaction for ‘Episodic Knowledge’, <italic>F</italic>(2, 268.96)=4.46, p=0.028, η2=0.03. To follow up on this significant interaction, post-hoc simple slopes analysis was performed to assess the effect of ‘Episodic Knowledge’ on comprehension performance across each movie, using FDR to control for multiple comparisons. The analysis found moments when patterns of thought were more similar to ‘Episodic Knowledge’ were associated with significantly better comprehension performance for information in <italic>500 Days of Summer</italic>, <italic>t</italic>(319.83)=2.54, p=0.030. The interaction predicted negative comprehension performance for information in <italic>Citizenfour</italic>, <italic>t</italic>(317.55)=–1.39, <italic>b</italic>=–0.09, SE = 0.06, p=0.240, but positive comprehension performance for information in <italic>Little Miss Sunshine</italic>, <italic>t</italic>(321.85)=0.93, <italic>b</italic>=0.07, SE = 0.07, p=0.350, although neither of these relationships was statistically significant. To see the complete model output and the pairwise comparisons, see <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1e</xref> One important implication of these results suggests mDES is sensitive to objective indicators of movie-watching experience because they indicate that individuals for whom self-reported experience shows less evidence of the pattern of ‘Intrusive Distraction’ tended to encode features of the movie more accurately and, therefore, performed better on the comprehension test.</p></sec><sec id="s2-7"><title>Brain – thought mappings: voxel-space analysis</title><p>Having established the dimensions that characterize the mDES data, how they organize experience in each movie, their variation over time, and their associations to memory, we then examined how these dimensions of experience relate to the brain activity at each moment in the films. Our first analysis examined this question at the voxel level. In this analysis, the averaged time course of each PCA dimension (collapsed across all individuals in Sample 2) was included as a regressor of interest at the first level for each of the three movies for the brain activity recorded in each subject in Sample 1. To perform a group comparison of these analyses, we used FLAME in FSL with a cluster forming threshold of <italic>z</italic>=3.1 FWE, controlling for the number of regressors of interest to determine the significance of each cluster (p&lt;0.0125). This generated four group-level thresholded maps, which we followed up with a FEAT query to extract cluster-wise parameter estimates, corresponding to regions whose activation during moments in the film was correlated with a specific thought pattern (see <xref ref-type="fig" rid="fig4">Figure 4</xref> and <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1f</xref>). ‘Episodic Knowledge’ was significantly positively associated with activation in a region of dorsal visual cortex (<italic>b</italic>=0.62, 95% CI [0.27, 0.97]). ‘Intrusive Distraction’ was significantly associated with deactivation in the FPN (<italic>b</italic>=–0.78, 95% CI [-1.37,–0.20]). ‘Verbal Detail’ was significantly associated with suppression of activity in primary auditory cortex (<italic>b</italic>=–1.64, 95% CI [-2.11,–1.17]). Lastly, ‘Sensory Engagement’ was significantly associated with activation in both visual and auditory cortexes (<italic>b</italic>=1.26, 95% CI [0.81, 1.70]) (see <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1f</xref> for the table of average Gradient score for each movie derived from this analysis). We also performed a functional connectivity analysis using each set of clusters as the seed region, see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>, <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>, and <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1g</xref>.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Group-level neural activation patterns associated with each of the dimensions of thought identified in a voxel space analysis.</title><p><italic>Left to Right</italic> - Regions in red are associated with activity corresponding to reports of ‘Episodic Knowledge’, green regions are associated with ‘Intrusive Distraction’, areas in purple are associated with ‘Verbal Detail’, and the regions in orange represent activity associated with ‘Sensory Engagement’. The bar plot illustrates the directionality of each parameter estimate with error bars representing 95% Confidence Intervals. Corresponding word clouds for each thought pattern are presented on the right for reference (<italic>Top to Bottom:</italic> ‘Episodic Knowledge’, ‘Intrusive Distraction’, ‘Verbal Detail’, and ‘Sensory Engagement’).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97731-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Functional connectivity summary.</title><p>Results of functional connectivity (FC) in which we used the regions identified in our voxel space analysis that related to “Episodic Knowledge” (Red - Yellow color map), “Verbal Detail” (Blue-Green color map) and “Sensory Engagement” (Black – Green color map). These are thresholded at <italic>p</italic> &lt; .001 and corrected for FEW at <italic>p</italic> &lt; .05.The panel on the right shows the same fully saturated maps to highlight their common regions (shown in white).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97731-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Relationship of functional connectivity &amp; Yeo 7 parcellation (DMN).</title><p>Overlap between the regions showing common functional connectivity between regions associated with three mDES components (‘Episodic Knowledge’, ‘Verbal Detail’ and ‘Sensory Engagement’) in the voxel space analysis and the DMN as defined by <xref ref-type="bibr" rid="bib70">Yeo et al., 2011</xref>. Regions in red show regions of common functional connectivity, regions in green are the DMN and regions in yellow are the overlap between these two maps.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97731-fig4-figsupp2-v1.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>Neurosynth decoding and functional connectivity relationship.</title><p>Meta analytic decoding of the regions showing common functional connectivity between regions associated with three mDES components (“Episodic Knowledge”, “Verbal Detail” &amp; “Sensory Engagement”) in the voxel space analysis and the DMN as defined by <xref ref-type="bibr" rid="bib70">Yeo et al., 2011</xref> (shown in yellow). The word cloud on the right shows the functional terms most likely to be associated with these regions following a Neurosynth analytic decoding. Regions in red are more likely and regions in blue are less likely. Words in a larger font size are more important.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97731-fig4-figsupp3-v1.tif"/></fig><fig id="fig4s4" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 4.</label><caption><title>Relationship of Intrusive Distraction map and FPN.</title><p>Overlap between regions associated with “Intrusive Distraction” in our voxel space analysis (green) and the FPN as defined by <xref ref-type="bibr" rid="bib70">Yeo et al., 2011</xref> (lavender). Regions of overlap are presented in cyan.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97731-fig4-figsupp4-v1.tif"/></fig></fig-group><p>Our voxel-space analysis highlights two notable features of how thought patterns during movie-watching were linked to brain activity. First, most regions whose activity we can predict based on mDES scores tended to fall within sensory cortex. Notably, ‘Sensory Engagement’, a pattern of multi-sensory thought linked to sounds and images, is associated with increased activity in both the visual and auditory systems. Interestingly, these regions overlap with regions linked to ‘Episodic Knowledge’ maps (Posterior [orange and red]) and those linked to ‘Verbal Detail’ (Right [orange and purple]). Notably, since both Episodic Knowledge and Sensory Engagement show positive links to comprehension and greater activity in sensory cortex regions, these results support the hypothesis that perceptual coupling is an important feature of making sense of events during movie-watching (e.g. <xref ref-type="bibr" rid="bib52">Smallwood, 2013a</xref>). Second, the only regions identified outside sensory cortex were linked to ‘Intrusive Distraction’ and broadly fall within regions of the FPN. <xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref> compares the regions linked to ‘Intrusive Distraction’ with the FPN as defined by <xref ref-type="bibr" rid="bib70">Yeo et al., 2011</xref>, showing that the regions showing less activation during moments when Intrusive Distraction was high generally fall within this system. This pattern is consistent with views of the FPN as playing an active role in maintaining a state of non-distracted task focus (<xref ref-type="bibr" rid="bib48">Scolari et al., 2015</xref>). See <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1h</xref> for the analysis output and <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>, which shows each map is shown separately.</p><p>Our analysis highlighted significant overlap across analyses in visual and auditory cortex regions. To better understand the likely functions of these common regions, we calculated the overlap in these maps (left-hand panel of <xref ref-type="fig" rid="fig5">Figure 5</xref>) and performed a large-scale automated analysis consisting of over 4400 studies using Neurosynth, with the aim of identifying the most likely functions ascribed to these regions by prior research (See <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1i</xref> for the specific loadings for each term). The results of this analysis are displayed in the form of word clouds where regions common to reduced ‘Verbal Detail’ and greater ‘Sensory Engagement’ are linked to auditory processes (‘sounds’, ‘noise’, and ‘pitch’). In contrast, regions common to ‘Sensory Engagement’ and ‘Episodic Knowledge’ are most likely associated with ‘videos’, providing independent meta-analytic corroboration that these regions are paramount for movie-watching. The Neurosynth analysis, therefore, shows that the regions highlight by our analysis tend to be involved in sensory processing, and, are most commonly observed during movie-watching. Finally, we conducted a resting state functional connectivity analysis using the regions overlapping as seeds (right-hand panel of <xref ref-type="fig" rid="fig5">Figure 5</xref>). This highlighted that both regions exhibited functional connectivity patterns, including many overlapping areas (coloured yellow). Notably, both functional connectivity maps contained the seed regions of the other analysis.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Brain regions associated with multiple experiential features during movie-watching.</title><p>A region of superior temporal cortex is associated with positive reports of thoughts like ‘Sensory Engagement’ and negative reports of thoughts like ‘Verbal Detail’ (coloured green). A region of dorsal visual cortex was associated with both thoughts reported like ‘Sensory Engagement’ and ‘Episodic Detail’ (coloured red). The word clouds in the middle panel show the results of a Neurosynth analysis of the regions, highlighting the most likely functions associated with these regions. The font size describes their importance (bigger = more important), and the colour describes their polarity (darker = positive). The panel on the right shows the results of seed-based functional connectivity analysis of these regions of overlap from a separate resting-state study. Regions in red indicate those connected to the region of visual cortex, regions in green show those linked to auditory cortex, and regions in yellow are common to both spatial maps.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97731-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Summary of voxel-space brain maps by thought pattern.</title><p>Brain maps of each voxel-space analysis output for each of the corresponding thought components separately, “Episodic Knowledge,” “Intrusive Distraction,” “Verbal Detail,” and “Sensory Engagement.” Each brain map is displayed from the coronal view, sagittal view, and axial view to maximize the understanding of the spatial distribution and localization of related brain regions for each thought pattern.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97731-fig5-figsupp1-v1.tif"/></fig></fig-group></sec><sec id="s2-8"><title>State space analysis</title><p>Our next analysis used a ‘state-space’ approach to determine how brain activity at each moment in the film predicted the patterns of thoughts reported at these moments (for prior examples in the domain of tasks, see <xref ref-type="bibr" rid="bib36">Mckeown et al., 2023</xref>; <xref ref-type="bibr" rid="bib60">Turnbull et al., 2020</xref>, See Methods). In this analysis, we used the coordinates of the group average of each TR in the ‘brain space’ and the coordinates of each experience sampling moment in the ‘thought space’. To clarify, the location of a moment in a film in ‘brain space’ is calculated by projecting the grand mean of brain activity for each volume of each film against the first five dimensions of brain activity from a decomposition of the Human Connectome Project (HCP) resting state data, referred to as Gradients 1–5. ‘Thought space’ is the decomposition of mDES items to create thought pattern components, referred to as ‘Episodic Knowledge’, ‘Intrusive Distraction’, ‘Verbal Detail’, and ‘Sensory Engagement’. We ran four LMMs, one for each thought component, in each case using the location of each sampling point in the movie on Gradients 1–5 as explanatory variables and the scores for each thought pattern component (‘Episodic Knowledge’, ‘Intrusive Distraction’, ‘Verbal Detail’ and ‘Sensory Engagement’) as dependent variables. Participant was included as a random intercept. The significance threshold was adjusted using the FDR to control for FWE within each model, controlling for five brain dimensions. After correction, we found two significant main effects. First, we found a significant main effect of Gradient 4 (DAN to Visual), which predicted the similarity of answers to the ‘Episodic Knowledge’ component, <italic>t</italic>(2046)=2.17, p=0.013, η2=0.01. This suggests that moments when thoughts were most similar to ‘Episodic Knowledge’ were associated with moments when activity was high in visual cortex and lower in regions of the dorsal attention network (See <xref ref-type="fig" rid="fig6">Figure 6</xref>). There was also a significant main effect of Gradient 1 (Primary to Association) predicting patterns of thought related to ‘Sensory Engagement’, <italic>t</italic>(2046.34)=–3.26, p=0.006, η2=0.01. These results show that moments when thoughts are high on ‘Sensory Engagement’ were associated with increased brain activity in regions within the primary cortex low on Gradient 1 (see <xref ref-type="fig" rid="fig6">Figure 6</xref>). See <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1j</xref> for complete results.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Comparison of the locations of each moment across the movie clip in the (top row) ‘Thought Space’ and the ‘Brain Space’.</title><p><italic>Left to Right</italic> – 3D scatterplots of the coordinate locations of each thought pattern (‘Episodic Knowledge’, ‘Verbal Detail’, and ‘Sensory Engagement’) and gradients 1–3 (Gradient 1 Associated – Primary), Gradient 2 (Visual – Somato-motor), Gradient 3 (Frontoparietal – Default) during <italic>Citizenfour</italic>, <italic>Little Miss Sunshine</italic>, and <italic>500 Days of Summer</italic>. Observations in blue occur earlier during the film, and observations in red occur later in the film. The gradient maps (1-3) and thought pattern word clouds are presented on the right for reference.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97731-fig6-v1.tif"/></fig><p>Our study highlighted links between patterns of self-reports resembling ‘Sensory Engagement’ and ‘Episodic Knowledge’ that were associated with brain activity patterns in our voxel and state space analyses. Therefore, in our final analysis, we aimed to understand the overlap between these two complementary approaches to understand the mapping between brain activity and experience during movie-watching. To this end, we used a spin test to formally understand the mapping between the voxel-based and state space analyses (<xref ref-type="bibr" rid="bib2">Alexander-Bloch et al., 2018</xref>). To this end, we sampled the location of the identified cluster in our voxel analysis on the gradient of interest (e.g. the cluster of voxels associated with ‘Sensory Engagement’ on Gradient 1) and used spin tests (<xref ref-type="bibr" rid="bib2">Alexander-Bloch et al., 2018</xref>) to determine the likelihood that a score with this magnitude would occur by chance (based on a null distribution of 2500 permutations). This analysis identified that our voxel-based estimate of ‘Sensory Engagement’ falls within regions of sensory cortex implied by the state space analysis (i.e. the sensory end of Gradient 1) at a level that is unlikely to occur by chance, p=0.018 (two-tailed). In contrast, the location of ‘Episodic Knowledge’ on Gradient 4 was not significant, p=0.251 (see <xref ref-type="fig" rid="fig7">Figure 7</xref>). This analysis indicates that for the ‘Sensory Engagement’ component both the voxel-space and state-space analysis yielded comparable results highlighting common regions of sensory and auditory cortex.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Comparison of ‘State-Space’ and Voxel based analyses of ‘Sensory Engagement’ and ‘Episodic Knowledge’ with Gradients.</title><p><italic>Left to right –</italic> The barplots illustrate the associations for the significant models using Gradients 1–5 as explanatory variables and the thought patterns, ‘Sensory Engagement’ and ‘Episodic Knowledge’ as dependent variables. We performed two spin tests to formally compare these results to those using the voxel space analysis (permutation = 2500). The spin tests revealed the location of the cluster of voxels associated with ‘Sensory Engagement’ are located within the sensory regions of Gradient 1, unlike to have occurred by chance, p=0.018. In contrast, the location of the cluster of voxels associated with Episodic Knowledge on Gradient 4 was within the null distribution, p=0.251. The locations of the relevant clusters in gradient parcel space are presented in the scatter plots (red points indicate the location of parcels from the relevant comparison).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-97731-fig7-v1.tif"/></fig></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Our study aimed to identify how patterns of thought during movie-watching relate to brain activity during movie clips from three different films: <italic>Citizenfour</italic> (a documentary), <italic>Little Miss Sunshine</italic> (a comedy), and <italic>500 Days of Summer</italic> (a romance). We used open-source fMRI data from one group of participants (Sample 1) who watched these films while brain activity was recorded using fMRI. We then measured ongoing thought patterns using mDES in a second group of participants (Sample 2) for whom no brain activity was acquired (<xref ref-type="fig" rid="fig1">Figure 1</xref>). We used a novel sampling approach to build a detailed description of the time series of different thought patterns every 15 s in the clips while only sampling individual participants a relatively small number of times per movie, minimizing disruption of the subjective experience of movie-watching. Our analyses examined the overlap between the time series of brain activity in one group of participants (Sample 1) and reported thought patterns in a second group of participants (Sample 2) to reveal the relationship between brain activity at different moments in a film and the associated experiential states.</p><p>Across the movies, we identified four thought patterns. First, ‘Episodic knowledge’ was linked to experiences related to knowledge, the past, and the self. This pattern was also highest during the romance movie, specifically associated with better memory of information in this context and increased activity in dorsal medial regions of visual cortex by our state space and voxel space analysis. Second, ‘Intrusive Distraction’ was related to thoughts with intrusive, distracting features that were spontaneous in nature. This thought pattern predicted poorer overall comprehension across all the movies, was higher in the documentary, and emerged in moments during movies associated with reduced activation in regions of the FPN by our voxel space analysis. Third, ‘Verbal Detail’, which described experience as deliberate, detailed experiences in the form of words and with a negative emotional valance, was most prevalent in the documentary and associated with relative reductions in auditory cortex activation using our voxel space analysis. Finally, ‘Sensory Engagement’ was related to multi-modal sensory experience (loading on images, sounds, and people with a positive emotional tone). ‘Sensory Engagement’ was highest in the romance movie, associated with better comprehension performance across all movies, linked to activity in sensory cortex by both the voxel-based analysis and the state-space analysis, which were formally linked through a spin test.</p><p>Our study supports the hypothesis that perceptual coupling between the brain and external input is a core feature of making sense of events in movies (e.g. <xref ref-type="bibr" rid="bib54">Smallwood, 2013b</xref>). For example, ‘Sensory Engagement’, a pattern of enjoyable multi-sensory experience, was linked to better memory for information across all the movies and emerged when activity was high in both auditory and visual cortexes (regions at the sensory end of the principle gradient of functional brain organization, <xref ref-type="bibr" rid="bib33">Margulies et al., 2016</xref>). ‘Sensory Engagement’ was the thought pattern with the most consistent and most apparent links to the brain since it was the only thought pattern that showed a brain-thought mapping across our voxel- and state-space analysis that were formally linked using a spin test (see <xref ref-type="fig" rid="fig2">Figures 2</xref> and <xref ref-type="fig" rid="fig6">6</xref>). Similarly, reports of ‘Episodic Knowledge’ emerged when brain activity was high within a dorsal region of visual cortex and was linked to better comprehension in one of the films (<italic>500 Days of Summer</italic>). Together, these data provide important corroboration for the hypothesis that states of sensory coupling support better memory for environmental events (<xref ref-type="bibr" rid="bib57">Smallwood et al., 2021b</xref>; <xref ref-type="bibr" rid="bib52">Smallwood, 2013a</xref>). Further, they also provide support for contemporary perspectives that movie-watching is a useful and important paradigm for understanding the brain basis behind naturalistic states because it allows brain function to be understood through the lens of a state rich in complex sensory input (<xref ref-type="bibr" rid="bib15">Finn, 2021</xref>).</p><p>Our study also provides support for the hypothesized role the frontoparietal system plays in supporting states of non-distracted focus during movie-watching. Reports of ‘Intrusive Distraction’ were the only thought pattern associated with activity outside primary sensory systems and was seen to emerge at moments in films when activity during regions within the FPN was reduced See <xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref> for the overlap between the regions identified linked to ‘Intrusive Distraction’ and the FPN as defined by Yeo and colleagues (<xref ref-type="bibr" rid="bib69">Yarkoni et al., 2011</xref>). Interestingly, the association between greater distraction and reduced activity within the FPN is consistent with this network’s assumed role in goal maintenance (<xref ref-type="bibr" rid="bib10">Cole and Schneider, 2007</xref>). This result also confirms predictions from psychological research that states of distraction, like mind-wandering, often emerge when executive control is reduced (<xref ref-type="bibr" rid="bib38">McVay and Kane, 2010</xref>). This hypothesis gains further support for the consistent negative association with comprehension. Notably, ‘Intrusive Distraction’ was the only component that showed no evidence of temporal variation across the movie clips we sampled. It is possible, therefore, that processes that drive the occurrence of states such as ‘Intrusive Distraction’ are likely to depend on individual and contextual factors (e.g. poor executive control <xref ref-type="bibr" rid="bib38">McVay and Kane, 2010</xref>; <xref ref-type="bibr" rid="bib39">McVay and Kane, 2012</xref>) and/or intrinsic changes in brain activity. Recently, a study using intracranial recordings established that periods of distraction, with similar features to those observed in this study, occur when sharp wave ripples within the hippocampus are common (<xref ref-type="bibr" rid="bib28">Iwata et al., 2024</xref>). It is likely, therefore, that further research may be necessary to understand the brain-cognition mappings which lead to distraction. For example, in the future, we can systematically explore conditions in which this state is more or less present and highlight deviations from the mean as markers to better understand states of cognition that are less related to a state of perceptual coupling than are other features of movie-watching. Notably, using mDES, we can also identify the same thought pattern in our analysis in daily life research (<xref ref-type="bibr" rid="bib35">Mckeown et al., 2021</xref>; <xref ref-type="bibr" rid="bib41">Mulholland et al., 2023</xref>), suggesting this thought pattern occurs in situations beyond movie-watching. Further investigation using mDES, for example with other forms of media, and other methods of brain imaging, can improve our understanding of what lead to the onset of distracted states.</p><p>Although our study highlighted neural activity in sensory cortex and regions of association cortex with the frontoparietal system, we found less evidence for the hypothesized role of the DMN during the movie-watching experience. Notably, the pattern of ‘Episodic Knowledge’ identified by our analysis focuses on features of cognition such as knowledge, people, and oneself — all of which are terms that previous literature suggests could relate to the DMN (<xref ref-type="bibr" rid="bib57">Smallwood et al., 2021b</xref>; <xref ref-type="bibr" rid="bib68">Yang et al., 2023</xref>). However, despite this conceptual mapping, neither our voxel space nor our state space analysis highlighted that this experience was related to moments when brain activity was higher within the DMN (See <xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig6">6</xref>).</p><p>There are several possible methodological reasons why such a mapping within the DMN may nonetheless exist. For example, our choice of films (documentary, romance, and comedy) may have precluded a genre in which the DMN may play a more obvious role (e.g. mystery or suspense). Another possibility is that the DMN may be relevant to an understanding aspect of experience that is only captured during longer intervals of movie-watching, such as extended plot lines, unexpected events, or other features of movies that depend on the segmentation of a movie into different events (<xref ref-type="bibr" rid="bib17">Geerligs et al., 2022</xref>). We only sampled experience in short 10 min clips, so the DMN may relate to aspects of experience that are important for movie-watching over longer time periods. It is also possible that the unique features of the DMN make it difficult for our method to reveal its role in experience. The DMN is a spatially heterogeneous system and highly variable across individuals (<xref ref-type="bibr" rid="bib5">Braga and Buckner, 2017</xref>). Since our analytic approach links thought patterns in one set of individuals to brain activity in another, it could be challenging for this method to identify its role in movie-related thought patterns in a highly idiosyncratic brain network such as the DMN (<xref ref-type="bibr" rid="bib5">Braga and Buckner, 2017</xref>; <xref ref-type="bibr" rid="bib11">Daitch and Parvizi, 2018</xref>). This possibility could be easily tested by examining mappings between thought patterns and individuals using precision scanning methods (<xref ref-type="bibr" rid="bib22">Gordon et al., 2017</xref>). Studies have also highlighted that the DMN is heterogeneous in the functions it is involved in and, in particular, is hypothesized to shift flexibly from perpetually decoupled to coupled states (<xref ref-type="bibr" rid="bib72">Zhang et al., 2022</xref>). So, for example, the role this network is hypothesized to play in off-task or mind-wandering states (e.g. <xref ref-type="bibr" rid="bib9">Christoff et al., 2009</xref>) may obscure its’ role in perceptually coupled states (like movie-watching).</p><p>It is important to note that while our study does not establish what role DMN plays in movie-watching states, it does highlight a clear role for sensory systems in experiential states that are time-locked, or ‘coupled’, to events in the film. Thus, based on our study, whatever role the DMN plays during movie-watching, it is likely to be built upon the foundational role sensory systems play in our thoughts and feelings while we watch films. Consistent with this possibility, contemporary views on the DMN argue that its function arises from its’ topographical location in the cortex (<xref ref-type="bibr" rid="bib57">Smallwood et al., 2021b</xref>). According to this perspective, the DMN is located at the maximal distance from primary systems but also constitutes the apex of processing streams (like the ventral and dorsal streams <xref ref-type="bibr" rid="bib33">Margulies et al., 2016</xref>). We have previously argued that whatever role the DMN plays in cognition may entail interactions with primary systems, possibly through the transformation of neural signals along different processing streams (<xref ref-type="bibr" rid="bib57">Smallwood et al., 2021b</xref>). In other words, it is possible that the DMN plays a role in movie-watching that complements information processing in sensory input, an important but possibly less direct contribution to the movie-watching experience than regions in the visual or auditory cortex. Since the DMN is widely hypothesized to be important in movie-watching, we performed an exploratory functional connectivity analysis to examine whether the sensory regions we identified in our study are functionally coupled to the DMN at rest (see <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). This revealed that sensory regions identified in our study shared a common set of regions within the DMN (including anterior regions of the temporal lobe and the inferior frontal gyrus; see <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref> and <xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>). This analysis was exploratory, so any results should be treated with caution; however, it is consistent with the possibility that a more fine-grained precision mapping approach could identify the role these regions play in ongoing thought during movie-watching (<xref ref-type="bibr" rid="bib22">Gordon et al., 2017</xref>).</p><p>In summary, our study used a novel paradigm to establish the role primary systems play during our experiences while we watch movies. Nonetheless, important questions about other features of experience during move-watching remain unanswered. For example, patterns of ‘Verbal Detail’ were associated with moments in the films where auditory cortex activation was reduced. This may reflect a shift in attention away from the processing of the auditory input related to the movie towards evaluative thoughts about the people or events in the film, perhaps in the form of inner speech (<xref ref-type="bibr" rid="bib36">Mckeown et al., 2023</xref>). These thoughts may occur when participants form opinions about movie characters, elaborate on the context, or make inferences about the information they have encoded from the film (<xref ref-type="bibr" rid="bib1">Alderson-Day and Fernyhough, 2015</xref>). This possibility could be easily explored by examining more specific experience sampling items that directly target inner speech or comprehension questions that target inferential processing on events within the movies (See <xref ref-type="bibr" rid="bib51">Smallwood et al., 2008b</xref>).</p><p>Importantly, our study provides a novel method for answering these questions and others regarding the brain basis of experiences during films that can be applied simply and cost-effectively. As we have shown, mDES can be combined with existing brain activity, allowing information about both brain activity and experience to be determined at a relatively low cost. For example, the cost-effective nature of our paradigm makes it an ideal way to explore the relationship between cognition and neural activity during movie-watching during different genres of film. In neuroimaging, conclusions are often made using one film in naturalistic paradigm studies (<xref ref-type="bibr" rid="bib68">Yang et al., 2023</xref>). Although the current study only used three movie clips, restraining our ability to form strong conclusions regarding how different patterns of thought relate to specific genres of film, in the future, it will be possible to map cognition across a more extensive set of movies and discern whether there are specific types of experience that different genres of films engage. One of the major strengths of our approach, therefore, is the ability to map thoughts across groups of participants across a wide range of movies at a relatively low cost.</p><p>Nonetheless, this paradigm is not without limitations. This is the first study, as far as we know, that attempts to compare experiential reports in one sample of participants with brain activity in a second set of participants, and while the utility of this method enables us to understand the relationship between thought and brain activity during movies, it will be important to extend our analysis to mDES data during movie-watching while brain activity is recorded. In addition, our study is correlational in nature, and in the future, it could be useful to generate a more mechanistic understanding of how brain activity maps onto the participants experience. Our analysis shows that mDES is able to discriminate between films, highlighting its broad sensitivity to variation in semantic or affective content. Armed with this knowledge, we propose that in the future, researchers could derive mechanistic insights into how the semantic features may influence the mDES data. For example, it may be possible to ask participants to watch movies in a scrambled order to understand how the structure of semantic or information influences the mapping between brains and ongoing experience as measured by mDES. Finally, our study focused on mapping group-level patterns of experience onto group-level descriptions of brain activity. In the future it may be possible to adopt a ‘precision-mapping’ approach by measuring longer periods of experience using mDES and determining how the neural correlates of experience vary across individuals who watched the same movies while brain activity was collected (<xref ref-type="bibr" rid="bib22">Gordon et al., 2017</xref>). In the future, we anticipate that the ease with which our method can be applied to different groups of individuals and different types of media will make it possible to build a more comprehensive and culturally inclusive understanding of the links between brain activity and movie-watching experience.</p><p>Finally, it is worth considering whether the patterns of brain activity identified by our analysis reflect the stimuli that are processed during movie watching, or the cognitive and affective processing of this information. On the one hand, the regions we found were often within regions of sensory cortex, areas of the brain which are often ascribed basic stimulus processing functions (<xref ref-type="bibr" rid="bib29">Kaas and Collins, 2001</xref>). Moreover, according to perspectives on cognition derived from more traditional task paradigms, complex features of cognition, such as the regulation of thought, are often attributed to regions of association cortex, such as the dorsolateral prefrontal cortex (<xref ref-type="bibr" rid="bib58">Turnbull et al., 2019a</xref>). It is possible, based on these views that the identification of regions of visual and auditory cortex by our study reflects the participants attention to sensory input, rather than the complex analysis of these inputs that may be required for certain features of the movie watching experience. On the other hand, it is possible that the movie-watching state is a qualitatively different type of mental state to those that emerge in typical task situations. For example, unlike tasks, the movie-watching state is characterized by multi-modal sensory input, semantically rich themes, that evolve together to reveals a continuous narrative to the viewer. It is possible, therefore, that these features allow movies to engender a situation an absorbed state where a relatively higher amount of processing are achieved in sensory cortex than would occur in traditional task paradigms (when systems in association cortex may be needed to maintain information related to task rules). Important headway into addressing this uncertainty can be achieved by using mDES to compare the types of states that occur in different contexts (including both movies and tasks) and comparing the topography of brain activity associated with different states.</p></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Participant pool – laboratory sample</title><p>The sample consisted of 120 participants (98 women (81.7%), 17 men (14.2%), 5 non-binary or similar gender identity (3.3%); age: <italic>M</italic>=18.83, SD = 1.19, range of 18–23) who participated in the in-person laboratory study to watch three 11 min movie clips, responded to mDES probes, and completed a brief comprehension assessment. All participants spoke English, with 95% of the sample primarily residing in Canada (China [1.7%], India [0.8%], Nigeria [0.8%], USA [1.7%]). This study was granted ethics clearance by the Queen’s University General Research Ethics Board (#6036804). Participants were recruited between March 2023 and April 2023 through the Queen’s University Psychology Participant Pool. Participants provided written, informed consent via electronic documentation before participating in the research study. Participants were rewarded with one-course credit or $10.00 for their participation and were provided with a verbal and written debrief form upon completion of the study. All data and corresponding analysis scripts included in this manuscript are available via Mendeley Data (DOI: 10.17632/mgb7ftwr9d.1).</p></sec><sec id="s4-2"><title>Participant pool – brain data sample</title><p>See Aliko and colleagues for a description of the sample (<xref ref-type="bibr" rid="bib3">Aliko et al., 2020</xref>).</p></sec><sec id="s4-3"><title>Participant pool – resting-state sample</title><p>191 student volunteers (mean age = 20.1 ± 2.25 years, range 18–31; 123 females) with normal or corrected-to-normal vision and no history of neurological disorders participated in this study. Written informed consent was obtained from all subjects prior to the resting-state scan. The study was approved by the ethics committees of the Department of Psychology and York Neuroimaging Centre, University of York. Previous studies have used this data to examine the neural basis of memory and mind-wandering, including region-of-interest-based connectivity analysis and cortical thickness investigations (<xref ref-type="bibr" rid="bib30">Karapanagiotidis et al., 2017</xref>; <xref ref-type="bibr" rid="bib66">Wang et al., 2018</xref>; <xref ref-type="bibr" rid="bib14">Evans et al., 2020</xref>; <xref ref-type="bibr" rid="bib18">Gonzalez Alam et al., 2018</xref>; <xref ref-type="bibr" rid="bib19">Gonzalez Alam et al., 2019</xref>; <xref ref-type="bibr" rid="bib21">Gonzalez Alam et al., 2022</xref>; <xref ref-type="bibr" rid="bib20">Gonzalez Alam et al., 2021</xref>; <xref ref-type="bibr" rid="bib45">Poerio et al., 2017</xref>; <xref ref-type="bibr" rid="bib59">Turnbull et al., 2019b</xref>; <xref ref-type="bibr" rid="bib64">Vatansever et al., 2017</xref>).</p></sec><sec id="s4-4"><title>Procedure</title><p>Participants attended an individual in-person testing session at the laboratory at Queen’s University to watch movie clips after providing written informed consent and basic demographic information. Participants were assigned to a testing booth, a small room with a desk, a chair, a computer to present the stimuli, and headphones to listen to the audio stimuli. Participants had to attend to the computer screen to watch and listen to three randomly presented 11 min video clips. During each movie clip, participants were briefly interrupted five times to answer randomly assigned mDES probes about the content of their thoughts just prior to the probe. After the first minute of each clip, each probe was delivered once every two minutes, using a jittered technique, by assigning participants to a counterbalanced probe order to minimize the systematic impact of prior and later probes at any given sampling moment (see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref> for visualization). Once participants finished watching the three clips, they completed a 12-item comprehension questionnaire on Qualtrics, with four items related to information from each of the three movie clips (see <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1d</xref>).</p></sec><sec id="s4-5"><title>Multi-dimensional experience sampling (mDES)</title><p>Participants received 16 total mDES probes across the three clips, five for each, and all responses were made with respect to their thoughts just before the probe interrupted their viewing. No probes were administered within the first minute of the clip — the first possible probe was administered at the 75 s mark to allow participants to situate themselves with the context of the movie clip. Each of the 16 mDES questions appeared in a randomized order, and participants were asked to use the directional arrow keys to move a slider across the screen to indicate, on a scale of 1 (not at all) to 10 (completely), how much that particular feature characterized their thoughts. The specific items used in this experiment are presented in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1a</xref>.</p></sec><sec id="s4-6"><title>Probe orders</title><p>There were 16 probe orders that a participant could be assigned to for each movie, which determined the delivery time of the five mDES probes throughout each 11 min clip. Each subject ID was assigned to three different probe orders for each of the three films, and no subject ID was given the same probe order twice. This was achieved by creating a matrix of equally distributed probe orders across subject IDs to ensure each moment in the movie was probed an equal amount of times while uniquely distributing probes to control for order effects. Probe orders were designed to sample participants at every 15 s interval of the entire movie clip but only probed a single participant five times per clip. This allowed us to sample experience as frequently as possible without interrupting participants from naturalistic viewing by oversampling or too frequent probes and to control for ordering effects from the delivery time of the other probes. Each participant received a probe approximately every two minutes using a jittered technique. The first eight probe orders do not share any of the same probe delivery times, whereas the latter eight probe orders (9-16) have been shuffled so that they share one probe time with only one of the orders from the former eight orders. Across orders 9–16, each probe from the first eight orders is repeated in a different combination of probes so that mDES responses at each probe are derived from participants in two different orders. See (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p></sec><sec id="s4-7"><title>Movie clip stimuli</title><p>Movie stimuli were presented in 11 min scenes from <italic>Citizenfour</italic>, <italic>Little Miss Sunshine</italic>, and <italic>500 Days of Summer</italic>. Stimuli were selected from the Naturalistic Neuroimaging Database (NNDb; <xref ref-type="bibr" rid="bib3">Aliko et al., 2020</xref>) and chosen based on genre, and they were cut from the full-length movie down to 11 min clips. Participants were informed they would watch three movie clips from different genres (romance, comedy, documentary) but were presented randomly. Written instructions were presented on screen at the beginning of each clip. After watching the three clips and responding to the mDES probes, participants were presented with a Qualtrics questionnaire to complete a comprehension test on the content of each film clip.</p></sec><sec id="s4-8"><title>Comprehension questions</title><p>Participants completed a comprehension test of 12 questions, four from each movie. The questions were created collaboratively to test general knowledge about the movie that would otherwise not be common sense and cover events during the clip’s beginning, middle, and end. An example of one of the comprehension questions was ‘What breakfast item did Olive order a la mode?’ for the movie clip <italic>Little Miss Sunshine</italic>. A table of all the questions with corresponding answers can be found in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1d</xref>. Participants responded using 1–2 words and were otherwise instructed to enter ‘?’ if they had no answer.</p></sec><sec id="s4-9"><title>Brain analysis</title><p>Our analyses used brain data acquired and shared by the NNDb, an open-access database of pre-processed MNI 2 mm fMRI data (TR = 1) of participants who watched one of 10 full-length movies (<xref ref-type="bibr" rid="bib3">Aliko et al., 2020</xref>). We utilized MNI 2 mm fMRI data corresponding to participants who watched <italic>Little Miss Sunshine</italic> (n=6), <italic>Citizenfour</italic> (n=18), and <italic>500 Days of Summer</italic> (n=20). The specific pre-processing steps applied to the brain data and specific details of the sample are described in <xref ref-type="bibr" rid="bib3">Aliko et al., 2020</xref>.</p></sec><sec id="s4-10"><title>Voxel-space analysis</title><p>Our analysis used the pre-processed data from <xref ref-type="bibr" rid="bib3">Aliko et al., 2020</xref>. The first step in our analysis was to extract the brain activity of each individual for the 10 min section that we sampled in experience using mDES. To map the mDES time series onto these data, we created a mean time series for each movie, which described the mDES experience, averaged across 40 observations at every 15 s interval. Next, we interpolated this time series to generate a time series of experiences that matched the TR used to sample brain activity in Sample 1 (1 s). Next, the interpolated time series for each PCA for each film were included as regressors for each individual’s brain activity (i.e. four regressors for each movie). Finally, we used FLAME as implemented in FSL to perform a group-level analysis across the three movie clips. In this analysis, we set the cluster-forming threshold at z=3.1 and corrected for FWE by accounting for the number of voxels in the brain, the three movies we examined, and the four PCAs in each movie. This resulted in the correction of the FWE p-value from FSL p&lt;0.0025.</p></sec><sec id="s4-11"><title>State-space analysis</title><p>To create the ‘state-space’ coordinates, we first calculated a group-averaged timeseries for each movie. To do this, we first z-scored each individual’s timeseries data and calculated the mean activity in each voxel at each TR across the whole sample, resulting in a group-averaged brain volume at each TR. Next, we applied a binarized mask to each group-averaged brain volume at each TR. This mask was generated based on the (cortical and subcortical) gradient maps openly available on Neurovault (<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/neurovault.collection">https://identifiers.org/neurovault.collection</ext-link>:1598). These gradient maps were produced from the decomposition of the Human Connectome Project resting-state fMRI data (<xref ref-type="bibr" rid="bib33">Margulies et al., 2016</xref>). Then, we calculated the (spearman rank) correlation between each group-averaged per-TR brain map and each of the first five gradient maps. Consistent with published literature, the results of these correlations constitute the coordinates of each moment of the film in the 5D Brain space (<xref ref-type="bibr" rid="bib36">Mckeown et al., 2023</xref>). An example of these coordinates is presented in the upper left panel of <xref ref-type="fig" rid="fig5">Figure 5</xref>. The code for this analysis is openly available at <ext-link ext-link-type="uri" xlink:href="https://github.com/willstrawson/StateSpace">https://github.com/willstrawson/StateSpace</ext-link> (v1.0.0), copy archived at <xref ref-type="bibr" rid="bib37">Mckeown et al., 2024</xref> (<ext-link ext-link-type="uri" xlink:href="https://zenodo.org/records/14112469">https://zenodo.org/records/14112469</ext-link>).</p></sec><sec id="s4-12"><title>Cognitive decoding</title><p>Connectivity maps were uploaded to Neurovault (<xref ref-type="bibr" rid="bib23">Gorgolewski et al., 2015</xref>; <ext-link ext-link-type="uri" xlink:href="https://neurovault.org/collections/13821/">https://neurovault.org/collections/13821/</ext-link>) and decoded using Neurosynth (<xref ref-type="bibr" rid="bib69">Yarkoni et al., 2011</xref>). Neurosynth is an automated analysis tool that uses text-mining approaches to extract terms from neuroimaging articles that typically co-occur with specific peak coordinates of activation. It can be used to generate a set of terms frequently associated with a spatial map. The results of cognitive decoding were rendered as word clouds using in-house scripts implemented in Python. We excluded terms referring to neuroanatomy (e.g<italic>.</italic> ‘inferior’ or ‘sulcus’), as well as the second occurrence of repeated terms (e.g<italic>.</italic> ‘semantic’ and ‘semantics’). The size of each word in the word cloud relates to the frequency of that term across studies.</p></sec><sec id="s4-13"><title>Analysis of intrinsic functional connectivity using resting-state fMRI</title><p>Our analysis additionally used resting state cohort data (see below) to seed the maps created from each of the four thought pattern time series regressors from the prior analysis. We used this seed-based analysis to see if different resting state networks converge with the maps we have generated from movie-watching.</p></sec><sec id="s4-14"><title>Pre-processing</title><p>Pre-processing and statistical analyses of resting-state data were performed using the CONN functional connectivity toolbox V.20a (<ext-link ext-link-type="uri" xlink:href="http://www.nitrc.org/projects/conn">http://www.nitrc.org/projects/conn</ext-link>; <xref ref-type="bibr" rid="bib67">Whitfield-Gabrieli and Nieto-Castanon, 2012</xref>) implemented through SPM (Version 12.0) and MATLAB (Version 19 a). For pre-processing, functional volumes were slice-time (bottom-up, interleaved) and motion-corrected, skull-stripped and co-registered to the high-resolution structural image, spatially normalized to the Montreal Neurological Institute (MNI) space using the unified-segmentation algorithm, smoothed with a 6 mm FWHM Gaussian kernel, and band-passed filtered (0.008–0.09 Hz) to reduce low-frequency drift and noise effects. A pre-processing pipeline of nuisance regression included motion (12 parameters: the six translation and rotation parameters and their temporal derivatives), scrubbing (outlier volumes were identified through the composite artifact detection algorithm ART in CONN with conservative settings, including scan-by-scan change in global signal z-value threshold = 3; subject motion threshold = 5 mm; differential motion and composite motion exceeding 95% percentile in the normative sample) and CompCor components (the first five) attributable to the signal from white matter and CSF (<xref ref-type="bibr" rid="bib4">Behzadi et al., 2007</xref>) as well as a linear detrending term, eliminating the need for global signal normalization (<xref ref-type="bibr" rid="bib6">Chai et al., 2012</xref>; <xref ref-type="bibr" rid="bib42">Murphy et al., 2009</xref>).</p></sec><sec id="s4-15"><title>Seed selection and analysis</title><p>Intrinsic connectivity seeds were binarized masks derived from voxel-space analysis using FLAME through FSL. We excluded all non-grey matter voxels that fell within these masks. We performed seed-to-voxel analyses convolved with a canonical hemodynamic response function for each seed. At the group-level, analyses were conducted using CONN with cluster correction at p&lt;0.05 and a threshold of p-FDR=0.001 (two-tailed) to define contiguous clusters.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Formal analysis, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Resources, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Validation, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Formal analysis, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Formal analysis, Validation, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con7"><p>Writing – review and editing</p></fn><fn fn-type="con" id="con8"><p>Conceptualization, Writing – review and editing</p></fn><fn fn-type="con" id="con9"><p>Conceptualization, Writing – review and editing</p></fn><fn fn-type="con" id="con10"><p>Writing – review and editing</p></fn><fn fn-type="con" id="con11"><p>Data curation, Formal analysis, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con12"><p>Conceptualization, Writing – review and editing</p></fn><fn fn-type="con" id="con13"><p>Writing – review and editing</p></fn><fn fn-type="con" id="con14"><p>Writing – review and editing</p></fn><fn fn-type="con" id="con15"><p>Writing – review and editing</p></fn><fn fn-type="con" id="con16"><p>Writing – review and editing</p></fn><fn fn-type="con" id="con17"><p>Conceptualization, Writing – review and editing</p></fn><fn fn-type="con" id="con18"><p>Conceptualization, Writing – review and editing</p></fn><fn fn-type="con" id="con19"><p>Conceptualization, Writing – review and editing</p></fn><fn fn-type="con" id="con20"><p>Conceptualization, Resources, Writing – review and editing</p></fn><fn fn-type="con" id="con21"><p>Conceptualization, Writing – review and editing</p></fn><fn fn-type="con" id="con22"><p>Conceptualization, Software, Formal analysis, Visualization, Writing – review and editing</p></fn><fn fn-type="con" id="con23"><p>Conceptualization, Resources, Supervision, Funding acquisition, Validation, Investigation, Visualization, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Active, informed consent to participate, obtain, and publish anonymized data was collected from each participant. The specific ethical approval we obtained were derived from the guidelines set out by Queen's University General Research Ethics Board (GREB) (#6036804).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Supplementary table data for corresponding manuscript results.</title><p><bold>(a)</bold> Multi-dimensional Experience sampling (mDES). (<bold>b)</bold> Percent variance explained by principal components by movie <bold>(c)</bold> Linear Mixed Models of Variance in Thoughts across Movies. <bold>(d)</bold> Movie Comprehension Questions. <bold>(e)</bold> Linear Mixed Models of Comprehension model. <bold>(f)</bold> FSL FEAT Query Parameter Estimates. <bold>(g)</bold> Grand average of Gradient score by movie. <bold>(h)</bold> Functional Connectivity Cluster Analysis (FLAME). <bold>(i)</bold> Neurosynth Decoder Analysis. <bold>(j)</bold> Linear Mixed Models of Gradients 1–5 Fixed Effects for each Thought Pattern</p></caption><media xlink:href="elife-97731-supp1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-97731-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All data and corresponding analysis scripts included in this manuscript are available via Mendeley Data (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.17632/mgb7ftwr9d.1">https://doi.org/10.17632/mgb7ftwr9d.1</ext-link>).</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Wallace</surname><given-names>RS</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Mapping patterns of thought onto brain activity during movie-watching Data and Scripts</data-title><source>Mendeley Data</source><pub-id pub-id-type="doi">10.17632/mgb7ftwr9d.1</pub-id></element-citation></p><p>The following previously published datasets were used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset2"><person-group person-group-type="author"><name><surname>Aliko</surname><given-names>S</given-names></name><name><surname>Huang</surname><given-names>J</given-names></name><name><surname>Gheorghiu</surname><given-names>F</given-names></name><name><surname>Meliss</surname><given-names>S</given-names></name><name><surname>Skipper</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Naturalistic Neuroimaging Database</data-title><source>OpenNeuro</source><pub-id pub-id-type="doi">10.18112/openneuro.ds002837.v2.0.0</pub-id></element-citation></p><p><element-citation publication-type="data" specific-use="references" id="dataset3"><person-group person-group-type="author"><name><surname>Karapanagiotidis</surname><given-names>T</given-names></name><name><surname>Bernhardt</surname><given-names>BC</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><data-title>Tracking thoughts: Exploring the neural architecture of mental time travel during mind-wandering</data-title><source>NeuroVault</source><pub-id pub-id-type="accession" xlink:href="https://identifiers.org/neurovault.collection:1448">1448</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alderson-Day</surname><given-names>B</given-names></name><name><surname>Fernyhough</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Inner speech: development, cognitive functions, phenomenology, and neurobiology</article-title><source>Psychological Bulletin</source><volume>141</volume><fpage>931</fpage><lpage>965</lpage><pub-id pub-id-type="doi">10.1037/bul0000021</pub-id><pub-id pub-id-type="pmid">26011789</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alexander-Bloch</surname><given-names>AF</given-names></name><name><surname>Shou</surname><given-names>H</given-names></name><name><surname>Liu</surname><given-names>S</given-names></name><name><surname>Satterthwaite</surname><given-names>TD</given-names></name><name><surname>Glahn</surname><given-names>DC</given-names></name><name><surname>Shinohara</surname><given-names>RT</given-names></name><name><surname>Vandekar</surname><given-names>SN</given-names></name><name><surname>Raznahan</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>On testing for spatial correspondence between maps of human brain structure and function</article-title><source>NeuroImage</source><volume>178</volume><fpage>540</fpage><lpage>551</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.05.070</pub-id><pub-id pub-id-type="pmid">29860082</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aliko</surname><given-names>S</given-names></name><name><surname>Huang</surname><given-names>J</given-names></name><name><surname>Gheorghiu</surname><given-names>F</given-names></name><name><surname>Meliss</surname><given-names>S</given-names></name><name><surname>Skipper</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A naturalistic neuroimaging database for understanding the brain using ecological stimuli</article-title><source>Scientific Data</source><volume>7</volume><elocation-id>347</elocation-id><pub-id pub-id-type="doi">10.1038/s41597-020-00680-2</pub-id><pub-id pub-id-type="pmid">33051448</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behzadi</surname><given-names>H</given-names></name><name><surname>Hadipour</surname><given-names>NL</given-names></name><name><surname>Mirzaei</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A density functional study of (17)O, (14)N and (2)H electric field gradient tensors in the real crystalline structure of alpha-glycine</article-title><source>Biophysical Chemistry</source><volume>125</volume><fpage>179</fpage><lpage>183</lpage><pub-id pub-id-type="doi">10.1016/j.bpc.2006.07.010</pub-id><pub-id pub-id-type="pmid">16914262</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braga</surname><given-names>RM</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Parallel interdigitated distributed networks within the individual estimated by intrinsic functional connectivity</article-title><source>Neuron</source><volume>95</volume><fpage>457</fpage><lpage>471</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.038</pub-id><pub-id pub-id-type="pmid">28728026</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chai</surname><given-names>XJ</given-names></name><name><surname>Castañón</surname><given-names>AN</given-names></name><name><surname>Ongür</surname><given-names>D</given-names></name><name><surname>Whitfield-Gabrieli</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Anticorrelations in resting state networks without global signal regression</article-title><source>NeuroImage</source><volume>59</volume><fpage>1420</fpage><lpage>1428</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2011.08.048</pub-id><pub-id pub-id-type="pmid">21889994</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>LJ</given-names></name><name><surname>Jolly</surname><given-names>E</given-names></name><name><surname>Cheong</surname><given-names>JH</given-names></name><name><surname>Rapuano</surname><given-names>KM</given-names></name><name><surname>Greenstein</surname><given-names>N</given-names></name><name><surname>Chen</surname><given-names>P-HA</given-names></name><name><surname>Manning</surname><given-names>JR</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Endogenous variation in ventromedial prefrontal cortex state dynamics during naturalistic viewing reflects affective experience</article-title><source>Science Advances</source><volume>7</volume><elocation-id>eabf7129</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.abf7129</pub-id><pub-id pub-id-type="pmid">33893106</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chenot</surname><given-names>Q</given-names></name><name><surname>Lepron</surname><given-names>E</given-names></name><name><surname>De Boissezon</surname><given-names>X</given-names></name><name><surname>Scannella</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Functional connectivity within the fronto-parietal network predicts complex task performance: a fNIRS Study</article-title><source>Frontiers in Neuroergonomics</source><volume>2</volume><elocation-id>718176</elocation-id><pub-id pub-id-type="doi">10.3389/fnrgo.2021.718176</pub-id><pub-id pub-id-type="pmid">38235214</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Christoff</surname><given-names>K</given-names></name><name><surname>Gordon</surname><given-names>AM</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Smith</surname><given-names>R</given-names></name><name><surname>Schooler</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Experience sampling during fMRI reveals default network and executive system contributions to mind wandering</article-title><source>PNAS</source><volume>106</volume><fpage>8719</fpage><lpage>8724</lpage><pub-id pub-id-type="doi">10.1073/pnas.0900234106</pub-id><pub-id pub-id-type="pmid">19433790</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cole</surname><given-names>MW</given-names></name><name><surname>Schneider</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>The cognitive control network: Integrated cortical regions with dissociable functions</article-title><source>NeuroImage</source><volume>37</volume><fpage>343</fpage><lpage>360</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.03.071</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Daitch</surname><given-names>AL</given-names></name><name><surname>Parvizi</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Spatial and temporal heterogeneity of neural responses in human posteromedial cortex</article-title><source>PNAS</source><volume>115</volume><fpage>4785</fpage><lpage>4790</lpage><pub-id pub-id-type="doi">10.1073/pnas.1721714115</pub-id><pub-id pub-id-type="pmid">29666262</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Demertzi</surname><given-names>A</given-names></name><name><surname>Tagliazucchi</surname><given-names>E</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Deco</surname><given-names>G</given-names></name><name><surname>Barttfeld</surname><given-names>P</given-names></name><name><surname>Raimondo</surname><given-names>F</given-names></name><name><surname>Martial</surname><given-names>C</given-names></name><name><surname>Fernández-Espejo</surname><given-names>D</given-names></name><name><surname>Rohaut</surname><given-names>B</given-names></name><name><surname>Voss</surname><given-names>HU</given-names></name><name><surname>Schiff</surname><given-names>ND</given-names></name><name><surname>Owen</surname><given-names>AM</given-names></name><name><surname>Laureys</surname><given-names>S</given-names></name><name><surname>Naccache</surname><given-names>L</given-names></name><name><surname>Sitt</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Human consciousness is supported by dynamic complex patterns of brain signal coordination</article-title><source>Science Advances</source><volume>5</volume><elocation-id>eaat7603</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.aat7603</pub-id><pub-id pub-id-type="pmid">30775433</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>D’Esposito</surname><given-names>M</given-names></name><name><surname>Postle</surname><given-names>BR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The cognitive neuroscience of working memory</article-title><source>Annual Review of Psychology</source><volume>66</volume><fpage>115</fpage><lpage>142</lpage><pub-id pub-id-type="doi">10.1146/annurev-psych-010814-015031</pub-id><pub-id pub-id-type="pmid">25251486</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Evans</surname><given-names>M</given-names></name><name><surname>Krieger-Redwood</surname><given-names>K</given-names></name><name><surname>Gonzalez Alam</surname><given-names>TRJ</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Controlled semantic summation correlates with intrinsic connectivity between default mode and control networks</article-title><source>Cortex</source><volume>129</volume><fpage>356</fpage><lpage>375</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2020.04.032</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Finn</surname><given-names>ES</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Is it time to put rest to rest?</article-title><source>Trends in Cognitive Sciences</source><volume>25</volume><fpage>1021</fpage><lpage>1032</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2021.09.005</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Finn</surname><given-names>ES</given-names></name><name><surname>Bandettini</surname><given-names>PA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Movie-watching outperforms rest for functional connectivity-based prediction of behavior</article-title><source>NeuroImage</source><volume>235</volume><elocation-id>117963</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2021.117963</pub-id><pub-id pub-id-type="pmid">33813007</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geerligs</surname><given-names>L</given-names></name><name><surname>Gözükara</surname><given-names>D</given-names></name><name><surname>Oetringer</surname><given-names>D</given-names></name><name><surname>Campbell</surname><given-names>KL</given-names></name><name><surname>van Gerven</surname><given-names>M</given-names></name><name><surname>Güçlü</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A partially nested cortical hierarchy of neural states underlies event segmentation in the human brain</article-title><source>eLife</source><volume>11</volume><elocation-id>e77430</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.77430</pub-id><pub-id pub-id-type="pmid">36111671</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gonzalez Alam</surname><given-names>T</given-names></name><name><surname>Murphy</surname><given-names>C</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Meaningful inhibition: exploring the role of meaning and modality in response inhibition</article-title><source>NeuroImage</source><volume>181</volume><fpage>108</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.06.074</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gonzalez Alam</surname><given-names>TRDJ</given-names></name><name><surname>Karapanagiotidis</surname><given-names>T</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Degrees of lateralisation in semantic cognition: Evidence from intrinsic connectivity</article-title><source>NeuroImage</source><volume>202</volume><elocation-id>116089</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116089</pub-id><pub-id pub-id-type="pmid">31419614</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gonzalez Alam</surname><given-names>TRJ</given-names></name><name><surname>Krieger-Redwood</surname><given-names>K</given-names></name><name><surname>Evans</surname><given-names>M</given-names></name><name><surname>Rice</surname><given-names>GE</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Intrinsic connectivity of anterior temporal lobe relates to individual differences in semantic retrieval for landmarks</article-title><source>Cortex</source><volume>134</volume><fpage>76</fpage><lpage>91</lpage><pub-id pub-id-type="doi">10.1016/j.cortex.2020.10.007</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gonzalez Alam</surname><given-names>TRDJ</given-names></name><name><surname>Mckeown</surname><given-names>BLA</given-names></name><name><surname>Gao</surname><given-names>Z</given-names></name><name><surname>Bernhardt</surname><given-names>B</given-names></name><name><surname>Vos de Wael</surname><given-names>R</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A tale of two gradients: differences between the left and right hemispheres predict semantic cognition</article-title><source>Brain Structure &amp; Function</source><volume>227</volume><fpage>631</fpage><lpage>654</lpage><pub-id pub-id-type="doi">10.1007/s00429-021-02374-w</pub-id><pub-id pub-id-type="pmid">34510282</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gordon</surname><given-names>EM</given-names></name><name><surname>Laumann</surname><given-names>TO</given-names></name><name><surname>Gilmore</surname><given-names>AW</given-names></name><name><surname>Newbold</surname><given-names>DJ</given-names></name><name><surname>Greene</surname><given-names>DJ</given-names></name><name><surname>Berg</surname><given-names>JJ</given-names></name><name><surname>Ortega</surname><given-names>M</given-names></name><name><surname>Hoyt-Drazen</surname><given-names>C</given-names></name><name><surname>Gratton</surname><given-names>C</given-names></name><name><surname>Sun</surname><given-names>H</given-names></name><name><surname>Hampton</surname><given-names>JM</given-names></name><name><surname>Coalson</surname><given-names>RS</given-names></name><name><surname>Nguyen</surname><given-names>AL</given-names></name><name><surname>McDermott</surname><given-names>KB</given-names></name><name><surname>Shimony</surname><given-names>JS</given-names></name><name><surname>Snyder</surname><given-names>AZ</given-names></name><name><surname>Schlaggar</surname><given-names>BL</given-names></name><name><surname>Petersen</surname><given-names>SE</given-names></name><name><surname>Nelson</surname><given-names>SM</given-names></name><name><surname>Dosenbach</surname><given-names>NUF</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Precision functional mapping of individual human brains</article-title><source>Neuron</source><volume>95</volume><fpage>791</fpage><lpage>807</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.07.011</pub-id><pub-id pub-id-type="pmid">28757305</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorgolewski</surname><given-names>KJ</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name><name><surname>Rivera</surname><given-names>G</given-names></name><name><surname>Schwarz</surname><given-names>Y</given-names></name><name><surname>Ghosh</surname><given-names>SS</given-names></name><name><surname>Maumet</surname><given-names>C</given-names></name><name><surname>Sochat</surname><given-names>VV</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name><name><surname>Poline</surname><given-names>J-B</given-names></name><name><surname>Yarkoni</surname><given-names>T</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>NeuroVault.org: a web-based repository for collecting and sharing unthresholded statistical maps of the human brain</article-title><source>Frontiers in Neuroinformatics</source><volume>9</volume><elocation-id>8</elocation-id><pub-id pub-id-type="doi">10.3389/fninf.2015.00008</pub-id><pub-id pub-id-type="pmid">25914639</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Furman</surname><given-names>O</given-names></name><name><surname>Clark</surname><given-names>D</given-names></name><name><surname>Dudai</surname><given-names>Y</given-names></name><name><surname>Davachi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2008">2008a</year><article-title>Enhanced intersubject correlations during movie viewing correlate with successful episodic encoding</article-title><source>Neuron</source><volume>57</volume><fpage>452</fpage><lpage>462</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2007.12.009</pub-id><pub-id pub-id-type="pmid">18255037</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Landesman</surname><given-names>O</given-names></name><name><surname>Knappmeyer</surname><given-names>B</given-names></name><name><surname>Vallines</surname><given-names>I</given-names></name><name><surname>Rubin</surname><given-names>N</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2008">2008b</year><article-title>Neurocinematics: the neuroscience of film</article-title><source>Projections</source><volume>2</volume><fpage>1</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.3167/proj.2008.020102</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haxby</surname><given-names>JV</given-names></name><name><surname>Gobbini</surname><given-names>MI</given-names></name><name><surname>Nastase</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Naturalistic stimuli reveal a dominant role for agentic action in visual representation</article-title><source>NeuroImage</source><volume>216</volume><elocation-id>116561</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116561</pub-id><pub-id pub-id-type="pmid">32001371</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ho</surname><given-names>NSP</given-names></name><name><surname>Poerio</surname><given-names>G</given-names></name><name><surname>Konu</surname><given-names>D</given-names></name><name><surname>Turnbull</surname><given-names>A</given-names></name><name><surname>Sormaz</surname><given-names>M</given-names></name><name><surname>Leech</surname><given-names>R</given-names></name><name><surname>Bernhardt</surname><given-names>B</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Facing up to the wandering mind: Patterns of off-task laboratory thought are associated with stronger neural recruitment of right fusiform cortex while processing facial stimuli</article-title><source>NeuroImage</source><volume>214</volume><elocation-id>116765</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116765</pub-id><pub-id pub-id-type="pmid">32213314</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iwata</surname><given-names>T</given-names></name><name><surname>Yanagisawa</surname><given-names>T</given-names></name><name><surname>Ikegaya</surname><given-names>Y</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Fukuma</surname><given-names>R</given-names></name><name><surname>Oshino</surname><given-names>S</given-names></name><name><surname>Tani</surname><given-names>N</given-names></name><name><surname>Khoo</surname><given-names>HM</given-names></name><name><surname>Kishima</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Hippocampal sharp-wave ripples correlate with periods of naturally occurring self-generated thoughts in humans</article-title><source>Nature Communications</source><volume>15</volume><elocation-id>4078</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-024-48367-1</pub-id><pub-id pub-id-type="pmid">38778048</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaas</surname><given-names>JH</given-names></name><name><surname>Collins</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The organization of sensory cortex</article-title><source>Current Opinion in Neurobiology</source><volume>11</volume><fpage>498</fpage><lpage>504</lpage><pub-id pub-id-type="doi">10.1016/s0959-4388(00)00240-3</pub-id><pub-id pub-id-type="pmid">11502398</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Karapanagiotidis</surname><given-names>T</given-names></name><name><surname>Bernhardt</surname><given-names>BC</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Tracking thoughts: exploring the neural architecture of mental time travel during mind-wandering</article-title><source>NeuroImage</source><volume>147</volume><fpage>272</fpage><lpage>281</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.12.031</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Konu</surname><given-names>D</given-names></name><name><surname>Turnbull</surname><given-names>A</given-names></name><name><surname>Karapanagiotidis</surname><given-names>T</given-names></name><name><surname>Wang</surname><given-names>H-T</given-names></name><name><surname>Brown</surname><given-names>LR</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A role for the ventromedial prefrontal cortex in self-generated episodic social cognition</article-title><source>NeuroImage</source><volume>218</volume><elocation-id>116977</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116977</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Konu</surname><given-names>D</given-names></name><name><surname>Mckeown</surname><given-names>B</given-names></name><name><surname>Turnbull</surname><given-names>A</given-names></name><name><surname>Siu Ping Ho</surname><given-names>N</given-names></name><name><surname>Karapanagiotidis</surname><given-names>T</given-names></name><name><surname>Vanderwal</surname><given-names>T</given-names></name><name><surname>McCall</surname><given-names>C</given-names></name><name><surname>Tipper</surname><given-names>SP</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Exploring patterns of ongoing thought under naturalistic and conventional task-based conditions</article-title><source>Consciousness and Cognition</source><volume>93</volume><elocation-id>103139</elocation-id><pub-id pub-id-type="doi">10.1016/j.concog.2021.103139</pub-id><pub-id pub-id-type="pmid">34111726</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Ghosh</surname><given-names>SS</given-names></name><name><surname>Goulas</surname><given-names>A</given-names></name><name><surname>Falkiewicz</surname><given-names>M</given-names></name><name><surname>Huntenburg</surname><given-names>JM</given-names></name><name><surname>Langs</surname><given-names>G</given-names></name><name><surname>Bezgin</surname><given-names>G</given-names></name><name><surname>Eickhoff</surname><given-names>SB</given-names></name><name><surname>Castellanos</surname><given-names>FX</given-names></name><name><surname>Petrides</surname><given-names>M</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Situating the default-mode network along a principal gradient of macroscale cortical organization</article-title><source>PNAS</source><volume>113</volume><fpage>12574</fpage><lpage>12579</lpage><pub-id pub-id-type="doi">10.1073/pnas.1608282113</pub-id><pub-id pub-id-type="pmid">27791099</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Matusz</surname><given-names>PJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><source>Are we ready for real-world neuroscience?</source><publisher-name>MIT Press</publisher-name><pub-id pub-id-type="doi">10.1162/jocn_e_01276</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mckeown</surname><given-names>B</given-names></name><name><surname>Poerio</surname><given-names>GL</given-names></name><name><surname>Strawson</surname><given-names>WH</given-names></name><name><surname>Martinon</surname><given-names>LM</given-names></name><name><surname>Riby</surname><given-names>LM</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>McCall</surname><given-names>C</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The impact of social isolation and changes in work patterns on ongoing thought during the first COVID-19 lockdown in the United Kingdom</article-title><source>PNAS</source><volume>118</volume><elocation-id>e2102565118</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2102565118</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mckeown</surname><given-names>B</given-names></name><name><surname>Strawson</surname><given-names>WH</given-names></name><name><surname>Zhang</surname><given-names>M</given-names></name><name><surname>Turnbull</surname><given-names>A</given-names></name><name><surname>Konu</surname><given-names>D</given-names></name><name><surname>Karapanagiotidis</surname><given-names>T</given-names></name><name><surname>Wang</surname><given-names>H-T</given-names></name><name><surname>Leech</surname><given-names>R</given-names></name><name><surname>Xu</surname><given-names>T</given-names></name><name><surname>Hardikar</surname><given-names>S</given-names></name><name><surname>Bernhardt</surname><given-names>B</given-names></name><name><surname>Margulies</surname><given-names>D</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Wammes</surname><given-names>J</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Experience sampling reveals the role that covert goal states play in task-relevant behavior</article-title><source>Scientific Reports</source><volume>13</volume><elocation-id>21710</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-023-48857-0</pub-id><pub-id pub-id-type="pmid">38066069</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Mckeown</surname><given-names>B</given-names></name><name><surname>Strawson</surname><given-names>W</given-names></name><name><surname>Goodall-Halliwell</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>StateSpace</data-title><version designator="swh:1:rev:5209c4e8f999f6c22011f1e4dd5e74183ce8c852">swh:1:rev:5209c4e8f999f6c22011f1e4dd5e74183ce8c852</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:933bb0a2d3762541fd313feb8731f7e2555b6443;origin=https://github.com/willstrawson/StateSpace;visit=swh:1:snp:d557954f3eebe4f3d2bfb7020c683c7111e2fd70;anchor=swh:1:rev:5209c4e8f999f6c22011f1e4dd5e74183ce8c852">https://archive.softwareheritage.org/swh:1:dir:933bb0a2d3762541fd313feb8731f7e2555b6443;origin=https://github.com/willstrawson/StateSpace;visit=swh:1:snp:d557954f3eebe4f3d2bfb7020c683c7111e2fd70;anchor=swh:1:rev:5209c4e8f999f6c22011f1e4dd5e74183ce8c852</ext-link></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McVay</surname><given-names>JC</given-names></name><name><surname>Kane</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Does mind wandering reflect executive function or executive failure? Comment on Smallwood and Schooler (2006) and Watkins (2008)</article-title><source>Psychological Bulletin</source><volume>136</volume><fpage>188</fpage><lpage>197</lpage><pub-id pub-id-type="doi">10.1037/a0018298</pub-id><pub-id pub-id-type="pmid">20192557</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McVay</surname><given-names>JC</given-names></name><name><surname>Kane</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Drifting from slow to “D’oh!”: working memory capacity and mind wandering predict extreme reaction times and executive control errors</article-title><source>Journal of Experimental Psychology. Learning, Memory, and Cognition</source><volume>38</volume><fpage>525</fpage><lpage>549</lpage><pub-id pub-id-type="doi">10.1037/a0025896</pub-id><pub-id pub-id-type="pmid">22004270</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Medea</surname><given-names>B</given-names></name><name><surname>Karapanagiotidis</surname><given-names>T</given-names></name><name><surname>Konishi</surname><given-names>M</given-names></name><name><surname>Ottaviani</surname><given-names>C</given-names></name><name><surname>Margulies</surname><given-names>D</given-names></name><name><surname>Bernasconi</surname><given-names>A</given-names></name><name><surname>Bernasconi</surname><given-names>N</given-names></name><name><surname>Bernhardt</surname><given-names>BC</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>How do we decide what to do? Resting-state connectivity patterns and components of self-generated thought linked to the development of more concrete personal goals</article-title><source>Experimental Brain Research</source><volume>236</volume><fpage>2469</fpage><lpage>2481</lpage><pub-id pub-id-type="doi">10.1007/s00221-016-4729-y</pub-id><pub-id pub-id-type="pmid">27443852</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mulholland</surname><given-names>B</given-names></name><name><surname>Goodall-Halliwell</surname><given-names>I</given-names></name><name><surname>Wallace</surname><given-names>R</given-names></name><name><surname>Chitiz</surname><given-names>L</given-names></name><name><surname>Mckeown</surname><given-names>B</given-names></name><name><surname>Rastan</surname><given-names>A</given-names></name><name><surname>Poerio</surname><given-names>GL</given-names></name><name><surname>Leech</surname><given-names>R</given-names></name><name><surname>Turnbull</surname><given-names>A</given-names></name><name><surname>Klein</surname><given-names>A</given-names></name><name><surname>Milham</surname><given-names>M</given-names></name><name><surname>Wammes</surname><given-names>JD</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Patterns of ongoing thought in the real world</article-title><source>Consciousness and Cognition</source><volume>114</volume><elocation-id>103530</elocation-id><pub-id pub-id-type="doi">10.1016/j.concog.2023.103530</pub-id><pub-id pub-id-type="pmid">37619452</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname><given-names>K</given-names></name><name><surname>Birn</surname><given-names>RM</given-names></name><name><surname>Handwerker</surname><given-names>DA</given-names></name><name><surname>Jones</surname><given-names>TB</given-names></name><name><surname>Bandettini</surname><given-names>PA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The impact of global signal regression on resting state correlations: are anti-correlated networks introduced?</article-title><source>NeuroImage</source><volume>44</volume><fpage>893</fpage><lpage>905</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.09.036</pub-id><pub-id pub-id-type="pmid">18976716</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naci</surname><given-names>L</given-names></name><name><surname>Cusack</surname><given-names>R</given-names></name><name><surname>Anello</surname><given-names>M</given-names></name><name><surname>Owen</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A common neural code for similar conscious experiences in different individuals</article-title><source>PNAS</source><volume>111</volume><fpage>14277</fpage><lpage>14282</lpage><pub-id pub-id-type="doi">10.1073/pnas.1407007111</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nastase</surname><given-names>SA</given-names></name><name><surname>Gazzola</surname><given-names>V</given-names></name><name><surname>Hasson</surname><given-names>U</given-names></name><name><surname>Keysers</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Measuring shared responses across subjects using intersubject correlation</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>14</volume><fpage>667</fpage><lpage>685</lpage><pub-id pub-id-type="doi">10.1093/scan/nsz037</pub-id><pub-id pub-id-type="pmid">31099394</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poerio</surname><given-names>GL</given-names></name><name><surname>Sormaz</surname><given-names>M</given-names></name><name><surname>Wang</surname><given-names>H-T</given-names></name><name><surname>Margulies</surname><given-names>D</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The role of the default mode network in component processes underlying the wandering mind</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>12</volume><fpage>1047</fpage><lpage>1062</lpage><pub-id pub-id-type="doi">10.1093/scan/nsx041</pub-id><pub-id pub-id-type="pmid">28402561</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rohr</surname><given-names>CS</given-names></name><name><surname>Arora</surname><given-names>A</given-names></name><name><surname>Cho</surname><given-names>IYK</given-names></name><name><surname>Katlariwala</surname><given-names>P</given-names></name><name><surname>Dimond</surname><given-names>D</given-names></name><name><surname>Dewey</surname><given-names>D</given-names></name><name><surname>Bray</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Functional network integration and attention skills in young children</article-title><source>Developmental Cognitive Neuroscience</source><volume>30</volume><fpage>200</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.1016/j.dcn.2018.03.007</pub-id><pub-id pub-id-type="pmid">29587178</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schooler</surname><given-names>JW</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Christoff</surname><given-names>K</given-names></name><name><surname>Handy</surname><given-names>TC</given-names></name><name><surname>Reichle</surname><given-names>ED</given-names></name><name><surname>Sayette</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Meta-awareness, perceptual decoupling and the wandering mind</article-title><source>Trends in Cognitive Sciences</source><volume>15</volume><fpage>319</fpage><lpage>326</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2011.05.006</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scolari</surname><given-names>M</given-names></name><name><surname>Seidl-Rathkopf</surname><given-names>KN</given-names></name><name><surname>Kastner</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Functions of the human frontoparietal attention network: Evidence from neuroimaging</article-title><source>Current Opinion in Behavioral Sciences</source><volume>1</volume><fpage>32</fpage><lpage>39</lpage><pub-id pub-id-type="doi">10.1016/j.cobeha.2014.08.003</pub-id><pub-id pub-id-type="pmid">27398396</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Schooler</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The restless mind</article-title><source>Psychological Bulletin</source><volume>132</volume><fpage>946</fpage><lpage>958</lpage><pub-id pub-id-type="doi">10.1037/0033-2909.132.6.946</pub-id><pub-id pub-id-type="pmid">17073528</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Beach</surname><given-names>E</given-names></name><name><surname>Schooler</surname><given-names>JW</given-names></name><name><surname>Handy</surname><given-names>TC</given-names></name></person-group><year iso-8601-date="2008">2008a</year><article-title>Going AWOL in the brain: mind wandering reduces cortical analysis of external events</article-title><source>Journal of Cognitive Neuroscience</source><volume>20</volume><fpage>458</fpage><lpage>469</lpage><pub-id pub-id-type="doi">10.1162/jocn.2008.20037</pub-id><pub-id pub-id-type="pmid">18004943</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>McSpadden</surname><given-names>M</given-names></name><name><surname>Schooler</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2008">2008b</year><article-title>When attention matters: The curious incident of the wandering mind</article-title><source>Memory &amp; Cognition</source><volume>36</volume><fpage>1144</fpage><lpage>1150</lpage><pub-id pub-id-type="doi">10.3758/MC.36.6.1144</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013a</year><article-title>Distinguishing how from why the mind wanders: A process–occurrence framework for self-generated mental activity</article-title><source>Psychological Bulletin</source><volume>139</volume><fpage>519</fpage><lpage>535</lpage><pub-id pub-id-type="doi">10.1037/a0030010</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Andrews-Hanna</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Not all minds that wander are lost: the importance of a balanced perspective on the mind-wandering state</article-title><source>Frontiers in Psychology</source><volume>4</volume><elocation-id>441</elocation-id><pub-id pub-id-type="doi">10.3389/fpsyg.2013.00441</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2013">2013b</year><article-title>Penetrating the fog of the decoupled mind: the effects of visual salience in the sustained attention to response task</article-title><source>Canadian Journal of Experimental Psychology = Revue Canadienne de Psychologie Experimentale</source><volume>67</volume><fpage>32</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1037/a0030760</pub-id><pub-id pub-id-type="pmid">23458549</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Schooler</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The science of mind wandering: empirically navigating the stream of consciousness</article-title><source>Annual Review of Psychology</source><volume>66</volume><fpage>487</fpage><lpage>518</lpage><pub-id pub-id-type="doi">10.1146/annurev-psych-010814-015331</pub-id><pub-id pub-id-type="pmid">25293689</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Bernhardt</surname><given-names>BC</given-names></name><name><surname>Leech</surname><given-names>R</given-names></name><name><surname>Bzdok</surname><given-names>D</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name></person-group><year iso-8601-date="2021">2021a</year><article-title>The default mode network in cognition: a topographical perspective</article-title><source>Nature Reviews. Neuroscience</source><volume>22</volume><fpage>503</fpage><lpage>513</lpage><pub-id pub-id-type="doi">10.1038/s41583-021-00474-4</pub-id><pub-id pub-id-type="pmid">34226715</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Turnbull</surname><given-names>A</given-names></name><name><surname>Wang</surname><given-names>H-T</given-names></name><name><surname>Ho</surname><given-names>NSP</given-names></name><name><surname>Poerio</surname><given-names>GL</given-names></name><name><surname>Karapanagiotidis</surname><given-names>T</given-names></name><name><surname>Konu</surname><given-names>D</given-names></name><name><surname>Mckeown</surname><given-names>B</given-names></name><name><surname>Zhang</surname><given-names>M</given-names></name><name><surname>Murphy</surname><given-names>C</given-names></name><name><surname>Vatansever</surname><given-names>D</given-names></name><name><surname>Bzdok</surname><given-names>D</given-names></name><name><surname>Konishi</surname><given-names>M</given-names></name><name><surname>Leech</surname><given-names>R</given-names></name><name><surname>Seli</surname><given-names>P</given-names></name><name><surname>Schooler</surname><given-names>JW</given-names></name><name><surname>Bernhardt</surname><given-names>B</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2021">2021b</year><article-title>The neural correlates of ongoing conscious thought</article-title><source>iScience</source><volume>24</volume><elocation-id>102132</elocation-id><pub-id pub-id-type="doi">10.1016/j.isci.2021.102132</pub-id><pub-id pub-id-type="pmid">33665553</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turnbull</surname><given-names>A</given-names></name><name><surname>Wang</surname><given-names>HT</given-names></name><name><surname>Murphy</surname><given-names>C</given-names></name><name><surname>Ho</surname><given-names>NSP</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Sormaz</surname><given-names>M</given-names></name><name><surname>Karapanagiotidis</surname><given-names>T</given-names></name><name><surname>Leech</surname><given-names>RM</given-names></name><name><surname>Bernhardt</surname><given-names>B</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Vatansever</surname><given-names>D</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019a</year><article-title>Left dorsolateral prefrontal cortex supports context-dependent prioritisation of off-task thought</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>3816</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-019-11764-y</pub-id><pub-id pub-id-type="pmid">31444333</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turnbull</surname><given-names>A</given-names></name><name><surname>Wang</surname><given-names>HT</given-names></name><name><surname>Schooler</surname><given-names>JW</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019b</year><article-title>The ebb and flow of attention: Between-subject variation in intrinsic connectivity and cognition associated with the dynamics of ongoing experience</article-title><source>NeuroImage</source><volume>185</volume><fpage>286</fpage><lpage>299</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.09.069</pub-id><pub-id pub-id-type="pmid">30266263</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turnbull</surname><given-names>A</given-names></name><name><surname>Karapanagiotidis</surname><given-names>T</given-names></name><name><surname>Wang</surname><given-names>H-T</given-names></name><name><surname>Bernhardt</surname><given-names>BC</given-names></name><name><surname>Leech</surname><given-names>R</given-names></name><name><surname>Margulies</surname><given-names>D</given-names></name><name><surname>Schooler</surname><given-names>J</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Reductions in task positive neural systems occur with the passage of time and are associated with changes in ongoing thought</article-title><source>Scientific Reports</source><volume>10</volume><elocation-id>9912</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-020-66698-z</pub-id><pub-id pub-id-type="pmid">32555212</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turnbull</surname><given-names>A</given-names></name><name><surname>Poerio</surname><given-names>GL</given-names></name><name><surname>Ho</surname><given-names>NS</given-names></name><name><surname>Martinon</surname><given-names>LM</given-names></name><name><surname>Riby</surname><given-names>LM</given-names></name><name><surname>Lin</surname><given-names>FV</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Age-related changes in ongoing thought relate to external context and individual cognition</article-title><source>Consciousness and Cognition</source><volume>96</volume><elocation-id>103226</elocation-id><pub-id pub-id-type="doi">10.1016/j.concog.2021.103226</pub-id><pub-id pub-id-type="pmid">34689074</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vago</surname><given-names>DR</given-names></name><name><surname>Zeidan</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The brain on silent: mind wandering, mindful awareness, and states of mental tranquility</article-title><source>Annals of the New York Academy of Sciences</source><volume>1373</volume><fpage>96</fpage><lpage>113</lpage><pub-id pub-id-type="doi">10.1111/nyas.13171</pub-id><pub-id pub-id-type="pmid">27398642</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vanderwal</surname><given-names>T</given-names></name><name><surname>Eilbott</surname><given-names>J</given-names></name><name><surname>Castellanos</surname><given-names>FX</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Movies in the magnet: naturalistic paradigms in developmental functional neuroimaging</article-title><source>Developmental Cognitive Neuroscience</source><volume>36</volume><elocation-id>100600</elocation-id><pub-id pub-id-type="doi">10.1016/j.dcn.2018.10.004</pub-id><pub-id pub-id-type="pmid">30551970</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vatansever</surname><given-names>D</given-names></name><name><surname>Bzdok</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>H-T</given-names></name><name><surname>Mollo</surname><given-names>G</given-names></name><name><surname>Sormaz</surname><given-names>M</given-names></name><name><surname>Murphy</surname><given-names>C</given-names></name><name><surname>Karapanagiotidis</surname><given-names>T</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Varieties of semantic cognition revealed through simultaneous decomposition of intrinsic brain connectivity and behaviour</article-title><source>NeuroImage</source><volume>158</volume><fpage>1</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.06.067</pub-id><pub-id pub-id-type="pmid">28655631</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vatansever</surname><given-names>D</given-names></name><name><surname>Karapanagiotidis</surname><given-names>T</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Distinct patterns of thought mediate the link between brain functional connectomes and well-being</article-title><source>Network Neuroscience</source><volume>4</volume><fpage>637</fpage><lpage>657</lpage><pub-id pub-id-type="doi">10.1162/netn_a_00137</pub-id><pub-id pub-id-type="pmid">32885119</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>H-T</given-names></name><name><surname>Poerio</surname><given-names>G</given-names></name><name><surname>Murphy</surname><given-names>C</given-names></name><name><surname>Bzdok</surname><given-names>D</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Dimensions of experience: exploring the heterogeneity of the wandering mind</article-title><source>Psychological Science</source><volume>29</volume><fpage>56</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1177/0956797617728727</pub-id><pub-id pub-id-type="pmid">29131720</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whitfield-Gabrieli</surname><given-names>S</given-names></name><name><surname>Nieto-Castanon</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Conn: A functional connectivity toolbox for correlated and anticorrelated brain networks</article-title><source>Brain Connectivity</source><volume>2</volume><fpage>125</fpage><lpage>141</lpage><pub-id pub-id-type="doi">10.1089/brain.2012.0073</pub-id><pub-id pub-id-type="pmid">22642651</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>E</given-names></name><name><surname>Milisav</surname><given-names>F</given-names></name><name><surname>Kopal</surname><given-names>J</given-names></name><name><surname>Holmes</surname><given-names>AJ</given-names></name><name><surname>Mitsis</surname><given-names>GD</given-names></name><name><surname>Misic</surname><given-names>B</given-names></name><name><surname>Finn</surname><given-names>ES</given-names></name><name><surname>Bzdok</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>The default network dominates neural responses to evolving movie stories</article-title><source>Nature Communications</source><volume>14</volume><elocation-id>4197</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-023-39862-y</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yarkoni</surname><given-names>T</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name><name><surname>Nichols</surname><given-names>TE</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Wager</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Large-scale automated synthesis of human functional neuroimaging data</article-title><source>Nature Methods</source><volume>8</volume><fpage>665</fpage><lpage>670</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1635</pub-id><pub-id pub-id-type="pmid">21706013</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yeo</surname><given-names>BTT</given-names></name><name><surname>Krienen</surname><given-names>FM</given-names></name><name><surname>Sepulcre</surname><given-names>J</given-names></name><name><surname>Sabuncu</surname><given-names>MR</given-names></name><name><surname>Lashkari</surname><given-names>D</given-names></name><name><surname>Hollinshead</surname><given-names>M</given-names></name><name><surname>Roffman</surname><given-names>JL</given-names></name><name><surname>Smoller</surname><given-names>JW</given-names></name><name><surname>Zöllei</surname><given-names>L</given-names></name><name><surname>Polimeni</surname><given-names>JR</given-names></name><name><surname>Fischl</surname><given-names>B</given-names></name><name><surname>Liu</surname><given-names>H</given-names></name><name><surname>Buckner</surname><given-names>RL</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The organization of the human cerebral cortex estimated by intrinsic functional connectivity</article-title><source>Journal of Neurophysiology</source><volume>106</volume><fpage>1125</fpage><lpage>1165</lpage><pub-id pub-id-type="doi">10.1152/jn.00338.2011</pub-id><pub-id pub-id-type="pmid">21653723</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>M</given-names></name><name><surname>Savill</surname><given-names>N</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Distinct individual differences in default mode network connectivity relate to off-task thought and text memory during reading</article-title><source>Scientific Reports</source><volume>9</volume><elocation-id>9</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-019-52674-9</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>M</given-names></name><name><surname>Bernhardt</surname><given-names>BC</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Varga</surname><given-names>D</given-names></name><name><surname>Krieger-Redwood</surname><given-names>K</given-names></name><name><surname>Royer</surname><given-names>J</given-names></name><name><surname>Rodríguez-Cruces</surname><given-names>R</given-names></name><name><surname>Vos de Wael</surname><given-names>R</given-names></name><name><surname>Margulies</surname><given-names>DS</given-names></name><name><surname>Smallwood</surname><given-names>J</given-names></name><name><surname>Jefferies</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Perceptual coupling and decoupling of the default mode network during mind-wandering and reading</article-title><source>eLife</source><volume>11</volume><elocation-id>e74011</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.74011</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.97731.4.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Obleser</surname><given-names>Jonas</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>University of Lübeck</institution><country>Germany</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Valuable</kwd></kwd-group></front-stub><body><p>This study presents a <bold>valuable</bold> methodological advancement in quantifying thoughts over time. A novel multi-dimensional experience-sampling approach is presented, identifying data-driven patterns that the authors use to interrogate fMRI data collected during naturalistic movie-watching. The experimentation is inventive and the analyses carried out and results presented are <bold>convincing</bold>.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.97731.4.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>The authors used a novel multi-dimensional experience sampling (mDES) approach to identify data-driven patterns of experience samples that they use to interrogate fMRI data collected during naturalistic movie-watching data. They identify a set of multi-sensory features of a set of movies that delineate low-dimensional gradients of BOLD fMRI signal patterns that have previously been linked to fundamental axes of cortical organization.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.97731.4.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>The present study explores how thoughts map onto brain activity, a notoriously challenging question because of the dynamic, subjective, and abstract nature of thoughts. To tackle this question, the authors collected continuous thought ratings from participants watching a movie, and additionally made use of an open-source fMRI dataset recorded during movie watching as well as five established gradients of brain variation as identified in resting state data. Using a voxel-space approach, the results show that episodic knowledge, verbal detail, and sensory engagement of thoughts commonly modulate visual and auditory cortex, while intrusive distraction modulates the frontoparietal network. Additionally, sensory engagement mapped onto a gradient from primary to association cortex, while episodic knowledge mapped onto a gradient from the dorsal attention network to visual cortex. Building on the association between behavioral performance and neural activation, the authors conclude that sensory coupling to external input and frontoparietal executive control are key to comprehension in naturalistic settings.</p><p>The manuscript stands out for its methodological advancements in quantifying thoughts over time and its aim to study the implementation of thoughts in the brain during naturalistic movie watching.</p><p>Strengths:</p><p>(1) The study raises a question that has been difficult to study in naturalistic settings so far but is key to understanding human cognition, namely how thoughts map onto brain activation.</p><p>(2) The thought ratings introduce a novel method for continuously tracking thoughts, promising utility beyond this study.</p><p>(3) The authors used diverse data types, metrics, and analyses to substantiate the effects of thinking from multiple perspectives.</p></body></sub-article><sub-article article-type="referee-report" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.97731.4.sa3</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>This study attempted to investigate the relations between processing in the human brain during movie watching and corresponding thought processes. This is a highly interesting question, as movie watching presents a semi-constrained task, combining naturally occurring thoughts and common processing of sensory inputs across participants. This task is inherently difficult because in order to know what participants are thinking at any given moment, one has to interrupt the same thought process which is the object of study.</p><p>This study attempts to deal with this issue by aggregating staggered experience sampling data across participants in one behavioral study and using the population level thought patterns to model brain activity in different participants in an open access fMRI dataset.</p><p>The behavioral data consist of 120 participants who watched 3 11-minute movie clips. Participants responded to the mDES questionnaire: 16 visual scales characterizing ongoing thought 5 times, two minutes apart, in each clip. The 16 items are first reduced to 4 factors using PCA, and their levels are compared across the different movies. The factors are &quot;episodic knowledge&quot;, &quot;intrusive distraction&quot;, &quot;verbal detail&quot;, and &quot;sensory engagement&quot;. The factors differ between the clips, and distraction is negatively correlated with movie comprehension and sensory engagement is positively correlated with comprehension.</p><p>The components are aggregated across participants (transforming single subject mDES answers into PCA space and concatenating responses of different participants) and are used as regressors in a GLM analysis. This analysis identifies brain regions corresponding to the components. The resulting brain maps reveal activations that are consistent with the proposed mental processes (e.g. negative loading for intrusion in frontoparietal network, positive loadings for visual and auditory cortices for sensory engagement).</p><p>Then, the coordinates for brain regions which were significant for more than one component are entered into a paper search in neurosynth. It is not clear what this analysis demonstrates beyond the fact that sensory engagement contained both visual and auditory components.</p><p>The next analysis projected group-averaged brain activation onto gradients (based on previous work) and used gradient timecourses to predict the behavioral report timecourses. This revealed that high activations in gradient 1 (sensory→association) predicted high sensory engagement, and that &quot;episodic knowledge&quot; thought patterns were predicted by increased visual cortex activations. Then, permutation tests were performed to see whether these thought pattern related activations corresponded to well defined regions on a given cluster.</p><p>In conclusion, this study tackles a highly interesting subject and does it creatively and expertly.</p></body></sub-article><sub-article article-type="author-comment" id="sa4"><front-stub><article-id pub-id-type="doi">10.7554/eLife.97731.4.sa4</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Wallace</surname><given-names>Raven Star</given-names></name><role specific-use="author">Author</role><aff><institution>Queen&amp;apos;s University</institution><addr-line><named-content content-type="city">Kingston</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Mckeown</surname><given-names>Bronte</given-names></name><role specific-use="author">Author</role><aff><institution>Queen&amp;apos;s University</institution><addr-line><named-content content-type="city">Kingston</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Goodall-Halliwell</surname><given-names>Ian</given-names></name><role specific-use="author">Author</role><aff><institution>Queen&amp;apos;s University</institution><addr-line><named-content content-type="city">Kingston</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Chitiz</surname><given-names>Louis</given-names></name><role specific-use="author">Author</role><aff><institution>Queen&amp;apos;s University</institution><addr-line><named-content content-type="city">Kingston</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Forest</surname><given-names>Philippe</given-names></name><role specific-use="author">Author</role><aff><institution>IMT Atlantique</institution><addr-line><named-content content-type="city">Nantes</named-content></addr-line><country>France</country></aff></contrib><contrib contrib-type="author"><name><surname>Karapanagiotidis</surname><given-names>Theodoros</given-names></name><role specific-use="author">Author</role><aff><institution>University of Sussex</institution><addr-line><named-content content-type="city">Falmer</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Mulholland</surname><given-names>Bridget</given-names></name><role specific-use="author">Author</role><aff><institution>Queen&amp;apos;s University</institution><addr-line><named-content content-type="city">Kingston</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Turnbull</surname><given-names>Adam</given-names></name><role specific-use="author">Author</role><aff><institution>Stanford University</institution><addr-line><named-content content-type="city">Stanford</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Vanderwal</surname><given-names>Tamara</given-names></name><role specific-use="author">Author</role><aff><institution>University of British Columbia</institution><addr-line><named-content content-type="city">British Columbia</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Hardikar</surname><given-names>Samyogita</given-names></name><role specific-use="author">Author</role><aff><institution>Max Planck Institute for Human Cognitive and Brain Sciences</institution><addr-line><named-content content-type="city">Leipzig</named-content></addr-line><country>Germany</country></aff></contrib><contrib contrib-type="author"><name><surname>Gonzalez Alam</surname><given-names>Tirso RJ</given-names></name><role specific-use="author">Author</role><aff><institution>Bangor University</institution><addr-line><named-content content-type="city">Bangor</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Bernhardt</surname><given-names>Boris C</given-names></name><role specific-use="author">Author</role><aff><institution>McGill University</institution><addr-line><named-content content-type="city">Montreal</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Wang</surname><given-names>Hao-Ting</given-names></name><role specific-use="author">Author</role><aff><institution>Institut Universitaire de Geriatrie de Montreal</institution><addr-line><named-content content-type="city">Montreal</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Strawson</surname><given-names>Will</given-names></name><role specific-use="author">Author</role><aff><institution>University of Sussex</institution><addr-line><named-content content-type="city">Falmer</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Milham</surname><given-names>Michael</given-names></name><role specific-use="author">Author</role><aff><institution>Child Mind Institute</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Xu</surname><given-names>Ting</given-names></name><role specific-use="author">Author</role><aff><institution>Child Mind Institute</institution><addr-line><named-content content-type="city">New York</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Margulies</surname><given-names>Daniel S</given-names></name><role specific-use="author">Author</role><aff><institution>Université de Paris</institution><addr-line><named-content content-type="city">Paris</named-content></addr-line><country>France</country></aff></contrib><contrib contrib-type="author"><name><surname>Poerio</surname><given-names>Giulia L</given-names></name><role specific-use="author">Author</role><aff><institution>University of Sussex</institution><addr-line><named-content content-type="city">Falmer</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Jefferies</surname><given-names>Elizabeth</given-names></name><role specific-use="author">Author</role><aff><institution>University of York</institution><addr-line><named-content content-type="city">York</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Skipper</surname><given-names>Jeremy I</given-names></name><role specific-use="author">Author</role><aff><institution>University College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Wammes</surname><given-names>Jeffrey D</given-names></name><role specific-use="author">Author</role><aff><institution>Queen&amp;apos;s University</institution><addr-line><named-content content-type="city">Kingston</named-content></addr-line><country>Canada</country></aff></contrib><contrib contrib-type="author"><name><surname>Leech</surname><given-names>Robert</given-names></name><role specific-use="author">Author</role><aff><institution>King&amp;apos;s College London</institution><addr-line><named-content content-type="city">London</named-content></addr-line><country>United Kingdom</country></aff></contrib><contrib contrib-type="author"><name><surname>Smallwood</surname><given-names>Jonathan</given-names></name><role specific-use="author">Author</role><aff><institution>Queens University</institution><addr-line><named-content content-type="city">Kingston</named-content></addr-line><country>Canada</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the previous reviews.</p><disp-quote content-type="editor-comment"><p><bold>Recommendations for the Authors:</bold></p><p><bold>Reviewer #2:</bold></p><p>(1) In my previous review, I noted that using three different movies to conclude that different genres evoke different thought patterns is an overinterpretation with only one instance per genre. In the rebuttal letter, the authors state that they provide &quot;evidence that is necessary but not sufficient to conclude that we can distinguish different genres of films&quot; (page 15). Accordingly, I suggest refraining from statements such as &quot;There was a significant main effect of movie genre on memory&quot; (page 13) in the manuscript.</p></disp-quote><p>Thank you for this point. We have removed any reference to genre.</p><p>Page 18 (referring to page 13) [354-355] “First, there was a significant main effect of movie on memory, F(2, 254.12) = 49.33, p &lt;.001, η2 = .28.”</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3:</bold></p><p>The revised manuscript is easier to read and better contextualized.</p></disp-quote><p>Thank you for this comment and for your feedback to allow us to make the manuscript more clear.</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1:</bold></p><p>The lack of direct interrogation of individual differences/reliability of the mDES scores warrants some pause.</p></disp-quote><p>Our study's goal was to understand how group-level patterns of thought in one group of participants relate to brain activity in a different group of participants. To this end, we decomposed trial-level mDES data to show dimensions that are common across individuals, which demonstrated excellent split-half reliability. Then we used these data in two complementary ways. First, we established that these ratings reliably distinguished between the different films (showing that our approach is sensitive to manipulations of semantic and affective features in a film) and that these group-level patterns were also able to predict patterns of brain activity in a different group of participants (suggesting that mDES dimensions are also sensitive to the way brain activity emerges during movie watching). Second, we established that variation across individuals in their mDES scores predicted their comprehension of information from films. Thus our study establishes that when applied to movie-watching, mDES is sensitive to individual differences in the movie-watching experience (as determined by an individual's comprehension). Given the success of this study and the relative ease with which mDES can be performed, it will be possible in the future to conduct mDES studies that hone in on both the general features of the movie-watching experience, as well as aspects that are more unique to an individual.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2:</bold></p><p>(1) The distinction between thinking and stimulus processing (in the sense of detecting and assigning meaning to features, modulated by factors such as attention) remains unclear. Is &quot;thinking&quot; a form of conscious access or a reportable read-out from sensory and higher-level stimulus processing? Or does it simply refer to the method used here to identify different processing states?</p></disp-quote><p>Thank you for highlighting this first point, which is an important consideration when attempting to map cognitive states. We have added some additional comments to our discussion section to expand on this point.</p><p>Page 35-36 [698-711] “It is possible, therefore, that the identification of regions of visual and auditory cortex by our study reflects the participants attention to sensory input, rather than the complex analysis of these inputs that may be required for certain features of the movie watching experience. On the other hand, it is possible that the movie-watching state is a qualitatively different type of mental state to those that emerge in typical task situations. For example, unlike tasks, the movie-watching state is characterized by multi-modal sensory input, semantically rich themes, that evolve together to reveal a continuous narrative to the viewer. It is possible, therefore, that movies engender an absorbed state which depends more on processing in sensory cortex than would occur in traditional task paradigms such as a working memory task (when systems in association cortex may be needed to maintain information related to task rules). Important headway into addressing this uncertainty can be achieved by using mDES to compare the types of states that occur in different contexts (including both movies and tasks) and comparing the topography of brain activity associated with different experiential states.”</p><disp-quote content-type="editor-comment"><p>(2) The dimensions of thought appear to be directly linked to brain areas traditionally associated with core faculties of perception and cognition. For example, superior temporal cortex codes for speech information, which is also where thought reports on verbal detail localize in this study. This raises the question of whether the present study truly captures mechanisms specific to thinking and distinct from processing, especially given that individual variations in reports were not considered and movie-specific features were not controlled for.</p></disp-quote><p>Thank you for this point, we have added an additional paragraph to the discussion to expand on this.</p><p>Page 35 [692-698] “Finally, it is worth considering whether the patterns of brain activity identified by our analysis reflect the stimuli that are processed during movie watching, or the cognitive and affective processing of this information. On the one hand, the regions we found were often within regions of sensory cortex, areas of the brain which are often ascribed basic stimulus processing functions [1]. Moreover, according to perspectives on cognition derived from more traditional task paradigms, complex features of cognition, such as the regulation of thought, are often attributed to regions of association cortex, such as the dorsolateral prefrontal cortex [2].”</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #3:</bold></p><p>This paper is framed as presenting a new paradigm but it does little to discuss what this paradigm serves, what are its limitations and how it should have been tested. The novelty appears to be in using experience sampling from 1 sample to model the responses of a second sample.</p></disp-quote><p>Thank you for this comment, we have since made clear what the novelty of the methodology is, as you have correctly identified, by expanding this point beyond the methods section to clearly orient the reader to the application and limitation of our methodological approach with our paradigm.</p><p>Page 7-8 [149-174] “One challenge that arises when attempting to map the dynamics of thought onto brain activity during movie-watching is accounting for the inherently disruptive nature of experience sampling: to measure experience with sufficient frequency to map experiential reports during movies would inherently disrupt the natural processes of the brain and alter the viewer’s experience (for example, by pausing the film at a moment of suspense). Therefore, if we periodically interrupt viewers to acquire a description of their thoughts while recording brain activity, this could impact on the ability to capture important dynamic features of the brain. On the other hand, if we measured fMRI activity continuously over movie-watching (as is usually the case), we would lack the capacity to directly relate brain signals to the corresponding experiential states. Thus, to overcome these obstacles, we developed a novel methodological approach using two independent samples of participants. In the current study, one set of 120 participants was probed with mDES five times across the three ten-minute movie clips (11 minutes total, no sampling in the first minute). We used a jittered sampling technique where probes were delivered at different intervals across the film for different people depending on the condition they were assigned. Probe orders were also counterbalanced to minimize the systematic impact of prior and later probes at any given sampling moment. We used these data to construct a precise description of the dynamics of experience for every 15 seconds of three ten-minute movie clips. These data were then combined with fMRI data from a different sample of 44 participants who had already watched these clips without experience sampling [3]. By combining data from two different groups of participants, our method allows us to describe the time series of different experiential states (as defined by mDES) and relate these to the time series of brain activity in another set of participants who watched the same films with no interruptions. In this way, our study set out to explicitly understand how the patterns of thoughts that dominate different moments in a film in one group of participants relate to the brain activity at these time points in a second set of participants and, therefore, better understand the contribution of different neural systems to the movie-watching experience.”</p><p>Page 33-35 [658-691] “Importantly, our study provides a novel method for answering these questions and others regarding the brain basis of experiences during films that can be applied simply and cost-effectively. As we have shown, mDES can be combined with existing brain activity, allowing information about both brain activity and experience to be determined at a relatively low cost. For example, the cost-effective nature of our paradigm makes it an ideal way to explore the relationship between cognition and neural activity during movie-watching during different genres of film. In neuroimaging, conclusions are often made using one film in naturalistic paradigm studies [4]. Although the current study only used three movie clips, restraining our ability to form strong conclusions regarding how different patterns of thought relate to specific genres of film, in the future, it will be possible to map cognition across a more extensive set of movies and discern whether there are specific types of experience that different genres of films engage. One of the major strengths of our approach, therefore, is the ability to map thoughts across groups of participants across a wide range of movies at a relatively low cost.</p><p>Nonetheless, this paradigm is not without limitations. This is the first study, as far as we know, that attempts to compare experiential reports in one sample of participants with brain activity in a second set of participants, and while the utility of this method enables us to understand the relationship between thought and brain activity during movies, it will be important to extend our analysis to mDES data during movie-watching while brain activity is recorded. In addition, our study is correlational in nature, and in the future, it could be useful to generate a more mechanistic understanding of how brain activity maps onto the participants experience. Our analysis shows that mDES is able to discriminate between films, highlighting its broad sensitivity to variation in semantic or affective content. Armed with this knowledge, we propose that in the future, researchers could derive mechanistic insights into how the semantic features may influence the mDES data. For example, it may be possible to ask participants to watch movies in a scrambled order to understand how the structure of semantic or information influences the mapping between brains and ongoing experience as measured by mDES. Finally, our study focused on mapping group-level patterns of experience onto group-level descriptions of brain activity. In the future it may be possible to adopt a “precision-mapping” approach by measuring longer periods of experience using mDES and determining how the neural correlates of experience vary across individuals who watched the same movies while brain activity was collected [5]. In the future, we anticipate that the ease with which our method can be applied to different groups of individuals and different types of media will make it possible to build a more comprehensive and culturally inclusive understanding of the links between brain activity and movie-watching experience.”</p><disp-quote content-type="editor-comment"><p>What are the considerations for treating high-order thought patterns that occur during film viewing as stable enough to use across participants? What would be the limitations of this method? (Do all people reading this paper think comparable thoughts reading through the sections?) This is briefly discussed in the revised manuscript and generally treated as an opportunity rather than as a limitation.</p></disp-quote><p>It is likely, based on our study, that films can evoke both stereotyped thought patterns (i.e. thoughts that many people will share) and others that are individualistic. It is clear that, in principle, mDES is capable of capturing empirical information on both stereotypical thoughts and idiosyncratic thoughts. For example, clear differences in experiences across films and, in particular, during specific periods within a film, show that movie-watching can evoke broadly similar thought patterns in different groups of participants (see Figure 3 right-hand panel). On the other hand, the association between comprehension and the different mDES components indicate that certain individuals respond to the same film clip in different ways and that these differences are rooted in objective information (i.e. their memory of an event in a film clip). A clear example of these more idiosyncratic features of movie watching experience can be seen in the association between “Episodic Knowledge” and comprehension. We found that “Episodic Knowledge” was generally high in the romance clip from 500 Days of Summer but was especially high for individuals who performed the best, indicating they remembered the most information. Thus good comprehends responded to the 500 Days of Summer clip with responses that had more evidence of “Episodic Knowledge” In the future, since the mDES approach can account for both stereotyped and idiosyncratic features of experience, it will be an important tool in understanding the common and distinct features that movie watching experiences can have, especially given the cost effective manner with which these studies can be run.</p><disp-quote content-type="editor-comment"><p>In conclusion, this study tackles a highly interesting subject and does it creatively and expertly. It fails to discuss and establish the utility and appropriateness of its proposed method.</p></disp-quote><p>Thank you very much for your feedback and critique. In our revision and our responses to these questions, we provided more information about the method's robustness utility and application to understanding cognition. Thank you for bringing these points to our attention.</p><p>References</p><disp-quote content-type="editor-comment"><p>(1) Kaas, J.H. and C.E. Collins, <italic>The organization of sensory cortex.</italic> Current Opinion in Neurobiology, 2001. 11(4): p. 498-504.</p><p>(2) Turnbull, A., et al., <italic>Left dorsolateral prefrontal cortex supports context-dependent prioritisation of off-task thought.</italic> Nature Communications, 2019. 10.</p><p>(3) Aliko, S., et al., <italic>A naturalistic neuroimaging database for understanding the brain using ecological stimuli.</italic> Scientific Data, 2020. 7(1).</p><p>(4) Yang, E., et al., <italic>The default network dominates neural responses to evolving movie stories.</italic> Nature Communications, 2023. 14(1): p. 4197.</p><p>(5) Gordon, E.M., et al., <italic>Precision Functional Mapping of Individual Human Brains.</italic> Neuron, 2017. 95(4): p. 791-807.e7.</p></disp-quote></body></sub-article></article>