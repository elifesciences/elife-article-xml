<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">101506</article-id><article-id pub-id-type="doi">10.7554/eLife.101506</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.101506.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Neurons throughout the brain embed robust signatures of their anatomical location into spike trains</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Tolossa</surname><given-names>Gemechu Bekele</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6405-2908</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Schneider</surname><given-names>Aidan M</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Dyer</surname><given-names>Eva</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Hengen</surname><given-names>Keith B</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-5017-4090</contrib-id><email>khengen@wustl.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01yc7t268</institution-id><institution>Department of Biology, Washington University in St Louis</institution></institution-wrap><addr-line><named-content content-type="city">St Louis</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01zkghx44</institution-id><institution>Department of Biomedical Engineering, Georgia Institute of Technology</institution></institution-wrap><addr-line><named-content content-type="city">Atlanta</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Sharpee</surname><given-names>Tatyana O</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03xez1567</institution-id><institution>Salk Institute for Biological Studies</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Nelson</surname><given-names>Sacha B</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05abbep66</institution-id><institution>Brandeis University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><p><sup>†</sup> These authors contributed equally to this work.</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>27</day><month>06</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP101506</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-07-30"><day>30</day><month>07</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-07-31"><day>31</day><month>07</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.07.11.603152"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-11-19"><day>19</day><month>11</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.101506.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-05-15"><day>15</day><month>05</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.101506.2"/></event></pub-history><permissions><copyright-statement>© 2024, Tolossa, Schneider et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Tolossa, Schneider et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-101506-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-101506-figures-v1.pdf"/><abstract><p>Neurons in the brain are known to encode diverse information through their spiking activity, primarily reflecting external stimuli and internal states. However, whether individual neurons also embed information about their own anatomical location within their spike patterns remains largely unexplored. Here, we show that machine learning models can predict a neuron’s anatomical location across multiple brain regions and structures based solely on its spiking activity. Analyzing high-density recordings from thousands of neurons in awake, behaving mice, we demonstrate that anatomical location can be reliably decoded from neuronal activity across various stimulus conditions, including drifting gratings, naturalistic movies, and spontaneous activity. Crucially, anatomical signatures generalize across animals and even across different research laboratories, suggesting a fundamental principle of neural organization. Examination of trained classifiers reveals that anatomical information is enriched in specific interspike intervals as well as responses to stimuli. Within the visual isocortex, anatomical embedding is robust at the level of layers and primary versus secondary but does not robustly separate individual secondary structures. In contrast, structures within the hippocampus and thalamus are robustly separable based on their spike patterns. Our findings reveal a generalizable dimension of the neural code, where anatomical information is multiplexed with the encoding of external stimuli and internal states. This discovery provides new insights into the relationship between brain structure and function, with broad implications for neurodevelopment, multimodal integration, and the interpretation of large-scale neuronal recordings. Computational approximations of anatomy have the potential to support in vivo electrode localization.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>Brain regions</kwd><kwd>machine learning</kwd><kwd>decoding</kwd><kwd>computation</kwd><kwd>spike train</kwd><kwd>neural code</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution>BRAIN Initiative</institution></institution-wrap></funding-source><award-id>R01NS118442</award-id><principal-award-recipient><name><surname>Hengen</surname><given-names>Keith B</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution>BRAIN Initiative</institution></institution-wrap></funding-source><award-id>R01EB029852</award-id><principal-award-recipient><name><surname>Dyer</surname><given-names>Eva</given-names></name><name><surname>Hengen</surname><given-names>Keith B</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>F31NS134240</award-id><principal-award-recipient><name><surname>Schneider</surname><given-names>Aidan M</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100007268</institution-id><institution>Washington University in St Louis</institution></institution-wrap></funding-source><award-id>CCSN Program</award-id><principal-award-recipient><name><surname>Tolossa</surname><given-names>Gemechu Bekele</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100007268</institution-id><institution>Washington University in St Louis</institution></institution-wrap></funding-source><award-id>Incubator for Transdisciplinary Futures</award-id><principal-award-recipient><name><surname>Hengen</surname><given-names>Keith B</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Machine learning analysis reveals that individual neurons throughout the brain embed information about their anatomical location in their spike trains, a feature that generalizes across animals, experimental conditions, and laboratories.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Foundational to any effort towards understanding the brain is a singular question: what information is carried in a neuron’s spiking? It is widely understood that the action potential is the unit of information exchange in the central nervous system. Adrian first recorded a single neuron’s action potential in 1928, establishing a rate code in sensory neurons (<xref ref-type="bibr" rid="bib1">Adrian and Bronk, 1928</xref>). In 1943, McCulloch and Pitts demonstrated that neuronal circuits could compute Boolean algebra (<xref ref-type="bibr" rid="bib47">McCulloch and Pitts, 1943</xref>), and 16 years later showed that the visual environment is conveyed to the brain by way of neuronal spike patterns (<xref ref-type="bibr" rid="bib39">Lettvin et al., 1959</xref>). Since then, the concept of a neural code has emerged—neuronal spiking is determined by inputs, including stimuli, and noise (<xref ref-type="bibr" rid="bib21">Faisal et al., 2008</xref>; <xref ref-type="bibr" rid="bib25">Gerstner et al., 2014</xref>; <xref ref-type="bibr" rid="bib44">Mainen and Sejnowski, 1995</xref>; <xref ref-type="bibr" rid="bib78">Softky and Koch, 1993</xref>). In parallel works spanning 1899–1951, Cajal, Brodmann, and Penfield demonstrated diverse neuronal types that organize into anatomical loci, each with distinct functional contributions to sensation, perception, and behavior (<xref ref-type="bibr" rid="bib68">Santiago Ram´on y Cajal, 1899</xref>; <xref ref-type="bibr" rid="bib12">Brodmann, 1909</xref>; <xref ref-type="bibr" rid="bib61">Penfield and Jasper, 1951</xref>). In other words, information carried by neighboring neurons is likely to be similar in content, be it visual or interoceptive. However, much of our understanding of the neural code is derived from experimental designs that manipulate stimuli or measure behavior. This approach leaves innumerable other forms of biologically relevant features as potentially latent variables, such as reliable identifying information about the neuron itself. A complete understanding of these latent variables is essential for a complete understanding of a neuron’s role in the brain.</p><p>The null hypothesis is that the impact of anatomy on a neuron’s activity is either nonexistent or unremarkable. This is supported by three observations at the level of models. First, from a computational perspective, neurons’ outputs primarily reflect their inputs along with noise (<xref ref-type="bibr" rid="bib78">Softky and Koch, 1993</xref>; <xref ref-type="bibr" rid="bib73">Shadlen and Newsome, 1994</xref>; <xref ref-type="bibr" rid="bib40">London et al., 2010</xref>). Second, artificial recurrent neural networks, which also perform input integration, can emulate patterns of neural circuit activity and functions central to biology, including motor control (<xref ref-type="bibr" rid="bib56">Pandarinath et al., 2018</xref>) and visual processing (<xref ref-type="bibr" rid="bib70">Sawant et al., 2022</xref>). Yet, such networks do not require the formalized structure that is a hallmark of brain organization. Finally, in deep neural networks, anatomy is only relevant insofar as progressively deeper layers are functionally distinct. Taken together, complex information processing is achievable with neither a strict concept of anatomy nor a computational encoding of anatomy.</p><p>However, there are three principal reasons to justify asking if neurons reliably embed their anatomical location in their spiking. First, recent work suggests that, in addition to stimulus information, neurons transmit their genetic identity (<xref ref-type="bibr" rid="bib72">Schneider et al., 2023</xref>). Second, in contrast to artificial systems, there are conceptual reasons why a brain might benefit from a reliable neuron-level code for anatomy. For example, anatomical information is presumably crucial during neurodevelopment (<xref ref-type="bibr" rid="bib58">Patel and Poo, 1982</xref>). Likewise, such information could be valuable when parsing inputs during multimodal integration (<xref ref-type="bibr" rid="bib28">Gütig and Sompolinsky, 2006</xref>). Finally, within a species, brain anatomy is highly stereotyped. Thus, it stands to reason that, should a neuron’s anatomy be embedded in its spike train, this embedding might generalize across individuals.</p><p>Historically, the classification of brain regions has utilized anatomical landmarks, functional outputs, and, more recently, genetic markers, creating a comprehensive map of neural diversity. There is evidence that neural activity may vary by region, although such observations are restricted to population-level statistics (<xref ref-type="bibr" rid="bib75">Siegle et al., 2021</xref>). Specifically, patterns of neural activity evolve gradually across the anatomical landscape, influenced by gradients of synaptic weight (<xref ref-type="bibr" rid="bib20">Elston, 2007</xref>; <xref ref-type="bibr" rid="bib15">Chaudhuri et al., 2015</xref>), the autocorrelation timescale (<xref ref-type="bibr" rid="bib52">Murray et al., 2014</xref>), and connectivity patterns (<xref ref-type="bibr" rid="bib46">Maunsell and van Essen, 1983</xref>; <xref ref-type="bibr" rid="bib24">Gămănuţ et al., 2018</xref>; <xref ref-type="bibr" rid="bib30">Harris et al., 2019</xref>). While indicative of the brain’s complex architecture, these observations comprise subtle, statistical differences between populations rather than stark, unique signatures that could be used to classify an individual neuron with any confidence. Thus, it is unclear whether different computational rules have evolved in functionally distinct circuits. Alternatively, subtle statistical changes could reflect methodological limitations to capturing the full spectrum of activity patterns that define distinct brain regions. Should robust, circuit-specific rules exist, their description would enable a more precise understanding of how regional variations contribute to the broader neural code and sharpen our understanding of the brain’s computational organization.</p><p>Ultimately, the question can be distilled as, what is the minimum spatial scale at which neural activity patterns are reliably structured by the region of origin? Such patterns, should they exist, are most meaningful when identified at the level of single neurons. However, given the variance observed in any number of neuronal features—from tuning properties, to genetic cell type, to connectivity — it is unlikely that anatomy reliably determines neural activity at an obvious level, if at all. To address this, we employed a supervised machine learning approach to analyze publicly available datasets of high-density, multi-region, single-unit recordings in awake and behaving mice. To specifically evaluate whether anatomical information is embedded in the neuronal code, we examined the timing of spikes generated by well-isolated single units. We examined the possibility of anatomically defined computational rules at four levels: (1) large-scale brain regions (hippocampus, midbrain, thalamus, and visual isocortex), (2) hippocampal structures (CA1, CA3, dentate gyrus, prosubiculum, and subiculum), (3) thalamic structures (ethmoid nucleus, dorsal lateral geniculate, lateral posterior nucleus, ventral medial geniculate, posterior complex, suprageniculate nucleus, ventral posteromedial nucleus), and (4) visual cortical structures (primary, anterolateral, anteromedial, lateral, posteromedial, rostrolateral). We find that traditional measures of neuronal activity (e.g. firing rate) alone are unable to reliably distinguish anatomical location. In contrast, using a multi-layer perceptron (MLP), we reveal that information about brain regions and structure is recoverable from more complete representations of single unit spiking (e.g. interspike interval distribution). Further, we demonstrate that learning the computational anatomical rules in one animal is sufficient to decode another, both within and across distinct research groups. These observations suggest a conserved code for anatomical origin in the output of individual neurons, and that, in modern datasets that span multiple regions, electrode localization can be assisted by spike timing.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Dataset and inclusion criteria</title><p>To evaluate whether individual neurons embed reliable information about their structural localization in their spike trains, we required consistently reproduced recordings of large numbers of single units distributed throughout numerous cortical and subcortical structures. Further, we reasoned that candidate recordings should involve only awake and behaving animals. Finally, while highly restricted and repetitive stimuli are frequently leveraged to average out noise (<xref ref-type="bibr" rid="bib49">Millman et al., 2020</xref>), this approach increases the likelihood of overfitting in our case. Thus, we only considered datasets that contained diverse stimuli as well as spontaneous activity. Two open datasets from the Allen Institute meet these criteria, specifically (1) Brain Observatory and (2) Functional Connectivity (<xref ref-type="bibr" rid="bib75">Siegle et al., 2021</xref>). These datasets comprise tens of thousands of neurons recorded with high-density silicon probes (Neuropixels) in a total of N=58 mice (BO N=32, FC N=26). We used the selections of drifting gratings and the naturalistic movie found in the Brain Observatory dataset, which were distinct from those in the Functional Connectivity dataset. Additionally, we used recordings of spontaneous activity during blank screen presentations from both the Brain Observatory and Functional Connectivity datasets. Raw data were spike sorted at the Allen Institute. Because information is primarily encoded by the firing rate or the timing of spiking and not waveforms (etc)., our studies involve only the timestamps of individual spikes from well-isolated units (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). These units were filtered according to objective quality metrics such as ISI violations, presence ratio, and amplitude cutoff (see Methods). At the largest spatial division, neurons were assigned to four distinct brain regions: hippocampus, midbrain, thalamus, and visual cortices. Within regions, neurons were assigned to fine-grained structures, for example, CA1 hippocampus, lateral posterior thalamus, and anteromedial visual cortex (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). Note that midbrain neurons were not further classified by structure due to the relatively low number of neurons recorded there (to be considered at the structure level, we required a minimum of n=150 neurons). We tested the possibility of a computational embedding of anatomical location at two levels of generalizability. In the transductive approach, all neurons from all animals were merged before splitting into a training set and a testing set. This arrangement preserves the capacity of a model to learn some within-animal features. In contrast, for the inductive approach, model training is performed on all neurons from a set of animals, and model testing is performed on neurons from entirely withheld animals. In this case, any successful learning must, by definition, be generalizable across animals (<xref ref-type="fig" rid="fig1">Figure 1A</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Dimensionality reduction suggests a limited relationship between neuroanatomy and spike timing.</title><p>(<bold>A</bold>) Experimental pipeline. Left to right: Recording, raw data, extracted spike times, spiking time features (e.g., rates, CV), and model training protocols. The Allen Institute Visual Coding dataset comprises high-density silicon extracellular recordings that span multiple brain regions and structures. During recording, mice were headfixed and presented with multiple visual stimuli, including drifting gratings. For supervised experiments, classifiers were either transductive—all neurons from all animals were mixed and divided into train and test sets, or inductive—train and test sets were divided at the level of the animal. (<bold>B</bold>) Brain regions and structures included in our analyses. (Left to right) Brain Regions: Hippocampus, Midbrain, Thalamus and Visual Cortex. Hippocampal Structures: CA1, CA3, Dentate Gyrus (DG), Prosubiculum (ProS), Subiculum (SUB). Thalamic Structures: Ethmoid Nucleus (Eth), Dorsal Lateral Geniculate (LGd), Lateral Posterior Nucleus (LP), Ventral Medial Geniculate (MGv), Posterior Complex (PO), Suprageniculate Nucleus (SGN), Ventral Posteromedial Nucleus (VPM). Visuocortical Structures: Anterolateral (VISal), Anteromedial (VISam), Lateral (VISl), Primary (VISp), Posteromedial (VISpm), Rostrolateral (VISrl). (<bold>C</bold>) PCA/LDA plot of units recorded in each set of regions/structures (values capped to 1st and 99th percentiles for visualization- see Exploratory Visualization section of Methods). For each unit, 14 spiking metrics (see methods) describe the spike train, which is then placed in a 2D scatterplot. Color scheme follows 1B. Adjusted Rand Index (ARI) of clustering with respect to ground truth labels of regions and structures is printed for each plot.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101506-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Exploratory visualization of spiking activity.</title><p>Left columns (scatters) show two methods of dimensionality reduction (2D): principal component analysis (PCA) and linear discriminant analysis (LDA). Right columns (Wasserstein distance matrices) show quantification of the distance between anatomical groupings in the corresponding scatter plots on the left. Distance is calculated in the primary dimension for each plot. Rows denote three separate representations of unit activity: 14 predetermined spike metrics (e.g. firing rate), the full ISI distribution, or concatenated PSTHs. Note that within a task (e.g. Brain Regions), there is not a consistent pattern in the distance matrices, suggesting that any structure in the scatterplots is circumstantial. Colors in scatter plots correspond to anatomical labels on the matrices. Adjusted Rand Index (ARI) of clustering with respect to ground truth labels of regions and structures is printed for each plot. Horizontal lines separate tasks. p-values in the bottom right corner of plots refer to a permutation test of a logistic regression classifier’s training accuracy for accurate prediction of region/structure labels (relative to shuffled) based on plot coordinates for all individual units.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101506-fig1-figsupp1-v1.tif"/></fig></fig-group></sec><sec id="s2-2"><title>Exploratory trends in spiking by region and structure across the population</title><p>Many studies have highlighted statistical differences in the activity of populations of neurons as a function of brain region and structure (<xref ref-type="bibr" rid="bib52">Murray et al., 2014</xref>; <xref ref-type="bibr" rid="bib74">Shinomoto et al., 2009</xref>; <xref ref-type="bibr" rid="bib51">Mochizuki et al., 2016</xref>; <xref ref-type="bibr" rid="bib84">Wang, 2022</xref>). At face value, this raises the possibility that anatomy may have a powerful role in shaping spiking patterns. However, the existence of population-level differences does not necessarily imply that the anatomical location of an individual neuron can be reliably inferred from its spike train alone; especially in large datasets, even subtle regional differences in spiking may be significant. Put simply, statistically separable populations can exhibit extensive overlap (<xref ref-type="bibr" rid="bib31">Hastie et al., 2009</xref>). Prior to considering patterns embedded in individual spike trains, we asked whether and to what extent anatomical location explains the diversity of spiking patterns when considered across the entire population of included neurons (n=18,691 neurons from N=32 mice). Specifically, we applied exploratory visualizations to observe the dominant trends in data with respect to both overall variance (unsupervised) and separability (supervised).</p><p>We examined three distinct representations of spiking activity: (1) a previously described collection of 14 well-established spiking metrics (e.g. firing rate, coefficient of variation, etc.; <xref ref-type="bibr" rid="bib72">Schneider et al., 2023</xref>), (2) the distribution of interspike intervals (ISIs; 0–3 s, 100 uniform bins), and (3) the trial averaged PSTHs for each drifting grating condition (the collection of gratings included 8 orientations and 5 frequencies, PSTH was calculated in 100 msec bins across a 3 s trial). The Principal Components Analysis (PCA) and Linear Discriminant Analysis (LDA) scatter plots suggest that, depending on the combination of analytical method and included features, there are often subtle influences of brain region and structure in these dimensionally reduced spaces (<xref ref-type="fig" rid="fig1">Figure 1C</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). However, across all 24 combinations of anatomical tasks, analytical method, and examined features, there was not a single example of a prominent clustering organization aligned with brain structures or brain regions, as indicated by the adjusted rand index. These data may suggest that, examined as large populations, various features of neuronal spike timing may differ between regions, but that such differences are neither distinct nor robust. However, in all cases, greater alignment of labels and clusters was observed in supervised LDA, suggesting the potential of supervised analyses to extract targeted insights about structure and anatomy (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>).</p></sec><sec id="s2-3"><title>Separability of brain structures using established spiking metrics</title><p>Conservatively, it is possible that our unsupervised analysis (<xref ref-type="fig" rid="fig1">Figure 1</xref>) reflects a true limit of the separability of structures based on spiking activity. However, by definition, unsupervised approaches reflect the most prominent trends (e.g. the largest sources of variance, in the case of PCA) in neuronal activity, which may or may not be related to anatomical location. As a result, it is possible that an analysis whose effectiveness is defined by the separability of region and structure may reveal more reliable anatomical rules. The more apparent separability in our LDA suggests the potential of such supervised analyses. To quantify this, we asked whether, given the spiking activity of a single unit, its region and/or structure could be successfully predicted by a machine-learning model.</p><p>Broadly, in our initial supervised experiments, we pooled units from all animals. Pooled neurons were divided into non-overlapping sets for training (60%), validation (20%), and testing (20%). Crucially, equal proportions of each animal’s neurons were maintained in each set. This architecture allowed us to seek patterns across all animals that generalize to unseen neurons from the same set of animals (<xref ref-type="fig" rid="fig1">Figure 1A</xref> Computational Anatomy). Here, borrowed from machine learning, we use the term <italic>transductive</italic> to describe this approach which can transfer patterns learned from neighboring neurons to unseen ones (<xref ref-type="bibr" rid="bib55">Pan and Yang, 2010</xref>; <xref ref-type="bibr" rid="bib80">Vapnik, 1998</xref>).</p><p>Model performance is quantified with balanced accuracy, which is the average prediction accuracy for each class (i.e. region or structure) (<xref ref-type="bibr" rid="bib11">Brodersen et al., 2010</xref>). Error is ± SEM, and chance is 1/number of classes. To clearly indicate how models make errors between classes, we use confusion matrices. Confusion matrices are square heat maps where rows represent true class labels and columns represent predicted class labels. Diagonal entries indicate the proportion of units correctly predicted for their region or structure, while off-diagonal entries reflect instances of the model’s ‘confusion’. An effective model will exhibit high balanced accuracy and a strong diagonal structure in the corresponding confusion matrix.</p><p>We first passed standard measures of neuronal activity to a simple model. Specifically, we trained logistic regressions to predict a unit’s region/structure from 14 statistical measures that comprised three categories: (1) standard statistics, such as mean or maximum firing rate, (2) measures of local variance, such as CV2, a temporally constrained alternative to the coefficient of variation (CV; <xref ref-type="bibr" rid="bib34">Holt et al., 1996</xref>), and (3) spectral power, such as the delta band (0.1–4 Hz). Models were trained and tested in each of four prediction tasks: (1) brain regions, (2) hippocampal structures, (3) thalamic structures, and (4) visuocortical structures (<xref ref-type="fig" rid="fig2">Figure 2A–D</xref>). In each of these tasks, we evaluated the effectiveness of the 14 features individually as well as in combination to predict the anatomical localization of individual neurons (<xref ref-type="fig" rid="fig2">Figure 2</xref>).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>A linear classifier can learn to predict single neuron location based on standard spiking metrics.</title><p>(<bold>A-D</bold>) Balanced accuracy of logistic regression models trained to predict the anatomical location of single units based on each of 14 individual spiking metrics: Coefficient of Variation 2 (CV2), Local Variation (LV), Revised Local Variation (LVR), Mean Firing Rate (FR), Standard Deviation (Std Dev) of interspike intervals (ISIs), Coefficient of Variation (CV), Minimum ISI (Min ISI), Median ISI (Med ISI), Maximum ISI (Max ISI), power spectral density (PSD)-δ (Delta Band 0.1–4 Hz), PSD-θ (Theta Band 4–8 Hz), PSD-α (Alpha Band 8–12 Hz), PSD-β (Beta Band 12–40 Hz), PSD-γ (Gamma Band 40–100 Hz). Balanced accuracy expected by chance varies by task and is indicated by the dashed red line. Features on the x-axis are ordered by performance. Feature (bar) colors are assigned by the ordering in A (brain region task) and maintained for the structure tasks. Error bars represent the standard error of the mean (SEM) across five splits. (<bold>B–D</bold>). This shows the extent to which individual features maintain their relative importance across tasks. (<bold>E-H</bold>) Confusion matrices from logistic regression models trained to predict unit location from the combination of all 14 spiking metrics. Each confusion matrix shows the average of 5 train/test splits of the data. The proportion is printed only in cells where the proportion was greater than chance level (1/number of classes). Balanced accuracy for each task: Brain Regions = 52.91 ± 1.24; Hippocampal Structures = 44.10 ± 1.99; Thalamic Structures = 37.14 ± 2.57; Visuocortical Structures = 24.09 ± 1.46 (error is the SEM across 5 splits).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101506-fig2-v1.tif"/></fig><p>In all four tasks, the majority of individual spiking metrics supported weak but above-chance classification (<xref ref-type="fig" rid="fig2">Figure 2A–D</xref>). In contrast to brain regions and hippocampal structures, the ability of the 14 metrics to reliably indicate different visuocortical structures was notably low. Ordered by their classification performance (<xref ref-type="fig" rid="fig2">Figure 2A–D</xref>, x-axes), the arrangement of spiking metrics was highly task dependent. We examined the correlation of metric ordering — the order of classification effectiveness for the spiking metrics, from greatest to least — between the region task and the three structure tasks. We found a range of correlation from 0.03 to 0.73 (Spearman Rank Correlations- regions/VC: p = 0.0336, regions/TH: p = 0.0814, regions/HC: p = 0.7253), suggesting that the characteristics of the spike train that best discriminate regions are in some cases distinct from the characteristics used to discriminate structure. In combination, the 14 metrics substantially increased the overall balanced accuracy for each of the four tasks, although the visuocortical task remained challenging (<xref ref-type="fig" rid="fig2">Figure 2E–H</xref>; Brain Regions Balanced Accuracy = 52.91 ± 1.24; Hippocampal Structures = 44.10 ± 1.99; Thalamic Structures = 37.14 ± 2.57; Visuocortical Structures = 24.09 ± 1.46). Perhaps unsurprisingly, the classification of regions was more effective than the structures within them. Taken together, these results demonstrate an intermediate divisibility of regions and structures by logistic regression based on spiking metrics. Given that spiking metrics were predetermined and that logistic regression can only learn linearly discriminable features, it is possible that more robust anatomical information could emerge from the spike train with more complex learned representations.</p></sec><sec id="s2-4"><title>Flexible, non-linear embedding of anatomical information in neuronal spiking</title><p>The 14 spiking metrics were selected based on prior literature (<xref ref-type="bibr" rid="bib72">Schneider et al., 2023</xref>). However, spike timing can vary along an enormous number of axes, many of which are not indicated by preselected features. To test the possibility that non-parametric, data-driven representations of a neuron’s spiking might contain additional, valuable information regarding anatomy, we considered the full collection of each neuron’s interspike intervals (ISIs), that is the time between two consecutive spikes. Prior work suggests the increased complexity of the ISI distribution is best captured by a nonlinear classification model (<xref ref-type="bibr" rid="bib72">Schneider et al., 2023</xref>). Thus, we employed a multilayer perceptron (MLP). MLPs are a relatively simple class of feedforward artificial neural networks. Briefly, an MLP consists of an input layer, one or more hidden layers, and an output layer. Each layer is composed of interconnected nodes (artificial neurons) that process and transmit information via weighted connections and nonlinear activation functions. This enables MLPs to learn and model complex relationships between input features and output targets.</p><p>Broadly, MLPs were more successful in extracting anatomical information from spike trains than logistic regressions trained on spiking metrics (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). Specifically, MLPs were trained transductively (which enables transfer of patterns learned from neurons to unseen neighbors) on each of three arrangements of spike times: (1) the entire distribution of ISIs generated during the presentation of drifting gratings (0–3 s in 100 uniform bins), (2) each neuron’s average PSTH across all stimuli—essentially describing a cell’s mean response to stimuli, and (3) the concatenated mean PSTHs for each of the 40 combinations of drifting grating orientation and frequency. Across all four classification tasks (brain regions and three sets of structures), MLPs trained on the ISI distribution and concatenated PSTHs outperformed logistic regression models. Conversely, MLPs trained on the average PSTH (averaged across all drifting gratings without respect to orientation or frequency) exhibited reduced balanced accuracy (<xref ref-type="fig" rid="fig3">Figure 3</xref>). Together, these data suggest that the embedding of anatomical information in a neuron’s activity is recoverable when some form of precise information about spike time is available, and that anatomical information is degraded by averaging.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Anatomical information in spike trains is captured by nonlinear models that learn patterns in ISIs and stimulus-specific responses.</title><p>(<bold>A</bold>) Average balanced accuracy of transductive multi-layer perceptrons (MLPs) in classifying unit location in each task (rows) based on three representations of the spike train (columns). Chance is red, and peak balanced accuracy is blue. ISI dist—full distribution of ISIs; Avg PSTH—mean peristimulus time histogram across all trials; Cat PSTH—concatenation of PSTHs from all 40 stimuli (see Methods). (<bold>B</bold>) MLP sensitivity as a function of test data duration. Model was trained normally and tested on varying amounts of data from each of the four brain regions. (<bold>C</bold>) Feature importance from models that classified anatomy based on ISI dist. Features are ISI ranges between 0 and 3 s in 10 ms bins. 5 splits and 100 iterations. Error is ± 1 SEM across 100 shuffles. High value ranges for each region are highlighted. (<bold>D</bold>) Illustration of ISI mean, slope, and variance. (<bold>E</bold>) Regional distributions of mean, slope, and variance within the highlighted range (in <bold>C</bold>) compared to averages from all other regions within that range (gray). Multiple comparisons corrected t-tests: <inline-formula><alternatives><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&gt;=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft1">\begin{document}$p \gt =0.05$\end{document}</tex-math></alternatives></inline-formula>, *: <inline-formula><alternatives><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft2">\begin{document}$p \lt 0.05$\end{document}</tex-math></alternatives></inline-formula>, **: <inline-formula><alternatives><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.01</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft3">\begin{document}$ p \lt 0.01$\end{document}</tex-math></alternatives></inline-formula>, ***: <inline-formula><alternatives><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:mstyle></mml:math><tex-math id="inft4">\begin{document}$ p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>. Corresponding effect sizes as absolute value of Cohen’s d (left-to-right): 0.0697, 0.4391, 0.2080, 0.4029, 0.3417, 0.5682, 0.0958, 0.0621, 0.0697, 0.2521, 0.1000, 0.0382. Visuocortical structure information is enriched in subsets of stimuli. Each rectangle represents one of the 40 stimulus parameter combinations. Colors correspond to visuocortical structures, and the area of color shows the relative importance of that stimulus to model classification of the given structure. Cat PSTH model. Dashed boxes—exemplar stimulus conditions. (<bold>G</bold>) PSTHs corresponding to structure/stimulus pair indicated in (<bold>F</bold>). Specific structure PSTH shown in color. Average PSTH of all other structures shown in gray.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101506-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Unsmoothed transductive classification: confusion matrices.</title><p>Confusion matrices for MLP models using a transductive train/test split are shown. Matrices for four classification tasks (rows) and three different spiking activity representations (columns) are shown. Note that in the transductive condition, all neurons across animals are pooled and divided into train/test splits, such that there is a within-animal aspect to classifier learning. In individual matrices, the proportion of true instances of a particular class (columns) are distributed across a row reflecting the distribution of MLP predictions. Correct classifications fall along the diagonal from top left to bottom right. The confusion matrices’ labels, provided in the first column, are consistent in subsequent columns. Average (across the 5 splits) balanced accuracy (expressed as percent) for each task across the features from left to right: Regions (65.29 ± 0.97%, 53.96 ± 0.98%, 59.15 ± 0.83%), Hippocampus (41.72 ± 2.36%, 35.51 ± 1.67%, 44.16 ± 2.48%), Thalamus (39.15 ± 2.01%, 31.91 ± 2.50%, 43.25 ± 3.68%), Visual Ctx (25.84 ± 1.35%, 28.84 ± 2.46%, 38.35 ± 3.19%).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101506-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>MLP-based model sensitivity as a function of input duration.</title><p>Models were trained normally as tested with varying amounts (durations) of input data. In all but one example, model performance increases as a function of input size (duration). The exception is in the visuocortical task; the secondary structure, VISam, declines with time. This reflects the model’s failure to learn a robust pattern. Three tasks are shown: (<bold>A</bold>) Hippocampal Structures, (<bold>B</bold>) Thalamic structures, and (C) Visuocortical structures.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101506-fig3-figsupp2-v1.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Interpretation of hippocampal and thalamic MLPs.</title><p>(<bold>A</bold>) Hippocampal structure information is enriched in subsets of stimuli. Each rectangle represents one of the 40 stimulus parameter combinations. Colors correspond to hippocampal structures, and the area of color shows the relative importance of that stimulus to model classification of the given structure. Cat PSTH model. Dashed boxes—exemplar stimulus conditions. (<bold>B</bold>) PSTHs corresponding to structure/stimulus pair indicated in A. Specific structure PSTH shown in color. Average PSTH of all other structures shown in gray. (<bold>C, D</bold>) Same as A and B except for thalamic neurons and structures.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101506-fig3-figsupp3-v1.tif"/></fig></fig-group><p>Due to their reliance on hidden layers, MLPs are prone to the black-box effect; deep models often offer limited insight into the underlying mechanisms of their performance. To elucidate the features of ISI distributions and PSTHs that MLPs use to infer a neuron’s anatomical location, we strategically manipulated three features of our data: (1) we varied input duration, (2) we permuted specific bands of the ISI distribution, and (3) we permuted neuronal responses to specific drifting grating orientation/frequency combinations.</p><p>We passed progressively reduced lengths of input data, ranging from 1800s down to 0.1 s, into the fully trained model and evaluated its sensitivity (true positive rate). This approach allowed us to assess the timescale of the anatomically informative patterns learned by the MLP. If short intervals of data reliably indicated anatomy, it would suggest that models learn to detect acute and reliable signatures. Conversely, if model sensitivity increased monotonically with time, it would indicate that anatomical information is temporally distributed and cumulative. Our manipulation of the test set duration supported the latter hypothesis; sensitivity for all four brain regions increased as input data duration increased. In all conditions, the slope of the input duration versus sensitivity line was still positive at 1800s (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). Because the training data were of similar duration, this could be explained by either of two possibilities. First, the signal is relatively short, but noisy—in this case, extended sampling will increase reliability. Second, the anatomical signal is, itself, distributed over time scales of tens to hundreds of seconds.</p><p>ISIs vary extensively, from the biophysical minimum of the absolute refractory period to many seconds of silence. To test whether anatomical information might be enriched in specific temporal ISI windows, we assembled each neuron’s entire ISI distribution (0–3 s in 10ms bins) and selectively permuted subsets of intervals before passing the distribution to the trained MLP for classification. We shuffled ISI counts across neurons within specific temporal windows (e.g. ISIs between 50 and 60ms). This approach identified regions of the ISI distribution informative for classification. Consistent with temporal tuning, certain subsets of ISIs were more important than others for MLP performance, with the critical time windows varying by brain region (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). For instance, very fast ISIs (&lt;∼150ms) were particularly valuable for identifying midbrain neurons, while ISIs of 200–600ms made an outsized contribution to visual cortical classification.</p><p>To gain insight into how regional information could be enriched within these ISI ranges, we examined ISI distribution properties within each identified range, contrasting the region preferentially embedded in that range with all others. Across every region and range, there were subtle but statistically significant differences in the mean, variance, and slope of distributions (<xref ref-type="fig" rid="fig3">Figure 3D and E</xref>). This suggests the presence of coarse features in regionally relevant spiking patterns but does not rule out the contribution of a combination of multiple ISI ranges for reliable embedding.</p><p>Brain region, the coarsest anatomical classification task, was most effectively extracted from broad ISI distributions (65.29 ± 0.97% Balanced Accuracy vs. 59.15 ± 0.83% concatenated PSTH vs. 52.91 ± 1.23% in spike metrics-based logistic regression, chance = 25%; <xref ref-type="fig" rid="fig3">Figure 3A</xref>). In contrast, the discriminability of smaller and more numerous structures was greatest when MLPs were trained on detailed spike timing information (i.e. concatenated PSTHs; <xref ref-type="fig" rid="fig3">Figure 3A</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Somewhat intuitively, the most robust embedding of visual cortical structures was obtained in conjunction with visual stimulus information (38.35 ± 3.19% Balanced Accuracy vs. 25.84 ± 1.35% ISI distribution vs. 24.09 ± 1.46% in spike metrics-based logistic regression, chance = 17%; <xref ref-type="fig" rid="fig3">Figure 3A</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>).</p><p>We next asked whether structural information might be conveyed by differing responses to specific stimuli. Analogous to our methods for ISIs, we shuffled the values of particular PSTHs (with specified orientation and frequency) across neurons prior to passing PSTHs to the trained MLP for structure classification. We found that information about each of the visuocortical structures was embedded in the response to multiple stimulus variants. In other words, the MLP learning of visuocortical structure was not characterized by responses to a single set of stimulus parameters (<xref ref-type="fig" rid="fig3">Figure 3F</xref>). However, despite the distributed nature of structured information, some stimuli carried more predictive value than others (<xref ref-type="fig" rid="fig3">Figure 3G</xref>). Interestingly, despite PSTHs being defined by the presentation of visual stimuli, similar improvements were observed in hippocampal and thalamic structure tasks (Hippocampal structures: 44.16 ± 2.48% Balanced Accuracy vs. 41.72 ± 2.36% ISI distribution vs. 44.10 ± 1.99% in spike metrics-based logistic regression, chance = 20%; Thalamic structures: 43.25 ± 3.68% Balanced Accuracy vs. 39.15 ± 2.01% ISI distribution vs. 37.14 ± 2.57% in spike metrics-based logistic regression, chance = 14%; <xref ref-type="fig" rid="fig3">Figure 3A</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). This finding is noteworthy because, with the exception of the LGN, none of the constituent structures are primarily associated with visual processing.</p></sec><sec id="s2-5"><title>Anatomical codes generalize across animals and conditions</title><p>Our results demonstrate that anatomical information is embedded in the spike trains of single neurons. However, thus far, our results employ transductive models (which can learn patterns for unseen neurons from their immediate neighbors in the same animal). This raises the possibility that MLPs learned to identify animal-specific spiking patterns that do not generalize across individuals. As an example, if hippocampal neurons from animal <italic>n</italic> happen to be characterized by a specific rhythm, it is reasonable to assume that their neighbors, who happen to be withheld for the test set, exhibit similar activity. Transductive models are agnostic to whether such a pattern is anatomically meaningful and simply a one-off correlation that happens to be localized. To disambiguate these possibilities, we adopted an inductive approach in which the train and test sets are divided at the level of the entire animal. In other words, patterns are learned in one set of animals and tested on another group of animals that is entirely new to the model (<xref ref-type="fig" rid="fig1">Figure 1A</xref>).</p><p>We trained and tested inductive models on the four classification tasks — brain regions, hippocampal structures, thalamic structures, and visuocortical structures – across two input conditions, general ISI distributions and concatenated PSTHs. The null hypothesis is that anatomical information generalizes within the animal but not to new animals. In support of the alternate—that anatomical embedding is a universal feature in the spike train–inductive models performed significantly above chance in seven out of eight conditions and were statistically indistinguishable from the performance of transductive models for all four ISI-based tasks. In the four concatenated PSTH tasks, inductive models exhibited significantly lower balanced accuracy than transductive models, although they were still above chance in all but the hippocampal structures task (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). These results suggest that stimulus-dependent representations of anatomical location are predominately specific to the animal, while ISI distribution-based anatomical information is general across animals.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Spike time features that predict anatomy generalize across animals.</title><p>(<bold>A</bold>) Mean balanced accuracy (± SEM across 5 splits) of multi-layer perceptrons (MLPs) trained on ISI distributions and concatenated PSTHs in both inductive (withhold entire animals for testing) and transductive splits. Chance (red dashed line) varies by task. Linear mixed effects regression (ns/not significant: <inline-formula><alternatives><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo>&gt;=</mml:mo><mml:mn>0.05</mml:mn></mml:mstyle></mml:math><tex-math id="inft5">\begin{document}$ p \gt =0.05$\end{document}</tex-math></alternatives></inline-formula>, *: <inline-formula><alternatives><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.05</mml:mn></mml:mstyle></mml:math><tex-math id="inft6">\begin{document}$ p \lt 0.05$\end{document}</tex-math></alternatives></inline-formula>, **: <inline-formula><alternatives><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.01</mml:mn></mml:mstyle></mml:math><tex-math id="inft7">\begin{document}$ p \lt 0.01$\end{document}</tex-math></alternatives></inline-formula>, ***: <inline-formula><alternatives><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mstyle></mml:math><tex-math id="inft8">\begin{document}$ p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>). (<bold>B</bold>) Left: Illustration of an example implanted silicon array spanning isocortex, hippocampus, and thalamus. Right: Brain region probability for the example implant shown on the left calculated by smoothing across neuron-based classifications. Colored background shows the consensus prediction as a function of neuron location (electrode number). (<bold>C</bold>) Confusion matrix resulting from hierarchical (region then structure) inductive classification with smoothing. Matrix cells with proportion less than chance (1/number of classes) contain no text. Average balanced accuracy after smoothing (by task): Brain Regions = 89.47 ± 2.98%; Hippocampal Structures = 51.01 ± 4.50%; Thalamic Structures = 53.21 ± 7.59%; Visuocortical Structures = 38.48 ± 3.31% (error is the SEM across 5 splits). Overall balanced accuracy: 46.91 ±1.90%.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101506-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Unsmoothed inductive classification: confusion matrices.</title><p>Confusion matrices for MLP models using an inductive train/test split are shown. Note that in the inductive condition, models are trained on all neurons from a subset of animals and tested on all neurons from a withheld group of animals. This eliminates any possibility of learning a local solution within animals. Matrices for four classification tasks (rows) and three different spiking activity representations (columns) are shown. In individual matrices, the proportion of true instances of a particular class (columns) are distributed across a row reflecting the distribution of MLP predictions. Correct classifications fall along the diagonal from top left to bottom right. The confusion matrices’ labels, provided in the first column, are consistent in subsequent columns. Average (across the 5 splits) balanced accuracy values (in %) for each task across the features from left to right: Regions (65.10 ± 1.77%, 51.72 ± 0.97%, 49.16 ± 0.95%), Hippocampus (35.89 ± 1.42%, 26.39 ± 1.36%, 21.50 ± 0.92%), Thalamus (32.79 ± 2.37%, 26.28 ± 2.98%, 21.72 ± 0.86%), Visual Ctx (25.52 ± 0.73%, 25.83 ± 0.61%, 26.51 ± 0.94%).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101506-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Smoothed inductive classification: confusion matrices.</title><p>Confusion matrices for MLP models using an inductive (across animals) train/test split are shown. Note that in the inductive condition, models are trained on all neurons from a subset of animals and tested on all neurons from a withheld group of animals. This eliminates any possibility of learning a local solution within animals. Matrices for four classification tasks (rows) and three different spiking activity representations (columns) are shown. In individual matrices, the proportion of true instances of a particular class (columns) is distributed across a row reflecting the distribution of MLP predictions. Correct classifications fall along the diagonal from top left to bottom right. The confusion matrices’ labels, provided in the first column, are consistent in subsequent columns. Average (across the 5 splits) balanced accuracy values (in %) for each task across the features from left to right: Regions (89.47 ± 2.98%, 67.95 ± 2.14%, 63.92 ± 1.13%), Hippocampus (51.01 ± 4.50%, 39.31 ± 4.90%, 25.84 ± 2.62%), Thalamus (53.21 ± 7.59%, 35.38 ± 3.77%, 24.81 ± 3.14%), Visual Ctx (38.48 ± 3.31%, 44.66 ± 3.21%, 43.97 ± 3.38%).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101506-fig4-figsupp2-v1.tif"/></fig></fig-group></sec><sec id="s2-6"><title>Single neuron classification errors can be corrected by population context</title><p>While the ISI-based inductive models demonstrate that generalizable anatomical information is carried in single unit spike trains, classification is imperfect. Note that the model classifies individual neurons via a winner-take-all approach. Even for correctly labeled neurons, the probability for the chosen class only needs to narrowly exceed the probability of other options. We next asked to what extent such uncertainty could be mitigated if the consensus was taken across a group of neurons, analogous to how the brain processes noisy information (<xref ref-type="bibr" rid="bib63">Riehle et al., 1997</xref>; <xref ref-type="bibr" rid="bib43">Maass, 2000</xref>; <xref ref-type="bibr" rid="bib59">Paz et al., 2016</xref>). One possibility is that uncertainty is driven by shared noise amongst neighboring cells. Errors of this form could be amplified by a consensus vote. Alternatively, if incorrect classifications are stochastically distributed across a recording array, errors should be trivially correctable by considering the surrounding ensemble—a stray CA1 neuron should not be detected in the middle of CA3, for example. To test this, we added a second step following single unit classification. This step comprised the use of a Gaussian kernel to smooth anatomical probabilities across neurons recorded on neighboring electrodes.</p><p>In support of the stochastic error hypothesis, smoothing dramatically increased the balanced accuracy of MLPs in all four tasks. The brain region identification task improved from 65.10 ± 1.77%–89.47 ± 2.98% compared to non-smoothed inductive models. The smoothed regional prediction probabilities across an individual probe from an example animal are shown in <xref ref-type="fig" rid="fig4">Figure 4B</xref>. Similarly, the hippocampal task improved from 35.89 ± 1.42%–51.01 ± 4.50%, the thalamic task improved from 32.79 ± 2.37%–53.21 ± 7.59%, and the visuocortical task improved from 25.52 ± 0.73%–38.48 ± 3.31% (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>, <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). This suggests that erroneously labeled neurons do not share anatomically relevant spike patterns with nearby cells, and thus are amenable to consensus-based correction.</p><p>To this point, MLPs were trained and tested only on neurons related to an individual task. For example, MLPs trained on visuocortical structures were never exposed to thalamic neurons. To evaluate inductive models across the full set of regional and structural comparisons while capitalizing on smoothing of errors, we trained a hierarchical model that combined smoothed brain region classification with subsequent smoothed structure identification. Across all 19 labels (18 structures and midbrain), the hierarchical inductive model achieved a balanced accuracy of 46.91 ±1.90% (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). An observable effect of a hierarchical approach is that, because smoothed brain region classification is so effective, errors generally occur only between similar structures (VISl vs. VISal) rather than highly divergent ones (VISl vs. CA1). Here, only 5 out of the total 250 possible cross-regional errors occurred above chance (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). These data demonstrate that, with smoothing, a hierarchical model can extract surprisingly effective anatomical structure information from single neuron spike timing that generalizes to unseen animals. This further suggests that there is a latent neural code for anatomical location embedded within the spike train, a feature that could be practically applied to determining the brain region of a recording electrode without the need for post-hoc histology. While significantly above chance, the structure-level model still lacks the accuracy for immediate practical application. However, it is highly likely that the incorporation of datasets with diverse multi-modal features and alternative regions from other research groups will increase the accuracy of such a model. In addition, a computational approach can be combined with other methods of anatomical reconstruction.</p></sec><sec id="s2-7"><title>Spike train embedding of visual superstructure and cortical layer</title><p>Even with smoothing, visuocortical structures remained the most challenging to classify. There are two possible explanations for this. First, it may be that there are truly no consistent differences in the organization of single unit spiking across visuocortical structures. Alternatively, there are true differences but our MLP-based approach fails to learn them. Although there are clear cytoarchitectural boundaries between primary visual cortex (VISp) and secondary visual areas, the differentiation of secondary visual areas is functionally determined (<xref ref-type="bibr" rid="bib82">Wang and Burkhalter, 2007</xref>; <xref ref-type="bibr" rid="bib26">Glickfeld and Olsen, 2017</xref>). We asked whether broadly defined superstructures, VISp and VISs—a combination of all secondary areas (VISal, VISam, VISl, VISpm, and VISrl)–increases the effectiveness of spike time-based classification (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). We trained an MLP on VISp versus VISs, and, in this binarized context, observed a balanced accuracy of 79.98 ±3.03 % (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). This effect was driven by VISs, which achieved 96% sensitivity. To understand if converting six visual structures into two superstructures truly improved discriminability, it is necessary to make the equivalent comparison in the more complex model. To achieve this, we simply took the results of the visuocortical task across 6 structures (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>, bottom left) and collapsed the secondary regions into a single class. Intriguingly, this yielded a balanced accuracy of 91.02 ± 0.95%, driven by VISp at 94.4% sensitivity. A likely explanation is that, despite using resampling strategies to correct for class imbalance, VISp initially has more true units than any other structure in the 6-class task, incentivizing accurate classification of it. In contrast, for the binary classification, VISp has fewer units than all secondary structures combined (VISs), which instead incentivises classification of VISs. It seems VISp is a more effective classification target for this problem. These results suggest that the computational differentiability of murine visuocortical regions is at the level of VISp versus secondary areas.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Primary vs secondary distinction and cortical layer are more evident in spike timing than individual structures.</title><p>(<bold>A</bold>) Illustration of visuocortical structures that can be grouped into primary versus secondary superstructures: VIS-am, -pm, -l, -al, -rl are grouped into secondary visual cortex (VISs) while VISp is primary visual cortex. (<bold>B</bold>) Confusion matrix resulting from inductive classification of superstructure (with smoothing). Cells with proportion less than chance (1/number of classes) contain no text. Balanced accuracy is 79.98 ± 3.03%. (C) Left: Illustration of example array implanted across cortical layers. Right: Layer probability for the example implant shown on the left calculated by smoothing across neuron-based classifications. Colored background shows the consensus prediction as a function of neuron location (electrode number). (<bold>D</bold>) Confusion matrix resulting from smoothed inductive classification of layer. Balanced accuracy is 62.59 ± 1.12%.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101506-fig5-v1.tif"/></fig><p>Another major axis along which cortical neurons exhibit anatomical structure is layer. This aligns with recent evidence that indicates that cortical layers can be distinguished computationally, particularly in terms of cell types and tuning preferences (<xref ref-type="bibr" rid="bib72">Schneider et al., 2023</xref>; <xref ref-type="bibr" rid="bib38">Lee et al., 2024</xref>; <xref ref-type="bibr" rid="bib85">Wang et al., 2022</xref>). Thus, we hypothesized that cortical layer might be more reliably embedded in single unit spike times than visuocortical structure. Consistent with this, models trained on visuocortical neurons from all structures were able to robustly recover layer information (<xref ref-type="fig" rid="fig5">Figure 5C and D</xref>). It is noteworthy that transductive and inductive models achieved similar balanced accuracies on both ISI distribution (inductive unsmoothed balanced accuracy: 46.43 ± 0.97%, inductive smoothed: 62.59 ± 1.13%, transductive unsmoothed: 46.52 ± 0.63%, transductive smoothed: 60.37 ± 2.64%) and concatenated PSTHs (inductive unsmoothed: 41.13 ± 1.28%, inductive smoothed: 52.16 ± 2.38%, transductive unsmoothed: 41.66 ± 0.51%, transductive smoothed: 52.35 ± 1.69%). However, cortical layer information was more robust in the broad ISI distribution, which outperformed concatenated PSTHs, even in transductive models. Also noteworthy is the fact that layer IV exhibited the greatest confusion (specifically, with adjacent layers), achieving a sensitivity of only 28%. These results suggest that general embeddings are more readily available for cortical layers than cortical structures.</p></sec><sec id="s2-8"><title>Anatomical embeddings generalize across experimental conditions</title><p>Drifting gratings, while widely embraced across decades of research in the visual system, are highly stereotyped and low dimensional compared to natural visual environments. As a result, the anatomical embeddings described thus far could require the repeated presentation of drifting gratings. In other words, it is reasonable to suggest that anatomical information embedded in single-unit activity would be immediately obscured by a complex visual environment. To evaluate this, we trained new, inductive MLPs on single unit activity in the context of drifting gratings as well as two additional conditions: (1) the presentation of naturalistic movies (ten repeated presentations of a 120 s long excerpt from the film <italic>Touch of Evil</italic>), and (2) spontaneous activity (an unchanging gray screen; <xref ref-type="fig" rid="fig6">Figure 6</xref>). We then tested these MLPs on activity from all three conditions. This allowed us to ascertain (a) whether anatomical information is available outside of the context of drifting gratings and (b) whether the anatomical information learned in one condition can generalize to another.</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Anatomical information embedding in spike trains generalizes across diverse stimuli.</title><p>(Top Left) Schematic showing inductive train/test split along with visual stimuli: naturalistic movie, drifting gratings, spontaneous activity (i.e. gray screen). (Left Column) Grids showing Matthew’s Correlation Coefficient (MCC) values for pairs of training stimuli (grid rows) and testing stimuli (grid columns). Grid diagonals (top right to bottom left) represent train/test within the same stimuli. (Right Column) Confusion matrices corresponding to each of the MCC grids in the left column.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101506-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>The effect of training and testing within and across stimulus conditions.</title><p>For each classification task (e.g. Brain Regions), the bar chart shows the mean MCC value with standard error for models trained and tested on the same stimulus condition (e.g. train: drifting gratings and test: drifting gratings; train: natural movie and test: natural movie) in gray. In black, MCC of models trained and tested on different stimuli (e.g. train: drifting gratings and test: spontaneous; train: natural movies and test: drifting gratings). Linear mixed effects. (ns/not significant: <inline-formula><alternatives><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo>&gt;=</mml:mo><mml:mn>0.05</mml:mn></mml:mstyle></mml:math><tex-math id="inft9">\begin{document}$ p \gt =0.05$\end{document}</tex-math></alternatives></inline-formula>, *<inline-formula><alternatives><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.05</mml:mn></mml:mstyle></mml:math><tex-math id="inft10">\begin{document}$ p \lt 0.05$\end{document}</tex-math></alternatives></inline-formula> **:, <inline-formula><alternatives><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.01</mml:mn></mml:mstyle></mml:math><tex-math id="inft11">\begin{document}$ p \lt 0.01$\end{document}</tex-math></alternatives></inline-formula>, ***: <inline-formula><alternatives><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>0.001</mml:mn></mml:mstyle></mml:math><tex-math id="inft12">\begin{document}$ p \lt 0.001$\end{document}</tex-math></alternatives></inline-formula>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101506-fig6-figsupp1-v1.tif"/></fig></fig-group><p>We tested every pairing of train/test condition on each of six tasks: brain regions, hippocampal structures, thalamic structures, visuocortical structures, visuocortical layers, and visuocortical superstructures. Chance levels varied between 14.3 and 50% across tasks. To facilitate inter-task comparisons, we quantified accuracy by employing Matthews Correlation Coefficient (MCC). MCC is a balanced measure that takes into account true and false positives and negatives, providing a reliable statistical measure especially for imbalanced datasets (<xref ref-type="bibr" rid="bib17">Chicco and Jurman, 2020</xref>; <xref ref-type="bibr" rid="bib9">Boughorbel et al., 2017</xref>). MCC values range from –1 to +1, with +1 representing perfect prediction, 0 indicating performance no better than random chance, and –1 signifying total disagreement between prediction and observation. Importantly, MCC is normalized by the number of categories, allowing for comparisons across tasks with different numbers of classes (<xref ref-type="bibr" rid="bib36">Jurman et al., 2012</xref>).</p><p>MLPs across almost every task and every pairing of train/test condition performed far above chance (MCC chance = 0) (<xref ref-type="fig" rid="fig6">Figure 6</xref>, left column). MLPs tasked with brain region showed remarkable generalizability across stimuli (mean MCC = 0.90). This was followed by hippocampal structures (mean MCC = 0.46), visuocortical layers (mean MCC = 0.41), thalamic structures (mean MCC = 0.30), visuocortical superstructures (mean MCC = 0.26), and visuocortical structures (mean MCC = 0.18). Interestingly, the only instances of chance-level performance arose in the visuocortical superstructure task—MLPs chance (MCC = 0) when trained on drifting gratings and tested on either spontaneous activity or naturalistic movies. While this appears consistent with stimulus-specific embeddings, visuocortical MLPs trained on spontaneous activity were above chance when tested on drifting gratings. The same was true for those trained on naturalistic movies. Taken together, these data suggest that the embedding of anatomical information in single neuron activity is not abolished by complex visual stimuli or spontaneous activity, and that the embeddings learned in one context are not absent in other contexts. The visuocortical superstructure task results imply that, in some contexts, complex stimuli may produce more generalizable results than simple stimuli.</p><p>In each of the 54 combinations of task and train/test condition, there were diverse underlying patterns of MLP learning (<xref ref-type="fig" rid="fig6">Figure 6</xref>, right column). Intuitively, instances with high MCC, such as those in the brain regions task, produced strong diagonal structure (where the predicted class aligns with the true class). Tasks resulting in lower MCC, such as the visuocortical structures, yielded slight diagonal structure in some cases, but were driven by a small number of accurate points. Across all six tasks, within-stimulus models (e.g. trained on spontaneous, tested on spontaneous) tended to produce significantly greater MCCs than across-stimulus models, although all were above chance (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>).</p></sec><sec id="s2-9"><title>Anatomical embeddings generalize across research laboratories</title><p>The results of inductive models trained and tested in mismatched conditions suggest that, amidst stimulus information, neuronal spike trains carry universal signatures of their anatomical location. If this were true, it should be possible to apply models trained on animals from one research group—in this case, the Allen Brain Observatory team—and decode neuronal anatomy from data generated at an independent location. In other words, the Allen-based model should predict a neuron’s anatomical location based on its spike train even if the recording was conducted in a different location and experimental context.</p><p>To test this, we required independently generated data that maintained two key features: (1) the spatiotemporal micro-scale resolution of the Allen Institute’s recordings, and (2) the anatomical breadth of the Allen Institute’s recordings. These criteria were satisfied by an open dataset from <xref ref-type="bibr" rid="bib79">Steinmetz et al., 2019</xref>, which comprises high-density silicon recordings that span many of the same regions and structures examined in the Allen data. However, the experiments (<xref ref-type="bibr" rid="bib79">Steinmetz et al., 2019</xref>) are markedly different, in that they comprise mice trained to carry out a decision-making task. Summarily, the task involved observing a Gabor patch of fixed orientation (45°) and spatial frequency (0.1 cycles per degree) with varying contrast on either the left or right side, in response to which the mouse must turn a wheel toward the side with higher contrast (<xref ref-type="bibr" rid="bib79">Steinmetz et al., 2019</xref>). Recall that the Allen data were recorded in the context of passive viewing (<xref ref-type="fig" rid="fig7">Figure 7A</xref>).</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Anatomical information embedded in spike trains generalizes across laboratories and protocols.</title><p>(A) Illustration of behavioral tasks employed by two laboratories: (left) Passive Viewing (Allen Institute) vs. (right) Active Decision-Making (Steinmetz et al.). In Active Decision-Making, the mouse spins a wheel in response to the location of the drifting grating presented on the screen. (B) Bubble chart showing balanced accuracy of individual test set animals from the Steinmetz et al. The model was trained on Allen Institute data. Bubble size indicates the number of units recorded in the test animal. Black horizontal lines represent the median of the balanced accuracy distributions across the animals. Models are trained with either drifting gratings alone (purple) or a combination of drifting gratings, natural movies, and spontaneous/gray screen (green). Balanced accuracy across all Steinmetz et al. neurons: BR DG = 80.46%, BR Mix: 81.28 %, HS DG: 40.07 %, HS Mix: 69.89 %, TS DG: 21.52 %, TS Mix: 58.22 %, VCS DG: 28.41 %, VCS Mix: 28.34 %, VCSS DG: 58 %, VCSS Mix: 59 %, VC Layers DG: 46.36 %, VC Layers Mix: 49.01% where BR stands for brain regions, HS hippocampal structures, TS thalamic structures, VCS visual cortex structures, VCSS visual cortex superstructures, DG drifting gratings and Mix denotes the combined stimuli. (C) Confusion matrices for prediction of hippocampal structures in Steinmetz et al. test set when trained on drifting gratings stimulus (left) vs. mixed stimuli (right) from the Allen Institute. (D) Confusion matrices for prediction of thalamic structures in Steinmetz et al. test set when trained on drifting gratings stimulus (left) vs. mixed stimuli (right) from the Allen Institute.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101506-fig7-v1.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>Train/test across laboratories: Allen-to-Steinmetz et al. confusion matrices.</title><p>Six tasks are displayed. The y-axis label denotes the task (e.g. Regions), and the column label denotes the training condition (drifting gratings or mixed stimuli). All models involve training on the Allen Institute data and testing on Steinmetz et al. data. Mixed stimuli models are trained on neuronal activity recorded during the presentation of drifting gratings, natural movies, and spontaneous activity. Balanced accuracy corresponding to each confusion matrix: BR DG = 80.46%, BR Mix: 81.28 %, HS DG: 40.07 %, HS Mix: 69.89 %, TS DG: 21.52 %, TS Mix: 58.22 %, VCS DG: 28.41 %, VCS Mix: 28.34 %, VCSS DG: 58 %, VCSS Mix: 59 %, VC Layers DG: 46.36 %, VC Layers Mix: 49.01% where BR stands for brain regions, HS hippocampal structures, TS thalamic structures, VCS visual cortex structures, VCSS visual cortex superstructures, DG drifting gratings and Mix denotes the combined stimuli.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-101506-fig7-figsupp1-v1.tif"/></fig></fig-group><p>We classified anatomy in <xref ref-type="bibr" rid="bib79">Steinmetz et al., 2019</xref> data using two variants of our Allen-based models; one trained on ISI distributions recorded during the presentation of drifting gratings, and one trained on ISI distributions recorded in three conditions (drifting gratings, naturalistic movies, and spontaneous activity). Both models successfully predicted brain region above chance in every Steinmetz et al. animal (N=10), with the exception of one animal in the drifting gratings model (mean balanced accuracy calculated across neurons, drifting gratings model—80.46%; combined stimuli—81.28%; <xref ref-type="fig" rid="fig7">Figure 7B</xref>). At the level of structures, two general principles emerged: (1) models trained on combined stimuli were generally more effective than drifting gratings models— this is particularly evident when examining diagonal structure in the confusion matrices (<xref ref-type="fig" rid="fig7">Figure 7B and C</xref>, 6.8), and (2) the visuocortical structures task did not transfer effectively between laboratories (drifting gratings model—28.41%, mixed model—28.34%). Hippocampal and thalamic structures as well as visuocortical layers were identifiable well above chance, especially in mixed models (drifting gratings/mixed models: hippocampal structures—40.07/69.89%; thalamic structures—21.52/58.22%; visuocortical layers—46.36/49.01%). Visuocortical superstructures were marginally identified, but only in the combined stimuli model (drifting gratings model—58.03%, mixed model—59.08%), as only one animal was above chance in the drifting gratings condition (<xref ref-type="fig" rid="fig7">Figure 7B</xref>). Note that, due to differences in the recordings and number of units from the structures, each Steinmetz et al. task involved four classes, such that chance is 25% with the exception of visuocortical structures (<italic>k</italic>=5, chance = 20%) and visuocortical superstructures (<italic>k</italic>=2, chance = 50%). Finally, error is not reported as there are no splits to test across in the Steinmetz et al. data; balanced accuracy is reported for the entire applicable dataset.</p><p>Taken together, these data suggest that information about a neuron’s anatomical location can be extracted from the time series of its spiking. This principle appears to apply to neurons from diverse structures across the telencephalon, diencephalon, and mesencephalon. Further, some of the rules by which this information is organized are shared across animals and are not an artifact of a task or local protocol.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Understanding the information carried within a neuron’s spiking has been the subject of investigation for a century (<xref ref-type="bibr" rid="bib1">Adrian and Bronk, 1928</xref>). While it is well established that neuronal activity encodes stimuli, behavior, and cognitive processes (<xref ref-type="bibr" rid="bib21">Faisal et al., 2008</xref>; <xref ref-type="bibr" rid="bib25">Gerstner et al., 2014</xref>), the possibility that spike trains might also carry information about a neuron’s own anatomical identity has remained largely unexplored. Our study provides compelling evidence that such anatomical information is indeed embedded within neuronal spike patterns. Using machine learning approaches, we demonstrate that this embedding is robust across multiple spatial scales, from broad brain regions to specific structures and cortical layers. Crucially, these anatomical signatures generalize across animals, experimental conditions, and even research laboratories, suggesting a fundamental principle of neural organization. Our findings reveal a previously unrecognized dimension of the neural code, one that is multiplexed with the encoding of external stimuli and internal states (<xref ref-type="bibr" rid="bib54">Olshausen and Field, 2004</xref>; <xref ref-type="bibr" rid="bib29">Harris and Thiele, 2011</xref>; <xref ref-type="bibr" rid="bib57">Parks et al., 2023</xref>). These data advance an understanding of the relationship between structure and function in neural circuits, raising the possibility that structure is not ancillary to neuronal computation, but intrinsically embedded within it. Beyond fundamental scientific insight, our findings may be of benefit in various practical applications, such as the continued development of brain-machine interfaces and neuroprosthetics, as well as for the interpretation of large-scale neuronal recordings. Note, however, that a purely utilitarian goal, for example electrode localization in electrophysiological recordings, would be well served by considering additional features, such as extracellular waveforms (<xref ref-type="bibr" rid="bib13">Buccino et al., 2018</xref>; <xref ref-type="bibr" rid="bib35">Jia et al., 2019</xref>), in addition to spike timing. While this approach holds promise for practical application, the inclusion of waveform information subverts the question of whether a neuron’s output—the timing of its spiking–contains an embedding of its location.</p><p>Clearly, there are powerful differences throughout the brain as a function of anatomy. There is extensive literature to describe this diversity at many levels, from gene expression gradients in hippocampal pyramidal neurons (<xref ref-type="bibr" rid="bib14">Cembrowski et al., 2016</xref>) to distinct connectivity patterns across cortical layers (<xref ref-type="bibr" rid="bib30">Harris et al., 2019</xref>). A complementary albeit smaller literature provides some indication that, at a coarse-grained level, similar gradients can be identified in neuronal activity. For example, examined at the level of the entire population, there are subtle but reliable differences in isocortical neuronal variability in functionally distinct cortical areas (<xref ref-type="bibr" rid="bib74">Shinomoto et al., 2009</xref>). Similarly, considered as a population-level statistic, there is a cortical gradient of neuronal intrinsic timescale (a measure of how long a neuron’s activity remains correlated with itself over time) (<xref ref-type="bibr" rid="bib52">Murray et al., 2014</xref>). However, while the ability to detect statistical differences across a population demonstrates that anatomy bears some influence on brain activity, it does not suggest that anatomy can be extracted from a single neuron’s activity. This is exemplified by placing two observations side by side. First, single neuron firing rates are log-normally distributed. This means that within any given brain region, there is a wide range of firing rates, with a long tail of high-firing neurons. Second, the population-level distribution of firing rates varies slightly but significantly as a function of region (<xref ref-type="bibr" rid="bib66">Roxin et al., 2011</xref>; <xref ref-type="bibr" rid="bib50">Mizuseki and Buzsáki, 2013</xref>). The combination of these facts implies that while there may be detectable differences between regions at the population level, the extensive overlap in firing rate distributions makes it challenging, if not impossible, to determine a neuron’s anatomical origin based solely on its firing rate.</p><p>Here, we approach this problem from a fundamentally different perspective than the population-based paradigm. Capitalizing on (1) the availability of open, high-density recordings across a plurality of brain regions and (2) machine learning methods capable of learning complex, nonlinear relationships, we approach the problem at the level of single neuron classification. This approach has strengths and weaknesses. The principal strength is the revelation that anatomical information is embedded in the activity of individual neurons throughout the brain. The principal weakness is limited interpretability, a criticism widely raised when contemplating machine learning (even when addressing this issue, the ground-truth patterns can themselves be complex and non-intuitive, e.g., <xref ref-type="fig" rid="fig3">Figure 3</xref>). However, in exchange for simplicity, our approach is founded on establishing whether there exist spike train-based anatomical signatures that generalize across animals, experimental conditions, and research laboratories. That such signatures are readily identifiable indicates neurons are not mere conduits of stimulus-related information. While neurons can be described as rate-varying Poisson processes (<xref ref-type="bibr" rid="bib78">Softky and Koch, 1993</xref>), it is increasingly clear that a more complete description should incorporate additional streams of information, such as transcriptomic cell type and anatomy across varying time scales (<xref ref-type="bibr" rid="bib72">Schneider et al., 2023</xref>; <xref ref-type="bibr" rid="bib48">Mi et al., 2023</xref>).</p><p>Our findings reveal a striking difference in the generalizability of anatomical information encoded in ISI distributions versus PSTHs. Specifically, inductive models trained on ISI distributions maintained performance levels comparable to their transductive counterparts across all tasks, while PSTH-based models showed a significant drop in performance when tested on new animals. This is perhaps surprising, given that stimulus response properties (such as receptive field size and response latency) are generally understood to exhibit some consistency across animals recorded under equivalent conditions (<xref ref-type="bibr" rid="bib53">Niell and Stryker, 2008</xref>; <xref ref-type="bibr" rid="bib71">Schmolesky et al., 1998</xref>; <xref ref-type="bibr" rid="bib75">Siegle et al., 2021</xref>). Viewed through the lens of stimulus and response, PSTHs in the Allen Institute datasets are robust to slight differences in retinotopic locations across animals (<xref ref-type="bibr" rid="bib75">Siegle et al., 2021</xref>). Despite this, our PSTH-based models performed poorly when trying to predict anatomical location in new animals under the same stimulus conditions. Thus, it is likely that stimulus-response information is dissociable from the embedding of anatomical location.</p><p>The difference in generalizability when comparing PSTH- and ISI-based models may reflect a fundamental distinction in the nature of information captured by these two representations of neural activity. ISI distributions encapsulate intrinsic properties of neuronal firing patterns that appear to be conserved across animals, potentially reflecting stable, anatomy-specific computational features. These might include cell types and their resultant ion channel compositions (<xref ref-type="bibr" rid="bib87">Zeisel et al., 2018</xref>; <xref ref-type="bibr" rid="bib69">Saunders et al., 2018</xref>), local circuit motifs (<xref ref-type="bibr" rid="bib10">Braganza and Beck, 2018</xref>; <xref ref-type="bibr" rid="bib41">Luo, 2021</xref>), or homeostatic mechanisms that shape firing statistics independent of stimuli (<xref ref-type="bibr" rid="bib32">Hengen et al., 2013</xref>; <xref ref-type="bibr" rid="bib33">Hengen et al., 2016</xref>; <xref ref-type="bibr" rid="bib42">Ma et al., 2019</xref>). Crucially, these features are not inherently tied to a stimulus. In contrast, PSTHs involve studying the repeated presentation of the same stimulus. Despite this repetition, there is neuron and trial level variability (<xref ref-type="bibr" rid="bib62">Renart and Machens, 2014</xref>; <xref ref-type="bibr" rid="bib18">Cohen and Kohn, 2011</xref>). Neuronal response variability to repeated stimuli often correlates among nearby neurons (<xref ref-type="bibr" rid="bib76">Smith and Kohn, 2008</xref>; <xref ref-type="bibr" rid="bib77">Smith and Sommer, 2013</xref>) and is influenced by local circuit connectivity and the animal’s cognitive factors such as attention (<xref ref-type="bibr" rid="bib64">Rosenbaum et al., 2017</xref>; <xref ref-type="bibr" rid="bib67">Ruff and Cohen, 2014</xref>). Thus, transductive models may learn from variability in the training dataset that is highly informative in the test dataset. However, such variability would not carry across animals. The robustness of ISI-based anatomical embeddings across animals and even across laboratories underscores the fundamental nature of these anatomical fingerprints in neural activity, transcending individual differences and specific experimental paradigms.</p><p>Our analysis of visual isocortical structures offers intriguing insights into the computational organization of the murine visual system. While PSTH-based models performed well in classifying visual areas, suggesting stimulus-specific differences in neuronal responses across these regions, the overall classification accuracy remained relatively low compared to other brain areas. This finding aligns with previous studies that have demonstrated differences in orientation and spatial frequency tuning across mouse visual areas (<xref ref-type="bibr" rid="bib45">Marshel et al., 2011</xref>; <xref ref-type="bibr" rid="bib5">Andermann et al., 2011</xref>; <xref ref-type="bibr" rid="bib65">Roth et al., 2012</xref>; <xref ref-type="bibr" rid="bib6">Ayzenshtat et al., 2016</xref>). However, our results suggest that these differences, while statistically significant at the population level, may not translate into robust, neuron-specific computational signatures. The murky distinction between primary and secondary visual areas in mice is reflected in our data, with the most reliable discrimination occurring between primary visual cortex (VISp) and grouped secondary areas, rather than among individual secondary regions. Even this distinction, however, was not dramatic. Interestingly, we found that isocortical layers within visual areas were more readily distinguishable than the areas themselves, suggesting that laminar organization may play a more fundamental role in shaping neuronal computations than areal boundaries in mouse visual cortex. This hierarchical organization - from broad regions to superstructures (e.g. VISp vs. secondary areas) to substructures (layers) - provides a nuanced view of functional specialization in the mouse visual system. While numerous recent studies have indicated functional specialization of mouse higher visual areas beyond VISp (<xref ref-type="bibr" rid="bib82">Wang and Burkhalter, 2007</xref>; <xref ref-type="bibr" rid="bib26">Glickfeld and Olsen, 2017</xref>; <xref ref-type="bibr" rid="bib37">Kumar et al., 2021</xref>), our data suggest that these specializations may not manifest as significant differences in single neuron spiking features across areas. This observation raises the possibility that secondary visual areas in mice may not be computationally distinct, at least in terms of their constituent neurons’ fundamental spiking patterns. The relative inability to classify the structure of visual cortical neurons may, in fact, reflect a genuine neurobiological feature: the computational properties of neurons in different visual areas may be largely indistinguishable based on spike timing alone.</p><p>Our findings demonstrate that individual neurons embed information about their anatomical location in their spike patterns, with these anatomical embeddings conserved across animals and experimental conditions. This previously unrecognized aspect of neural coding raises questions about the relationship between brain structure and function at the single-neuron level. Future research will be crucial in determining whether and how different streams of information, including these anatomical embeddings, contribute to neural computation and the variegated functions of the brain. While the technical barriers are daunting, the obvious experiment is to manipulate a neuron’s anatomical embedding while minimally impacting external and internal variables, such as stimulus information and levels of neurotransmitters or neuromodulators. Should this disrupt any aspect of sensation, perception, cognition, or behavior, the answer would be clear. If not, there is still great practical utility in an experimenter’s capacity to ascertain anatomy based on neuronal activity.</p></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Datasets</title><p>Neurodata Without Borders (NWB) files for the Allen Institute’s Visual Coding Neuropixels dataset were retrieved with AllenSDK (<xref ref-type="bibr" rid="bib2">Allen Institute for Brain Science, 2019</xref>). Units passing the default filtering criteria of ISI violations &lt; 0.5, amplitude cutoff &lt; 0.1, and presence ratio &gt; 0.9 were selected for further analysis. Units with a firing rate below 0.1 Hz over the session were excluded.</p><p>Mice were head fixed and presented with visual stimuli for a roughly 3-hr session (<xref ref-type="bibr" rid="bib75">Siegle et al., 2021</xref>). The mice were shown one of the two slightly different visual stimulus sets: ‘Brain Observatory 1.1’ (N=32 animals) or ‘Functional Connectivity’ (N=28 animals; <xref ref-type="bibr" rid="bib3">Allen Institute MindScope Program, 2019a</xref>; <xref ref-type="bibr" rid="bib4">Allen Institute MindScope Program, 2019b</xref>). From these sessions, we retrieved spike times coincident with the presentation of drifting gratings and natural movie three from ‘Brain Observatory 1.1’ and gray screen (spontaneous) from both sets. For each animal, 30 min of drifting gratings were presented. Each trial consisted of 1 s of gray screen followed by 2 s of drifting gratings. Gratings were varied in spatial orientation (0°, 45°, 90°, 135°, 180°, 225°, 270°, 315°) and temporal frequency (1, 2, 4, 8, and 15 Hz), but consistent in spatial frequency (0.04 cycles/degree) and contrast (80%) with 15 equivalent presentations of each particular stimulus. Separately, a sustained mean-luminance blank (gray) screen was presented during intervals between blocks of stimuli. In total, the gray screen was presented in this manner for approximately 20 min to each animal. Natural movie three consisted of a 120 s clip from the opening scene of the movie Touch of Evil (<xref ref-type="bibr" rid="bib86">Welles, 1958</xref>) repeated 10 times. After passing through the criteria above, there were 18,961 units for drifting gratings and natural movie three (visual cortex = 9402, hippocampus = 4301, thalamus = 4068, and midbrain = 920) while the spontaneous stimulus contains 37,458 units (visual cortex = 18,514, hippocampus = 10,337, thalamus = 6625, and midbrain = 1982). In order to have at least 30 units in the test for each split, we removed classes (regions or structures) from the dataset if they contained less than 150 units. We also removed units with ambiguous structure assignment such as ‘VIS’ or ‘TH’. The final number of units in each structure (for drifting gratings and natural movie three) is as summarized in <xref ref-type="table" rid="table1">Table 1</xref>. The spontaneous (blank screen) stimulus has more units from the ‘Functional Connectivity’ dataset in addition to the units from the ‘Brain Observatory’.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Number of included single units as a function of brain structure: Allen Institute data.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Region</th><th align="left" valign="bottom">Structure</th><th align="left" valign="bottom">Number of Units</th></tr></thead><tbody><tr><td align="left" valign="bottom">Hippocampus</td><td align="left" valign="bottom">CA1</td><td align="left" valign="bottom">2,552</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">CA3</td><td align="left" valign="bottom">367</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">DG</td><td align="left" valign="bottom">713</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">ProS</td><td align="left" valign="bottom">176</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">SUB</td><td align="left" valign="bottom">470</td></tr><tr><td align="left" valign="bottom">Midbrain</td><td align="left" valign="bottom">MB</td><td align="left" valign="bottom">920</td></tr><tr><td align="left" valign="bottom">Thalamus</td><td align="left" valign="bottom">Eth</td><td align="left" valign="bottom">225</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">LGd</td><td align="left" valign="bottom">903</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">LP</td><td align="left" valign="bottom">1462</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">MGv</td><td align="left" valign="bottom">175</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">PO</td><td align="left" valign="bottom">289</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">SGN</td><td align="left" valign="bottom">178</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">VPM</td><td align="left" valign="bottom">261</td></tr><tr><td align="left" valign="bottom">Visual Cortex</td><td align="left" valign="bottom">VISal</td><td align="left" valign="bottom">1595</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">VISam</td><td align="left" valign="bottom">1537</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">VISl</td><td align="left" valign="bottom">971</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">VISp</td><td align="left" valign="bottom">2076</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">VISpm</td><td align="left" valign="bottom">904</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">VISrl</td><td align="left" valign="bottom">1467</td></tr></tbody></table></table-wrap><p>The dataset provides labels for each unit’s brain structure as ecephys_structure_acronym, determined through a combination of stereotactic targeting, histology, common coordinate framework (CCF) mapping, and intrinsic signal imaging (particularly for visual cortical areas; <xref ref-type="bibr" rid="bib75">Siegle et al., 2021</xref>; <xref ref-type="bibr" rid="bib4">Allen Institute MindScope Program, 2019b</xref>). For our larger brain region prediction tasks, we grouped the provided brain structures into a higher hierarchy based on the Allen Brain Atlas ontology’s structure tree (<xref ref-type="bibr" rid="bib83">Wang et al., 2020</xref>). However, the publicly available units’ metadata does not include layer information. To address this for cortical units, we mapped the CCF coordinates of each unit onto a finer-grained parcellation (25 µm) level within the ontology, enabling the extraction of layer labels. There were 1229 units, 1601 units, 3046 units, and 1057 units in layers 2, 4, 5, and 6, respectively, for drifting gratings and natural movie three.</p><p>To generalize across experimental conditions, we used a dataset from <xref ref-type="bibr" rid="bib79">Steinmetz et al., 2019</xref>, which generally inspired the experiments used in the International Brain Laboratory (IBL) datasets. The mice were shown drifting gratings (oriented at 45° and spatial frequency of 0.1 cycles per degree) of varying contrast. The tasks were divided into an average of four second trials and involved presentation of auditory cue, wheel turning, and reward presentation with inter-trial intervals of gray screen (<xref ref-type="bibr" rid="bib79">Steinmetz et al., 2019</xref>). The experimental sessions also involved passive stimulus presentation after the behavioral sessions (<xref ref-type="bibr" rid="bib79">Steinmetz et al., 2019</xref>). We did not restrict our analysis to any interval but used all the available spikes in the experiments. The data is collected from 10 mice and 39 sessions, with each session potentially resulting in different units from the same mice. The units (or clusters) have structure labels or anatomical locations which were determined by combining electrophysiological features, histology, and CCF mapping (<xref ref-type="bibr" rid="bib79">Steinmetz et al., 2019</xref>). To extract layer information, we used the same method as with the Allen Institute’s dataset: mapping the CCF coordinates to higher resolution parcellation using the Allen CCF reference space. We observed that some brain structure labels provided in the dataset did not match the coordinate mappings, possibly due to manual adjustments. Since accurate layer extraction required the provided structures to overlap with the CCF-mapped structures, we decided to use only those units where the labels matched. In addition, we removed the structures that were not in the training set, that is structures not found in our final Allen dataset. This resulted in 8219 units with the number of units in each structure as summarized in <xref ref-type="table" rid="table2">Table 2</xref>.</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Number of included single units as a function of brain structure: Steinmetz et al. data.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Region</th><th align="left" valign="bottom">Structure</th><th align="left" valign="bottom">Number of Units</th></tr></thead><tbody><tr><td align="left" valign="bottom">Hippocampus</td><td align="left" valign="bottom">CA1</td><td align="left" valign="bottom">1078</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">CA3</td><td align="left" valign="bottom">511</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">DG</td><td align="left" valign="bottom">548</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">SUB</td><td align="left" valign="bottom">541</td></tr><tr><td align="left" valign="bottom">Midbrain</td><td align="left" valign="bottom">MB</td><td align="left" valign="bottom">108</td></tr><tr><td align="left" valign="bottom">Thalamus</td><td align="left" valign="bottom">LGd</td><td align="left" valign="bottom">134</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">LP</td><td align="left" valign="bottom">395</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">PO</td><td align="left" valign="bottom">619</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">VPM</td><td align="left" valign="bottom">68</td></tr><tr><td align="left" valign="bottom">Visual Cortex</td><td align="left" valign="bottom">VISam</td><td align="left" valign="bottom">1358</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">VISl</td><td align="left" valign="bottom">535</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">VISp</td><td align="left" valign="bottom">1535</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">VISpm</td><td align="left" valign="bottom">540</td></tr><tr><td align="left" valign="bottom"/><td align="left" valign="bottom">VISrl</td><td align="left" valign="bottom">249</td></tr></tbody></table></table-wrap></sec><sec id="s4-2"><title>Exploratory visualization</title><p>Dimensionality reductions across spiking features utilized python implementations of principal component analysis (PCA; <xref ref-type="bibr" rid="bib60">Pedregosa et al., 2011</xref>) and linear discriminability analysis (LDA; <xref ref-type="bibr" rid="bib22">Fisher, 1936</xref>). Features to be dimensionally reduced were either a collection of established spiking metrics (<xref ref-type="bibr" rid="bib72">Schneider et al., 2023</xref>; see Logistic Regression section for more details), ISI distributions (100 uniform bins between 0 and 3 s; see Multi-Layer Perceptron section), and averaged PSTHs (100 uniform bins over the 3 s span of a trial; see Multi-Layer Perceptron section) for each stimulus condition grouped/concatenated together.</p><p>For scatterplots, after computation of the values in the spaces, these values were capped between the 1st and 99th percentiles of the data solely for visualization. This was done because outliers cause the central tendency of the data and its separability by region/structure to be less visually apparent. Points affected by this cap remain visible at the bounds of these axes. This was done solely for visualization purposes and did not affect the construction of the dimensionally reduced spaces.</p><p>To evaluate whether the ground truth labels of structures or regions emerged as clusters in the dimensionally reduced spaces. To do this, we performed k-means clustering in the dimensionally reduced space with k equal to the number of ground truth classes. We then calculated the adjusted r and index between the region/structure labels and the cluster labels. We also sought to evaluate whether the relationship (relative distances) between regions/structures was preserved between classes across feature sets and dimensionality reduction methods. First, we created histograms of the distribution of scores along the primary axis of the dimensionality reduction for each region/structure. For each pair of regions/structures, we calculated the Wasserstein distance between their histograms. We plotted the results as triangular distance matrices to show that these relationships are largely unconserved across feature sets and dimensionality reduction methods.</p></sec><sec id="s4-3"><title>Dataset splitting</title><p>To properly optimize our supervised models while ensuring generalizability to unseen data, we performed a standard split into train, validation, and test sets (with an approximate 60/20/20 ratio with respect to the number of neurons). To ensure the full dataset was evaluated, we extracted five stratified samples such that each unit was included in the validation set in one of these splits and separately included in the test set in another split. This is intuitively similar to a fivefold cross-validation.</p><p>In a transductive split, for each animal, 60% of the neurons were allocated to train, 20% of the neurons were in the validation set, and 20% were allocated to the test set. We sought to ensure classes (i.e. regions/structures) were represented appropriately in each set. If 20% of the dataset was class A, we attempted to stratify our sets such that ∼20% of the train set was class A, ∼20% of the validation set was class A, and ∼20% of the test set was class A.</p><p>In an inductive split, all neurons from 60% of the animals were allocated to train, all neurons from 20% of the animals were allocated to validation, and all neurons from 20% of the animals were allocated to the test set.</p><p>For the generalization across experimental conditions, 80% of the Allen units were allocated to a training set, while 20% were used as a validation set. All of the Steinmetz et al. units in the final dataset were used as the test set.</p></sec><sec id="s4-4"><title>Logistic regression</title><p>Summary statistics based on spike times during drifting gratings presentation were obtained and used as features for a logistic regression implemented in scikit-learn (<xref ref-type="bibr" rid="bib60">Pedregosa et al., 2011</xref>). This workflow largely follows our prior work (<xref ref-type="bibr" rid="bib72">Schneider et al., 2023</xref>). The logistic regression used L2-regularization and 1E-4 tolerance stopping criterion. When possible, interspike intervals were used to compute these statistics instead of binned spike counts. The following standard statistics were computed: mean firing rate, standard deviation of ISI, median ISI, maximum ISI, minimum ISI, coefficient of variation. Oscillatory activity of the spike train was captured using the power spectral density (PSD) from a periodogram using scipy.signal (<xref ref-type="bibr" rid="bib81">Virtanen et al., 2020</xref>). The mean value was calculated within each of the following bands (&lt; 4 Hz, 4–8 Hz, 8–12 Hz, 12–40 Hz, 40–100 Hz), and the ratio of each band’s power to the power across all bands &lt; 100 Hz was used as a feature. Local variability in the spike train was captured through the CV2, LV, and LVR statistics (as implemented in Elephant; <xref ref-type="bibr" rid="bib19">Denker et al., 2018</xref>). These statistics were used first individually, and second aggregated to predict each class (structure/region) for a task.</p></sec><sec id="s4-5"><title>Multi-layer perceptron</title><p>For each task, an MLP was implemented in scikit-learn (<xref ref-type="bibr" rid="bib60">Pedregosa et al., 2011</xref>) with a designated set of features to represent the spike train. Features were either: (1) interspike intervals (ISIs) distribution, (2) averaged peri-stimulus histogram (PSTH), or (3) concatenated PSTHs.</p><p>To calculate ISI distribution for a neuron under specific stimulus, we converted all the spike times of that neuron during the stimulus’s presentation into ISIs. Then, we created 100 uniform bins between 1ms and 3 s and counted the neuron’s ISIs in each bin. This resulted in 300 features of ISI ‘distribution’ for each neuron. Finally, we performed min-max normalization, where for each neuron, the maximum value across all bins was set to 1, and the minimum value was set to 0.</p><p>The average and concatenated PSTHs were calculated for the drifting grating stimulus. For the average PSTH, we aligned all spikes around the stimulus presentation (1 s before the stimulus presentation and 2 s of stimulus presentation) for each neuron. Then, we created 100 uniform bins over 3 s and counted the number of spikes in each bin for each trial. Then, we averaged the values in each bin across all trials. This resulted in 300 features for each neuron. Finally, we performed min-max normalization, where the maximum value across all bins was set to 1, and the minimum value was set to 0. For the concatenated PSTH, a PSTH was calculated separately for each combination of the drifting grating’s parameters, that is temporal frequency and orientation. Similar to the average PSTH, we aligned the spikes around the stimulus presentation and performed a binned spike count for 30 uniform bins between 0 and 3 s. We then constructed the PSTH by taking the mean across the number of trials. As each combination of the drifting grating’s parameter was repeated 15 times during the experiment, the PSTHs are the mean of 15 trials. Similar to the ISI distribution and average PSTH, we performed min-max normalization for each neuron. This operation took place on each PSTH prior to concatenation. Given that there were 40 parameter combinations and 30 bins for each combination, this resulted in 1,200 features per neuron.</p><p>For each task, a Bayesian hyperparameter optimization (HyperOpt package) (<xref ref-type="bibr" rid="bib8">Bergstra et al., 2013</xref>) was used to tune hyperparameters (<xref ref-type="table" rid="table3">Table 3</xref>) such that they maximized balanced accuracy on the validation set. To mitigate the effect of class imbalance in our dataset, we treated resampling as a hyperparameter and evaluated undersampling, oversampling, and data augmentation. We found that the synthetic minority oversampling technique (SMOTE; <xref ref-type="bibr" rid="bib16">Chawla et al., 2002</xref>), a data augmentation approach, yielded optimal performance on validation sets. Therefore, classes were resampled with SMOTE in all cases unless otherwise specified. A different model was trained and tuned for each of five splits to avoid data leakages. For our inductive predictions across datasets (Allen to Steinmetz et al.) tasks, to ensure that the training data encompassed the relevant anatomical representations present in the Steinmetz et al. dataset, we trained models on a subset of the Allen dataset that included only brain structures that are also present in the Steinmetz et al. dataset.</p><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>MLP hyperparameters.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Hyperparameter</th><th align="left" valign="bottom">ISI Distribution</th><th align="left" valign="bottom">Avg. PSTH</th><th align="left" valign="bottom">Cat. PSTH</th></tr></thead><tbody><tr><td align="left" valign="bottom">Number of Nodes</td><td align="left" valign="bottom">50:600:50</td><td align="left" valign="bottom">30:300:50</td><td align="left" valign="bottom">50:600:50</td></tr><tr><td align="left" valign="bottom">Learning Rate</td><td align="left" valign="bottom">1E-7,1E-6,1E-5,1E-4,1E-3,1E-2,1E-1</td><td align="left" valign="bottom">1E-5,1E-4,1E-3,1E-2,1E-1</td><td align="left" valign="bottom">1E-5,1E-4,1E-3,1E-2,1E-1</td></tr><tr><td align="left" valign="bottom">Batch Size</td><td align="left" valign="bottom">25:500:50</td><td align="left" valign="bottom">50:600:50</td><td align="left" valign="bottom">50:600:50</td></tr><tr><td align="left" valign="bottom">Alpha</td><td align="left" valign="bottom">1E-4,1E-3,1E-2,1E-1,1E0,5,10</td><td align="left" valign="bottom">1E-4,1E-3,1E-2,1E-1,1E0</td><td align="left" valign="bottom">1E-4,1E-3,1E-2,1E-1,1E0</td></tr><tr><td align="left" valign="bottom">Beta_1</td><td align="left" valign="bottom">0.5:0.9:0.1</td><td align="left" valign="bottom">0.5:0.9:0.1</td><td align="left" valign="bottom">0.5:0.9:0.1</td></tr></tbody></table></table-wrap><p>Consistent with prior work (<xref ref-type="bibr" rid="bib72">Schneider et al., 2023</xref>), an MLP with a single hidden layer was generally found to perform better than an MLP with multiple hidden layers. The number of nodes for this hidden layer was optimized. Alpha is the L2 regularization term. Beta_1 is the exponential decay rate for estimates of the first moment vector in the Adam optimizer. All unmentioned hyperparameters took on default values from sklearn.</p><p>To identify the features contributing to the models’ learning, we employed permutation feature importance, which measures the extent to which shuffling a specific feature across samples increases the model’s prediction error (<xref ref-type="bibr" rid="bib23">Fisher et al., 2018</xref>). To quantify the feature importance of a specific inter-spike interval (ISI) distribution bin for predicting a particular brain region or structure, we first estimated the model’s error for the original features, given that the neurons originated from that specific brain region or structure. Then, for those neurons, we randomly permuted (shuffled) a specific bin of the ISI distribution across all samples (neurons) and estimated the model’s error for the permuted features. The difference between the original and the permuted features’ error represents the feature importance for that specific bin and region/structure. We repeated this process 100 times for all bins in the ISI distribution, each region/structure, and across the five splits. The feature importance is the mean across the splits and repetitions. We followed a similar approach for the concatenated PSTH.</p></sec><sec id="s4-6"><title>Smoothing</title><p>For some tasks, predictions were spatially smoothed to improve predictions by leveraging the spatial arrangements of recording channels to weight the influence of nearby units on each prediction. First, neurons (units) were grouped by session and probe to ensure the smoothing was applied within the same probe and session. Second, the predicted probabilities for each class were averaged for all neurons sorted to a particular electrode. Electrodes with no neurons detected were ignored for the purposes of this smoothing. Third, for each electrode, the spatial proximity of nearby units was leveraged by calculating a Gaussian weight. For an electrode, the weight for each nearby unit was determined using a normal distribution centered on the current unit’s electrode index (i.e. a linear approximation of the electrode geometry) with a standard deviation equal to the smoothing window. The probability density function (PDF) of the normal distribution was used to compute these weights. The class probabilities for each nearby unit were multiplied by their respective weights. The weighted probabilities were then summed and normalized by the sum of the weights to produce the smoothed prediction for each class for that electrode. The process was repeated for all electrodes. To determine an optimal standard deviation of the Gaussian kernel, we used Hyperopt to maximize balanced accuracy on the validation set.</p></sec><sec id="s4-7"><title>Models performance metrics and statistical tests</title><p>In order to quantify the models’ performances, we mainly used balanced accuracy, which is the macro average of recall (true positive rate) per class (<xref ref-type="bibr" rid="bib11">Brodersen et al., 2010</xref>). Chance level is 1/number of classes. In some cases, we used the Matthews Correlation Coefficient (MCC). This measure considers true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). It provides a balanced measure, useful even with imbalanced datasets, with a value ranging from –1 (total disagreement) to 1 (perfect prediction) (<xref ref-type="bibr" rid="bib17">Chicco and Jurman, 2020</xref>; <xref ref-type="bibr" rid="bib9">Boughorbel et al., 2017</xref>). 0 represents chance-level (which is adjusted to the number of classes). As most of our tasks were multiclass classification, we used a multi-class version of MCC (<xref ref-type="bibr" rid="bib60">Pedregosa et al., 2011</xref>; <xref ref-type="bibr" rid="bib27">Gorodkin, 2004</xref>).</p><p>Given a confusion matrix <inline-formula><alternatives><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>C</mml:mi></mml:mstyle></mml:math><tex-math id="inft13">\begin{document}$  C$\end{document}</tex-math></alternatives></inline-formula> for <inline-formula><alternatives><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math><tex-math id="inft14">\begin{document}$  N$\end{document}</tex-math></alternatives></inline-formula> classes, the following intermediate variables are defined:<disp-formula id="equ1"><alternatives><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mspace width="1em"/><mml:mrow><mml:mtext>(total occurrences of class </mml:mtext><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mtext> in the actual data)</mml:mtext></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t1">\begin{document}$$\displaystyle  t_n = \sum_{i=1}^N C_{in} \quad \text{(total occurrences of class \(n\) in the actual data)},$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ2"><alternatives><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mspace width="1em"/><mml:mrow><mml:mtext>(total occurrences of class </mml:mtext><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mtext> in the predictions)</mml:mtext></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t2">\begin{document}$$\displaystyle  p_n = \sum_{i=1}^N C_{ni} \quad \text{(total occurrences of class \(n\) in the predictions)},$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ3"><alternatives><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mspace width="1em"/><mml:mtext>(total number of correctly predicted samples)</mml:mtext><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t3">\begin{document}$$\displaystyle  c = \sum_{n=1}^N C_{nn} \quad \text{(total number of correctly predicted samples)},$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ4"><alternatives><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="1em"/><mml:mtext>(total number of samples)</mml:mtext><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t4">\begin{document}$$\displaystyle  s = \sum_{i=1}^N \sum_{j=1}^N C_{ij} \quad \text{(total number of samples)}.$$\end{document}</tex-math></alternatives></disp-formula></p><p>The multi-class MCC is defined as:<disp-formula id="equ5"><alternatives><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtext>MCC</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>c</mml:mi><mml:mo>×</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msqrt><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>p</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>×</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msubsup><mml:mi>t</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:msqrt></mml:mfrac><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t5">\begin{document}$$\displaystyle  \text{MCC}=\frac{c\times s-\sum_{n=1}^{N}p_{n}\times t_{n}}{\sqrt{\left(s^{2}-\sum_{n=1}^{N}p_{n}^{2}\right)\times\left(s^{2}-\sum_{n=1}^{N}t_{n}^{2}\right)}}.$$\end{document}</tex-math></alternatives></disp-formula></p><p>In all cases, the statistical test and level of significance are indicated in the relevant sections of the main text and figure legends. In most cases, linear mixed effects models are employed with subsequent ANOVA for main effect and post-hoc EMMeans with Tukey test for pairwise comparisons. The implementation was in R (lmer; <xref ref-type="bibr" rid="bib7">Bates et al., 2015</xref>). In some cases, multiple T-tests with Bonferroni correction (as appropriate) were employed. The implementation was in Python (scipy.stats; <xref ref-type="bibr" rid="bib81">Virtanen et al., 2020</xref>).</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Data curation, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Supervision</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Supervision, Funding acquisition, Visualization, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-101506-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The current manuscript analyzes publicly available data not generated by the authors.</p><p>The following previously published datasets were used:</p><p><element-citation publication-type="data" specific-use="references" id="dataset1"><person-group person-group-type="author"><name><surname>Siegle et al.</surname></name></person-group><year iso-8601-date="2021">2021</year><data-title>Allen Brain Observatory -- Neuropixels Visual Coding [dataset]</data-title><source>Allen Brain Map</source><pub-id pub-id-type="accession" xlink:href="https://portal.brain-map.org/circuits-behavior/visual-behavior-neuropixels">visual-behavior-neuropixels</pub-id></element-citation></p><p><element-citation publication-type="data" specific-use="references" id="dataset2"><person-group person-group-type="author"><name><surname>Steinmetz</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2019">2019</year><data-title>Distributed coding of choice, action and engagement across the mouse brain</data-title><source>figshare</source><pub-id pub-id-type="doi">10.6084/m9.figshare.9598406</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We would like to thank the Allen Institute for generating and sharing the Visual Coding datasets. We would like to thank Dr. Josh Siegle for technical insights into the Allen datasets and his helpful perspective on our work. We would also like to thank Dr. Nick Steinmetz for sharing data and technical advice. We are grateful for the funding that enabled this work: R01NS118442 (KBH), R01EB029852 (ELD &amp; KBH), F31NS134240 (AMS), the Cognitive, Computational and Systems Neuroscience (CCSN) Fellowship (GBT), and the Incubator for Transdisciplinary Futures, an Arts &amp; Sciences signature initiative at Washington University in St. Louis (KBH).</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Adrian</surname><given-names>ED</given-names></name><name><surname>Bronk</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="1928">1928</year><article-title>The discharge of impulses in motor nerve fibres: Part I. Impulses in single fibres of the phrenic nerve</article-title><source>The Journal of Physiology</source><volume>66</volume><fpage>81</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1928.sp002509</pub-id><pub-id pub-id-type="pmid">16993976</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="software"><person-group person-group-type="author"><collab>Allen Institute for Brain Science</collab></person-group><year iso-8601-date="2019">2019</year><data-title>AllenSDK</data-title><version designator="2.5.0">2.5.0</version><source>Allensdk</source><ext-link ext-link-type="uri" xlink:href="https://allensdk.readthedocs.io/en/latest/">https://allensdk.readthedocs.io/en/latest/</ext-link></element-citation></ref><ref id="bib3"><element-citation publication-type="data"><person-group person-group-type="author"><collab>Allen Institute MindScope Program</collab></person-group><year iso-8601-date="2019">2019a</year><data-title>Allen brain observatory – neuropixels visual coding</data-title><source>Dataset</source><ext-link ext-link-type="uri" xlink:href="http://brain-map.org/explore/circuits">http://brain-map.org/explore/circuits</ext-link></element-citation></ref><ref id="bib4"><element-citation publication-type="web"><person-group person-group-type="author"><collab>Allen Institute MindScope Program</collab></person-group><year iso-8601-date="2019">2019b</year><article-title>Allen brain observatory – neuropixels visual coding</article-title><source>Technical white paper</source><ext-link ext-link-type="uri" xlink:href="https://allensdk.readthedocs.io/en/latest/visual_coding_neuropixels.html">https://allensdk.readthedocs.io/en/latest/visual_coding_neuropixels.html</ext-link><date-in-citation iso-8601-date="2022-01-04">January 4, 2022</date-in-citation></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andermann</surname><given-names>ML</given-names></name><name><surname>Kerlin</surname><given-names>AM</given-names></name><name><surname>Roumis</surname><given-names>DK</given-names></name><name><surname>Glickfeld</surname><given-names>LL</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Functional specialization of mouse higher visual cortical areas</article-title><source>Neuron</source><volume>72</volume><fpage>1025</fpage><lpage>1039</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.11.013</pub-id><pub-id pub-id-type="pmid">22196337</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ayzenshtat</surname><given-names>I</given-names></name><name><surname>Jackson</surname><given-names>J</given-names></name><name><surname>Yuste</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Orientation tuning depends on spatial frequency in mouse visual cortex</article-title><source>eNeuro</source><volume>3</volume><elocation-id>ENEURO.0217-16.2016</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0217-16.2016</pub-id><pub-id pub-id-type="pmid">27699210</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname><given-names>D</given-names></name><name><surname>Mächler</surname><given-names>M</given-names></name><name><surname>Bolker</surname><given-names>B</given-names></name><name><surname>Walker</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Fitting linear mixed-effects models using lme4</article-title><source>Journal of Statistical Software</source><volume>67</volume><fpage>1</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.18637/jss.v067.i01</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bergstra</surname><given-names>J</given-names></name><name><surname>Yamins</surname><given-names>D</given-names></name><name><surname>Cox</surname><given-names>DD</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures</article-title><conf-name>In Proceedings of the 30th International Conference on Machine Learning (ICML 2013)</conf-name><fpage>1</fpage><lpage>115</lpage></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boughorbel</surname><given-names>S</given-names></name><name><surname>Jarray</surname><given-names>F</given-names></name><name><surname>El-Anbari</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Optimal classifier for imbalanced data using matthews correlation coefficient metric</article-title><source>PLOS ONE</source><volume>12</volume><elocation-id>e0177678</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0177678</pub-id><pub-id pub-id-type="pmid">28574989</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Braganza</surname><given-names>O</given-names></name><name><surname>Beck</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The Circuit motif as a conceptual tool for multilevel neuroscience</article-title><source>Trends in Neurosciences</source><volume>41</volume><fpage>128</fpage><lpage>136</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2018.01.002</pub-id><pub-id pub-id-type="pmid">29397990</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Brodersen</surname><given-names>KH</given-names></name><name><surname>Ong</surname><given-names>CS</given-names></name><name><surname>Stephan</surname><given-names>KE</given-names></name><name><surname>Buhmann</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>The balanced accuracy and its posterior distribution</article-title><conf-name>Proceedings of the 20th International Conference on Pattern Recognition (ICPR)</conf-name><fpage>3121</fpage><lpage>3124</lpage><pub-id pub-id-type="doi">10.1109/ICPR.2010.764</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Brodmann</surname><given-names>K</given-names></name></person-group><year iso-8601-date="1909">1909</year><source>Vergleichende Lokalisationslehre Der Großhirnrinde in Ihren Prinzipien Dargestellt Auf Grund Des Zellenbaues</source><publisher-name>Johann Ambrosius Barth Verlag</publisher-name></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buccino</surname><given-names>AP</given-names></name><name><surname>Kordovan</surname><given-names>M</given-names></name><name><surname>Ness</surname><given-names>TV</given-names></name><name><surname>Merkt</surname><given-names>B</given-names></name><name><surname>Häfliger</surname><given-names>PD</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Cauwenberghs</surname><given-names>G</given-names></name><name><surname>Rotter</surname><given-names>S</given-names></name><name><surname>Einevoll</surname><given-names>GT</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Combining biophysical modeling and deep learning for multielectrode array neuron localization and classification</article-title><source>Journal of Neurophysiology</source><volume>120</volume><fpage>1212</fpage><lpage>1232</lpage><pub-id pub-id-type="doi">10.1152/jn.00210.2018</pub-id><pub-id pub-id-type="pmid">29847231</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cembrowski</surname><given-names>MS</given-names></name><name><surname>Bachman</surname><given-names>JL</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Sugino</surname><given-names>K</given-names></name><name><surname>Shields</surname><given-names>BC</given-names></name><name><surname>Spruston</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Spatial gene-expression gradients underlie prominent heterogeneity of CA1 pyramidal neurons</article-title><source>Neuron</source><volume>89</volume><fpage>351</fpage><lpage>368</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.12.013</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chaudhuri</surname><given-names>R</given-names></name><name><surname>Knoblauch</surname><given-names>K</given-names></name><name><surname>Gariel</surname><given-names>MA</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A large-scale circuit mechanism for hierarchical dynamical processing in the primate cortex</article-title><source>Neuron</source><volume>88</volume><fpage>419</fpage><lpage>431</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.008</pub-id><pub-id pub-id-type="pmid">26439530</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chawla</surname><given-names>NV</given-names></name><name><surname>Bowyer</surname><given-names>KW</given-names></name><name><surname>Hall</surname><given-names>LO</given-names></name><name><surname>Kegelmeyer</surname><given-names>WP</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>SMOTE: synthetic minority over-sampling technique</article-title><source>Journal of Artificial Intelligence Research</source><volume>16</volume><fpage>321</fpage><lpage>357</lpage><pub-id pub-id-type="doi">10.1613/jair.953</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chicco</surname><given-names>D</given-names></name><name><surname>Jurman</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation</article-title><source>BMC Genomics</source><volume>21</volume><elocation-id>6</elocation-id><pub-id pub-id-type="doi">10.1186/s12864-019-6413-7</pub-id><pub-id pub-id-type="pmid">31898477</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>MR</given-names></name><name><surname>Kohn</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Measuring and interpreting neuronal correlations</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>811</fpage><lpage>819</lpage><pub-id pub-id-type="doi">10.1038/nn.2842</pub-id><pub-id pub-id-type="pmid">21709677</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Denker</surname><given-names>M</given-names></name><name><surname>Yegenoglu</surname><given-names>A</given-names></name><name><surname>Grün</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Collaborative HPC-enabled workflows on the HBP collaboratory using the elephant framework</article-title><source>Neuroinformatics</source><volume>01</volume><elocation-id>e0019</elocation-id><pub-id pub-id-type="doi">10.12751/incf.ni2018.0019</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Elston</surname><given-names>GN</given-names></name></person-group><year iso-8601-date="2007">2007</year><chapter-title>Specialization of the neocortical pyramidal cell during primate evolution</chapter-title><person-group person-group-type="editor"><name><surname>Kaas</surname><given-names>JH</given-names></name></person-group><source>Evolution of Nervous Systems</source><publisher-loc>Oxford</publisher-loc><publisher-name>Elsevier</publisher-name><fpage>191</fpage><lpage>242</lpage><pub-id pub-id-type="doi">10.1016/B0-12-370878-8/00164-6</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faisal</surname><given-names>AA</given-names></name><name><surname>Selen</surname><given-names>LPJ</given-names></name><name><surname>Wolpert</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Noise in the nervous system</article-title><source>Nature Reviews. Neuroscience</source><volume>9</volume><fpage>292</fpage><lpage>303</lpage><pub-id pub-id-type="doi">10.1038/nrn2258</pub-id><pub-id pub-id-type="pmid">18319728</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fisher</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="1936">1936</year><article-title>The use of multiple measurements in taxonomic problems</article-title><source>Annals of Eugenics</source><volume>7</volume><fpage>179</fpage><lpage>188</lpage><pub-id pub-id-type="doi">10.1111/j.1469-1809.1936.tb02137.x</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Fisher</surname><given-names>A</given-names></name><name><surname>Rudin</surname><given-names>C</given-names></name><name><surname>Dominici</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>All models are wrong, but many are useful: learning a variable’s importance by studying an entire class of prediction models simultaneously</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1801.01489">https://arxiv.org/abs/1801.01489</ext-link></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gămănuţ</surname><given-names>R</given-names></name><name><surname>Kennedy</surname><given-names>H</given-names></name><name><surname>Toroczkai</surname><given-names>Z</given-names></name><name><surname>Ercsey-Ravasz</surname><given-names>M</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Knoblauch</surname><given-names>K</given-names></name><name><surname>Burkhalter</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The mouse cortical connectome, characterized by an ultra-dense cortical graph, maintains specificity by distinct connectivity profiles</article-title><source>Neuron</source><volume>97</volume><fpage>698</fpage><lpage>715</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.12.037</pub-id><pub-id pub-id-type="pmid">29420935</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gerstner</surname><given-names>W</given-names></name><name><surname>Kistler</surname><given-names>WM</given-names></name><name><surname>Naud</surname><given-names>R</given-names></name><name><surname>Paninski</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2014">2014</year><source>Neuronal Dynamics: From Single Neurons to Networks and Models of Cognition</source><publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1017/CBO9781107447615</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glickfeld</surname><given-names>LL</given-names></name><name><surname>Olsen</surname><given-names>SR</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Higher-order areas of the mouse visual cortex</article-title><source>Annual Review of Vision Science</source><volume>3</volume><fpage>251</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1146/annurev-vision-102016-061331</pub-id><pub-id pub-id-type="pmid">28746815</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorodkin</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Comparing two K-category assignments by a K-category correlation coefficient</article-title><source>Computational Biology and Chemistry</source><volume>28</volume><fpage>367</fpage><lpage>374</lpage><pub-id pub-id-type="doi">10.1016/j.compbiolchem.2004.09.006</pub-id><pub-id pub-id-type="pmid">15556477</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gütig</surname><given-names>R</given-names></name><name><surname>Sompolinsky</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The tempotron: a neuron that learns spike timing-based decisions</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>420</fpage><lpage>428</lpage><pub-id pub-id-type="doi">10.1038/nn1643</pub-id><pub-id pub-id-type="pmid">16474393</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Thiele</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cortical state and attention</article-title><source>Nature Reviews. Neuroscience</source><volume>12</volume><fpage>509</fpage><lpage>523</lpage><pub-id pub-id-type="doi">10.1038/nrn3084</pub-id><pub-id pub-id-type="pmid">21829219</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>JA</given-names></name><name><surname>Mihalas</surname><given-names>S</given-names></name><name><surname>Hirokawa</surname><given-names>KE</given-names></name><name><surname>Whitesell</surname><given-names>JD</given-names></name><name><surname>Choi</surname><given-names>H</given-names></name><name><surname>Bernard</surname><given-names>A</given-names></name><name><surname>Bohn</surname><given-names>P</given-names></name><name><surname>Caldejon</surname><given-names>S</given-names></name><name><surname>Casal</surname><given-names>L</given-names></name><name><surname>Cho</surname><given-names>A</given-names></name><name><surname>Feiner</surname><given-names>A</given-names></name><name><surname>Feng</surname><given-names>D</given-names></name><name><surname>Gaudreault</surname><given-names>N</given-names></name><name><surname>Gerfen</surname><given-names>CR</given-names></name><name><surname>Graddis</surname><given-names>N</given-names></name><name><surname>Groblewski</surname><given-names>PA</given-names></name><name><surname>Henry</surname><given-names>AM</given-names></name><name><surname>Ho</surname><given-names>A</given-names></name><name><surname>Howard</surname><given-names>R</given-names></name><name><surname>Knox</surname><given-names>JE</given-names></name><name><surname>Kuan</surname><given-names>L</given-names></name><name><surname>Kuang</surname><given-names>X</given-names></name><name><surname>Lecoq</surname><given-names>J</given-names></name><name><surname>Lesnar</surname><given-names>P</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Luviano</surname><given-names>J</given-names></name><name><surname>McConoughey</surname><given-names>S</given-names></name><name><surname>Mortrud</surname><given-names>MT</given-names></name><name><surname>Naeemi</surname><given-names>M</given-names></name><name><surname>Ng</surname><given-names>L</given-names></name><name><surname>Oh</surname><given-names>SW</given-names></name><name><surname>Ouellette</surname><given-names>B</given-names></name><name><surname>Shen</surname><given-names>E</given-names></name><name><surname>Sorensen</surname><given-names>SA</given-names></name><name><surname>Wakeman</surname><given-names>W</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Williford</surname><given-names>A</given-names></name><name><surname>Phillips</surname><given-names>JW</given-names></name><name><surname>Jones</surname><given-names>AR</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Hierarchical organization of cortical and thalamic connectivity</article-title><source>Nature</source><volume>575</volume><fpage>195</fpage><lpage>202</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1716-z</pub-id><pub-id pub-id-type="pmid">31666704</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hastie</surname><given-names>T</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name><name><surname>Friedman</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2009">2009</year><source>The Elements of Statistical Learning</source><publisher-loc>New York</publisher-loc><publisher-name>Springer</publisher-name><pub-id pub-id-type="doi">10.1007/978-0-387-84858-7</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hengen</surname><given-names>KB</given-names></name><name><surname>Lambo</surname><given-names>ME</given-names></name><name><surname>Van Hooser</surname><given-names>SD</given-names></name><name><surname>Katz</surname><given-names>DB</given-names></name><name><surname>Turrigiano</surname><given-names>GG</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Firing rate homeostasis in visual cortex of freely behaving rodents</article-title><source>Neuron</source><volume>80</volume><fpage>335</fpage><lpage>342</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.08.038</pub-id><pub-id pub-id-type="pmid">24139038</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hengen</surname><given-names>KB</given-names></name><name><surname>Torrado Pacheco</surname><given-names>A</given-names></name><name><surname>McGregor</surname><given-names>JN</given-names></name><name><surname>Van Hooser</surname><given-names>SD</given-names></name><name><surname>Turrigiano</surname><given-names>GG</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neuronal firing rate homeostasis is inhibited by sleep and promoted by wake</article-title><source>Cell</source><volume>165</volume><fpage>180</fpage><lpage>191</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2016.01.046</pub-id><pub-id pub-id-type="pmid">26997481</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holt</surname><given-names>GR</given-names></name><name><surname>Softky</surname><given-names>WR</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Douglas</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Comparison of discharge variability in vitro and in vivo in cat visual cortex neurons</article-title><source>Journal of Neurophysiology</source><volume>75</volume><fpage>1806</fpage><lpage>1814</lpage><pub-id pub-id-type="doi">10.1152/jn.1996.75.5.1806</pub-id><pub-id pub-id-type="pmid">8734581</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jia</surname><given-names>X</given-names></name><name><surname>Siegle</surname><given-names>JH</given-names></name><name><surname>Bennett</surname><given-names>C</given-names></name><name><surname>Gale</surname><given-names>SD</given-names></name><name><surname>Denman</surname><given-names>DJ</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Olsen</surname><given-names>SR</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>High-density extracellular probes reveal dendritic backpropagation and facilitate neuron classification</article-title><source>Journal of Neurophysiology</source><volume>121</volume><fpage>1831</fpage><lpage>1847</lpage><pub-id pub-id-type="doi">10.1152/jn.00680.2018</pub-id><pub-id pub-id-type="pmid">30840526</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jurman</surname><given-names>G</given-names></name><name><surname>Riccadonna</surname><given-names>S</given-names></name><name><surname>Furlanello</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>A comparison of MCC and CEN error measures in multi-class prediction</article-title><source>PLOS ONE</source><volume>7</volume><elocation-id>e41882</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0041882</pub-id><pub-id pub-id-type="pmid">22905111</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumar</surname><given-names>MG</given-names></name><name><surname>Hu</surname><given-names>M</given-names></name><name><surname>Ramanujan</surname><given-names>A</given-names></name><name><surname>Sur</surname><given-names>M</given-names></name><name><surname>Murthy</surname><given-names>HA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Functional parcellation of mouse visual cortex using statistical techniques reveals response-dependent clustering of cortical processing areas</article-title><source>PLOS Computational Biology</source><volume>17</volume><elocation-id>e1008548</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008548</pub-id><pub-id pub-id-type="pmid">33539361</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>EK</given-names></name><name><surname>Gül</surname><given-names>AE</given-names></name><name><surname>Heller</surname><given-names>G</given-names></name><name><surname>Lakunina</surname><given-names>A</given-names></name><name><surname>Jaramillo</surname><given-names>S</given-names></name><name><surname>Przytycki</surname><given-names>PF</given-names></name><name><surname>Chandrasekaran</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Physmap - interpretablein vivoneuronal cell type identification using multi-modal analysis of electrophysiological data</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2024.02.28.582461</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lettvin</surname><given-names>J</given-names></name><name><surname>Maturana</surname><given-names>H</given-names></name><name><surname>McCulloch</surname><given-names>W</given-names></name><name><surname>Pitts</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1959">1959</year><article-title>What the frog’s eye tells the frog’s brain</article-title><source>Proceedings of the IRE</source><volume>47</volume><fpage>1940</fpage><lpage>1951</lpage><pub-id pub-id-type="doi">10.1109/JRPROC.1959.287207</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>London</surname><given-names>M</given-names></name><name><surname>Roth</surname><given-names>A</given-names></name><name><surname>Beeren</surname><given-names>L</given-names></name><name><surname>Häusser</surname><given-names>M</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Sensitivity to perturbations in vivo implies high noise and suggests rate coding in cortex</article-title><source>Nature</source><volume>466</volume><fpage>123</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1038/nature09086</pub-id><pub-id pub-id-type="pmid">20596024</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luo</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Architectures of neuronal circuits</article-title><source>Science</source><volume>373</volume><elocation-id>eabg7285</elocation-id><pub-id pub-id-type="doi">10.1126/science.abg7285</pub-id><pub-id pub-id-type="pmid">34516844</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>Z</given-names></name><name><surname>Turrigiano</surname><given-names>GG</given-names></name><name><surname>Wessel</surname><given-names>R</given-names></name><name><surname>Hengen</surname><given-names>KB</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Cortical circuit dynamics are homeostatically tuned to criticality in vivo</article-title><source>Neuron</source><volume>104</volume><fpage>655</fpage><lpage>664</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.08.031</pub-id><pub-id pub-id-type="pmid">31601510</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maass</surname><given-names>W</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>On the computational power of winner-take-all</article-title><source>Neural Computation</source><volume>12</volume><fpage>2519</fpage><lpage>2535</lpage><pub-id pub-id-type="doi">10.1162/089976600300014827</pub-id><pub-id pub-id-type="pmid">11110125</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mainen</surname><given-names>ZF</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Reliability of spike timing in neocortical neurons</article-title><source>Science</source><volume>268</volume><fpage>1503</fpage><lpage>1506</lpage><pub-id pub-id-type="doi">10.1126/science.7770778</pub-id><pub-id pub-id-type="pmid">7770778</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marshel</surname><given-names>JH</given-names></name><name><surname>Garrett</surname><given-names>ME</given-names></name><name><surname>Nauhaus</surname><given-names>I</given-names></name><name><surname>Callaway</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Functional specialization of seven mouse visual cortical areas</article-title><source>Neuron</source><volume>72</volume><fpage>1040</fpage><lpage>1054</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.12.004</pub-id><pub-id pub-id-type="pmid">22196338</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maunsell</surname><given-names>JH</given-names></name><name><surname>van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>The connections of the middle temporal visual area (MT) and their relationship to a cortical hierarchy in the macaque monkey</article-title><source>The Journal of Neuroscience</source><volume>3</volume><fpage>2563</fpage><lpage>2586</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.03-12-02563.1983</pub-id><pub-id pub-id-type="pmid">6655500</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCulloch</surname><given-names>WS</given-names></name><name><surname>Pitts</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1943">1943</year><article-title>A logical calculus of the ideas immanent in nervous activity</article-title><source>The Bulletin of Mathematical Biophysics</source><volume>5</volume><fpage>115</fpage><lpage>133</lpage><pub-id pub-id-type="doi">10.1007/BF02478259</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mi</surname><given-names>L</given-names></name><name><surname>Le</surname><given-names>T</given-names></name><name><surname>He</surname><given-names>T</given-names></name><name><surname>Shlizerman</surname><given-names>E</given-names></name><name><surname>Sümbül</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2023">2023</year><chapter-title>Learning time-invariant representations for individual neurons from population dynamics</chapter-title><person-group person-group-type="editor"><name><surname>Oh</surname><given-names>A</given-names></name><name><surname>Naumann</surname><given-names>T</given-names></name><name><surname>Globerson</surname><given-names>A</given-names></name><name><surname>Saenko</surname><given-names>K</given-names></name><name><surname>Hardt</surname><given-names>M</given-names></name><name><surname>Levine</surname><given-names>S</given-names></name></person-group><source>Advances in Neural Information Processing Systems</source><publisher-name>Curran Associates, Inc</publisher-name><fpage>1</fpage><lpage>20</lpage></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Millman</surname><given-names>DJ</given-names></name><name><surname>Ocker</surname><given-names>GK</given-names></name><name><surname>Caldejon</surname><given-names>S</given-names></name><name><surname>Kato</surname><given-names>I</given-names></name><name><surname>Larkin</surname><given-names>JD</given-names></name><name><surname>Lee</surname><given-names>EK</given-names></name><name><surname>Luviano</surname><given-names>J</given-names></name><name><surname>Nayan</surname><given-names>C</given-names></name><name><surname>Nguyen</surname><given-names>TV</given-names></name><name><surname>North</surname><given-names>K</given-names></name><name><surname>Seid</surname><given-names>S</given-names></name><name><surname>White</surname><given-names>C</given-names></name><name><surname>Lecoq</surname><given-names>J</given-names></name><name><surname>Reid</surname><given-names>C</given-names></name><name><surname>Buice</surname><given-names>MA</given-names></name><name><surname>de Vries</surname><given-names>SE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>VIP interneurons in mouse primary visual cortex selectively enhance responses to weak but specific stimuli</article-title><source>eLife</source><volume>9</volume><elocation-id>e55130</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.55130</pub-id><pub-id pub-id-type="pmid">33108272</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mizuseki</surname><given-names>K</given-names></name><name><surname>Buzsáki</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Preconfigured, skewed distribution of firing rates in the hippocampus and entorhinal cortex</article-title><source>Cell Reports</source><volume>4</volume><fpage>1010</fpage><lpage>1021</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2013.07.039</pub-id><pub-id pub-id-type="pmid">23994479</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mochizuki</surname><given-names>Y</given-names></name><name><surname>Onaga</surname><given-names>T</given-names></name><name><surname>Shimazaki</surname><given-names>H</given-names></name><name><surname>Shimokawa</surname><given-names>T</given-names></name><name><surname>Tsubo</surname><given-names>Y</given-names></name><name><surname>Kimura</surname><given-names>R</given-names></name><name><surname>Saiki</surname><given-names>A</given-names></name><name><surname>Sakai</surname><given-names>Y</given-names></name><name><surname>Isomura</surname><given-names>Y</given-names></name><name><surname>Fujisawa</surname><given-names>S</given-names></name><name><surname>Shibata</surname><given-names>K</given-names></name><name><surname>Hirai</surname><given-names>D</given-names></name><name><surname>Furuta</surname><given-names>T</given-names></name><name><surname>Kaneko</surname><given-names>T</given-names></name><name><surname>Takahashi</surname><given-names>S</given-names></name><name><surname>Nakazono</surname><given-names>T</given-names></name><name><surname>Ishino</surname><given-names>S</given-names></name><name><surname>Sakurai</surname><given-names>Y</given-names></name><name><surname>Kitsukawa</surname><given-names>T</given-names></name><name><surname>Lee</surname><given-names>JW</given-names></name><name><surname>Lee</surname><given-names>H</given-names></name><name><surname>Jung</surname><given-names>MW</given-names></name><name><surname>Babul</surname><given-names>C</given-names></name><name><surname>Maldonado</surname><given-names>PE</given-names></name><name><surname>Takahashi</surname><given-names>K</given-names></name><name><surname>Arce-McShane</surname><given-names>FI</given-names></name><name><surname>Ross</surname><given-names>CF</given-names></name><name><surname>Sessle</surname><given-names>BJ</given-names></name><name><surname>Hatsopoulos</surname><given-names>NG</given-names></name><name><surname>Brochier</surname><given-names>T</given-names></name><name><surname>Riehle</surname><given-names>A</given-names></name><name><surname>Chorley</surname><given-names>P</given-names></name><name><surname>Grün</surname><given-names>S</given-names></name><name><surname>Nishijo</surname><given-names>H</given-names></name><name><surname>Ichihara-Takeda</surname><given-names>S</given-names></name><name><surname>Funahashi</surname><given-names>S</given-names></name><name><surname>Shima</surname><given-names>K</given-names></name><name><surname>Mushiake</surname><given-names>H</given-names></name><name><surname>Yamane</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>firing regimes across mammalian species</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>5736</fpage><lpage>5747</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0230-16.2016</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murray</surname><given-names>JD</given-names></name><name><surname>Bernacchia</surname><given-names>A</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name><name><surname>Romo</surname><given-names>R</given-names></name><name><surname>Wallis</surname><given-names>JD</given-names></name><name><surname>Cai</surname><given-names>X</given-names></name><name><surname>Padoa-Schioppa</surname><given-names>C</given-names></name><name><surname>Pasternak</surname><given-names>T</given-names></name><name><surname>Seo</surname><given-names>H</given-names></name><name><surname>Lee</surname><given-names>D</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A hierarchy of intrinsic timescales across primate cortex</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1661</fpage><lpage>1663</lpage><pub-id pub-id-type="doi">10.1038/nn.3862</pub-id><pub-id pub-id-type="pmid">25383900</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niell</surname><given-names>CM</given-names></name><name><surname>Stryker</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Highly selective receptive fields in mouse visual cortex</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>7520</fpage><lpage>7536</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0623-08.2008</pub-id><pub-id pub-id-type="pmid">18650330</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olshausen</surname><given-names>BA</given-names></name><name><surname>Field</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Sparse coding of sensory inputs</article-title><source>Current Opinion in Neurobiology</source><volume>14</volume><fpage>481</fpage><lpage>487</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2004.07.007</pub-id><pub-id pub-id-type="pmid">15321069</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pan</surname><given-names>SJ</given-names></name><name><surname>Yang</surname><given-names>Q</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A survey on transfer learning</article-title><source>IEEE Transactions on Knowledge and Data Engineering</source><volume>22</volume><fpage>1345</fpage><lpage>1359</lpage><pub-id pub-id-type="doi">10.1109/TKDE.2009.191</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pandarinath</surname><given-names>C</given-names></name><name><surname>O’Shea</surname><given-names>DJ</given-names></name><name><surname>Collins</surname><given-names>J</given-names></name><name><surname>Jozefowicz</surname><given-names>R</given-names></name><name><surname>Stavisky</surname><given-names>SD</given-names></name><name><surname>Kao</surname><given-names>JC</given-names></name><name><surname>Trautmann</surname><given-names>EM</given-names></name><name><surname>Kaufman</surname><given-names>MT</given-names></name><name><surname>Ryu</surname><given-names>SI</given-names></name><name><surname>Hochberg</surname><given-names>LR</given-names></name><name><surname>Henderson</surname><given-names>JM</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Inferring single-trial neural population dynamics using sequential auto-encoders</article-title><source>Nature Methods</source><volume>15</volume><fpage>805</fpage><lpage>815</lpage><pub-id pub-id-type="doi">10.1038/s41592-018-0109-9</pub-id><pub-id pub-id-type="pmid">30224673</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Parks</surname><given-names>DF</given-names></name><name><surname>Schneider</surname><given-names>AM</given-names></name><name><surname>Xu</surname><given-names>Y</given-names></name><name><surname>Brunwasser</surname><given-names>SJ</given-names></name><name><surname>Funderburk</surname><given-names>S</given-names></name><name><surname>Thurber</surname><given-names>D</given-names></name><name><surname>Blanche</surname><given-names>T</given-names></name><name><surname>Dyer</surname><given-names>EL</given-names></name><name><surname>Haussler</surname><given-names>D</given-names></name><name><surname>Hengen</surname><given-names>KB</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>A Non-oscillatory, millisecond-scale embedding of brain state provides insight into behavior</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.06.09.544399</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patel</surname><given-names>N</given-names></name><name><surname>Poo</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Orientation of neurite growth by extracellular electric fields</article-title><source>The Journal of Neuroscience</source><volume>2</volume><fpage>483</fpage><lpage>496</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.02-04-00483.1982</pub-id><pub-id pub-id-type="pmid">6279799</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Paz</surname><given-names>L</given-names></name><name><surname>Insabato</surname><given-names>A</given-names></name><name><surname>Zylberberg</surname><given-names>A</given-names></name><name><surname>Deco</surname><given-names>G</given-names></name><name><surname>Sigman</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Confidence through consensus: a neural mechanism for uncertainty monitoring</article-title><source>Scientific Reports</source><volume>6</volume><elocation-id>21830</elocation-id><pub-id pub-id-type="doi">10.1038/srep21830</pub-id><pub-id pub-id-type="pmid">26907162</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pedregosa</surname><given-names>F</given-names></name><name><surname>Varoquaux</surname><given-names>G</given-names></name><name><surname>Gramfort</surname><given-names>A</given-names></name><name><surname>Michel</surname><given-names>V</given-names></name><name><surname>Thirion</surname><given-names>B</given-names></name><name><surname>Grisel</surname><given-names>O</given-names></name><name><surname>Blondel</surname><given-names>M</given-names></name><name><surname>Prettenhofer</surname><given-names>P</given-names></name><name><surname>Weiss</surname><given-names>R</given-names></name><name><surname>Dubourg</surname><given-names>V</given-names></name><name><surname>Vanderplas</surname><given-names>J</given-names></name><name><surname>Passos</surname><given-names>A</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Brucher</surname><given-names>M</given-names></name><name><surname>Perrot</surname><given-names>M</given-names></name><name><surname>Duchesnay</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Scikit-learn: machine learning in Python</article-title><source>Journal of Machine Learning Research</source><volume>12</volume><fpage>2825</fpage><lpage>2830</lpage><pub-id pub-id-type="doi">10.5555/1953048.2078195</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Penfield</surname><given-names>W</given-names></name><name><surname>Jasper</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1951">1951</year><source>Epilepsy and the Functional Anatomy of the Human Brain</source><publisher-name>Little, Brown and Company</publisher-name></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Renart</surname><given-names>A</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Variability in neural activity and behavior</article-title><source>Current Opinion in Neurobiology</source><volume>25</volume><fpage>211</fpage><lpage>220</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2014.02.013</pub-id><pub-id pub-id-type="pmid">24632334</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Riehle</surname><given-names>A</given-names></name><name><surname>Grün</surname><given-names>S</given-names></name><name><surname>Diesmann</surname><given-names>M</given-names></name><name><surname>Aertsen</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Spike synchronization and rate modulation differentially involved in motor cortical function</article-title><source>Science</source><volume>278</volume><fpage>1950</fpage><lpage>1953</lpage><pub-id pub-id-type="doi">10.1126/science.278.5345.1950</pub-id><pub-id pub-id-type="pmid">9395398</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenbaum</surname><given-names>R</given-names></name><name><surname>Smith</surname><given-names>MA</given-names></name><name><surname>Kohn</surname><given-names>A</given-names></name><name><surname>Rubin</surname><given-names>JE</given-names></name><name><surname>Doiron</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The spatial structure of correlated neuronal variability</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>107</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1038/nn.4433</pub-id><pub-id pub-id-type="pmid">27798630</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roth</surname><given-names>MM</given-names></name><name><surname>Helmchen</surname><given-names>F</given-names></name><name><surname>Kampa</surname><given-names>BM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Distinct functional properties of primary and posteromedial visual area of mouse neocortex</article-title><source>The Journal of Neuroscience</source><volume>32</volume><fpage>9716</fpage><lpage>9726</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0110-12.2012</pub-id><pub-id pub-id-type="pmid">22787057</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roxin</surname><given-names>A</given-names></name><name><surname>Brunel</surname><given-names>N</given-names></name><name><surname>Hansel</surname><given-names>D</given-names></name><name><surname>Mongillo</surname><given-names>G</given-names></name><name><surname>van Vreeswijk</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>On the distribution of firing rates in networks of cortical neurons</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>16217</fpage><lpage>16226</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1677-11.2011</pub-id><pub-id pub-id-type="pmid">22072673</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruff</surname><given-names>DA</given-names></name><name><surname>Cohen</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Attention can either increase or decrease spike count correlations in visual cortex</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1591</fpage><lpage>1597</lpage><pub-id pub-id-type="doi">10.1038/nn.3835</pub-id><pub-id pub-id-type="pmid">25306550</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="book"><person-group person-group-type="author"><collab>Santiago Ram´on y Cajal</collab></person-group><year iso-8601-date="1899">1899</year><source>Textura Del Sistema Nervioso Del Hombre y de Los Vertebrados</source><publisher-name>University of Calgary</publisher-name></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saunders</surname><given-names>A</given-names></name><name><surname>Macosko</surname><given-names>EZ</given-names></name><name><surname>Wysoker</surname><given-names>A</given-names></name><name><surname>Goldman</surname><given-names>M</given-names></name><name><surname>Krienen</surname><given-names>FM</given-names></name><name><surname>de Rivera</surname><given-names>H</given-names></name><name><surname>Bien</surname><given-names>E</given-names></name><name><surname>Baum</surname><given-names>M</given-names></name><name><surname>Bortolin</surname><given-names>L</given-names></name><name><surname>Wang</surname><given-names>S</given-names></name><name><surname>Goeva</surname><given-names>A</given-names></name><name><surname>Nemesh</surname><given-names>J</given-names></name><name><surname>Kamitaki</surname><given-names>N</given-names></name><name><surname>Brumbaugh</surname><given-names>S</given-names></name><name><surname>Kulp</surname><given-names>D</given-names></name><name><surname>McCarroll</surname><given-names>SA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Molecular diversity and specializations among the cells of the adult mouse brain</article-title><source>Cell</source><volume>174</volume><fpage>1015</fpage><lpage>1030</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.07.028</pub-id><pub-id pub-id-type="pmid">30096299</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sawant</surname><given-names>Y</given-names></name><name><surname>Kundu</surname><given-names>JN</given-names></name><name><surname>Radhakrishnan</surname><given-names>VB</given-names></name><name><surname>Sridharan</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A midbrain inspired recurrent neural network model for robust change detection</article-title><source>The Journal of Neuroscience</source><volume>42</volume><fpage>8262</fpage><lpage>8283</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0164-22.2022</pub-id><pub-id pub-id-type="pmid">36123120</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmolesky</surname><given-names>MT</given-names></name><name><surname>Wang</surname><given-names>Y</given-names></name><name><surname>Hanes</surname><given-names>DP</given-names></name><name><surname>Thompson</surname><given-names>KG</given-names></name><name><surname>Leutgeb</surname><given-names>S</given-names></name><name><surname>Schall</surname><given-names>JD</given-names></name><name><surname>Leventhal</surname><given-names>AG</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Signal timing across the macaque visual system</article-title><source>Journal of Neurophysiology</source><volume>79</volume><fpage>3272</fpage><lpage>3278</lpage><pub-id pub-id-type="doi">10.1152/jn.1998.79.6.3272</pub-id><pub-id pub-id-type="pmid">9636126</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schneider</surname><given-names>A</given-names></name><name><surname>Azabou</surname><given-names>M</given-names></name><name><surname>McDougall-Vigier</surname><given-names>L</given-names></name><name><surname>Parks</surname><given-names>DF</given-names></name><name><surname>Ensley</surname><given-names>S</given-names></name><name><surname>Bhaskaran-Nair</surname><given-names>K</given-names></name><name><surname>Nowakowski</surname><given-names>T</given-names></name><name><surname>Dyer</surname><given-names>EL</given-names></name><name><surname>Hengen</surname><given-names>KB</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Transcriptomic cell type structures in vivo neuronal activity across multiple timescales</article-title><source>Cell Reports</source><volume>42</volume><elocation-id>112318</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2023.112318</pub-id><pub-id pub-id-type="pmid">36995938</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Noise, neural codes and cortical organization</article-title><source>Current Opinion in Neurobiology</source><volume>4</volume><fpage>569</fpage><lpage>579</lpage><pub-id pub-id-type="doi">10.1016/0959-4388(94)90059-0</pub-id><pub-id pub-id-type="pmid">7812147</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shinomoto</surname><given-names>S</given-names></name><name><surname>Kim</surname><given-names>H</given-names></name><name><surname>Shimokawa</surname><given-names>T</given-names></name><name><surname>Matsuno</surname><given-names>N</given-names></name><name><surname>Funahashi</surname><given-names>S</given-names></name><name><surname>Shima</surname><given-names>K</given-names></name><name><surname>Fujita</surname><given-names>I</given-names></name><name><surname>Tamura</surname><given-names>H</given-names></name><name><surname>Doi</surname><given-names>T</given-names></name><name><surname>Kawano</surname><given-names>K</given-names></name><name><surname>Inaba</surname><given-names>N</given-names></name><name><surname>Fukushima</surname><given-names>K</given-names></name><name><surname>Kurkin</surname><given-names>S</given-names></name><name><surname>Kurata</surname><given-names>K</given-names></name><name><surname>Taira</surname><given-names>M</given-names></name><name><surname>Tsutsui</surname><given-names>K-I</given-names></name><name><surname>Komatsu</surname><given-names>H</given-names></name><name><surname>Ogawa</surname><given-names>T</given-names></name><name><surname>Koida</surname><given-names>K</given-names></name><name><surname>Tanji</surname><given-names>J</given-names></name><name><surname>Toyama</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Relating neuronal firing patterns to functional differentiation of cerebral cortex</article-title><source>PLOS Computational Biology</source><volume>5</volume><elocation-id>e1000433</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000433</pub-id><pub-id pub-id-type="pmid">19593378</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siegle</surname><given-names>JH</given-names></name><name><surname>Jia</surname><given-names>X</given-names></name><name><surname>Durand</surname><given-names>S</given-names></name><name><surname>Gale</surname><given-names>S</given-names></name><name><surname>Bennett</surname><given-names>C</given-names></name><name><surname>Graddis</surname><given-names>N</given-names></name><name><surname>Heller</surname><given-names>G</given-names></name><name><surname>Ramirez</surname><given-names>TK</given-names></name><name><surname>Choi</surname><given-names>H</given-names></name><name><surname>Luviano</surname><given-names>JA</given-names></name><name><surname>Groblewski</surname><given-names>PA</given-names></name><name><surname>Ahmed</surname><given-names>R</given-names></name><name><surname>Arkhipov</surname><given-names>A</given-names></name><name><surname>Bernard</surname><given-names>A</given-names></name><name><surname>Billeh</surname><given-names>YN</given-names></name><name><surname>Brown</surname><given-names>D</given-names></name><name><surname>Buice</surname><given-names>MA</given-names></name><name><surname>Cain</surname><given-names>N</given-names></name><name><surname>Caldejon</surname><given-names>S</given-names></name><name><surname>Casal</surname><given-names>L</given-names></name><name><surname>Cho</surname><given-names>A</given-names></name><name><surname>Chvilicek</surname><given-names>M</given-names></name><name><surname>Cox</surname><given-names>TC</given-names></name><name><surname>Dai</surname><given-names>K</given-names></name><name><surname>Denman</surname><given-names>DJ</given-names></name><name><surname>de Vries</surname><given-names>SEJ</given-names></name><name><surname>Dietzman</surname><given-names>R</given-names></name><name><surname>Esposito</surname><given-names>L</given-names></name><name><surname>Farrell</surname><given-names>C</given-names></name><name><surname>Feng</surname><given-names>D</given-names></name><name><surname>Galbraith</surname><given-names>J</given-names></name><name><surname>Garrett</surname><given-names>M</given-names></name><name><surname>Gelfand</surname><given-names>EC</given-names></name><name><surname>Hancock</surname><given-names>N</given-names></name><name><surname>Harris</surname><given-names>JA</given-names></name><name><surname>Howard</surname><given-names>R</given-names></name><name><surname>Hu</surname><given-names>B</given-names></name><name><surname>Hytnen</surname><given-names>R</given-names></name><name><surname>Iyer</surname><given-names>R</given-names></name><name><surname>Jessett</surname><given-names>E</given-names></name><name><surname>Johnson</surname><given-names>K</given-names></name><name><surname>Kato</surname><given-names>I</given-names></name><name><surname>Kiggins</surname><given-names>J</given-names></name><name><surname>Lambert</surname><given-names>S</given-names></name><name><surname>Lecoq</surname><given-names>J</given-names></name><name><surname>Ledochowitsch</surname><given-names>P</given-names></name><name><surname>Lee</surname><given-names>JH</given-names></name><name><surname>Leon</surname><given-names>A</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Liang</surname><given-names>E</given-names></name><name><surname>Long</surname><given-names>F</given-names></name><name><surname>Mace</surname><given-names>K</given-names></name><name><surname>Melchior</surname><given-names>J</given-names></name><name><surname>Millman</surname><given-names>D</given-names></name><name><surname>Mollenkopf</surname><given-names>T</given-names></name><name><surname>Nayan</surname><given-names>C</given-names></name><name><surname>Ng</surname><given-names>L</given-names></name><name><surname>Ngo</surname><given-names>K</given-names></name><name><surname>Nguyen</surname><given-names>T</given-names></name><name><surname>Nicovich</surname><given-names>PR</given-names></name><name><surname>North</surname><given-names>K</given-names></name><name><surname>Ocker</surname><given-names>GK</given-names></name><name><surname>Ollerenshaw</surname><given-names>D</given-names></name><name><surname>Oliver</surname><given-names>M</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Perkins</surname><given-names>J</given-names></name><name><surname>Reding</surname><given-names>M</given-names></name><name><surname>Reid</surname><given-names>D</given-names></name><name><surname>Robertson</surname><given-names>M</given-names></name><name><surname>Ronellenfitch</surname><given-names>K</given-names></name><name><surname>Seid</surname><given-names>S</given-names></name><name><surname>Slaughterbeck</surname><given-names>C</given-names></name><name><surname>Stoecklin</surname><given-names>M</given-names></name><name><surname>Sullivan</surname><given-names>D</given-names></name><name><surname>Sutton</surname><given-names>B</given-names></name><name><surname>Swapp</surname><given-names>J</given-names></name><name><surname>Thompson</surname><given-names>C</given-names></name><name><surname>Turner</surname><given-names>K</given-names></name><name><surname>Wakeman</surname><given-names>W</given-names></name><name><surname>Whitesell</surname><given-names>JD</given-names></name><name><surname>Williams</surname><given-names>D</given-names></name><name><surname>Williford</surname><given-names>A</given-names></name><name><surname>Young</surname><given-names>R</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Naylor</surname><given-names>S</given-names></name><name><surname>Phillips</surname><given-names>JW</given-names></name><name><surname>Reid</surname><given-names>RC</given-names></name><name><surname>Mihalas</surname><given-names>S</given-names></name><name><surname>Olsen</surname><given-names>SR</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Survey of spiking in the mouse visual system reveals functional hierarchy</article-title><source>Nature</source><volume>592</volume><fpage>86</fpage><lpage>92</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-03171-x</pub-id><pub-id pub-id-type="pmid">33473216</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>MA</given-names></name><name><surname>Kohn</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Spatial and temporal scales of neuronal correlation in primary visual cortex</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>12591</fpage><lpage>12603</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2929-08.2008</pub-id><pub-id pub-id-type="pmid">19036953</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>MA</given-names></name><name><surname>Sommer</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Spatial and temporal scales of neuronal correlation in visual area V4</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>5422</fpage><lpage>5432</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4782-12.2013</pub-id><pub-id pub-id-type="pmid">23516307</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Softky</surname><given-names>WR</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>The highly irregular firing of cortical cells is inconsistent with temporal integration of random EPSPs</article-title><source>The Journal of Neuroscience</source><volume>13</volume><fpage>334</fpage><lpage>350</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.13-01-00334.1993</pub-id><pub-id pub-id-type="pmid">8423479</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Zatka-Haas</surname><given-names>P</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Distributed coding of choice, action and engagement across the mouse brain</article-title><source>Nature</source><volume>576</volume><fpage>266</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1787-x</pub-id><pub-id pub-id-type="pmid">31776518</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Vapnik</surname><given-names>VN</given-names></name></person-group><year iso-8601-date="1998">1998</year><source>Statistical Learning Theory</source><publisher-name>Wiley-Interscience</publisher-name><pub-id pub-id-type="doi">10.1109/72.788640</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Virtanen</surname><given-names>P</given-names></name><name><surname>Gommers</surname><given-names>R</given-names></name><name><surname>Oliphant</surname><given-names>TE</given-names></name><name><surname>Haberland</surname><given-names>M</given-names></name><name><surname>Reddy</surname><given-names>T</given-names></name><name><surname>Cournapeau</surname><given-names>D</given-names></name><name><surname>Burovski</surname><given-names>E</given-names></name><name><surname>Peterson</surname><given-names>P</given-names></name><name><surname>Weckesser</surname><given-names>W</given-names></name><name><surname>Bright</surname><given-names>J</given-names></name><name><surname>Brett</surname><given-names>M</given-names></name><name><surname>Joshua Wilson</surname><given-names>KJM</given-names></name><name><surname>Mayorov</surname><given-names>N</given-names></name><name><surname>Nelson</surname><given-names>ARJ</given-names></name><name><surname>Jones</surname><given-names>E</given-names></name><name><surname>Kern</surname><given-names>R</given-names></name><name><surname>Eric Larson</surname><given-names>CJC</given-names></name><name><surname>Polat</surname><given-names>İ</given-names></name><name><surname>Feng</surname><given-names>Y</given-names></name><name><surname>Moore</surname><given-names>EW</given-names></name><name><surname>VanderPlas</surname><given-names>J</given-names></name><name><surname>Laxalde</surname><given-names>D</given-names></name><name><surname>Perktold</surname><given-names>J</given-names></name><name><surname>Cimrman</surname><given-names>R</given-names></name><name><surname>Ian Henriksen</surname><given-names>EAQ</given-names></name><name><surname>Harris</surname><given-names>CR</given-names></name><name><surname>Archibald</surname><given-names>AM</given-names></name><name><surname>Ribeiro</surname><given-names>AH</given-names></name><name><surname>Pedregosa</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Paul van Mulbregt, and SciPy 1.0 contributors. SciPy 1.0: fundamental algorithms for scientific computing in python</article-title><source>Nature Methods</source><volume>17</volume><fpage>261</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Burkhalter</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Area map of mouse visual cortex</article-title><source>The Journal of Comparative Neurology</source><volume>502</volume><fpage>339</fpage><lpage>357</lpage><pub-id pub-id-type="doi">10.1002/cne.21286</pub-id><pub-id pub-id-type="pmid">17366604</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>Ding</surname><given-names>S-L</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Royall</surname><given-names>J</given-names></name><name><surname>Feng</surname><given-names>D</given-names></name><name><surname>Lesnar</surname><given-names>P</given-names></name><name><surname>Graddis</surname><given-names>N</given-names></name><name><surname>Naeemi</surname><given-names>M</given-names></name><name><surname>Facer</surname><given-names>B</given-names></name><name><surname>Ho</surname><given-names>A</given-names></name><name><surname>Dolbeare</surname><given-names>T</given-names></name><name><surname>Blanchard</surname><given-names>B</given-names></name><name><surname>Dee</surname><given-names>N</given-names></name><name><surname>Wakeman</surname><given-names>W</given-names></name><name><surname>Hirokawa</surname><given-names>KE</given-names></name><name><surname>Szafer</surname><given-names>A</given-names></name><name><surname>Sunkin</surname><given-names>SM</given-names></name><name><surname>Oh</surname><given-names>SW</given-names></name><name><surname>Bernard</surname><given-names>A</given-names></name><name><surname>Phillips</surname><given-names>JW</given-names></name><name><surname>Hawrylycz</surname><given-names>M</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>Zeng</surname><given-names>H</given-names></name><name><surname>Harris</surname><given-names>JA</given-names></name><name><surname>Ng</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The allen mouse brain common coordinate framework: A 3D reference atlas</article-title><source>Cell</source><volume>181</volume><fpage>936</fpage><lpage>953</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.04.007</pub-id><pub-id pub-id-type="pmid">32386544</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>XJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Theory of the multiregional neocortex: Large-scale neural dynamics and distributed Cognition</article-title><source>Annual Review of Neuroscience</source><volume>45</volume><fpage>533</fpage><lpage>560</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-110920-035434</pub-id><pub-id pub-id-type="pmid">35803587</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>H</given-names></name><name><surname>Dey</surname><given-names>O</given-names></name><name><surname>Lagos</surname><given-names>WN</given-names></name><name><surname>Callaway</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Diversity in spatial frequency, temporal frequency, and speed tuning across mouse visual cortical areas and layers</article-title><source>The Journal of Comparative Neurology</source><volume>530</volume><fpage>3226</fpage><lpage>3247</lpage><pub-id pub-id-type="doi">10.1002/cne.25404</pub-id><pub-id pub-id-type="pmid">36070574</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Welles</surname><given-names>O</given-names></name></person-group><year iso-8601-date="1958">1958</year><source>Touch of Evil (film)</source><publisher-name>Universal Pictures</publisher-name></element-citation></ref><ref id="bib87"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeisel</surname><given-names>A</given-names></name><name><surname>Hochgerner</surname><given-names>H</given-names></name><name><surname>Lönnerberg</surname><given-names>P</given-names></name><name><surname>Johnsson</surname><given-names>A</given-names></name><name><surname>Memic</surname><given-names>F</given-names></name><name><surname>van der Zwan</surname><given-names>J</given-names></name><name><surname>Häring</surname><given-names>M</given-names></name><name><surname>Braun</surname><given-names>E</given-names></name><name><surname>Borm</surname><given-names>LE</given-names></name><name><surname>La Manno</surname><given-names>G</given-names></name><name><surname>Codeluppi</surname><given-names>S</given-names></name><name><surname>Furlan</surname><given-names>A</given-names></name><name><surname>Lee</surname><given-names>K</given-names></name><name><surname>Skene</surname><given-names>N</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Hjerling-Leffler</surname><given-names>J</given-names></name><name><surname>Arenas</surname><given-names>E</given-names></name><name><surname>Ernfors</surname><given-names>P</given-names></name><name><surname>Marklund</surname><given-names>U</given-names></name><name><surname>Linnarsson</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Molecular architecture of the mouse nervous system</article-title><source>Cell</source><volume>174</volume><fpage>999</fpage><lpage>1014</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.06.021</pub-id><pub-id pub-id-type="pmid">30096314</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.101506.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Sharpee</surname><given-names>Tatyana O</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Salk Institute for Biological Studies</institution><country>United States</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Useful</kwd></kwd-group></front-stub><body><p>This paper provides a <bold>useful</bold> systematic quantification of the relationship between electrophysiological response properties of single neurons with their position in the brain. The quality of the classification setup is high and the methodology is <bold>solid</bold>.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.101506.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>The paper by Tolossa et al. presents classification studies that aim to predict the anatomical location of a neuron from the statistics of its in-vivo firing pattern. They study two types of statistics (ISI distribution, PSTH) and try to predict the location at different resolutions (region, subregion, cortical layer).</p><p>Strengths:</p><p>This paper provides a systematic quantification of the single-neuron firing vs location relationship.</p><p>The quality of the classification setup seems high.</p><p>The paper uncovers that, at the single neuron level, the firing pattern of a neuron carries some information on the neuron's anatomical location, although the predictive accuracy is not high enough to rely on this relationship in most cases.</p><p>Weaknesses:</p><p>As the authors mention in the Discussion, it is not clear whether the observed differences in firing is epiphenomenal. If the anatomical location information is useful to the neuron, to what extent can this be inferred from the vicinity of the synaptic site, based on the neurotransmitter and neuromodulator identities? Why would the neuron need to dynamically update its prediction of the anatomical location of its pre-synaptic partner based on activity when that location is static, and if that information is genetically encoded in synaptic proteins, etc (e.g., the type of the synaptic site)? Note that the neuron does not need to classify all possible locations to guess the location of its pre-synaptic partner because it may only receive input from a subset of locations. Ultimately, the inability to dissect whether the paper's findings point to a mechanism utilized by neurons or merely represent an epiphenomenon is the main weakness of the curious, though somewhat weak, observations described in this paper.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.101506.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>In this manuscript, Tolossa et al. analyze Inter-spike intervals from various freely available datasets from the Allen Institute and from a dataset from Steinmetz et al.. They show that they can modestly decode between gross brain regions (Visual vs. Hippocampus vs. Thalamus), and modestly separate sub areas within brain regions (DG vs. CA1 or various visual brain areas). The core result is that a multi-layer perceptron trained on the ISI distributions can modestly classify different brain areas and perhaps in a reasonably compelling way generalize across animals. The result is interesting but the exact problem formulation still feels a tad murky to me because I am worried the null is a strawman and I'm unsure if anyone has ever argued for this null hypothesis (&quot;the impact of anatomy on a neuron's activity is either nonexistent or unremarkable&quot;). Given the patterns of inputs to different brain areas and the existence of different developmental origin and different cell types within these areas, I am unclear why this would be a good null hypothesis. Nevertheless, the machine learning is reasonable, and the authors demonstrate that a nonlinear population based classifier can pull out reasonable information about the brain area and layer.</p><p>Strengths:</p><p>The paper is reasonably well written, and the definitions are quite well done. For example, the authors clearly explained transductive vs. inductive inference in their decoders. E.g., transductive learning allows the decoder to learn features from each animal, whereas inductive inference focuses on withheld animals and prioritizes the learning of generalizable features. The authors walk the reader through various analyses starting as simply as PCA, then finally showing a MLP trained on ISI distributions and PSTHs performs modestly well in decoding brain area. The key is ISI distributions work well in inductive settings for generalizing from one mouse to the other.</p><p>Weaknesses:</p><p>As articulated in my overall summary, I still found the null hypothesis a tad underwhelming. I am not sure this is really a valid null hypothesis (&quot;the impact of anatomy on a neuron's activity is either nonexistent or unremarkable&quot;), although in the statistical sense it is fine. The authors took on board some of the advice from the first review and clarified the paper but there are portions that are unnecessarily verbose (e.g., &quot;Beyond fundamental scientific insight, our findings may be of benefit in various practical applications, such as the continued development of brain-machine interfaces and neuroprosthetics&quot;). Also, given that ISIs cannot separate between visual areas, why is the statement that these are conserved. I still find it somewhat underwhelming that the thalamus, hippocampus , and visual cortex have different ISI distributions. Multiple researchers have reported similar things in cortex perhaps without the focus on decoding area from these ISI distributions.</p><p>All in all, it is an interesting paper with the notion that ISI distributions can modestly predict brain area and layer. It could have some potential for a tool for neuropixels, although this needs to be developed further for this use case.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.101506.3.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Tolossa</surname><given-names>Gemechu Bekele</given-names></name><role specific-use="author">Author</role><aff><institution>Washington University in St. Louis</institution><addr-line><named-content content-type="city">Saint Louis</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Schneider</surname><given-names>Aidan M</given-names></name><role specific-use="author">Author</role><aff><institution>Washington University in St. Louis</institution><addr-line><named-content content-type="city">Saint Louis</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Dyer</surname><given-names>Eva</given-names></name><role specific-use="author">Author</role><aff><institution>Georgia Tech</institution><addr-line><named-content content-type="city">Georgia</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Hengen</surname><given-names>Keith B</given-names></name><role specific-use="author">Author</role><aff><institution>Washington University in St. Louis</institution><addr-line><named-content content-type="city">Saint Louis</named-content></addr-line><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Recommendations for the authors):</bold></p></disp-quote><p>We appreciate the reviewers' thoughtful comments and suggestions. Below, we provide point-by-point responses to the recommendations and outline the updates made to the manuscript.</p><disp-quote content-type="editor-comment"><p>(1) Discussion, &quot;the obvious experiment is to manipulate a neuron's anatomical embedding while leaving stimulus information intact.&quot; The epiphenomenon can arise from the placement and types of a neuron's neurotransmitters and neuromodulators, too.</p></disp-quote><p>The content of vesicles released by a neuron is obviously of great importance in determining postsynaptic impact. However, we’re suggesting that (assuming vesicular content is held constant) the anatomically-relevant patterning of spiking might additionally affect the postsynaptic neuron’s integration of the presynaptic input. To avoid confusion, we updated the text accordingly: “the obvious experiment is to manipulate a neuron's anatomical embedding while minimally impacting external and internal variables, such as stimulus information and levels of neurotransmitters or neuromodulators” (Line 594 - 596).</p><disp-quote content-type="editor-comment"><p>(2) “In all conditions, the slope of the input duration versus sensitivity line was still positive at 1,800 seconds (Fig. 3B)&quot;. This may suggest that the estimate of the calculated statistics (ISI, PSTH) is more reliable with more data, rather than (or in addition to) specific information being extracted from faraway time points. Another potential confound is the training statistics were calculated from all training data, so the test data is a better match to training data when test statistics are calculated from more data. Overall, the validity of the conclusions following this observation is not clear to me.</p></disp-quote><p>This is a great point. Accordingly, we revised the text to include this possibility: “Because the training data were of similar duration, this could be explained by either of two possibilities. First, the signal is relatively short, but noisy—in this case, extended sampling will increase reliability. Second, the anatomical signal is, itself, distributed over time scales of tens to hundreds of seconds.” (Line 252 - 255).</p><disp-quote content-type="editor-comment"><p>(3) &quot;This further suggests that there is a latent neural code for anatomical location embedded within the spike train, a feature that could be practically applied to determining the brain region of a recording electrode without the need for post-hoc histology&quot;. The performance of the model at the subregion level, which is a typical level of desired precision in locating cells, does not seem to support such a practical application. Please clarify to avoid confusion.</p></disp-quote><p>The current model should not be considered a replacement for traditional methods, such as histology. Our intention is to convey that, with the inclusion of multimodal data and additional samples, a computational approach to anatomical localization has great promise. We updated the manuscript to clarify this point: “While significantly above chance, the structure-level model still lacks the accuracy for immediate practical application. However, it is highly likely that the incorporation of datasets with diverse multi-modal features and alternative regions from other research groups will increase the accuracy of such a model. In addition, a computational approach can be combined with other methods of anatomical reconstruction.” (Line 355 - 359).</p><p>Additionally, we directly addressed this point in our original manuscript (Discussion section: Line 498 - 505 in the current version). Furthermore, following the release of our preprint, independent efforts have adopted a multimodal strategy with qualitatively similar results (Yu et al., 2024). Other recent work expands on the idea of utilizing single-neuron features for brain region/structure characterization (La Merre et al., 2024).</p><p>Yu, H., Lyu, H., Xu, E. Y., Windolf, C., Lee, E. K., Yang, F., ... &amp; Hurwitz, C. (2024). In vivo cell-type and brain region classification via multimodal contrastive learning. bioRxiv, 2024-11.</p><p>Le Merre, P., Heining, K., Slashcheva, M., Jung, F., Moysiadou, E., Guyon, N., ... &amp; Carlén, M. (2024). A Prefrontal Cortex Map based on Single Neuron Activity. bioRxiv, 2024-11.</p><disp-quote content-type="editor-comment"><p>(4) &quot;These results support the notion the meaningful computational division in murine visuocortical regions is at the level of VISp versus secondary areas.&quot;. The use of the word &quot;meaningful&quot; is vague and this conclusion is not well justified because it is possible that subregions serve different functional roles without having different spiking statistics.</p></disp-quote><p>Precisely! It is well established that different subregions serve different functional purposes - but they do not necessitate different regional embeddings. It is important to note the difference between stimulus encoding and the embedding that we are describing. As a rough analogy, the regional embedding might be considered a language, while the stimulus is the content of the spoken words. However, to avoid vague words, we revised the sentence to “These results suggest that the computational differentiability of murine visuocortical regions is at the level of VISp versus secondary areas.” (Line 380 - 381)</p><disp-quote content-type="editor-comment"><p>(5) Figure 3D left/right halves look similar. A measure of the effect size needs to accompany these p-values.</p></disp-quote><p>We assume the reviewer is referring to Figure 3E. Although some of the violin plots in Figure 3E look similar, they are not identical. In the revision, we include effect sizes in the caption.</p><disp-quote content-type="editor-comment"><p>(6) Figure 3A, 3F: Could uncertainty estimates be provided?</p></disp-quote><p>Yes. We added uncertainty estimates to the text (Line 272 - 294) and to the caption of Figure S2, which displays confusion matrices corresponding to Figure 3A. The inclusion of similar estimates for 3F would be so unwieldy as to be a disservice to the reader—there are 240 unique combinations of stimulus parameters and structures. In the context of the larger figure, 3F serves to illustrate a relationship between stimulus, region, and the anatomical embedding.</p><disp-quote content-type="editor-comment"><p>(7) Page 21. &quot;semi-orthogonal&quot;. Please reword or explain if this usage is technical.</p></disp-quote><p>We replaced “semi-orthogonal” with “dissociable” (Line 549).</p><disp-quote content-type="editor-comment"><p>(8) Page 11, &quot;This approach tested whether...&quot; Unclear sentence. Please reword.</p></disp-quote><p>We changed “This approach tested whether the MLP’s performance depended on viewing the entire ISI distribution or was enriched in a subset of patterns” to “This approach identified regions of the ISI distribution informative for classification” (Line 261).</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations for the authors):</bold></p></disp-quote><p>We appreciate the reviewer’s comments and summary of the results. We agree that the introductory results (Figs. 1-3) are not particularly compelling when considered in isolation. They provide a baseline of comparison for the subsequent results. Our intention was to approach the problem systematically, progressing from well-established, basic methods to more advanced approaches. This allows us to clearly test a baseline and avoid analytical leaps or untested assumptions. Specifically:</p><p>● Figure 1 provides an evaluation of the standard dimensionality reduction methods. As expected, these methods yield minimal results, serving as a clear baseline. This is consistent, for example, with an understanding of single units as rate-varying Poisson processes.</p><p>● Figures 2 and 3 then build upon these results with spiking features frequent in neuroscience literature such as firing rate, coefficient of variation, etc using linear supervised and more detailed spiking features such as ISI distribution using nonlinear supervised machine learning methods.</p><p>By starting from the standpoint of the status quo, we are better able to contextualize the significance of our later findings in Figures 4–6.</p><p>Response to Specific Points in the Summary</p><disp-quote content-type="editor-comment"><p>(6) Separability of VISp vs. Secondary Visual Areas</p><p>I found the entire argument about visual areas somewhat messy and unclear. The stimuli used might not drive the secondary visual areas particularly well and might necessitate task engagement.</p></disp-quote><p>We appreciate your feedback that the dissection of visual cortical structures is unclear. To summarize, as shown in the bottom three rows of Figure 6, there is a notable lack of diagonality in visuocortical structures. This means that our model was unable to learn signatures to reliably predict these classes. In contrast, visuocortical layer is returned well above chance, and superstructures (primary and secondary areas) are moderately well identified, albeit still well above chance.</p><disp-quote content-type="editor-comment"><p>Consider a thought experiment, if Charlie Gross had not shown faces to monkeys to find IT, or Newsome and others shown motion to find MT and Zeki and others color stimuli to find V4, we would conclude that there are no differences.</p></disp-quote><p>The thought experiment is misleading. The results specifically do not arise from stimulus selectivity—much of Newsome’s own work suggests that the selectivity of neurons in IT etc. is explained by little more than rate varying Poisson processes. In this case, there should be no fundamental anatomical difference in the “language” of the neurons in V4 and IT, only a difference in the inputs driving those neurons. In contrast, our work suggests that the “language” of neurons varies as a function of some anatomical divisions. In other words, in contrast to a Poisson rate code, our results predict that single neuron spike patterns might be remarkably different in MT and IT— and that this is not a function of stimulus selectivity. Notably, the anatomical (and functional) division between V1 and secondary visual areas does not appear to manifest in a different “language”, thus constituting an interesting result in and of itself.</p><p>We regret a failure to communicate this in a tight and compelling fashion on the first submission, but hope that the revision is limpid and accessible.</p><p>Barberini, C. L., Horwitz, G. D., &amp; Newsome, W. T. (2001). A comparison of spiking statistics in motion sensing neurones of flies and monkeys. Motion Vision: Computational, Neural, and Ecological Constraints, 307-320.</p><p>Bair, W., Zohary, E., &amp; Newsome, W. T. (2001). Correlated firing in macaque visual area MT: time scales and relationship to behavior. Journal of Neuroscience, 21(5), 1676-1697.</p><disp-quote content-type="editor-comment"><p>Similarly, why would drifting gratings be a good example of a stimulus for the hippocampus, an area thought to be involved in memory/place fields?</p></disp-quote><p>The results suggest that anatomical “language” is not tied to stimuli. It is imperative to recall that neurons are highly active absent experimentally imposed stimuli, such as when an animal is at rest, when an animal is asleep, and when an animal is in the dark (relevant to visual cortices). With this in mind, also recall that, despite the lack of stimuli tailored to the hippocampus, neurons therein were still reliably separable from neurons in seven nuclei in the thalamus, 6 of which are not classically considered visual regions. Should these regions (including hippocampus) have been inert during the presentation of visual stimuli, there would have been very little separability.</p><disp-quote content-type="editor-comment"><p>(7) Generalization across laboratories</p><p>“[C]omparison across laboratories was somewhat underwhelming. It does okay but none of the results are particularly compelling in terms of performance.</p></disp-quote><p>Any result above chance is a rejection of the null hypothesis: that a model trained on a set of animals in Laboratory A will be ineffective in identifying brain regions when tested on recordings collected in Laboratory B (in different animals and under different experimental conditions). As an existence proof, the results suggest conserved principles (however modest) that constrain neuronal activity as a function of anatomy. That models fail to achieve high accuracy (in this context) is not surprising (given the limitations of available recordings)---that models achieve anything above chance, however, is.</p><disp-quote content-type="editor-comment"><p>Thus, after reading the paper many times, I think part of the problem is that the study is not cohesive, and the authors need to either come up with a tool or demonstrate a scientific finding.</p></disp-quote><p>We demonstrate that neuronal spike trains carry robust anatomical information. We developed an ML architecture for this and that architecture is publicly available.</p><disp-quote content-type="editor-comment"><p>They try to split the middle and I am left somewhat perplexed about what exact scientific problem they or other researchers are solving.</p></disp-quote><p>We humbly suggest that the question of a neurons “language” is highly important and central to an understanding of how brains work. From a computational perspective, there is no reason for a vast diversity of cell types, nor a differentiation of the rules that dictate neuronal activity in one region versus another. A Turing Complete system can be trivially constructed from a small number of simple components, such as an excitatory and inhibitory cell type. This is the basis of many machine learning tools.</p><p>Please do not confuse stimulus specificity with the concept of a neuron’s language. Neurons in VISp might fire more in response to light, while those in auditory cortex respond to sound. This does not mean that these neurons are different - only that their inputs are. Given the lack of a literature describing our main effect—that single neuron spiking carries information about anatomical location—it is difficult to conclude that our results are either commonplace or to be expected.</p><disp-quote content-type="editor-comment"><p>I am also unsure why the authors think some of these results are particularly important.</p></disp-quote><p>See above.</p><disp-quote content-type="editor-comment"><p>For instance, has anyone ever argued that brain areas do not have different spike patterns?</p></disp-quote><p>Yes. In effect, by two avenues. The first is a lack of any argument otherwise (please do not conflate spike patterns with stimulus tuning), and the second is the preponderance of, e.g., rate codes across many functionally distinct regions and circuits.</p><disp-quote content-type="editor-comment"><p>Is that not the premise for all systems neuroscience?</p></disp-quote><p>No. The premise for all systems neuroscience (from our perspective) is that the brain is (a) a collection of interacting neurons and (b) the collective system of neurons gives rise to behavior, cognition, sensation, and perception. As stated above, these axiomatic first principles fundamentally do not require that neurons, as individual entities, obey different rules in different parts of the brain.</p><disp-quote content-type="editor-comment"><p>I could see how one could argue no one has said ISIs matter but the premise that the areas are different is a fundamental part of neuroscience.</p></disp-quote><p>Based on logic and the literature, we fundamentally disagree. Consider: while systems neuroscience operates on the principle that brain regions have specialized functions, there is no a priori reason to assume that these functions must be reflected in different underlying computational rules. The simplest explanation is that a single language of spiking exists across regions, with functional differences arising from processing distinct inputs rather than fundamentally different spiking rules. For example, an identical spike train in the amygdala and Layer 5 of M1 would have profoundly different functional impacts, yet the spike timing itself could be identical (even as stimulus response). Until now, evidence for region-specific spiking patterns has been lacking, and our work attempts to begin addressing this gap. There is extensive further work to be conducted in this space, and it is certain that models will improve, rules will be clarified, and mechanisms will be identified.</p><disp-quote content-type="editor-comment"><p>Detailed major comments</p><p>(1) Exploratory trends in spiking by region and structure across the population:</p><p>The argument in this section is that unsupervised analyses might reveal subtle trends in the organization of spiking patterns by area. The authors show 4 plots from t-SNE and claim to see subtle organization. I have concerns. For Figure 1C, it is nearly impossible to see if a significant structure exists that differentiates regions and structures. So this leads certain readers to conclude that the authors are looking at the artifactual structure (see Chari et al. 2024) - likely to contribute to large Twitter battles. Contributing to this issue is that the hyperparameter for tSNE was incorrectly chosen. I do think that a different perplexity should be used for the visualization in order to better show the underlying structure; the current visualization just looks like a single &quot;blob&quot;. The UMAP visualizations in the supplement make this point more clearly. I also think the authors should include a better plot with appropriate perplexity or not include this at all. The color map of subtle shades of green and yellow is hard to see as well in both Figure S1 and Figure 1.</p></disp-quote><p>In response to the feedback, we replaced t-SNE/UMAP with LDA, while keeping PCA for dimensionality reduction.</p><p>As stated in the original methods, t-SNE/UMAP hyperparameters were chosen based on the combination that led to the greatest classifiable separability of the regions/structures in the space (across a broad range of possible combinations). It just so happens that the maximally separable structure from a regions/structures perspective is the “blob”. This suggests that perhaps the predominant structure the t-SNE finds in the data is not driven by anatomy. If we selected hyperparameters in some other way that was not based specifically on regions/structures (e.g. simple visual inspection of the plots) the conformation would of course be different and not blob-like. However, we removed the t-SNE and UMAP to avoid further confusion.</p><p>The “muddy appearance” is not an issue with the color map. As seen in Figure 1B, the chosen colors are visibly distinct. Figure 1C (previous version) appeared muddy yellow/green because of points that overlap with transparency, resulting in a mix of clearly defined classes (e.g., a yellow point on top of a blue point creating green). This overlap is a meaningful representation of the separability observed in this analysis. We also tried using 2D KDE for visualization, but it did not improve the impression of visual separability.</p><p>We are removing p-values from the figures because they lead to the impression that we over-interpret these results quantitatively. However, we calculated p-values based on label permutation similar to the way R2 suggests (see previous methods). The conflation with the Wasserstein distances is an understandable misunderstanding. These are unrelated to p-values and used for the heatmaps in S1 only (see previous methods).</p><p>Instead of p-values, we now use the adjusted rand index, which measures how accurately neurons within the same region are clustered together (see Line 670 - 671, Figure 1C, and Figure S1) (Hubert &amp; Arabie 1985). This quantifies the extent to which the distribution of points in dimensionally-reduced space is shaped by region/structure.</p><p>Hubert, L., &amp; Arabie, P. (1985). Comparing partitions. Journal of Classification, 2(1), 193–218. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/BF01908075">https://doi.org/10.1007/BF01908075</ext-link></p><disp-quote content-type="editor-comment"><p>(2) Logistic classifiers:</p><p>The results in this section are somewhat underwhelming. Accuracy is around 40% and yes above chance but I would be very surprised if someone is worried about separating visual structures from the thalamus. Such coarse brain targeting is not difficult. If the authors want to include this data, I recommend they show it as a control in the ISI distribution section. The entire argument here is that perhaps one should not use derived metrics and a nonlinear classifier on more data is better, which is essentially the thrust of the next section.</p></disp-quote><p>As outlined above, our work systematically increases in model complexity. The logistic result is an intermediate model, and it returns intermediate results. This is an important stepping stone between the lack of a result based on unsupervised linear dimensionality reduction and the performance of supervised nonlinear models.</p><p>From a purely utilitarian perspective, the argument could be framed as “one should not use derived metrics, and a nonlinear classifier on more data is better.” However, please see all of our notes above.</p><disp-quote content-type="editor-comment"><p>(3) MLP classifiers:</p><p>Even in this section, I was left somewhat underwhelmed that a nonlinear classifier with large amounts of data outperforms a linear classifier with small amounts of data. I found the analysis of the ISIs and which timescales are driving the classifier interesting but I think the classifier with smoothing is more interesting. So with a modest chance level decodability of different brain areas in the visual system, I found it somewhat grandiose to claim a &quot;conserved&quot; code for anatomy in the brain. If there is conservation, it seems to be at the level of the coarse brain organization, which in my opinion is not particularly compelling.</p></disp-quote><p>The sample size used for both the linear and nonlinear classifiers is the same; however, the nonlinear classifier leverages the detailed spiking time information from ISIs. Our goal here was to systematically evaluate how classical spike metrics compare to more detailed temporal features in their ability to decode brain areas. We chose a linear classifier for spike metrics because, with fewer features, nonlinear methods like neural networks often offer very modest advantages over linear methods, less interpretability, and are prone to overfitting.</p><p>Respectfully, we stand by our word choice. The term “conserved” is appropriate given that our results hold appreciably, i.e., statistically above chance, across animals.</p><disp-quote content-type="editor-comment"><p>(4) Generalization section:</p><p>The authors suggest that a classifier learned from one set of data could be used for new data. I was unsure if this was a scientific point or the fact that they could use it as a tool.</p></disp-quote><p>It can be both. We are more driven by the scientific implications of a rejection of the null.</p><disp-quote content-type="editor-comment"><p>Is the scientific argument that ISIs are similar across areas even in different tasks?</p></disp-quote><p>It appears so - despite heterogeneity in the tuning of single neurons, their presynaptic inputs, and stimuli, there is identifiable information about anatomical location in the spike train.</p><disp-quote content-type="editor-comment"><p>Why would one not learn a classifier from every piece of available data: like LFP bands, ISI distributions, and average firing rates, and use that to predict the brain area as a comparison?</p></disp-quote><p>Because this would obfuscate the ability to conclude that spike trains embed information about anatomy.</p><p>Considering all features simultaneously and adding additional data modalities—such as LFP bands and spike waveforms—has potential to improve classification accuracy at the cost of understanding the contribution of each feature. The spike train as a time series is the most fundamental component of neuronal communication. As a result, this is the only feature of neuronal activity of concern for the present investigation.</p><disp-quote content-type="editor-comment"><p>Or is the argument that the ISIs are a conserved code for anatomy? Unfortunately, even in this section, the data are underwhelming.</p></disp-quote><p>We appreciate the reviewer’s comments, but arrive at a very different conclusion. We were quite surprised to find any generalizability whatsoever.</p><disp-quote content-type="editor-comment"><p>Moreover, for use as a tool, I think the authors need to seriously consider a control that is either waveforms from different brain areas or the local field potentials. Without that, I am struggling to understand how good this tool is. The authors said &quot;because information transmission in the brain arises primarily from the timing of spiking and not waveforms (etc)., our studies involve only the timestamps of individual spikes from well-isolated units &quot;. However, we are not talking about information transmission and actually trying to identify and assess brain areas from electrophysiological data.</p></disp-quote><p>While we are not blind to the “tool” potential that is suggested by our work, this is not the primary motivation or content in any section of the paper. As stated clearly in the abstract, our motivation is to ask “whether individual neurons [...] embed information about their own anatomical location within their spike patterns”. We go on to say “This discovery provides new insights into the relationship between brain structure and function, with broad implications for neurodevelopment, multimodal integration, and the interpretation of large-scale neuronal recordings. Immediately, it has potential as a strategy for in-vivo electrode localization.” Crucially, the last point we make is a nod to application. Indeed, our results suggest that in-vivo electrode localization protocols may benefit from the incorporation of such a model.</p><p>In light of the reviewer’s concerns, we have further dampened the weight of statements about our model as a consumer-ready tool.</p><p>Example 1: The final sentence of the abstract now reads: “Computational approximations of anatomy have potential to support in-vivo electrode localization.”</p><p>Example 2: The results sections now contains the following text: “While significantly above chance, the structure-level model still lacks the accuracy for immediate practical application. However, it is highly likely that the incorporation of datasets with diverse multi-modal features and alternative regions from other research groups will increase the accuracy of such a model. In addition, a computational approach can be combined with other methods of anatomical reconstruction.” (Line 355 - 359).</p><p>Example 3: We replaced the phrase &quot;because information transmission in the brain arises primarily from the timing of spiking and not waveforms (etc) &quot; with the phrase “because information is primarily encoded by the firing rate or the timing of spiking and not waveforms (etc)” (Line 116 - 118).</p><disp-quote content-type="editor-comment"><p>(5) Discussion section:</p><p>In the discussion, beginning with &quot;It is reasonable to consider . . .&quot; all the way to the penultimate paragraph, I found the argumentation here extremely hard to follow. Furthermore, the parts of the discussion here I did feel I understood, I heavily disagreed with. They state that &quot;recordings are random in their local sampling&quot; which is almost certainly untrue when it comes to electrophysiology which tends to oversample task-modulated excitatory neurons (<ext-link ext-link-type="uri" xlink:href="https://elifesciences.org/articles/69068">https://elifesciences.org/articles/69068</ext-link>). I also disagree that &quot;each neuron's connectivity is unique, and vertebrate brains lack 'identified neurons' characteristic of simple organisms. While brains are only eutelic and &quot;nameable&quot; in only the simplest organisms (<italic>C. elegans</italic>), cell types are exceedingly stereotyped in their connectivity even in mammals and such connectivity defines their computational properties. Thus I don't find the premise the authors state in the next sentence to be undermined (&quot;it seems unlikely that a single neuron's happenstance imprinting of its unique connectivity should generalize across stimuli and animals&quot;). Overall, I found this subsection to rely on false premises and in my opinion it should be removed.</p></disp-quote><p>At the suggestion of R2, we removed the paragraph in question. However, we would like to address some points of disagreement:</p><p>We agree that electrophysiology, along with spike-sorting, quality metrics, and filtering of low-firing neurons, leads to oversampling of task-modulated neurons. However, when we stated that recordings are random in their local sampling, we were referring to structural (anatomical) randomness, not functional randomness. In other words, the recorded neurons were not specifically targeted (see below).</p><p>Electrode arrays, such as Neuropixels, record from hundreds of neurons within a small volume relative to the total number of neurons and the volume of a given brain region. For instance, the paper R2 referenced includes a statement supporting this: “... assuming a 50-μm ‘listening radius’ for the probes (radius of half-cylinder around the probe where the neurons’ spike amplitude is sufficiently above noise to trigger detection) …, the average yield of 116 regular-spiking units/probe (prior to QC filtering) would imply a density of 42,000 neurons/mm³, much lower than the known density of ~90,000 neurons/mm³ for excitatory cells in mouse visual cortex….”</p><p>If we take the estimated volume of V1 to be approximately 3 mm³, this region could theoretically be subdivided into multiple cylinders with a 100-μm diameter. While stereotaxic implantation of the probe mitigates some variability, the natural anatomical variability across individual animals introduces spatially random sampling. This was the randomness we were referring to, and thus, we disagree with the assertion that our claim is “almost certainly untrue.”</p><p>Additionally, each cortical pyramidal neuron is understood to have ~ 10,000 presynaptic partners. It is highly unlikely that these connections are entirely pre-specified, perfectly replicated within the same animal, and identical across all members of species. Further, there is enormous diversity in the activity properties of even neighboring cells of the same type. Consider pyramidal neurons in V1. Single neuron firing rates are log normally distributed, there are many of combinations of tuning properties (i.e., direction, orientation) that must occupy each point in retinotopic space, and there is powerful experience dependent change in the connectivity of these cells. We suggest that it is inconceivable that any two neurons, even within a small region of V1, have identical connectivity.</p><disp-quote content-type="editor-comment"><p>Minor Comments:</p><p>(1) Although the description of confusion matrices is good from a didactic perspective, some of this could be moved to methods to simplify the paper.</p></disp-quote><p>We thank the reviewer for the suggestion. However, given the broad readership of eLife, we gently suggest that confusion matrices are not a trivial and universally appreciated plotting format. For the purpose of accessibility, a brief and didactic 2-sentence description will make the paper far more comprehensible to many readers at little cost to experts.</p><disp-quote content-type="editor-comment"><p>(2) Figure 3A: It is concluded in their subsequent figure that the longer the measured amount of time, the better the decoding performance. Thus it makes sense why the average PSTHs do not show significant decoding of areas or structures</p></disp-quote><p>That is a good observation. However, all features were calculated from the same duration of data, except in Figure 3B, where we tested the effect of duration. The averaged PSTH was calculated from the same length of data as the ISI distribution and binned to have the same number of feature lengths as the ISI distribution (refer to Methods section). Therefore, we interpreted this as an indication of information degradation through averaging, rather than an effect of data length (Line 234 - 237).</p><disp-quote content-type="editor-comment"><p>(3) Figure 3D: A Gaussian is used to fit the ISI distributions here but ISI distributions do not follow a normal distribution, they follow an inverse gamma distribution.</p></disp-quote><p>We agree with the reviewer and we are familiar with the literature that the ISI distribution is best fitted by a gamma family distribution (as a recent, but not earliest example: Li et al. 2018). However, we did not fit a gaussian (or any distribution) to the data, we just calculated the sample mean and variance. Reporting sample mean and variance (or standard deviation) is not something that is only done for Gaussian distributions. They are broadly used metrics that simply have additional intrinsic meaning for Gaussian distributions. We used the schematic illustration in Fig 3D because mean and variance are much more familiar in Gaussian distribution context, but ultimately that does not affect our analyses in Fig 3 E-F. Alternatively, the alpha and beta intrinsic parameters of a gamma distribution could have been used, but they are known by a much smaller portion of neuroscientists.</p><p>Li, M., Xie, K., Kuang, H., Liu, J., Wang, D., Fox, G. E., ... &amp; Tsien, J. Z. (2018). Spike-timing pattern operates as gamma-distribution across cell types, regions and animal species and is essential for naturally-occurring cognitive states. Biorxiv, 145813(10.1101), 145813.</p><disp-quote content-type="editor-comment"><p>(4) Figure 3G: Something is wrong with this figure as each vertical bar is supposed to represent a drifting grating onset but yet, they are all at 5 hz despite the PSTH being purportedly shown at many different frequencies from 1 to 15 hz.</p></disp-quote><p>We appreciate your attention to detail, but we are not representing the onset of individual drifting gratings in this. We just meant to represent the overall start\end of the drifting grating session. We did not intend to signal the temporal frequency of the drifting gratings (or the spatial frequency, orientation, or contrast).</p></body></sub-article></article>