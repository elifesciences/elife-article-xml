<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">66112</article-id><article-id pub-id-type="doi">10.7554/eLife.66112</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Tools and Resources</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Fully autonomous mouse behavioral and optogenetic experiments in home-cage</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-220301"><name><surname>Hao</surname><given-names>Yaoyao</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-220302"><name><surname>Thomas</surname><given-names>Alyse Marian</given-names></name><xref ref-type="aff" rid="aff1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-142528"><name><surname>Li</surname><given-names>Nuo</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6613-5018</contrib-id><email>nuol@bcm.edu</email><xref ref-type="aff" rid="aff1"/><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund8"/><xref ref-type="other" rid="fund9"/><xref ref-type="other" rid="fund10"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution>Department of Neuroscience, Baylor College of Medicine</institution><addr-line><named-content content-type="city">Houston</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Bathellier</surname><given-names>Brice</given-names></name><role>Reviewing Editor</role><aff><institution>CNRS</institution><country>France</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Colgin</surname><given-names>Laura L</given-names></name><role>Senior Editor</role><aff><institution>University of Texas at Austin</institution><country>United States</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>04</day><month>05</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e66112</elocation-id><history><date date-type="received" iso-8601-date="2020-12-29"><day>29</day><month>12</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-05-02"><day>02</day><month>05</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Hao et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Hao et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-66112-v2.pdf"/><abstract><p>Goal-directed behaviors involve distributed brain networks. The small size of the mouse brain makes it amenable to manipulations of neural activity dispersed across brain areas, but existing optogenetic methods serially test a few brain regions at a time, which slows comprehensive mapping of distributed networks. Laborious operant conditioning training required for most experimental paradigms exacerbates this bottleneck. We present an autonomous workflow to survey the involvement of brain regions at scale during operant behaviors in mice. Naive mice living in a home-cage system learned voluntary head-fixation (&gt;1 hr/day) and performed difficult decision-making tasks, including contingency reversals, for 2 months without human supervision. We incorporated an optogenetic approach to manipulate activity in deep brain regions through intact skull during home-cage behavior. To demonstrate the utility of this approach, we tested dozens of mice in parallel unsupervised optogenetic experiments, revealing multiple regions in cortex, striatum, and superior colliculus involved in tactile decision-making.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>automated training</kwd><kwd>optogenetics</kwd><kwd>decision-making</kwd><kwd>cortex</kwd><kwd>striatum</kwd><kwd>superior colliculus</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100001234</institution-id><institution>Robert and Janice McNair Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Li</surname><given-names>Nuo</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100001391</institution-id><institution>Whitehall Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Li</surname><given-names>Nuo</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000879</institution-id><institution>Alfred P. Sloan Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Li</surname><given-names>Nuo</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100014185</institution-id><institution>Searle Scholars Program</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Li</surname><given-names>Nuo</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000875</institution-id><institution>Pew Charitable Trusts</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Li</surname><given-names>Nuo</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>NS112312</award-id><principal-award-recipient><name><surname>Li</surname><given-names>Nuo</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>NS104781</award-id><principal-award-recipient><name><surname>Li</surname><given-names>Nuo</given-names></name></principal-award-recipient></award-group><award-group id="fund8"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>NS113110</award-id><principal-award-recipient><name><surname>Li</surname><given-names>Nuo</given-names></name></principal-award-recipient></award-group><award-group id="fund9"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>543005</award-id><principal-award-recipient><name><surname>Li</surname><given-names>Nuo</given-names></name></principal-award-recipient></award-group><award-group id="fund10"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000872</institution-id><institution>McKnight Endowment Fund for Neuroscience</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Li</surname><given-names>Nuo</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A fully automated workflow for high-throughput mouse behavioral and optogenetic experiments in homecage reveals involvement of brain regions in tactile decision-making.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Goal-directed behavior is orchestrated by activity distributed across multiple brain regions. A starting point for understanding how distributed activity mediates a single behavior is to identify activity that causally contributes to the behavior. For example during perceptual decisions, activities that correlate with sensation, choice, and movement are distributed across distinct brain areas (<xref ref-type="bibr" rid="bib28">Gold and Shadlen, 2001</xref>; <xref ref-type="bibr" rid="bib32">Hernández et al., 2010</xref>; <xref ref-type="bibr" rid="bib30">Guo et al., 2014a</xref>; <xref ref-type="bibr" rid="bib68">Siegel et al., 2015</xref>; <xref ref-type="bibr" rid="bib70">Sippy et al., 2015</xref>; <xref ref-type="bibr" rid="bib7">Brody and Hanks, 2016</xref>; <xref ref-type="bibr" rid="bib76">Svoboda and Li, 2018</xref>; <xref ref-type="bibr" rid="bib2">Allen et al., 2019</xref>; <xref ref-type="bibr" rid="bib15">Crochet et al., 2019</xref>; <xref ref-type="bibr" rid="bib52">Mayrhofer et al., 2019</xref>; <xref ref-type="bibr" rid="bib59">Pinto et al., 2019</xref>; <xref ref-type="bibr" rid="bib72">Steinmetz et al., 2019</xref>; <xref ref-type="bibr" rid="bib46">Li and Mrsic-Flogel, 2020</xref>). Delineating which activity casually contributes to decision-making requires spatially and temporally precise manipulation of specific activity that is widely dispersed across the brain.</p><p>The mouse is particularly suitable for comprehensive analysis of neural activity due to the small size of the brain. Modern optogenetic methods can manipulate activity in specific brain regions with excellent temporal resolution (<xref ref-type="bibr" rid="bib16">Deisseroth, 2015</xref>; <xref ref-type="bibr" rid="bib81">Wiegert et al., 2017</xref>; <xref ref-type="bibr" rid="bib45">Li et al., 2019</xref>), but optogenetic experiments currently can only probe a limited number of brain regions in single studies. In standard optogenetic experiments, mice are trained in operant behavior and optogenetic testing is carried out in daily sessions to manipulate individual brain regions. This process is serial and slow, prohibiting comprehensive surveys of many brain regions during complex behaviors.</p><p>One bottleneck results from manual operant conditioning training, which is required in most experimental paradigms. For example, training mice in decision-making tasks requires significant human involvement in evaluating mice performance and modifying task parameters to gradually shape behavior toward high performance (<xref ref-type="bibr" rid="bib31">Guo et al., 2014b</xref>; <xref ref-type="bibr" rid="bib8">Burgess et al., 2017</xref>; <xref ref-type="bibr" rid="bib1">Aguillon-Rodriguez et al., 2020</xref>). This process is laborious and requires human expertise. Such expertise is difficult to transfer across experimenters and across labs. The low throughput also rises significant barriers for explorations of more complex decision-making tasks, due to the significant time and effort required to explore many task parameter variations. The other bottleneck is due to the serial nature of optogenetic testing. In particular, existing optogenetic methods probe deep brain regions using optical fibers, which target one brain region at a time, are labor-intensive to implant, and require manual tethering of light source to the fiber implant. An experimental framework to swiftly survey the behavioral involvement of many brain regions at scale would significantly speed up mapping of brain networks contributing to decision-making or other goal-directed behaviors.</p><p>Automated experiment can potentially overcome these bottlenecks. Automated systems can train rodents in behavioral tasks by changing task parameters based on performance free of human supervision, thus enabling parallel and high-throughput experiments (<xref ref-type="bibr" rid="bib37">Kampff et al., 2010</xref>; <xref ref-type="bibr" rid="bib21">Erlich et al., 2011</xref>; <xref ref-type="bibr" rid="bib60">Poddar et al., 2013</xref>; <xref ref-type="bibr" rid="bib67">Scott et al., 2013</xref>; <xref ref-type="bibr" rid="bib53">Murphy et al., 2016</xref>; <xref ref-type="bibr" rid="bib3">Aoki et al., 2017</xref>; <xref ref-type="bibr" rid="bib6">Bollu et al., 2019</xref>; <xref ref-type="bibr" rid="bib22">Erskine et al., 2019</xref>; <xref ref-type="bibr" rid="bib61">Qiao et al., 2019</xref>; <xref ref-type="bibr" rid="bib1">Aguillon-Rodriguez et al., 2020</xref>; <xref ref-type="bibr" rid="bib4">Bernhard et al., 2020</xref>; <xref ref-type="bibr" rid="bib54">Murphy et al., 2020</xref>). Moreover, automated training provides standardization that frees the training process from idiosyncratic human interventions and documents the entire training process. Automated training has been extended to train rodents in home-cages (<xref ref-type="bibr" rid="bib60">Poddar et al., 2013</xref>; <xref ref-type="bibr" rid="bib3">Aoki et al., 2017</xref>; <xref ref-type="bibr" rid="bib69">Silasi et al., 2018</xref>; <xref ref-type="bibr" rid="bib6">Bollu et al., 2019</xref>; <xref ref-type="bibr" rid="bib22">Erskine et al., 2019</xref>; <xref ref-type="bibr" rid="bib61">Qiao et al., 2019</xref>; <xref ref-type="bibr" rid="bib4">Bernhard et al., 2020</xref>; <xref ref-type="bibr" rid="bib54">Murphy et al., 2020</xref>), opening the possibility of prolonged behavioral training that permits more difficult decision-making tasks. In some cases, automated systems can also be incorporated into a large environment to probe effects of social and environmental factors on cognitive behaviors (<xref ref-type="bibr" rid="bib25">Freund et al., 2013</xref>; <xref ref-type="bibr" rid="bib11">Castelhano-Carlos et al., 2014</xref>; <xref ref-type="bibr" rid="bib78">Torquet et al., 2018</xref>).</p><p>However, significant aspects of home-cage training still need to be improved and validated to enable high-throughput experiments. First, it remains to be determined whether mice can robustly learn challenging decision-making tasks under home-cage operant conditioning. Existing home-cage trainings are limited to relatively simple behavioral tasks and modest training durations. Second, it remains to be determined whether behaviors resulting from home-cage training resemble human-supervised training and whether they engage the same brain areas. For example, cortical regions contributing to perceptual decisions can vary across tasks and training conditions (<xref ref-type="bibr" rid="bib13">Chowdhury and DeAngelis, 2008</xref>; <xref ref-type="bibr" rid="bib47">Licata et al., 2017</xref>; <xref ref-type="bibr" rid="bib50">Liu and Pack, 2017</xref>; <xref ref-type="bibr" rid="bib27">Gilad et al., 2018</xref>; <xref ref-type="bibr" rid="bib34">Hong et al., 2018</xref>). Finally, home-cage training has not been integrated with unsupervised optogenetic testing. Automation could potentially enable comprehensive optogenetic experiments targeting many brain regions during complex behaviors.</p><p>Here, we introduce a fully autonomous workflow that combines home-cage behavioral training and optogenetic testing. We introduce a low-cost standalone home-cage system that allows robust training in difficult decision-making tasks. Completely naive mice self-engaged in prolonged voluntary head-fixation (&gt;1 hr/day) and underwent continuous training and testing for 2 months without human supervision. In the context of automated home-cage behavior, we integrated a fiber-free optogenetic method to manipulate cortical and subcortical regions through an intact clear skull. Electrophysiological recordings show that photostimulation could potently modulate neural activity in deep brain structures such as the striatum and midbrain. We collected an extensive benchmark dataset (113 mice, 1.92 million trials) training mice in a tactile decision task with a short-term memory component to show that mice in automated training learned the task using similar behavioral strategies as mice in manual training. Optogenetic loss-of-function experiments show that the learned behavior engaged the same cortical regions. The hardware design files, software, and task training protocols for the home-cage system are made publicly available along with extensive documentations for other researchers to implement similar automated training for other operant behaviors.</p><p>Our automated home-cage system significantly lowers the barrier for training mice in difficult decision-making tasks. To demonstrate this utility, we show that mice could robustly learn contingency reversals in which they flexibly reported tactile decisions using directional licking, a behavior that was previously difficult to attain in manual training. In addition, our workflow is particularly suitable for mapping cortico-basal-ganglia loops involved in goal-directed behaviors. The striatum, its cortical inputs, and downstream output nuclei are topographically organized (<xref ref-type="bibr" rid="bib33">Hintiryan et al., 2016</xref>; <xref ref-type="bibr" rid="bib36">Hunnicutt et al., 2016</xref>; <xref ref-type="bibr" rid="bib35">Hooks et al., 2018</xref>; <xref ref-type="bibr" rid="bib58">Peters et al., 2019</xref>; <xref ref-type="bibr" rid="bib41">Lee et al., 2020</xref>). However, a systematic survey of different striatal domains’ involvement in specific behaviors has not been achieved. We demonstrate the utility of our workflow in high-throughput optogenetic mapping, revealing multiple subregions in the striatum and downstream superior colliculus critical for tactile-guided licking decisions. Our workflow opens the door to rapidly survey distributed brain networks driving goal-directed behaviors.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Workflow overview for autonomous behavior and optogenetic experiments</title><p>Our goal is to develop an automated workflow to swiftly probe the involvement of many brain regions in a single perceptual decision task. To accomplish this, we target specific brain regions for optogenetic manipulation in individual cohorts of mice. Mice undergo standardized behavioral training in perceptual decision tasks. After training, the targeted brain regions are perturbed during specific behavioral epochs to examine their involvement in the behavior (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). Across different cohorts of mice, different brain regions are tested. Two bottlenecks addressed in this workflow are manual behavioral training and manual optogenetic testing (<xref ref-type="fig" rid="fig1">Figure 1B</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Workflow for autonomous behavior and optogenetic experiments and design of home-cage system.</title><p>(<bold>A</bold>) Workflow for autonomous behavioral and optogenetic experiments. In each group of mice, optogenetic opsins are expressed in a specific brain region. Naive mice undergo autonomous behavioral training and optogenetic testing in their home-cage. Multiple groups of mice are tested in parallel to examine multiple brain regions. Data is stored on SD cards for analysis. Histology is performed at the end of the workflow to register the targeted brain regions to an atlas. Green bounding box highlights the portion of the workflow that is unsupervised by experimenters. (<bold>B</bold>) Workflow for automated behavioral training and optogenetic testing. After recovery from surgery, mice are housed in the home-cage system 24/7. Automated computer algorithms train mice to perform voluntary head-fixation, decision-making task, and carry out optogenetic testing. The progression in the workflow is based on behavioral performance. Green bounding box corresponds to the bounding box in (<bold>A</bold>). (<bold>C</bold>) Design of the home-cage system. The main component is a behavioral test chamber which can be accessed through a headport from the home-cage. Inset shows the view of the headport from inside the home-cage. Mice access the headport on a load-sensing platform. See <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref> and Materialsand methods for details. (<bold>D</bold>) Photographs of the home-cage system. Top: side view of the system. The system is standalone with controllers (Arduinos) and actuators packed into a self-contained enclosure. Bottom, the front and back view of a mouse accessing the headport and performing the tactile decision task.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66112-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Overview of the home-cage system.</title><p>(<bold>A</bold>) Diagram of the control system for the home-cage system. The main controller consists of three Arduinos (‘Arduino Master’, ‘Arduino Task’, and ‘Arduino Wave’) that control peripherals through digital input/output (DIO), digital-analog-convertor (DAC), pulse width modulation (PWM) and serial ports. The ‘Master’ controllers from multiple systems can be connected to a PC to display mouse behavioral data in a GUI. See Materials and methods for details. (<bold>B</bold>) Screenshot of the GUI display. Each square shows one home-cage system. The color indicates the number of trials the mouse performed in the last 24 hr (ranging from green, &gt;640 trials, to red, &lt;80 trials). Gray squares are not connected to any system. Each square displays mouse meta data and behavioral training data, including mouse ID, body weight, training start date, days and number of trials performed since the start, number of trials performed in the last 24 hr, performance in the last 100 trials, and training protocol number. The two buttons labeled ‘Msg’ and ‘plot_p/w’ bring up additional windows to display messages from the home-cage system and plot detailed behavioral data from the last 24 hr. Error messages are also displayed in the bottom right box. (<bold>C</bold>) Fifteen standalone home-cage systems placed on a standard rack.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66112-fig1-figsupp1-v2.tif"/></fig></fig-group><p>To overcome these bottlenecks, we designed a robust home-cage system for mice to voluntarily engage in head-fixation that was amenable to operant conditioning and optogenetic testing (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). A behavioral test chamber was built onto the mouse home-cage and ran autonomously without human supervision. Mice accessed the test chamber through a headport and engaged in behavioral tasks (<xref ref-type="video" rid="video1">Video 1</xref>). Automated computer algorithms trained naive mice to perform head-fixation and decision-making tasks. In the context of unsupervised behavioral testing, we integrated an optogenetic method to manipulate activity in specific brain regions. The entire process ran autonomously 24/7 for 2 months or longer (<xref ref-type="fig" rid="fig1">Figure 1A–B</xref>).</p><media id="video1" mime-subtype="mp4" mimetype="video" xlink:href="elife-66112-video1.mp4"><label>Video 1.</label><caption><title>A mouse performing voluntary head-fixation, tactile decision task, and self-release in home-cage.</title><p>A mouse voluntarily pokes into the headport and gets head-fixed. Once head-fixed, a trial is initiated. A pole drops into the whisker field at specific locations for 1.3 s then retracts (‘sample’). After another 1.3 s (‘delay’), an auditory go cue is played, and the mouse licks the left or right lickspouts to report choice (‘response’). The mouse is released after 60 s of head-fixation (‘time-up release’). The mouse also self-releases by pressing against the floor (‘self-release’).</p></caption></media><p>To build the behavioral test chamber, we designed a 3D-printed ‘L’-shaped board which could be attached to standard mouse cages (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). An opening (20 mm wide) in the center formed a headport. Mice with headbar implants enter the headport in head-restrained configuration from the home-cage (<xref ref-type="fig" rid="fig1">Figure 1D</xref>). A motorized lickport in front of the headport dispensed water reward. The lickport was actuated by two linear motors, moving the lickport toward or away from the mouse. The stimulus for the decision-making task was a mechanical pole on the right side of the headport. The pole was moved vertically by a piston to stimulate the whiskers at different locations to instruct a tactile decision (see <italic>tactile decision task</italic> below). The location of the pole relative to the mouse was controlled by another motor. Inside the home-cage, mice accessed the headport on an elevated platform (<xref ref-type="fig" rid="fig1">Figure 1C</xref>, inset). The platform was embedded with a micro load cell. The weight of the mouse could be read out from the load sensor, which eliminated daily human interventions to measure mouse body weight.</p><p>To make the system run standalone, microcontrollers (Arduino) were used to control the whole system (Materials and methods, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>). A master microcontroller controlled the progression of head-fixation training and task training. The task difficulty was gradually increased to facilitate learning. A second microcontroller was triggered by the master controller and it ran finite-state machines that controlled individual behavioral trials with high temporal precision (0.1 ms). The master controller was equipped with a SD card that stored mouse-specific metadata, task parameters, and behavioral data. Each mouse had its unique SD card and could use it to run on any home-cage system. Optionally, the system could be connected to a PC to display behavioral performance and monitor training progression in real-time (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B</xref>). The entire system was fit into a self-contained enclosure (<xref ref-type="fig" rid="fig1">Figure 1D</xref>, 56 × 25 × 23 cm). Multiple systems could be packed onto a standard rack in a small space to enable parallel testing (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1C</xref>).</p><p>To screen for brain regions involved in behavior, we adapted a fiber-free optogenetic strategy that non-invasively manipulated activity in specific brain regions though an intact skull. For each mouse, we virally expressed red-shifted opsins in a targeted brain region. Mice were prepared with a clear skull implant that provided optical access to the brain (<xref ref-type="bibr" rid="bib30">Guo et al., 2014a</xref>). During head-fixed behavior, 630 nm light emitted from above the headport to broadly illuminate the targeted brain region and photostimulate the locally expressed opsins (<xref ref-type="video" rid="video2">Video 2</xref>). Red light can penetrate deep in neural tissue (<xref ref-type="bibr" rid="bib79">Tromberg et al., 2000</xref>; <xref ref-type="bibr" rid="bib49">Liu et al., 2015</xref>; <xref ref-type="bibr" rid="bib81">Wiegert et al., 2017</xref>; <xref ref-type="bibr" rid="bib45">Li et al., 2019</xref>) and thus can non-invasively manipulate deep brain regions (<xref ref-type="bibr" rid="bib48">Lin et al., 2013</xref>; <xref ref-type="bibr" rid="bib14">Chuong et al., 2014</xref>; <xref ref-type="bibr" rid="bib39">Klapoetke et al., 2014</xref>).</p><media id="video2" mime-subtype="mp4" mimetype="video" xlink:href="elife-66112-video2.mp4"><label>Video 2.</label><caption><title>Optogenetic photostimulation during task performance in home-cage.</title><p>In a subset of trials, 630 nm light is turned on during either the sample or delay epoch. Photostimulation is through a clear skull implant to activate red-shifted opsins expressed in specific brain regions. During unsupervised optogenetic testing, the light source is positioned over the targeted brain region. In addition, a 630 nm masking flashing is given in every trial to prevent the mouse from distinguishing the trials with photostimulation. The masking flash is turned off in this example video for demonstration purposes.</p></caption></media><p>The integrated workflow thus overcame the bottlenecks of manual behavioral training and manual optogenetic testing (<xref ref-type="fig" rid="fig1">Figure 1A–B</xref>). Completely naive mice learned to perform tactile decision-making and underwent optogenetic testing in their home-cage without human supervision. A large number of brain regions can be tested in parallel across different cohorts of mice.</p></sec><sec id="s2-2"><title>Voluntary head-fixation in home-cage</title><p>We adapted a head-fixation mechanism that was previously designed for head immobilizations in rats (<xref ref-type="bibr" rid="bib67">Scott et al., 2013</xref>). Two pneumatic pistons pressed against a custom titanium headbar to immobilize the head. The headbar (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) was processed with two kinematic depressions that were fit to the cone shaped tips of the pneumatic pistons, which mechanically brought the headbar to the same position upon head-fixation. This head-fixation mechanism was integrated into the headport that accessed the behavioral test chamber (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). <xref ref-type="fig" rid="fig2">Figure 2B</xref> shows the sequence of a head-fixation and release cycle. Head-fixation was triggered by mouse entry into the headport. The two wings of the headport have widened tracks to guide headbar entry. The tracks funneled to a narrow spacing with shapes complementary to the headbar. Mice thus always entered the headport to reach the same head-restrained configuration. Upon entry, the headbar triggered two mechanical switches on both sides of the headport which activated the pneumatic pistons. At the end of the head-fixation, the pneumatic pistons were retracted, and the mouse was free to pull out from the headport. The release either came after a predefined duration for each head-fixation (up to 1 min, ‘time-up release’) or could be triggered by the mouse (‘self-release’) (<xref ref-type="video" rid="video1">Video 1</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Voluntary head-fixation in home-cage.</title><p>(<bold>A</bold>) Left, schematic drawing of the custom headbar. Right, photograph of a headbar implant. (<bold>B</bold>) Schematic drawings of a head-fixation and release sequence. Headbar enters a widened track on both sides of the headport that guides the headbar into a narrow spacing at the end. Two mechanical switches located on either side of the headport trigger pneumatic pistons to clamp the headbar. Head-fixations are released by retracting the pneumatic pistons. (<bold>C</bold>) Left, photograph of the load-sensing platform with top plate removed and load cell exposed. Right, example readings from the load cell (20 samples/s) in a 24-hr period. Shaded areas, dark cycles. Absence of samples indicates the mouse is off the platform. The histogram shows all readings from the 24-hr period. The peak can be used to estimate the mouse’s body weight. (<bold>D</bold>) Example readings from the load cell during four consecutive head-fixations (green shades). Head-fixations typically reduce weight on the platform. Readings crossing a threshold (blue dashed line) result in self-release (blue arrows). Otherwise, the mouse is released after a predefined fixation duration (time-up release, green arrows). Fixation duration is 30 s in this example. (<bold>E</bold>) Flow chart of the head-fixation training protocol. See Materials and methods for details. (<bold>F</bold>) Data from an example mouse undergoing head-fixation training. Top, data from the first 4 days. The plots show lickport position (top, large value indicates further away from the home-cage, see inset), switch trigger events (middle), and head-fixation events (bottom). For head-fixation events, each tick indicates one fixation, with the height indicating fixation duration. The color indicates time-up release (green) and self-release (blue). Shaded areas, dark cycles. Time spent in learning headport entry and learning head-fixation are colored as in (<bold>E</bold>). Bottom: head-fixation data from the same mouse over 29 days. (<bold>G</bold>) Head-fixation duration over 40 days. Gray lines, individual mice; black line, mean. Bar plot shows average fixation duration throughout the entire head-fixation training. Error bar, standard deviation. Circles, individual mice. (<bold>H</bold>) Same as (<bold>G</bold>) but for mice without the self-release mechanism. (<bold>I</bold>) Displacement of the headbar implant across different head-fixations along medial-lateral, rostral-caudal, and dorsal-ventral directions. (<bold>J</bold>) Fraction of head-fixations in which mice trigger self-release. Gray line, individual mice; black line, mean. Bar plot shows average fraction throughout the entire head-fixation training. Error bar, standard deviation. Circles, individual mice. (<bold>K</bold>) Frequency of head-fixation across dark and light cycles. Bars show average across all mice. Error bars, standard deviations. (<bold>L</bold>) Time interval between head-fixations. Data from all mice are pooled.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66112-fig2-v2.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Displacement of headbar implant across multiple head-fixations.</title><p>(<bold>A</bold>) Left, a region of interest (ROI) on the clear skull implant is indicated by the red bounding box (30 × 30 pixels). Middle, example frames within the ROI from 16 different head-fixations. Red cross indicates the center of mass based on pixel intensity. Right, histogram of displacement in the medial-lateral (<bold>x</bold>) and rostral-caudal (<bold>y</bold>) directions, calculated by sub-pixel correlations of ROIs across all possible pairs of frames from different head-fixations (Materials and methods). (<bold>B–D</bold>) Same as (<bold>A</bold>) for three other ROIs selected around the clear skull implant. (<bold>E–F</bold>) Same as (<bold>A</bold>) but for 2 ROIs around a marker attached to the skull to measure displacements in the dorsal-ventral direction (<bold>z</bold>). (<bold>G</bold>) Same as (<bold>A</bold>) but for a ROI on the wall above the headport. As expected, the ROI shows little displacement compared to (<bold>A</bold>)-(<bold>F</bold>). (<bold>H</bold>) Same as (<bold>A</bold>) but for a ROI on the mouse whiskers. As expected, the ROI shows large displacement compared to (<bold>A</bold>)-(<bold>F</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66112-fig2-figsupp1-v2.tif"/></fig></fig-group><p>Self-release was detected by a load-sensing platform (<xref ref-type="fig" rid="fig2">Figures 2C</xref> and <xref ref-type="fig" rid="fig1">1C</xref> insert). Continuous readings from a micro load cell reported weight on the platform and could be used to measure the mouse’s daily body weight (<xref ref-type="fig" rid="fig2">Figure 2C</xref>) (adapted from <xref ref-type="bibr" rid="bib55">Noorshams et al., 2017</xref>). During head-fixation, the weight on the platform decreased as a part of the weight was taken off by the headbar clamp (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). The fluctuations in weight readings reflected mouse body movements. During struggles that typically indicated the mouse’s efforts to get free from head-fixation, the weight readings produced either large negative or positive values that were far outside the normal range. A threshold was set to detect these struggle events and trigger self-release (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). This threshold was adaptive: it gradually increased if struggle events were frequent or decreased if infrequent (Materials and methods).</p><p>We developed an operant conditioning algorithm to acclimate naive mice to voluntarily perform head-fixations in their home-cage (<xref ref-type="fig" rid="fig2">Figure 2E</xref>). Initially, the lickport was positioned close to the headport with the lickspouts inside the home-cage. Mice easily accessed the lickport and obtained water rewards upon licking. The rewarded lickspout alternated between the left and right lickspouts (three times each) to encourage licking on both. Gradually, the lickport retracted away from the home-cage (3 mm after every 20 rewarded licks) and mice were lured into the headport (<xref ref-type="fig" rid="fig2">Figure 2F</xref>). The lickport retraction stopped when mice entered deep into the headport to reliably trigger the head-fixation switches (Materials and methods). If no licks were detected for 12 hr, the program would re-extend the lickport closer to the home-cage to lure mice in again (<xref ref-type="fig" rid="fig2">Figure 2F</xref> top). During this phase of the training, the pneumatic pistons for head-fixation were not activated by the switches (<xref ref-type="fig" rid="fig2">Figure 2E–F</xref>, ‘learn headport entry’). This was important to let mice first acclimate to the headport entry.</p><p>Once lickport retraction was completed, the pneumatic pistons were turned on (<xref ref-type="fig" rid="fig2">Figure 2E–F</xref>, ‘learn head-fixation’). Head-fixation training started with soft clamp (low pistons pressure, 1.78 bar) and short duration (time-up release, 3 s). During head-fixation, mice could lick the lickspouts to obtain water reward. Gradually, the fixation duration was increased (2 s after every 20 time-up releases). After the fixation duration reached 10 s, the pressure of the clamp also increased (hard clamp, 2.78 bar). Head-fixation training concluded after the fixation duration reached 30 s (<xref ref-type="fig" rid="fig2">Figure 2E</xref>). The fixation duration was further increased to 1 min at the late stage of task learning (<xref ref-type="fig" rid="fig2">Figure 2F</xref>, see task training below).</p><p>Under this protocol, mice quickly acclimated to the head-fixation (<xref ref-type="fig" rid="fig2">Figure 2G</xref>). Most mice (37/39) learned to self-engage in voluntary head-fixation and reached 30 s fixation duration in 7 ± 4.8 days (mean ± SD across mice). The total fixation duration per day increased monotonically over the first 10 days and plateaued at 69 ± 32.4 min per day (<xref ref-type="fig" rid="fig2">Figure 2G</xref>, 130 ± 56 fixations/day, mean ± SD). The self-release mechanism was critical for learning voluntary head-fixation. Without the self-release mechanism, the headport became aversive to mice after one unsuccess attempt to get free from head-fixation. Consequently, mice failed to learn voluntary head-fixation (<xref ref-type="fig" rid="fig2">Figure 2H</xref>). Highly trained mice continued to utilize self-release on 20.7 ± 14% of the head-fixations (<xref ref-type="fig" rid="fig2">Figure 2J</xref>). Most (67%) head-fixations occurred during the dark cycles (<xref ref-type="fig" rid="fig2">Figure 2F and K</xref>). Multiple head-fixations typically occurred in bouts, with majority of head-fixations occurring within a second apart (<xref ref-type="fig" rid="fig2">Figure 2L</xref>). The headbar position across multiple head-fixations was highly reliable (<xref ref-type="fig" rid="fig2">Figure 2I</xref> and <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>, |displacements| in medial-lateral, rostral-caudal, and ventral-dorsal dimensions, 6.4 ± 12, 8.8 ± 15 and 12.1 ± 14.7 µm, mean ± SD; Materials and methods).</p><p>Thus, mice can readily learn to perform repeated voluntary head-fixations for water reward. The extended duration of head-fixation makes behavioral task training possible.</p></sec><sec id="s2-3"><title>Autonomous training in a tactile decision task</title><p>We next integrated an algorithm to autonomously train mice in a tactile decision task with a short-term memory component (<xref ref-type="bibr" rid="bib31">Guo et al., 2014b</xref>; <xref ref-type="bibr" rid="bib30">Guo et al., 2014a</xref>; <xref ref-type="fig" rid="fig3">Figure 3A</xref>). During each head-fixation, mice were tested in a succession of trials. Each trial started with a sample epoch (1.3 s), in which mice were presented with a pole at one of two locations (anterior or posterior). The pole was always presented to the right whiskers. Mice were trained to discriminate pole location using their whiskers and report object location using directional licking (anterior location→ lick left, posterior location→ lick right). The sample epoch terminated when the pole moved out of reach, and mice were trained to withhold licking while remembering the choice during a delay epoch (1.3 s). At the end of the delay epoch, an auditory ‘go’ cue (100 ms) signaled the beginning of the response epoch and mice initiated licking to get water reward (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). Incorrect responses led to a timeout. Premature licks before the ‘go’ cue were rare in trained mice and led to a brief timeout (‘early lick’, Materials and methods). Each trial was followed by an inter-trial-interval (2.5 s), after which the next trial began, until the head-fixation is released (<xref ref-type="video" rid="video1">Video 1</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Tactile decision task in home-cage.</title><p>(<bold>A</bold>) Task structure. Mice discriminate the location of a pole (anterior or posterior) during a sample epoch (1.3 s) and report the location using directional licking (left or right) after a delay epoch (1.3 s). An auditory go cue (0.1 s) signals the beginning of the response epoch. (<bold>B</bold>) Example behavioral data in 100 consecutive trials. Dots show individual licks. Blue, lick right; red, lick left. Circles indicate the first lick after the go cue (choice). In trials with early licks before the ‘go’ cue, choice licks occur late due to the timeouts (Materials and methods). (<bold>C</bold>) Flow chart of the task training protocol. See Materials and methods for details. Auto-assist programs (green box) evaluate mice performance continuously and assist mice whenever certain behavioral biases are detected. (<bold>D</bold>) Data from an example mouse undergoing task training in home-cage. Top, behavioral performance. Shaded areas indicate different phases of the training as in (<bold>C</bold>). During the delay epoch training, the red dash lines indicate delay duration increases. Bottom, fraction of trials in which the mouse licked before the go cue. After mice complete the task training protocol, experimenters examine the mice performance and initiate optogenetic testing protocol (indicated by the orange arrow in this example). (<bold>E</bold>) Behavioral performance of all mice in home-cage training (<italic>n</italic> = 32). Black dash line, criterion performance, 70% correct. (<bold>F</bold>) In a subset of mice (n = 4), the right whiskers were trimmed after home-cage training. Behavioral performance dropped to chance level (50%, black dash line) and did not recover. (<bold>G</bold>) Behavioral performance of all mice in manual training (<italic>n</italic> = 64). (<bold>H</bold>) Percentage of mice successfully trained in home-cage vs. manual training. Training is deemed successful if the mouse reached 70% correct criterion performance. (<bold>I</bold>) Number of trials performed per day in home-cage versus manual training. Bar plot shows mean and standard deviation across mice. Circles, individual mice. ***, p&lt;0.001, two-tailed t-test. (<bold>J</bold>) Left, number of days to reach 70% correct criterion performance. Right, number of trials to reach 70% correct criterion performance. *, p&lt;0.05; n.s., p&gt;0.05, two-tailed t-test.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66112-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Behavioral performance of home-cage trained mice after transferring to an electrophysiology setup.</title><p>After reaching high levels of performance in home-cage training, mice were transferred to an electrophysiology setup (day 0, dash line). Performance initially dropped but gradually recovered over 7 days as the mice acclimated to the new setup. The acclimation time is much less than the time needed to manually train naïve mice to perform the task (<xref ref-type="fig" rid="fig3">Figure 3</xref>). Thus, the automated home-cage system can train mice to support neurophysiology experiments. Individual lines show individual mice (n = 6).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66112-fig3-figsupp1-v2.tif"/></fig></fig-group><p>To facilitate learning, the automated algorithm divided task training into three phases (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). The first phase started after mice learned to maintain head-fixation for 30 s (<xref ref-type="fig" rid="fig2">Figure 2E</xref>). In this phase (<xref ref-type="fig" rid="fig3">Figure 3C</xref>, ‘learn directional licking’), lick left or lick right trials were presented consecutively and mice had to obtain three trials correct before the program switched trial type. This forced mice to lick both lickspouts. Once mice reliably switched lick direction across trial types, the program advanced to the second phase, in which the two trial types were presented randomly (<xref ref-type="fig" rid="fig3">Figure 3C</xref>, ‘learn discrimination’). This required mice to discriminate object location to produce correct choice responses. During these early phases of training (‘learn directional licking’ and ‘learn discrimination’), mice were free to lick at any time during the trial, but only the first lick after the 'go' cue were registered as choice (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). When performance reached 75% correct, the final phase of the training enforced a delay epoch in which licking before the ‘go’ cue triggered a brief timeout (<xref ref-type="fig" rid="fig3">Figure 3C</xref>, ‘learn delay’, Materials and methods). The duration of the delay epoch was initially short (0.3 s), but it gradually increased to 1.3 s. Task training concluded when performance was stably above 70% correct. After task training concluded, the head-fixation duration was further increased from 30 s to 1 min before the start of optogenetic testing. This allowed more trials in each head-fixation.</p><p>We found that two factors were critical for successful home-cage training. First, mice must be acclimated to the task stimuli while learning voluntary head-fixation (<xref ref-type="fig" rid="fig2">Figure 2E</xref>), well before task training. During head-fixation training, the tactile stimulus and the auditory ‘go’ cue were presented upon each headport entry, even though the information was not required for successful performance (<xref ref-type="fig" rid="fig2">Figure 2E</xref>, Materials and methods). Second, mice often developed idiosyncratic biases by licking one lickspout more frequently, or sometimes continuously licking one lickspout without switching to the other. To counter these behavioral patterns, several ‘auto-assist’ programs were needed throughout task training (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). The auto-assist programs evaluated mice performance and assisted the mice whenever certain behavioral patterns were detected (Materials and methods). Specifically, if a mouse licked one lickspout more frequently, the program moved the preferred lickspout further away from the mouse. When a mouse made consecutive errors for one trial type, the program presented that trial type more frequently or gave a free water reward on the correct lickspout. These measures countered biases and encouraged mice to switch lick direction across trial types.</p><p>Most mice (32/37, 87%) successfully learned the tactile decision task in automated home-cage training. <xref ref-type="fig" rid="fig3">Figure 3D</xref> shows the performance of an example mouse. Performance gradually improved during training. During introduction of the delay epoch, performance fluctuated as longer delays were progressively added (<xref ref-type="fig" rid="fig3">Figure 3D</xref>, red lines). Performance eventually increased and was stable over long periods of testing. Meanwhile, the number of early licks decreased. The learning speed was variable across individual mice (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). Mice performed 547 ± 205 trials (mean ± SD) per day in home-cage training and reached 70% correct in 19.3 ± 7.2 days (equivalent to 8588 ± 3453 trials). To confirm that mice solved the tactile decision task using their whiskers, we trimmed the whiskers in a subset of mice. Performance dropped to chance level after whisker trimming (<xref ref-type="fig" rid="fig3">Figure 3F</xref>). To examine whether home-cage training was robust to setup transfers, several mice were transferred to an electrophysiology setup after reaching criterion performance. Performance initially dropped, but it quickly recovered over 7 days (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). Thus, automated home-cage training could be used to support head-fixed electrophysiology or imaging experiments.</p><p>We compared the home-cage training to manual training supervised by experimenters. We trained a separate group of mice (n = 70) in daily sessions using conventional methods (<xref ref-type="bibr" rid="bib31">Guo et al., 2014b</xref>). Mice were manually head-fixed and underwent daily training sessions (1–2 hr). The manual training followed a similar protocol as the home-cage training (Materials and methods). Learning speed and success rate were similar to the home-cage training (<xref ref-type="fig" rid="fig3">Figure 3G–H</xref>, 64/70 mice reached criterion performance vs. 32/37 in home-cage training; p=0.42, Chi-square test). Mice performed fewer number of trials per day in manual training (<xref ref-type="fig" rid="fig3">Figure 3I</xref>, 547 ± 205 vs. 377 ± 30 trials, automated vs. manual training, mean ± SD, p&lt;0.001, two-tailed t-test). Consequently, manual training took more days to achieve performance criteria (<xref ref-type="fig" rid="fig3">Figure 3J</xref>, 19.3 ± 7.2 vs. 27.1 ± 16.3 days, p&lt;0.05, two-tailed t-test), as mice took similar number of trials to reach criterion performance (<xref ref-type="fig" rid="fig3">Figures 3J</xref> and 8, 588 ± 3453 vs. 10,210 ± 5918 trials, p=0.39, two-tailed t-test).</p><p>These results show that mice could learn challenging perceptual decision tasks under head-fixation through unsupervised training in home-cage settings. Automated home-cage training has similar success rate and speed as manual training.</p></sec><sec id="s2-4"><title>A model-based comparison of task learning in automated and manual training</title><p>The home-cage system standardized the training across mice and continuously tracked mice behavior across the entire acquisition of the tactile decision task, thus providing an opportunity to examine task learning free of human interventions. We examined mice’s behavioral strategies during task learning by modeling the choice behavior at various stages of training using logistic regression (Materials and methods). The model predicted mice’s choice (lick left or lick right) from the tactile stimulus, stimulus history, choice history, reward history, a win-stay-lose-switch strategy (choice x reward in the previous trial), and a constant bias (<xref ref-type="fig" rid="fig4">Figure 4A</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Model-based comparison of task learning in home-cage and manual training.</title><p>(<bold>A</bold>) A logistic regression model to predict choice. Weighted sum of the tactile stimulus, stimulus history, choice history, reward history, a win-stay-lose-switch strategy (choice x reward in the last trial), and a constant bias is passed through a logistic function to predict choice in the current trial. (<bold>B</bold>) Behavioral data and model prediction from an example mouse in home-cage training. Trials are binned (bin size, 500 trials; step size, 100 trials). Top, behavioral performance. Middle, prediction performance of the full model and two partial models excluding either the current stimulus (S<sub>0</sub>, blue) or 1-back choice (A<sub>1</sub>, red). Model performance is calculated as the fraction of choice predicted (Materials and methods; chance level is 50%). Shaded area indicates SEM. Bottom, the significance of individual regressors. Circle size corresponds to p values. The significance of a regressor is evaluated by comparing the prediction of the full model to a partial model with the regressor of interest excluded. p Values are based on bootstrap (Materials and methods). (<bold>C</bold>) Average model prediction across all mice in home-cage training. Black line, prediction of the full model. Blue, performance of a partial model excluding both the current stimulus S<sub>0</sub> and stimulus history S<sub>1-5</sub>. Red, performance of a partial model excluding choice history A<sub>1-5</sub>. Green, performance of a partial model with only the current stimulus S<sub>0</sub>, choice history A<sub>1</sub>, and a constant bias term β<sub>0</sub>. Dashed line, the performance of the full model predicting shuffled behavioral data (Materials and methods). Shaded area indicates SEM across mice. Chance, 50%. (<bold>D</bold>) Percentage of mice showing significant contribution from each regressor at different stages of learning. Significance is defined as p&lt;0.05. Top, mice in home-cage training (<italic>n</italic> = 32); Bottom, mice in manual training (<italic>n</italic> = 64). (<bold>E</bold>) Percentage of mice relying on different regressors during task learning. A mouse is deemed to rely on a regressor if it shows significant contribution to choice prediction in at least five consecutive time bins during training (1000 trials). Regressors shown are the current stimulus (<bold>S<sub>0</sub></bold>), 1-back and 2-back stimulus history (S<sub>1-2</sub>), 1-back, 2-back and 3-back choice history (A<sub>1-3</sub>), and 1-back reward history (<bold>R<sub>1</sub></bold>). Error bars show SEM across mice (bootstrap). Dash line and shaded area show the mean and SEM across all other regressors. All other regressors show small contributions and they are pooled. Regressors from both home-cage and manual training are also pooled.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66112-fig4-v2.tif"/></fig><p>The model was able to predict mice’s behavioral choice across different stages of training (<xref ref-type="fig" rid="fig4">Figure 4B–C</xref>). Interestingly, the model could predict choice well before the behavioral performance was above chance (<xref ref-type="fig" rid="fig4">Figure 4B–C</xref>). This suggests that mice used behavioral strategies other than the tactile stimulus to guide choice during the early phase of training. To determine which model regressor was driving choice, we built partial models that excluded individual regressors and compared their prediction accuracy to the full model (<xref ref-type="fig" rid="fig4">Figure 4B,p</xref> value indicates significantly worse prediction than the full model based on cross validated performance, bootstrap, Materials and methods). Model selection showed that two regressors most strongly contributed to choice prediction, but these regressors contributed at different stages of training (<xref ref-type="fig" rid="fig4">Figure 4B–C</xref>). During the early phase of training, choice history from the last trial had a significant contribution, suggesting that mice tended to repeat their choice regardless of the tactile stimulus. During the late phase of training, the contribution of choice history diminished, and the contribution of the tactile stimulus increased, which suggests that mice learned to use the tactile stimulus to guide choice (<xref ref-type="fig" rid="fig4">Figure 4B</xref> bottom, 4C). A model that only considered choice history and tactile stimulus was sufficient to account the choice prediction performance of the full model (<xref ref-type="fig" rid="fig4">Figure 4C</xref>).</p><p>This pattern of behavioral strategy was consistently observed in home-cage training (<xref ref-type="fig" rid="fig4">Figure 4D</xref> top). A similar pattern of behavioral strategy was also observed in manual training (<xref ref-type="fig" rid="fig4">Figure 4D</xref> bottom). Overall, similar percentages of mice in home-cage and manual training used the tactile stimulus, choice history, and reward history to solve the task during learning (<xref ref-type="fig" rid="fig4">Figure 4E</xref>). These results suggest that naive mice initially adapted a behavioral strategy of repeating their past actions, and then abandoned this strategy as they learned the sensorimotor contingency. These results show that mice in home-cage training used similar behavioral strategies to learn the tactile decision task as mice in manual training. This provides further validation data that shows automated training can replace conventional manual training.</p></sec><sec id="s2-5"><title>Contingency reversal learning</title><p>The automated home-cage system permits prolonged task training, which opened the possibility of training mice in challenging behavioral tasks that were previously difficult to attain. To test this utility, we trained mice in contingency reversals in which they had to flexibly report the tactile decision using lick left or lick right (<xref ref-type="fig" rid="fig5">Figure 5A</xref>).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Contingency reversal learning in home-cage.</title><p>(<bold>A</bold>) Mice discriminate the location of a pole (anterior or posterior) and report the location using directional licking (left or right) without a delay epoch. The task switches between standard sensorimotor contingency and reversed contingency once mice reach criterion performance. Criterion performance, &gt;80% for 100 trials. (<bold>B</bold>) Behavioral performance data from two example mice. Bin size, 50 trials. Blue line, contingency reversals. Dashed line, 70% correct. (<bold>C</bold>) The number of trials to acquire new contingencies over multiple contingency reversals. The number of trials to reach criterion performance is normalized to the first contingency reversal. Individual lines show individual mice. (<bold>D</bold>) The number of trials needed to learn the tactile decision task vs. the average number of trials to reach criterion performance in contingency reversal learning. Task learning is from the start of head-fixation training to reaching criterion performance. Individual dots show individual mice. Line, linear regression. Two mice from (<bold>C</bold>) were excluded because they previously learned a different behavioral task.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66112-fig5-v2.tif"/></fig><p>Mice first learned the standard tactile decision task (without a delay) in which they reported anterior pole location by licking left and posterior pole location by licking right. After mice attained high levels of performance (&gt;80% correct for 100 trials), the sensorimotor contingency was reversed in which anterior pole location corresponded to lick right and posterior pole location corresponded to lick left. Mice did not receive any cues about the reversal other than reward feedbacks: correct responses led to water rewards; incorrect responses led to timeouts. Immediately after the reversal, behavioral performance dropped to below chance (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). Performance steadily recovered and was eventually stably above 70% correct.</p><p>To examine whether mice could robustly switch sensorimotor contingency, we repeatedly reversed the contingency after mice reached criterion performance. Mice consistently acquired new contingencies and did so in similar number of trials (<xref ref-type="fig" rid="fig5">Figure 5B–C</xref>). However, the reversal learning speed varied substantially across mice (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). The initial task acquisition speed (i.e. the number of trials to reach criterion performance from the start of head-fixation training) was correlated with the reversal learning speed (i.e. the number of trials to reach criterion performance after contingency reversal) (<xref ref-type="fig" rid="fig5">Figure 5D</xref>). Thus, mice could be screened for fast learners based on the initial task acquisition speed.</p><p>These data, together with the robust training in the tactile decision task with short-term memory (<xref ref-type="fig" rid="fig3">Figure 3</xref>), demonstrate the utility of prolonged home-cage training in teaching mice difficult decision-making tasks.</p></sec><sec id="s2-6"><title>Home-cage testing reveals behavioral signatures of motivation</title><p>In home-cage experiments, mice behavior was motivated by water rewards. Mice received all their daily water by engaging in the task. We examined mice’s water consumption and body weight during home-cage training. When water restricted mice were introduced into the home-cage system, all mice obtained a large number of rewards on day 1 (<xref ref-type="fig" rid="fig6">Figures 6A–B</xref>, 600 rewards on average, 1.8 mL of water). This was likely due to the ease of accessing the lickport (see Voluntary head-fixation in home-cage, <xref ref-type="fig" rid="fig2">Figure 2E</xref>). As the lickport was retracted into the headport (away from the home-cage), reward rate dropped significantly on subsequent days. Water consumption and body weight gradually increased after the initial dip as mice acclimated to the head-fixation (<xref ref-type="fig" rid="fig6">Figure 6A–B</xref>). At steady state, a mouse typically consumed ~1 mL of water daily in the home-cage while maintaining stable body weight. This amount of water consumption was similar to mice engaged in daily manual experiments (<xref ref-type="bibr" rid="bib31">Guo et al., 2014b</xref>). The number of head-fixations per day was correlated with body weight (<xref ref-type="fig" rid="fig6">Figure 6C</xref>). Since body weight reflected prior water consumption, this indicates different levels of motivation due to thirst, which drove engagement in the task. In highly trained mice, task performance was stable despite the body weight change (<xref ref-type="fig" rid="fig6">Figure 6D</xref>).</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Contingency reversal learning in home-cage.</title><p>(<bold>A</bold>) Mouse weight as a function of time. Body weights were estimated from the load-sensing platform in home-cage (see <xref ref-type="fig" rid="fig2">Figure 2C</xref>). Weights are normalized to the initial weights on day 1. Black line and shades, mean ± standard deviation across mice. Green lines, in a subset of mice, body weights were also measured outside of the home-cage on a weight scale. (<bold>B</bold>) Number of rewards and water consumed per day. Line and shades, mean ± standard deviation across mice. (<bold>C</bold>) Number of head-fixations per day as a function of normalized body weights. Each symbol corresponds to one day. Different colors show different mice. (<bold>D</bold>) Task performance as a function of normalized body weights. Multiple factors can affect task performance, including motivation and task learning. Here, the data are taken from days after the mice have reached criterion performance. (<bold>E</bold>) Average IFI durations following correct and error trials. Individual lines show individual mice. Bars show averages across mice. ***p&lt;0.001, paired two-tailed t-test. (<bold>F</bold>) Average IFI durations during contingency reversal learning. Trials are taken from periods right before contingency reversals, immediately following reversals, and before the next reversals. Individual lines show individual mice. Bars show averages across mice. *p&lt;0.05, paired two-tailed t-test. (<bold>G</bold>) Prediction of choice by logistic regression on trials following long vs. short inter-fixation-intervals. The logistic regression model was fit using trials in their natural sequential order (regardless of the inter-fixation-intervals). The model was then used to predict choice on independent trials. Trials were then sorted by the preceding inter-fixation-intervals. Prediction performance was calculated separately for trials following short or long inter-fixation-intervals. Individual lines show individual mice. Bars show averages across mice. n.s. p&gt;0.05, paired two-tailed t-test. (<bold>H</bold>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66112-fig6-v2.tif"/></fig><p>We inferred mice’s motivation to engage in the task by examining the time intervals between head-fixations (‘inter-fixation-interval’). We sorted the inter-fixation-intervals by the outcome of the last trial in the previous head-fixation. The inter-fixation-interval after an error (which led to no reward) was significantly longer than following a correct trial (<xref ref-type="fig" rid="fig6">Figure 6E</xref>). This indicates a loss of motivation after an error, perhaps due to the loss of an expected reward. Consistent with this interpretation, we also found a significant increase in inter-fixation-intervals shortly after a sensorimotor contingency reversal (<xref ref-type="fig" rid="fig6">Figure 6F</xref>). This coincided with a drop in task performance due to the rule change (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). As performance recovered, inter-fixation-intervals also decreased (<xref ref-type="fig" rid="fig6">Figure 6F</xref>).</p><p>Despite the motivational change, mice maintained the same strategy in their choice behavior. To examine this, we used the logistic regression model to predict choice on trials following short vs. long inter-fixation-intervals (<xref ref-type="fig" rid="fig6">Figure 6G</xref>). If behavioral strategy changed across motivational state (reflected in short vs. long inter-fixation-intervals), the predictive power of the model would differ between these conditions. However, we did not find a significant difference in the model prediction performance. The result was similar in early and late stages of task learning (<xref ref-type="fig" rid="fig6">Figure 6G</xref>), even though mice used distinct strategies during these periods (<xref ref-type="fig" rid="fig4">Figure 4</xref>). These results suggest consistent strategies in the choice behavior.</p><p>Together, these results show behavioral signatures of motivation in self-initiated behavior in home-cage, which could be potentially exploited in studies of goal-directed behavior.</p></sec><sec id="s2-7"><title>Unsupervised home-cage optogenetic experiment</title><p>We integrated optical components into the behavioral test chamber (<xref ref-type="fig" rid="fig1">Figure 1C</xref>) to perform optogenetic manipulations during home-cage behavior. We used red light (630 nm) to photostimulate targeted brain regions through a clear skull implant (<xref ref-type="fig" rid="fig7">Figure 7A</xref>, Materials and methods) (<xref ref-type="bibr" rid="bib30">Guo et al., 2014a</xref>). Red light is less subject to hemoglobin absorption (<xref ref-type="bibr" rid="bib75">Svoboda and Block, 1994</xref>; <xref ref-type="bibr" rid="bib79">Tromberg et al., 2000</xref>) and can penetrate neural tissues in vivo with less attenuation compared to blue or green light while producing less heating (<xref ref-type="bibr" rid="bib49">Liu et al., 2015</xref>; <xref ref-type="bibr" rid="bib74">Stujenske et al., 2015</xref>; <xref ref-type="bibr" rid="bib81">Wiegert et al., 2017</xref>). A light source was mounted above the headport to broadly illuminate the targeted brain region (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). To manipulate activity specifically in the targeted brain regions, we locally expressed red-shifted opsins, ChrimsonR (<xref ref-type="bibr" rid="bib39">Klapoetke et al., 2014</xref>), or ChRmine (<xref ref-type="bibr" rid="bib51">Marshel et al., 2019</xref>). This approach did not require optical fiber implants. Thus, it eliminated the need to manually couple a light source to the mouse and enabled continuous optogenetic testing without human interventions. Importantly, head-fixation provided stable access to the brain for repeatable optical stimulations.</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Photoinhibition of cortical regions and comparisons of home-cage optogenetic experiments with manual optogenetic experiments.</title><p>(<bold>A</bold>) Left, an optogenetic approach to silence activity in specific brain regions and electrophysiology characterization in the barrel cortex (vS1). Right top, an example clear skull implant. Right bottom, a coronal section showing ChrimsonR expression in vS1. The coronal section is aligned to the Allen Refence Brain (Materials and methods). (<bold>B</bold>) Silicon probe recording in vS1 during photostimulation. Multi-unit activity from three example channels showing photoexcitation (first row) and photoinhibition (second and third rows). Red lines, photostimulation. (<bold>C</bold>) Effects of photostimulation on cell types defined by spike waveform. Dots, individual neurons. Circled dots, neurons with significant spike rate change, p&lt;0.05, two-tailed t-test. Spike rate of each neuron during photostimulation is normalized to its baseline (‘relative firing rate’, Materials and methods). Neurons with narrow spike waveforms are putative fast-spiking (FS) interneurons (gray). Neurons with wide spike waveforms are putative pyramidal neurons (black). (<bold>D</bold>) Relative firing rate of putative pyramidal neurons (black) and interneurons (gray) as a function of photostimulation intensity. Error bars show SEM across neurons. (<bold>E</bold>) Workflow schematics. (<bold>F</bold>) Photoinhibition of the left vS1. Left, a 3D rendered brain showing virus injection location. Middle, a coronal section showing virus expression in the left vS1. Right, behavioral performance change relative to the control trials during photoinhibition in the sample and delay epoch. Performance for lick left (red) and lick right trials (blue) are computed separately. Thin lines, individual mice; thick lines, mean. *p&lt;0.025; **p&lt;0.01; ***p&lt;0.001, significant performance change compared to the control trials (bootstrap, Materials and methods). (<bold>G</bold>) Same as (<bold>F</bold>) but for photoinhibition of the left ALM. (<bold>H</bold>) Same as (<bold>F</bold>) but for photoinhibition of the right ALM. (<bold>I</bold>) Behavioral performance change relative to the control trials during photoinhibition in home-cage optogenetic experiments (top row) and manual optogenetic experiments (bottom row). See the full dose response in <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>. (<bold>J</bold>) Comparison of performance change during the first vs. second half of optogenetic testing. Data from all mice and experiments (left vS1 photoinhibition, three mice; left ALM photoinhibition, one mouse; right ALM photoinhibition, two mice). Lines connect data from multiple photostimulation intensities for individual mice. For each brain region, only the condition in which photoinhibition induced the largest behavioral effect is included. Left vS1, data from the lick right trials, sample epoch photoinhibition. Left ALM, data from the lick right trials, delay epoch photoinhibition. Right ALM, data from the lick left trials, delay epoch photoinhibition. Linear regression, slope: 0.8; range: 0.5–1.1 (95% confidential interval). There is no difference between the first and second half of the home-cage optogenetic experiments (p=0.78, paired t-test). Home-cage optogenetic experiments span 12 ± 4.5 days, mean ± SD. (<bold>K</bold>) Comparison of performance change in home-cage versus manual optogenetic experiments. Linear regression, slope: 0.97; range: 0.73–1.22 (95% confidential interval). There is no difference between home-cage and manual experiments (p=0.36, paired t-test).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66112-fig7-v2.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>Comparisons of effect size with previous studies.</title><p>(<bold>A</bold>) Behavioral performance during photostimulation of the left ALM (top row) and right ALM (bottom row) in this study. Left, average performance across both trial types. Lines, individual mice. Bar, mean across mice. Dashed line, chance. Right, performance in each trial type. Blue, lick left trials; red, lick right trials. Thin lines, individual mice; thick lines, mean. *p&lt;0.05, **p&lt;0.01, ***p&lt;0.001, significant performance change compared to the control trials (bootstrap, Materials and methods). (<bold>B</bold>) Behavioral performance during photostimulation of the left ALM (top row) and right ALM (bottom row) from previous studies (<xref ref-type="bibr" rid="bib43">Li et al., 2015</xref>; <xref ref-type="bibr" rid="bib26">Gao et al., 2018</xref>; <xref ref-type="bibr" rid="bib44">Li et al., 2016</xref>). (<bold>C</bold>) Behavioral performance during photostimulation of the left vS1 in this study. Left, average performance across both trial types. Middle, performance in each trial type. Right, performance change relative to the control trials. (<bold>D</bold>) Behavioral performance during photostimulation of the left vS1 from previous study (<xref ref-type="bibr" rid="bib30">Guo et al., 2014a</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66112-fig7-figsupp1-v2.tif"/></fig><fig id="fig7s2" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 2.</label><caption><title>Behavioral performance change dose-response curve during optogenetics.</title><p>(<bold>A</bold>) Behavioral performance during photostimulation in the sample or delay epoch. Three mice with only GFP viruses injected into the left ALM. Left, performance change relative to the control trials in each trial type. Blue, lick left trials; red, lick right trials. Thin lines, individual mice; thick lines, mean. Right, average performance across both trial types. Lines, individual mice; bar, mean. Dashed line, chance performance. *p&lt;0.05, **p&lt;0.01, ***p&lt;0.001, significant performance change compared to the control trials (bootstrap, Materials and methods). (<bold>B</bold>) Same as (<bold>A</bold>) but for photostimulation of the left vS1 in home-cage optogenetic experiments (top row) and manual optogenetic experiments (bottom row). (<bold>C</bold>) Same as (<bold>A</bold>) but for photostimulation of the anterior dorsal striatum. (<bold>D</bold>) Same as (<bold>A</bold>) but for photostimulation of the dorsolateral striatum. (<bold>E</bold>) Same as (<bold>A</bold>) but for photostimulation of the posterior dorsal striatum. (<bold>F</bold>) Same as (<bold>A</bold>) but for photoinhibition of the lateral superior colliculus.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66112-fig7-figsupp2-v2.tif"/></fig></fig-group><p>We first tested this optogenetic strategy in the barrel cortex (vS1) for a well-documented channelrhodopsin-assisted photoinhibition method (<xref ref-type="bibr" rid="bib10">Cardin et al., 2009</xref>; <xref ref-type="bibr" rid="bib57">Olsen et al., 2012</xref>; <xref ref-type="bibr" rid="bib45">Li et al., 2019</xref>). We injected small volumes (200 nL) of cre-dependent AAV viruses carrying either ChrimsonR or ChRmine in GAD2-IRES-cre mice (<xref ref-type="bibr" rid="bib77">Taniguchi et al., 2011</xref>) to excite GABAergic neurons and inhibit nearby pyramidal neurons. Virus injection localized the opsin expression (<xref ref-type="fig" rid="fig7">Figure 7A</xref>, diameter of expression, 0.79–1.18 mm). We characterized this photoinhibition using silicon probe recordings in awake non-behaving mice under the same illumination conditions as in the home-cage (<xref ref-type="fig" rid="fig7">Figure 7B</xref>). Units with narrow spikes were putative fast spiking (FS) neurons (<xref ref-type="bibr" rid="bib10">Cardin et al., 2009</xref>; <xref ref-type="bibr" rid="bib57">Olsen et al., 2012</xref>; <xref ref-type="bibr" rid="bib30">Guo et al., 2014a</xref>; <xref ref-type="bibr" rid="bib63">Resulaj et al., 2018</xref>; <xref ref-type="bibr" rid="bib45">Li et al., 2019</xref>) and a subset of the FS neurons were activated by light (<xref ref-type="fig" rid="fig7">Figure 7C–D</xref>, 7/14 with significantly elevated spike rate at 2.8 mW/mm<sup>2</sup>, p&lt;0.01, two-tailed t-test, photostimulation vs. baseline epoch). Neurons with wide spikes were likely mostly pyramidal neurons and majority of these neurons were silenced in a dose-dependent manner (<xref ref-type="fig" rid="fig7">Figure 7C–D</xref>, 114/157 with significantly depressed spike rate at 2.8 mW/mm<sup>2</sup>). Photoinhibition silenced &gt;70% of the spikes in putative pyramidal neurons at the virus injection site over a wide range of laser powers (<xref ref-type="fig" rid="fig7">Figure 7D</xref>, 0.3–8.2 mW/mm<sup>2</sup>).</p><p>We next tested the feasibility of unsupervised home-cage optogenetic experiments. Cortical regions involved in decision-making can vary across behavioral strategies and training conditions (<xref ref-type="bibr" rid="bib13">Chowdhury and DeAngelis, 2008</xref>; <xref ref-type="bibr" rid="bib50">Liu and Pack, 2017</xref>; <xref ref-type="bibr" rid="bib27">Gilad et al., 2018</xref>). We examined whether behaviors resulting from automated home-cage training engaged the same cortical regions as manual training. We photoinhibited activity in two cortical regions known to be involved in tactile decision-making. We targeted the left vS1, contralateral to the side of the tactile stimulus, where photoinhibition was expected to impair tactile sensation (<xref ref-type="bibr" rid="bib56">O'Connor et al., 2013</xref>; <xref ref-type="bibr" rid="bib65">Sachidhanandam et al., 2013</xref>; <xref ref-type="bibr" rid="bib30">Guo et al., 2014a</xref>). In addition, we targeted anterior lateral motor cortex (ALM), where unilateral photoinhibition was expected to bias choice to the ipsilateral direction (<xref ref-type="bibr" rid="bib30">Guo et al., 2014a</xref>; <xref ref-type="bibr" rid="bib43">Li et al., 2015</xref>). After mice reached high levels of performance in home-cage training, photostimulation was deployed in a subset of trials during either the sample or delay epoch (<xref ref-type="fig" rid="fig7">Figure 7E</xref>).</p><p>Photoinhibition of the left vS1 reduced behavioral performance primarily during the sample epoch (<xref ref-type="fig" rid="fig7">Figure 7F</xref>). The performance deficit was limited to lick right trials, which corresponded to the posterior pole position where the pole strongly contacted the whiskers. This pattern of behavioral effect is consistent with a deficit in pole detection (<xref ref-type="bibr" rid="bib56">O'Connor et al., 2013</xref>; <xref ref-type="bibr" rid="bib65">Sachidhanandam et al., 2013</xref>; <xref ref-type="bibr" rid="bib30">Guo et al., 2014a</xref>). Photoinhibition of ALM produced an ipsilateral bias, primarily during the delay epoch (<xref ref-type="fig" rid="fig7">Figure 7G–H</xref>). Photoinhibition of the left ALM biased upcoming licking to the left, resulting in lower performance in lick right trials and slightly higher performance in lick left trials. An opposite bias was induced by photoinhibiting the right ALM. These patterns of behavioral deficit were similar to those observed in previous studies (<xref ref-type="bibr" rid="bib30">Guo et al., 2014a</xref>; <xref ref-type="bibr" rid="bib43">Li et al., 2015</xref>) and the effect size was comparable (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). As a negative control, photostimulation produced no effect when only GFP viruses were injected into ALM (<xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2A</xref>).</p><p>Home-cage optogenetic experiments lasted 12 days on average (SD, 4.5 days). Mice showed little adaptation to photostimulation. Later days of the home-cage optogenetic experiments elicited similar effect sizes as the early days (<xref ref-type="fig" rid="fig7">Figure 7J</xref>). To directly compare the behavioral effects from home-cage testing to those induced in manual experiments, we subsequently tested a subset of mice (n = 6) in conventional optogenetic experiments. In daily supervised sessions, the mice were manually head-fixed and tested for photoinhibition on a different setup (Materials and methods). vS1 photoinhibition in manual experiments elicited the same pattern of behavioral deficit as those induced in home-cage testing (<xref ref-type="fig" rid="fig7">Figure 7I and K</xref>). The magnitude of behavior performance deficit was similar across a wide range of light doses (<xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2B</xref>). Similar results were also obtained for ALM photoinhibition (<xref ref-type="fig" rid="fig7">Figure 7K</xref>).</p><p>These characterization data show that the optogenetic approach can potently manipulate cortical activity and unsupervised home-cage optogenetic experiments can be used to screen for cortical regions involved in behavior.</p></sec><sec id="s2-8"><title>Survey of subcortical regions involved in tactile decision-making</title><p>We next tested the optogenetic strategy in manipulating activity of deep brain regions. We focused on the action-selection networks that include the striatum and downstream superior colliculus (SC). Previous studies in rodents suggest both the striatum and SC play roles in perceptual decision-making based on olfactory, auditory, or visual cues (<xref ref-type="bibr" rid="bib23">Felsen and Mainen, 2008</xref>; <xref ref-type="bibr" rid="bib24">Felsen and Mainen, 2012</xref>; <xref ref-type="bibr" rid="bib73">Stubblefield et al., 2013</xref>; <xref ref-type="bibr" rid="bib83">Znamenskiy and Zador, 2013</xref>; <xref ref-type="bibr" rid="bib17">Duan et al., 2015</xref>; <xref ref-type="bibr" rid="bib40">Kopec et al., 2015</xref>; <xref ref-type="bibr" rid="bib70">Sippy et al., 2015</xref>; <xref ref-type="bibr" rid="bib82">Yartsev et al., 2018</xref>; <xref ref-type="bibr" rid="bib18">Duan et al., 2019</xref>; <xref ref-type="bibr" rid="bib41">Lee et al., 2020</xref>). However, the previous studies examined different subregions of the striatum and SC in different perceptual decision behaviors, making comparisons across studies difficult. We therefore compared striatal and SC subregions’ involvement in the tactile decision behavior.</p><p>We injected cre-dependent ChRmine viruses into the left striatum of GAD2-IRES-cre mice to perturb GABAergic neurons non-specifically in the targeted region. We first tested if photostimulation through an intact clear skull could manipulate activity deep in the brain. We performed silicon probe recordings around an injection site 2.2 mm below the brain surface (<xref ref-type="fig" rid="fig8">Figure 8A–B</xref>). Most striatal neurons near the injection site were significantly excited or inhibited by photostimulation through the clear skull (<xref ref-type="fig" rid="fig8">Figure 8C</xref>). The mixture of excitation and inhibition was expected since the ChRmine viruses targeted GABAergic neurons non-specifically (<xref ref-type="bibr" rid="bib77">Taniguchi et al., 2011</xref>), and the GABAergic striatal projection neurons and interneurons locally inhibit each other (<xref ref-type="bibr" rid="bib9">Burke et al., 2017</xref>). For neurons modulated by light (p&lt;0.01, two-tailed t-test), the changes in spike rate monotonically increased as a function of laser power (<xref ref-type="fig" rid="fig8">Figure 8D</xref>). Significant spike rate changes were observed even at low laser powers (3 mW or 1.75 mW/mm<sup>2</sup> on the brain surface). The effect was spatially localized to the injection site (<xref ref-type="fig" rid="fig8">Figure 8E</xref>). These data show that the optogenetic method can potently manipulate striatal activity.</p><fig-group><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Photostimulation of subcortical regions in home-cage optogenetic experiment.</title><p>(<bold>A</bold>) A coronal section showing virus expression in the striatum (red) and silicon probe recording track (green). (<bold>B</bold>) Silicon probe recording in the striatum during photostimulation. Multi-unit activity from two example channels near the virus injection site (top) and one example channel below the injection site. Red lines, photostimulation. (<bold>C</bold>) Effects of photostimulation across depths. Dots correspond to individual neurons. Circled dots indicate neurons with significant spike rate change, p&lt;0.05, two-tailed t-test. Spike rate of each neuron during photostimulation is normalized to its baseline (‘relative firing rate’, Materials and methods). Shaded area indicates the virus expression region estimated from histology. (<bold>D</bold>) Relative firing rate of all significantly excited and inhibited neurons as a function of photostimulation intensity. Error bars show SEM across neurons. (<bold>E</bold>) Fraction of neurons significantly excited (red) and inhibited (blue) by photostimulation, p&lt;0.05, two-tailed t-test. Left, neurons from near the virus injection site. Right, neurons from below the virus injection site. (<bold>F</bold>) Left, a 3D rendered brain showing the striatum (blue) and the injection location in the anterior dorsal striatum (yellow). Middle, a coronal section showing example virus expression. The coronal section is aligned to the Allen Reference Brain (Materials and methods). Right, behavioral performance change relative to the control trials during photostimulation in the sample, delay, or response epoch. Blue, lick left trials; red, lick right trials. Thin lines, individual mice; thick lines, mean. **p&lt;0.01, ***p&lt;0.001, significant performance change compared to the control trials (bootstrap, Materials and methods). (<bold>G</bold>) Same as (<bold>F</bold>) but for photostimulation in the dorsolateral striatum. (<bold>H</bold>) Same as (<bold>F</bold>) but for photostimulation in the posterior dorsal striatum. (<bold>I–L</bold>) Same as (<bold>A–D</bold>) but for photoinhibition in the left superior colliculus. (<bold>M</bold>) Same as (<bold>E</bold>) but for photoinhibition in the left superior colliculus. (<bold>N</bold>) The 3D rendered brain shows the striatum and superior colliculus (blue) and the centers of virus expression in individual mice used in this study (dots). See individual mouse data in <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66112-fig8-v2.tif"/></fig><fig id="fig8s1" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 1.</label><caption><title>Virus injection sites in the striatum and superior colliculus.</title><p>(<bold>A</bold>) Left, a coronal section showing the centers of virus expression in individual mice (yellow dots). Right, coronal sections of individual mice showing virus expression in the anterior dorsal striatum. The coronal sections are aligned to the Allen Reference Brain (Materials and methods). (<bold>B</bold>) Same as (<bold>A</bold>) but for the dorsolateral striatum. (<bold>C</bold>) Same as (<bold>A</bold>) but for the posterior dorsal striatum. (<bold>D</bold>) Same as (<bold>A</bold>) but for the lateral superior colliculus.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-66112-fig8-figsupp1-v2.tif"/></fig></fig-group><p>We next tested if the striatal optogenetic manipulation was sufficient to bias behavior. We targeted three subregions of the striatum previously implicated in different types of decision-making behaviors, including a subregion of the anterior dorsal striatum (<xref ref-type="bibr" rid="bib82">Yartsev et al., 2018</xref>), a subregion of the dorsolateral striatum (<xref ref-type="bibr" rid="bib70">Sippy et al., 2015</xref>), and a subregion of the posterior dorsal striatum (<xref ref-type="bibr" rid="bib83">Znamenskiy and Zador, 2013</xref>; <xref ref-type="fig" rid="fig8">Figure 8F–H</xref> and <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1A–C</xref>). Among them, the dorsolateral striatal subregion received inputs from both ALM (<xref ref-type="bibr" rid="bib35">Hooks et al., 2018</xref>) and the barrel cortex (<xref ref-type="bibr" rid="bib70">Sippy et al., 2015</xref>). The anterior striatum received inputs from only ALM and the posterior dorsal striatum did not receive inputs from either cortical regions (<xref ref-type="bibr" rid="bib35">Hooks et al., 2018</xref>). We targeted the left striatum, ipsilateral to the left barrel cortex and contralateral to the tactile stimulus. Moreover, we targeted the striatal regions unilaterally to examine their roles in directional licking. Perturbation of the three striatal subregions differentially affected task performance (<xref ref-type="fig" rid="fig8">Figure 8F–H</xref> and <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2C–E</xref>). The performance deficits induced by perturbing the anterior and posterior striatum were minimal and limited to the delay epoch (<xref ref-type="fig" rid="fig8">Figure 8F and H</xref>; <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2C and E</xref>). In contrast, perturbing the dorsolateral striatum produced large performance deficit in both the sample and delay epochs, but not the response epoch (<xref ref-type="fig" rid="fig8">Figure 8G</xref> and <xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2D</xref>). These patterns of behavioral deficit suggest that the dorsolateral stratum was required for tactile-guided licking decisions (<xref ref-type="bibr" rid="bib70">Sippy et al., 2015</xref>).</p><p>Additionally, we examined SC downstream of the basal ganglia. We targeted a lateral region of SC previously implicated in the control of licking movement (<xref ref-type="bibr" rid="bib64">Rossi et al., 2016</xref>; <xref ref-type="bibr" rid="bib41">Lee et al., 2020</xref>; <xref ref-type="fig" rid="fig8">Figure 8I</xref> and <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1D</xref>). Activity in the lateral SC is thought to drive contralateral licking (<xref ref-type="bibr" rid="bib41">Lee et al., 2020</xref>). We injected cre-dependent ChrimsonR (or ChRmine) viruses into the left SC in GAD2-IRES-cre mice and activated SC GABAergic neurons to photoinhibit SC output (<xref ref-type="bibr" rid="bib18">Duan et al., 2019</xref>). Silicon probe recordings show that photostimulation modulated activity in the targeted SC region even at moderate laser powers (<xref ref-type="fig" rid="fig8">Figure 8J–K</xref>). SC neurons activated by light were presumably GABAergic neurons and they inhibited other SC neurons (<xref ref-type="fig" rid="fig8">Figure 8L</xref>). Silencing the left SC biased upcoming licking to the left, resulting in performance decrease specifically in lick right trials (<xref ref-type="fig" rid="fig8">Figure 8M</xref>). The effect was elicited by photoinhibition during the delay epoch, but not during the sample epoch (<xref ref-type="fig" rid="fig8">Figure 8M</xref>). The bias was light-dose dependent and was significant at moderate laser power (<xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2F</xref>). These behavioral effects qualitatively mirrored those induced by photoinhibiting the left ALM (<xref ref-type="fig" rid="fig7">Figure 7G</xref>). This suggests that both ALM and SC are involved in the tactile decision task during the delay epoch.</p><p>These experiments show that the automated workflow could be used to rapidly survey distributed brain networks involved in behavior, including deep brain regions (<xref ref-type="fig" rid="fig8">Figure 8N</xref>).</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><sec id="s3-1"><title>Fully autonomous home-cage mouse behavioral and optogenetic experiments</title><p>We present a fully autonomous workflow for high-throughput mouse behavioral and optogenetic experiments (<xref ref-type="fig" rid="fig1">Figure 1</xref>). Mice engaged in voluntary head-fixation in an autonomous home-cage system that was amenable to operant conditioning (<xref ref-type="fig" rid="fig2">Figure 2</xref>). We developed algorithms that trained completely naive mice to perform tactile decision-making without human supervision (<xref ref-type="fig" rid="fig3">Figure 3</xref>). We integrated a fiber-free optogenetic method to manipulate activity in specific brain regions during home-cage behavior. We characterized the optogenetic approach using electrophysiology and loss-of-function experiments (<xref ref-type="fig" rid="fig7">Figure 7</xref>). Finally, we show that the workflow can be used to rapidly survey subregions of the striatum and downstream superior colliculus involved in decision-making (<xref ref-type="fig" rid="fig8">Figure 8</xref>).</p><p>Our approach presents three key advances. First, we introduce a low-cost, open source, and robust home-cage system that allows continuous task training (&gt;1 hr per day) for 2 months without human supervision. Our system significantly boosts the yield and duration of home-cage training to rival and slightly surpass that of manual training (<xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). This lowers the barrier for training mice in difficult operant conditioning tasks. We show that mice in home-cage training robustly learned a tactile decision task with short-term memory, and they robustly learned contingency reversals in which they flexibly reported decisions using directional licking (<xref ref-type="fig" rid="fig5">Figure 5</xref>). These tasks are previously difficult to train and require human expertise. Manual behavioral training is often not well documented. The automation and standardization afforded by the home-cage system increase the ease of transferring behavioral paradigms across labs.</p><p>Second, we provide the first benchmark dataset that shows fully automated experiments could supersede manual experiments. We show that automated training has similar success rate and speed as manual training (<xref ref-type="fig" rid="fig3">Figure 3</xref>). A logistic regression model of the choice behavior shows that mice in home-cage training learned the task using similar strategies as in human-supervised training (<xref ref-type="fig" rid="fig4">Figure 4</xref>). The behaviors resulting from home-cage training engaged the same cortical regions as manual training (<xref ref-type="fig" rid="fig7">Figure 7</xref>; <xref ref-type="bibr" rid="bib56">O'Connor et al., 2013</xref>; <xref ref-type="bibr" rid="bib65">Sachidhanandam et al., 2013</xref>; <xref ref-type="bibr" rid="bib30">Guo et al., 2014a</xref>; <xref ref-type="bibr" rid="bib43">Li et al., 2015</xref>). In addition, we directly demonstrate the capacity for high-throughput experiments by testing dozens of mice at a time in parallel.</p><p>Finally, our workflow is the first to combine home-cage training and unsupervised optogenetic testing. We provide a fiber-free method to manipulate deep brain regions and provide characterization data to show that the method can potently modulate neural activity and bias behavior (<xref ref-type="fig" rid="fig8">Figure 8</xref>). Voluntary head-fixation and photostimulation through an intact skull bypasses the need to manually tether the mice to a light source and it facilitates continuous optogenetic testing across days without human interventions. In the fully automated workflow, only one injection and headbar implant surgery is needed to prepare a mouse and little supervision is needed thereafter. Parallel testing allows a large number of mice and brain regions to be tested in a single behavior. The approach will enable rapid surveys of distributed brain networks underlying operant behaviors in mice.</p><p>Our workflow is particularly suitable for mapping cortico-basal-ganglia loops involved in operant behaviors that require extended training. The striatum is topographically organized (<xref ref-type="bibr" rid="bib33">Hintiryan et al., 2016</xref>; <xref ref-type="bibr" rid="bib36">Hunnicutt et al., 2016</xref>; <xref ref-type="bibr" rid="bib35">Hooks et al., 2018</xref>; <xref ref-type="bibr" rid="bib58">Peters et al., 2019</xref>; <xref ref-type="bibr" rid="bib41">Lee et al., 2020</xref>). The striatum in the mouse brain is ~21.5 mm<sup>3</sup> in size (Allen reference brain, <xref ref-type="bibr" rid="bib80">Wang et al., 2020</xref>). Optogenetic experiments using optical fibers manipulate activity near the fiber tip (approximately 1 mm<sup>3</sup>). Previous studies examined different subregions of the striatum in different perceptual decision behaviors, making comparisons across studies difficult. A systematic survey of different striatal domains’ involvement in specific behaviors is currently difficult. In our workflow, individual striatal subregions (~1 mm<sup>3</sup>, <xref ref-type="fig" rid="fig8">Figure 8</xref>) could be rapidly screened through parallel testing. At moderate throughput (15 mice/2 months), a screen that tiles the entire striatum could be completed in under 12 months with little human effort. To illustrate its feasibility, we tested three subregions in the striatum previously implicated in different types of perceptual decision behaviors (<xref ref-type="bibr" rid="bib83">Znamenskiy and Zador, 2013</xref>; <xref ref-type="bibr" rid="bib70">Sippy et al., 2015</xref>; <xref ref-type="bibr" rid="bib82">Yartsev et al., 2018</xref>). The results show that our approach could reliably differentiate striatal regions that biased tactile decision-making from those that did not (<xref ref-type="fig" rid="fig8">Figure 8F–H</xref>).</p><p>By eliminating human intervention, automated training also allows quantitative assaying of task learning (<xref ref-type="fig" rid="fig4">Figure 4</xref>). Home-cage testing also exposes behavioral signatures of motivation in self-initiated behavior (<xref ref-type="fig" rid="fig6">Figure 6</xref>). These observations suggest additional opportunities for inquires of goal-directed behaviors in the context of home-cage testing.</p></sec><sec id="s3-2"><title>Relation to previous automated behavioral experiments</title><p>Several recent studies have developed automated systems to train rodents in decision-making and motor control tasks (<xref ref-type="bibr" rid="bib21">Erlich et al., 2011</xref>; <xref ref-type="bibr" rid="bib60">Poddar et al., 2013</xref>; <xref ref-type="bibr" rid="bib3">Aoki et al., 2017</xref>; <xref ref-type="bibr" rid="bib69">Silasi et al., 2018</xref>; <xref ref-type="bibr" rid="bib6">Bollu et al., 2019</xref>; <xref ref-type="bibr" rid="bib22">Erskine et al., 2019</xref>; <xref ref-type="bibr" rid="bib61">Qiao et al., 2019</xref>; <xref ref-type="bibr" rid="bib62">Reinert et al., 2019</xref>; <xref ref-type="bibr" rid="bib4">Bernhard et al., 2020</xref>). Automated systems have also been incorporated into large environments to probe social and environmental factors on cognitive behaviors (<xref ref-type="bibr" rid="bib25">Freund et al., 2013</xref>; <xref ref-type="bibr" rid="bib11">Castelhano-Carlos et al., 2014</xref>; <xref ref-type="bibr" rid="bib78">Torquet et al., 2018</xref>). For operant behaviors, automated testing has been combined with imaging (<xref ref-type="bibr" rid="bib67">Scott et al., 2013</xref>; <xref ref-type="bibr" rid="bib53">Murphy et al., 2016</xref>; <xref ref-type="bibr" rid="bib54">Murphy et al., 2020</xref>), lesion (<xref ref-type="bibr" rid="bib38">Kawai et al., 2015</xref>), video-based behavioral analysis (<xref ref-type="bibr" rid="bib61">Qiao et al., 2019</xref>), and optogenetics (<xref ref-type="bibr" rid="bib6">Bollu et al., 2019</xref>). Some of these systems also implement automated head-fixation (<xref ref-type="bibr" rid="bib37">Kampff et al., 2010</xref>; <xref ref-type="bibr" rid="bib67">Scott et al., 2013</xref>; <xref ref-type="bibr" rid="bib53">Murphy et al., 2016</xref>; <xref ref-type="bibr" rid="bib3">Aoki et al., 2017</xref>; <xref ref-type="bibr" rid="bib54">Murphy et al., 2020</xref>). However, most previous systems still require manual interventions to couple the neurophysiology or manipulation apparatus to the animals before each session (<xref ref-type="bibr" rid="bib3">Aoki et al., 2017</xref>; <xref ref-type="bibr" rid="bib6">Bollu et al., 2019</xref>), but see <xref ref-type="bibr" rid="bib67">Scott et al., 2013</xref>; <xref ref-type="bibr" rid="bib54">Murphy et al., 2020</xref>. Moreover, previous home-cage training with head-fixation is limited to relatively simple behavioral tasks and short training durations (<xref ref-type="bibr" rid="bib3">Aoki et al., 2017</xref>; <xref ref-type="bibr" rid="bib54">Murphy et al., 2020</xref>; <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). In our workflow, mice can engage in prolonged head-fixation (&gt;1 hour/day for 2 months) that permits extended training (tens of thousands of trials) in difficult behavioral tasks and continuous optogenetic testing in home-cage. Stable head-fixation also makes our workflow compatible with widefield imaging, and potentially two-photon imaging.</p><p>Our general approach and workflow are not restrictive to any specific behavioral system. We integrate and validate several design elements from previous studies. For example, our system has a layout design similar to <xref ref-type="bibr" rid="bib53">Murphy et al., 2016</xref>; <xref ref-type="bibr" rid="bib69">Silasi et al., 2018</xref>, where the headport is integrated into the home-cage for easy access. Our head-fixation mechanism is modeled after Scott and Tank (<xref ref-type="bibr" rid="bib67">Scott et al., 2013</xref>). We employ a load cell to measure mice’s body weight, based on <xref ref-type="bibr" rid="bib55">Noorshams et al., 2017</xref>. In turn, our automated training protocols (<xref ref-type="fig" rid="fig2">Figures 2</xref>–<xref ref-type="fig" rid="fig3">3</xref>) can be readily used for other behavioral tasks. Importantly, we find that the self-release mechanism is critical for mice to learn voluntary head-fixation (<xref ref-type="fig" rid="fig2">Figure 2H</xref>). Without it, mice will start to struggle beyond a certain duration, and if failed to get free, mice will stop engaging in head-fixation subsequently. In addition, we find that auto-assistance to the mice is critical for successful task learning (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). These guidelines will likely generalize to other automated training.</p><p>Other design choices not explored here may further improve the efficiency of automated training. Mice in our study are singly housed. Other studies testing group housed mice suggest a potential for higher yield in trial count (<xref ref-type="bibr" rid="bib53">Murphy et al., 2016</xref>; <xref ref-type="bibr" rid="bib62">Reinert et al., 2019</xref>). One factor that may negatively affect yield in group housed mice is social hierarchy. Dominant mouse may occupy the headport most of the time, which could reduce training time for other co-housed mice (<xref ref-type="bibr" rid="bib53">Murphy et al., 2016</xref>). This problem can be alleviated by building behavioral test chambers that are separated from the home-cage (<xref ref-type="bibr" rid="bib11">Castelhano-Carlos et al., 2014</xref>; <xref ref-type="bibr" rid="bib3">Aoki et al., 2017</xref>; <xref ref-type="bibr" rid="bib78">Torquet et al., 2018</xref>; <xref ref-type="bibr" rid="bib61">Qiao et al., 2019</xref>). Access to the test chamber can then be managed using intelligent protocols based on RFID tags of individual mice (<xref ref-type="bibr" rid="bib42">Lewejohann et al., 2009</xref>; <xref ref-type="bibr" rid="bib5">Bolaños et al., 2017</xref>; <xref ref-type="bibr" rid="bib22">Erskine et al., 2019</xref>).</p></sec><sec id="s3-3"><title>Probing brain regions involved in perceptual decision-making</title><p>Our optogenetic experiments suggest that a subregion of the dorsolateral striatum and a lateral region of the superior colliculus (SC) are required for tactile-guided licking decisions (<xref ref-type="fig" rid="fig7">Figure 7N</xref>). These regions overlap with regions in the striatum and SC previously implicated in licking motor control (<xref ref-type="bibr" rid="bib64">Rossi et al., 2016</xref>; <xref ref-type="bibr" rid="bib41">Lee et al., 2020</xref>). In particular, the subregion of the dorsolateral striatum targeted here (<xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1B</xref>) is slightly dorsal to but has substantial overlap with a ventrolateral region of the striatum that receives strong ALM input (<xref ref-type="bibr" rid="bib35">Hooks et al., 2018</xref>; <xref ref-type="bibr" rid="bib41">Lee et al., 2020</xref>). Stimulation of the ventrolateral striatal region can evoke contralateral licking (<xref ref-type="bibr" rid="bib41">Lee et al., 2020</xref>). It is worth noting that the subregion of the dorsolateral striatum targeted here also receives some ALM input, but it additionally receives input from the barrel cortex (<xref ref-type="bibr" rid="bib70">Sippy et al., 2015</xref>; <xref ref-type="bibr" rid="bib35">Hooks et al., 2018</xref>) and perturbation of this region impairs tactile-guided licking decisions (<xref ref-type="fig" rid="fig8">Figure 8G</xref>, sample epoch) (<xref ref-type="bibr" rid="bib70">Sippy et al., 2015</xref>). However, our data cannot yet resolve whether the behavioral effects observed here was due to perturbations of part of the ventrolateral striatal region. Perturbations of the anterior and posterior striatum produced small but significant effects (<xref ref-type="fig" rid="fig8">Figure 8F and G</xref>). The effect was only observed during the delay epoch and only at the highest laser power (<xref ref-type="fig" rid="fig7s2">Figure 7—figure supplement 2</xref>). The effect could result from overlaps of the perturbed regions with the dorsolateral striatum. A more systematic mapping around these striatal regions is needed to determine whether a discrete subregion of the striatum contributes to licking decisions. Our high-throughput workflow is ideally suited for such survey studies.</p><p>One limitation of the current workflow is the interpretation of deficit effect size induced by photostimulation. In previous studies, we have shown that photoinhibition of ALM results in chance level performance (<xref ref-type="bibr" rid="bib44">Li et al., 2016</xref>; <xref ref-type="bibr" rid="bib26">Gao et al., 2018</xref>). In this study, mice performance was above chance during photoinhibition of ALM (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1A</xref>). This difference in effect size likely resulted from incomplete silencing of ALM. The photostimulus intensity used here was less than those used in previous studies (<xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1</xref>). In addition, a single virus injection was not sufficient to cover the entire ALM (1 mm<sup>2</sup> in diameter) (<xref ref-type="bibr" rid="bib12">Chen et al., 2017</xref>). Thus a partial behavioral effect could be due to incomplete silencing of a brain region, or partial involvement of the brain region in the task.</p><p>Given this limitation, manipulations alone cannot yet elucidate the function of a brain region in behavior. The workflow presented here can be used as a discovery platform to quickly identify regions of interest for more detailed neurophysiology analysis. Our proof-of-concept experiments show that our automated workflow can be a useful tool to facilitate discovery of distributed multi-regional networks driving complex behaviors, and it paves the way for more targeted neurophysiology analysis.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><table-wrap id="keyresource" position="anchor"><label>Key resources table</label><table frame="hsides" rules="groups"><thead><tr><th>Reagent type <break/>(species) or resource</th><th>Designation</th><th>Source or reference</th><th>Identifiers</th><th>Additional information</th></tr></thead><tbody><tr><td>Strain, strain background (Mouse)</td><td>Gad2-IRES-Cre</td><td>The Jackson Laboratory</td><td>JAX: 010802 <break/>(RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/IMSR_JAX:014548">IMSR_JAX:014548</ext-link>)</td><td>Cre targeted at the<italic>Gad2</italic> locus</td></tr><tr><td>Strain, strain background (Mouse)</td><td>PV-IRES-Cre</td><td>The Jackson Laboratory</td><td>JAX: 008069 <break/>(RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/IMSR_JAX:008069">IMSR_JAX:008069</ext-link>)</td><td>Cre targeted at the<italic>Pvalb</italic> locus</td></tr><tr><td>Strain, strain background (Mouse)</td><td>VGAT-ChR2-EYFP</td><td>The Jackson Laboratory</td><td>JAX: 014548 <break/>(RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/IMSR_JAX:014548">IMSR_JAX:014548</ext-link>)</td><td>ChR2 targeted at the<italic>Slc32a1</italic> locus</td></tr><tr><td>Strain, strain background (Mouse)</td><td>Ai32(RC-hR2(H134R)/EYFP)</td><td>The Jackson Laboratory</td><td>JAX: 012569 <break/>(RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/IMSR_JAX:012569">IMSR_JAX:012569</ext-link>)</td><td>ChR2 targeted at the<italic>Gt(ROSA)26Sor</italic> locus</td></tr><tr><td>Recombinant DNA reagent</td><td>AAV9-hSyn-FLEX-ChrimsonR-tdTomato</td><td>UNC Viral Core</td><td>N/A</td><td/></tr><tr><td>Recombinant DNA reagent</td><td>AAV8-Ef1a-DIO-ChRmine-mScarlet-WPRE</td><td>Stanford Viral Core</td><td>GVVC-AAV-188</td><td/></tr><tr><td>Recombinant DNA reagent</td><td>AAV-pCAG-FLEX-EGFP-WPRE</td><td>Addgene</td><td>51502 <break/>(RRID:<ext-link ext-link-type="uri" xlink:href="https://scicrunch.org/resolver/Addgene_51502">Addgene_51502</ext-link>)</td><td/></tr><tr><td>Software, algorithm</td><td>MATLAB</td><td>Mathworks</td><td><ext-link ext-link-type="uri" xlink:href="https://www.mathworks.com">https://www.mathworks.com</ext-link></td><td/></tr><tr><td>Other</td><td>Design files, software, and documentations for the automated home-cage system.</td><td>This paper - Github repository</td><td><ext-link ext-link-type="uri" xlink:href="https://github.com/NuoLiLabBCM/Autocage">https://github.com/NuoLiLabBCM/Autocage</ext-link></td><td>The Github repository contains the hardware design files and software for the construction of automated home-cage system, along with documentations and protocols for automated head-fixation training and task training.</td></tr></tbody></table></table-wrap><sec id="s4-1"><title>Hardware and code availability</title><p>All hardware design files and software for the construction of automated home-cage system are made available, along with documentations and protocols for automated head-fixation training and task training (<ext-link ext-link-type="uri" xlink:href="https://github.com/NuoLiLabBCM/Autocage">https://github.com/NuoLiLabBCM/Autocage</ext-link>). Behavioral data and code used are also available in the Github repository.</p></sec><sec id="s4-2"><title>Mice</title><p>This study is based on data from 140 mice (both males and females, 2–6 months old). 50 GAD2-IRES-Cre (Cre targeted at the <italic>Gad2</italic> locus, Jackson Laboratory, JAX 010802) and PV-IRES-Cre (Cre targeted at the <italic>Pvalb</italic> locus, JAX 008069) mice were used for automated home-cage training and optogenetic experiments targeting the barrel cortex, ALM, striatum and superior colliculus. eight mice were used for contingency reversal learning experiment. Another three GAD2-IRES-Cre mice were used for control optogenetic experiments in which GFP viruses were injected into ALM. An additional four mice were trained in home-cage without self-release mechanism. Another five GAD2-IRES-Cre mice were used for electrophysiology to characterize the effects of optogenetic manipulation in the barrel cortex (two mice), striatum (two mice), and superior colliculus (one mouse). Seventy mice, including GAD2-IRES-Cre, VGAT-ChR2-eYFP (ChR2 targeted at the <italic>Slc32a1</italic> locus, JAX 014548), Ai32 (ChR2 targeted at the <italic>Gt(ROSA)26Sor</italic> locus, Rosa26-LSL-ChR2-eYFP, JAX 012569), and wild-type mice, were used for supervised manual training.</p><p>All procedures were performed in accordance with protocols approved by the Institutional Animal Care and Use Committees at Baylor College of Medicine (protocol AN7012). Mice were housed in a 12:12 reverse light:dark cycle. On days not tested, mice received 0.5–1 ml of water. In home-cage experiments, mice were singly housed in the automated home-cage 24/7 and received unrestricted access to the lickport and water rewards by engaging in the task. Body weights were monitored daily. Mice experiencing loss of body weight or failed to engage in voluntary head-fixation for prolonged time period were removed from the study (2/61 mice). In manual training, mice were tested in daily sessions during the dark phase. Experimental sessions lasted 1–2 hr, during which mice received all their water (0.3 to 2 ml). On days not tested, mice received 0.5–1 mL of water. In all cases, if mice did not maintain a stable body weight, they received supplementary water (<xref ref-type="bibr" rid="bib31">Guo et al., 2014b</xref>).</p></sec><sec id="s4-3"><title>Headbar implant surgery and virus injection</title><p>All surgical procedures were carried out aseptically under 1–2% isoflurane anesthesia. Buprenorphine Sustained Release (1 mg/kg) and Meloxicam Sustained Release (4 mg/kg) were used for pre- and post-operative analgesia. After the surgery, mice were allowed to recover for at least 3 days with free access to water before water restriction.</p><p>Mice were prepared with a clear-skull implant and a custom headpost (<xref ref-type="fig" rid="fig7">Figure 7A</xref>; <xref ref-type="bibr" rid="bib30">Guo et al., 2014a</xref>). In brief, the scalp and periosteum over the dorsal surface of the skull were removed. A layer of cyanoacrylate adhesive (Krazy Glue, Elmer’s Products) was directly applied to the intact skull. A custom-made headpost (<xref ref-type="fig" rid="fig2">Figure 2A</xref>) was placed on the skull (approximately over the cerebellum) and cemented in place with clear dental acrylic (1223CLR, Lang Dental). A thin layer of clear dental acrylic was applied over the cyanoacrylate adhesive covering the entire exposed skull.</p><p>In GAD2-IRES-Cre and PV-IRES-Cre mice prepared for optogenetic experiments, a small craniotomy (~0.5 mm diameter) was made to inject viruses through a pulled glass pipette (20–30 µm tip diameter). For photoinhibition of cortical regions, we injected 200 nL of AAV9-hSyn-FLEX-ChrimsonR-tdTomato (UNC viral core, titer 5.7 × 10<sup>12</sup> vg/ml) (<xref ref-type="bibr" rid="bib39">Klapoetke et al., 2014</xref>) in PV-IRES-Cre or GAD2-IRES-Cre mice (<xref ref-type="fig" rid="fig7">Figure 7</xref>). The injection coordinates were as follows: the left or right ALM, anterior 2.5 mm from bregma, lateral 1.5 mm, depth 0.4 and 0.8 mm; the left somatosensory cortex, posterior 1.5 mm from bregma, lateral 3.5 mm, depth 0.4 and 0.8 mm. For injections in the somatosensory cortex, we injected viruses in three adjacent sites (~0.5 mm apart) to cover the whole barrel cortex. For photoinhibition of the lateral superior colliculus, we injected 200 nL of AAV8-Ef1a-DIO-ChRmine-mScarlet-WPRE (Stanford viral core [<xref ref-type="bibr" rid="bib51">Marshel et al., 2019</xref>], titer 3.3 × 10<sup>13</sup> vg/ml) or AAV9-hSyn-FLEX-ChrimsonR-tdTomato in GAD2-IRES-Cre mice at posterior 3.5 mm from bregma, lateral 1.5 mm, depth 2.4 and 2.6 mm. For photostimulation of the striatal regions, we injected 100 nL of AAV8-Ef1a-DIO-ChRmine-mScarlet-WPRE in the left anterior dorsal striatum (anterior 1.3 mm from bregma, lateral 1.8 mm, depth 2.2 mm), or the left dorsolateral striatum (anterior 0.6 mm from bregma, lateral 2.4 mm, depth 2.2 mm), or the left posterior dorsal striatum (posterior 0.4 mm from bregma, lateral 2.0 mm, depth 2.1 mm) of GAD2-IRES-Cre mice. For control experiments, we injected 100 nL AAV-pCAG-FLEX-EGFP-WPRE (AddGene, 51502) into the left ALM of 2 GAD2-Cre mice.</p></sec><sec id="s4-4"><title>Autonomous home-cage system hardware</title><sec id="s4-4-1"><title>Behavioral test chamber</title><p>The core of the autonomous home-cage system was a behavioral test chamber attached to the mouse home-cage. An ‘L’-shape board (180 × 100 × 72 mm) housed all components of the behavioral test chamber as shown in <xref ref-type="fig" rid="fig1">Figure 1C</xref>. The board was designed using CAD software (Fusion 360, Autodesk) and 3D-printed with Nylon material. The board has a headport (~20 × 20 mm) in the center that accessed the home-cage. The board was attached to a standard mouse cage (290 × 180 × 120 mm) using two screws. A 25 × 25 mm pass-through was made on wall of the mouse cage to connect with the headport.</p><p>The two sides of the headport were fitted with widened tracks that guided a custom headbar (26.5 mm long, 3.2 mm wide) into a narrow spacing where the headbar could be clamped (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Two snap action switches (D429-R1ML-G2, Mouser) were mounted on both sides of the headport. The first 3 mm of the switch tips were bent 90 degrees to fit into the slots of the headport to detect headbar entries (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Two air pistons (6604K11, McMaster), with tips processed into a cone shape, were fixed into two holes above the headport. The pistons were pneumatically driven and controlled by an analog pressure regulator (557773, Festo).</p><p>A lickport with two lickspouts (5 mm apart) was placed in front of the headport. The lickport was actuated by two orthogonally fixed miniature linear motors (L12-50-100-12-I and L12-30-50-12-I, Actuonix), one moving the lickport forward and backward (i.e. toward or away from the headport) and the other in the left and right directions. Each of the lickspout was electrically coupled to a custom circuit board that detected licks via completion of an electrical circuit upon licking contacts (<xref ref-type="bibr" rid="bib71">Slotnick, 2009</xref>; <xref ref-type="bibr" rid="bib30">Guo et al., 2014a</xref>). Water rewards were dispensed by two solenoid valves (LHDA1233215H, Lee Co.).</p><p>The sensory stimulus for the tactile decision task was a mechanical pole (1.5 mm diameter) on the right side of the headport. The pole was motorized by a linear motor (L12-30-50-12-I, Actuonix) and presented at different location to stimulate the whiskers. The motorized pole was attached to an air piston (6498K999, McMaster), driven by a 3/2-way solenoid valve (196847, Festo), which moved the pole vertically into the reach of the whiskers. The entire pole mechanism was mounted on a holder on the behavioral test chamber board. The auditory ‘go’ cue in the tactile decision task was provided by a piezo buzzer (3.5 kHz, cpe163, Mouser) placed in front of the headport.</p><p>A custom 3D-printed platform was placed inside the home-cage in front of the headport (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). The stage was embedded with a load cell (<xref ref-type="fig" rid="fig2">Figure 2C</xref>, CZL639HD, Phidgets) to record mouse body weight. The load-sensing stage was also used to detect struggles during head-fixations and trigger self-release (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). The surface of the stage was coated with aluminum foil to produce electrical contact between the mouse and the electric lickspouts upon licking. The aluminum foil is connected to the lick detection circuit board.</p><p>An optical fiber (M79L005, Thorlabs), coupled to a red laser (633 nm, MRL-III-633–50, Ultralaser) or a LED (625 nm, M625F2, Thorlabs), was mounted above the headport. The fiber was approximately 12 mm above the clear skull implant during head-fixations. In cases where higher light power was needed, the optical fiber was placed closer to the mouse and aimed at the photostimulation site. To prevent mice from distinguishing photostimulation trials from control trials using visual cues, a masking flash (10 Hz) was delivered using a 627 nm LED (SP-01-R5, LexonStar) mounted in front of the headport.</p></sec><sec id="s4-4-2"><title>Controllers</title><p>Three Arduino microcontrollers (A000062, Mouser) operated the home-cage system (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1A</xref>). A ‘master’ controller stored the protocols for head-fixation training (<xref ref-type="fig" rid="fig2">Figure 2E</xref>), task training (<xref ref-type="fig" rid="fig3">Figure 3C</xref>), and optogenetic experiments (see <italic>Autonomous training protocols</italic>). The master controller autonomously advanced these protocols based on mouse behavioral performance. In addition, the master controller controlled the head-fixation logics, the lickport motors, and the motor that positioned the pole (i.e. tactile stimulus). For head-fixations, the controller read switch triggers through a digital input/output (DIO) port and controlled the pressure regulator that actuated the pneumatic pistons via a digital-to-analog converter (DAC) port. For the self-release mechanism, the output from the load cell was amplified (HX711, SparkFun) and read by the master controller through a DIO port (sampled at 20 Hz). To position the lickport and the pole, the master controller interfaced with the motors through DIO ports.</p><p>A second ‘task’ controller controlled individual behavioral trials using finite state machines with high temporal resolution (0.1 ms, adapted from the open-source Bpod project <ext-link ext-link-type="uri" xlink:href="https://github.com/sanworks/Bpod_StateMachine_Firmware">https://github.com/sanworks/Bpod_StateMachine_Firmware</ext-link>; <xref ref-type="bibr" rid="bib66">Sanders, 2018</xref>). The task controller was triggered by the master controller. Before each trial, the master controller generated a finite state machine and sent the state matrix to the task controller to execute. The task controller actuated the air piston that presented the pole and the solenoid valves that delivered reward through solid state relays (DMO063, Mouser). The task controller also actuated the piezo buzzer for the ‘go’ cue via a pulse width modulation (PWM) port. The task controller read licking events (TTL high logic) from the lick detection circuit board.</p><p>Finally, a third ‘wave’ controller was used to generate custom waveforms to drive the optogenetic components, including the masking flash LED (through an LED driver, SS25S075, SparkFun) and a red laser (through a high-precision DAC, MCP4725, Adafruit). The ‘wave’ controller received meta information from the master controller that specified the output waveform (e.g. amplitude) before each trial, but the output was triggered by the task controller during specific task epochs.</p><p>The home-cage system operated standalone. The master controller was equipped with a data logging shield (ID1141, Adafruit) and a real time clock (RTC) module to timestamp and store all behavioral data and training parameters on a SD card. Behavioral data included detailed information for each trial (e.g. trial number, trial type, trial outcome, licking events, etc.) and head-fixation events (e.g. switch trigger, head-fixation, release, etc.). Training parameters specified the current protocol and training progression. Behavioral data and training parameters were updated after each behavioral trial. Each mouse was associated with its own SD card that contained its behavioral data and training parameters. If interrupted, the home-cage system could resume training based on the training parameters stored on the SD card. In this manner, each mouse could switch between any home-cage systems using its unique SD card.</p></sec><sec id="s4-4-3"><title>Enclosure</title><p>The entire behavioral system was fit into an enclosure (560 × 250 × 230 mm) constructed with rails (XE25L, Thorlabs) and detachable acrylic boards (8505K745, McMaster). The top board of the enclosure was cut with an opening (170 × 170 mm) to provide light access during light cycles. The opening was protected with a mesh screen. The enclosed system was standalone and powered by a 12 V power supply (for Arduino microcontrollers), a 24 V power supply (for solenoid valve and analog pressure regulator), a 4 bar air supply (for the pneumatics and analog pressure regulator). In addition, each system has an optional USB cable (from the master controller) to stream real-time data for display on a PC (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>). However, the system could operate without the PC display. Multiple systems could be connected to a single PC through a USB hub (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>).</p></sec></sec><sec id="s4-5"><title>Autonomous training and optogenetic testing protocols</title><p>Three separate protocols (‘head-fixation training’, ‘task training’ and ‘optogenetics’) on the master controller autonomously trained mice in voluntary head-fixation and the tactile decision-making task, as well as carrying out optogenetic testing.</p><sec id="s4-5-1"><title>Head-fixation training protocol</title><p>Head-fixation training had two subprotocols. A ‘headport entry’ subprotocol lured mice into the headport and acclimated them to headport entry. A second ‘head-fixation’ subprotocol acclimated mice to head immobilization (<xref ref-type="fig" rid="fig2">Figure 2E</xref>).</p><p>The headport entry subprotocol started by placing the lickport close to the headport with the two lickspouts inside the home-cage. Mice could lick both lickspouts freely. However, only licking the rewarded lickspout led to a water reward. Licks on the other lickspout were ignored. The rewarded lickspout alternated between the two lickspouts (three times each) to encourage licking on both lickspouts. This phase of the training acclimated mice to the lickport. After every 20 rewarded licks, the lickport was retracted one step (3 mm) away from the home-cage. The lickport retraction continued until the tip of the lickspouts was approximately 14 mm away from the headport. At this point, mice could only reach the lickspouts by entering the headport with the headbar reaching the end of the guide tracks (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). This reliably triggered the mechanical switches at the end of the tracks. If mice failed to trigger the switches when the lickport was fully retracted, or if no licks were detected in 12 hr, these scenarios typically indicated that mice were not lured into the headport. In these cases, the headport entry subprotocol would re-extend the lickport toward to the home-cage to lure mice in again (<xref ref-type="fig" rid="fig2">Figure 2E</xref>). After the mechanical switches were triggered 30 times, the training advanced to the head-fixation subprotocol (<xref ref-type="fig" rid="fig2">Figure 2E</xref>).</p><p>The head-fixation subprotocol started by turning on the pneumatic pistons and the head-fixation control logics. Whenever the switches were triggered, the pneumatic pistons were activated to clamp the headbar. The clamps were released under three scenarios: (1) ‘time-up release’, when head-fixation lasted for a predefined duration; (2) ‘escape’, when the switches were no longer triggered by the mice, (‘escape’ occurred when mice quickly pulled out from the headport before the pistons could clamp the headbar); (3) ‘self-release’, when the weight readings from the load-sensing platform exceeded a threshold. Head-fixations reduced the weight load on the platform, and overt movements of the mouse typically produced large fluctuations in weight readings (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). We set two thresholds at −1 and 30 g to robustly detect any struggles, that is whenever the weight readings fell below −1 g or exceeded 30 g, the clamps were released. These thresholds were dynamically adjusted during the training process: if there were too many self-releases (&gt;90% of the head-fixations), the upper threshold would increase by 2 g and the lower threshold would decrease by 2 g (increasing the range); conversely, if there were too few self-releases (&lt;5%), the upper threshold would decrease by 2 g and the lower threshold would increase by 2 g (decreasing the range). The thresholds were adjusted based on the last 20 head-fixations.</p><p>Initially, head-fixation started with a ‘soft clamp’ mode (pistons pressure 1.78 bar) and each head-fixation lasted for a short duration (time-up release, 3 s). The duration was increased by 2 s after every 20 successfully head-fixations (i.e., time-up release). After the duration reached 10 s, head-fixation switched to a ‘hard clamp’ mode. In the hard clamp mode, each head-fixation started with low pressure (1.78 bar), but the pressure increased to 2.78 bar after the first 2 s of fixation. At the end of each head-fixation, if the mouse did not pull out from the headport after the pistons were release (i.e., the switches remained triggered), the next head-fixation would initiate. The head-fixation training subprotocol completed when the fixation duration reached 30 s (<xref ref-type="fig" rid="fig2">Figure 2E</xref>), and the master controller automatically advanced to the task training protocols. From this point onward, the head-fixation control logics ran continuously.</p><p>Importantly, we found it necessary to acclimate mice with task stimuli during head-fixation training, well before task training started (see below). Introducing novel stimuli after head-fixation training often caused an increase in self-release rate and reduced the number of head-fixations, which hindered task training. To circumvent this issue, we introduced the tactile stimulus and the auditory ‘go’ cue at the beginning of the headport entry subprotocol. Specifically, the pole was presented to touch the whiskers at the locations corresponding to the rewarded lickspout. Water reward was only given for the first lick on the rewarded lickspout after the ‘go’ cue sound.</p></sec><sec id="s4-5-2"><title>Task training protocol</title><p>We trained mice in a tactile decision task with a short-term memory component. Mice used their whiskers to discriminate the location of a pole and reported choice using directional licking for a water reward (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, anterior pole position→lick left, posterior pole position→lick right) (<xref ref-type="bibr" rid="bib31">Guo et al., 2014b</xref>; <xref ref-type="bibr" rid="bib30">Guo et al., 2014a</xref>). The pole was presented at one of two positions that were 6 mm apart along the anterior-posterior axis. The posterior pole position was approximately 5 mm from the whisker pad. The pole was always presented to the right whiskers. In each head-fixation, mice were tested in a succession of trials. At the beginning of each trial, the pole moved into reach of the whiskers (0.2 s travel time), where it remained for 1 s, after which it was retracted (retraction time 0.2 s). The sample epoch was defined as the time between the pole movement onset to 0.1 s after the pole retraction onset (sample epoch, 1.3 s). A delay epoch followed, during which the mice must keep the information in short-term memory (delay epoch, 1.3 s). An auditory ‘go’ cue (pure tone, 3.5 kHz, 0.1 s duration) signaled the beginning of response epoch and mice reported choice by licking one of the two lickspouts. Each trial was followed by an inter-trial-interval (2.5 s), after which the next trial began, until the head-fixation is released (<xref ref-type="video" rid="video1">Video 1</xref>).</p><p>Task training had three subprotocols that shaped mice behavior in stages (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). First, a ‘directional licking’ subprotocol trained mice to lick both lickspouts and switch between the two. Then, a ‘discrimination’ subprotocol taught mice to report pole position with directional licking. Finally, a ‘delay’ subprotocol taught mice to withhold licking during the delay epoch and initiate licking upon the ‘go’ cue.</p><p>The directional licking subprotocol started immediately after mice completed the head-fixation training. Lick left or lick right trials were presented consecutively. Mice had to obtain three trials correct before the program switched to the other trial type. At this stage of the training, the pole was presented for 1.3 s and a short delay epoch (200 ms) was included but not enforced. Mice were free to lick at any time during the trial, but only the first lick after the ‘go’ cue were registered as choice. Licking the correct lickspout after the ‘go’ cue led to water reward (2–3 µL). Licking the incorrect lickspout triggered a timeout (2 s). Trials in which mice did not lick within a 1.5 s window after the ‘go’ cue were counted as ignores.</p><p>The discrimination subprotocol started once mice reached 70% correct in the directional licking subprotocol (assessed over 30 trials). All aspects of the task remained the same, but the lick left and lick right trials were presented in random order. Several auto-assist programs tracked mice’s performance and occasionally adjusted the probability of each trial type (see <italic>Auto-assist programs</italic>). In addition, licking the incorrect lickspout triggered a longer timeout (4 s).</p><p>The delay subprotocol started once mice reached 75% correct in the discrimination subprotocol. At this stage, licking before the ‘go’ cue triggered a brief pause (0.1 s). After the pause, the program resumed the trial from the beginning of the epoch in which the early lick occurred (sample or delay). This constituted an additional timeout. However, the mouse could still complete the trial to obtain a reward if it licked the correct lickspout after the ‘go’ cue. Initially, the delay epoch was brief (0.3 s). The duration of the delay epoch increased by 0.2 s every time mice reached 70% correct performance. The delay subprotocol ended when the delay epoch duration reached 1.3 s.</p><p>At the end of the delay subprotocol, the head-fixation duration was further increased from 30 to 60 s. The duration was increased by 2 s after every 20 successfully head-fixations. This was done to obtain more behavioral trials in each head-fixation.</p></sec><sec id="s4-5-3"><title>Auto-assist programs</title><p>During task training, mice often developed idiosyncratic biases by licking one lickspout more frequently or continuously licking one lickspout without switching to the other. We implemented four different ‘auto-assist’ programs to counter these behavioral patterns (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). These auto-assist programs evaluated mice performance continuously and assisted mice whenever behavioral biases were detected.</p><p>First, if a bias developed (i.e. performance difference between the two trial types exceeded 30% in the last 50 trials or exceeded 80% in the last 20 trials), the left/right motor moved the lickport such that the non-preferred lickspout was closer to the mouse. Second, if a mouse made five consecutive errors in one trial type, a free water reward was delivered to the rewarded lickspout in the next trial. This motivated the mouse to lick the rewarded lickspout. Third, the program calculated behavioral performance in the last 30 trials and the trial type with worse performance was presented more frequently. Finally, if a mouse made three consecutive errors in one trial type, the program would keep presenting the same trial type until the mouse got two trials correct.</p></sec><sec id="s4-5-4"><title>Contingency reversal learning</title><p>Mice were trained in the tactile decision task without a delay epoch. The training protocol is the same as described above, with the exception that the delay subprotocol was not included. Mice always learned the standard contingency first where posterior pole position corresponded to lick right and anterior pole position corresponded to lick left. Once performance was &gt;80% correct for 100 trials, the correspondence between pole locations and lick directions were reversed. Mice did not receive any cues about the reversal other than reward feedbacks: correct responses led to rewards and incorrect responses led to timeouts. The new contingency remained in place until mice reached 80% correct, upon which the continency was reversed again.</p></sec><sec id="s4-5-5"><title>Optogenetics protocol</title><p>The optogenetics protocol was manually initiated by experimenters based on inspections of behavioral performance (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1B</xref>). In the optogenetics protocol, photostimulation was given in a random subset of trials (10%) during the sample, delay, or response epoch. Photostimulation power was randomly selected (see <italic>Optogenetic experiments</italic>). In addition, a masking flash (10 Hz) was given on all trials. Masking flash began at the start of the sample epoch and continued through the end of the response epoch in which photostimulation could occur.</p></sec></sec><sec id="s4-6"><title>Measuring head-fixation stability</title><p>To measure the repositioning of the headbar across multiple head-fixations, we used a CMOS camera (CM3-U3-13Y3M, FLIR) to measure the displacements of the clear skull implant. To measure the displacements in the rostral-caudal and medial-lateral directions, the camera was placed over the headport (pixel resolution, 52.6 µm/pixel). To measure the displacement in the dorsal-ventral direction, we glued a small plastic marker on the clear skull implant and placed the camera in front of the headport (pixel resolution, 78.1 µm/pixel) to measure the vertical displacement of the marker. Across 16 different head-fixations, 10 images were acquired at random time points during each head-fixation.</p><p>To determine the displacement, we selected small regions of interest (ROIs, 30 × 30 pixels) on the clear skull implant or the marker (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). For each ROI, we computed 2D cross-correlations for every possible image pairs across the 16 different head-fixations (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A</xref>). Cross-correlation (<italic>xcorr2</italic> function, MATLAB) always produced zero-pixel shift, indicating that any displacement was at a subpixel scale. We thus employed a subpixel image registration algorithm (<xref ref-type="bibr" rid="bib29">Guizar-Sicairos et al., 2008</xref>), which measured 2D rigid translation for a small fraction of pixels to calculate the displacements. Displacements in the rostral-caudal/medial-lateral directions and the dorsal-ventral direction were quantified separately since it involved different camera configurations. Displacements were calculated for multiple ROIs (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A–F</xref>). <xref ref-type="fig" rid="fig2">Figure 2I</xref> shows the displacements pooled across all ROIs (mean, 8.8, 6.4, and 12.1 µm in rostral-caudal, medial-lateral, and dorsal-ventral direction). The mean and SD were calculated on the absolute values of the displacement.</p><p>To verify that the subpixel algorithm captured the displacements accurately, we also selected a ROI on the wall of the headport. The ROI on the wall of the headport showed little displacement (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1G</xref>; mean, 2.07 and 1.10 µm in rostral-caudal/medial-lateral directions). We also selected a ROI containing the mouse’s whiskers. The ROI on whiskers showed large displacement (<xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1H</xref>; mean, 266 and 351 µm in rostral-caudal/medial-lateral directions).</p></sec><sec id="s4-7"><title>Manual behavioral training</title><p>The procedures for manual behavioral training have been described previously (<xref ref-type="bibr" rid="bib31">Guo et al., 2014b</xref>). Mice were manually acclimated to head-fixation and tested in daily sessions that lasted 1–2 hr. The training started by rewarding mice for simply licking the lickspouts. The auditory ‘go’ cue was played immediately before water delivery.</p><p>After mice learned to lick for water (~60 rewards), the reward scheme was changed to teach mice to sample both lickspouts (similar to the directional licking training protocol in home-cage training). Only one lickspout held a water reward and the rewarded lickspout alternated after three rewards. Occasionally, manual water delivery was necessary to prompt mice to lick from the other lickport. In addition, the rewarded lickspout was moved closer to the mouse in each trial to encourage licking. Gradually, the movement of the lickport was reduced and the lickport eventually remained in a fixed center position. During this phase of the training, the vertical pole was also presented at the position corresponding to the rewarded lickport (anterior pole position→lick left, posterior pole position→lick right). Presentation of the pole allowed mice to gradually associate the pole position with the rewarded lickspout.</p><p>Once mice reliably switched licking between lickspouts, object location discrimination task started (equivalent to the discrimination training protocol in home-cage training). In this stage of the training, the two trial types were presented in random order and the task did not include a delay epoch. Mice were free to lick at any time during the trial, but only the first lick after the ‘go’ cue were registered as choice. Correct choice led to a water reward. Incorrect choice led to a time out.</p><p>After mice reached performance criterion (&gt;70% correct), the delay epoch was introduced. Licking before the ‘go’ cue triggered an alarm sound from a siren buzzer and a brief timeout. The delay epoch was initially short (0.3 s) and gradually increased to 1.3 s.</p></sec><sec id="s4-8"><title>Optogenetic experiments</title><p>For mice tested in unsupervised optogenetic experiments (see <italic>Optogenetics protocol</italic>), light from a 633 nm laser (MRL-III-633–50, Ultralaser) or 625 nm LED (M625F2, Thorlabs) was delivered via an optical fiber (M79L005, Thorlabs) above the headport. The photostimulus was a 40 Hz sinusoid lasting for 1.3 s, including a 100 ms linear ramp during photostimulus offset to reduce rebound neuronal activity (<xref ref-type="bibr" rid="bib30">Guo et al., 2014a</xref>; <xref ref-type="bibr" rid="bib45">Li et al., 2019</xref>). Photostimulation started at the beginning of the sample, delay, or response epoch. We used average power of 5–50 mW at the fiber tips, which corresponded to light intensity of 0.3–3.5 mW/mm<sup>2</sup> given the size of the light beam on the surface of the skull.</p><p>For mice tested in photoinhibition of vS1 and ALM, we subsequently tested them in manual optogenetic experiments. In daily sessions, mice were manually head-fixed and tested by an experimenter on an electrophysiology setup. The light source and light delivery were the same as the home-cage optogenetic experiments. The size of the light beam on the brain surface was also matched. To prevent the mice from distinguishing photostimulation trials from control trials using visual cues, a masking flash was delivered using 627 nm LEDs (Luxeon Star) near the eyes of the mice. The masking flash began at the start of the sample epoch and continued through the end of the response epoch in which photostimulation could occur.</p></sec><sec id="s4-9"><title>Behavioral data analysis</title><p>The duration of each head-fixation was calculated as the interval between the onset of the piston clamps and the following release (<xref ref-type="fig" rid="fig2">Figure 2</xref>). The inter-fixation-interval was calculated as the interval between a release and the next head-fixation (<xref ref-type="fig" rid="fig2">Figures 2L</xref> and <xref ref-type="fig" rid="fig6">6</xref>). Performance was computed as the percentage of correct choices. Mice that never exceeded 70% correct after 35–40 days of training were deemed as unsuccessful in task training. To quantify the effect of photostimulation, we also separately computed performance for lick left and lick right trials. Chance performance was 50%.</p><p>Behavioral effects of photostimulation for each mouse were quantified by comparing its performance under photostimulation with control trials. The within-mouse performance changes were then averaged across mice. Significance of the average performance change in each photostimulation condition was determined using a nested bootstrap to account for variability across mice, sessions, and trials. We tested against the null hypothesis that the average performance change caused by photostimulation was due to normal behavioral variability. In each round of bootstrap, we generated a resampled dataset by first resampling (with replacement) the mice included in the analysis. We then resampled (with replacement) the sessions of each mouse. For each session, we then resampled (with replacement) the trials in the session. We computed the performance change on the resampled dataset. Repeating this procedure 10,000 times produced a distribution of performance changes that reflected the behavioral variability. The p value of the observed performance change was computed as fraction of times the bootstrap produced an inconsistent performance change (e.g. if a performance decrease was observed during photostimulation, the p value is the fraction of times a performance increase was observed during bootstrap, one-tailed test). In this bootstrap analysis, each day (dark +light cycle) in the home-cage optogenetic experiments was treated as a ‘session’.</p></sec><sec id="s4-10"><title>Logistic regression model of behavioral data</title><p>We used a logistic regression model to predict mice’s choice. The probability of choice in the current trial, <italic>P(left</italic>), was a logistic function of the weighted sum of several behavioral and task variables. The variables are the tactile stimulus in the current trial (<italic>S<sub>0</sub></italic>, 1 for lick left trial, -1 for lick right trial), the tactile stimuli in the last five trials (<italic>S<sub>1</sub></italic> to <italic>S<sub>5</sub></italic>), choice in the last five trials (<italic>A<sub>1</sub></italic> to <italic>A<sub>5</sub></italic>, 1 for licking left, -1 for licking right), reward outcomes in the last five trials (<italic>R<sub>1</sub></italic> to <italic>R<sub>5</sub></italic>, 1 for rewarded, -1 for unrewarded), the average stimuli in the last 20 trials (<italic>S<sub>avg</sub></italic> =<inline-formula><mml:math id="inf1"><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>20</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:mn>20</mml:mn></mml:math></inline-formula>), a win-stay-lose-switch strategy (<italic>WSLS</italic> = <italic>A<sub>1</sub></italic>×<italic>R<sub>1</sub></italic>), and a constant bias term <inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>. The model was defined by the following equations:<disp-formula id="equ1"><mml:math id="m1"><mml:mi>P</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mo>(</mml:mo><mml:mi>z</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:math></disp-formula><disp-formula id="equ2"><mml:math id="m2"><mml:mi>z</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>A</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>g</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mi>v</mml:mi><mml:mi>g</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mi>W</mml:mi><mml:mi>S</mml:mi><mml:mi>L</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:msub><mml:mi>W</mml:mi><mml:mi>S</mml:mi><mml:mi>L</mml:mi><mml:mi>S</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></disp-formula>where the β’s were the weights for the regressors. <italic>P(left</italic>)&gt;0.5 predicted licking left and <italic>P(left</italic>)&lt;0.5 predicted licking right.</p><p>For each mouse, we built separate logistic regression models at different stages of learning. The behavioral trials were concatenated in time, that is, across multiple head-fixations for home-cage training and across multiple sessions for manual training. We used a sliding window of 500 trials (in 100-trial steps). In each window, the model was fit to the behavioral choice data using a gradient descent algorithm to maximize the likelihood estimation cost function (<italic>glmfit</italic>, MATLAB). The model performance was evaluated using 5-fold cross validation. In each round of cross validation, 60 consecutive trials and their history data (the 20 trials before) were selected as the test set. A total of 400 trials were used as the training set while excluding the 20 trials before and 20 trials after the block of trials used as the test dataset. This ensured absolute independence of the training and test data since the logistic regression model used trial history data as its input. This cross-validation procedure was repeated nine times and the prediction performance was averaged. To quantify the model prediction performance, we computed the fraction of trials in which the model correctly predicted choice in the test dataset.</p><p>During home-cage training, mice first underwent the ‘directional licking’ subprotocol that presented the same trial type in blocks to teach the mice to lick both lickspouts (see <italic>Task training protocol</italic>). This phase of the training could introduce dependencies of choice on the choice history. Thus, the logistic regression analysis was performed only on behavioral data after mice advanced to the ‘discrimination’ phase of the training in which both trial types were presented randomly. For behavioral data from manual training, the logistic regression analysis started at an equivalent time point (see <italic>Manual behavioral training)</italic>.</p><p>To quantify the contribution of each regressor, we constructed partial models in which specific regressors were removed from the full model. Specifically, we set the weight (β) of the regressor to zero and determined whether the prediction performance of the partial model was significantly worse than the full model (<xref ref-type="bibr" rid="bib20">Engelhard et al., 2019</xref>). To assess statistical significance, we used bootstrap (<xref ref-type="bibr" rid="bib19">Efron and Tibshirani, 1994</xref>) in which the test dataset was resampled with replacement 1000 times and the p value was computed as the fraction of times in which the partial model produced a better performance than the full model (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). In <xref ref-type="fig" rid="fig4">Figure 4E</xref>, if a regressor was significant (p&lt;0.05) in five consecutive time windows (1000 trials), the mouse was deemed to rely on this regressor during task learning. As a control, we also tested the full model fit to a shuffled dataset (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). To generate the shuffled dataset, we shuffled the choice across trials while maintaining the stimulus and reward history. Model fitting and testing on the shuffled dataset was computed using the same cross validation procedure described above. To examine whether the tactile stimulus (S<sub>0</sub>) and choice history (A<sub>1</sub>) were sufficient to account choice prediction of the full model, we tested a reduced model which only included the two regressors and a constant bias term (<inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>β</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>) (<xref ref-type="fig" rid="fig4">Figure 4C</xref>).</p></sec><sec id="s4-11"><title>Electrophysiology</title><p>To characterize photoinhibition in cortex, we injected 200 nL of AAV9-hSyn-FLEX-ChrimsonR-tdTomato viruses into the left barrel cortex (bregma posterior 1.5 mm, 3.5 mm lateral, 0.4 and 0.8 mm deep) of GAD2-IRES-Cre mice. To characterize the effect of photostimulation in the striatum, we injected 100 nL of AAV8-Ef1a-DIO-ChRmine-mScarlet-WPRE viruses into the left striatum (bregma posterior 0.6 mm, 2.4 mm lateral, 2.2 mm deep) of GAD2-IRES-Cre mice. To characterize photoinhibition in the superior colliculus, we injected 200 nL of AAV8-Ef1a-DIO-ChRmine-mScarlet-WPRE viruses into the left superior colliculus (bregma posterior 3.5 mm, 1.5 mm lateral, 2.2 mm deep) of GAD2-IRES-Cre mice.</p><p>Three weeks after the virus injection, we recorded extracellular spikes using 64-channel silicon probes (H2 probes, Cambridge Neurotech) near the injection site. A small craniotomy (diameter,&lt;1 mm) was made one day before the recording session. During the recording session, the silicon probe was acutely inserted into the brain. To minimize brain movement, a drop of silicone gel (3–4680, Dow Corning) was applied over the craniotomy after the electrode was in the tissue. The tissue was allowed to settle for several minutes before the recording started. For recordings in the barrel cortex, the silicon probe was inserted 0.9–1.11 mm below the brain surface. For recordings in the striatum and superior colliculus, multiple recordings were obtained at a range of depths along a penetration (insertion depths, 2.3–3.5 mm). Recording depth was inferred from manipulator depth and verified with histology (<xref ref-type="fig" rid="fig8">Figure 8A and I</xref>). The voltage signals were amplified and digitized on an Intan RHD2164 64-Channel Amplifier Board (Intan Technology) at 16 bit, recorded on an Intan RHD2000-Series Amplifier Evaluation System (sampling at 20,000 Hz), and stored for offline analysis.</p><p>Photostimulation was performed by directing a laser beam over the surface of the brain (<xref ref-type="bibr" rid="bib30">Guo et al., 2014a</xref>). The light source and light delivery were the same as the home-cage optogenetic experiments. Photostimulation was delivered in approximately 7 s intervals. The mice were awake but not engaged in any task. The power was chosen randomly from a predefined set. We used average power of 0.5, 1.2, 3, 5, 10 and 14.5 mW, which corresponded to light intensity of 0.28, 0.68, 1.7, 2.83, 5.66, 8.21 mW/mm<sup>2</sup> given the size of the light beam measured at the surface of the skull.</p></sec><sec id="s4-12"><title>Electrophysiology data analysis</title><p>The extracellular recording traces were band-pass filtered (300–6,000 Hz). Spike events that exceeded four SDs of the background were subjected to manual spike sorting (<xref ref-type="bibr" rid="bib30">Guo et al., 2014a</xref>). 171 single-units were obtained in the barrel cortex. A total of 348 single-units were obtained in the striatum and 170 single-units were obtained in the superior colliculus.</p><p>In cortex, fast-spiking (FS) neurons and pyramidal neurons could be putatively distinguished based on spike waveform. Spike widths were computed as the trough-to-peak interval in the mean spike waveform (<xref ref-type="fig" rid="fig7">Figure 7C</xref>). Units with spike width &lt;0.55 ms were defined as putative FS neurons (14/171) and units with spike widths &gt; 0.55 ms as putative pyramidal neurons (157/171). In the striatum and superior colliculus, cell types were not distinguished based on spike waveform. Instead, we separately analyzed neurons that were significantly excited or inhibited by photostimulation (<xref ref-type="fig" rid="fig8">Figure 8D and L</xref>).</p><p>For each neuron, we computed spike rates during the photostimulus and a baseline period (500 ms time before photostimulus onset). Significant spike rate change was tested using two-tailed t-test (<xref ref-type="fig" rid="fig7">Figures 7C</xref>, <xref ref-type="fig" rid="fig8">8C, E and K</xref>). To quantify the effect size of photostimulation, we calculated a ‘relative firing rate’. The spike rates during photostimulation were normalized by dividing the baseline spike rate. The relative firing rate reported the spike rate modulation during photostimulation.</p></sec><sec id="s4-13"><title>Histology</title><p>Mice were deeply anaesthetized with isoflurane and transcranially perfused with PBS followed by 4% paraformaldehyde (PFA). The brains were removed and post-fixed in 4% PFA for 24 hr before transferring to 30% sucrose. 100 μm coronal sections were cut and imaged on a fluorescence macroscope (Olympus MVX10). We aligned each coronal section to the Allen Mouse Common Coordinate Framework (CCF) (<xref ref-type="bibr" rid="bib80">Wang et al., 2020</xref>) using landmark-based image registration. The registration target was the 10 μm per voxel CCF anatomical template. To align a coronal section, we first manually selected the coronal plane in the anatomical template that best corresponded to the section. We then manually placed control points at corresponding local landmarks in each image. Thirty to fifty control points were placed in a single image. Next, the image was warped to the CCF using an affine transformation followed by a non-rigid transformation using b-splines (<xref ref-type="bibr" rid="bib26">Gao et al., 2018</xref>).</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We are grateful to Karl Deisseroth, James Marshel, and Stanford Neurosciences Institute Viral Core for sharing the AAV8-Ef1a-DIO-ChRmine-mScarlet-WPRE virus. We thank Ben Scott, Hidehiko Inagaki, Jia Zhu, and Guang Chen for valuable comments on the manuscript, Kaiwen Wu for pilot work on software development, Kunxun Qian for pilot work on logistic regression analysis, Jing Lin for hardware support, Sri Laasya Tipparaju for animal care and histology, and Weiguo Yang for animal weight data. This work was funded by the Robert and Janice McNair Foundation, Whitehall Foundation, Alfred P Sloan Foundation, Searle Scholars Program, Pew Scholars Program, NIH NS112312, NS104781, NS113110, Simons Collaboration on the Global Brain (543005), and McKnight Foundation.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Investigation, Writing - review and editing, AMT performed early experiments that identified the region of interest in the superior colliculus</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: All procedures were performed in accordance with protocols approved by the Institutional Animal Care and Use Committees at Baylor College of Medicine (protocol AN7012). All surgical procedures were carried out aseptically under 1-2% isoflurane anesthesia. Buprenorphine Sustained Release (1 mg/kg) and Meloxicam Sustained Release (4mg/kg) were used for pre- and post-operative analgesia.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Comparison with previous automated home-cage training systems with voluntary head-fixation.</title></caption><media mime-subtype="docx" mimetype="application" xlink:href="elife-66112-supp1-v2.docx"/></supplementary-material><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-66112-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>All hardware design files and software for the construction of automated home-cage system are made available, along with documentations and protocols for automated head-fixation training and task training. Source data and code are also available at the same Github repository (<ext-link ext-link-type="uri" xlink:href="https://github.com/NuoLiLabBCM/Autocage">https://github.com/NuoLiLabBCM/Autocage</ext-link>).</p><p>The following dataset was generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><name><surname>Li</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2021">2021</year><data-title>Autocage version 1.0: Release for Zenodo.</data-title><source>Zenodo</source><pub-id assigning-authority="Zenodo" pub-id-type="doi">10.5281/zenodo.4716811</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Aguillon-Rodriguez</surname> <given-names>V</given-names></name><name><surname>Angelaki</surname> <given-names>DE</given-names></name><name><surname>Bayer</surname> <given-names>HM</given-names></name><name><surname>Bonacchi</surname> <given-names>N</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Cazettes</surname> <given-names>F</given-names></name><name><surname>Chapuis</surname> <given-names>GA</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name><name><surname>Dan</surname> <given-names>Y</given-names></name><name><surname>Dewitt</surname> <given-names>EE</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A standardized and reproducible method to measure decision-making in mice</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.01.17.909838</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allen</surname> <given-names>WE</given-names></name><name><surname>Chen</surname> <given-names>MZ</given-names></name><name><surname>Pichamoorthy</surname> <given-names>N</given-names></name><name><surname>Tien</surname> <given-names>RH</given-names></name><name><surname>Pachitariu</surname> <given-names>M</given-names></name><name><surname>Luo</surname> <given-names>L</given-names></name><name><surname>Deisseroth</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Thirst regulates motivated behavior through modulation of brainwide neural population dynamics</article-title><source>Science</source><volume>364</volume><elocation-id>253</elocation-id><pub-id pub-id-type="doi">10.1126/science.aav3932</pub-id><pub-id pub-id-type="pmid">30948440</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aoki</surname> <given-names>R</given-names></name><name><surname>Tsubota</surname> <given-names>T</given-names></name><name><surname>Goya</surname> <given-names>Y</given-names></name><name><surname>Benucci</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>An automated platform for high-throughput mouse behavior and physiology with voluntary head-fixation</article-title><source>Nature communications</source><volume>8</volume><elocation-id>1196</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-017-01371-0</pub-id><pub-id pub-id-type="pmid">29084948</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bernhard</surname> <given-names>SM</given-names></name><name><surname>Lee</surname> <given-names>J</given-names></name><name><surname>Zhu</surname> <given-names>M</given-names></name><name><surname>Hsu</surname> <given-names>A</given-names></name><name><surname>Erskine</surname> <given-names>A</given-names></name><name><surname>Hires</surname> <given-names>SA</given-names></name><name><surname>Barth</surname> <given-names>AL</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>An automated homecage system for multiwhisker detection and discrimination learning in mice</article-title><source>PLOS ONE</source><volume>15</volume><elocation-id>e0232916</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0232916</pub-id><pub-id pub-id-type="pmid">33264281</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bolaños</surname> <given-names>F</given-names></name><name><surname>LeDue</surname> <given-names>JM</given-names></name><name><surname>Murphy</surname> <given-names>TH</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Cost effective raspberry pi-based radio frequency identification tagging of mice suitable for automated in vivo imaging</article-title><source>Journal of neuroscience methods</source><volume>276</volume><fpage>79</fpage><lpage>83</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2016.11.011</pub-id><pub-id pub-id-type="pmid">27899319</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bollu</surname> <given-names>T</given-names></name><name><surname>Whitehead</surname> <given-names>SC</given-names></name><name><surname>Prasad</surname> <given-names>N</given-names></name><name><surname>Walker</surname> <given-names>J</given-names></name><name><surname>Shyamkumar</surname> <given-names>N</given-names></name><name><surname>Subramaniam</surname> <given-names>R</given-names></name><name><surname>Kardon</surname> <given-names>B</given-names></name><name><surname>Cohen</surname> <given-names>I</given-names></name><name><surname>Goldberg</surname> <given-names>JH</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Automated home cage training of mice in a hold-still center-out reach task</article-title><source>Journal of neurophysiology</source><volume>121</volume><fpage>500</fpage><lpage>512</lpage><pub-id pub-id-type="doi">10.1152/jn.00667.2018</pub-id><pub-id pub-id-type="pmid">30540551</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brody</surname> <given-names>CD</given-names></name><name><surname>Hanks</surname> <given-names>TD</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural underpinnings of the evidence accumulator</article-title><source>Current opinion in neurobiology</source><volume>37</volume><fpage>149</fpage><lpage>157</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2016.01.003</pub-id><pub-id pub-id-type="pmid">26878969</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burgess</surname> <given-names>CP</given-names></name><name><surname>Lak</surname> <given-names>A</given-names></name><name><surname>Steinmetz</surname> <given-names>NA</given-names></name><name><surname>Zatka-Haas</surname> <given-names>P</given-names></name><name><surname>Bai Reddy</surname> <given-names>C</given-names></name><name><surname>Jacobs</surname> <given-names>EAK</given-names></name><name><surname>Linden</surname> <given-names>JF</given-names></name><name><surname>Paton</surname> <given-names>JJ</given-names></name><name><surname>Ranson</surname> <given-names>A</given-names></name><name><surname>Schröder</surname> <given-names>S</given-names></name><name><surname>Soares</surname> <given-names>S</given-names></name><name><surname>Wells</surname> <given-names>MJ</given-names></name><name><surname>Wool</surname> <given-names>LE</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>High-Yield Methods for Accurate Two-Alternative Visual Psychophysics in Head-Fixed Mice</article-title><source>Cell reports</source><volume>20</volume><fpage>2513</fpage><lpage>2524</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2017.08.047</pub-id><pub-id pub-id-type="pmid">28877482</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burke</surname> <given-names>DA</given-names></name><name><surname>Rotstein</surname> <given-names>HG</given-names></name><name><surname>Alvarez</surname> <given-names>VA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Striatal Local Circuitry: A New Framework for Lateral Inhibition</article-title><source>Neuron</source><volume>96</volume><fpage>267</fpage><lpage>284</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.09.019</pub-id><pub-id pub-id-type="pmid">29024654</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cardin</surname> <given-names>JA</given-names></name><name><surname>Carlén</surname> <given-names>M</given-names></name><name><surname>Meletis</surname> <given-names>K</given-names></name><name><surname>Knoblich</surname> <given-names>U</given-names></name><name><surname>Zhang</surname> <given-names>F</given-names></name><name><surname>Deisseroth</surname> <given-names>K</given-names></name><name><surname>Tsai</surname> <given-names>LH</given-names></name><name><surname>Moore</surname> <given-names>CI</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Driving fast-spiking cells induces gamma rhythm and controls sensory responses</article-title><source>Nature</source><volume>459</volume><fpage>663</fpage><lpage>667</lpage><pub-id pub-id-type="doi">10.1038/nature08002</pub-id><pub-id pub-id-type="pmid">19396156</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Castelhano-Carlos</surname> <given-names>M</given-names></name><name><surname>Costa</surname> <given-names>PS</given-names></name><name><surname>Russig</surname> <given-names>H</given-names></name><name><surname>Sousa</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>PhenoWorld: a new paradigm to screen rodent behavior</article-title><source>Translational psychiatry</source><volume>4</volume><elocation-id>e399</elocation-id><pub-id pub-id-type="doi">10.1038/tp.2014.40</pub-id><pub-id pub-id-type="pmid">26126181</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname> <given-names>TW</given-names></name><name><surname>Li</surname> <given-names>N</given-names></name><name><surname>Daie</surname> <given-names>K</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A Map of Anticipatory Activity in Mouse Motor Cortex</article-title><source>Neuron</source><volume>94</volume><fpage>866</fpage><lpage>879</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.05.005</pub-id><pub-id pub-id-type="pmid">28521137</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chowdhury</surname> <given-names>SA</given-names></name><name><surname>DeAngelis</surname> <given-names>GC</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Fine discrimination training alters the causal contribution of macaque area MT to depth perception</article-title><source>Neuron</source><volume>60</volume><fpage>367</fpage><lpage>377</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.08.023</pub-id><pub-id pub-id-type="pmid">18957227</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chuong</surname> <given-names>AS</given-names></name><name><surname>Miri</surname> <given-names>ML</given-names></name><name><surname>Busskamp</surname> <given-names>V</given-names></name><name><surname>Matthews</surname> <given-names>GA</given-names></name><name><surname>Acker</surname> <given-names>LC</given-names></name><name><surname>Sørensen</surname> <given-names>AT</given-names></name><name><surname>Young</surname> <given-names>A</given-names></name><name><surname>Klapoetke</surname> <given-names>NC</given-names></name><name><surname>Henninger</surname> <given-names>MA</given-names></name><name><surname>Kodandaramaiah</surname> <given-names>SB</given-names></name><name><surname>Ogawa</surname> <given-names>M</given-names></name><name><surname>Ramanlal</surname> <given-names>SB</given-names></name><name><surname>Bandler</surname> <given-names>RC</given-names></name><name><surname>Allen</surname> <given-names>BD</given-names></name><name><surname>Forest</surname> <given-names>CR</given-names></name><name><surname>Chow</surname> <given-names>BY</given-names></name><name><surname>Han</surname> <given-names>X</given-names></name><name><surname>Lin</surname> <given-names>Y</given-names></name><name><surname>Tye</surname> <given-names>KM</given-names></name><name><surname>Roska</surname> <given-names>B</given-names></name><name><surname>Cardin</surname> <given-names>JA</given-names></name><name><surname>Boyden</surname> <given-names>ES</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Noninvasive optical inhibition with a red-shifted microbial rhodopsin</article-title><source>Nature neuroscience</source><volume>17</volume><fpage>1123</fpage><lpage>1129</lpage><pub-id pub-id-type="doi">10.1038/nn.3752</pub-id><pub-id pub-id-type="pmid">24997763</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crochet</surname> <given-names>S</given-names></name><name><surname>Lee</surname> <given-names>SH</given-names></name><name><surname>Petersen</surname> <given-names>CCH</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neural Circuits for Goal-Directed Sensorimotor Transformations</article-title><source>Trends in neurosciences</source><volume>42</volume><fpage>66</fpage><lpage>77</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2018.08.011</pub-id><pub-id pub-id-type="pmid">30201180</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deisseroth</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Optogenetics: 10 years of microbial opsins in neuroscience</article-title><source>Nature neuroscience</source><volume>18</volume><fpage>1213</fpage><lpage>1225</lpage><pub-id pub-id-type="doi">10.1038/nn.4091</pub-id><pub-id pub-id-type="pmid">26308982</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duan</surname> <given-names>CA</given-names></name><name><surname>Erlich</surname> <given-names>JC</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Requirement of Prefrontal and Midbrain Regions for Rapid Executive Control of Behavior in the Rat</article-title><source>Neuron</source><volume>86</volume><fpage>1491</fpage><lpage>1503</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.05.042</pub-id><pub-id pub-id-type="pmid">26087166</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Duan</surname> <given-names>CA</given-names></name><name><surname>Pan</surname> <given-names>Y</given-names></name><name><surname>Ma</surname> <given-names>G</given-names></name><name><surname>Zhou</surname> <given-names>T</given-names></name><name><surname>Nl</surname> <given-names>X</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A cortico-collicular pathway for motor planning in a memory-dependent perceptual decision task</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/709170</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Efron</surname> <given-names>B</given-names></name><name><surname>Tibshirani</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="1994">1994</year><source>An Introduction to the Bootstrap</source><edition>1</edition><publisher-loc>London, United Kingdom</publisher-loc><publisher-name>Chapman and Hall/CRC</publisher-name></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Engelhard</surname> <given-names>B</given-names></name><name><surname>Finkelstein</surname> <given-names>J</given-names></name><name><surname>Cox</surname> <given-names>J</given-names></name><name><surname>Fleming</surname> <given-names>W</given-names></name><name><surname>Jang</surname> <given-names>HJ</given-names></name><name><surname>Ornelas</surname> <given-names>S</given-names></name><name><surname>Koay</surname> <given-names>SA</given-names></name><name><surname>Thiberge</surname> <given-names>SY</given-names></name><name><surname>Daw</surname> <given-names>ND</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name><name><surname>Witten</surname> <given-names>IB</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Specialized coding of sensory, motor and cognitive variables in VTA dopamine neurons</article-title><source>Nature</source><volume>570</volume><fpage>509</fpage><lpage>513</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1261-9</pub-id><pub-id pub-id-type="pmid">31142844</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erlich</surname> <given-names>JC</given-names></name><name><surname>Bialek</surname> <given-names>M</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A cortical substrate for memory-guided orienting in the rat</article-title><source>Neuron</source><volume>72</volume><fpage>330</fpage><lpage>343</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.07.010</pub-id><pub-id pub-id-type="pmid">22017991</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erskine</surname> <given-names>A</given-names></name><name><surname>Bus</surname> <given-names>T</given-names></name><name><surname>Herb</surname> <given-names>JT</given-names></name><name><surname>Schaefer</surname> <given-names>AT</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>AutonoMouse: High throughput operant conditioning reveals progressive impairment with graded olfactory bulb lesions</article-title><source>PLOS ONE</source><volume>14</volume><elocation-id>e0211571</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0211571</pub-id><pub-id pub-id-type="pmid">30840676</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Felsen</surname> <given-names>G</given-names></name><name><surname>Mainen</surname> <given-names>ZF</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Neural substrates of sensory-guided locomotor decisions in the rat superior colliculus</article-title><source>Neuron</source><volume>60</volume><fpage>137</fpage><lpage>148</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.09.019</pub-id><pub-id pub-id-type="pmid">18940594</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Felsen</surname> <given-names>G</given-names></name><name><surname>Mainen</surname> <given-names>ZF</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Midbrain contributions to sensorimotor decision making</article-title><source>Journal of neurophysiology</source><volume>108</volume><fpage>135</fpage><lpage>147</lpage><pub-id pub-id-type="doi">10.1152/jn.01181.2011</pub-id><pub-id pub-id-type="pmid">22496524</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freund</surname> <given-names>J</given-names></name><name><surname>Brandmaier</surname> <given-names>AM</given-names></name><name><surname>Lewejohann</surname> <given-names>L</given-names></name><name><surname>Kirste</surname> <given-names>I</given-names></name><name><surname>Kritzler</surname> <given-names>M</given-names></name><name><surname>Krüger</surname> <given-names>A</given-names></name><name><surname>Sachser</surname> <given-names>N</given-names></name><name><surname>Lindenberger</surname> <given-names>U</given-names></name><name><surname>Kempermann</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Emergence of individuality in genetically identical mice</article-title><source>Science</source><volume>340</volume><fpage>756</fpage><lpage>759</lpage><pub-id pub-id-type="doi">10.1126/science.1235294</pub-id><pub-id pub-id-type="pmid">23661762</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gao</surname> <given-names>Z</given-names></name><name><surname>Davis</surname> <given-names>C</given-names></name><name><surname>Thomas</surname> <given-names>AM</given-names></name><name><surname>Economo</surname> <given-names>MN</given-names></name><name><surname>Abrego</surname> <given-names>AM</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name><name><surname>De Zeeuw</surname> <given-names>CI</given-names></name><name><surname>Li</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A cortico-cerebellar loop for motor planning</article-title><source>Nature</source><volume>563</volume><fpage>113</fpage><lpage>116</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0633-x</pub-id><pub-id pub-id-type="pmid">30333626</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilad</surname> <given-names>A</given-names></name><name><surname>Gallero-Salas</surname> <given-names>Y</given-names></name><name><surname>Groos</surname> <given-names>D</given-names></name><name><surname>Helmchen</surname> <given-names>F</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Behavioral strategy determines frontal or posterior location of Short-Term memory in neocortex</article-title><source>Neuron</source><volume>99</volume><fpage>814</fpage><lpage>828</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.07.029</pub-id><pub-id pub-id-type="pmid">30100254</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gold</surname> <given-names>JI</given-names></name><name><surname>Shadlen</surname> <given-names>MN</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Neural computations that underlie decisions about sensory stimuli</article-title><source>Trends in cognitive sciences</source><volume>5</volume><fpage>10</fpage><lpage>16</lpage><pub-id pub-id-type="doi">10.1016/s1364-6613(00)01567-9</pub-id><pub-id pub-id-type="pmid">11164731</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guizar-Sicairos</surname> <given-names>M</given-names></name><name><surname>Thurman</surname> <given-names>ST</given-names></name><name><surname>Fienup</surname> <given-names>JR</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Efficient subpixel image registration algorithms</article-title><source>Optics letters</source><volume>33</volume><fpage>156</fpage><lpage>158</lpage><pub-id pub-id-type="doi">10.1364/ol.33.000156</pub-id><pub-id pub-id-type="pmid">18197224</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname> <given-names>ZV</given-names></name><name><surname>Li</surname> <given-names>N</given-names></name><name><surname>Huber</surname> <given-names>D</given-names></name><name><surname>Ophir</surname> <given-names>E</given-names></name><name><surname>Gutnisky</surname> <given-names>D</given-names></name><name><surname>Ting</surname> <given-names>JT</given-names></name><name><surname>Feng</surname> <given-names>G</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014a</year><article-title>Flow of cortical activity underlying a tactile decision in mice</article-title><source>Neuron</source><volume>81</volume><fpage>179</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.10.020</pub-id><pub-id pub-id-type="pmid">24361077</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guo</surname> <given-names>ZV</given-names></name><name><surname>Hires</surname> <given-names>SA</given-names></name><name><surname>Li</surname> <given-names>N</given-names></name><name><surname>O'Connor</surname> <given-names>DH</given-names></name><name><surname>Komiyama</surname> <given-names>T</given-names></name><name><surname>Ophir</surname> <given-names>E</given-names></name><name><surname>Huber</surname> <given-names>D</given-names></name><name><surname>Bonardi</surname> <given-names>C</given-names></name><name><surname>Morandell</surname> <given-names>K</given-names></name><name><surname>Gutnisky</surname> <given-names>D</given-names></name><name><surname>Peron</surname> <given-names>S</given-names></name><name><surname>Xu</surname> <given-names>NL</given-names></name><name><surname>Cox</surname> <given-names>J</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2014">2014b</year><article-title>Procedures for behavioral experiments in head-fixed mice</article-title><source>PLOS ONE</source><volume>9</volume><elocation-id>e88678</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0088678</pub-id><pub-id pub-id-type="pmid">24520413</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hernández</surname> <given-names>A</given-names></name><name><surname>Nácher</surname> <given-names>V</given-names></name><name><surname>Luna</surname> <given-names>R</given-names></name><name><surname>Zainos</surname> <given-names>A</given-names></name><name><surname>Lemus</surname> <given-names>L</given-names></name><name><surname>Alvarez</surname> <given-names>M</given-names></name><name><surname>Vázquez</surname> <given-names>Y</given-names></name><name><surname>Camarillo</surname> <given-names>L</given-names></name><name><surname>Romo</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Decoding a perceptual decision process across cortex</article-title><source>Neuron</source><volume>66</volume><fpage>300</fpage><lpage>314</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.03.031</pub-id><pub-id pub-id-type="pmid">20435005</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hintiryan</surname> <given-names>H</given-names></name><name><surname>Foster</surname> <given-names>NN</given-names></name><name><surname>Bowman</surname> <given-names>I</given-names></name><name><surname>Bay</surname> <given-names>M</given-names></name><name><surname>Song</surname> <given-names>MY</given-names></name><name><surname>Gou</surname> <given-names>L</given-names></name><name><surname>Yamashita</surname> <given-names>S</given-names></name><name><surname>Bienkowski</surname> <given-names>MS</given-names></name><name><surname>Zingg</surname> <given-names>B</given-names></name><name><surname>Zhu</surname> <given-names>M</given-names></name><name><surname>Yang</surname> <given-names>XW</given-names></name><name><surname>Shih</surname> <given-names>JC</given-names></name><name><surname>Toga</surname> <given-names>AW</given-names></name><name><surname>Dong</surname> <given-names>HW</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The mouse cortico-striatal projectome</article-title><source>Nature neuroscience</source><volume>19</volume><fpage>1100</fpage><lpage>1114</lpage><pub-id pub-id-type="doi">10.1038/nn.4332</pub-id><pub-id pub-id-type="pmid">27322419</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hong</surname> <given-names>YK</given-names></name><name><surname>Lacefield</surname> <given-names>CO</given-names></name><name><surname>Rodgers</surname> <given-names>CC</given-names></name><name><surname>Bruno</surname> <given-names>RM</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Sensation, movement and learning in the absence of barrel cortex</article-title><source>Nature</source><volume>561</volume><fpage>542</fpage><lpage>546</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0527-y</pub-id><pub-id pub-id-type="pmid">30224746</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hooks</surname> <given-names>BM</given-names></name><name><surname>Papale</surname> <given-names>AE</given-names></name><name><surname>Paletzki</surname> <given-names>RF</given-names></name><name><surname>Feroze</surname> <given-names>MW</given-names></name><name><surname>Eastwood</surname> <given-names>BS</given-names></name><name><surname>Couey</surname> <given-names>JJ</given-names></name><name><surname>Winnubst</surname> <given-names>J</given-names></name><name><surname>Chandrashekar</surname> <given-names>J</given-names></name><name><surname>Gerfen</surname> <given-names>CR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Topographic precision in sensory and motor corticostriatal projections varies across cell type and cortical area</article-title><source>Nature communications</source><volume>9</volume><elocation-id>3549</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-05780-7</pub-id><pub-id pub-id-type="pmid">30177709</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunnicutt</surname> <given-names>BJ</given-names></name><name><surname>Jongbloets</surname> <given-names>BC</given-names></name><name><surname>Birdsong</surname> <given-names>WT</given-names></name><name><surname>Gertz</surname> <given-names>KJ</given-names></name><name><surname>Zhong</surname> <given-names>H</given-names></name><name><surname>Mao</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A comprehensive excitatory input map of the striatum reveals novel functional organization</article-title><source>eLife</source><volume>5</volume><elocation-id>e19103</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.19103</pub-id><pub-id pub-id-type="pmid">27892854</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kampff</surname> <given-names>AR</given-names></name><name><surname>Xie</surname> <given-names>K</given-names></name><name><surname>Agrochao</surname> <given-names>M</given-names></name><name><surname>Meister</surname> <given-names>M</given-names></name><name><surname>Olveczky</surname> <given-names>BP</given-names></name></person-group><year iso-8601-date="2010">2010</year><source>The voluntarily head-restrained rat</source><publisher-loc>In</publisher-loc><publisher-name>Society for Neuroscience Annual Meeting</publisher-name></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kawai</surname> <given-names>R</given-names></name><name><surname>Markman</surname> <given-names>T</given-names></name><name><surname>Poddar</surname> <given-names>R</given-names></name><name><surname>Ko</surname> <given-names>R</given-names></name><name><surname>Fantana</surname> <given-names>AL</given-names></name><name><surname>Dhawale</surname> <given-names>AK</given-names></name><name><surname>Kampff</surname> <given-names>AR</given-names></name><name><surname>Ölveczky</surname> <given-names>BP</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Motor cortex is required for learning but not for executing a motor skill</article-title><source>Neuron</source><volume>86</volume><fpage>800</fpage><lpage>812</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.024</pub-id><pub-id pub-id-type="pmid">25892304</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klapoetke</surname> <given-names>NC</given-names></name><name><surname>Murata</surname> <given-names>Y</given-names></name><name><surname>Kim</surname> <given-names>SS</given-names></name><name><surname>Pulver</surname> <given-names>SR</given-names></name><name><surname>Birdsey-Benson</surname> <given-names>A</given-names></name><name><surname>Cho</surname> <given-names>YK</given-names></name><name><surname>Morimoto</surname> <given-names>TK</given-names></name><name><surname>Chuong</surname> <given-names>AS</given-names></name><name><surname>Carpenter</surname> <given-names>EJ</given-names></name><name><surname>Tian</surname> <given-names>Z</given-names></name><name><surname>Wang</surname> <given-names>J</given-names></name><name><surname>Xie</surname> <given-names>Y</given-names></name><name><surname>Yan</surname> <given-names>Z</given-names></name><name><surname>Zhang</surname> <given-names>Y</given-names></name><name><surname>Chow</surname> <given-names>BY</given-names></name><name><surname>Surek</surname> <given-names>B</given-names></name><name><surname>Melkonian</surname> <given-names>M</given-names></name><name><surname>Jayaraman</surname> <given-names>V</given-names></name><name><surname>Constantine-Paton</surname> <given-names>M</given-names></name><name><surname>Wong</surname> <given-names>GK</given-names></name><name><surname>Boyden</surname> <given-names>ES</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Independent optical excitation of distinct neural populations</article-title><source>Nature methods</source><volume>11</volume><fpage>338</fpage><lpage>346</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2836</pub-id><pub-id pub-id-type="pmid">24509633</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kopec</surname> <given-names>CD</given-names></name><name><surname>Erlich</surname> <given-names>JC</given-names></name><name><surname>Brunton</surname> <given-names>BW</given-names></name><name><surname>Deisseroth</surname> <given-names>K</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Cortical and subcortical contributions to Short-Term memory for orienting movements</article-title><source>Neuron</source><volume>88</volume><fpage>367</fpage><lpage>377</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.08.033</pub-id><pub-id pub-id-type="pmid">26439529</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname> <given-names>J</given-names></name><name><surname>Wang</surname> <given-names>W</given-names></name><name><surname>Sabatini</surname> <given-names>BL</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Anatomically segregated basal ganglia pathways allow parallel behavioral modulation</article-title><source>Nature neuroscience</source><volume>23</volume><fpage>1388</fpage><lpage>1398</lpage><pub-id pub-id-type="doi">10.1038/s41593-020-00712-5</pub-id><pub-id pub-id-type="pmid">32989293</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewejohann</surname> <given-names>L</given-names></name><name><surname>Hoppmann</surname> <given-names>AM</given-names></name><name><surname>Kegel</surname> <given-names>P</given-names></name><name><surname>Kritzler</surname> <given-names>M</given-names></name><name><surname>Krüger</surname> <given-names>A</given-names></name><name><surname>Sachser</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Behavioral phenotyping of a murine model of Alzheimer's disease in a seminaturalistic environment using RFID tracking</article-title><source>Behavior research methods</source><volume>41</volume><fpage>850</fpage><lpage>856</lpage><pub-id pub-id-type="doi">10.3758/BRM.41.3.850</pub-id><pub-id pub-id-type="pmid">19587201</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>N</given-names></name><name><surname>Chen</surname> <given-names>TW</given-names></name><name><surname>Guo</surname> <given-names>ZV</given-names></name><name><surname>Gerfen</surname> <given-names>CR</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A motor cortex circuit for motor planning and movement</article-title><source>Nature</source><volume>519</volume><fpage>51</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1038/nature14178</pub-id><pub-id pub-id-type="pmid">25731172</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>N</given-names></name><name><surname>Daie</surname> <given-names>K</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name><name><surname>Druckmann</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Robust neuronal dynamics in premotor cortex during motor planning</article-title><source>Nature</source><volume>532</volume><fpage>459</fpage><lpage>464</lpage><pub-id pub-id-type="doi">10.1038/nature17643</pub-id><pub-id pub-id-type="pmid">27074502</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>N</given-names></name><name><surname>Chen</surname> <given-names>S</given-names></name><name><surname>Guo</surname> <given-names>ZV</given-names></name><name><surname>Chen</surname> <given-names>H</given-names></name><name><surname>Huo</surname> <given-names>Y</given-names></name><name><surname>Inagaki</surname> <given-names>HK</given-names></name><name><surname>Chen</surname> <given-names>G</given-names></name><name><surname>Davis</surname> <given-names>C</given-names></name><name><surname>Hansel</surname> <given-names>D</given-names></name><name><surname>Guo</surname> <given-names>C</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Spatiotemporal constraints on optogenetic inactivation in cortical circuits</article-title><source>eLife</source><volume>8</volume><elocation-id>e48622</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.48622</pub-id><pub-id pub-id-type="pmid">31736463</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname> <given-names>N</given-names></name><name><surname>Mrsic-Flogel</surname> <given-names>TD</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Cortico-cerebellar interactions during goal-directed behavior</article-title><source>Current opinion in neurobiology</source><volume>65</volume><fpage>27</fpage><lpage>37</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2020.08.010</pub-id><pub-id pub-id-type="pmid">32979846</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Licata</surname> <given-names>AM</given-names></name><name><surname>Kaufman</surname> <given-names>MT</given-names></name><name><surname>Raposo</surname> <given-names>D</given-names></name><name><surname>Ryan</surname> <given-names>MB</given-names></name><name><surname>Sheppard</surname> <given-names>JP</given-names></name><name><surname>Churchland</surname> <given-names>AK</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Posterior Parietal Cortex Guides Visual Decisions in Rats</article-title><source>Journal of Neuroscience</source><volume>37</volume><fpage>4954</fpage><lpage>4966</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0105-17.2017</pub-id><pub-id pub-id-type="pmid">28408414</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname> <given-names>JY</given-names></name><name><surname>Knutsen</surname> <given-names>PM</given-names></name><name><surname>Muller</surname> <given-names>A</given-names></name><name><surname>Kleinfeld</surname> <given-names>D</given-names></name><name><surname>Tsien</surname> <given-names>RY</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>ReaChR: a red-shifted variant of channelrhodopsin enables deep transcranial optogenetic excitation</article-title><source>Nature neuroscience</source><volume>16</volume><fpage>1499</fpage><lpage>1508</lpage><pub-id pub-id-type="doi">10.1038/nn.3502</pub-id><pub-id pub-id-type="pmid">23995068</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>Y</given-names></name><name><surname>Jacques</surname> <given-names>SL</given-names></name><name><surname>Azimipour</surname> <given-names>M</given-names></name><name><surname>Rogers</surname> <given-names>JD</given-names></name><name><surname>Pashaie</surname> <given-names>R</given-names></name><name><surname>Eliceiri</surname> <given-names>KW</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>OptogenSIM: a 3D Monte Carlo simulation platform for light delivery design in optogenetics</article-title><source>Biomedical optics express</source><volume>6</volume><fpage>4859</fpage><lpage>4870</lpage><pub-id pub-id-type="doi">10.1364/BOE.6.004859</pub-id><pub-id pub-id-type="pmid">26713200</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname> <given-names>LD</given-names></name><name><surname>Pack</surname> <given-names>CC</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The Contribution of Area MT to Visual Motion Perception Depends on Training</article-title><source>Neuron</source><volume>95</volume><fpage>436</fpage><lpage>446</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.024</pub-id><pub-id pub-id-type="pmid">28689980</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marshel</surname> <given-names>JH</given-names></name><name><surname>Kim</surname> <given-names>YS</given-names></name><name><surname>Machado</surname> <given-names>TA</given-names></name><name><surname>Quirin</surname> <given-names>S</given-names></name><name><surname>Benson</surname> <given-names>B</given-names></name><name><surname>Kadmon</surname> <given-names>J</given-names></name><name><surname>Raja</surname> <given-names>C</given-names></name><name><surname>Chibukhchyan</surname> <given-names>A</given-names></name><name><surname>Ramakrishnan</surname> <given-names>C</given-names></name><name><surname>Inoue</surname> <given-names>M</given-names></name><name><surname>Shane</surname> <given-names>JC</given-names></name><name><surname>McKnight</surname> <given-names>DJ</given-names></name><name><surname>Yoshizawa</surname> <given-names>S</given-names></name><name><surname>Kato</surname> <given-names>HE</given-names></name><name><surname>Ganguli</surname> <given-names>S</given-names></name><name><surname>Deisseroth</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Cortical layer–specific critical dynamics triggering perception</article-title><source>Science</source><volume>365</volume><elocation-id>eaaw5202</elocation-id><pub-id pub-id-type="doi">10.1126/science.aaw5202</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mayrhofer</surname> <given-names>JM</given-names></name><name><surname>El-Boustani</surname> <given-names>S</given-names></name><name><surname>Foustoukos</surname> <given-names>G</given-names></name><name><surname>Auffret</surname> <given-names>M</given-names></name><name><surname>Tamura</surname> <given-names>K</given-names></name><name><surname>Petersen</surname> <given-names>CCH</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Distinct Contributions of Whisker Sensory Cortex and Tongue-Jaw Motor Cortex in a Goal-Directed Sensorimotor Transformation</article-title><source>Neuron</source><volume>103</volume><fpage>1034</fpage><lpage>1043</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.07.008</pub-id><pub-id pub-id-type="pmid">31402199</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname> <given-names>TH</given-names></name><name><surname>Boyd</surname> <given-names>JD</given-names></name><name><surname>Bolaños</surname> <given-names>F</given-names></name><name><surname>Vanni</surname> <given-names>MP</given-names></name><name><surname>Silasi</surname> <given-names>G</given-names></name><name><surname>Haupt</surname> <given-names>D</given-names></name><name><surname>LeDue</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>High-throughput automated home-cage mesoscopic functional imaging of mouse cortex</article-title><source>Nature communications</source><volume>7</volume><elocation-id>11611</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms11611</pub-id><pub-id pub-id-type="pmid">27291514</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Murphy</surname> <given-names>TH</given-names></name><name><surname>Michelson</surname> <given-names>NJ</given-names></name><name><surname>Boyd</surname> <given-names>JD</given-names></name><name><surname>Fong</surname> <given-names>T</given-names></name><name><surname>Bolanos</surname> <given-names>LA</given-names></name><name><surname>Bierbrauer</surname> <given-names>D</given-names></name><name><surname>Siu</surname> <given-names>T</given-names></name><name><surname>Balbi</surname> <given-names>M</given-names></name><name><surname>Bolanos</surname> <given-names>F</given-names></name><name><surname>Vanni</surname> <given-names>M</given-names></name><name><surname>LeDue</surname> <given-names>JM</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Automated task training and longitudinal monitoring of mouse mesoscale cortical circuits using home cages</article-title><source>eLife</source><volume>9</volume><elocation-id>e55964</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.55964</pub-id><pub-id pub-id-type="pmid">32412409</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noorshams</surname> <given-names>O</given-names></name><name><surname>Boyd</surname> <given-names>JD</given-names></name><name><surname>Murphy</surname> <given-names>TH</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Automating mouse weighing in group homecages with Raspberry Pi micro-computers</article-title><source>Journal of neuroscience methods</source><volume>285</volume><fpage>1</fpage><lpage>5</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2017.05.002</pub-id><pub-id pub-id-type="pmid">28476590</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O'Connor</surname> <given-names>DH</given-names></name><name><surname>Hires</surname> <given-names>SA</given-names></name><name><surname>Guo</surname> <given-names>ZV</given-names></name><name><surname>Li</surname> <given-names>N</given-names></name><name><surname>Yu</surname> <given-names>J</given-names></name><name><surname>Sun</surname> <given-names>QQ</given-names></name><name><surname>Huber</surname> <given-names>D</given-names></name><name><surname>Svoboda</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neural coding during active somatosensation revealed using illusory touch</article-title><source>Nature neuroscience</source><volume>16</volume><fpage>958</fpage><lpage>965</lpage><pub-id pub-id-type="doi">10.1038/nn.3419</pub-id><pub-id pub-id-type="pmid">23727820</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olsen</surname> <given-names>SR</given-names></name><name><surname>Bortone</surname> <given-names>DS</given-names></name><name><surname>Adesnik</surname> <given-names>H</given-names></name><name><surname>Scanziani</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Gain control by layer six in cortical circuits of vision</article-title><source>Nature</source><volume>483</volume><fpage>47</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1038/nature10835</pub-id><pub-id pub-id-type="pmid">22367547</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Peters</surname> <given-names>AJ</given-names></name><name><surname>Steinmetz</surname> <given-names>N</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Striatal activity reflects cortical activity patterns</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/703710</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pinto</surname> <given-names>L</given-names></name><name><surname>Rajan</surname> <given-names>K</given-names></name><name><surname>DePasquale</surname> <given-names>B</given-names></name><name><surname>Thiberge</surname> <given-names>SY</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Task-Dependent Changes in the Large-Scale Dynamics and Necessity of Cortical Regions</article-title><source>Neuron</source><volume>104</volume><fpage>810</fpage><lpage>824</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.08.025</pub-id><pub-id pub-id-type="pmid">31564591</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poddar</surname> <given-names>R</given-names></name><name><surname>Kawai</surname> <given-names>R</given-names></name><name><surname>Ölveczky</surname> <given-names>BP</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A fully automated high-throughput training system for rodents</article-title><source>PLOS ONE</source><volume>8</volume><elocation-id>e83171</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0083171</pub-id><pub-id pub-id-type="pmid">24349451</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Qiao</surname> <given-names>M</given-names></name><name><surname>Zhang</surname> <given-names>T</given-names></name><name><surname>Segalin</surname> <given-names>C</given-names></name><name><surname>Sam</surname> <given-names>S</given-names></name><name><surname>Perona</surname> <given-names>P</given-names></name><name><surname>Meister</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Mouse academy: high-throughput automated training and trial-by-trial behavioral analysis during learning</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/467878</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reinert</surname> <given-names>JK</given-names></name><name><surname>Schaefer</surname> <given-names>AT</given-names></name><name><surname>Kuner</surname> <given-names>T</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>High-Throughput Automated Olfactory Phenotyping of Group-Housed Mice</article-title><source>Frontiers in behavioral neuroscience</source><volume>13</volume><elocation-id>267</elocation-id><pub-id pub-id-type="doi">10.3389/fnbeh.2019.00267</pub-id><pub-id pub-id-type="pmid">31920577</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Resulaj</surname> <given-names>A</given-names></name><name><surname>Ruediger</surname> <given-names>S</given-names></name><name><surname>Olsen</surname> <given-names>SR</given-names></name><name><surname>Scanziani</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>First spikes in visual cortex enable perceptual discrimination</article-title><source>eLife</source><volume>7</volume><elocation-id>e34044</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.34044</pub-id><pub-id pub-id-type="pmid">29659352</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossi</surname> <given-names>MA</given-names></name><name><surname>Li</surname> <given-names>HE</given-names></name><name><surname>Lu</surname> <given-names>D</given-names></name><name><surname>Kim</surname> <given-names>IH</given-names></name><name><surname>Bartholomew</surname> <given-names>RA</given-names></name><name><surname>Gaidis</surname> <given-names>E</given-names></name><name><surname>Barter</surname> <given-names>JW</given-names></name><name><surname>Kim</surname> <given-names>N</given-names></name><name><surname>Cai</surname> <given-names>MT</given-names></name><name><surname>Soderling</surname> <given-names>SH</given-names></name><name><surname>Yin</surname> <given-names>HH</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A GABAergic nigrotectal pathway for coordination of drinking behavior</article-title><source>Nature neuroscience</source><volume>19</volume><fpage>742</fpage><lpage>748</lpage><pub-id pub-id-type="doi">10.1038/nn.4285</pub-id><pub-id pub-id-type="pmid">27043290</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sachidhanandam</surname> <given-names>S</given-names></name><name><surname>Sreenivasan</surname> <given-names>V</given-names></name><name><surname>Kyriakatos</surname> <given-names>A</given-names></name><name><surname>Kremer</surname> <given-names>Y</given-names></name><name><surname>Petersen</surname> <given-names>CC</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Membrane potential correlates of sensory perception in mouse barrel cortex</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1671</fpage><lpage>1677</lpage><pub-id pub-id-type="doi">10.1038/nn.3532</pub-id><pub-id pub-id-type="pmid">24097038</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Sanders</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><data-title>Sanworks Bpod StateMachine Firmware</data-title><source>GitHub</source><version designator=" 20">20</version><ext-link ext-link-type="uri" xlink:href="https://github.com/sanworks/Bpod_StateMachine_Firmware">https://github.com/sanworks/Bpod_StateMachine_Firmware</ext-link></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scott</surname> <given-names>BB</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name><name><surname>Tank</surname> <given-names>DW</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Cellular resolution functional imaging in behaving rats using voluntary head restraint</article-title><source>Neuron</source><volume>80</volume><fpage>371</fpage><lpage>384</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2013.08.002</pub-id><pub-id pub-id-type="pmid">24055015</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siegel</surname> <given-names>M</given-names></name><name><surname>Buschman</surname> <given-names>TJ</given-names></name><name><surname>Miller</surname> <given-names>EK</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Cortical information flow during flexible sensorimotor decisions</article-title><source>Science</source><volume>348</volume><fpage>1352</fpage><lpage>1355</lpage><pub-id pub-id-type="doi">10.1126/science.aab0551</pub-id><pub-id pub-id-type="pmid">26089513</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Silasi</surname> <given-names>G</given-names></name><name><surname>Boyd</surname> <given-names>JD</given-names></name><name><surname>Bolanos</surname> <given-names>F</given-names></name><name><surname>LeDue</surname> <given-names>JM</given-names></name><name><surname>Scott</surname> <given-names>SH</given-names></name><name><surname>Murphy</surname> <given-names>TH</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Individualized tracking of self-directed motor learning in group-housed mice performing a skilled lever positioning task in the home cage</article-title><source>Journal of neurophysiology</source><volume>119</volume><fpage>337</fpage><lpage>346</lpage><pub-id pub-id-type="doi">10.1152/jn.00115.2017</pub-id><pub-id pub-id-type="pmid">29070625</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sippy</surname> <given-names>T</given-names></name><name><surname>Lapray</surname> <given-names>D</given-names></name><name><surname>Crochet</surname> <given-names>S</given-names></name><name><surname>Petersen</surname> <given-names>CC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Cell-Type-Specific Sensorimotor Processing in Striatal Projection Neurons during Goal-Directed Behavior</article-title><source>Neuron</source><volume>88</volume><fpage>298</fpage><lpage>305</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.08.039</pub-id><pub-id pub-id-type="pmid">26439527</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Slotnick</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>A simple 2-transistor touch or lick detector circuit</article-title><source>Journal of the experimental analysis of behavior</source><volume>91</volume><fpage>253</fpage><lpage>255</lpage><pub-id pub-id-type="doi">10.1901/jeab.2009.91-253</pub-id><pub-id pub-id-type="pmid">19794837</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Steinmetz</surname> <given-names>NA</given-names></name><name><surname>Zatka-Haas</surname> <given-names>P</given-names></name><name><surname>Carandini</surname> <given-names>M</given-names></name><name><surname>Harris</surname> <given-names>KD</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Distributed coding of choice, action and engagement across the mouse brain</article-title><source>Nature</source><volume>576</volume><fpage>266</fpage><lpage>273</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1787-x</pub-id><pub-id pub-id-type="pmid">31776518</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stubblefield</surname> <given-names>EA</given-names></name><name><surname>Costabile</surname> <given-names>JD</given-names></name><name><surname>Felsen</surname> <given-names>G</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Optogenetic investigation of the role of the superior colliculus in orienting movements</article-title><source>Behavioural brain research</source><volume>255</volume><fpage>55</fpage><lpage>63</lpage><pub-id pub-id-type="doi">10.1016/j.bbr.2013.04.040</pub-id><pub-id pub-id-type="pmid">23643689</pub-id></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stujenske</surname> <given-names>JM</given-names></name><name><surname>Spellman</surname> <given-names>T</given-names></name><name><surname>Gordon</surname> <given-names>JA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Modeling the Spatiotemporal Dynamics of Light and Heat Propagation for In Vivo Optogenetics</article-title><source>Cell reports</source><volume>12</volume><fpage>525</fpage><lpage>534</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2015.06.036</pub-id><pub-id pub-id-type="pmid">26166563</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Svoboda</surname> <given-names>K</given-names></name><name><surname>Block</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Biological applications of optical forces</article-title><source>Annual Review of Biophysics and Biomolecular Structure</source><volume>23</volume><fpage>247</fpage><lpage>285</lpage><pub-id pub-id-type="doi">10.1146/annurev.bb.23.060194.001335</pub-id><pub-id pub-id-type="pmid">7919782</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Svoboda</surname> <given-names>K</given-names></name><name><surname>Li</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Neural mechanisms of movement planning: motor cortex and beyond</article-title><source>Current opinion in neurobiology</source><volume>49</volume><fpage>33</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2017.10.023</pub-id><pub-id pub-id-type="pmid">29172091</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taniguchi</surname> <given-names>H</given-names></name><name><surname>He</surname> <given-names>M</given-names></name><name><surname>Wu</surname> <given-names>P</given-names></name><name><surname>Kim</surname> <given-names>S</given-names></name><name><surname>Paik</surname> <given-names>R</given-names></name><name><surname>Sugino</surname> <given-names>K</given-names></name><name><surname>Kvitsiani</surname> <given-names>D</given-names></name><name><surname>Kvitsani</surname> <given-names>D</given-names></name><name><surname>Fu</surname> <given-names>Y</given-names></name><name><surname>Lu</surname> <given-names>J</given-names></name><name><surname>Lin</surname> <given-names>Y</given-names></name><name><surname>Miyoshi</surname> <given-names>G</given-names></name><name><surname>Shima</surname> <given-names>Y</given-names></name><name><surname>Fishell</surname> <given-names>G</given-names></name><name><surname>Nelson</surname> <given-names>SB</given-names></name><name><surname>Huang</surname> <given-names>ZJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A resource of Cre driver lines for genetic targeting of GABAergic neurons in cerebral cortex</article-title><source>Neuron</source><volume>71</volume><fpage>995</fpage><lpage>1013</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.07.026</pub-id><pub-id pub-id-type="pmid">21943598</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Torquet</surname> <given-names>N</given-names></name><name><surname>Marti</surname> <given-names>F</given-names></name><name><surname>Campart</surname> <given-names>C</given-names></name><name><surname>Tolu</surname> <given-names>S</given-names></name><name><surname>Nguyen</surname> <given-names>C</given-names></name><name><surname>Oberto</surname> <given-names>V</given-names></name><name><surname>Benallaoua</surname> <given-names>M</given-names></name><name><surname>Naudé</surname> <given-names>J</given-names></name><name><surname>Didienne</surname> <given-names>S</given-names></name><name><surname>Debray</surname> <given-names>N</given-names></name><name><surname>Jezequel</surname> <given-names>S</given-names></name><name><surname>Le Gouestre</surname> <given-names>L</given-names></name><name><surname>Hannesse</surname> <given-names>B</given-names></name><name><surname>Mariani</surname> <given-names>J</given-names></name><name><surname>Mourot</surname> <given-names>A</given-names></name><name><surname>Faure</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Social interactions impact on the dopaminergic system and drive individuality</article-title><source>Nature communications</source><volume>9</volume><elocation-id>3081</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-05526-5</pub-id><pub-id pub-id-type="pmid">30082725</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tromberg</surname> <given-names>BJ</given-names></name><name><surname>Shah</surname> <given-names>N</given-names></name><name><surname>Lanning</surname> <given-names>R</given-names></name><name><surname>Cerussi</surname> <given-names>A</given-names></name><name><surname>Espinoza</surname> <given-names>J</given-names></name><name><surname>Pham</surname> <given-names>T</given-names></name><name><surname>Svaasand</surname> <given-names>L</given-names></name><name><surname>Butler</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Non-invasive in vivo characterization of breast tumors using photon migration spectroscopy</article-title><source>Neoplasia</source><volume>2</volume><fpage>26</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1038/sj.neo.7900082</pub-id><pub-id pub-id-type="pmid">10933066</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname> <given-names>Q</given-names></name><name><surname>Ding</surname> <given-names>SL</given-names></name><name><surname>Li</surname> <given-names>Y</given-names></name><name><surname>Royall</surname> <given-names>J</given-names></name><name><surname>Feng</surname> <given-names>D</given-names></name><name><surname>Lesnar</surname> <given-names>P</given-names></name><name><surname>Graddis</surname> <given-names>N</given-names></name><name><surname>Naeemi</surname> <given-names>M</given-names></name><name><surname>Facer</surname> <given-names>B</given-names></name><name><surname>Ho</surname> <given-names>A</given-names></name><name><surname>Dolbeare</surname> <given-names>T</given-names></name><name><surname>Blanchard</surname> <given-names>B</given-names></name><name><surname>Dee</surname> <given-names>N</given-names></name><name><surname>Wakeman</surname> <given-names>W</given-names></name><name><surname>Hirokawa</surname> <given-names>KE</given-names></name><name><surname>Szafer</surname> <given-names>A</given-names></name><name><surname>Sunkin</surname> <given-names>SM</given-names></name><name><surname>Oh</surname> <given-names>SW</given-names></name><name><surname>Bernard</surname> <given-names>A</given-names></name><name><surname>Phillips</surname> <given-names>JW</given-names></name><name><surname>Hawrylycz</surname> <given-names>M</given-names></name><name><surname>Koch</surname> <given-names>C</given-names></name><name><surname>Zeng</surname> <given-names>H</given-names></name><name><surname>Harris</surname> <given-names>JA</given-names></name><name><surname>Ng</surname> <given-names>L</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The Allen Mouse Brain Common Coordinate Framework: A 3D Reference Atlas</article-title><source>Cell</source><volume>181</volume><fpage>936</fpage><lpage>953</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.04.007</pub-id><pub-id pub-id-type="pmid">32386544</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wiegert</surname> <given-names>JS</given-names></name><name><surname>Mahn</surname> <given-names>M</given-names></name><name><surname>Prigge</surname> <given-names>M</given-names></name><name><surname>Printz</surname> <given-names>Y</given-names></name><name><surname>Yizhar</surname> <given-names>O</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Silencing Neurons: Tools, Applications, and Experimental Constraints</article-title><source>Neuron</source><volume>95</volume><fpage>504</fpage><lpage>529</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.06.050</pub-id><pub-id pub-id-type="pmid">28772120</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yartsev</surname> <given-names>MM</given-names></name><name><surname>Hanks</surname> <given-names>TD</given-names></name><name><surname>Yoon</surname> <given-names>AM</given-names></name><name><surname>Brody</surname> <given-names>CD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Causal contribution and dynamical encoding in the striatum during evidence accumulation</article-title><source>eLife</source><volume>7</volume><elocation-id>e34929</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.34929</pub-id><pub-id pub-id-type="pmid">30141773</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Znamenskiy</surname> <given-names>P</given-names></name><name><surname>Zador</surname> <given-names>AM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Corticostriatal neurons in auditory cortex drive decisions during auditory discrimination</article-title><source>Nature</source><volume>497</volume><fpage>482</fpage><lpage>485</lpage><pub-id pub-id-type="doi">10.1038/nature12077</pub-id><pub-id pub-id-type="pmid">23636333</pub-id></element-citation></ref></ref-list></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.66112.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Bathellier</surname><given-names>Brice</given-names></name><role>Reviewing Editor</role><aff><institution>CNRS</institution><country>France</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Bathellier</surname><given-names>Brice</given-names> </name><role>Reviewer</role><aff><institution>CNRS</institution><country>France</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Faure</surname><given-names>Philippe</given-names> </name><role>Reviewer</role><aff><institution>Sorbonne Université, INSERM, CNRS</institution><country>France</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2020.12.27.424480">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2020.12.27.424480v2">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>This article details a new open source setup and protocol for automated training of mice to a challenging sensory discrimination task. This tool brings a level of automation (no human intervention) never achieved in a context that also allows targeted manipulation brain areas, in a non-invasive manner. Both these aspects and the potential for combined optical imaging will be extremely useful for the neuroscience community.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Fully autonomous mouse behavioral and optogenetic experiments in home-cage&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, including Brice Bathellier as the Reviewing Editor and Reviewer #1, and the evaluation has been overseen by Laura Colgin as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Philippe Faure (Reviewer #3).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential Revisions:</p><p>While the referees recognize the solidity of this work, a number of revisions are needed to better highlight its novelties with respect to previous publications on behavior during voluntary head-fixation, to reinforce the description of optogenetic silencing results and to help the reader grasp motivation aspects in this self-initiated behavior.</p><p>1. Due to the authors' choice of plotting performance in optogenetics, it is not possible to know if the mice reach chance level during silencing. However, appreciating if the chance level is reached during silencing is important to evaluate if the silencing method leads to complete or partial impairments. The authors should thus also provide plots in which performance during optogenetics is express as the distance to chance level (e.g. 60% correct for a balanced binary task is 10% above chance level). Depending on the outcome of this re-plotting, the author should comment, based on the literature, whether incomplete effects are due to incomplete silencing or due to partial involvement of the target region in the task.</p><p>2. The comparison to other methods is important. As it stands, these seem marginal. This should be strengthened. It would be also important to highlight what types of questions, qualitatively, can be answered that are not possible (or difficult) otherwise.</p><p>3. The task structure needs to be clarified. The sample period (1.3 sec) is followed by a delay epoch (1.3 sec), an auditory go cue and the response epoch. It is indicated that &quot;Mice were free to respond by licking at any time during the trial, but only the first lick after the 'go' cue were registered as choice&quot;. The question is what exactly is a trial ? Is it: (i) a sequence sample-delay – response, with only the first lick taken as a response. That is, 1 head fixation = a trial and is associated with a maximum of 1 water reward (2-3 µL). (ii) a succession of sample-delay -1 response sequences during 30 or 60 sec. That is, 1 head fixation is associated with more than one water reward (2-3 µL). I suspect that the first proposal is the correct one, but this should be clearly stated in the manuscript. Along that line, Figure 3B is confusing. Authors should may be indicate the first lick, the one registered as choice in full color and the additional one as transparent?</p><p>4. The authors should provide information about the daily water consumption (2-3 µL per lick number of correct trials per days) and whether it is stable during the protocol. Considering that a mouse drinks about 3-5 mL daily if it weighs more than 30 grams, it would correspond to 2000 correct trials more than 16 h of 30 sec head fixed session, if the above interpretation of a trial is correct.</p><p>5. In a paper (Torquet et al. 2018) which describes mouse behavior in an automated T-maze task (left or right to access water versus water + sugar), mice showed a decreased return time after choosing the less-rewarded side. This indicated an increased motivation after a failure, but also the fact that some trial can be associated with low motivation for the reward and engagement in the test just for exploration. Here, the authors showed a distribution of inter-fixation interval, with a long tail. Are these inter-fixation intervals correlated with the success or failure in the last trial which could indicate different motivation depending on the intervals?</p><p>6. In the contingency reversals task, do the animals adapted their inter-fixation intervals just after the reversal?</p><p>7. The position of the pole with respect to the head (stimulation of the left or right whiskers) is not clearly indicated in the method, information seems to be shown only in Figure 3A. This should be indicated clearly. Along the same lines, on line 498, replace &quot;Photoinhibition of S1&quot; by &quot;Photoinhibition of left S1&quot;.</p><p>8. The statistics used in the optogenetic experiment is based on bootstrap and unilateral testing (one tail test). It is indicated that &quot;In each round of bootstrap, we replaced the original behavioral dataset with a re-sampled dataset in which we re-sampled with replacement from: (1) mice, (2) sessions performed by each mouse, (3) trials within each session. We then computed the performance change on the re-sampled dataset. Repeating this procedure 10,000 times produced a distribution of performance changes that reflected the behavioral variability.&quot; It is not clear what 'sessions' means for &quot;unsupervised optogenetic experiments&quot;. It is not clear why there are replacements from mice in the bootstrap method. Optogenetic experiment allow quantifying effect at the level of individuals: Test should be paired test and authors have to estimate individual distribution of performance changes under the null hypothesis. Finally, the authors used a unilateral test. This is fine, but the hypothesis should then be clearly stated. It is clearly expected that photo-stimulation of left S1 will reduce performance (with stimulation of the right whisker). The justification for a unilateral should be better justified for the other regions, and in particular the subcortical regions. The sentence l.560 &quot;We next tested if the striatal optogenetic manipulation was sufficient to bias behavior&quot; does not correspond to an unilateral test.</p><p>9. Finally, to obtain a proper control group, it is certainly better to use a control-AAV instead of no AAV. Could it be mentioned?</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.66112.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential Revisions:</p><p>While the referees recognize the solidity of this work, a number of revisions are needed to better highlight its novelties with respect to previous publications on behavior during voluntary head-fixation, to reinforce the description of optogenetic silencing results and to help the reader grasp motivation aspects in this self-initiated behavior.</p></disp-quote><p>We thank the reviewers for the constructive comments. In the revised manuscripts, we have addressed these comments with the following revisions.</p><p>1. We strengthened the optogenetic manipulation results, including fraction of neurons affected and behavioral effect size relative to chance. We also quantitatively compared our effect size to previous studies and we discuss the interpretation of effect size.</p><p>2. We better highlight the advance provided by our method over previous methods and the utility of our workflow in surveying cortico-basal-ganglia loops. We discuss why this is currently difficult but is enabled by the advance here. We added new experiments probing additional sites in the striatum, further illustrating the ease and throughput of our workflow. Our mapping revealed a hotspot in the dorsolateral striatum that biased tactile-guided decision-making.</p><p>3. We added a new section in the Results examining behavioral signatures of motivation in the self-initiated behavior.</p><p>4. We have clarified method descriptions in various places.</p><p>5. We also added data from new optogenetic control mice in which GFP viruses were injected.</p><p>Please find our point-by-point response below.</p><disp-quote content-type="editor-comment"><p>1. Due to the authors' choice of plotting performance in optogenetics, it is not possible to know if the mice reach chance level during silencing. However, appreciating if the chance level is reached during silencing is important to evaluate if the silencing method leads to complete or partial impairments. The authors should thus also provide plots in which performance during optogenetics is express as the distance to chance level (e.g. 60% correct for a balanced binary task is 10% above chance level). Depending on the outcome of this re-plotting, the author should comment, based on the literature, whether incomplete effects are due to incomplete silencing or due to partial involvement of the target region in the task.</p></disp-quote><p>We have now added raw performance levels to Figure 7—figure supplements 1 and 2. In the power range tested in this study, photostimulation did not reduce performance to chance level (Figure 7—figure supplement 2). One limitation of the optogenetic workflow is the interpretation of behavioral deficit effect size. We examined this issue in ALM, a brain region from which we have the most extensive data (new Figure 7—figure supplement 1). In previous studies we have shown that bilateral photoinhibition of ALM results in chance level performance (Li et al. 2016, Figure 2b; Gao et al., 2018, Extended Data Figure 6b). Here, mice performance was above chance during photoinhibition of ALM (Figure 7—figure supplement 1). This difference in behavioral effect size likely resulted from incomplete silencing of ALM. The photostimulus intensity used here was much less than those used in previous studies (0.3 vs. 11.9 mW/mm<sup>2</sup>). In addition, a single virus injection was not sufficient to cover the entire ALM. Thus a partial behavioral effect could be due to incomplete silencing of a brain region, or partial involvement of the brain region in the task. Given this limitation, we caution that the function of a brain region could only be fully deduced in more detailed analysis and together with neurophysiology. We now better highlight these points in the Discussion (page 22-23).</p><p>Nevertheless, we believe our workflow is a highly useful tool to quickly screen brain regions that play roles in behavior.</p><p>1. At relatively low laser power, the effect sizes induced by photoinhibiting ALM and S1 are large and comparable to previous studies (Figure 7—figure supplement 1).</p><p>2. At relatively low laser power, we induced large and consistent biases by photostimulating subcortical regions that receive ALM and/or S1 inputs (dorsolateral striatum and SC).</p><p>3. We added new experiments showing that photostimulation in the posterior striatum (a region that does not receive ALM and S1 inputs) produced little effect. Thus, our method could differentiate brain regions involved in behavior from those that do not.</p><p>This makes more targeted analysis possible.</p><disp-quote content-type="editor-comment"><p>2. The comparison to other methods is important. As it stands, these seem marginal. This should be strengthened. It would be also important to highlight what types of questions, qualitatively, can be answered that are not possible (or difficult) otherwise.</p></disp-quote><p>The most significant advance of our workflow over previous methods is a substantial increase in the yield and duration of training. Our method also does not require pre-acclimation of mice and eliminates human supervision. We show that self-release is critical for automated training, which is missing from all current head-fixation systems for mice. Our automated training now rivals and slightly surpass the yield of manual training for the first time. We think this degree of automation is an important technical advance because it now enables systematic surveys of deep brain regions in behaviors that require thousands of trials to learn. We better highlight comparisons to previous methods in several key areas in the Supplemental Table 1. We have also strengthened the Discussion (page 20).</p><p>One line of inquiry immediately enabled by our automated training and optogenetic workflow is a systematic mapping of the cortico-basal-ganglia loops during difficult perceptual decision-making tasks. The striatum is topographically organized. Previous studies examined different subregions of the striatum in different perceptual decision behaviors, making comparisons across studies difficult. In the revised manuscript, we better highlight this issue using realistic calculations of yields and time. The striatum in the mouse brain is ~21.5 mm<sup>3</sup> in size (Allen reference brain, (Wang, et al., Cell 2020)). Optogenetic experiments using optical fibers manipulate activity near the fiber tip (approximately 1 mm<sup>3</sup>). A systematic survey of different striatal domains’ involvement in specific behaviors is currently difficult. In our workflow, individual striatal subregions (~1 mm<sup>3</sup>, Figure 8) could be rapidly screened through parallel testing. At moderate throughput (15 mice / 2 months), a screen that tiles the entire striatum could be completed in under 12 months with little human effort. To illustrate its feasibility, we tested 3 subregions in the striatum previously implicated in different types of perceptual decision behaviors (Yartsev et al., <italic>eLife</italic> 2018; Sippy et al., Neuron 2015; Znamenskiy and Zador, Nature 2013), including an additional region in the posterior striatum that does not receive ALM and S1 inputs. The results revealed a hotspot in the dorsolateral striatum that biased tactile-guided decision-making (Figure 8). Our approach thus opens the door to rapid screening of the striatal domains during complex operant behaviors.</p><p>Moreover, by eliminating human intervention, automated training allows quantitative assaying of task learning (Figure 4). Home-cage testing also exposes behavioral signatures of motivation in self-initiated behavior (Figure 6). These observations suggest additional opportunities for inquires of goal-directed behaviors in the context of home-cage testing.</p><disp-quote content-type="editor-comment"><p>3. The task structure needs to be clarified. The sample period (1.3 sec) is followed by a delay epoch (1.3 sec), an auditory go cue and the response epoch. It is indicated that &quot;Mice were free to respond by licking at any time during the trial, but only the first lick after the 'go' cue were registered as choice&quot;. The question is what exactly is a trial ? Is it: (i) a sequence sample-delay – response, with only the first lick taken as a response. That is, 1 head fixation = a trial and is associated with a maximum of 1 water reward (2-3 µL). (ii) a succession of sample-delay -1 response sequences during 30 or 60 sec. That is, 1 head fixation is associated with more than one water reward (2-3 µL). I suspect that the first proposal is the correct one, but this should be clearly stated in the manuscript. Along that line, Figure 3B is confusing. Authors should may be indicate the first lick, the one registered as choice in full color and the additional one as transparent?</p></disp-quote><p>In each head-fixation (30-60 s), mice were tested in a succession of trials. A sequence of sample-delay-response epochs constituted a trial (~5 s). Each trial was followed by an inter-trial-interval (2.5 s), after which the next trial began, until the head-fixation is released (Video 1). During the early phases of training (‘learn directional licking’ and ‘learn discrimination’), mice were free to lick any time during the trial. After the delay epoch was added, licking before the ‘go’ cue triggered a brief timeout, but mice were allowed to complete the trial. In all cases, the water reward was only contingent on the first lick after the ‘go’ cue. We have clarified this in the Results (page 9) and Methods (page 32). We have also revised Figure 3B as suggested by the reviewer to indicate the choice lick.</p><disp-quote content-type="editor-comment"><p>4. The authors should provide information about the daily water consumption (2-3 µL per lick number of correct trials per days) and whether it is stable during the protocol. Considering that a mouse drinks about 3-5 mL daily if it weighs more than 30 grams, it would correspond to 2000 correct trials more than 16 h of 30 sec head fixed session, if the above interpretation of a trial is correct.</p></disp-quote><p>We have added a new Figure 6 and a new section in the Results (page 13-14) describing detailed water consumption and body weight information in home-cage testing. At steady state, a mouse typically consumed ~1mL of water daily (~400 rewarded trials) while maintaining stable body weight. This amount of water consumption is similar to mice engaged in daily manual experiments (Guo et al., Plos ONE 2014).</p><disp-quote content-type="editor-comment"><p>5. In a paper (Torquet et al. 2018) which describes mouse behavior in an automated T-maze task (left or right to access water versus water + sugar), mice showed a decreased return time after choosing the less-rewarded side. This indicated an increased motivation after a failure, but also the fact that some trial can be associated with low motivation for the reward and engagement in the test just for exploration. Here, the authors showed a distribution of inter-fixation interval, with a long tail. Are these inter-fixation intervals correlated with the success or failure in the last trial which could indicate different motivation depending on the intervals?</p></disp-quote><p>We thank the reviewer for pointing us to this study, which was missed in our previous survey of the literature. We also now include citations to this line of work in the Introduction and Discussion (page 4 and 20).</p><p>We examined the inter-fixation-interval as suggested by the reviewer. Interestingly, the inter-fixation-interval after an error (which led to no reward) was significantly longer than following a correct trial (Figure 6E). This is inconsistent with error from exploration. Rather it likely reflects a loss of motivation after an error, perhaps due to the loss of an expected reward. In Torquet et al., mice showed a decreased return time after a less rewarding choice. Several factors could have contributed to this apparent difference. In Torquet et al., the location associated with higher reward was relatively constant (swapped every 3-4 days). A failed attempt in that context was likely due to exploration and a failed exploration would mean a higher reward is available on the other arm. Here, the context is different in that mice were learning to associate a sensory stimulus with a motor response. Licking either side could have caused an error depending on the sensory stimulus. When mice have not learned to associate the sensory stimulus with lick direction. We suspect that an error trial violated the mice’s expectation of reward, and therefore discouraged the mice, leading to a loss in motivation. Consistent with this interpretation, we also found a significant increase in inter-fixation-intervals shortly after a sensorimotor contingency reversal (Figure 6F). This coincided with an increase in error rate due to the rule change (Figure 5B). However, we recognize these are complex factors that would require further study to systematically dissect.</p><p>These new analyses have led us to include a new section in the revised manuscript (page 13-14 and Figure 6).</p><disp-quote content-type="editor-comment"><p>6. In the contingency reversals task, do the animals adapted their inter-fixation intervals just after the reversal?</p></disp-quote><p>Mice indeed increased their inter-fixation intervals just after the reversal (Figure 6F). This was likely due to failures to obtain expected rewards due to the rule change, leading to a loss of motivation. Inter-fixation interval recovered after mice learned the new contingency (Figure 6F). These results have been added to the new section of the manuscript (page 14).</p><disp-quote content-type="editor-comment"><p>7. The position of the pole with respect to the head (stimulation of the left or right whiskers) is not clearly indicated in the method, information seems to be shown only in Figure 3A. This should be indicated clearly. Along the same lines, on line 498, replace &quot;Photoinhibition of S1&quot; by &quot;Photoinhibition of left S1&quot;.</p></disp-quote><p>We have added this information as suggested.</p><disp-quote content-type="editor-comment"><p>8. The statistics used in the optogenetic experiment is based on bootstrap and unilateral testing (one tail test). It is indicated that &quot;In each round of bootstrap, we replaced the original behavioral dataset with a re-sampled dataset in which we re-sampled with replacement from: (1) mice, (2) sessions performed by each mouse, (3) trials within each session. We then computed the performance change on the re-sampled dataset. Repeating this procedure 10,000 times produced a distribution of performance changes that reflected the behavioral variability.&quot; It is not clear what 'sessions' means for &quot;unsupervised optogenetic experiments&quot;. It is not clear why there are replacements from mice in the bootstrap method. Optogenetic experiment allow quantifying effect at the level of individuals: Test should be paired test and authors have to estimate individual distribution of performance changes under the null hypothesis. Finally, the authors used a unilateral test. This is fine, but the hypothesis should then be clearly stated. It is clearly expected that photo-stimulation of left S1 will reduce performance (with stimulation of the right whisker). The justification for a unilateral should be better justified for the other regions, and in particular the subcortical regions. The sentence l.560 &quot;We next tested if the striatal optogenetic manipulation was sufficient to bias behavior&quot; does not correspond to an unilateral test.</p></disp-quote><p>We thank the reviewer for catching these. We have clarified the description in the Methods (page 37). For home-cage optogenetic experiments, each day (dark + light cycle) was treated as a ‘session’.</p><p>We clarify that in each round of bootstrap, for each mouse we computed its performance change in photostimulation trials relative to the control trials, this is equivalent to a paired test (i.e. a change across conditions within-individuals). The resampling of mice was done before performance change was computed in each mouse. In essence, the <italic>nested</italic> bootstrap produced a distribution of observed performance change (within-individuals) taking into account variabilities across 3 levels: (1) mice included in the analysis, (2) sessions from each mouse, (3) trials from each session. The distribution was used to assess the probability of observing a behavioral change in the opposite direction from that observed (i.e. one-tailed test).</p><p>We now justify the use of unilateral photostimulation in the text (page 15 and 17-18). In our task, mice discriminate object location using the right whiskers and report choice using directional licking. We targeted the left barrel cortex, contralateral to the side of the tactile stimulus. For ALM, we tested each hemisphere because previous studies show that unilateral photoinhibition of ALM biases licking to the ipsilateral direction (Guo et al., Neuron 2014; Li et al., Nature 2015). This enabled comparisons to previous studies. For striatum and superior colliculus, previous studies suggest their roles in driving directional licking are lateralized (Lee and Sabatini, BioRxiv 2020; Duan, et al., BioRxiv 2019). In addition, the dorsolateral striatum targeted here receives inputs predominately from the ipsilateral barrel cortex (Sippy et al., Neuron 2015). We therefore targeted the left striatum, ipsilateral to the left barrel cortex and contralateral to the tactile stimulus.</p><disp-quote content-type="editor-comment"><p>9. Finally, to obtain a proper control group, it is certainly better to use a control-AAV instead of no AAV. Could it be mentioned?</p></disp-quote><p>We have tested a new group of GAD2-Cre mice in which AAV-pCAG-FLEX-EGFP-WPRE viruses were injected into the left ALM. Photostimulation induced no detectable effect on behavioral performance. This data now replaces the data from mice with no viruses injected (Figure 7—figure supplement 2A).</p></body></sub-article></article>