<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">99302</article-id><article-id pub-id-type="doi">10.7554/eLife.99302</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.99302.4</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Learning place cells and remapping by decoding the cognitive map</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Pettersen</surname><given-names>Markus Borud</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-9004-4995</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Schøyen</surname><given-names>Vemund</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8932-5706</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Malthe-Sørenssen</surname><given-names>Anders</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-8138-3995</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Lepperød</surname><given-names>Mikkel E</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4262-5549</contrib-id><email>mikkel@simula.no</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00vn06n10</institution-id><institution>Simula Research Laboratory</institution></institution-wrap><addr-line><named-content content-type="city">Oslo</named-content></addr-line><country>Norway</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01xtthb56</institution-id><institution>Department of Physics, University of Oslo</institution></institution-wrap><addr-line><named-content content-type="city">Oslo</named-content></addr-line><country>Norway</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01xtthb56</institution-id><institution>Department of Biosciences, University of Oslo</institution></institution-wrap><addr-line><named-content content-type="city">Oslo</named-content></addr-line><country>Norway</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Bhalla</surname><given-names>Upinder Singh</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03gf8rp76</institution-id><institution>National Centre for Biological Sciences</institution></institution-wrap><country>India</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Colgin</surname><given-names>Laura L</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hj54h04</institution-id><institution>University of Texas at Austin</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>28</day><month>07</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP99302</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-05-08"><day>08</day><month>05</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-03-25"><day>25</day><month>03</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.03.14.585049"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-07-17"><day>17</day><month>07</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.99302.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-05-27"><day>27</day><month>05</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.99302.2"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-06-25"><day>25</day><month>06</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.99302.3"/></event></pub-history><permissions><copyright-statement>© 2024, Pettersen et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Pettersen et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-99302-v1.pdf"/><abstract><p>Hippocampal place cells are known for their spatially selective firing and are believed to encode an animal’s location while forming part of a cognitive map of space. These cells exhibit marked tuning curves and rate changes when an animal’s environment is sufficiently manipulated, in a process known as remapping. Place cells are accompanied by many other spatially tuned cells, such as border cells and grid cells, but how these cells interact during navigation and remapping is unknown. In this work, we build a normative place cell model wherein a neural network is tasked with accurate position reconstruction and path integration. Motivated by the notion of a cognitive map, the network’s position is estimated directly from its learned representations. To obtain a position estimate, we propose a non-trainable decoding scheme applied to network output units, inspired by the localized firing patterns of place cells. We find that output units learn place-like spatial representations, while upstream recurrent units become boundary-tuned. When the network is trained to perform the same task in multiple simulated environments, its place-like units learn to remap like biological place cells, displaying global, geometric, and rate remapping. These remapping abilities appear to be supported by rate changes in upstream units. While the model does not learn grid-like units, its place unit centers form clusters organized in a hexagonal lattice in open fields. When we decode the center locations of CA1 place fields in mice, we find preliminary evidence of a similar clustering tendency. This suggests a potential mechanism for the interaction between place cells, border cells, and grid cells. Our model provides a normative framework for learning spatial representations previously reserved for biological place cells, providing new insight into place cell field formation and remapping.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>place cells</kwd><kwd>border cells</kwd><kwd>spatial navigation</kwd><kwd>recurrent neural network</kwd><kwd>machine learning</kwd><kwd>artificial intelligence</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100005416</institution-id><institution>Research Council of Norway</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Malthe-Sørenssen</surname><given-names>Anders</given-names></name><name><surname>Lepperød</surname><given-names>Mikkel E</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Border cells are sufficient to generate place cells and remapping during path integration in artificial neural networks, challenging the role of grid cells for spatial navigation.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Being able to accurately determine your location in an environment is an essential skill shared by any navigating system, both animal and machine. Hippocampal place cells (<xref ref-type="bibr" rid="bib36">O’Keefe and Dostrovsky, 1971</xref>) are believed to be crucial for this ability in animals. Place cells get their name from their distinct spatial tuning: A single place cell only tends to fire in select locations within a given recording environment (<xref ref-type="bibr" rid="bib37">O’Keefe, 1976</xref>; <xref ref-type="bibr" rid="bib40">Park et al., 2011</xref>).</p><p>When an animal is moved between different recording arenas, or a familiar environment is significantly manipulated, place cells can undergo global remapping (<xref ref-type="bibr" rid="bib27">Leutgeb et al., 2004</xref>), wherein spatial responses are uncorrelated across environments. For less severe changes to the environment (e.g. mild changes in smell or color), place cells can also exhibit less drastic tuning curve changes in the form of partial (<xref ref-type="bibr" rid="bib19">Jeffery, 2011</xref>), rate (<xref ref-type="bibr" rid="bib28">Leutgeb et al., 2005</xref>), and orientation (<xref ref-type="bibr" rid="bib34">Muller and Kubie, 1987</xref>) remapping. Furthermore, geometric modifications of a recording environment elicit distinct place field changes. For example, elongating an environment induces field elongation (<xref ref-type="bibr" rid="bib39">O’Keefe and Burgess, 1996</xref>). Adding a novel wall to a familiar environment may spur so-called field doubling (<xref ref-type="bibr" rid="bib3">Barry et al., 2006</xref>), where a second place field emerges, situated at the same distance from the new wall as the field used to be from the original.</p><p>Since the discovery of place cells, a range of other neuron types with navigational behavior correlates have been discovered experimentally. These include head direction cells (<xref ref-type="bibr" rid="bib54">Taube et al., 1990</xref>), grid cells (<xref ref-type="bibr" rid="bib14">Hafting et al., 2005</xref>), border cells (<xref ref-type="bibr" rid="bib29">Lever et al., 2009</xref>; <xref ref-type="bibr" rid="bib51">Solstad et al., 2008</xref>), band cells (<xref ref-type="bibr" rid="bib21">Krupic et al., 2012</xref>), and object vector cells (<xref ref-type="bibr" rid="bib18">Høydal et al., 2019</xref>). Some of these spatial cells can also exhibit changes in their firing profile when an animal is moved between different recording arenas or a familiar environment is sufficiently manipulated (<xref ref-type="bibr" rid="bib11">Fyhn et al., 2007</xref>; <xref ref-type="bibr" rid="bib54">Taube et al., 1990</xref>).</p><p>How does the myriad of spatial cell types observed in the brain cooperate to do navigation? One popular theory posits that spatial cells collectively set up cognitive maps of the animal’s surroundings (<xref ref-type="bibr" rid="bib56">Tolman, 1948</xref>; <xref ref-type="bibr" rid="bib38">O’Keefe and Nadel, 1978</xref>; <xref ref-type="bibr" rid="bib5">Behrens et al., 2018</xref>). In the past, the term cognitive map has been used colloquially, referring to everything from a neural representation of geometry to charts of social relationships (<xref ref-type="bibr" rid="bib56">Tolman, 1948</xref>; <xref ref-type="bibr" rid="bib55">Tavares et al., 2015</xref>; <xref ref-type="bibr" rid="bib1">Aronov et al., 2017</xref>; <xref ref-type="bibr" rid="bib5">Behrens et al., 2018</xref>; <xref ref-type="bibr" rid="bib58">Whittington et al., 2020</xref>). In this work, we formalize the intuitive notion of a spatial cognitive map by proposing a mathematical definition of it. This serves as a foundation for developing models of spatial cell types and can be used to describe several normative models in the literature.</p><p>A range of models has already been proposed in an attempt to explain the striking spatial tuning and remapping behaviors exhibited by place cells. One prominent theory holds that place cell activity results from upstream input from grid cells in the medial entorhinal Cortex (mEC) (<xref ref-type="bibr" rid="bib33">Moser et al., 2008</xref>; <xref ref-type="bibr" rid="bib50">Solstad et al., 2006</xref>; <xref ref-type="bibr" rid="bib19">Jeffery, 2011</xref>). However, there are several experimental findings that challenge this so-called forward theory. For instance, place cells tend to mature prior to grid cells in rodent development (<xref ref-type="bibr" rid="bib24">Langston et al., 2010</xref>; <xref ref-type="bibr" rid="bib59">Wills et al., 2010</xref>). Also, place cell inactivation has been associated with abolished grid cell activity, rather than the other way around (<xref ref-type="bibr" rid="bib32">Morris and Derdikman, 2023</xref>). Another approach is to suggest that non-grid spatial cells are responsible (<xref ref-type="bibr" rid="bib17">Hartley et al., 2000</xref>; <xref ref-type="bibr" rid="bib3">Barry et al., 2006</xref>; <xref ref-type="bibr" rid="bib32">Morris and Derdikman, 2023</xref>). However, the exact origins of place fields and their remapping behavior remain undetermined.</p><p>How, then, would one go about modeling place cells in a way that allows for <italic>discovering</italic> how place fields emerge, how remapping occurs, and how different cell types relate? An exciting recent alternative is to leverage normative models of the hippocampus and surrounding regions, using neural networks optimized for a navigation task. When trained, such models learn tuning profiles similar to their biological counterparts (<xref ref-type="bibr" rid="bib8">Cueva and Wei, 2018</xref>; <xref ref-type="bibr" rid="bib2">Banino et al., 2018</xref>; <xref ref-type="bibr" rid="bib52">Sorscher et al., 2023</xref>; <xref ref-type="bibr" rid="bib58">Whittington et al., 2020</xref>; <xref ref-type="bibr" rid="bib61">Xu et al., 2022</xref>; <xref ref-type="bibr" rid="bib10">Dorrell and Latham, 2022</xref>; <xref ref-type="bibr" rid="bib46">Schaeffer et al., 2023</xref>; <xref ref-type="bibr" rid="bib30">Low et al., 2023</xref>). To the best of our knowledge, however, no normative models have tackled the problem of directly learning place cell formation and remapping. Only some address remapping, but do so for other cell types or brain regions (<xref ref-type="bibr" rid="bib58">Whittington et al., 2020</xref>; <xref ref-type="bibr" rid="bib30">Low et al., 2023</xref>; <xref ref-type="bibr" rid="bib47">Schøyen et al., 2023</xref>; <xref ref-type="bibr" rid="bib57">Uria et al., 2020</xref>).</p><p>Using our definition of a cognitive map, we, therefore, propose a normative model of spatial navigation with the flexibility required to study place cells and remapping in one framework. In our model, the output representations of a neural network are decoded into a position estimate. Simultaneously, the network is tasked with accurate position reconstruction while path integrating. Crucially, the non-trainable decoding operation is inspired by the localized firing patterns of place cells, but with minimal constraints on their individual tuning profile and their population coding properties.</p><p>We find that our model learns representations with spatial tuning profiles similar to those found in the mammalian brain, including place units in the downstream output layer and predominantly border-tuned units in the upstream recurrent layer. We thus find that border representations are the main spatially tuned basis for forming place cell representations, aligning with previous mechanistic theories of place cell formation from border cells (<xref ref-type="bibr" rid="bib3">Barry et al., 2006</xref>).</p><p>Interestingly, our model does not learn grid-like representations despite being able to path integrate. Thus, our work raises questions about the necessity of grid cells for path integration. However, we find that the centers of the learned place fields arrange on a hexagonal lattice in open arenas. This indicates that although grid-like cells are not necessary to form place cells, optimal position decoding still dictates hexagonal symmetry. Inspired by this, we decode center locations for CA1 place fields in mice (data provided by <xref ref-type="bibr" rid="bib26">Lee et al., 2023</xref>), and find preliminary evidence that biological place cells could exhibit clustering in a manner similar to our model.</p><p>We train our model in multiple environments and observe that the network learns global, rate, and geometric remapping akin to biological place cells. We find that remapping in the place-like units of the network can be understood as a consequence of sparse input from near-independent sets of upstream, rate-remapping boundary-tuned units. Thus, we show that border cell input can explain not only place field formation, but also remapping.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Decoding the cognitive map</title><p>The foundation for the proposed place cell model is a learned cognitive map of space. We define a spatial cognitive map as a (vector-valued) function <inline-formula><alternatives><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math><tex-math id="inft1">\begin{document}$  \hat{\mathbf{u}}\in\mathbb{R}^{N}$\end{document}</tex-math></alternatives></inline-formula> that minimizes<disp-formula id="equ1"><label>(1)</label><alternatives><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t1">\begin{document}$$\displaystyle  S = \mathbb{E}_{t} \left[ \mathcal{L}(\mathbf{u}(\mathbf{x}_t), \hat{\mathbf{u}}(\mathbf{z}_t)) + R(\hat{\mathbf{u}}(\mathbf{z}_t)) \right], \label{eq:cognitive_map}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>M</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math><tex-math id="inft2">\begin{document}$  \mathbf{u}(\mathbf{x}_{t})\in\mathbb{R}^{M}$\end{document}</tex-math></alternatives></inline-formula> is some target spatial representation at a true location <inline-formula><alternatives><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft3">\begin{document}$  \mathbf{x}_{t}$\end{document}</tex-math></alternatives></inline-formula> (e.g. <inline-formula><alternatives><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>∈</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math><tex-math id="inft4">\begin{document}$  \in\mathbb{R}^{2}$\end{document}</tex-math></alternatives></inline-formula>) at a particular time <inline-formula><alternatives><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math><tex-math id="inft5">\begin{document}$  t$\end{document}</tex-math></alternatives></inline-formula>, while <inline-formula><alternatives><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math><tex-math id="inft6">\begin{document}$  \hat{\mathbf{u}}$\end{document}</tex-math></alternatives></inline-formula> is the learned representation, constrained according to some conditions <inline-formula><alternatives><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>R</mml:mi></mml:mstyle></mml:math><tex-math id="inft7">\begin{document}$  R$\end{document}</tex-math></alternatives></inline-formula>. Lastly, <inline-formula><alternatives><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft8">\begin{document}$  \mathbf{z}_{t}$\end{document}</tex-math></alternatives></inline-formula> is a latent position estimate corresponding to <inline-formula><alternatives><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft9">\begin{document}$  \mathbf{x}_{t}$\end{document}</tex-math></alternatives></inline-formula>. In our case, we consider a recurrently connected neural network architecture navigating along simulated trajectories. As such, <inline-formula><alternatives><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft10">\begin{document}$  \mathbf{z}_{t}$\end{document}</tex-math></alternatives></inline-formula> can be thought of as the network’s (internal) position estimate at a particular trajectory step, formed by integrating earlier locations and velocities. For details, refer to Model and objective.</p><p>Each entry in <inline-formula><alternatives><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math><tex-math id="inft11">\begin{document}$  \hat{\mathbf{u}}$\end{document}</tex-math></alternatives></inline-formula> can be viewed as the firing rate of a unit in an ensemble of <inline-formula><alternatives><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math><tex-math id="inft12">\begin{document}$  N$\end{document}</tex-math></alternatives></inline-formula> simulated neurons. On the other hand, <inline-formula><alternatives><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft13">\begin{document}$  \mathbf{u}$\end{document}</tex-math></alternatives></inline-formula> is an alternative representation of the space that we wish to represent. In machine learning terms, <inline-formula><alternatives><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft14">\begin{document}$  \mathcal{L}$\end{document}</tex-math></alternatives></inline-formula> is the loss function, while <inline-formula><alternatives><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>R</mml:mi></mml:mstyle></mml:math><tex-math id="inft15">\begin{document}$  R$\end{document}</tex-math></alternatives></inline-formula> is a regularization term. In our case, we want <inline-formula><alternatives><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft16">\begin{document}$  \mathcal{L}$\end{document}</tex-math></alternatives></inline-formula> to gauge the similarity between the learned and target representations, and for <inline-formula><alternatives><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>R</mml:mi></mml:mstyle></mml:math><tex-math id="inft17">\begin{document}$  R$\end{document}</tex-math></alternatives></inline-formula> to impose biological constraints on the learned <inline-formula><alternatives><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math><tex-math id="inft18">\begin{document}$  \hat{\mathbf{u}}$\end{document}</tex-math></alternatives></inline-formula>.</p><p>The target representation <inline-formula><alternatives><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft19">\begin{document}$  \mathbf{u}$\end{document}</tex-math></alternatives></inline-formula> does not need to be of the same dimensionality as <inline-formula><alternatives><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math><tex-math id="inft20">\begin{document}$  \hat{\mathbf{u}}$\end{document}</tex-math></alternatives></inline-formula>, or even particularly biologically plausible. This is evident in several prominent models in the literature (<xref ref-type="bibr" rid="bib9">Dordek et al., 2016</xref>; <xref ref-type="bibr" rid="bib8">Cueva and Wei, 2018</xref>; <xref ref-type="bibr" rid="bib2">Banino et al., 2018</xref>; <xref ref-type="bibr" rid="bib52">Sorscher et al., 2023</xref>) which can be accommodated by the proposed definition in <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> (see A Taxonomy of Cognitive Maps for complete descriptions). As an example, <xref ref-type="bibr" rid="bib8">Cueva and Wei, 2018</xref> trained a recurrent neural network (RNN) to minimize the mean squared error between a Cartesian coordinate target representation and a predicted coordinate decoded from the neural network (<xref ref-type="bibr" rid="bib8">Cueva and Wei, 2018</xref>). Remarkably, by adding biologically plausible constraints (including ‘energy’ constraints and noise injection) to this network, the authors found that the learned representations resembled biological (albeit square) grid cells.</p><p>As the goal of this work is to arrive at a model of place cells, we will denote the learned representation as <inline-formula><alternatives><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft21">\begin{document}$  \mathbf{p}$\end{document}</tex-math></alternatives></inline-formula>. We take <inline-formula><alternatives><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft22">\begin{document}$  \mathbf{p}$\end{document}</tex-math></alternatives></inline-formula> to be produced by a neural network with non-negative firing rates, whose architecture is illustrated in <xref ref-type="fig" rid="fig1">Figure 1a</xref>. Specifically, the network features recurrently connected units (with states <inline-formula><alternatives><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft23">\begin{document}$  \mathbf{g}$\end{document}</tex-math></alternatives></inline-formula>) that project onto output units (with states <inline-formula><alternatives><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft24">\begin{document}$  \mathbf{p}$\end{document}</tex-math></alternatives></inline-formula>), in loose analogy to the connectivity of the Entorhinal Cortex and CA1 subfield of the Hippocampus (<xref ref-type="bibr" rid="bib60">Witter, 2010</xref>; <xref ref-type="bibr" rid="bib27">Leutgeb et al., 2004</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>The model and task.</title><p>(<bold>a</bold>) Overview of the decoding approach: Given a simulated trajectory with coordinates <inline-formula><alternatives><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft25">\begin{document}$  \mathbf{x}$\end{document}</tex-math></alternatives></inline-formula>, the output states of the network are decoded in terms of their spatial center locations <italic><bold>μ</bold></italic>, which in turn are used to decode an estimate of the current location <inline-formula><alternatives><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math><tex-math id="inft26">\begin{document}$  \hat{\mathbf{x}}$\end{document}</tex-math></alternatives></inline-formula>. The network is trained to minimize the squared difference between true and decoded positions. (<bold>b</bold>) Illustration of the proposed decoding procedure. For a single unit, the center location is estimated as the average location, weighted by the unit activity along a trajectory. By iterating this procedure, every unit can be assigned a center location. A location can then be estimated as the average center location, weighted by the activity of the corresponding unit at a particular time. Repeating this for every timestep, full trajectories can be reconstructed. (<bold>c</bold>) The investigated geometries, each with an example simulated trajectory. Each environment is labelled by its context signal (one-hot vector). (<bold>d</bold>) Illustration of the network architecture and inputs. <inline-formula><alternatives><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft27">\begin{document}$  \mathbf{g}$\end{document}</tex-math></alternatives></inline-formula> features recurrently connected units, while <inline-formula><alternatives><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft28">\begin{document}$  \mathbf{p}$\end{document}</tex-math></alternatives></inline-formula> receives densely connected feedforward input from <inline-formula><alternatives><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft29">\begin{document}$  \mathbf{g}$\end{document}</tex-math></alternatives></inline-formula>. When moved between environments, the state of the RNN is maintained (<inline-formula><alternatives><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>prev</mml:mtext></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft30">\begin{document}$  \mathbf{g}_{\text{prev}}$\end{document}</tex-math></alternatives></inline-formula>). The input <inline-formula><alternatives><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">v</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft31">\begin{document}$  \mathbf{v}$\end{document}</tex-math></alternatives></inline-formula> denotes Cartesian velocities along simulated trajectories, while <inline-formula><alternatives><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">c</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft32">\begin{document}$  \mathbf{c}$\end{document}</tex-math></alternatives></inline-formula> is a constant (in time and space) context signal.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99302-fig1-v1.tif"/></fig><p>We constrain the ’energy’ of the learned representation by imposing an L1 penalty on its magnitude, use Cartesian coordinates as our target representation, and the mean squared error as our loss. In other words,<disp-formula id="equ2"><label>(2)</label><alternatives><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mrow><mml:mo>|</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>|</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t2">\begin{document}$$\displaystyle  S = \mathbb{E}_t\left[ \left|\mathbf{x}_t - \hat{\mathbf{x}}_t\right|_2^2 + \lambda |\mathbf{g}(\mathbf{z}_t)|_1 \right], \label{eq:loss}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft33">\begin{document}$  \mathbf{x}_{t}$\end{document}</tex-math></alternatives></inline-formula> is a true Cartesian coordinate, <inline-formula><alternatives><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft34">\begin{document}$  |\cdot|_{p}$\end{document}</tex-math></alternatives></inline-formula> denotes the <inline-formula><alternatives><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi></mml:mstyle></mml:math><tex-math id="inft35">\begin{document}$  p$\end{document}</tex-math></alternatives></inline-formula>-norm, and <inline-formula><alternatives><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:math><tex-math id="inft36">\begin{document}$  \lambda$\end{document}</tex-math></alternatives></inline-formula> is a regularization hyperparameter. Crucially, however, Cartesian coordinates are not predicted directly by the network, but are decoded from the population activity of the output layer. This decoder is non-trainable and inspired by the localized firing profile of place cells. Concretely, we form a position estimate directly from the population activity, according to<disp-formula id="equ3"><label>(3)</label><alternatives><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>ε</mml:mi><mml:mo>,</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t3">\begin{document}$$\displaystyle  \hat{\mathbf{x}}_t = \frac{\sum_{i=1}^N p_i(\mathbf{z}_t)\boldsymbol{\mu}_i}{\max\left(\varepsilon,\sum_{i=1}^N p_i(\mathbf{z}_t)\right) }, \label{eq:decoding}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where, again, <inline-formula><alternatives><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math><tex-math id="inft37">\begin{document}$  N$\end{document}</tex-math></alternatives></inline-formula> is the number of output units and <inline-formula><alternatives><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ε</mml:mi></mml:mstyle></mml:math><tex-math id="inft38">\begin{document}$  \varepsilon$\end{document}</tex-math></alternatives></inline-formula> is a small constant to prevent zero-division, while<disp-formula id="equ4"><label>(4)</label><alternatives><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow><mml:mrow><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>ε</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">]</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mstyle></mml:math><tex-math id="t4">\begin{document}$$\displaystyle  \boldsymbol{\mu}_i = \frac{\mathbb{E}_t [p_i(\mathbf{z}_t) \mathbf{x}_t] }{\max\left(\varepsilon,\mathbb{E}_t [p_i(\mathbf{z}_t)] \right)}, \quad i = 1, 2, 3, ..., N \label{eq:center_decoding}$$\end{document}</tex-math></alternatives></disp-formula></p><p>is the estimated <italic>center</italic> of a given output unit. Note that the decoding essentially just consists of two soft maximum operations: <xref ref-type="disp-formula" rid="equ4">Equation 4</xref> estimates the location of a cell’s maximal activity and <xref ref-type="disp-formula" rid="equ3">Equation 3</xref> yields a predicted position using a weighted average (i.e. an approximate center of mass) of unit activity and their corresponding center locations.</p><p>Intuitively, if one cell is highly active at a particular location, its center location will be pulled toward that position. If the centers of the entire ensemble can be established, a position estimate can then be formed as a weighted (by firing rate) sum of the ensemble activity. If multiple units in a particular region of space are co-active, the position estimate is pulled towards the (weighted) average of their center locations. This approach allows us to extract a position estimate directly from the neural ensemble without knowing the shape or firing characteristics of a given unit. This should encourage minimally constrained, yet place-like representations.</p><p><xref ref-type="fig" rid="fig1">Figure 1a</xref> provides a high-level overview of the proposed decoding scheme and the network explored in this work, and <xref ref-type="fig" rid="fig1">Figure 1b</xref> provides a more detailed account of how output unit activity is decoded to estimate the network’s position.</p><p>The network is tasked with minimizing <xref ref-type="disp-formula" rid="equ2">Equation 2</xref> while simultaneously path integrating (see 4.1 for details) along simulated trajectories in six distinct environments. Each environment, along with example trajectories is shown in <xref ref-type="fig" rid="fig1">Figure 1c</xref>. To discriminate between environments, the network is also provided with a constant context signal that uniquely identifies the geometry. An overview of the network architecture and inputs is given in <xref ref-type="fig" rid="fig1">Figure 1d</xref>, and each context signal is inset in <xref ref-type="fig" rid="fig1">Figure 1c</xref>. Notably, our network is not given any positional information and must infer its position by traversing and learning the geometry of the environment.</p></sec><sec id="s2-2"><title>Learned representations and remapping</title><p>With a model in place, we proceed by investigating the learned representations and behaviors of the trained network. <xref ref-type="fig" rid="fig2">Figure 2a</xref> shows the evolution of the decoding error (the average Euclidean distance between true and predicted trajectories) as a function of training time for the RNN. The validation set error closely trails the training error, and appears to converge around 0.15. The error is computed as an average over all six environments and over full trajectories (time). Thus, the decoding error includes initial timesteps, where the network has no positional information. Disentangled errors for each environment and along trajectories (time) can be seen in supplementary Fig. <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>, showing how different environments have different error profiles, and how errors decrease after some initial exploration. This can also be seen in <xref ref-type="fig" rid="fig2">Figure 2b</xref>, which showcases a slice of a true and corresponding predicted trajectory for timesteps 250–400 in the square environment.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Trained network performance and representations.</title><p>(<bold>a</bold>) Euclidean distance (error) between target and reconstructed trajectories over training time. Shown is the error for both training and validation datasets. (<bold>b</bold>) A slice (timesteps 250–400) of a decoded trajectory (dashed, red) and the corresponding target trajectory (black). (<bold>c</bold>) Ratemaps for the 16 output units with the largest mean activity, in the square environment. (<bold>d</bold>) Same as (<bold>c</bold>), but for recurrent units.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99302-fig2-v1.tif"/></fig><p>Having established that network predictions align with target trajectories (confirming that the network has learned to path integrate), we consider the learned representations of the network. <xref ref-type="fig" rid="fig2">Figure 2c</xref> displays ratemaps of the 16 most active output units in the square environment. Notably, the responses of these units resemble biological place cell tuning curves. The learned place fields appear unimodal, isotropic, and with a monotonically decaying firing rate from their center, much like a Gaussian profile. However, some units display more irregular fields, especially near boundaries and corners. Responses of the most active recurrent units resemble biological border cells (<xref ref-type="fig" rid="fig2">Figure 2d</xref>). For both the output and recurrent layers, a large fraction of units are silent or display no clear spatial tuning (see <xref ref-type="fig" rid="app1fig2">Appendix 1—figures 2</xref> and <xref ref-type="fig" rid="app1fig3">3</xref> for ratemaps in all environments). For example, in the square arena, approximately half of all output units are silent.</p><p>Interestingly, when comparing network spatial responses across environments, units display changes in their tuning curve. This effect can be clearly observed in unit ratemaps shown in <xref ref-type="fig" rid="fig3">Figure 3a</xref>. In the numerical experiment, the trained network is first run in the square environment (context A), before being moved to the square with a central wall (context B), and subsequently returned to the original square (context A’). Visually, many output units exhibit marked shifts in their preferred firing location when the network is moved between contexts (i.e. transfers A to B or B to A’). However, returning to the original context appears to cause fields to revert to their original preferred firing locations. In addition to firing location modifications, units also exhibit distinct rate changes. Besides output units, recurrently connected units also display remapping behavior when the network is moved between environments. As shown in the unit ratemaps of <xref ref-type="fig" rid="fig3">Figure 3a</xref> and (i), boundary units exhibit rate changes. In particular, several units are silenced when moving between conditions. However, none of the included units exhibit changes in their preferred firing location. Thus, recurrent units appear to remap mainly through pronounced rate changes, which we also demonstrate in Recurrent units rate remap.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Comparing representations across environments.</title><p>(<bold>a</bold>) Top: The network is run in a familiar square environment (<bold>A</bold>), transferred to the square with a central wall (<bold>B</bold>), and revisits the original square (<bold>A’</bold>). The network state persists between environments, and starting locations are randomly sampled. Bottom: (i) Ratemaps for a subset of recurrent units (<inline-formula><alternatives><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft39">\begin{document}$  \mathbf{g}$\end{document}</tex-math></alternatives></inline-formula>) with the largest minimum mean rate across arenas. Rows represent unit activity, with max rate inset on the right. (ii) Same as (i), for output units. (<bold>b</bold>) Distribution of spatial correlations comparing ratemaps from active units across similar contexts (<bold>A, A’</bold>) and distinct contexts (<bold>A, B</bold>). Shuffled distributions are formed by randomly pairing units across contexts. The dashed red line indicates the 95<sup>th</sup> percentile of the shuffled distribution. (<bold>c</bold>) Distribution of rate overlaps for all units with non-zero activity in any environment. (<bold>d</bold>) Distribution of rate differences. (<bold>e</bold>) Ratemap population vector correlations for units with non-zero activity at every timestep for transitions (timestep 500) from A to B.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99302-fig3-v1.tif"/></fig><p>That the network exhibits remapping-type behaviors is supported by multiple analyses (<xref ref-type="fig" rid="fig3">Figure 3b–e</xref>). In particular, the distribution of output unit spatial correlations across different environments (A and B) matches that expected from a shuffled distribution. Conversely, correlations comparing different visits of the same environment (A and A’) are different from a shuffled distribution (<xref ref-type="fig" rid="fig3">Figure 3b</xref>). This behavior is consistent with global remapping behavior (<xref ref-type="bibr" rid="bib27">Leutgeb et al., 2004</xref>; <xref ref-type="bibr" rid="bib28">Leutgeb et al., 2005</xref>). Notably, the network’s remapping occurs with fixed weights (i.e. after training). Rate overlaps (<xref ref-type="fig" rid="fig3">Figure 3c</xref>) display similar distributional properties: Comparing across environments yields rate overlaps resembling those from a shuffled distribution, and comparing similar environments yields higher rate overlaps.</p><p>Rate differences (<xref ref-type="fig" rid="fig3">Figure 3d</xref>) also follow the same trend. In this case, the difference in rates between A and A’ is chiefly zero-centered and approximately symmetric, suggesting that there are only small rate changes when revisiting an environment. The rate difference between environments (and between shuffled units), is also roughly symmetric. However, in this case, the distribution is bimodal with peaks corresponding to maximally different rates. Thus, a large number of output units are active in only one environment. Again, the distribution of differences between distinct contexts closely trails a shuffled distribution. As shown in <xref ref-type="fig" rid="fig3">Figure 3e</xref>, ratemap population vector correlations mirror the transition between environments, both for recurrent units and output units. Included are correlations for the transition from A to B (at timestep 500). Notably, there is a sharp drop-off in correlation at the transfer time, demonstrating that population vectors are uncorrelated between environments for both unit types. Conversely, ratemaps are highly correlated within an environment. However, there is a time delay before maximum correlation is achieved.</p><p>Together, these findings demonstrate that the model learns place- and border-like spatial representations. Moreover, output units exhibit global remapping between contexts, whereas recurrent units mainly rate remap.</p></sec><sec id="s2-3"><title>Effects of geometric manipulations</title><p>In addition to remapping between different contexts, we show that manipulating familiar geometries induces distinct representational changes. In particular, <xref ref-type="fig" rid="fig4">Figure 4a</xref> shows how unit ratemaps respond as the familiar square environment is elongated horizontally. Intriguingly, the learned place-like fields of the output units appear to expand with the arena. For sufficient elongation, responses even appear to split, with an additional, albeit weaker firing field emerging (e.g. lower right output unit, 2 x elongation). Elongation behavior has also been observed in biological place cells in similar experiments (<xref ref-type="bibr" rid="bib39">O’Keefe and Burgess, 1996</xref>).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Effects of geometric manipulations on learned representations while maintaining the original context signal.</title><p>(<bold>a</bold>) Ratemaps of ine recurrent (<inline-formula><alternatives><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft40">\begin{document}$  \mathbf{g}$\end{document}</tex-math></alternatives></inline-formula>) and output units (<inline-formula><alternatives><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft41">\begin{document}$  \mathbf{p}$\end{document}</tex-math></alternatives></inline-formula>) during horizontal elongation of a familiar square context. The top inset indicates the geometry and context signal (<bold>A</bold>), as well as manipulation of the environment (horizontal stretch by factors of 2 and 3). (<bold>b</bold>) Similar to (<bold>a</bold>), but the geometric manipulation consists of filling in the central hole of the familiar context (square with central hole, context B). (<bold>c</bold>) Similar to (<bold>a</bold>), but for joint horizontal and vertical elongation. (<bold>d</bold>) Similar to (<bold>c</bold>), but for uniform expansion of a familiar circular environment (<bold>C</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99302-fig4-v1.tif"/></fig><p>Expanding the square also elicits a distinct response in recurrent units: Unit firing fields extend to the newly accessible region, while maintaining their affinity for boundaries. A similar effect can be observed in <xref ref-type="fig" rid="fig4">Figure 4b</xref>, where the central hole is removed from a familiar geometry. In this case, both recurrent and output units perform field completion by extending existing firing fields to previously unseen regions. This shows that the network is capable of generalizing to never-before-seen regions of space.</p><p>Finally, we also considered the effects of expanding environments in a symmetric fashion. Included are results for the familiar square (<xref ref-type="fig" rid="fig4">Figure 4c</xref>) and circular (<xref ref-type="fig" rid="fig4">Figure 4d</xref>) environments. Unlike the single-axis expansion in <xref ref-type="fig" rid="fig4">Figure 4a</xref>, network representations expand symmetrically in response to uniform expansion. However, some output units display distinct field doubling (see e.g. 2x expansion; middle inset for both <xref ref-type="fig" rid="fig4">Figure 4c</xref>, bottom right, and <xref ref-type="fig" rid="fig4">Figure 4d</xref>, middle row). For large expansions (3 x), output responses become more irregular. However, in the square environment, there are still visible subpeaks within unit ratemaps and some output units reflect their main boundary input (with greater activity near one boundary). Recurrent units, on the other hand, largely maintain their firing profile. In the circular environment, some output units display an almost center surround-like profile (e.g. 3 x expansion, middle row, two rightmost units). This peculiar tuning pattern is an experimentally testable prediction of our model.</p></sec><sec id="s2-4"><title>Representations are attractive</title><p>We have demonstrated that the RNN exhibits signs of global remapping between different familiar contexts, and field changes when a familiar geometry is altered. In this section, we further explore the behavior of the network when perturbing its internal states out of its normal operating range. Finally, we also discovered possible mechanisms supporting the network’s remapping ability.</p><p>The first analysis consists of injecting noise into the recurrent state of the network, to determine whether it exhibits attractor-like behavior. <xref ref-type="fig" rid="fig5">Figure 5</xref> shows the resulting ratemap population vector correlations for an 800-step trajectories in the square context, when noise is injected at the midpoint of the sequence. When no noise is injected (<inline-formula><alternatives><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math><tex-math id="inft42">\begin{document}$  \sigma=0$\end{document}</tex-math></alternatives></inline-formula>), both recurrent units (<xref ref-type="fig" rid="fig5">Figure 5a</xref>) and output units (<xref ref-type="fig" rid="fig5">Figure 5b</xref>) quickly settle into a stable highly correlated state. Unit ratemaps reveal that this state corresponds to network units firing at their preferred locations.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Effects of noise injection during navigation.</title><p>(<bold>a</bold>) Ratemap population vector Pearson correlation between timepoints of 800-step trajectories in the square environment. At timestep 400, additive Gaussian noise (with standard deviation <inline-formula><alternatives><mml:math id="inf43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi></mml:mstyle></mml:math><tex-math id="inft43">\begin{document}$  \sigma$\end{document}</tex-math></alternatives></inline-formula>) is injected into the recurrent state (<inline-formula><alternatives><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft44">\begin{document}$  \mathbf{g}$\end{document}</tex-math></alternatives></inline-formula>). The top row shows correlations for different noise levels (<inline-formula><alternatives><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0.01</mml:mn><mml:mo>,</mml:mo><mml:mn>0.1</mml:mn></mml:mstyle></mml:math><tex-math id="inft45">\begin{document}$  \sigma=0,0.01,0.1$\end{document}</tex-math></alternatives></inline-formula>, and 1.0). The bottom row features ratemaps of the four units with the largest mean activity, at different timepoints. Ratemaps are shown for <inline-formula><alternatives><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math><tex-math id="inft46">\begin{document}$  \sigma=0$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>1.0</mml:mn></mml:mstyle></mml:math><tex-math id="inft47">\begin{document}$  \sigma=1.0$\end{document}</tex-math></alternatives></inline-formula>. (<bold>b</bold>) Same as a), but for output units <inline-formula><alternatives><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft48">\begin{document}$  (\mathbf{p}$\end{document}</tex-math></alternatives></inline-formula>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99302-fig5-v1.tif"/></fig><p>When noise is injected, ratemap correlations temporarily decrease, before the network settles back into a steady-state configuration. Importantly, states before, and long after noise injection are highly correlated. We observe that this is also the case for moderate amounts of injected noise, as can be seen from unit ratemaps for <inline-formula><alternatives><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>1.0</mml:mn></mml:mstyle></mml:math><tex-math id="inft49">\begin{document}$  \sigma=1.0$\end{document}</tex-math></alternatives></inline-formula>. We also observe that the time required to reach a steady state increases in proportion to the amount of noise injected. Thus, even though the network was trained without noise, it appears robust to moderate perturbations. This suggests that the learned solutions form an approximate attractor. To verify that this attractive behavior is not solely due to error correction following boundary interactions, we also conducted a similar experiment, in which velocities are ablated at noise injection (see Velocity Ablation).</p><p>Beyond the fact that the network appears to converge towards particular, steady-state representations after noise injection, we also note that each environment appears to correspond to distinct attractive states (as evidenced by the global-type remapping behavior). To uncover why the network converges to a given representation, we conducted a simple context mismatch experiment (see Representations are guided by context for details and ratemaps), which suggests that the context signal determines the resulting representation, up to geometric deformations (as in <xref ref-type="fig" rid="fig4">Figure 4</xref>).</p><p>To further explore the network’s behavior, we applied dimensionality reduction techniques to network states along a single trajectory visiting all geometries (and contexts). Remarkably, we find that a low-dimensional projection of the recurrent state captures the shape of each traversed environment. The top row of <xref ref-type="fig" rid="fig6">Figure 6a</xref> showcases a 3D projection of the recurrent state, where each point is color-coded by the visited environment. Besides reflecting the shape of the environment, the low-dimensional projection also showcases transitions between environments. For output units (bottom row of <xref ref-type="fig" rid="fig6">Figure 6a</xref>), the low-dimensional projection consists of intersecting hyperplanes that appear to maintain some of the structure of the original geometry. For example, states produced in the square with a central hole, appears to maintain a central void in the low-dimensional projection. The difference between recurrent and output states may reflect the pronounced sparsity of the recurrent layer, as well as the observed reuse of output units during remapping. In other words, a large number of recurrent units are mutually silent across environments, which could make for easily separable states. In contrast, a larger fraction of output units are used, and reused, across environments, leading to entangled and less separable states.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Low-dimensional behavior of the trained recurrent network.</title><p>(<bold>a</bold>) Low-dimensional UMAP projection of the recurrent (top) and output unit (bottom) activity for a trajectory visiting all six environments. The color of a point in the cloud corresponds to the environment identity. (<bold>b</bold>) Fractional and cumulative explained variance using PCA for recurrent units for each environment. (<bold>c</bold>) similar to (<bold>b</bold>) but for output units. (color scheme as in <bold>a</bold>). (<bold>d</bold>) Eigenvalue spectrum of the recurrent weight matrix. The unit circle (gray) is inset for reference. (<bold>e</bold>) Jitter plots of context weights corresponding to each environment. For every environment, the weight to each recurrent unit is indicated. (<bold>f</bold>) Pearson correlation between context weights corresponding to different environments.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99302-fig6-v1.tif"/></fig><p>Using PCA, we find that the recurrent states of the network within an environment can be well described using just a few principal components (four principal components explains &gt;90% of the variance). For reference, <xref ref-type="fig" rid="fig6">Figure 6b</xref> showcases the fraction of explained variance, as well as the cumulative variance of the recurrent state. However, the same is not true for the full trajectory visiting all environments (requiring around 20 principal components to achieve a similar amount of explained variance). This hints that the multi-environment representation can be factorized into several independent, low-dimensional representations, possibly one for each environment.</p><p>A similar trend is evident for output unit responses (shown in <xref ref-type="fig" rid="fig6">Figure 6c</xref>). However, in this case, a larger number of units is needed to explain a substantial fraction of the state variance for each environment (&gt;25 for approximately 70–90% explained variance) with noticeable differences between environments. Also, almost all (&gt;75, out of 100) principal components are required to account for the full output state across environments. It thus appears that more independent units are active within a given environment, and that all 100 units are involved in encoding the full set of environments.</p><p>To begin exploring possible mechanisms supporting remapping, and the apparent independence of network states across environments, we investigated the weights of the recurrent layer. <xref ref-type="fig" rid="fig6">Figure 6d</xref> shows the eigenvalues of the recurrent weight matrix. It has several eigenvalues with above-unit magnitude. In other words, the RNN is potentially unstable. However, as shown in <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>, the network exhibits stable decoding errors, even for very long sequences. Moreover, we know from <xref ref-type="fig" rid="fig5">Figure 5</xref> that the network is stable in the face of transient noise injection. One possibility is that the nonlinearity of the recurrent network ensures stability. Another interesting possibility is that large eigenvalues are associated with remapping, where unstable eigenvectors correspond to transitions between discrete attractors representing distinct environments.</p><p>We have already demonstrated that the context signal apparently fixes the global representation (see Representations are guided by context) but the question still remains <italic>how</italic> the network switches between representations. While a complete description depends on the non-linear behavior of the full RNN, we observe a relationship within the context input weights that could shed light on the behavior in the network. Concretely, we find that a large proportion of context weights are negative (<xref ref-type="fig" rid="fig6">Figure 6e</xref>), and the rows of this matrix are largely uncorrelated (<xref ref-type="fig" rid="fig6">Figure 6f</xref>). Thus, the context signal (which is non-negative) could inhibit independent sets of units, leading to sparse and orthogonal recurrent units across environments through rate changes, and providing a simple mechanistic interpretation of the observed remapping behavior.</p></sec><sec id="s2-5"><title>Distribution of learned centers</title><p>Experimentally, place fields appear to be irregularly distributed throughout large environments with a small increase in the number of fields near boundaries (<xref ref-type="bibr" rid="bib16">Harland et al., 2021</xref>). Place field phases have also been shown to correlate with the peak firing locations of grid cells (<xref ref-type="bibr" rid="bib58">Whittington et al., 2020</xref>). We, therefore, explore whether there is structure to the spatial arrangement of the model’s learned place fields.</p><p><xref ref-type="fig" rid="fig7">Figure 7a</xref> shows the arrangement of decoded centers for all units, collected over 100 long-sequence trajectories, in each environment. In other words, for each cell in the population, their centers are decoded 100 times, one for each trajectory. Surprisingly, we find that the decoded centers tend to reside on the vertices of a semi-hexagonal grid, especially in larger symmetrical geometries. This effect is especially evident in the square and large square environments. However, in all environments, this grid structure exhibits distortions, and in the case of an anisotropic environment (the rectangle), the grid is clearly elongated along the horizontal axis. Our findings accord with the notion that place fields are likely to reside on the vertices of a hexagonal grid (<xref ref-type="bibr" rid="bib58">Whittington et al., 2020</xref>). These findings also resonate with the observations that grid cell patterns deform in non-symmetric environments and novel environments (<xref ref-type="bibr" rid="bib22">Krupic et al., 2015</xref>; <xref ref-type="bibr" rid="bib4">Barry et al., 2012</xref>; <xref ref-type="bibr" rid="bib13">Ginosar et al., 2023</xref>). However, our model does not feature any grid-like units. Together with the fact that our model is optimized for decoding, it appears likely that such an arrangement is somehow advantageous for encoding and decoding location.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Output unit centers reside in hexagon-like arrangements.</title><p>(<bold>a</bold>) Center locations for each output unit (<inline-formula><alternatives><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft50">\begin{document}$  \mathbf{p}$\end{document}</tex-math></alternatives></inline-formula>) in every geometry, decoded from 100, 30000-timestep trajectories for units with high spatial information. Decoded centers are shaded by unit identity. (<bold>b</bold>) Center locations and marginal distributions of centers in each environment, for active units along a single trajectory. (<bold>c</bold>) Displacement of centers between environments for units with high spatial information. Every unit is color-coded by its spatial location in the environment on the diagonal. For each row, the distribution of the included units are shown in every other environment. (<bold>d</bold>) Same as (<bold>c</bold>), but for all units. (<bold>e</bold>) Experimental CA1 place field centers decoded from ratemaps for a mouse foraging in a square 75×75 cm environment (left) and corresponding kernel density estimate (right). (<bold>f</bold>) Ripley’s H for the field centers in (<bold>e</bold>) and random (uniform) distributions on the same 15×15 grid as in <bold>e</bold>. The shaded region indicates two standard deviations for 100 random, uniform samplings of the grid.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99302-fig7-v1.tif"/></fig><p>In <xref ref-type="fig" rid="fig7">Figure 7b</xref> we display an example decoding of centers along with their one-dimensional marginal distributions. We find that the centers seem to cluster somewhat along the borders of the environment, similar to experimental observations in <xref ref-type="bibr" rid="bib16">Harland et al., 2021</xref>, which might reflect the upstream boundary input of our model’s output units. Unlike the aggregate over multiple trajectories, the single-trajectory decoding does not reveal an equally pronounced hexagonal arrangement. Besides exhibiting a striking hexagonal distribution within an environment, we also observe that there is no apparent pattern to the transformation of center locations between environments. This once again supports the finding that units undergo global-type remapping between environments (see <xref ref-type="fig" rid="fig7">Figure 7c–d</xref>) where color coding is relative to position in the environment along the diagonal.</p><p>To investigate whether fields in biological place cells display center clustering similar to our model, we decoded the field centers of CA1 place cells (data provided by <xref ref-type="bibr" rid="bib26">Lee et al., 2023</xref>), see Ripley’s H &amp; Clustering and Experimental Phase Distributions for details and extended results. <xref ref-type="fig" rid="fig7">Figure 7e</xref> shows a distribution of place field centers from one example animal (QLAK-CA1-50), and a corresponding kernel density estimate. We can see that field centers cluster near boundaries. Moreover, there appears to be a tendency for the clusters to arrange in a hexagonal fashion, similar to our computational findings.</p><p>To further quantify the regularity in the spatial arrangement of field centers, we considered Ripley’s H function, which gauges the average number of points falling within a particular radius of any other point relative to a uniform baseline, thus providing a measure of clustering in point data. <xref ref-type="fig" rid="fig7">Figure 7f</xref> shows Ripley’s H for the field centers, as well as a random baseline sampled on a 15×15 grid matching the experimental ratemap resolution. We find that Ripley’s H is larger for the experimental data than for random, uniform samples at small and intermediate scales. This indicates that the place field centers cluster more than expected (outside two standard deviations) for uniform sampling. The clustering is stronger at small distances and intermediate ones (0–5 cm and around 7–17 cm). We also observed similar clustering for other animals, but most did not exhibit any pronounced spatial arrangement in the kernel density estimate (see Experimental Phase Distributions for more). While not conclusive, these findings provide preliminary evidence that there might be more structure to the arrangements of Hippocampal place cells, and investigation of larger datasets is warranted in the future.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this work, we have proposed a neural network model that forms place-like spatial representations by decoding learned cognitive maps. Surprisingly, the trained network displays a range of behaviors exhibited by biological place cells, including global remapping across environments and field deformation during geometric manipulations of familiar arenas. Besides reproducing existing place cell experiments, our model makes some surprising predictions.</p><p>Our first prediction is that border-type input is sufficient to explain not only place field formation, but also place cell global remapping. While a strong relationship between border cells and place cells has been argued previously (<xref ref-type="bibr" rid="bib3">Barry et al., 2006</xref>; <xref ref-type="bibr" rid="bib17">Hartley et al., 2000</xref>), possible influences on Hippocampal remapping remain relatively unexplored. In our model, we find that place cell remapping arises as a result of sparse input from independent cell assemblies, enacted through strong boundary cell rate changes. Current experimental evidence suggests that border cells largely maintain their firing rate during conditions that elicit place cell remapping (<xref ref-type="bibr" rid="bib51">Solstad et al., 2008</xref>; <xref ref-type="bibr" rid="bib29">Lever et al., 2009</xref>). However, we find that the border code is highly sparse, and so only a small number of such rate-remapping, boundary-type cells would actually be required. Thus, investigating whether border cells <italic>can</italic> display rate changes could be an interesting avenue for future research.</p><p>While it could be that border cells in the brain do not (rate) remap, a border-to-place model could still be viable through alternate pathways, such as via gating mechanisms. In this case, a boundary signal projected onto downstream place cells could be gated by contextual signals originating from the lateral Entorhinal Cortex (lEC). <xref ref-type="bibr" rid="bib19">Jeffery, 2011</xref> demonstrated that a gated grid cell input signal could give rise to biologically plausible, place-like spatial signals (<xref ref-type="bibr" rid="bib19">Jeffery, 2011</xref>). In a similar way, gated boundary input could conceivably account for not only place field formation and boundary-selectivity, but also remapping.</p><p>Given the range of place cell behaviors our model reproduces, we hold that the border-to-place model it learns should be taken seriously. However, it is worth noting that there are still place behaviors unaccounted for in our work. For instance, we do not observe field doubling when walls are inserted in familiar environments (results not shown), as observed in vivo (<xref ref-type="bibr" rid="bib3">Barry et al., 2006</xref>). However, it is reasonable to suspect that this is due to the lack of sensory information available to the network, as there is no way for the network to detect novel walls. Therefore, adding boundary-selective sensory input to our network could conceivable uncover even more place cell behaviors. This is also supported by the fact that <xref ref-type="bibr" rid="bib57">Uria et al., 2020</xref> observed field doubling in the responses of their model, which utilizes visual input. Thus, adding other sensory modalities may be a fruitful extension of the current model.</p><p>A related missing feature is the lack of multiple firing fields as expressed by biological place cells, particularly in large recording environments (<xref ref-type="bibr" rid="bib40">Park et al., 2011</xref>). While our network does exhibit more firing fields when familiar contexts are expanded, place cells can reliably exhibit multiple fields, likely as part of a coding strategy. In contrast, our decoding operation only extracts a single center location, which may limit the expressivity of the network. Future work could, therefore, consider alternative decoding approaches that place even less strict requirements on learned representations.</p><p>Our second surprising finding is the model’s conspicuous lack of grid cells. As already mentioned, grid cells have been proposed as a possible precursor to place cells (<xref ref-type="bibr" rid="bib19">Jeffery, 2011</xref>; <xref ref-type="bibr" rid="bib33">Moser et al., 2008</xref>; <xref ref-type="bibr" rid="bib50">Solstad et al., 2006</xref>). Grid cells are also often posited as being important for path integration (<xref ref-type="bibr" rid="bib14">Hafting et al., 2005</xref>; <xref ref-type="bibr" rid="bib6">Burak and Fiete, 2009</xref>; <xref ref-type="bibr" rid="bib7">Bush et al., 2015</xref>). Accurate path integration is especially important in the absence of location-specific cues such as landmarks. The only pieces of information available to our model is a velocity signal, an environment-identifying context signal, and a weak, implicit boundary signal (since trajectories cannot exit environment boundaries). As such, there is no explicit sensory information, and path integration is required to solve the position reconstruction task. If grid cells are optimized chiefly for path integration, one would expect that the model learned grid-like solutions. As our model only learns border-type recurrent representations, our findings raise questions concerning the necessity of grid cells for path integration, as well as the causal relationship between place cells and grid cells. That grid cells may not be required to do path integration has also been shown in other recent normative models (<xref ref-type="bibr" rid="bib47">Schøyen et al., 2023</xref>).</p><p>While the lack of grid cells in this model is interesting, it does not disqualify grid cells from serving as a neural substrate for path integration. Rather, it suggests that path integration may also be performed by other, non-grid spatial cells, and/or that grid cells may serve additional computational purposes. If grid cells are involved during path integration, our findings indicate that additional tasks and constraints are necessary for learning such representations. This possibility has been explored in recent normative models, in which several constraints have been proposed for learning grid-like solutions. Examples include constraints concerning population vector magnitude, conformal isometry (<xref ref-type="bibr" rid="bib61">Xu et al., 2022</xref>; <xref ref-type="bibr" rid="bib46">Schaeffer et al., 2023</xref>; <xref ref-type="bibr" rid="bib48">Schøyen et al., 2024</xref>), capacity, spatial separation, and path invariance (<xref ref-type="bibr" rid="bib46">Schaeffer et al., 2023</xref>). Another possibility is that grid cells are geared more towards other cognitive tasks, such as providing a neural metric for space (<xref ref-type="bibr" rid="bib13">Ginosar et al., 2023</xref>; <xref ref-type="bibr" rid="bib42">Pettersen et al., 2024</xref>), or supporting memory and inference-making (<xref ref-type="bibr" rid="bib58">Whittington et al., 2020</xref>). That our model performs path integration without grid cells, and that a myriad of independent constraints are sufficient for grid-like units to emerge in other models, presents strong computational evidence that grid cells are not solely defined by path integration, and that path integration is not only reserved for grid cells.</p><p>Besides functional constraints, an important consideration when building neural network models is their architecture. In our model, information primarily flows from recurrently connected, mEC-type units, to CA1-type units by feedforward projections. However, CA1 responses also feed back to the Entorhinal Cortex, via the Subiculum (<xref ref-type="bibr" rid="bib24">Langston et al., 2010</xref>). Such a loop structure is explored in <xref ref-type="bibr" rid="bib32">Morris and Derdikman, 2023</xref>, which also makes use of nongrid spatial cells to inform place field formation, similar to our findings. Incorporating a feedback pathway (from output units to recurrent units) could allow for exploring the connection between grid cells, place cells, and remapping.</p><p>While our model does not produce grid-like <italic>representations</italic>, we do observe a striking, grid-like structure in the arrangement of output unit centers. Notably, these centers arrange hexagonally in arenas with open interiors, such as the large square. While a hexagonal placement of field centers has yet to be uncovered experimentally, <xref ref-type="bibr" rid="bib58">Whittington et al., 2020</xref> showed that place cell phases are correlated with grid cell peak locations across environments (<xref ref-type="bibr" rid="bib58">Whittington et al., 2020</xref>). Because the network has learned this particular arrangement to optimize position reconstruction, a hexagonal phase pattern may be optimal for decoding one’s position, even in diverse geometries. This is also alluded to by the fact that we observe clustering, and possible structure in the center locations of CA1 place fields in mice data obtained in <xref ref-type="bibr" rid="bib26">Lee et al., 2023</xref>. In the future, larger recordings and in different animals could help solidify whether place field centers exhibit the striking hexagonal arrangement predicted by our model for optimal decoding.</p><p>A hexagonal place field arrangement also suggests a possible connection between boundary, place, and grid cells. Boundary-tuned cells could inform place cell pattern formation, which in turn guides grid cell patterns. Such a border-to-place-to-grid cell model could explain grid cell behavior in non-standard or changing environments. For example, grid cells can exhibit (temporary) pattern elongation in novel environments (<xref ref-type="bibr" rid="bib4">Barry et al., 2012</xref>). This grid elongation could be induced by field elongation in place cells, which in turn is caused by boundary field continuation. Besides temporary rescaling, grid patterns are also permanently influenced by environment geometry (<xref ref-type="bibr" rid="bib22">Krupic et al., 2015</xref>), hinting that grid cells receive boundary-dependent input. Furthermore, it has been suggested that border cells serve an error-correcting function for grid cells during navigation (<xref ref-type="bibr" rid="bib15">Hardcastle et al., 2015</xref>). In a boundary-to-place-to-grid model, grid error correction could arise from place-cell inputs informed by boundary responses, or from border cells directly.</p><p>In summary, our proposed model, with its notion of a spatial cognitive map and fixed decoding, allows for exploring place cell formation and remapping. In particular, we find that learned place-like representations are formed by boundary input from upstream recurrent units. Global remapping arises from sparse input from differentially activated boundary units. Our work has important implications for understanding Hippocampal remapping, place field formation, as well as the place cell-grid cell system.</p></sec><sec id="s4" sec-type="methods"><title>Methods</title><p>Code Availability: Code to reproduce models, datasets, and numerical experiments is available from <ext-link ext-link-type="uri" xlink:href="https://github.com/bioAI-Oslo/VPC">https://github.com/bioAI-Oslo/VPC</ext-link> (copy archived at <xref ref-type="bibr" rid="bib43">Pettersen, 2025</xref>).</p><sec id="s4-1"><title>Model &amp; objective</title><p>In this work, we trained a recurrent neural network to solve the proposed position reconstruction task <xref ref-type="disp-formula" rid="equ2">Equation 2</xref> using stochastic gradient descent, using the mean squared error as a loss function, i.e.,<disp-formula id="equ5"><alternatives><mml:math id="m5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">[</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi mathvariant="bold">t</mml:mi></mml:msub></mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mn>2</mml:mn></mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t5">\begin{document}$$\displaystyle  \mathcal{L} = \mathbb{E}_t [(\mathbf{x_t} - \hat{\mathbf{x}}_t)^2],$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft51">\begin{document}$  \mathbf{x}_{t}$\end{document}</tex-math></alternatives></inline-formula> is a Cartesian target coordinate at a particular time <inline-formula><alternatives><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math><tex-math id="inft52">\begin{document}$  t$\end{document}</tex-math></alternatives></inline-formula> along a spatial trajectory, and <inline-formula><alternatives><mml:math id="inf53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft53">\begin{document}$  \hat{\mathbf{x}}_{t}$\end{document}</tex-math></alternatives></inline-formula> a corresponding predicted position, decoded from the network’s output representations (see below).</p><p>As the proposed objective function does not impose explicit constraints on the functional form or spatial arrangement of the learned representations, we trained the network in a small set of diverse geometries (see <xref ref-type="fig" rid="fig1">Figure 1c</xref>) for an illustration. This was done to explore whether the network would learn different representations in different rooms, as a way of optimally encoding the space.</p><p>The recurrent network was only given velocity information as input and, therefore, had to learn to perform path integration in order to minimize the position reconstruction task. Concretely, the path integration task consisted of predicting self-position along simulated trajectories. For each trajectory, the network was initialized at a random location in the environment, without initial position information (see 4.2 for initialization details). At every time step <inline-formula><alternatives><mml:math id="inf54"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math><tex-math id="inft54">\begin{document}$  t$\end{document}</tex-math></alternatives></inline-formula> along a trajectory, the network received a Cartesian velocity signal <inline-formula><alternatives><mml:math id="inf55"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft55">\begin{document}$  \mathbf{v}_{t}$\end{document}</tex-math></alternatives></inline-formula>, mimicking biological self-motion information. Denoting a particular point along a trajectory parameterized by time as <inline-formula><alternatives><mml:math id="inf56"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft56">\begin{document}$  \mathbf{x}_{t}$\end{document}</tex-math></alternatives></inline-formula>, the decoded position of the network was<disp-formula id="equ6"><label>(5)</label><alternatives><mml:math id="m6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>ε</mml:mi><mml:mo>,</mml:mo><mml:munderover><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t6">\begin{document}$$\displaystyle  \hat{\mathbf{x}}_t = \frac{\sum_{i=1}^N p_i(\mathbf{z}_t)\boldsymbol{\mu}_i}{\max\left(\varepsilon, \sum_{i=1}^N p_i(\mathbf{z}_t)\right)}, \label{eq:latent_position_estimate}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf57"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft57">\begin{document}$  \mathbf{z}_{t}$\end{document}</tex-math></alternatives></inline-formula> is the network’s latent estimate of position at time <inline-formula><alternatives><mml:math id="inf58"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math><tex-math id="inft58">\begin{document}$  t$\end{document}</tex-math></alternatives></inline-formula>, formed by integration of previous positions and velocities. In our case, output states <inline-formula><alternatives><mml:math id="inf59"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft59">\begin{document}$  \mathbf{p}_{t}$\end{document}</tex-math></alternatives></inline-formula> are computed as rectified linear combinations of an upstream recurrent layer (see 4.2 for a description). Meanwhile,<disp-formula id="equ7"><label>(6)</label><alternatives><mml:math id="m7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi mathvariant="bold-italic">μ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>ε</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>]</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mstyle></mml:math><tex-math id="t7">\begin{document}$$\displaystyle  \boldsymbol{\mu}_i = \frac{\mathbb{E}_{t} \left[ p_i(\mathbf{z}_t)\mathbf{x}_t \right]}{\max\left(\varepsilon, \mathbb{E}_t\left[ p_i(\mathbf{z}_t)\right]\right)} \quad i = 1, 2, 3, ..., N$$\end{document}</tex-math></alternatives></disp-formula></p><p>is the center location estimate for output unit <inline-formula><alternatives><mml:math id="inf60"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math><tex-math id="inft60">\begin{document}$  i$\end{document}</tex-math></alternatives></inline-formula>, formed using the network states during navigation.</p><p>Lastly, we provided the network with a constant one-hot context signal at every timestep, as a token for identifying the environment. The input at time <inline-formula><alternatives><mml:math id="inf61"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math><tex-math id="inft61">\begin{document}$  t$\end{document}</tex-math></alternatives></inline-formula> was, therefore, a concatenation of <inline-formula><alternatives><mml:math id="inf62"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft62">\begin{document}$  \mathbf{v}_{t}$\end{document}</tex-math></alternatives></inline-formula> and a time-independent context signal <inline-formula><alternatives><mml:math id="inf63"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">c</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft63">\begin{document}$  \mathbf{c}$\end{document}</tex-math></alternatives></inline-formula>. See <xref ref-type="fig" rid="fig1">Figure 1d</xref> for an illustration.</p></sec><sec id="s4-2"><title>Neural network architecture and training</title><p>In this work, we consider a one-layer vanilla recurrent neural network (RNN) featuring <inline-formula><alternatives><mml:math id="inf64"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>500</mml:mn></mml:mstyle></mml:math><tex-math id="inft64">\begin{document}$  N_{g}=500$\end{document}</tex-math></alternatives></inline-formula> units. These recurrent units project linearly onto an output layer consisting of <inline-formula><alternatives><mml:math id="inf65"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mstyle></mml:math><tex-math id="inft65">\begin{document}$  N_{p}=100$\end{document}</tex-math></alternatives></inline-formula> units. Both recurrent and output units were equipped with ReLU activation functions and no added bias.</p><p>At time <inline-formula><alternatives><mml:math id="inf66"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math><tex-math id="inft66">\begin{document}$  t$\end{document}</tex-math></alternatives></inline-formula>, the hidden state of the recurrent layer was given by<disp-formula id="equ8"><label>(7)</label><alternatives><mml:math id="m8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t8">\begin{document}$$\displaystyle  \mathbf{g}_{t+1} = \left[W_{R} \mathbf{g}_t + W_I\mathbf{I}_t \right]_+,$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf67"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>W</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>R</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mstyle></mml:math><tex-math id="inft67">\begin{document}$  W_{R}\in\mathbb{R}^{N_{g}\times N_{g}}$\end{document}</tex-math></alternatives></inline-formula> is a trainable matrix of recurrent weights, and <inline-formula><alternatives><mml:math id="inf68"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>W</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mstyle></mml:math><tex-math id="inft68">\begin{document}$  W_{I}\in\mathbb{R}^{N_{g}\times N_{I}}$\end{document}</tex-math></alternatives></inline-formula> a matrix of input weights, with <inline-formula><alternatives><mml:math id="inf69"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft69">\begin{document}$  \mathbf{I}_{t}$\end{document}</tex-math></alternatives></inline-formula> being the input at time <inline-formula><alternatives><mml:math id="inf70"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math><tex-math id="inft70">\begin{document}$  t$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf71"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft71">\begin{document}$  N_{I}$\end{document}</tex-math></alternatives></inline-formula> the dimensionality of the input signal. The input consisted of a concatenation of a velocity signal and a six-entry, one-hot context signal, i.e., <inline-formula><alternatives><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">I</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mtext>cat</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math><tex-math id="inft72">\begin{document}$  \mathbf{I}_{t}=\text{cat}(\dot{\mathbf{x}}_{t},\mathbf{c})$\end{document}</tex-math></alternatives></inline-formula>. Subsequently, output states were computed according to<disp-formula id="equ9"><alternatives><mml:math id="m9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t9">\begin{document}$$\displaystyle  \mathbf{p}_t = [W_p \mathbf{g}_t]_+,$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>W</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>×</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mstyle></mml:math><tex-math id="inft73">\begin{document}$  W_{p}\in\mathbb{R}^{N_{p}\times N_{g}}$\end{document}</tex-math></alternatives></inline-formula> is a trainable weight matrix.</p><p>Feedforward weights were all initialized according to a uniform distribution <inline-formula><alternatives><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">U</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>k</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math><tex-math id="inft74">\begin{document}$  \mathcal{U}(-k_{i},k_{i})$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf75"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>k</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>/</mml:mo></mml:mrow><mml:msqrt><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:msqrt></mml:mstyle></mml:math><tex-math id="inft75">\begin{document}$  k_{i}=1/\sqrt{N_{i}}$\end{document}</tex-math></alternatives></inline-formula> with <inline-formula><alternatives><mml:math id="inf76"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft76">\begin{document}$  N_{i}$\end{document}</tex-math></alternatives></inline-formula> being the number of inputs to that layer. For the recurrent layer, the RNN weight matrix was initialized to the identity. This was done to mitigate vanishing/exploding gradients caused by the long sequence lengths used for training, as suggested by <xref ref-type="bibr" rid="bib25">Le et al., 2015</xref>.</p><p>To explore network dynamics when transitioning between different environments, we trained the recurrent network in a <italic>stateful</italic> fashion. This involved maintaining the recurrent state from the end of one trajectory, and using it as the initial state along a new trajectory. For each transition, the new environment and the starting location within that environment were sampled randomly (and uniformly). To ensure stability, the network state was reset every ten trajectories, to an all-zero initial state. When reset, the network state was initially set to all zeros, providing no positional information at the start of the trajectory. While the network state was carried between different environments, gradient calculations were truncated at the end of each episode.</p><p>Because the network is not provided with initial position information (all-zero initial state), the network has to infer its location within an environment (the identity of which is known due to the context-input) based on its geometry, e.g., through border interactions. This requires a large sample (long trajectory) of the geometry. The recurrent network was, therefore, trained on trajectories of sequence length <inline-formula><alternatives><mml:math id="inf77"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>500</mml:mn></mml:mstyle></mml:math><tex-math id="inft77">\begin{document}$  T=500$\end{document}</tex-math></alternatives></inline-formula>. The minibatch size used for gradient descent was 64. Because of statefulness and resetting, the network, therefore, experienced effective sequences of 5000 timesteps during training. However, no gradient information was carried between subsequent trajectories.</p><p>To implement models, we used the PyTorch Python library (<xref ref-type="bibr" rid="bib41">Paszke, 2019</xref>). We used the Adam optimizer (<xref ref-type="bibr" rid="bib20">Kingma, 2017</xref>) for training, with a learning rate of 10<sup>−4</sup> and otherwise default parameters (<xref ref-type="bibr" rid="bib41">Paszke, 2019</xref>). The network was trained for a total of 100 epochs using the training dataset detailed in 4.3. To regularize the network, we applied an L1 penalty to the recurrent network states, i.e., <inline-formula><alternatives><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft78">\begin{document}$  \mathbf{g}$\end{document}</tex-math></alternatives></inline-formula>. The associated L1 hyperparameter <inline-formula><alternatives><mml:math id="inf79"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>λ</mml:mi></mml:mstyle></mml:math><tex-math id="inft79">\begin{document}$  \lambda$\end{document}</tex-math></alternatives></inline-formula> was set to 10.</p></sec><sec id="s4-3"><title>Trajectory simulation and datasets</title><p>Networks were trained using simulated datasets of trajectories traversing 2D geometries. The starting location of a trajectory was sampled randomly and uniformly within an environment. To sample points uniformly from non-square geometries, a rejection sampling strategy was used: First, points were sampled according to a uniform distribution, whose support was given by the smallest rectangle that completely covered the given geometry. Then, ray casting was done to determine whether points were in the interior of the geometry. Concretely, a horizontal ray was cast from a given point and the number of intersections with the enclosure walls was determined. If the number of intersections was odd, the point was accepted as being inside the environment. If the number of intersections was even, the point was resampled. This procedure was iterated until the desired number of samples was obtained. Note that the interior determination method only works for extended objects, such as holes. Therefore, to add thin environment boundaries (infinitely thin walls), we simply superimposed two boundaries with no spatial separation.</p><p>To approximate the semi-smooth motions of foraging rodents, trajectory steps were generated by drawing step sizes according to a Rayleigh distribution with <inline-formula><alternatives><mml:math id="inf80"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mstyle></mml:math><tex-math id="inft80">\begin{document}$  \sigma=0.5$\end{document}</tex-math></alternatives></inline-formula>, and heading direction from a von Mises distribution centered at the previous heading with scale parameter <inline-formula><alternatives><mml:math id="inf81"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mstyle></mml:math><tex-math id="inft81">\begin{document}$  \kappa=4$\end{document}</tex-math></alternatives></inline-formula>. To ensure that the random walk remained within the geometry, we checked whether a proposed step intersected with any of the environment walls. If an intersection was detected, the heading direction was resampled until an allowed step was achieved. This procedure was iterated until the desired amount of timesteps was obtained. Note that step sizes were not resampled. This procedure yields smooth trajectories, with inherent turning away from boundaries. Trajectory positions were generated using a forward Euler integration scheme, with timestep <inline-formula><alternatives><mml:math id="inf82"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtext>d</mml:mtext><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mstyle></mml:math><tex-math id="inft82">\begin{document}$  \text{d}t=0.1$\end{document}</tex-math></alternatives></inline-formula>.</p><p>For computational efficiency, the network was trained and evaluated on precomputed datasets of trajectories. The full dataset contained 15000 trajectories, each of which was 500 timesteps long. Of these, 80% was reserved for training, and the remaining 20% for validation. In both datasets, an equal number of samples were included for every environment. All analyses were conducted using newly generated test trajectories.</p></sec><sec id="s4-4"><title>Contexts and geometries</title><p>To explore the possibility that the model could learn to remap, we trained networks in multiple distinct environments, each labeled by a unique, one-hot context vector. The included geometries were square, circular, and rectangular. In addition, we also included a large square, a square with a thin, central dividing wall, and finally, a square with a central hole. Each geometry and associated context signal is illustrated in <xref ref-type="fig" rid="fig1">Figure 1c</xref>.</p></sec><sec id="s4-5"><title>Remapping experiments</title><p>We conducted two remapping experiments to study whether the behavior of the trained neural networks aligned with those observed experimentally in animals. The first consisted of running the trained network (with frozen weights) in multiple familiar geometries (with the corresponding context signal), similar to canonical remapping experiments (<xref ref-type="bibr" rid="bib27">Leutgeb et al., 2004</xref>; <xref ref-type="bibr" rid="bib11">Fyhn et al., 2007</xref>). Referring to <xref ref-type="fig" rid="fig3">Figure 3a</xref> we ran the trained recurrent network along 25,000-timestep sequences, that initially visited the square environment. Then, the network was transferred to the square with a central wall, before being returned to the square environment. For each trajectory, the starting position was sampled randomly within the geometry, and the state of the network was maintained between environments. The initial state of the network in the first environment was set to the zero vector.</p><p>The second set of experiments was designed to explore the consequences of geometric manipulations of familiar environments on the learned spatial representations. To do so, we ran the trained network (with fixed weights) in elongated versions of the familiar environments, similar to the experimental setup in <xref ref-type="bibr" rid="bib39">O’Keefe and Burgess, 1996</xref>.</p><p>The first of these trials involved running the trained RNN in the square environment, with the appropriate context. However, during inference the environment walls were elongated by factors of 2 and 3 compared to their original length. For reference, <xref ref-type="fig" rid="fig4">Figure 4a</xref> illustrates the environment rescaling protocol.</p><p>The second trial concerned the effects of extending a familiar environment to previously unseen locations. Concretely, this experiment entailed transforming the environment with a central hole, into a square environment, while retaining the original context signal. In other words, the four walls of the central hole were removed, allowing movement in previously inaccessible parts of the arena. The third trial featured rescaling of the square environment into a larger square, i.e., proportional scaling in both horizontal and vertical directions while maintaining the context cue of the square environment. Again, wall lengths were scaled by factors of 2 and 3.</p><p>The final geometric manipulation involved expanding the circular environment uniformly, again by factors of 2 and 3, respectively.</p></sec><sec id="s4-6"><title>Attractor dynamics and noise injection</title><p>To investigate whether the learned representations exhibited attractor-like behavior, we performed a noise-injection experiment. The experiment consisted of evaluating the trained RNN on 1000, 800-timestep trajectories within the square environment. At the midpoint of the trajectory Gaussian noise was injected into the recurrent state. This perturbed state was subsequently rectified, before the network was run normally for the remainder of the trajectory. We performed the same experiment for multiple noise levels <inline-formula><alternatives><mml:math id="inf83"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>0.0</mml:mn><mml:mo>,</mml:mo><mml:mn>0.01</mml:mn><mml:mo>,</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mstyle></mml:math><tex-math id="inft83">\begin{document}$  \sigma=\{0.0,0.01,0.1,1\}$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf84"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi></mml:mstyle></mml:math><tex-math id="inft84">\begin{document}$  \sigma$\end{document}</tex-math></alternatives></inline-formula> determines the scale of the normal distribution used for noise generation. The state of the RNN directly after noise injection could, therefore, be described as <inline-formula><alternatives><mml:math id="inf85"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>perturbed</mml:mtext><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>τ</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">χ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mo>+</mml:mo></mml:msub><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="inft85">\begin{document}$ \mathbf{g}_{\text{perturbed},i} =[\mathbf{g}_{\tau} + \boldsymbol{\chi}_i]_+,$\end{document}</tex-math></alternatives></inline-formula> where <inline-formula><alternatives><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="bold-italic">χ</mml:mi></mml:mstyle></mml:math><tex-math id="inft86">\begin{document}$  \boldsymbol{\chi}$\end{document}</tex-math></alternatives></inline-formula> is a vector of random variables, drawn from a multivariate normal distribution. <inline-formula><alternatives><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi></mml:mstyle></mml:math><tex-math id="inft87">\begin{document}$  \tau$\end{document}</tex-math></alternatives></inline-formula> denotes the time of noise injection, taken to be timestep 400, while <inline-formula><alternatives><mml:math id="inf88"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo stretchy="false">[</mml:mo><mml:mo>⋅</mml:mo><mml:msub><mml:mo stretchy="false">]</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft88">\begin{document}$  [\cdot]_{+}$\end{document}</tex-math></alternatives></inline-formula> is a rectification operation.</p><p>To assess whether the representation was stable, and whether the state of the network was attractive, we computed ratemap population vector correlations (see 5 for details) between every time point in the sequence for each noise level.</p></sec><sec id="s4-7"><title>Low-dimensional representations and explainability</title><p>To better understand the behavior of the recurrent network, we performed PCA, alongside dimensionality reduction using UMAP (<xref ref-type="bibr" rid="bib31">McInnes et al., 2020</xref>). PCA was done on the recurrent and output states of the network as it was run on long (10000 timesteps in each environment) trajectories that visited every environment sequentially. For each environment transition, the state of the network was maintained. PCA was performed for each environment separately, as well as for the full trajectory visiting every environment. As an example, for a trajectory of length <inline-formula><alternatives><mml:math id="inf89"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>T</mml:mi></mml:mstyle></mml:math><tex-math id="inft89">\begin{document}$  T$\end{document}</tex-math></alternatives></inline-formula>, the output activity <inline-formula><alternatives><mml:math id="inf90"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mstyle></mml:math><tex-math id="inft90">\begin{document}$  \mathbf{p}\in\mathbb{R}^{T,N_{p}}$\end{document}</tex-math></alternatives></inline-formula> was projected to a low-dimensional representation <inline-formula><alternatives><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mo stretchy="false">~</mml:mo></mml:mover></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>T</mml:mi><mml:mo>×</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup></mml:mstyle></mml:math><tex-math id="inft91">\begin{document}$  \tilde{\mathbf{p}}\in\mathbb{R}^{T\times n_{pca}}$\end{document}</tex-math></alternatives></inline-formula>, with <inline-formula><alternatives><mml:math id="inf92"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>n</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft92">\begin{document}$  n_{pca}$\end{document}</tex-math></alternatives></inline-formula> being the number of principal components.</p><p>The second dimensionality reduction technique consisted of performing UMAP (<xref ref-type="bibr" rid="bib31">McInnes et al., 2020</xref>) on the states of the network along the full trajectory. This was done to explore whether network activity resided on a low-dimensional manifold. Population activity at each time point was subsequently projected down to three dimensions, yielding a dimensionality-reduced vector representing the full network activity at a particular point along the trajectory. To further explore the dynamics of the network, we computed the eigenvalue spectrum of the recurrent weight matrix. Finally, we computed Pearson correlation coefficients between columns of the input weight matrix corresponding to different context signals.</p></sec><sec id="s4-8"><title>Analyses</title><p>To compare the representational similarity of the network output across environments and time, we performed several analyses using unit ratemaps.</p></sec><sec id="s4-9"><title>Ratemaps</title><p>Ratemaps of unit activity were computed by discretizing environments into bins. The rate was then determined by dividing unit activity by the number of visitations to that bin along a single trajectory. Unless otherwise specified, ratemaps were formed using 25,000-timestep trajectories. For long-sequence experiments, a burn-in period of 500 initial timesteps was excluded from ratemap creation. This was done to only include the steady-state behavior of the network. For the remapping dynamics in <xref ref-type="fig" rid="fig3">Figure 3e</xref>, ratemaps were created by aggregating responses over 500 distinct, 800-timestep trajectories.</p></sec><sec id="s4-10"><title>Spatial correlation</title><p>Following (<xref ref-type="bibr" rid="bib11">Fyhn et al., 2007</xref>), we computed unit-wise ratemap spatial correlations to investigate possible remapping behavior. For a single unit, the spatial correlation was calculated by computing the Pearson correlation coefficient between flattened unit ratemaps. We considered the correlations between the square environment, and the square with a central wall, due to their geometric similarity. In other words, the ratemap of a unit in the square environment was correlated with its ratemap in the square with a central wall environment. This procedure was repeated for all units that were active (exhibited nonzero activity) in both environments, and a distribution of spatial correlations was formed. As a baseline, a shuffled distribution was computed by correlating every active unit with every other active unit, across environments. Finally, correlations were computed for relative ratemap rotations of 0, 90, 180, and 270 degrees, and the maximimal correlation reported. This was done to account for the possibility that remapping consisted of a rigid rotation in space.</p></sec><sec id="s4-11"><title>Ratemap population vector correlation</title><p>To compare the representational similarity of entire unit populations at different timepoints (as in <xref ref-type="fig" rid="fig5">Figure 5</xref>), we computed the Pearson correlation between ratemap population vectors at different times. A ratemap population vector at a particular time was constructed by stacking the flattened ratemaps of every unit into a single array of dimension <inline-formula><alternatives><mml:math id="inf93"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>⋅</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft93">\begin{document}$  N_{units}\cdot N_{x}\cdot N_{y}$\end{document}</tex-math></alternatives></inline-formula> with <inline-formula><alternatives><mml:math id="inf94"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>u</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft94">\begin{document}$  N_{units}$\end{document}</tex-math></alternatives></inline-formula> being the number of units in the relevant layer, and <inline-formula><alternatives><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>16</mml:mn></mml:mstyle></mml:math><tex-math id="inft95">\begin{document}$  N_{x}=N_{y}=16$\end{document}</tex-math></alternatives></inline-formula> is the number of bins along the canonical <inline-formula><alternatives><mml:math id="inf96"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi></mml:mstyle></mml:math><tex-math id="inft96">\begin{document}$  x,y$\end{document}</tex-math></alternatives></inline-formula> directions. In other words, this measures the correlation of an entire population at every spatial point, at a particular point in time, and can thus be used to gauge the time evolution of an entire representation. Note that states were aggregated across multiple trajectories, at the same time point.</p><p>Using Astropy (<xref ref-type="bibr" rid="bib44">Price Whelan et al., 2022</xref>), Gaussian smoothing with NaN interpolation was used to fill in unvisited regions. The smoothing kernel standard deviation was one pixel. For the experiment featuring transfers between different environments (<xref ref-type="fig" rid="fig3">Figure 3e</xref>), only units with nonzero activity in one or more environments were included in the population vector.</p></sec><sec id="s4-12"><title>Rate overlap and difference</title><p>As a measure of rate changes between conditions, we computed the rate overlap (<xref ref-type="bibr" rid="bib27">Leutgeb et al., 2004</xref>), and rate difference. Considering two conditions (e.g. comparing across two environments), rate overlap was computed by dividing the mean activity in the least active condition by that in the most active. Only units that were active in at least one condition were included in the analysis. The rate difference was computed by simply subtracting the activity in one condition from that in another, and dividing by the sum of activity in both conditions. This measure is similar to the rate difference used in <xref ref-type="bibr" rid="bib28">Leutgeb et al., 2005</xref>, but maintains the sign of the difference. As with the rate overlap, only units that were active in at least one condition were included.</p><p>For both the overlap and difference, a shuffled distribution was formed by randomly pairing units across conditions. For both quantities, pairings were performed 1000 times.</p></sec><sec id="s4-13"><title>Spatial information</title><p>To select the most place-like units for the phase distribution visualization, we computed the spatial information content (<xref ref-type="bibr" rid="bib49">Skaggs and McNaughton, 1992</xref>) of all units. Using unit ratemaps of <inline-formula><alternatives><mml:math id="inf97"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi></mml:mstyle></mml:math><tex-math id="inft97">\begin{document}$  M$\end{document}</tex-math></alternatives></inline-formula> bins, the spatial information of a single unit was computed as<disp-formula id="equ10"><alternatives><mml:math id="m10"><mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mi>i</mml:mi><mml:mi>M</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:msub><mml:mi>log</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁡</mml:mo><mml:mrow><mml:mfrac><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mfrac><mml:mo>⁢</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math><tex-math id="t10">\begin{document}$$\displaystyle  S=\sum_{i}^{M}f_{i}\bar{f}\log_{2}\frac{f_{i}}{\bar{f}}p_{i},$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf98"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>p</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft98">\begin{document}$  p_{i}$\end{document}</tex-math></alternatives></inline-formula> is the occupancy of bin <inline-formula><alternatives><mml:math id="inf99"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>i</mml:mi></mml:mstyle></mml:math><tex-math id="inft99">\begin{document}$  i$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>f</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft100">\begin{document}$  f_{i}$\end{document}</tex-math></alternatives></inline-formula> is the firing rate in that bin, while <inline-formula><alternatives><mml:math id="inf101"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mi>f</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math><tex-math id="inft101">\begin{document}$  \bar{f}$\end{document}</tex-math></alternatives></inline-formula> is the unit’s average firing rate over all bins. High spatial information units were subsequently selected as those whose spatial information were above the 2.5th percentile in all environments.</p></sec><sec id="s4-14"><title>Ripley’s H and clustering</title><p>To assess whether biological place fields exhibit non-uniform clustering, we computed the Ripley’s H statistic (<xref ref-type="bibr" rid="bib23">Lagache et al., 2013</xref>) for the center locations of place cells recorded from animals (<xref ref-type="bibr" rid="bib26">Lee et al., 2023</xref>).</p><p>For a set of <inline-formula><alternatives><mml:math id="inf102"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>N</mml:mi></mml:mstyle></mml:math><tex-math id="inft102">\begin{document}$  N$\end{document}</tex-math></alternatives></inline-formula> points, we computed Ripley’s H in two steps: First, we determined Ripley’s K, which counts the average number of points within a distance <inline-formula><alternatives><mml:math id="inf103"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>R</mml:mi></mml:mstyle></mml:math><tex-math id="inft103">\begin{document}$  R$\end{document}</tex-math></alternatives></inline-formula> of a point, given by<disp-formula id="equ11"><alternatives><mml:math id="m11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:munder><mml:mo>∑</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>≠</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:mrow></mml:munder><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn mathvariant="bold">1</mml:mn></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mi>R</mml:mi><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:msub><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi><mml:mo mathvariant="bold">,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo mathvariant="bold" stretchy="false">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t11">\begin{document}$$\displaystyle  K(N, R) = \frac{|\Omega|}{N(N-1)}\sum_{\mathbf{x}\neq \mathbf{y}} \mathbf{1}_{\{|\mathbf{x} - \mathbf{y}| \lt R\}} f(\mathbf{x, \mathbf{y})},$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf104"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft104">\begin{document}$  \mathbf{x}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf105"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">y</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft105">\begin{document}$  \mathbf{y}$\end{document}</tex-math></alternatives></inline-formula> are distinct points, <inline-formula><alternatives><mml:math id="inf106"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft106">\begin{document}$  |\Omega|$\end{document}</tex-math></alternatives></inline-formula> is the area of the domain <inline-formula><alternatives><mml:math id="inf107"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Ω</mml:mi></mml:mstyle></mml:math><tex-math id="inft107">\begin{document}$  \Omega$\end{document}</tex-math></alternatives></inline-formula> encompassing the set of points, while <bold>1</bold> is the indicator function. <inline-formula><alternatives><mml:math id="inf108"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math><tex-math id="inft108">\begin{document}$  f(\mathbf{x},\mathbf{y})$\end{document}</tex-math></alternatives></inline-formula> is a boundary correction factor to account for a lack of observations outside the region <inline-formula><alternatives><mml:math id="inf109"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Ω</mml:mi></mml:mstyle></mml:math><tex-math id="inft109">\begin{document}$  \Omega$\end{document}</tex-math></alternatives></inline-formula>. We follow <xref ref-type="bibr" rid="bib23">Lagache et al., 2013</xref> and take<disp-formula id="equ12"><alternatives><mml:math id="m12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t12">\begin{document}$$\displaystyle  f(\mathbf{x}, \mathbf{y}) = \frac{1}{2}(k(\mathbf{x},\mathbf{y}) + k(\mathbf{y}, \mathbf{x})),$$\end{document}</tex-math></alternatives></disp-formula><disp-formula id="equ13"><alternatives><mml:math id="m13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>∩</mml:mo><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t13">\begin{document}$$\displaystyle  k(\mathbf{x}, \mathbf{y}) = \frac{|\partial b(\mathbf{x}, |\mathbf{x}-\mathbf{y}|)|}{|\partial b(\mathbf{x}, |\mathbf{x}-\mathbf{y}|)\cap \Omega|},$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>b</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math><tex-math id="inft110">\begin{document}$  \partial b(\mathbf{x},|\mathbf{x}-\mathbf{y}|)$\end{document}</tex-math></alternatives></inline-formula> is the circumference of a ball centered at <inline-formula><alternatives><mml:math id="inf111"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft111">\begin{document}$  \mathbf{x}$\end{document}</tex-math></alternatives></inline-formula> of radius <inline-formula><alternatives><mml:math id="inf112"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mstyle></mml:math><tex-math id="inft112">\begin{document}$  |\mathbf{x}-\mathbf{y}|$\end{document}</tex-math></alternatives></inline-formula>, and the denominator the circumference of the part of the ball that is inside the geometry. We used the Shapely Python library (<xref ref-type="bibr" rid="bib12">Gillies et al., 2024</xref>) for computing intersections between balls and the enclosing geometry. The second step consisted of centering and normalizing Ripley’s K, obtaining Ripley’s H, given by<disp-formula id="equ14"><alternatives><mml:math id="m14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>H</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:mi>K</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>N</mml:mi><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>π</mml:mi></mml:mfrac></mml:msqrt><mml:mo>−</mml:mo><mml:mi>r</mml:mi><mml:mo>.</mml:mo></mml:mstyle></mml:math><tex-math id="t14">\begin{document}$$\displaystyle  H(N, R) = \sqrt{\frac{K(N,R)}{\pi}} - r.$$\end{document}</tex-math></alternatives></disp-formula></p><p>For our analysis, we computed Ripley’s H for center locations of place cells in mice traversing a 75×75 cm square environment (<xref ref-type="bibr" rid="bib26">Lee et al., 2023</xref>) over four distinct recording days. Centers, in this case, were decoded as the maximum firing location in 15×15 smoothed ratemaps. For each animal, we included place cells above the 75th percentile. For each cell, the ratemap corresponding to the recording day with the largest spatial information was selected. As a baseline, Ripley’s H was computed for 100 sets of points sampled randomly and uniformly on a 15×15 square grid, matching the spatial discretization of the ratemaps used. For both baseline and real data, ball radii were varied from <inline-formula><alternatives><mml:math id="inf113"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>ε</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo>−</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:math><tex-math id="inft113">\begin{document}$  \varepsilon=10^{-8}$\end{document}</tex-math></alternatives></inline-formula> to approximately 26.5 cm, corresponding to a quarter of the square’s diagonal.</p><p>To visualize possible clustering of place fields, we computed Gaussian kernel density estimates of decoded field centers. This procedure was repeated for all animals, and only centers of cells with spatial information above the 75<sup>th</sup> percentile were included. For all kernel density estimates, the bandwidth parameter was set to 0.2, and kernels were evaluated on 64×64 grids. See (<xref ref-type="bibr" rid="bib26">Lee et al., 2023</xref>) for details on ratemap creation and experiments.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Data curation, Software, Supervision, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Resources, Supervision, Funding acquisition, Writing – original draft, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Data curation, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing – original draft, Project administration, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="data-availability" id="s6"><title>Data availability</title><p>The current manuscript is a computational study, so no data has been generated for this manuscript. Modelling code is found at <ext-link ext-link-type="uri" xlink:href="https://github.com/bioai-oslo/vpc">https://github.com/bioai-oslo/vpc</ext-link> (copy archived at <xref ref-type="bibr" rid="bib43">Pettersen, 2025</xref>).</p></sec><ack id="ack"><title>Acknowledgements</title><p>We would like to thank J Quinn Lee and Mark Brandon of McGill University, as well as their co-authors, for graciously sharing their data with us. We hope others follow their example of open and helpful collaboration.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aronov</surname><given-names>D</given-names></name><name><surname>Nevers</surname><given-names>R</given-names></name><name><surname>Tank</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Mapping of a non-spatial dimension by the hippocampal-entorhinal circuit</article-title><source>Nature</source><volume>543</volume><fpage>719</fpage><lpage>722</lpage><pub-id pub-id-type="doi">10.1038/nature21692</pub-id><pub-id pub-id-type="pmid">28358077</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Banino</surname><given-names>A</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Uria</surname><given-names>B</given-names></name><name><surname>Blundell</surname><given-names>C</given-names></name><name><surname>Lillicrap</surname><given-names>T</given-names></name><name><surname>Mirowski</surname><given-names>P</given-names></name><name><surname>Pritzel</surname><given-names>A</given-names></name><name><surname>Chadwick</surname><given-names>MJ</given-names></name><name><surname>Degris</surname><given-names>T</given-names></name><name><surname>Modayil</surname><given-names>J</given-names></name><name><surname>Wayne</surname><given-names>G</given-names></name><name><surname>Soyer</surname><given-names>H</given-names></name><name><surname>Viola</surname><given-names>F</given-names></name><name><surname>Zhang</surname><given-names>B</given-names></name><name><surname>Goroshin</surname><given-names>R</given-names></name><name><surname>Rabinowitz</surname><given-names>N</given-names></name><name><surname>Pascanu</surname><given-names>R</given-names></name><name><surname>Beattie</surname><given-names>C</given-names></name><name><surname>Petersen</surname><given-names>S</given-names></name><name><surname>Sadik</surname><given-names>A</given-names></name><name><surname>Gaffney</surname><given-names>S</given-names></name><name><surname>King</surname><given-names>H</given-names></name><name><surname>Kavukcuoglu</surname><given-names>K</given-names></name><name><surname>Hassabis</surname><given-names>D</given-names></name><name><surname>Hadsell</surname><given-names>R</given-names></name><name><surname>Kumaran</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Vector-based navigation using grid-like representations in artificial agents</article-title><source>Nature</source><volume>557</volume><fpage>429</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1038/s41586-018-0102-6</pub-id><pub-id pub-id-type="pmid">29743670</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Lever</surname><given-names>C</given-names></name><name><surname>Hayman</surname><given-names>R</given-names></name><name><surname>Hartley</surname><given-names>T</given-names></name><name><surname>Burton</surname><given-names>S</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Jeffery</surname><given-names>K</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The boundary vector cell model of place cell firing and spatial memory</article-title><source>Reviews in the Neurosciences</source><volume>17</volume><fpage>71</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1515/revneuro.2006.17.1-2.71</pub-id><pub-id pub-id-type="pmid">16703944</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Ginzberg</surname><given-names>LL</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Grid cell firing patterns signal environmental novelty by expansion</article-title><source>PNAS</source><volume>109</volume><fpage>17687</fpage><lpage>17692</lpage><pub-id pub-id-type="doi">10.1073/pnas.1209918109</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Muller</surname><given-names>TH</given-names></name><name><surname>Whittington</surname><given-names>JCR</given-names></name><name><surname>Mark</surname><given-names>S</given-names></name><name><surname>Baram</surname><given-names>AB</given-names></name><name><surname>Stachenfeld</surname><given-names>KL</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>What is a cognitive map? organizing knowledge for flexible behavior</article-title><source>Neuron</source><volume>100</volume><fpage>490</fpage><lpage>509</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.002</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Burak</surname><given-names>Y</given-names></name><name><surname>Fiete</surname><given-names>IR</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Accurate path integration in continuous attractor network models of grid cells</article-title><source>PLOS Computational Biology</source><volume>5</volume><elocation-id>e1000291</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1000291</pub-id><pub-id pub-id-type="pmid">19229307</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bush</surname><given-names>D</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Manson</surname><given-names>D</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Using grid cells for navigation</article-title><source>Neuron</source><volume>87</volume><fpage>507</fpage><lpage>520</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.07.006</pub-id><pub-id pub-id-type="pmid">26247860</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Cueva</surname><given-names>CJ</given-names></name><name><surname>Wei</surname><given-names>XX</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Emergence of grid-like representations by training recurrent neural networks to perform spatial localization</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1803.07770">http://arxiv.org/abs/1803.07770</ext-link></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dordek</surname><given-names>Y</given-names></name><name><surname>Soudry</surname><given-names>D</given-names></name><name><surname>Meir</surname><given-names>R</given-names></name><name><surname>Derdikman</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Extracting grid cell characteristics from place cell inputs using non-negative principal component analysis</article-title><source>eLife</source><volume>5</volume><elocation-id>e10094</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.10094</pub-id><pub-id pub-id-type="pmid">26952211</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Dorrell</surname><given-names>W</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Actionable neural representations: grid cells from minimal constraints</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2209.15563">http://arxiv.org/abs/2209.15563</ext-link></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>Treves</surname><given-names>A</given-names></name><name><surname>Moser</surname><given-names>M-B</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Hippocampal remapping and grid realignment in entorhinal cortex</article-title><source>Nature</source><volume>446</volume><fpage>190</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1038/nature05601</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Gillies</surname><given-names>S</given-names></name><name><surname>van der Wel</surname><given-names>C</given-names></name><name><surname>Van den Bossche</surname><given-names>J</given-names></name><name><surname>Taves</surname><given-names>MW</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Shapely</data-title><version designator="1">1</version><source>Zenodo</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.5597138">https://doi.org/10.5281/zenodo.5597138</ext-link></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ginosar</surname><given-names>G</given-names></name><name><surname>Aljadeff</surname><given-names>J</given-names></name><name><surname>Las</surname><given-names>L</given-names></name><name><surname>Derdikman</surname><given-names>D</given-names></name><name><surname>Ulanovsky</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Are grid cells used for navigation? On local metrics, subjective spaces, and black holes</article-title><source>Neuron</source><volume>111</volume><fpage>1858</fpage><lpage>1875</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2023.03.027</pub-id><pub-id pub-id-type="pmid">37044087</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Molden</surname><given-names>S</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Microstructure of a spatial map in the entorhinal cortex</article-title><source>Nature</source><volume>436</volume><fpage>801</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1038/nature03721</pub-id><pub-id pub-id-type="pmid">15965463</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hardcastle</surname><given-names>K</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name><name><surname>Giocomo</surname><given-names>LM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Environmental boundaries as an error correction mechanism for grid cells</article-title><source>Neuron</source><volume>86</volume><fpage>827</fpage><lpage>839</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.03.039</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harland</surname><given-names>B</given-names></name><name><surname>Contreras</surname><given-names>M</given-names></name><name><surname>Souder</surname><given-names>M</given-names></name><name><surname>Fellous</surname><given-names>J-M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Dorsal CA1 hippocampal place cells form a multi-scale representation of megaspace</article-title><source>Current Biology</source><volume>31</volume><fpage>2178</fpage><lpage>2190</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2021.03.003</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hartley</surname><given-names>T</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>Lever</surname><given-names>C</given-names></name><name><surname>Cacucci</surname><given-names>F</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Modeling place fields in terms of the cortical inputs to the hippocampus</article-title><source>Hippocampus</source><volume>10</volume><fpage>369</fpage><lpage>379</lpage><pub-id pub-id-type="doi">10.1002/1098-1063(2000)10:4&lt;369::AID-HIPO3&gt;3.0.CO;2-0</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Høydal</surname><given-names>ØA</given-names></name><name><surname>Skytøen</surname><given-names>ER</given-names></name><name><surname>Andersson</surname><given-names>SO</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Object-vector coding in the medial entorhinal cortex</article-title><source>Nature</source><volume>568</volume><fpage>400</fpage><lpage>404</lpage><pub-id pub-id-type="doi">10.1038/s41586-019-1077-7</pub-id><pub-id pub-id-type="pmid">30944479</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jeffery</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Place cells, grid cells, attractors, and remapping</article-title><source>Neural Plasticity</source><volume>2011</volume><elocation-id>182602</elocation-id><pub-id pub-id-type="doi">10.1155/2011/182602</pub-id><pub-id pub-id-type="pmid">22135756</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Kingma</surname><given-names>DP</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Adam: a method for stochastic optimization</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</ext-link></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krupic</surname><given-names>J</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neural representations of location composed of spatially periodic bands</article-title><source>Science</source><volume>337</volume><fpage>853</fpage><lpage>857</lpage><pub-id pub-id-type="doi">10.1126/science.1222403</pub-id><pub-id pub-id-type="pmid">22904012</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krupic</surname><given-names>J</given-names></name><name><surname>Bauza</surname><given-names>M</given-names></name><name><surname>Burton</surname><given-names>S</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Grid cell symmetry is shaped by environmental geometry</article-title><source>Nature</source><volume>518</volume><fpage>232</fpage><lpage>235</lpage><pub-id pub-id-type="doi">10.1038/nature14153</pub-id><pub-id pub-id-type="pmid">25673417</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lagache</surname><given-names>T</given-names></name><name><surname>Lang</surname><given-names>G</given-names></name><name><surname>Sauvonnet</surname><given-names>N</given-names></name><name><surname>Olivo-Marin</surname><given-names>J-C</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Analysis of the spatial organization of molecules with robust statistics</article-title><source>PLOS ONE</source><volume>8</volume><elocation-id>e80914</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0080914</pub-id><pub-id pub-id-type="pmid">24349021</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Langston</surname><given-names>RF</given-names></name><name><surname>Ainge</surname><given-names>JA</given-names></name><name><surname>Couey</surname><given-names>JJ</given-names></name><name><surname>Canto</surname><given-names>CB</given-names></name><name><surname>Bjerknes</surname><given-names>TL</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Development of the spatial representation system in the rat</article-title><source>Science</source><volume>328</volume><fpage>1576</fpage><lpage>1580</lpage><pub-id pub-id-type="doi">10.1126/science.1188210</pub-id><pub-id pub-id-type="pmid">20558721</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Le</surname><given-names>QV</given-names></name><name><surname>Jaitly</surname><given-names>N</given-names></name><name><surname>Hinton</surname><given-names>GE</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A simple way to initialize recurrent networks of rectified linear units</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1504.00941">http://arxiv.org/abs/1504.00941</ext-link></element-citation></ref><ref id="bib26"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>JQ</given-names></name><name><surname>Keinath</surname><given-names>AT</given-names></name><name><surname>Cianfarano</surname><given-names>E</given-names></name><name><surname>Brandon</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Identifying representational structure in Ca1 to benchmark theoretical models of cognitive mapping</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.10.08.561112</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leutgeb</surname><given-names>S</given-names></name><name><surname>Leutgeb</surname><given-names>JK</given-names></name><name><surname>Treves</surname><given-names>A</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Distinct ensemble codes in hippocampal areas CA3 and CA1</article-title><source>Science</source><volume>305</volume><fpage>1295</fpage><lpage>1298</lpage><pub-id pub-id-type="doi">10.1126/science.1100265</pub-id><pub-id pub-id-type="pmid">15272123</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Leutgeb</surname><given-names>S</given-names></name><name><surname>Leutgeb</surname><given-names>JK</given-names></name><name><surname>Barnes</surname><given-names>CA</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Independent codes for spatial and episodic memory in hippocampal neuronal ensembles</article-title><source>Science</source><volume>309</volume><fpage>619</fpage><lpage>623</lpage><pub-id pub-id-type="doi">10.1126/science.1114037</pub-id><pub-id pub-id-type="pmid">16040709</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lever</surname><given-names>C</given-names></name><name><surname>Burton</surname><given-names>S</given-names></name><name><surname>Jeewajee</surname><given-names>A</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Boundary vector cells in the subiculum of the hippocampal formation</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>9771</fpage><lpage>9777</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1319-09.2009</pub-id><pub-id pub-id-type="pmid">19657030</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Low</surname><given-names>IIC</given-names></name><name><surname>Giocomo</surname><given-names>LM</given-names></name><name><surname>Williams</surname><given-names>AH</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Remapping in a recurrent neural network model of navigation and context inference</article-title><source>eLife</source><volume>13</volume><elocation-id>86943.1</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.86943.1</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>McInnes</surname><given-names>L</given-names></name><name><surname>Healy</surname><given-names>J</given-names></name><name><surname>Melville</surname><given-names>U</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>UMAP: uniform manifold approximation and projection for dimension reduction</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1802.03426">https://arxiv.org/abs/1802.03426</ext-link></element-citation></ref><ref id="bib32"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Morris</surname><given-names>G</given-names></name><name><surname>Derdikman</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2023">2023</year><chapter-title>The chicken and egg problem of grid cells and place cells</chapter-title><person-group person-group-type="editor"><name><surname>Morris</surname><given-names>G</given-names></name></person-group><source>Trends in Cognitive Sciences</source><publisher-name>Cell Press</publisher-name><fpage>125</fpage><lpage>138</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2022.11.003</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Kropff</surname><given-names>E</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Place cells, grid cells, and the brain’s spatial representation system</article-title><source>Annual Review of Neuroscience</source><volume>31</volume><fpage>69</fpage><lpage>89</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.31.061307.090723</pub-id><pub-id pub-id-type="pmid">18284371</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muller</surname><given-names>RU</given-names></name><name><surname>Kubie</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>The effects of changes in the environment on the spatial firing of hippocampal complex-spike cells</article-title><source>The Journal of Neuroscience</source><volume>7</volume><fpage>1951</fpage><lpage>1968</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.07-07-01951.1987</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nayebi</surname><given-names>A</given-names></name><name><surname>Attinger</surname><given-names>A</given-names></name><name><surname>Campbell</surname><given-names>MG</given-names></name><name><surname>Hardcastle</surname><given-names>K</given-names></name><name><surname>Low</surname><given-names>IIC</given-names></name><name><surname>Mallory</surname><given-names>CS</given-names></name><name><surname>Mel</surname><given-names>GC</given-names></name><name><surname>Sorscher</surname><given-names>B</given-names></name><name><surname>Williams</surname><given-names>AH</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name><name><surname>Giocomo</surname><given-names>LM</given-names></name><name><surname>Yamins</surname><given-names>DLK</given-names></name></person-group><year iso-8601-date="2021">2021</year><chapter-title>Explaining heterogeneity in medial entorhinal cortex with task-driven neural networks</chapter-title><person-group person-group-type="editor"><name><surname>Ranzato</surname><given-names>M</given-names></name><name><surname>Beygelzimer</surname><given-names>A</given-names></name><name><surname>Dauphin</surname><given-names>Y</given-names></name><name><surname>Liang</surname><given-names>PS</given-names></name><name><surname>Vaughan</surname><given-names>JW</given-names></name></person-group><source>Advances in Neural Information Processing Systems</source><publisher-name>Curran Associates, Inc</publisher-name><fpage>12167</fpage><lpage>12179</lpage><pub-id pub-id-type="doi">10.1101/2021.10.30.466617</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Dostrovsky</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>The hippocampus as a spatial map. Preliminary evidence from unit activity in the freely-moving rat</article-title><source>Brain Research</source><volume>34</volume><fpage>171</fpage><lpage>175</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(71)90358-1</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Keefe</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>Place units in the hippocampus of the freely moving rat</article-title><source>Experimental Neurology</source><volume>51</volume><fpage>78</fpage><lpage>109</lpage><pub-id pub-id-type="doi">10.1016/0014-4886(76)90055-8</pub-id><pub-id pub-id-type="pmid">1261644</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1978">1978</year><source>The Hippocampus as a Cognitive Map</source><publisher-loc>Oxford</publisher-loc><publisher-name>Oxford University Press</publisher-name></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Geometric determinants of the place fields of hippocampal neurons</article-title><source>Nature</source><volume>381</volume><fpage>425</fpage><lpage>428</lpage><pub-id pub-id-type="doi">10.1038/381425a0</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>E</given-names></name><name><surname>Dvorak</surname><given-names>D</given-names></name><name><surname>Fenton</surname><given-names>AA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Ensemble place codes in hippocampus: CA1, CA3, and dentate gyrus place cells have multiple place fields in large environments</article-title><source>PLOS ONE</source><volume>6</volume><elocation-id>e22349</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0022349</pub-id><pub-id pub-id-type="pmid">21789250</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Paszke</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>PyTorch: an imperative style, high-performance deeplearning library</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1912.01703">https://arxiv.org/abs/1912.01703</ext-link></element-citation></ref><ref id="bib42"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Pettersen</surname><given-names>M</given-names></name><name><surname>Schøyen</surname><given-names>VS</given-names></name><name><surname>∅stby</surname><given-names>MD</given-names></name><name><surname>Malthe-Sørenssen</surname><given-names>A</given-names></name><name><surname>Lepperød</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Self-supervised grid cells without path integration</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2024.05.30.596577</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Pettersen</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>VPC</data-title><version designator="swh:1:rev:2b2b34d2002c3c476a56b544e6e506766f2aa094">swh:1:rev:2b2b34d2002c3c476a56b544e6e506766f2aa094</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:9f762dca2b906037f9a13abd31cfa0ae73e7d7f3;origin=https://github.com/bioAI-Oslo/VPC;visit=swh:1:snp:b7dd8202bd96b2ac6e89f0663d0854f9d7eddf2d;anchor=swh:1:rev:2b2b34d2002c3c476a56b544e6e506766f2aa094">https://archive.softwareheritage.org/swh:1:dir:9f762dca2b906037f9a13abd31cfa0ae73e7d7f3;origin=https://github.com/bioAI-Oslo/VPC;visit=swh:1:snp:b7dd8202bd96b2ac6e89f0663d0854f9d7eddf2d;anchor=swh:1:rev:2b2b34d2002c3c476a56b544e6e506766f2aa094</ext-link></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Price Whelan</surname><given-names>AM</given-names></name><name><surname>Lim</surname><given-names>PL</given-names></name><name><surname>Earl</surname><given-names>N</given-names></name><name><surname>Starkman</surname><given-names>N</given-names></name><name><surname>Bradley</surname><given-names>L</given-names></name><name><surname>Shupe</surname><given-names>DL</given-names></name><name><surname>Patil</surname><given-names>AA</given-names></name><name><surname>Corrales</surname><given-names>L</given-names></name><name><surname>Brasseur</surname><given-names>CE</given-names></name><name><surname>Nöthe</surname><given-names>M</given-names></name><name><surname>Donath</surname><given-names>A</given-names></name><name><surname>Tollerud</surname><given-names>E</given-names></name><name><surname>Morris</surname><given-names>BM</given-names></name><name><surname>Ginsburg</surname><given-names>A</given-names></name><name><surname>Vaher</surname><given-names>E</given-names></name><name><surname>Weaver</surname><given-names>BA</given-names></name><name><surname>Tocknell</surname><given-names>J</given-names></name><name><surname>Jamieson</surname><given-names>W</given-names></name><name><surname>van Kerkwijk</surname><given-names>MH</given-names></name><name><surname>Robitaille</surname><given-names>TP</given-names></name><name><surname>Merry</surname><given-names>B</given-names></name><name><surname>Bachetti</surname><given-names>M</given-names></name><name><surname>Günther</surname><given-names>HM</given-names></name><name><surname>Aldcroft</surname><given-names>TL</given-names></name><name><surname>Alvarado-Montes</surname><given-names>JA</given-names></name><name><surname>Archibald</surname><given-names>AM</given-names></name><name><surname>Bódi</surname><given-names>A</given-names></name><name><surname>Bapat</surname><given-names>S</given-names></name><name><surname>Barentsen</surname><given-names>G</given-names></name><name><surname>Bazán</surname><given-names>J</given-names></name><name><surname>Biswas</surname><given-names>M</given-names></name><name><surname>Boquien</surname><given-names>M</given-names></name><name><surname>Burke</surname><given-names>DJ</given-names></name><name><surname>Cara</surname><given-names>D</given-names></name><name><surname>Cara</surname><given-names>M</given-names></name><name><surname>Conroy</surname><given-names>KE</given-names></name><name><surname>Conseil</surname><given-names>S</given-names></name><name><surname>Craig</surname><given-names>MW</given-names></name><name><surname>Cross</surname><given-names>RM</given-names></name><name><surname>Cruz</surname><given-names>KL</given-names></name><name><surname>D’Eugenio</surname><given-names>F</given-names></name><name><surname>Dencheva</surname><given-names>N</given-names></name><name><surname>Devillepoix</surname><given-names>HAR</given-names></name><name><surname>Dietrich</surname><given-names>JP</given-names></name><name><surname>Eigenbrot</surname><given-names>AD</given-names></name><name><surname>Erben</surname><given-names>T</given-names></name><name><surname>Ferreira</surname><given-names>L</given-names></name><name><surname>Foreman-Mackey</surname><given-names>D</given-names></name><name><surname>Fox</surname><given-names>R</given-names></name><name><surname>Freij</surname><given-names>N</given-names></name><name><surname>Garg</surname><given-names>S</given-names></name><name><surname>Geda</surname><given-names>R</given-names></name><name><surname>Glattly</surname><given-names>L</given-names></name><name><surname>Gondhalekar</surname><given-names>Y</given-names></name><name><surname>Gordon</surname><given-names>KD</given-names></name><name><surname>Grant</surname><given-names>D</given-names></name><name><surname>Greenfield</surname><given-names>P</given-names></name><name><surname>Groener</surname><given-names>AM</given-names></name><name><surname>Guest</surname><given-names>S</given-names></name><name><surname>Gurovich</surname><given-names>S</given-names></name><name><surname>Handberg</surname><given-names>R</given-names></name><name><surname>Hart</surname><given-names>A</given-names></name><name><surname>Hatfield-Dodds</surname><given-names>Z</given-names></name><name><surname>Homeier</surname><given-names>D</given-names></name><name><surname>Hosseinzadeh</surname><given-names>G</given-names></name><name><surname>Jenness</surname><given-names>T</given-names></name><name><surname>Jones</surname><given-names>CK</given-names></name><name><surname>Joseph</surname><given-names>P</given-names></name><name><surname>Kalmbach</surname><given-names>JB</given-names></name><name><surname>Karamehmetoglu</surname><given-names>E</given-names></name><name><surname>Kałuszyński</surname><given-names>M</given-names></name><name><surname>Kelley</surname><given-names>MSP</given-names></name><name><surname>Kern</surname><given-names>N</given-names></name><name><surname>Kerzendorf</surname><given-names>WE</given-names></name><name><surname>Koch</surname><given-names>EW</given-names></name><name><surname>Kulumani</surname><given-names>S</given-names></name><name><surname>Lee</surname><given-names>A</given-names></name><name><surname>Ly</surname><given-names>C</given-names></name><name><surname>Ma</surname><given-names>Z</given-names></name><name><surname>MacBride</surname><given-names>C</given-names></name><name><surname>Maljaars</surname><given-names>JM</given-names></name><name><surname>Muna</surname><given-names>D</given-names></name><name><surname>Murphy</surname><given-names>NA</given-names></name><name><surname>Norman</surname><given-names>H</given-names></name><name><surname>O’Steen</surname><given-names>R</given-names></name><name><surname>Oman</surname><given-names>KA</given-names></name><name><surname>Pacifici</surname><given-names>C</given-names></name><name><surname>Pascual</surname><given-names>S</given-names></name><name><surname>Pascual-Granado</surname><given-names>J</given-names></name><name><surname>Patil</surname><given-names>RR</given-names></name><name><surname>Perren</surname><given-names>GI</given-names></name><name><surname>Pickering</surname><given-names>TE</given-names></name><name><surname>Rastogi</surname><given-names>T</given-names></name><name><surname>Roulston</surname><given-names>BR</given-names></name><name><surname>Ryan</surname><given-names>DF</given-names></name><name><surname>Rykoff</surname><given-names>ES</given-names></name><name><surname>Sabater</surname><given-names>J</given-names></name><name><surname>Sakurikar</surname><given-names>P</given-names></name><name><surname>Salgado</surname><given-names>J</given-names></name><name><surname>Sanghi</surname><given-names>A</given-names></name><name><surname>Saunders</surname><given-names>N</given-names></name><name><surname>Savchenko</surname><given-names>V</given-names></name><name><surname>Schwardt</surname><given-names>L</given-names></name><name><surname>Seifert-Eckert</surname><given-names>M</given-names></name><name><surname>Shih</surname><given-names>AY</given-names></name><name><surname>Jain</surname><given-names>AS</given-names></name><name><surname>Shukla</surname><given-names>G</given-names></name><name><surname>Sick</surname><given-names>J</given-names></name><name><surname>Simpson</surname><given-names>C</given-names></name><name><surname>Singanamalla</surname><given-names>S</given-names></name><name><surname>Singer</surname><given-names>LP</given-names></name><name><surname>Singhal</surname><given-names>J</given-names></name><name><surname>Sinha</surname><given-names>M</given-names></name><name><surname>Sipőcz</surname><given-names>BM</given-names></name><name><surname>Spitler</surname><given-names>LR</given-names></name><name><surname>Stansby</surname><given-names>D</given-names></name><name><surname>Streicher</surname><given-names>O</given-names></name><name><surname>Šumak</surname><given-names>J</given-names></name><name><surname>Swinbank</surname><given-names>JD</given-names></name><name><surname>Taranu</surname><given-names>DS</given-names></name><name><surname>Tewary</surname><given-names>N</given-names></name><name><surname>Tremblay</surname><given-names>GR</given-names></name><name><surname>de Val-Borro</surname><given-names>M</given-names></name><name><surname>Van Kooten</surname><given-names>SJ</given-names></name><name><surname>Vasović</surname><given-names>Z</given-names></name><name><surname>Verma</surname><given-names>S</given-names></name><name><surname>de Miranda Cardoso</surname><given-names>JV</given-names></name><name><surname>Williams</surname><given-names>PKG</given-names></name><name><surname>Wilson</surname><given-names>TJ</given-names></name><name><surname>Winkel</surname><given-names>B</given-names></name><name><surname>Wood-Vasey</surname><given-names>WM</given-names></name><name><surname>Xue</surname><given-names>R</given-names></name><name><surname>Yoachim</surname><given-names>P</given-names></name><name><surname>Zhang</surname><given-names>C</given-names></name><name><surname>Zonca</surname><given-names>A</given-names></name><collab>Paper Authors</collab><collab>Astropy Project Contributors</collab></person-group><year iso-8601-date="2022">2022</year><article-title>The astropy project: sustaining and growing a community-oriented open-source project and the latest major release (v5.0) of the core package*</article-title><source>The Astrophysical Journal</source><volume>01</volume><elocation-id>ac7c74</elocation-id><pub-id pub-id-type="doi">10.3847/1538-4357/ac7c74</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sargolini</surname><given-names>F</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Conjunctive representation of position, direction, and velocity in entorhinal cortex</article-title><source>Science</source><volume>312</volume><fpage>758</fpage><lpage>762</lpage><pub-id pub-id-type="doi">10.1126/science.1125572</pub-id><pub-id pub-id-type="pmid">16675704</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Schaeffer</surname><given-names>R</given-names></name><name><surname>Khona</surname><given-names>M</given-names></name><name><surname>Ma</surname><given-names>T</given-names></name><name><surname>Eyzaguirre</surname><given-names>C</given-names></name><name><surname>Koyejo</surname><given-names>S</given-names></name><name><surname>Fiete</surname><given-names>IR</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Self-supervised learning of representations for space generates multi-modular grid cells</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2311.02316">https://arxiv.org/abs/2311.02316</ext-link></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schøyen</surname><given-names>V</given-names></name><name><surname>Pettersen</surname><given-names>MB</given-names></name><name><surname>Holzhausen</surname><given-names>K</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Malthe-Sørenssen</surname><given-names>A</given-names></name><name><surname>Lepperød</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Coherently remapping toroidal cells but not Grid cells are responsible for path integration in virtual agents</article-title><source>iScience</source><volume>26</volume><elocation-id>108102</elocation-id><pub-id pub-id-type="doi">10.1016/j.isci.2023.108102</pub-id><pub-id pub-id-type="pmid">37867941</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Schøyen</surname><given-names>V</given-names></name><name><surname>Bechkov</surname><given-names>C</given-names></name><name><surname>Pettersen</surname><given-names>MB</given-names></name><name><surname>Hermansen</surname><given-names>E</given-names></name><name><surname>Holzhausen</surname><given-names>K</given-names></name><name><surname>Malthe-Sørenssen</surname><given-names>A</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Lepperød</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Hexagons all the way down: grid cells as a conformal isometric map of space</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2024.02.02.578585</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Skaggs</surname><given-names>W</given-names></name><name><surname>McNaughton</surname><given-names>B</given-names></name></person-group><year iso-8601-date="1992">1992</year><chapter-title>An information-theoretic approach to deciphering the hippocampal code</chapter-title><person-group person-group-type="editor"><name><surname>Hanson</surname><given-names>S</given-names></name><name><surname>Cowan</surname><given-names>J</given-names></name></person-group><source>Advances in Neural Information Processing Systems</source><publisher-name>Morgan-Kaufmann</publisher-name><fpage>1030</fpage><lpage>1037</lpage></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Solstad</surname><given-names>T</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Einevoll</surname><given-names>GT</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>From grid cells to place cells: a mathematical model</article-title><source>Hippocampus</source><volume>16</volume><fpage>1026</fpage><lpage>1031</lpage><pub-id pub-id-type="doi">10.1002/hipo.20244</pub-id><pub-id pub-id-type="pmid">17094145</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Solstad</surname><given-names>T</given-names></name><name><surname>Boccara</surname><given-names>CN</given-names></name><name><surname>Kropff</surname><given-names>E</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Representation of geometric borders in the entorhinal cortex</article-title><source>Science</source><volume>322</volume><fpage>1865</fpage><lpage>1868</lpage><pub-id pub-id-type="doi">10.1126/science.1166466</pub-id><pub-id pub-id-type="pmid">19095945</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sorscher</surname><given-names>B</given-names></name><name><surname>Mel</surname><given-names>GC</given-names></name><name><surname>Ocko</surname><given-names>SA</given-names></name><name><surname>Giocomo</surname><given-names>LM</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>A unified theory for the computational and mechanistic origins of grid cells</article-title><source>Neuron</source><volume>111</volume><fpage>121</fpage><lpage>137</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2022.10.003</pub-id><pub-id pub-id-type="pmid">36306779</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srivastava</surname><given-names>N</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name><name><surname>Krizhevsky</surname><given-names>A</given-names></name><name><surname>Sutskever</surname><given-names>I</given-names></name><name><surname>Salakhutdinov</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dropout: a simple way to prevent neural networks from overfitting</article-title><source>ACM</source><volume>15</volume><fpage>1929</fpage><lpage>1958</lpage></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taube</surname><given-names>JS</given-names></name><name><surname>Muller</surname><given-names>RU</given-names></name><name><surname>Ranck</surname><given-names>JB</given-names><suffix>Jr</suffix></name></person-group><year iso-8601-date="1990">1990</year><article-title>Head-direction cells recorded from the postsubiculum in freely moving rats. I. Description and quantitative analysis</article-title><source>The Journal of Neuroscience</source><volume>10</volume><fpage>420</fpage><lpage>435</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.10-02-00420.1990</pub-id><pub-id pub-id-type="pmid">2303851</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tavares</surname><given-names>RM</given-names></name><name><surname>Mendelsohn</surname><given-names>A</given-names></name><name><surname>Grossman</surname><given-names>Y</given-names></name><name><surname>Williams</surname><given-names>CH</given-names></name><name><surname>Shapiro</surname><given-names>M</given-names></name><name><surname>Trope</surname><given-names>Y</given-names></name><name><surname>Schiller</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A map for social navigation in the human brain</article-title><source>Neuron</source><volume>87</volume><fpage>231</fpage><lpage>243</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.06.011</pub-id><pub-id pub-id-type="pmid">26139376</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tolman</surname><given-names>EC</given-names></name></person-group><year iso-8601-date="1948">1948</year><article-title>Cognitive maps in rats and men</article-title><source>Psychological Review</source><volume>55</volume><fpage>189</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1037/h0061626</pub-id><pub-id pub-id-type="pmid">18870876</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Uria</surname><given-names>B</given-names></name><name><surname>Ibarz</surname><given-names>B</given-names></name><name><surname>Banino</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A Model of Egocentric to Allocentric Understanding in Mammalian Brains</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2020.11.11.378141</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JCR</given-names></name><name><surname>Muller</surname><given-names>TH</given-names></name><name><surname>Mark</surname><given-names>S</given-names></name><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The tolman-eichenbaum machine: unifying space and relational memory through generalization in the hippocampal formation</article-title><source>Cell</source><volume>183</volume><fpage>1249</fpage><lpage>1263</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.10.024</pub-id><pub-id pub-id-type="pmid">33181068</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wills</surname><given-names>TJ</given-names></name><name><surname>Cacucci</surname><given-names>F</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Development of the hippocampal cognitive map in preweanling rats</article-title><source>Science</source><volume>328</volume><fpage>1573</fpage><lpage>1576</lpage><pub-id pub-id-type="doi">10.1126/science.1188224</pub-id><pub-id pub-id-type="pmid">20558720</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Witter</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2010">2010</year><chapter-title>Connectivity of the hippocampus</chapter-title><person-group person-group-type="editor"><name><surname>Cutsuridis</surname><given-names>V</given-names></name><name><surname>Graham</surname><given-names>B</given-names></name></person-group><source>Hippocampal Microcircuits</source><publisher-name>Springer</publisher-name><fpage>5</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1007/978-1-4419-0996-1_1</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>D</given-names></name><name><surname>Gao</surname><given-names>R</given-names></name><name><surname>Zhang</surname><given-names>WH</given-names></name><name><surname>Wei</surname><given-names>XX</given-names></name><name><surname>Wu</surname><given-names>YN</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Conformal isometry of lie group representation in recurrent network of grid cells</article-title><source>Proceedings of Machine Learning Research</source><volume>197</volume><elocation-id>2022</elocation-id><pub-id pub-id-type="doi">10.48550/arXiv.2210.02684</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s7"><title>Long sequence evaluation</title><p>To verify that the model performs accurate path integration, even for very long sequences, we computed Gaussian kernel density estimates of the Euclidean decoding error at every step along 100, 10000 timestep trajectories in each environment. The bandwidth parameter was set to approximately 0.4 according to Scott’s Rule, and the resulting error distributions are shown in <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>.</p><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Error distribution for long sequence evaluation.</title><p>Each pane shows the distribution and median of Euclidean distances (error) between true and decoded trajectories for the trained recurrent neural network (RNN) evaluated on 100 long (10000-timestep) test trajectories in a particular environment (inset). The color indicates the kernel density estimate value at a particular timestep.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99302-app1-fig1-v1.tif"/></fig><sec sec-type="appendix" id="s7-1"><title>Extended model ratemaps</title><p><xref ref-type="fig" rid="app1fig2">Appendix 1—figures 2</xref> and <xref ref-type="fig" rid="app1fig3">3</xref> show ratemaps for all 100 output units and 100 recurrent units, respectively. Responses in every environment are included. Notably, both output and recurrent units are sparse, with most recurrent units silent in a given environment. Output units display field shifts between environments, indicative of remapping.</p><fig id="app1fig2" position="float"><label>Appendix 1—figure 2.</label><caption><title>Ratemaps of all 100 output units in each environment.</title><p>The geometry is indicated atop every ensemble. Unit identity is given by its location on the grid (e.g. unit 1 is top left in each environment).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99302-app1-fig2-v1.tif"/></fig><fig id="app1fig3" position="float"><label>Appendix 1—figure 3.</label><caption><title>Ratemaps of 100 recurrent units in each environment.</title><p>The geometry is indicated atop every ensemble. Unit identity is given by its location on the grid (e.g. unit 1 is top left in each environment).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99302-app1-fig3-v1.tif"/></fig></sec><sec sec-type="appendix" id="s7-2"><title>Experimental phase distributions</title><p>Figure <xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4</xref> shows example ratemaps, animal trajectories, and estimated distributions of center locations, for centers decoded from ratemaps of high spatial-information place cells in mice (data provided by <xref ref-type="bibr" rid="bib26">Lee et al., 2023</xref>). Also shown is Ripley’s H for center locations decoded from the same cell ratemaps.</p><p>While some distributions display no clear patterns in their center arrangements (e.g., for animal QLAK-CA1-74), some distributions do display signs of clustering and center locations even show some signs of regularity in their arrangement (e.g., QLAK-CA1-50), possibly even similar to the hexagonal arrangements we observe in our model (as shown in <xref ref-type="fig" rid="fig7">Figure 7</xref>).</p><p>To quantify whether the ensemble of place cells were indeed hexagonally arranged, we computed the grid score <xref ref-type="bibr" rid="bib45">Sargolini et al., 2006</xref> of a kernel density estimate over decoding center locations. In this case, all center distributions exhibited low grid scores. However, as it results from correlating rotated versions of an autocorrelogram, the grid score is sensitive to differential clustering in the place cell center distribution. Such clustering could occur in data due to e.g. insufficient sampling of cells encoding particular spatial locations. To combat this possibility, we extracted the peaks of the center location KDE, and computed the grid score of the corresponding KDE over these peaks. The resulting peak grid score measures the degree of hexagonality in the distribution while smoothing out differences due to unequal clustering.</p><p>This analysis revealed that many animals displayed no clear orientation in their center distribution (e.g. QLAK-CA1-08). However, some exhibited exhibited a tendency towards some degree of hexagonal symmetry (QLAK-CA1-50; peak GS 0.67, QLAK-CA1-75; peak GS 0.27). Notably, these are also the two animals with the largest number of included cells.</p><p>Another interesting finding, is that most animals exhibited stronger clustering than expected by random (and uniform) center distributions (as evidenced by greater-than-random Ripley’s H for small ball radii). Note however, that this result could reflect the clustering of field centers near boundaries, which is seen in almost all included animals.</p><p>While preliminary, these findings, in light of our computational predictions, warrant further investigation into the distributional properties of place cells center locations in even larger, high quality datasets.</p><fig id="app1fig4" position="float"><label>Appendix 1—figure 4.</label><caption><title>Place cell center distributions in mice.</title><p>From left to right: trajectories, as well as example ratemaps of CA1 place cells in mice (animal indicated by title), next to kernel density estimates of field center locations (locations of maximal firing rate) for cells with high spatial information. Inset is the number of included cells (<inline-formula><alternatives><mml:math id="inf114"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>n</mml:mi></mml:mstyle></mml:math><tex-math id="inft114">\begin{document}$  n$\end{document}</tex-math></alternatives></inline-formula>) and grid score of the KDE. Also shown is a KDE over maximum locations, alongside the corresponding maximum location grid score (peak GS). The rightmost panel shows Ripley’s H for all place cell peak locations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99302-app1-fig4-v1.tif"/></fig></sec><sec sec-type="appendix" id="s7-3"><title>Velocity ablation</title><p>In 5, we investigated whether the network exhibited attractor-like behavior in the face of noise injection. However, we only considered the case where the network was allowed to explore the arena (with velocity input) after noise injection. In this case, it is possible that representations converge back to their original states after performing error-corrections based on boundary interactions in the environment. This is not entirely consistent with the notion of an attractor state. Therefore, we repeated the noise-injection experiment, with velocities ablated upon noise injection. In other words, the network was allowed to run for an extended period of time (<inline-formula><alternatives><mml:math id="inf115"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>399</mml:mn></mml:mstyle></mml:math><tex-math id="inft115">\begin{document}$  t=399$\end{document}</tex-math></alternatives></inline-formula> steps) before noise was injected into the network state.</p><p>The resulting population vector correlations are shown in <xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5a, b</xref>. As seemingly expected, state-to-state correlations are approximately constant over time in the zero velocity, zero-noise case (<inline-formula><alternatives><mml:math id="inf116"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.0</mml:mn></mml:mstyle></mml:math><tex-math id="inft116">\begin{document}$  \sigma=0.0$\end{document}</tex-math></alternatives></inline-formula>). However, for increased noise, output unit correlations become smaller (<inline-formula><alternatives><mml:math id="inf117"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mstyle></mml:math><tex-math id="inft117">\begin{document}$  \sigma=0.01$\end{document}</tex-math></alternatives></inline-formula>), and for large noise levels, output states before and after noise injection become decorrelated. As seen in <xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5c</xref>, larger noise levels coincide with output unit silencing (<inline-formula><alternatives><mml:math id="inf118"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mstyle></mml:math><tex-math id="inft118">\begin{document}$  \sigma=0.1$\end{document}</tex-math></alternatives></inline-formula>), while some units appear to shift firing location (<inline-formula><alternatives><mml:math id="inf119"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>1.0</mml:mn></mml:mstyle></mml:math><tex-math id="inft119">\begin{document}$  \sigma=1.0$\end{document}</tex-math></alternatives></inline-formula>). Together, these findings suggest that for small noise levels, network representations do converge to their steady-state value (<inline-formula><alternatives><mml:math id="inf120"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.01</mml:mn></mml:mstyle></mml:math><tex-math id="inft120">\begin{document}$  \sigma=0.01$\end{document}</tex-math></alternatives></inline-formula>). However, for sufficiently large noise, network states fail to converge. In 5 on the other hand, representations converge even for the largest noise scales. Thus, while the network exhibits attractor-like behavior for low noise levels, it seems that exploration can serve as an error-correcting mechanism for larger noise scales.</p><p>An interesting aspect of this result, is that recurrent representations remain somewhat correlated, even for maximal noise injection (<xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5b</xref>), even when output units are uncorrelated. This could suggest that recurrent units, while maintaining some of their spatial tuning, fire insufficiently to drive output units beyond their firing threshold (which is zero, due to the ReLU activation function). Another important point is the size of the injected noise. <xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5d</xref> showcases that noise levels are large relative to typical recurrent unit firing rate, especially considering that most recurrent units are silent. Considering that the network has not experienced any noise during training, it is surprising that representations are quite robust to noise, with or without a velocity signal. Collectively, these findings all support the notion that the network has learned attractor-like structures corresponding to the explored environments.</p><fig id="app1fig5" position="float"><label>Appendix 1—figure 5.</label><caption><title>Representational stability after velocity ablation.</title><p>(<bold>a</bold>) Output unit ratemap population vector correlations between all timesteps for trajectories visiting the square environment, with noise injected at timestep.<inline-formula><alternatives><mml:math id="inf121"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>400</mml:mn></mml:mstyle></mml:math><tex-math id="inft121">\begin{document}$  t=400$\end{document}</tex-math></alternatives></inline-formula> Velocity input is ablated after noise injection. (<bold>b</bold>) As in (<bold>a</bold>), but for recurrent units. (<bold>c</bold>) Ratemaps of output units before and after noise injection, for varying noise scales.<inline-formula><alternatives><mml:math id="inf122"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>σ</mml:mi></mml:mstyle></mml:math><tex-math id="inft122">\begin{document}$  \sigma$\end{document}</tex-math></alternatives></inline-formula> (<bold>d</bold>) Distribution of maximum firing rates for all recurrent units across all timesteps, when no noise is injected.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99302-app1-fig5-v1.tif"/></fig></sec></sec><sec sec-type="appendix" id="s8"><title>Learned recurrent representations align with environment boundaries</title><p>One peculiar feature of the learned, border-like representations exhibited by the recurrent layer, is their propensity to align with the cardinal directions. In most arenas, this coincides with the orientation of environment boundaries. However, to some extent, cardinal spatial tuning is also evident in the only non-polarized environment, i.e., the circular arena (see e.g. <xref ref-type="fig" rid="fig4">Figure 4d</xref>), where recurrent responses are slightly rotated, but mostly align with the horizontal and vertical directions. This raises the question of whether recurrent units could inherit their tuning profile from some source other than the environment geometry, such as the Euclidean coordinate system of the velocity input signal.</p><p>To explore whether recurrent unit responses actually align with environment boundaries, we trained a new RNN model in a rotated square (rhombus) environment, while keeping all other training parameters fixed (see Neural Network Architecture and Training for details). Ratemaps of recurrent unit responses for this network is shown in <xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref>. In this case, recurrent responses are still highly sparse, as most units are silent. However, as with the multi-environment model, some units display boundary-like tuning. As expected from boundary-tuned units, responses are no longer aligned with the cardinal directions, but rather with the walls of the arena, providing evidence that representations are indeed tuned to boundaries. This also aligns with the fact that no positional information is available to the recurrent network, and that self-localization must rely on boundary interactions.</p><p>However, the apparent polarization of representations in the circular environment could still point to several interesting possibilities: For one, it might be that responses in the circular environment inherit some of their tuning from learning in other, polarized environments, which might also facilitate representational reuse across environments. As an alternative, representational polarization may also reflect the coordinate system of the velocity signal, in the absence of environmental directionality. Exploring more biologically inspired inputs, such as introducing head direction units, could therefore prove an interesting extension of the current model.</p><p>In summary, learned recurrent representations appear to be tuned to the boundaries of the environment, but investigating how and why such a firing profile emerges could prove an interesting avenue for future work.</p><fig id="app1fig6" position="float"><label>Appendix 1—figure 6.</label><caption><title>Recurrent representations in a rhombus environment.</title><p>Spatial representations of all 500 recurrent units for a model trained in a rotated square (rhombus) environment.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99302-app1-fig6-v1.tif"/></fig></sec><sec sec-type="appendix" id="s9"><title>Representations are guided by context</title><fig id="app1fig7" position="float"><label>Appendix 1—figure 7.</label><caption><title>Ratemaps during context-geometry mismatch.</title><p>Ratemaps of 25 randomly selected output units, evaluated in all geometries, when the context signal is fixed equal to the square context signal (<bold>A</bold>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99302-app1-fig7-v1.tif"/></fig><p>We have established that the network exhibits attractor-like behavior in the face of injected noise. The question then remains how the network selects a particular attractor state to converge towards. In particular, there are two possibilities that appear particularly likely; the context signal, or the geometry of the environment. To distinguish these two cases, we conducted a simple context mismatch experiment, by evaluating the trained network in all geometries, while keeping the context signal fixed at the value corresponding to the square arena. Resulting ratemaps are showcased in <xref ref-type="fig" rid="app1fig7">Appendix 1—figure 7</xref>, which demonstrates that representations in all geometries coincide with those in the original square environment. This indicates that the network relies on the context signal alone for attractor state selection. Note that in large environments, like the rectangle or large square, firing fields appear somewhat enlarged (consistent with 4). Thus, representations are responsive to changes in the geometry, but the global remapping-type behavior between contexts appears to be determined by the context signal itself.</p><sec sec-type="appendix" id="s9-1"><title>Recurrent units rate remap</title><p>We have demonstrated that output units undergo global-type remapping between distinct contexts. However, this remapping behavior appears to be facilitated by rate remapping in recurrent units. This is shown explicitly in <xref ref-type="fig" rid="app1fig8">Appendix 1—figure 8</xref>, which includes rate differences between recurrent responses across all environments. Notably, responses appear highly independent across environments. This can be seen from the large proportion of (normalized) rate differences of either –1 (unit becomes silent), or +1 (unit becomes active). Thus, recurrent unit exhibits strong rate remapping, and the recurrent code is highly sparse when comparing across environments.</p><fig id="app1fig8" position="float"><label>Appendix 1—figure 8.</label><caption><title>Rate differences for recurrent units across all environments.</title><p>Included are differences when comparing rates between the environment illustrated on the diagonal and all other environents (columns; illustrated in top inset). Note that differences are (anti-)symmetric.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-99302-app1-fig8-v1.tif"/></fig></sec><sec sec-type="appendix" id="s9-2"><title>A taxonomy of cognitive maps</title><p>With the definition of a cognitive map in <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>, we can categorise and compare recent normative neural navigation models. A range of models have recently been put forward that solve tasks similar to ours. In this section, we provide a brief recap of these models, and show that they may be viewed as instances of the cognitive map in <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> with different constraints and target representations.</p><p>Common to these models is that they all make use of random sampling of space in the form of simulated spatial trajectories in bounded 2D spaces, motivated by the foraging behaviour of rats. In addition, most works employ gradient-based optimization schemes, and optimize over independent minibatches. We will, however, omit indexing by minibatches for brevity.</p><p>For example, <xref ref-type="bibr" rid="bib9">Dordek et al., 2016</xref> used a target representation <inline-formula><alternatives><mml:math id="inf123"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math><tex-math id="inft123">\begin{document}$  \mathbf{u}(\mathbf{r})=\mathbf{p}(\mathbf{r})$\end{document}</tex-math></alternatives></inline-formula> of place cells modelled as either zero-mean Gaussians or difference of Gaussians, with <inline-formula><alternatives><mml:math id="inf124"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft124">\begin{document}$  \mathbf{r}$\end{document}</tex-math></alternatives></inline-formula> being a Cartesian coordinate which is encoded into a target place code. The target unit centre was sampled from a random, uniform distribution.</p><p>The task, in this case, was to perform non-negative PCA on the label place cells in a square domain <inline-formula><alternatives><mml:math id="inf125"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Ω</mml:mi></mml:mstyle></mml:math><tex-math id="inft125">\begin{document}$  \Omega$\end{document}</tex-math></alternatives></inline-formula>, i.e., finding a constrained low-dimensional representation of the label activity. Concretely, we can formulate PCA as the minimization problem<disp-formula id="equ15"><label>(A8)</label><alternatives><mml:math id="m15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mn>2</mml:mn></mml:msup></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mtext>s.t.</mml:mtext><mml:mspace width="1em"/><mml:msup><mml:mi>W</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mi>W</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:msub><mml:mi>W</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:math><tex-math id="t15">\begin{document}$$\displaystyle  \mathcal{L} &amp;= \|\mathbf{p}(\mathbf{r}) - \hat{\mathbf{p}}(\mathbf{r}) \|^2 \\ &amp;\text{s.t.} \quad W^TW = I_N, \quad W_{ij} \geq 0,$$\end{document}</tex-math></alternatives></disp-formula></p><p>with <inline-formula><alternatives><mml:math id="inf126"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>W</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math><tex-math id="inft126">\begin{document}$  W\in\mathbb{R}^{M\times N}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf127"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi><mml:mo>≤</mml:mo><mml:mi>N</mml:mi></mml:mstyle></mml:math><tex-math id="inft127">\begin{document}$  M\leq N$\end{document}</tex-math></alternatives></inline-formula> and where <inline-formula><alternatives><mml:math id="inf128"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>∪</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math><tex-math id="inft128">\begin{document}$  \hat{\mathbf{u}}(\mathbf{r})=\hat{\mathbf{g}}\cup\hat{\mathbf{p}}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf129"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mi>W</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft129">\begin{document}$  \hat{\mathbf{g}}=W\mathbf{p}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf130"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math><tex-math id="inft130">\begin{document}$  \hat{\mathbf{p}}=W^{T}\hat{\mathbf{g}}$\end{document}</tex-math></alternatives></inline-formula>. The authors found that grid-like responses <inline-formula><alternatives><mml:math id="inf131"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math><tex-math id="inft131">\begin{document}$  \hat{\mathbf{g}}$\end{document}</tex-math></alternatives></inline-formula> appear as an optimal low-dimensional representation of the target place code <inline-formula><alternatives><mml:math id="inf132"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow></mml:mstyle></mml:math><tex-math id="inft132">\begin{document}$  \mathbf{p}$\end{document}</tex-math></alternatives></inline-formula>. This formulation <xref ref-type="bibr" rid="bib9">Dordek et al., 2016</xref> is suitable for studying optimal cognitive maps in an idealized spatial setting. In the ideal setting, the candidate map is learned directly from true spatial coordinates, in contrast to the case where this information is latent, and agents have to build estimates of their location by integrating several sources of spatial information, such as landmark locations and path integration.</p><p><xref ref-type="bibr" rid="bib8">Cueva and Wei, 2018</xref>, <xref ref-type="bibr" rid="bib2">Banino et al., 2018</xref>, <xref ref-type="bibr" rid="bib52">Sorscher et al., 2023</xref> learns latent spatial representations through path integration in a recurrent neural network model. The state of the recurrent network at time <inline-formula><alternatives><mml:math id="inf133"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math><tex-math id="inft133">\begin{document}$  t$\end{document}</tex-math></alternatives></inline-formula> is given by a recurrence relation<disp-formula id="equ16"><label>(A9)</label><alternatives><mml:math id="m16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mstyle></mml:math><tex-math id="t16">\begin{document}$$\displaystyle  \hat{\mathbf{u}}_{t+\Delta t} = \hat{\mathbf{u}}_{t+\Delta t}(\hat{\mathbf{u}}_{t}, \mathbf{v}(t), \Theta), \label{eq:recurrence_relation}$$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf134"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Θ</mml:mi></mml:mstyle></mml:math><tex-math id="inft134">\begin{document}$  \Theta$\end{document}</tex-math></alternatives></inline-formula> denotes a set of model parameters, and <inline-formula><alternatives><mml:math id="inf135"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math><tex-math id="inft135">\begin{document}$  \mathbf{v}(t)$\end{document}</tex-math></alternatives></inline-formula> the input velocities at some time <inline-formula><alternatives><mml:math id="inf136"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math><tex-math id="inft136">\begin{document}$  t$\end{document}</tex-math></alternatives></inline-formula>, while <inline-formula><alternatives><mml:math id="inf137"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Δ</mml:mi><mml:mi>t</mml:mi></mml:mstyle></mml:math><tex-math id="inft137">\begin{document}$  \Delta t$\end{document}</tex-math></alternatives></inline-formula> is an increment of time. For the RNNs described in the coming sections, we suppress the dependency on parameters <inline-formula><alternatives><mml:math id="inf138"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Θ</mml:mi></mml:mstyle></mml:math><tex-math id="inft138">\begin{document}$  \Theta$\end{document}</tex-math></alternatives></inline-formula> for the sake of readability.</p><p><xref ref-type="bibr" rid="bib8">Cueva and Wei, 2018</xref> considered a version of the cognitive map <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> in which a recurrent neural network was trained to minimize the reconstruction error and soft constraints<disp-formula id="equ17"><label>(A10)</label><alternatives><mml:math id="m17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:msubsup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">C</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:munder><mml:mo>∑</mml:mo><mml:mi>t</mml:mi></mml:munder><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:msubsup><mml:mrow class="MJX-TeXAtom-ORD"><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mn>2</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">C</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mspace width="1em"/><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">C</mml:mi></mml:mrow><mml:mn>3</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:math><tex-math id="t17">\begin{document}$$\displaystyle  &amp;\mathcal{L} = \| \mathbf{r}_t - \hat{\mathbf{r}}_t \|_2^2, \\ &amp;\mathcal{C}_1 = \lambda_1 \sum_t |\hat{\mathbf{g}}_t|_2^2, \quad \mathcal{C}_2 =\lambda_2 \|W_{in}\|_F^2 \quad \mathcal{C}_3 =\lambda_3 \|W_{out}\|_F^2 $$\end{document}</tex-math></alternatives></disp-formula></p><p>where <inline-formula><alternatives><mml:math id="inf139"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∪</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft139">\begin{document}$  \hat{\mathbf{u}}_{t}=\hat{\mathbf{g}}_{t}\cup\hat{\mathbf{r}}_{t}$\end{document}</tex-math></alternatives></inline-formula>, <inline-formula><alternatives><mml:math id="inf140"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>ξ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math><tex-math id="inft140">\begin{document}$  \hat{\mathbf{g}}_{t}=\hat{\mathbf{g}}_{t}(\mathbf{g}_{t-1},\mathbf{v}_{t},\xi_ {t})$\end{document}</tex-math></alternatives></inline-formula> is implemented using a continuous time RNN, with initial state <inline-formula><alternatives><mml:math id="inf141"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:math><tex-math id="inft141">\begin{document}$  \hat{\mathbf{g}}_{0}=0$\end{document}</tex-math></alternatives></inline-formula>, and subsequent states given by the recurrence relation in <xref ref-type="disp-formula" rid="equ16">Equation A9</xref> and stationary noise <inline-formula><alternatives><mml:math id="inf142"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>ξ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>μ</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math><tex-math id="inft142">\begin{document}$  \xi_{t}\sim\mathcal{N}(\mu,\sigma^{2})$\end{document}</tex-math></alternatives></inline-formula>. Moreover, <inline-formula><alternatives><mml:math id="inf143"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft143">\begin{document}$  \hat{\mathbf{r}}_{t}=W_{out}\hat{\mathbf{g}}_{t}$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf144"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>W</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft144">\begin{document}$  W_{in}$\end{document}</tex-math></alternatives></inline-formula> is a weight matrix for the velocity input <inline-formula><alternatives><mml:math id="inf145"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">v</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft145">\begin{document}$  \mathbf{v}_{t}$\end{document}</tex-math></alternatives></inline-formula> to the RNN. The domain <inline-formula><alternatives><mml:math id="inf146"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Ω</mml:mi></mml:mstyle></mml:math><tex-math id="inft146">\begin{document}$  \Omega$\end{document}</tex-math></alternatives></inline-formula> is a 2D square arena visited along simulated trajectories, and the network only received velocity inputs along trajectories, necessitating path integration. In this case, the target representation is Cartesian coordinates <inline-formula><alternatives><mml:math id="inf147"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="normal">Ω</mml:mi></mml:mstyle></mml:math><tex-math id="inft147">\begin{document}$  \mathbf{u}(\mathbf{r}_{t})=\mathbf{r}_{t}\in\Omega$\end{document}</tex-math></alternatives></inline-formula>. The authors report that the learned recurrent representations <inline-formula><alternatives><mml:math id="inf148"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math><tex-math id="inft148">\begin{document}$  \hat{\mathbf{g}}$\end{document}</tex-math></alternatives></inline-formula> appear square grid, band, and border cell-like.</p><p><xref ref-type="bibr" rid="bib2">Banino et al., 2018</xref> considered the case of a recurrent long short-term memory (LSTM) network trained to do supervised position prediction. Unlike <xref ref-type="bibr" rid="bib8">Cueva and Wei, 2018</xref>, the training objective featured two target representations, <inline-formula><alternatives><mml:math id="inf149"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∪</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft149">\begin{document}$  \mathbf{u}_{t}=\mathbf{p}_{t}\cup\mathbf{z}_{t}$\end{document}</tex-math></alternatives></inline-formula>. The first target representation, <inline-formula><alternatives><mml:math id="inf150"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math><tex-math id="inft150">\begin{document}$  \mathbf{p}_{t}=\mathbf{p}(\mathbf{r}_{t})$\end{document}</tex-math></alternatives></inline-formula>, was given by an ensemble of normalized, Gaussian place-like units, with <inline-formula><alternatives><mml:math id="inf151"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mi mathvariant="normal">Ω</mml:mi></mml:mstyle></mml:math><tex-math id="inft151">\begin{document}$  \mathbf{r}_{t}\in\Omega$\end{document}</tex-math></alternatives></inline-formula> being Cartesian coordinates along discretized spatial trajectories in a square domain <inline-formula><alternatives><mml:math id="inf152"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">Ω</mml:mi></mml:mstyle></mml:math><tex-math id="inft152">\begin{document}$  \Omega$\end{document}</tex-math></alternatives></inline-formula>. The second target representation consisted of an ensemble of units encoding heading direction, <inline-formula><alternatives><mml:math id="inf153"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math><tex-math id="inft153">\begin{document}$  \mathbf{z}_{t}=\mathbf{z}(\phi_{t})$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf154"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft154">\begin{document}$  \phi_{t}$\end{document}</tex-math></alternatives></inline-formula> is the head direction at time <inline-formula><alternatives><mml:math id="inf155"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math><tex-math id="inft155">\begin{document}$  t$\end{document}</tex-math></alternatives></inline-formula>. The representations of the head direction ensemble were given by a normalized mixture of von Mises distributions. At each step of path integration, the network received linear and angular velocity information along simulated trajectories. In summary, the loss and corresponding soft constraints can be written as<disp-formula id="equ18"><label>(A11)</label><alternatives><mml:math id="m18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mtext>CE</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mspace width="thinmathspace"/><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mtext>CE</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mspace width="thinmathspace"/><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">C</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mi>λ</mml:mi><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mi>W</mml:mi><mml:msubsup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mi>F</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">C</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mtext>Dropout</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>,</mml:mo><mml:mtext>rate</mml:mtext><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:math><tex-math id="t18">\begin{document}$$\displaystyle  &amp;\mathcal{L} = \text{CE}\left(\mathbf{p}_t \, \| \, \hat{\mathbf{p}}_t\right) + \text{CE}\left(\mathbf{z}_t \, \| \, \hat{\mathbf{z}}_t\right), \\ &amp;\mathcal{C}_1 : \lambda \|W\|_F^2 \\ &amp;\mathcal{C}_2 : \text{Dropout}(\hat{\mathbf{u}}, \text{rate}=0.5) $$\end{document}</tex-math></alternatives></disp-formula></p><p>where CE is the cross entropy and Dropout <xref ref-type="bibr" rid="bib53">Srivastava et al., 2014</xref> is a method that ablates random units with a specified rate during training to promote redundancy.</p><p>The cognitive map, in this case, is given by <inline-formula><alternatives><mml:math id="inf156"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∪</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∪</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∪</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft156">\begin{document}$  \hat{\mathbf{u}}_{t}=\hat{\mathbf{h}}_{t}\cup\hat{\mathbf{g}}_{t}\cup\hat{ \mathbf{p}}_{t}\cup\hat{\mathbf{z}}_{t}$\end{document}</tex-math></alternatives></inline-formula>, with <inline-formula><alternatives><mml:math id="inf157"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft157">\begin{document}$  \hat{\mathbf{h}}_{t}$\end{document}</tex-math></alternatives></inline-formula> defined by a recurrent neural network with a <inline-formula><alternatives><mml:math id="inf158"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>tanh</mml:mi></mml:mstyle></mml:math><tex-math id="inft158">\begin{document}$  \tanh$\end{document}</tex-math></alternatives></inline-formula> activation function, while <inline-formula><alternatives><mml:math id="inf159"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft159">\begin{document}$  \hat{\mathbf{g}}_{t}=W_{g}\hat{\mathbf{h}}_{t}$\end{document}</tex-math></alternatives></inline-formula> is an intermediate linear layer. Finally, <inline-formula><alternatives><mml:math id="inf160"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math><tex-math id="inft160">\begin{document}$  \hat{\mathbf{p}}=W_{p}\hat{\mathbf{g}}$\end{document}</tex-math></alternatives></inline-formula>, and <inline-formula><alternatives><mml:math id="inf161"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">z</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>W</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>z</mml:mi></mml:mrow></mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math><tex-math id="inft161">\begin{document}$  \hat{\mathbf{z}}=W_{z}\hat{\mathbf{g}}$\end{document}</tex-math></alternatives></inline-formula>. The intermediate representations, a subset of the cognitive map, <inline-formula><alternatives><mml:math id="inf162"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft162">\begin{document}$  \hat{\mathbf{g}}_{t}$\end{document}</tex-math></alternatives></inline-formula> were found to display heterogeneous, grid-like responses.</p><p>Sorscher et al. reproduced <xref ref-type="bibr" rid="bib2">Banino et al., 2018</xref>; <xref ref-type="bibr" rid="bib8">Cueva and Wei, 2018</xref>; <xref ref-type="bibr" rid="bib9">Dordek et al., 2016</xref> and refined the grid cell model in <xref ref-type="bibr" rid="bib2">Banino et al., 2018</xref> by considering a simpler RNN structure (a vanilla RNN - although other variations have also been tested and shown to provide similar results <xref ref-type="bibr" rid="bib35">Nayebi et al., 2021</xref>), removing head-direction inputs and outputs, the intermediate linear layer, dropout, refining the place cell target representation, and selecting the ReLU as the recurrent activation function <xref ref-type="bibr" rid="bib52">Sorscher et al., 2023</xref>.<disp-formula id="equ19"><label>(A12)</label><alternatives><mml:math id="m19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mtable rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd/><mml:mtd><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mtext>CE</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mspace width="thinmathspace"/><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mspace width="thinmathspace"/><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mi>t</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">C</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msub><mml:mo>:</mml:mo><mml:mi>λ</mml:mi><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mi>W</mml:mi><mml:msub><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mn>2</mml:mn></mml:msub></mml:mtd></mml:mtr></mml:mtable></mml:mstyle></mml:math><tex-math id="t19">\begin{document}$$\displaystyle  &amp;\mathcal{L} = \text{CE}\left(\mathbf{p}_t\, \| \, \hat{\mathbf{p}}_t\right), \\ &amp;\mathcal{C}_1 : \lambda \|W\|_2 $$\end{document}</tex-math></alternatives></disp-formula></p><p>where CE is again the cross entropy, <inline-formula><alternatives><mml:math id="inf163"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:math><tex-math id="inft163">\begin{document}$  \mathbf{p}_{t}=\mathbf{p}(\mathbf{r}_{t})$\end{document}</tex-math></alternatives></inline-formula> is a difference of softmax place cell encoding of the current position of the virtual agent. In this case, the cognitive map is given by <inline-formula><alternatives><mml:math id="inf164"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">u</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>∪</mml:mo><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft164">\begin{document}$  \hat{\mathbf{u}}_{t}=\hat{\mathbf{p}}_{t}\cup\hat{\mathbf{g}}_{t}$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf165"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft165">\begin{document}$  \hat{\mathbf{g}}_{t}$\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf166"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>W</mml:mi><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft166">\begin{document}$  \hat{\mathbf{p}}_{t}=W\hat{\mathbf{g}}_{t}$\end{document}</tex-math></alternatives></inline-formula>, where <inline-formula><alternatives><mml:math id="inf167"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>W</mml:mi></mml:mstyle></mml:math><tex-math id="inft167">\begin{document}$  W$\end{document}</tex-math></alternatives></inline-formula> is a weight matrix. Notably, <inline-formula><alternatives><mml:math id="inf168"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft168">\begin{document}$  \hat{\mathbf{g}}_{t}$\end{document}</tex-math></alternatives></inline-formula> is computed using a vanilla RNN that learns implicit path integration using Cartesian velocity inputs. The authors report that the recurrent responses <inline-formula><alternatives><mml:math id="inf169"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow class="MJX-TeXAtom-ORD"><mml:mover><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi mathvariant="bold">g</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math><tex-math id="inft169">\begin{document}$  \hat{\mathbf{g}}_{t}$\end{document}</tex-math></alternatives></inline-formula> learn to exhibit striking hexagonal firing fields, similar to <xref ref-type="bibr" rid="bib9">Dordek et al., 2016</xref>.</p><p>This brief taxonomy of normative navigation models hopefully shows how our definition of a cognitive map can be used describe a range of different models that learn biologically inspired representations through the lens of machine learning. Furthermore, our definition, and the notion of a target representation, could hopefully inspire new models. For example, one could consider decoding into a target representation of simulated grid cells.</p></sec></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.99302.4.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Bhalla</surname><given-names>Upinder Singh</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>National Centre for Biological Sciences</institution><country>India</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Useful</kwd></kwd-group></front-stub><body><p>This <bold>useful</bold> modeling study shows how spatial representations similar to experiment emerge in a recurrent neural network trained on a navigation task by requiring path integration and decodability, but without relying on grid cells. The network modeling results are <bold>solid</bold>, although the link to experimental data may benefit from further development.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.99302.4.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This work studies representations in a network with one recurrent layer and one output layer that needs to path-integrate so that its position can be accurately decoded from its output. To formalise this problem, the authors define a cost function consisting of the decoding error and a regularisation term. They specify a decoding procedure that, at a given time, averages the output unit center locations, weighted by the activity of the unit at that time. The network is initialised without position information, and only receives a velocity signal (and a context signal to index the environment) at each timestep, so to achieve low decoding error it needs to infer its position and keep it updated with respect to its velocity by path integration.</p><p>The authors take the trained network and let it explore a series of environments with different geometries while collecting unit activities to probe learned representations. They find localised responses in the output units (resembling place fields) and border responses in the recurrent units. Across environments, the output units show global remapping and the recurrent units show rate remapping. Stretching the environment generally produces stretched responses in output and recurrent units. Ratemaps remain stable within environments and stabilise after noise injection. Low-dimensional projections of the recurrent population activity forms environment-specific clusters that reflect the environment's geometry, which suggests independent rather than generalised representations. Finally, the authors discover that the centers of the output unit ratemaps cluster together on a triangular lattice (like the receptive fields of a single grid cell), and find significant clustering of place cell centers in empirical data as well.</p><p>The model setup and simulations are clearly described, and are an interesting exploration of the consequences of a particular set of training requirements - here: path integration and decodability. But it is not obvious to what extent the modelling choices are a realistic reflection of how the brain solves navigation. Therefore, it is not clear whether the results generalize beyond the specifics of the setup here.</p><p>Strengths:</p><p>The authors introduce a very minimal set of model requirements, assumptions, and constraints. In that sense, the model can function as a useful 'baseline', that shows how spatial representations and remapping properties can emerge from the requirement of path integration and decodability alone. Moreover, the authors use the same formalism to relate their setup to existing spatial navigation models, which is informative.</p><p>The global remapping that the authors show is convincing and well-supported by their analyses. The geometric manipulations and the resulting stretching of place responses, without additional training, are interesting. They seem to suggest that the recurrent network may scale the velocity input by the environment dimensions so that the exact same path integrator-output mappings remain valid (but maybe there are other mechanisms too that achieve the same).</p><p>The simulations and analyses in the appendices serve as insightful controls for the main results.</p><p>The clustering of place cell peaks on a triangular lattice is intriguing, given there is no grid cell input. It could have something to do with the fact that a triangular lattice provides optimal coverage of 2d space? The included comparison with empirical data is valuable as a first exploration, showing a promising example, but doesn't robustly support the modelling results.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.99302.4.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>The authors proposed a neural network model to explore the spatial representations of the hippocampal CA1 and entorhinal cortex (EC) and the remapping of these representations when multiple environments are learned. The model consists of a recurrent network and output units (a decoder) mimicking the EC and CA1, respectively. The major results of this study are: the EC network generates cells with their receptive fields tuned to a border of the arena; the decoder develops neuron clusters arranged in a hexagonal lattice. Thus, the model accounts for entrohinal border cells and CA1 place cells. It suggests that the remapping of place cells occurs between different environments through state transitions corresponding to unstable dynamical modes in the recurrent network.</p><p>Strengths:</p><p>The authors found a spatial arrangement of receptive fields similar to their model's prediction in experimental data recorded from CA1. Thus, the model proposes plausible mechanisms to generate hippocampal spatial representations without relying on grid cells. The model also suggests an interesting possibility that path integration is not the speciality of grid cells.</p><p>Weaknesses:</p><p>The role of grid cells in the proposed view, i.e., the boundary-to-place-to-grid model, remains elusive. The model can generate place cells without generating entorhinal grid cells. Moreover, the model can generate hexagonal grid patterns of place cells in a large arena. Whether and how the proposed model is integrated into the entire picture of the hippocampal-entorhinal meｍory processing remains elusive.</p></body></sub-article><sub-article article-type="referee-report" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.99302.4.sa3</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>The authors used recurrent neural network modelling of spatial navigation tasks to investigate border and place cell behaviour during remapping phenomena.</p><p>Strengths:</p><p>The neural network training seemed for the most part (see comments later) well-performed, and the analyses used to make the points were thorough.</p><p>The paper and ideas were well-explained.</p><p>Figure 4 contained some interesting and strong evidence for map-like generalisation as environmental geometry was warped.</p><p>Figure 7 was striking and potentially very interesting.</p><p>It was impressive that the RNN path-integration error stayed low for so long (Fig A1), given that normally networks that only work with dead-reckoning have errors that compound. I would have loved to know how the network was doing this, given that borders did not provide sensory input to the network. I could not think of many other plausible explanations... It would be even more impressive if it was preserved when the network was slightly noisy.</p><p>Update:</p><p>The analysis of how the RNN remapped, using a context signal to switch between largely independent maps, and the examination of the border like tuning in the recurrent units of the RNN, were both thorough and interesting. Further, in the updated response I appreciated the additional appendix E which helped substantiate the claim that the RNN neurons were border cells.</p></body></sub-article><sub-article article-type="author-comment" id="sa4"><front-stub><article-id pub-id-type="doi">10.7554/eLife.99302.4.sa4</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Pettersen</surname><given-names>Markus Borud</given-names></name><role specific-use="author">Author</role><aff><institution>Simula Research Laboratory</institution><addr-line><named-content content-type="city">Oslo</named-content></addr-line><country>Norway</country></aff></contrib><contrib contrib-type="author"><name><surname>Schøyen</surname><given-names>Vemund</given-names></name><role specific-use="author">Author</role><aff><institution>University of Oslo</institution><addr-line><named-content content-type="city">Oslo</named-content></addr-line><country>Norway</country></aff></contrib><contrib contrib-type="author"><name><surname>Malthe-Sørenssen</surname><given-names>Anders</given-names></name><role specific-use="author">Author</role><aff><institution>University of Oslo</institution><addr-line><named-content content-type="city">Oslo</named-content></addr-line><country>Norway</country></aff></contrib><contrib contrib-type="author"><name><surname>Lepperød</surname><given-names>Mikkel E</given-names></name><role specific-use="author">Author</role><aff><institution>Simula Research Laboratory</institution><addr-line><named-content content-type="city">Oslo</named-content></addr-line><country>Norway</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the previous reviews.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1:</bold></p><p>In the future, could you please include the exact changes made to the manuscript in the relevant section of the rebuttal, so it's clear which changes addressed the comment? That would make it easier to see what you refer to exactly - currently I have to guess which manuscript changes implement e.g. &quot;We have tried to make these points more evident&quot;.</p></disp-quote><p>Yes, we apologize for the inconvenience.</p><disp-quote content-type="editor-comment"><p>On possible navigation solutions:</p><p>I'm not sure if I follow this argument. If the networks uses a shifted allocentric representation centred on its initial state, it couldn't consistently decode the position from different starting positions within the same environment (I don't think egocentric is the right term here - egocentric generally refers to representations relative to the animal's own direction like &quot;to the left&quot; rather than &quot;to the west&quot; but these would not work in the allocentric decoding scheme here). In other words: If I path integrate my location relative to my starting location s1 in environment 1 and learn how to decode that representation to an environment location, I cannot use the same representation when I start from s2 in environment 1, because everything will have shifted. I still believe using boundaries is the only solution to infer the absolute location for the agent here (because that's the only information that it gets), and that's the reason for finding boundary representations (and not grid cells). Imagine doing this task on a perfect torus where there are no boundaries: it would be impossible to ever find out at what 'absolute' location you are in the environment. I have therefore not updated this part of my review, but do let me know if I misunderstood.</p></disp-quote><p>Thank you for addressing this point, which is a somewhat unusual feature of our network: We believe the point you raise applies if the decoding were fixed. However, in our case, the decoding is dynamic and depends on the firing pattern, as place unit centers are decoded on a per-trajectory basis. Thus, a new place-like basis may be formed for each trajectory (and in each environment). Hence, the model is not constrained to reuse its representation across trajectories or environments, as place centers are inferred based on unit firing. However, we do observe that the network learns to use a fixed place field placement in each geometry, which likely reflects some optimal solution to the decoding problem. This might also help to explain the hexagonal arrangement of learned field centers. Finally, we agree that egocentric may not be entirely accurate, but we found it to be the best word to distinguish from the allocentric-type navigation adopted by the network.</p><disp-quote content-type="editor-comment"><p>Regarding noise injection:</p><p>Beyond that noise level, the network might return to high correlations, but that must be due to the boundary interactions - very much like what happens at the very beginning of entering an environment: the network has learned to use the boundary to figure out where it is from an uninformative initial hidden state. But I don't think this is currently reflected well in the main text. That still reads &quot;Thus, even though the network was trained without noise, it appears robust even to large perturbations. This suggests that the learned solutions form an approximate attractor.&quot; I think your new (very useful!) velocity ablations show that only small noise is compensated for by attractor dynamics, and larger noise injections are error corrected through boundary interactions. I've added this to the new review.</p></disp-quote><p>Thank you for your kind feedback: We have changed the phrasing in the text to say “robust even to moderate perturbations. ” As we hold that, while numerically small, the amount of injected noise is rather large when compared to the magnitude of activities in the network (see Fig. A5d); the largest maximal rate is around 0.1, which is similar to the noise level at which output representations fail to re-converge. However, some moderation is appropriate, we agree.</p><disp-quote content-type="editor-comment"><p>On contexts being attractive:</p><p>In the new bit of text, I'm not sure why &quot;each environment appears to correspond to distinct attractive states (as evidenced by the global-type remapping behavior)&quot;, i.e. why global-type remapping is evidence for attractive states. Again, to me global-type remapping is evidence that contexts occupy different parts of activity space, but not that they are attractive. I like the new analysis in Appendix F, as it demonstrates that the context signal determines which region of activity space is selected (as opposed to the boundary information!). If I'm not mistaken, we know three things: 1. Different contexts exist in different parts of representation space, 2. Representations are attractive for small amounts of noise, 3. The context signal determines which point in representation space is selected (thanks to the new analysis in Appendix F). That seems to be in line with what the paper claims (I think &quot;contexts are attractive&quot; has been removed?) so I've updated the review.</p></disp-quote><p>It seems to us that we are in agreement on this point; our aim is simply to point out that a particular context signal appears to correspond to a particular (discrete) attractor state (i.e., occupying a distinct part of representation space, as you state), it just seems we use slightly different language, but to avoid confusion, we changed this to say that “representations are attractive”.</p><p>Thanks again for engaging with us, this discussion has been very helpful in improving the paper.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2:</bold></p><p>However, I still struggle to understand the entire picture of the boundary-to-place-to-grid model. After all, what is the role of grid cells in the proposed view? Are they just redundant representations of the space? I encourage the authors to clarify these points in the last two paragraphs on pages 17-18 of the discussion.</p></disp-quote><p>Thank you for your feedback. While we have discussed the possible role of a grid code to some extent, we agree that this point requires clarification. We have therefore added to the discussion on the role of grid cells, which now reads “While the lack of grid cells in this model is interesting, it does not disqualify grid cells from serving as a neural substrate for path integration. Rather, it suggests that path integration may also be performed by other, non-grid spatial cells, and/or that grid cells may serve additional computational purposes. If grid cells are involved during path integration, our findings indicate that additional tasks and constraints are necessary for learning such representations. This possibility has been explored in recent normative models, in which several constraints have been proposed for learning grid-like solutions. Examples include constraints concerning population vector magnitude, conformal isometry (xu, 2022, schaeffer, 2023, schoyen,2024), capacity, spatial separation and path invariance (schaeffer, 2023). Another possibility is that grid cells are geared more towards other cognitive tasks, such as providing a neural metric for space (ginosar, 2023, pettersen, 2024), or supporting memory and inference-making (whittington, 2020). That our model performs path integration without grid cells, and that a myriad of independent constraints are sufficient for grid-like units to emerge in other models, presents strong computational evidence that grid cells are not solely defined by path integration, and that path integration is not only reserved for grid cells.”</p><p>Thank you again for your time and input.</p></body></sub-article></article>