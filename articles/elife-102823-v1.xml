<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">102823</article-id><article-id pub-id-type="doi">10.7554/eLife.102823</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.102823.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Increased listening effort and cochlear neural degeneration underlie speech-in-noise deficits in normal-hearing middle-aged adults</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Zink</surname><given-names>Maggie E</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-2018-2772</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Zhen</surname><given-names>Leslie</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>McHaney</surname><given-names>Jacie R</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="pa1">‡</xref><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Klara</surname><given-names>Jennifer</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Yurasits</surname><given-names>Kimberly</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Cancel</surname><given-names>Victoria E</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Flemm</surname><given-names>Olivia</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con7"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Mitchell</surname><given-names>Claire</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con8"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Datta</surname><given-names>Jyotishka</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con9"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Chandresekaran</surname><given-names>Bharath</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="pa1">‡</xref><xref ref-type="fn" rid="con10"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Parthasarathy</surname><given-names>Aravindakshan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-4573-8004</contrib-id><email>Aravind_Partha@pitt.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con11"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an3r305</institution-id><institution>Department of Communication Science and Disorders, School of Health and Rehabilitation Sciences, University of Pittsburgh</institution></institution-wrap><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02smfhw86</institution-id><institution>Department of Statistics, Virginia Polytechnic Institute and State University</institution></institution-wrap><addr-line><named-content content-type="city">Blacksburg</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an3r305</institution-id><institution>Department of Bioengineering, Swanson School of Engineering, University of Pittsburgh</institution></institution-wrap><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an3r305</institution-id><institution>Department of Otolaryngology, School of Medicine, University of Pittsburgh</institution></institution-wrap><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Obleser</surname><given-names>Jonas</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00t3r8h32</institution-id><institution>University of Lübeck</institution></institution-wrap><country>Germany</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>King</surname><given-names>Andrew J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052gg0110</institution-id><institution>University of Oxford</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn><fn fn-type="present-address" id="pa1"><label>‡</label><p>Department of Communication Sciences and Disorders, Northwestern University, Evanston, United States</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>22</day><month>07</month><year>2025</year></pub-date><volume>13</volume><elocation-id>RP102823</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2024-09-03"><day>03</day><month>09</month><year>2024</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2024-10-16"><day>16</day><month>10</month><year>2024</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2024.08.01.606213"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-11-14"><day>14</day><month>11</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.102823.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-06-26"><day>26</day><month>06</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.102823.2"/></event></pub-history><permissions><copyright-statement>© 2024, Zink, Zhen, McHaney et al</copyright-statement><copyright-year>2024</copyright-year><copyright-holder>Zink, Zhen, McHaney et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-102823-v1.pdf"/><abstract><p>Middle age represents a critical period of accelerated brain changes and provides a window for early detection and intervention in age-related neurological decline. Hearing loss is a key early marker of such decline and is linked to numerous comorbidities in older adults. Yet, ~10% of middle-aged individuals who report hearing difficulties show normal audiograms. Cochlear neural degeneration (CND) could contribute to these hidden hearing deficits, though its role remains unclear due to a lack of objective diagnostics and uncertainty regarding its perceptual outcomes. Here, we employed a cross-species design to examine neural and behavioral signatures of CND. We measured envelope following responses (EFRs) – neural ensemble responses to sound originating from the peripheral auditory pathway – in young and middle-aged adults with normal audiograms and compared these responses to young and middle-aged Mongolian gerbils, where CND was histologically confirmed. We observed near-identical changes in EFRs across species that were associated with CND. Behavioral assessments revealed age-related speech-in-noise deficits under challenging conditions, while pupil-indexed listening effort increased with age even when behavioral performance was matched. Together, these results demonstrate that CND contributes to speech perception difficulties and elevated listening effort in midlife, which may ultimately lead to listening fatigue and social withdrawal.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>cochlear synaptopathy</kwd><kwd>listening effort</kwd><kwd>cross-species</kwd><kwd>EFRs</kwd><kwd>hidden hearing loss</kwd><kwd>Mongolian gerbil</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd><kwd>Other</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>R21DC018882</award-id><principal-award-recipient><name><surname>Parthasarathy</surname><given-names>Aravindakshan</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>F31DC020085</award-id><principal-award-recipient><name><surname>McHaney</surname><given-names>Jacie R</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>T32DC011499</award-id><principal-award-recipient><name><surname>Zink</surname><given-names>Maggie E</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution>PNC Foundation</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Chandresekaran</surname><given-names>Bharath</given-names></name><name><surname>Parthasarathy</surname><given-names>Aravindakshan</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Cochlear neural degeneration in middle-aged adults with normal-hearing thresholds is associated with increased listening effort and behavioral deficits in challenging acoustic environments.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Age-related hearing loss, defined as declines in hearing sensitivity, is exceedingly common; according to some estimates, 45 million adults in the United States over 50 years of age have age-related hearing loss that is significant enough to interfere with communication (<xref ref-type="bibr" rid="bib45">Lin et al., 2011</xref>). Untreated hearing loss decreases quality of life and is considered to be the single-largest modifiable risk factor in middle age for other age-related comorbidities such as cognitive impairment and dementia (<xref ref-type="bibr" rid="bib46">Livingston et al., 2017</xref>). However, current measures of hearing sensitivity fail to capture critical aspects of real-world listening challenges in this population (<xref ref-type="bibr" rid="bib28">Hind et al., 2011</xref>; <xref ref-type="bibr" rid="bib91">Tremblay et al., 2015</xref>). Hearing difficulties experienced by up to 10% of adults seeking help in the hearing clinic are ‘hidden’ to current diagnostic procedures (<xref ref-type="bibr" rid="bib28">Hind et al., 2011</xref>; <xref ref-type="bibr" rid="bib91">Tremblay et al., 2015</xref>; <xref ref-type="bibr" rid="bib13">Cancel et al., 2023</xref>; <xref ref-type="bibr" rid="bib66">Parthasarathy et al., 2020</xref>). Peripheral deafferentation caused by cochlear neural degeneration (CND) may underlie many of these perceptual difficulties (<xref ref-type="bibr" rid="bib41">Kujawa and Liberman, 2009</xref>; <xref ref-type="bibr" rid="bib80">Schaette and McAlpine, 2011</xref>). Anatomical evidence for progressive CND with aging is clear – postmortem studies using human temporal bones estimate a 40% deafferentation caused by CND by the fifth decade of life (<xref ref-type="bibr" rid="bib103">Wu et al., 2019</xref>; <xref ref-type="bibr" rid="bib105">Wu et al., 2023</xref>; <xref ref-type="bibr" rid="bib104">Wu et al., 2020</xref>). CND causes neural coding deficits in the peripheral auditory pathway, affecting the faithful representation of spectrotemporally complex auditory stimuli (<xref ref-type="bibr" rid="bib65">Parthasarathy and Kujawa, 2018</xref>; <xref ref-type="bibr" rid="bib55">Mepani et al., 2021</xref>; <xref ref-type="bibr" rid="bib83">Shaheen et al., 2015</xref>). However, the evidence linking CND with perceptual deficits is mixed – current assessments of perceptual deficits associated with CND primarily focus on behavioral measures of speech in noise listening ability, with mixed evidence of deficits in individuals with putative CND (<xref ref-type="bibr" rid="bib71">Prendergast et al., 2017a</xref>; <xref ref-type="bibr" rid="bib27">Guest et al., 2017</xref>; <xref ref-type="bibr" rid="bib23">Grant et al., 2020</xref>; <xref ref-type="bibr" rid="bib24">Grant et al., 2022</xref>).</p><p>Two challenges impede our understanding of the perceptual consequences of CND. First, while many noninvasive markers of CND have been proposed and validated in animal models (<xref ref-type="bibr" rid="bib41">Kujawa and Liberman, 2009</xref>; <xref ref-type="bibr" rid="bib83">Shaheen et al., 2015</xref>; <xref ref-type="bibr" rid="bib96">Valero et al., 2018</xref>; <xref ref-type="bibr" rid="bib53">Mehraei et al., 2016</xref>), noninvasive estimates of putative CND in humans cannot be confirmed with histological assessment of synapses in the same participants. Cross-species comparative studies and computational modeling provide promising avenues for overcoming this gap (<xref ref-type="bibr" rid="bib9">Bharadwaj et al., 2022</xref>; <xref ref-type="bibr" rid="bib12">Buran et al., 2022</xref>). Second, behavioral readouts of perceptual difficulties in humans show mixed results, with putative CND depending on the specific test used and degree of spectrotemporal and contextual information provided in that test (<xref ref-type="bibr" rid="bib23">Grant et al., 2020</xref>; <xref ref-type="bibr" rid="bib72">Prendergast et al., 2017b</xref>; <xref ref-type="bibr" rid="bib54">Mepani et al., 2020</xref>). The most promising tests for CND are ones with no linguistic context and short spectrotemporal processing windows (<xref ref-type="bibr" rid="bib55">Mepani et al., 2021</xref>; <xref ref-type="bibr" rid="bib54">Mepani et al., 2020</xref>). However, these behavioral readouts may minimize subliminal changes in perception that are reflected in listening effort but <italic>not</italic> in accuracies (<xref ref-type="bibr" rid="bib68">Pichora-Fuller et al., 2016</xref>; <xref ref-type="bibr" rid="bib67">Peelle, 2018</xref>; <xref ref-type="bibr" rid="bib106">Zekveld et al., 2011</xref>). Specifically, two individuals may show similar accuracies on a listening task, but one individual may need to exert substantially more listening effort to achieve the same accuracy as the other. Here, we used a cross-species approach, combined with simultaneous measurements of behavior and listening effort, to show that CND was associated with decreased neural coding fidelity and increased listening effort in middle-aged adults with normal audiometric thresholds. We measured putative CND using the envelope following response (EFR) to rapid (~1000 Hz) modulation frequencies – a suggested marker for CND (<xref ref-type="bibr" rid="bib65">Parthasarathy and Kujawa, 2018</xref>; <xref ref-type="bibr" rid="bib83">Shaheen et al., 2015</xref>). Cross-species comparisons with identical recordings in a low-frequency hearing animal model, the Mongolian gerbil, confirmed that decreases in EFRs were selective only for responses with generators in the auditory nerve. These EFRs were also associated with histologically-confirmed CND in gerbils. In the human model, we simultaneously measured pupil-indexed listening effort in participants as they performed a speech-in-noise task and showed that increased listening effort was present despite matched behavioral accuracies. These results point to hitherto underexplored aspects of auditory perceptual difficulties associated with listening effort and CND.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>‘Normal’ hearing middle-aged adults show evidence of peripheral neural coding deficits that are associated with CND</title><p>Middle-aged (40–55 years) and young adult (18–25 years) listeners were recruited to participate in this study (<xref ref-type="fig" rid="fig1">Figure 1A</xref>). All participants had clinically-normal hearing thresholds and spoke fluent American English. Participants had normal otoscopy by visual examination and air conduction thresholds ≤25 dB HL for octave frequencies between 250 Hz and 8 kHz (<xref ref-type="fig" rid="fig1">Figure 1B</xref>, <xref ref-type="table" rid="table1">Table 1</xref>), consistent with WHO guidelines for normal hearing (<xref ref-type="bibr" rid="bib102">World Health Organization, 2024</xref>). Threshold differences were exaggerated in MAs at extended high frequencies (&gt;8 kHz), which are seldom clinically measured but may be a marker for accumulated lifetime noise damage (<xref ref-type="bibr" rid="bib23">Grant et al., 2020</xref>; <xref ref-type="bibr" rid="bib86">Škerková et al., 2023</xref>; <xref ref-type="bibr" rid="bib58">Mishra et al., 2022</xref>; <xref ref-type="bibr" rid="bib47">Lough and Plack, 2022</xref>, <xref ref-type="fig" rid="fig1">Figure 1B</xref>, <xref ref-type="table" rid="table2">Table 2</xref>). Outer hair cell function, assessed using distortion product otoacoustic emissions (DPOAEs), was comparable between young adult and middle-aged listeners up to 4 kHz, the frequency regions that contain most of the spectral information in speech (<xref ref-type="fig" rid="fig1">Figure 1C</xref>, <xref ref-type="table" rid="table3">Table 3</xref>). Participants also showed no severe symptoms of tinnitus (<xref ref-type="fig" rid="fig1">Figure 1D</xref>), assessed using the Tinnitus Handicap Inventory (THI; <xref ref-type="bibr" rid="bib60">Newman et al., 1996</xref>) and loudness discomfort levels (LDLs; <xref ref-type="bibr" rid="bib60">Newman et al., 1996</xref>) above 80 dB SPL for frequencies up to 3 kHz (<xref ref-type="fig" rid="fig1">Figure 1E</xref>, <xref ref-type="table" rid="table4">Table 4</xref>). Self-reported noise exposure using the Noise Exposure Questionnaire (NEQ; <xref ref-type="bibr" rid="bib33">Johnson et al., 2017</xref>) was not significantly different between age groups (<xref ref-type="fig" rid="fig1">Figure 1F</xref>, <xref ref-type="table" rid="table4">Table 4</xref>). Participants also had normal cognitive function indexed by the Montreal Cognitive Assessment (MoCA&gt;25; <xref ref-type="bibr" rid="bib59">Nasreddine et al., 2005</xref>) and comparable working memory scores assessed using the operation span (OSPAN) task (<xref ref-type="bibr" rid="bib93">Turner and Engle, 1989</xref>, <xref ref-type="fig" rid="fig1">Figure 1G</xref>, <xref ref-type="table" rid="table4">Table 4</xref>). Hence, the middle-aged adults recruited for this study were all considered ‘normal’ by currently administered behavioral and audiological assessments in the hearing clinic, while exhibiting some subclinical outer hair cell dysfunction, especially at frequencies above 4 kHz.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Age-related cochlear neural degeneration (CND) occurs prior to overt changes in hearing thresholds and can be assessed noninvasively by measuring phase-locked neural envelope following responses.</title><p>(<bold>A</bold>) Thirty seven middle-aged (MA, 40–55 years, mean = 46.1 ± 4.6 years) and 35 young adults (YA, 18–25 years, mean = 21.17 ± 1.8 years) participated in this study. (<bold>B</bold>) All participants had clinically normal-hearing thresholds, with some evidence of threshold losses at extended high frequencies above 8 kHz typically not tested in the clinic. Hearing thresholds in dB HL are shown on the Y-axis and frequency in kHz is plotted on the X-axis. (<bold>C</bold>) Outer hair cell function assessed using distortion product otoacoustic emissions (DPOAEs) is comparable between YA and MA up to 4 kHz and showed age-related decreases at higher frequencies. Both cohorts show no evidence of self-reported tinnitus (<bold>D</bold>) or hyperacusis measured as loudness discomfort levels (LDLs) (<bold>E</bold>), have comparable self-reported noise exposure levels (<bold>F</bold>), and present with comparable working memory scores assessed using operation span task (OSPAN) (<bold>G</bold>). (<bold>H</bold>) Envelope following responses (EFRs) to modulation frequencies of 1024 Hz can be reliably recorded in YA and MA using ‘tiptrodes’. The panel shows grand-averaged fast Fourier transform (FFT) traces for YA and MA. (<bold>I</bold>) MA showed significant declines in EFR amplitudes at 1024 Hz amplitude modulation (AM), with putative neural generators in the auditory nerve. (<bold>J</bold>) Signal-to-noise ratios were 8 dB on average for YA and 4 dB for MA. (<bold>K</bold>) Statistically significant decreases in EFR amplitudes were selective for 1024 Hz AM, the modulation frequency with putative generators in the auditory nerve. All panels: Error bars and shading represent standard error of the mean (SEM). Asterisks represent p&lt;0.05, analysis of variance (ANOVA).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102823-fig1-v1.tif"/></fig><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Comparison of air conduction thresholds using a three-way analysis of variance (ANOVA) (middle-aged adults [MA] =37, young adults [YA] =35)<italic>.</italic></title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Effects</th><th align="left" valign="bottom">DFn</th><th align="left" valign="bottom">Sum Sq</th><th align="left" valign="bottom">Mean Sq</th><th align="left" valign="bottom">F-value</th><th align="left" valign="bottom"><italic>p</italic>-Value</th></tr></thead><tbody><tr><td align="left" valign="bottom">Frequency</td><td align="left" valign="bottom">6</td><td align="left" valign="bottom">5067</td><td align="left" valign="bottom">844</td><td align="left" valign="bottom">20.786</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">Ear</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">3</td><td align="left" valign="bottom">3</td><td align="left" valign="bottom">0.068</td><td align="left" valign="bottom">0.8</td></tr><tr><td align="left" valign="bottom">Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">5831</td><td align="left" valign="bottom">5813</td><td align="left" valign="bottom">143.521</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">Freq:Ear</td><td align="left" valign="bottom">6</td><td align="left" valign="bottom">85</td><td align="left" valign="bottom">14</td><td align="left" valign="bottom">0.349</td><td align="left" valign="bottom">0.9</td></tr><tr><td align="left" valign="bottom">Freq:Group</td><td align="left" valign="bottom">6</td><td align="left" valign="bottom">905</td><td align="left" valign="bottom">151</td><td align="left" valign="bottom">3.712</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">Ear:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">7</td><td align="left" valign="bottom">7</td><td align="left" valign="bottom">0.164</td><td align="left" valign="bottom">0.7</td></tr><tr><td align="left" valign="bottom">Freq:Ear:Group</td><td align="left" valign="bottom">6</td><td align="left" valign="bottom">234</td><td align="left" valign="bottom">39</td><td align="left" valign="bottom">0.961</td><td align="left" valign="bottom">0.5</td></tr><tr><td align="left" valign="bottom">Residuals</td><td align="left" valign="bottom">840</td><td align="left" valign="bottom">34125</td><td align="left" valign="bottom">41</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr></tbody></table><table-wrap-foot><fn><p>*<italic>p</italic>&lt;0.05; ***<italic>p</italic>&lt;0.001.</p></fn></table-wrap-foot></table-wrap><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Comparison of extended high frequencies using three-way analysis of variance (ANOVA) (middle-aged adults [MA] =37, young adults [YA] =35).</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Effects</th><th align="left" valign="bottom">DFn</th><th align="left" valign="bottom">Sum Sq</th><th align="left" valign="bottom">Mean Sq</th><th align="left" valign="bottom">F-value</th><th align="left" valign="bottom"><italic>p</italic>-Value</th></tr></thead><tbody><tr><td align="left" valign="bottom">Frequency</td><td align="left" valign="bottom">2</td><td align="left" valign="bottom">21209</td><td align="left" valign="bottom">10605</td><td align="left" valign="bottom">74.523</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">Ear</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">6</td><td align="left" valign="bottom">6</td><td align="left" valign="bottom">0.039</td><td align="left" valign="bottom">0.8</td></tr><tr><td align="left" valign="bottom">Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">32868</td><td align="left" valign="bottom">32868</td><td align="left" valign="bottom">230.978</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">Freq:Ear</td><td align="left" valign="bottom">2</td><td align="left" valign="bottom">142</td><td align="left" valign="bottom">142</td><td align="left" valign="bottom">0.498</td><td align="left" valign="bottom">0.6</td></tr><tr><td align="left" valign="bottom">Freq:Group</td><td align="left" valign="bottom">2</td><td align="left" valign="bottom">6016</td><td align="left" valign="bottom">6016</td><td align="left" valign="bottom">21.137</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">Ear:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">152</td><td align="left" valign="bottom">152</td><td align="left" valign="bottom">1.069</td><td align="left" valign="bottom">0.3</td></tr><tr><td align="left" valign="bottom">Freq:Ear:Group</td><td align="left" valign="bottom">2</td><td align="left" valign="bottom">38</td><td align="left" valign="bottom">19</td><td align="left" valign="bottom">0.134</td><td align="left" valign="bottom">0.9</td></tr><tr><td align="left" valign="bottom">Residuals</td><td align="left" valign="bottom">350</td><td align="left" valign="bottom">49805</td><td align="left" valign="bottom">142</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr></tbody></table><table-wrap-foot><fn><p>*<italic>p</italic>&lt;0.05; ***<italic>p</italic>&lt;0.001.</p></fn></table-wrap-foot></table-wrap><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Comparison of right ear distortion product otoacoustic emissions using a two-way analysis of variance (ANOVA) (middle-aged adults [MA] =34, young adults [YA] =31).</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Effects</th><th align="left" valign="bottom">DFn</th><th align="left" valign="bottom">DFd</th><th align="left" valign="bottom">F-value</th><th align="left" valign="bottom">p-Value</th></tr></thead><tbody><tr><td align="left" valign="bottom">Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">25.85</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">Freq</td><td align="left" valign="bottom">9.55</td><td align="left" valign="bottom">601.56</td><td align="left" valign="bottom">58.786</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">Group:Freq</td><td align="left" valign="bottom">9.55</td><td align="left" valign="bottom">601.56</td><td align="left" valign="bottom">7.341</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">501:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">0.713</td><td align="left" valign="bottom">1.00</td></tr><tr><td align="left" valign="bottom">595:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">1.939</td><td align="left" valign="bottom">1.00</td></tr><tr><td align="left" valign="bottom">707:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">0.718</td><td align="left" valign="bottom">1.00</td></tr><tr><td align="left" valign="bottom">841:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">0.268</td><td align="left" valign="bottom">1.00</td></tr><tr><td align="left" valign="bottom">998:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">4.38</td><td align="left" valign="bottom">0.84</td></tr><tr><td align="left" valign="bottom">1188:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">0.794</td><td align="left" valign="bottom">1.00</td></tr><tr><td align="left" valign="bottom">1414:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">4.67</td><td align="left" valign="bottom">0.74</td></tr><tr><td align="left" valign="bottom">1681:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">1.724</td><td align="left" valign="bottom">1.00</td></tr><tr><td align="left" valign="bottom">2000:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">0.87</td><td align="left" valign="bottom">1.00</td></tr><tr><td align="left" valign="bottom">2378:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">0.059</td><td align="left" valign="bottom">1.00</td></tr><tr><td align="left" valign="bottom">2828:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">4.755</td><td align="left" valign="bottom">0.69</td></tr><tr><td align="left" valign="bottom">3365:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">2.095</td><td align="left" valign="bottom">1.00</td></tr><tr><td align="left" valign="bottom">4001:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">10.463</td><td align="left" valign="bottom">0.04*</td></tr><tr><td align="left" valign="bottom">4757:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">18.015</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">5658:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">29.947</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">6727:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">37.01</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">8000:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">28.94</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">9514:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">39.235</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">11314:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">26.847</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">13454:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">7.771</td><td align="left" valign="bottom">0.147</td></tr><tr><td align="left" valign="bottom">160000:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">0.436</td><td align="left" valign="bottom">1.00</td></tr></tbody></table><table-wrap-foot><fn><p>*<italic>p</italic> &lt; .05; ***<italic>p</italic> &lt; .001.</p></fn></table-wrap-foot></table-wrap><table-wrap id="table4" position="float"><label>Table 4.</label><caption><title>Comparisons using one-way analyses of variance (ANOVAs).</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Measure</th><th align="left" valign="bottom">YA (<italic>n</italic>)</th><th align="left" valign="bottom">MA (<italic>n</italic>)</th><th align="left" valign="bottom">DFn</th><th align="left" valign="bottom">DFd</th><th align="left" valign="bottom">F-value</th><th align="left" valign="bottom"><italic>p-</italic>Value</th></tr></thead><tbody><tr><td align="left" valign="bottom">THI</td><td align="left" valign="bottom">33</td><td align="left" valign="bottom">37</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">68</td><td align="left" valign="bottom">0.834</td><td align="left" valign="bottom">0.364</td></tr><tr><td align="left" valign="bottom">OSPAN</td><td align="left" valign="bottom">34</td><td align="left" valign="bottom">34</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">66</td><td align="left" valign="bottom">3.501</td><td align="left" valign="bottom">0.066</td></tr><tr><td align="left" valign="bottom">QuickSIN Clinical Score</td><td align="left" valign="bottom">31</td><td align="left" valign="bottom">34</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">63</td><td align="left" valign="bottom">3.214</td><td align="left" valign="bottom">0.078</td></tr><tr><td align="left" valign="bottom">NEQ</td><td align="left" valign="bottom">32</td><td align="left" valign="bottom">32</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">66</td><td align="left" valign="bottom">0.8375</td><td align="left" valign="bottom">0.363</td></tr></tbody></table><table-wrap-foot><fn><p>Adjusted <italic>p</italic>-values are reported using Bonferroni correction.</p></fn></table-wrap-foot></table-wrap><p>We then measured putative CND using neural ensemble responses from the auditory periphery phase-locked to the stimulus amplitude envelope via the EFR. EFRs can be used to emphasize neural generators in the auditory periphery by exploiting divergent phase-locking abilities along the ascending auditory pathway. EFRs at rapid amplitude modulation (AM) frequencies above 600 Hz have been shown to relate to underlying CND in animal models (<xref ref-type="bibr" rid="bib65">Parthasarathy and Kujawa, 2018</xref>; <xref ref-type="bibr" rid="bib83">Shaheen et al., 2015</xref>) and in humans (<xref ref-type="bibr" rid="bib55">Mepani et al., 2021</xref>). Here, we measured EFRs to AM frequencies that have putative neural generators in the central auditory pathway such as the cortex (40 Hz AM) (<xref ref-type="bibr" rid="bib65">Parthasarathy and Kujawa, 2018</xref>; <xref ref-type="bibr" rid="bib63">Parthasarathy and Bartlett, 2012</xref>), as well as faster modulation rates (110 Hz, 512 Hz, and 1024 Hz AM) that emphasize progressively peripheral auditory regions (<xref ref-type="bibr" rid="bib65">Parthasarathy and Kujawa, 2018</xref>). We were able to reliably record EFRs up to 1024 Hz by using gold-foil tipped electrodes (‘tiptrodes’) placed in the ear canal, closer to the presumptive neural generators in the auditory nerve (<xref ref-type="fig" rid="fig1">Figure 1H</xref>). EFR peaks analyzed in the spectral domain were above the noise floor, with average signal-to-noise ratios (SNRs) of 8 dB in younger and 4 dB in middle-aged adults (the panels I and J of <xref ref-type="fig" rid="fig1">Figure 1</xref>). Statistically significant age-related decreases in EFR amplitudes were only present for EFRs to the 1024 Hz AM rate, which has putative generators in the auditory nerve (<xref ref-type="bibr" rid="bib65">Parthasarathy and Kujawa, 2018</xref>; <xref ref-type="bibr" rid="bib83">Shaheen et al., 2015</xref>), but were not present for slower AM rates with putative generators in the midbrain or cortex (<xref ref-type="fig" rid="fig1">Figure 1K</xref>, <xref ref-type="table" rid="table5">Table 5</xref>).</p><table-wrap id="table5" position="float"><label>Table 5.</label><caption><title>Comparison of envelope following responses (EFRs) using two-way analyses of variance (ANOVAs) (middle-aged adults [MA] =29, young adults [YA] =28).</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Effects</th><th align="left" valign="bottom">DFn</th><th align="left" valign="bottom">DFd</th><th align="left" valign="bottom">F-value</th><th align="left" valign="bottom"><italic>p</italic>-Value</th></tr></thead><tbody><tr><td align="left" valign="bottom">Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">54</td><td align="left" valign="bottom">0.275</td><td align="left" valign="bottom">0.6</td></tr><tr><td align="left" valign="bottom">AM</td><td align="left" valign="bottom">1.47</td><td align="left" valign="bottom">79.49</td><td align="left" valign="bottom">151.407</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">Group:AM</td><td align="left" valign="bottom">1.47</td><td align="left" valign="bottom">79.49</td><td align="left" valign="bottom">0.151</td><td align="left" valign="bottom">0.929</td></tr><tr><td align="left" valign="bottom">1024:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">55</td><td align="left" valign="bottom">23.8</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">512:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">56</td><td align="left" valign="bottom">3.171</td><td align="left" valign="bottom">0.083</td></tr><tr><td align="left" valign="bottom">110:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">55</td><td align="left" valign="bottom">0.491</td><td align="left" valign="bottom">0.487</td></tr><tr><td align="left" valign="bottom">40:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">54</td><td align="left" valign="bottom">0.027</td><td align="left" valign="bottom">0.870</td></tr></tbody></table><table-wrap-foot><fn><p>*<italic>p</italic>&lt;0.05; ***<italic>p</italic>&lt;0.001.</p></fn></table-wrap-foot></table-wrap><p>To confirm that the EFR parameters used here were indeed sensitive to putative CND, we measured EFRs using identical stimuli, acquisition, and analysis parameters in young (22 weeks) and middle-aged (80 weeks) Mongolian gerbils (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). The hearing range of gerbils largely overlaps with that of humans at speech frequencies (<xref ref-type="bibr" rid="bib78">Ryan, 1976</xref>), making them an ideal animal model for direct comparison in cross-species studies. Middle-aged gerbils showed no loss of hearing thresholds, similar to middle-aged humans (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Remarkably, gerbils also exhibited a selective decrease in EFR amplitudes for AM rates at 1024 Hz, similar to middle-aged humans (<xref ref-type="fig" rid="fig2">Figure 2C</xref>, <xref ref-type="table" rid="table6">Table 6</xref>). CND in gerbils was assessed using immunohistological analysis of cochlear whole mounts where the cell bodies, presynaptic ribbon terminals, and the postsynaptic glutamate receptor patches were immunostained, visualized using confocal microscopy, and quantified from 3D reconstructed images (<xref ref-type="fig" rid="fig2">Figure 2D</xref>). Significant decreases in afferent synapse counts were present in middle-aged gerbils, reaching up to 20% losses compared to the young gerbils (<xref ref-type="fig" rid="fig2">Figure 2E</xref>, <xref ref-type="table" rid="table7">Table 7</xref>). Further, EFR amplitudes were significantly correlated to the number of remaining cochlear synapses (<xref ref-type="fig" rid="fig2">Figure 2F</xref>), thus confirming that our EFRs were a sensitive metric of CND.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Cross-species experiments in a rodent model show that envelope following responses (EFRs) are a sensitive biomarker for histologically-confirmed cochlear neural degeneration (CND).</title><p>(<bold>A</bold>) Cross-species comparisons were made with young (22±0.86 weeks, <italic>n</italic>=14) and middle-aged (80±0.76 weeks, <italic>n</italic>=12) Mongolian gerbils, with identical stimuli, recording, and analysis parameters. (<bold>B</bold>) Middle-aged gerbils did not show any age-related decreases in hearing thresholds. (<bold>C</bold>) Age-related decreases in EFR amplitudes were isolated to the 1024 Hz modulation frequency, similar to middle-aged humans in <xref ref-type="fig" rid="fig1">Figure 1K</xref>. (<bold>D</bold>) CND was quantified using immunostained organ of Corti whole mounts, where afferent excitatory synapses were quantified using 3D reconstructed images. (<bold>E</bold>) Cochlear synapse counts at the 3 kHz cochlear region corresponding to the carrier frequency for the EFRs were significantly decreased in middle-aged gerbils, despite matched auditory thresholds. (<bold>F</bold>) EFR amplitudes at 1024 Hz amplitude modulation (AM) were significantly correlated with the number of remaining cochlear synapses, suggesting that these EFRs are a sensitive metric for CND with age. All panels: Error bars and shading represent standard error of the mean (SEM). Asterisks represent p&lt;0.05, analysis of variance (ANOVA).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102823-fig2-v1.tif"/></fig><table-wrap id="table6" position="float"><label>Table 6.</label><caption><title>Comparison of 22-week-old gerbil (<italic>n</italic>=14) and 80-week-old gerbil (<italic>n</italic>=12) envelope following responses (EFRs) using two-way analyses of variance (ANOVAs).</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Effects</th><th align="left" valign="bottom">DFn</th><th align="left" valign="bottom">DFd</th><th align="left" valign="bottom">F-value</th><th align="left" valign="bottom"><italic>p</italic>-Value</th></tr></thead><tbody><tr><td align="left" valign="bottom">Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">24</td><td align="left" valign="bottom">4.125</td><td align="left" valign="bottom">0.053</td></tr><tr><td align="left" valign="bottom">AM</td><td align="left" valign="bottom">2.68</td><td align="left" valign="bottom">64.28</td><td align="left" valign="bottom">74.636</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">Group:AM</td><td align="left" valign="bottom">2.68</td><td align="left" valign="bottom">64.28</td><td align="left" valign="bottom">0.875</td><td align="left" valign="bottom">0.449</td></tr><tr><td align="left" valign="bottom">16:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">24</td><td align="left" valign="bottom">0.456</td><td align="left" valign="bottom">0.506</td></tr><tr><td align="left" valign="bottom">40:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">24</td><td align="left" valign="bottom">2.461</td><td align="left" valign="bottom">0.130</td></tr><tr><td align="left" valign="bottom">110:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">24</td><td align="left" valign="bottom">3.056</td><td align="left" valign="bottom">0.093</td></tr><tr><td align="left" valign="bottom">256:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">24</td><td align="left" valign="bottom">1.959</td><td align="left" valign="bottom">0.174</td></tr><tr><td align="left" valign="bottom">724:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">24</td><td align="left" valign="bottom">2.483</td><td align="left" valign="bottom">0.128</td></tr><tr><td align="left" valign="bottom">1024:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">24</td><td align="left" valign="bottom">5.158</td><td align="left" valign="bottom">0.032*</td></tr></tbody></table><table-wrap-foot><fn><p>*<italic>p</italic> &lt; .05; ***<italic>p</italic> &lt; .001.</p></fn></table-wrap-foot></table-wrap><table-wrap id="table7" position="float"><label>Table 7.</label><caption><title>Comparison of synapse counts at 3000 Hz in 22- and 80-week-old gerbils using one-way analysis of variance (ANOVA).</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Measure</th><th align="left" valign="bottom">22 weeks (<italic>n</italic>)</th><th align="left" valign="bottom">80 weeks (<italic>n</italic>)</th><th align="left" valign="bottom">DFn</th><th align="left" valign="bottom">DFd</th><th align="left" valign="bottom">F-value</th><th align="left" valign="bottom"><italic>p</italic>-Value</th></tr></thead><tbody><tr><td align="left" valign="bottom">Synapse counts</td><td align="left" valign="bottom">14</td><td align="left" valign="bottom">12</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">16</td><td align="left" valign="bottom">4.877</td><td align="left" valign="bottom">0.042*</td></tr></tbody></table><table-wrap-foot><fn><p>*<italic>p</italic>&lt;0.05; ***<italic>p</italic>&lt;0.001.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s2-2"><title>Perceptual deficits manifest as increased listening effort prior to behavioral deficits in middle-aged adults</title><p>Do middle-aged adults with putative CND experience challenges with hearing in noise despite having clinically normal-hearing thresholds? We measured speech perception in noise abilities with the clinically-used Quick Speech-in-Noise (QuickSIN; <xref ref-type="bibr" rid="bib36">Killion et al., 2004</xref>) task to assess hearing in noise changes that mimic real-world listening scenarios. The QuickSIN tests suprathreshold hearing of medium-context sentences presented in varying levels of four-talker background babble ranging from 25 dB to 0 dB SNR levels in 5 dB steps (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). Further, QuickSIN is a clinically-relevant test that we recently identified as being sensitive to perceptual deficits in adult populations with normal audiograms (<xref ref-type="bibr" rid="bib13">Cancel et al., 2023</xref>). On each trial, participants were instructed to repeat a target sentence, which contained five keywords for identification. Clinically, QuickSIN is scored as dB SNR loss, reflecting the SNR level required to accurately identify keywords in noise correctly half the time. No significant age-related differences were observed in clinically scored QuickSIN dB SNR loss (<xref ref-type="fig" rid="fig3">Figure 3B</xref>, <xref ref-type="table" rid="table4">Table 4</xref>). When analyzing performance at each SNR, accuracy was at near-ceiling from 25 dB SNR to 10 dB SNR, but dropped from 5 dB SNR in both young and middle-aged adults. Statistically significant behavioral deficits with age were observed on QuickSIN only in the most challenging SNR of 0 dB (<xref ref-type="fig" rid="fig3">Figure 3C</xref>, <xref ref-type="table" rid="table8">Table 8</xref>).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Increased listening effort precedes behavioral deficits in speech-in-noise perception in middle-aged adults.</title><p>(<bold>A</bold>) Speech perception in noise was assessed using the Quick Speech-in-Noise (QuickSIN) test, which presents moderate context sentences in varying levels of multi-talker babble. Pupillary measures were analyzed in two time-windows: (1) during stimulus presentation and (2) after target sentence offset and prior to response initiation. (<bold>B</bold>) No significant age-related differences were observed in clinical QuickSIN scores presented as dB signal-to-noise ratio (SNR) loss. (<bold>C</bold>) QuickSIN performance is matched between middle-aged (MA) and younger adults (YA) until the most difficult noise condition (SNR 0). The x-axis shows the SNR condition that the target sentences were presented in, with 25 dB being the easiest noise condition, and 0 dB being the most difficult noise condition. The y-axis shows participant accuracy in repeating keywords from the target sentences as percent correct. (<bold>D</bold>) Grand-averaged pupillary responses, measured during task listening as an index of effort, exhibit modulation with task difficulty, with greater pupillary dilations observed in harder conditions for both groups. (<bold>E</bold>) Middle-aged adults show consistently higher pupillary responses during performance on the QuickSIN task and at SNR levels prior to when overt behavioral deficits are observed. (<bold>F</bold>) Grand-averaged pupillary responses measured after target sentence offset as an index of effort exhibit greater modulation with task difficulty, compared to changes in the listening window. (<bold>G</bold>) Trends seen in the listening window were amplified in this integration window, with middle-aged adults showing even greater effort, especially at moderate SNRs where behavior was matched.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102823-fig3-v1.tif"/></fig><table-wrap id="table8" position="float"><label>Table 8.</label><caption><title>Comparison of Quick Speech-in-Noise (QuickSIN) performance using a mixed-design analysis of variance (ANOVA) (middle-age adults [MA] =34, young adults [YA] =31).</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Effects</th><th align="left" valign="bottom">DFn</th><th align="left" valign="bottom">DFd</th><th align="left" valign="bottom">F-value</th><th align="left" valign="bottom"><italic>p</italic>-value</th></tr></thead><tbody><tr><td align="left" valign="bottom">Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">372</td><td align="left" valign="bottom">3.79</td><td align="left" valign="bottom">0.0522</td></tr><tr><td align="left" valign="bottom">SNR</td><td align="left" valign="bottom">5</td><td align="left" valign="bottom">372</td><td align="left" valign="bottom">541.81</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">Group:SNR</td><td align="left" valign="bottom">5</td><td align="left" valign="bottom">372</td><td align="left" valign="bottom">6.57</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">0:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">62</td><td align="left" valign="bottom">10.512</td><td align="left" valign="bottom">0.001*</td></tr><tr><td align="left" valign="bottom">5:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">62</td><td align="left" valign="bottom">0.002</td><td align="left" valign="bottom">0.956</td></tr><tr><td align="left" valign="bottom">10:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">62</td><td align="left" valign="bottom">1.336</td><td align="left" valign="bottom">0.252</td></tr><tr><td align="left" valign="bottom">15:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">62</td><td align="left" valign="bottom">1.834</td><td align="left" valign="bottom">0.180</td></tr><tr><td align="left" valign="bottom">20:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">62</td><td align="left" valign="bottom">0.227</td><td align="left" valign="bottom">0.634</td></tr><tr><td align="left" valign="bottom">25:Group</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom">62</td><td align="left" valign="bottom">4.980</td><td align="left" valign="bottom">0.0292*</td></tr></tbody></table><table-wrap-foot><fn><p><italic>*p</italic> &lt; .05; ***<italic>p</italic> &lt; .001.</p></fn></table-wrap-foot></table-wrap><p>Are there perceptual deficits experienced by middle-aged adults that are not captured by traditional behavioral readouts? We addressed this question by measuring isoluminous task-related changes in pupil diameter as an index of listening effort (<xref ref-type="bibr" rid="bib5">Beatty, 1982</xref>; <xref ref-type="bibr" rid="bib99">Winn et al., 2015</xref>; <xref ref-type="bibr" rid="bib38">Kuchinsky et al., 2013</xref>) while participants performed the QuickSIN task (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). Pupillary changes were analyzed using growth curve analysis (GCA, <xref ref-type="bibr" rid="bib57">Mirman, 2014</xref>). GCAs provide a statistical approach to modeling changes over time in the timing and shape of the pupillary response and have several advantages to analyzing pupillary response over traditional approaches. First, GCA does not require time-binned samples, thus removing the trade-off between temporal resolution and statistical power, and, second, GCA can account for individual variability. Two second-order GCAs were fit to different time-windows (<xref ref-type="table" rid="table9 table10">Tables 9–10</xref>, see Methods). One time-window encompassed the onset of the masker through the first 2.8 s of the target sentence (listening window). The second window spanned from the offset of the target sentence up to the verbal response prompt (integration window). These two time-windows were hypothesized to represent effort associated with differing sensory and cognitive processes. The listening window reflects linguistic and semantic processing of ongoing speech stimuli and is a physiological response to auditory processing (<xref ref-type="bibr" rid="bib50">McHaney et al., 2021</xref>), while the integration window reflects error correction, working memory, and comparisons with predictive internal models (<xref ref-type="bibr" rid="bib39">Kuchinsky et al., 2014</xref>; <xref ref-type="bibr" rid="bib101">Winn, 2023</xref>). The linear term from the GCA was further analyzed as a marker for the slope of pupillary change over time.</p><table-wrap id="table9" position="float"><label>Table 9.</label><caption><title>Fixed-effect estimates for the model of pupillary responses from 0 s to 5.8 s time-locked to the babble masker onset to examine the effect of signal-to-noise ratio (SNR) and age group (observations =96,612, groups: participant × SNR =332, participant =63).</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Fixed effect</th><th align="left" valign="bottom">Estimate</th><th align="left" valign="bottom">SE</th><th align="left" valign="bottom">95% CI</th><th align="left" valign="bottom">t</th><th align="left" valign="bottom">p</th></tr></thead><tbody><tr><td align="left" valign="bottom"> Intercept</td><td align="left" valign="bottom">7.26</td><td align="left" valign="bottom">1.26</td><td align="left" valign="bottom">[4.79, 9.73]</td><td align="left" valign="bottom">5.76</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom"> ot1</td><td align="left" valign="bottom">48.14</td><td align="left" valign="bottom">10.62</td><td align="left" valign="bottom">[27.33, 68.94]</td><td align="left" valign="bottom">4.53</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom"> ot2</td><td align="left" valign="bottom">–30.44</td><td align="left" valign="bottom">6.90</td><td align="left" valign="bottom">[-43.96,–16.92]</td><td align="left" valign="bottom">–4.41</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom"> SNR 0</td><td align="left" valign="bottom">–0.43</td><td align="left" valign="bottom">1.80</td><td align="left" valign="bottom">[–3.95, 3.09]</td><td align="left" valign="bottom">–0.24</td><td align="left" valign="bottom">0.811</td></tr><tr><td align="left" valign="bottom"> SNR 5</td><td align="left" valign="bottom">–3.45</td><td align="left" valign="bottom">1.80</td><td align="left" valign="bottom">[–6.98, 0.07]</td><td align="left" valign="bottom">–1.92</td><td align="left" valign="bottom">0.055</td></tr><tr><td align="left" valign="bottom"> SNR 10</td><td align="left" valign="bottom">–3.53</td><td align="left" valign="bottom">1.80</td><td align="left" valign="bottom">[−7.06,–0.01]</td><td align="left" valign="bottom">–1.96</td><td align="left" valign="bottom">0.049*</td></tr><tr><td align="left" valign="bottom"> SNR 15</td><td align="left" valign="bottom">–3.72</td><td align="left" valign="bottom">1.77</td><td align="left" valign="bottom">[−7.19,–0.25]</td><td align="left" valign="bottom">–2.10</td><td align="left" valign="bottom">0.035*</td></tr><tr><td align="left" valign="bottom"> SNR 20</td><td align="left" valign="bottom">–2.32</td><td align="left" valign="bottom">1.80</td><td align="left" valign="bottom">[–5.85, 1.20]</td><td align="left" valign="bottom">–1.29</td><td align="left" valign="bottom">0.197</td></tr><tr><td align="left" valign="bottom"> ot1 × SNR 0</td><td align="left" valign="bottom">44.77</td><td align="left" valign="bottom">14.58</td><td align="left" valign="bottom">[16.19, 73.34]</td><td align="left" valign="bottom">3.07</td><td align="left" valign="bottom">0.002*</td></tr><tr><td align="left" valign="bottom"> ot1 × SNR 5</td><td align="left" valign="bottom">7.21</td><td align="left" valign="bottom">14.59</td><td align="left" valign="bottom">[–21.39, 35.81]</td><td align="left" valign="bottom">0.49</td><td align="left" valign="bottom">0.621</td></tr><tr><td align="left" valign="bottom"> ot1 × SNR 10</td><td align="left" valign="bottom">–11.30</td><td align="left" valign="bottom">14.59</td><td align="left" valign="bottom">[–39.90, 17.30]</td><td align="left" valign="bottom">–0.77</td><td align="left" valign="bottom">0.439</td></tr><tr><td align="left" valign="bottom"> ot1 × SNR 15</td><td align="left" valign="bottom">–16.19</td><td align="left" valign="bottom">14.34</td><td align="left" valign="bottom">[–44.29, 11.92]</td><td align="left" valign="bottom">–1.13</td><td align="left" valign="bottom">0.259</td></tr><tr><td align="left" valign="bottom"> ot1 × SNR 20</td><td align="left" valign="bottom">–13.08</td><td align="left" valign="bottom">14.58</td><td align="left" valign="bottom">[–41.65, 15.50]</td><td align="left" valign="bottom">–0.90</td><td align="left" valign="bottom">0.370</td></tr><tr><td align="left" valign="bottom"> ot2 × SNR 0</td><td align="left" valign="bottom">44.88</td><td align="left" valign="bottom">9.26</td><td align="left" valign="bottom">[26.73, 63.02]</td><td align="left" valign="bottom">4.85</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom"> ot2 × SNR 5</td><td align="left" valign="bottom">61.77</td><td align="left" valign="bottom">9.27</td><td align="left" valign="bottom">[43.60, 79.94]</td><td align="left" valign="bottom">6.66</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom"> ot2 × SNR 10</td><td align="left" valign="bottom">26.06</td><td align="left" valign="bottom">9.27</td><td align="left" valign="bottom">[7.88, 44.23]</td><td align="left" valign="bottom">2.81</td><td align="left" valign="bottom">0.005*</td></tr><tr><td align="left" valign="bottom"> ot2 × SNR 15</td><td align="left" valign="bottom">14.74</td><td align="left" valign="bottom">9.11</td><td align="left" valign="bottom">[–3.11, 32.59]</td><td align="left" valign="bottom">1.62</td><td align="left" valign="bottom">0.105</td></tr><tr><td align="left" valign="bottom"> ot2 × SNR 20</td><td align="left" valign="bottom">20.07</td><td align="left" valign="bottom">9.26</td><td align="left" valign="bottom">[1.92, 38.22]</td><td align="left" valign="bottom">2.17</td><td align="left" valign="bottom">0.030*</td></tr><tr><td align="left" valign="bottom"> Group (MA vs. YA)</td><td align="left" valign="bottom">1.03</td><td align="left" valign="bottom">1.85</td><td align="left" valign="bottom">[–2.60, 4.65]</td><td align="left" valign="bottom">0.55</td><td align="left" valign="bottom">0.579</td></tr><tr><td align="left" valign="bottom"> Group × SNR 0</td><td align="left" valign="bottom">1.53</td><td align="left" valign="bottom">2.64</td><td align="left" valign="bottom">[–3.65, 6.70]</td><td align="left" valign="bottom">0.58</td><td align="left" valign="bottom">0.564</td></tr><tr><td align="left" valign="bottom"> Group × SNR 5</td><td align="left" valign="bottom">1.87</td><td align="left" valign="bottom">2.63</td><td align="left" valign="bottom">[–3.28, 7.02]</td><td align="left" valign="bottom">0.71</td><td align="left" valign="bottom">0.476</td></tr><tr><td align="left" valign="bottom"> Group × SNR 10</td><td align="left" valign="bottom">–4.82e–03</td><td align="left" valign="bottom">2.60</td><td align="left" valign="bottom">[–5.10, 5.10]</td><td align="left" valign="bottom">–1.85e–03</td><td align="left" valign="bottom">0.999</td></tr><tr><td align="left" valign="bottom"> Group × SNR 15</td><td align="left" valign="bottom">–1.26</td><td align="left" valign="bottom">2.62</td><td align="left" valign="bottom">[–6.39, 3.88]</td><td align="left" valign="bottom">–0.48</td><td align="left" valign="bottom">0.632</td></tr><tr><td align="left" valign="bottom"> Group × SNR 20</td><td align="left" valign="bottom">–1.26</td><td align="left" valign="bottom">2.64</td><td align="left" valign="bottom">[–6.44, 3.91]</td><td align="left" valign="bottom">–0.48</td><td align="left" valign="bottom">0.632</td></tr><tr><td align="left" valign="bottom"> ot1 × Group</td><td align="left" valign="bottom">–4.37</td><td align="left" valign="bottom">15.56</td><td align="left" valign="bottom">[–34.87, 26.14]</td><td align="left" valign="bottom">–0.28</td><td align="left" valign="bottom">0.779</td></tr><tr><td align="left" valign="bottom"> ot1 × Group × SNR 0</td><td align="left" valign="bottom">13.71</td><td align="left" valign="bottom">21.46</td><td align="left" valign="bottom">[–28.35, 55.77]</td><td align="left" valign="bottom">0.64</td><td align="left" valign="bottom">0.523</td></tr><tr><td align="left" valign="bottom"> ot1 × Group × SNR 5</td><td align="left" valign="bottom">32.89</td><td align="left" valign="bottom">21.35</td><td align="left" valign="bottom">[–8.94, 74.73]</td><td align="left" valign="bottom">1.54</td><td align="left" valign="bottom">0.123</td></tr><tr><td align="left" valign="bottom"> ot1 × Group × SNR 10</td><td align="left" valign="bottom">24.20</td><td align="left" valign="bottom">21.16</td><td align="left" valign="bottom">[–17.26, 65.66]</td><td align="left" valign="bottom">1.14</td><td align="left" valign="bottom">0.253</td></tr><tr><td align="left" valign="bottom"> ot1 × Group × SNR 15</td><td align="left" valign="bottom">15.46</td><td align="left" valign="bottom">21.28</td><td align="left" valign="bottom">[–26.25, 57.18]</td><td align="left" valign="bottom">0.73</td><td align="left" valign="bottom">0.468</td></tr><tr><td align="left" valign="bottom"> ot1 × Group × SNR 20</td><td align="left" valign="bottom">8.97</td><td align="left" valign="bottom">21.45</td><td align="left" valign="bottom">[–33.07, 51.00]</td><td align="left" valign="bottom">0.42</td><td align="left" valign="bottom">0.676</td></tr><tr><td align="left" valign="bottom"> ot2 × Group</td><td align="left" valign="bottom">–4.89</td><td align="left" valign="bottom">10.11</td><td align="left" valign="bottom">[–24.70, 14.92]</td><td align="left" valign="bottom">–0.48</td><td align="left" valign="bottom">0.628</td></tr><tr><td align="left" valign="bottom"> ot2 × Group × SNR 0</td><td align="left" valign="bottom">3.18</td><td align="left" valign="bottom">13.65</td><td align="left" valign="bottom">[–23.57, 29.93]</td><td align="left" valign="bottom">0.23</td><td align="left" valign="bottom">0.816</td></tr><tr><td align="left" valign="bottom"> ot2 × Group × SNR 5</td><td align="left" valign="bottom">–11.65</td><td align="left" valign="bottom">13.57</td><td align="left" valign="bottom">[–38.26, 14.96]</td><td align="left" valign="bottom">–0.86</td><td align="left" valign="bottom">0.391</td></tr><tr><td align="left" valign="bottom"> ot2 × Group × SNR 10</td><td align="left" valign="bottom">16.76</td><td align="left" valign="bottom">13.46</td><td align="left" valign="bottom">[–9.62, 43.13]</td><td align="left" valign="bottom">1.24</td><td align="left" valign="bottom">0.213</td></tr><tr><td align="left" valign="bottom"> ot2 × Group × SNR 15</td><td align="left" valign="bottom">14.82</td><td align="left" valign="bottom">13.53</td><td align="left" valign="bottom">[–11.70, 41.35]</td><td align="left" valign="bottom">1.10</td><td align="left" valign="bottom">0.273</td></tr><tr><td align="left" valign="bottom"> ot2 × Group × SNR 20</td><td align="left" valign="bottom">12.19</td><td align="left" valign="bottom">13.63</td><td align="left" valign="bottom">[–14.54, 38.91]</td><td align="left" valign="bottom">0.89</td><td align="left" valign="bottom">0.371</td></tr></tbody></table><table-wrap-foot><fn><p>Growth curve formula: <italic>lmer</italic>(<italic>Pupil ~ (ot1 + ot2)*Group*SNR + (0+ot1+ot2 | participant) + (ot1 +ot2 | participant:SNR), control = lmerControl(optimizer = ‘bobyqa’), REML = FALSE</italic>). Orthogonal polynomial terms: ot1=linear (slope); ot2=quadratic (curvature).</p></fn><fn><p>*<italic>p</italic>&lt;0.05; ***<italic>p</italic>&lt;0.001.</p></fn></table-wrap-foot></table-wrap><table-wrap id="table10" position="float"><label>Table 10.</label><caption><title>Fixed-effect estimates for model of pupillary responses from 0 s to 3 s time-locked to Quick Speech-in-Noise (QuickSIN) target sentence offset to examine the effect of signal-to-noise ratio (SNR) and age group (observations =63,184, groups: participant × SNR =359, participant =63).</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Fixed effect</th><th align="left" valign="bottom">Estimate</th><th align="left" valign="bottom">SE</th><th align="left" valign="bottom">95% CI</th><th align="left" valign="bottom">t</th><th align="left" valign="bottom">p</th></tr></thead><tbody><tr><td align="left" valign="bottom">Intercept</td><td align="left" valign="bottom">–0.36</td><td align="left" valign="bottom">0.81</td><td align="left" valign="bottom">[–1.95, 1.22]</td><td align="left" valign="bottom">–0.45</td><td align="left" valign="bottom">0.652</td></tr><tr><td align="left" valign="bottom">ot1</td><td align="left" valign="bottom">–10.33</td><td align="left" valign="bottom">6.06</td><td align="left" valign="bottom">[–22.20, 1.54]</td><td align="left" valign="bottom">–1.71</td><td align="left" valign="bottom">0.088</td></tr><tr><td align="left" valign="bottom">ot2</td><td align="left" valign="bottom">–2.24</td><td align="left" valign="bottom">3.12</td><td align="left" valign="bottom">[–8.35, 3.88]</td><td align="left" valign="bottom">–0.72</td><td align="left" valign="bottom">0.474</td></tr><tr><td align="left" valign="bottom">SNR 0</td><td align="left" valign="bottom">7.40</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">[5.45, 9.36]</td><td align="left" valign="bottom">7.43</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">SNR 5</td><td align="left" valign="bottom">6.93</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">[4.97, 8.88]</td><td align="left" valign="bottom">6.95</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">SNR 10</td><td align="left" valign="bottom">1.86</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">[–0.09, 3.82]</td><td align="left" valign="bottom">1.87</td><td align="left" valign="bottom">0.062</td></tr><tr><td align="left" valign="bottom">SNR 15</td><td align="left" valign="bottom">0.84</td><td align="left" valign="bottom">1.01</td><td align="left" valign="bottom">[–1.13, 2.81]</td><td align="left" valign="bottom">0.83</td><td align="left" valign="bottom">0.404</td></tr><tr><td align="left" valign="bottom">SNR 20</td><td align="left" valign="bottom">–0.55</td><td align="left" valign="bottom">1.00</td><td align="left" valign="bottom">[–2.50, 1.41]</td><td align="left" valign="bottom">–0.55</td><td align="left" valign="bottom">0.583</td></tr><tr><td align="left" valign="bottom">ot1 × SNR 0</td><td align="left" valign="bottom">60.92</td><td align="left" valign="bottom">7.15</td><td align="left" valign="bottom">[46.91, 74.92]</td><td align="left" valign="bottom">8.52</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">ot1 × SNR 5</td><td align="left" valign="bottom">45.16</td><td align="left" valign="bottom">7.15</td><td align="left" valign="bottom">[31.15, 59.16]</td><td align="left" valign="bottom">6.32</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">ot1 × SNR 10</td><td align="left" valign="bottom">20.10</td><td align="left" valign="bottom">7.15</td><td align="left" valign="bottom">[6.10, 34.11]</td><td align="left" valign="bottom">2.81</td><td align="left" valign="bottom">0.005*</td></tr><tr><td align="left" valign="bottom">ot1 × SNR 15</td><td align="left" valign="bottom">13.38</td><td align="left" valign="bottom">7.21</td><td align="left" valign="bottom">[–0.76, 27.51]</td><td align="left" valign="bottom">1.85</td><td align="left" valign="bottom">0.064</td></tr><tr><td align="left" valign="bottom">ot1 × SNR 20</td><td align="left" valign="bottom">12.27</td><td align="left" valign="bottom">7.15</td><td align="left" valign="bottom">[–1.74, 26.28]</td><td align="left" valign="bottom">1.72</td><td align="left" valign="bottom">0.086</td></tr><tr><td align="left" valign="bottom">ot2 × SNR 0</td><td align="left" valign="bottom">–3.41</td><td align="left" valign="bottom">4.19</td><td align="left" valign="bottom">[–11.62, 4.81]</td><td align="left" valign="bottom">–0.81</td><td align="left" valign="bottom">0.416</td></tr><tr><td align="left" valign="bottom">ot2 × SNR 5</td><td align="left" valign="bottom">–14.97</td><td align="left" valign="bottom">4.19</td><td align="left" valign="bottom">[-23.19,–6.75]</td><td align="left" valign="bottom">–3.57</td><td align="left" valign="bottom">&lt;0.001***</td></tr><tr><td align="left" valign="bottom">ot2 × SNR 10</td><td align="left" valign="bottom">6.43</td><td align="left" valign="bottom">4.19</td><td align="left" valign="bottom">[–1.78, 14.65]</td><td align="left" valign="bottom">1.53</td><td align="left" valign="bottom">0.125</td></tr><tr><td align="left" valign="bottom">ot2 × SNR 15</td><td align="left" valign="bottom">8.83</td><td align="left" valign="bottom">4.23</td><td align="left" valign="bottom">[0.54, 17.12]</td><td align="left" valign="bottom">2.09</td><td align="left" valign="bottom">0.037*</td></tr><tr><td align="left" valign="bottom">ot2 × SNR 20</td><td align="left" valign="bottom">7.83</td><td align="left" valign="bottom">4.19</td><td align="left" valign="bottom">[–0.39, 16.05]</td><td align="left" valign="bottom">1.87</td><td align="left" valign="bottom">0.062</td></tr><tr><td align="left" valign="bottom">Group (MA vs YA)</td><td align="left" valign="bottom">–0.30</td><td align="left" valign="bottom">1.16</td><td align="left" valign="bottom">[–2.57, 1.97]</td><td align="left" valign="bottom">–0.26</td><td align="left" valign="bottom">0.796</td></tr><tr><td align="left" valign="bottom">Group × SNR 0</td><td align="left" valign="bottom">1.64</td><td align="left" valign="bottom">1.44</td><td align="left" valign="bottom">[–1.18, 4.46]</td><td align="left" valign="bottom">1.14</td><td align="left" valign="bottom">0.254</td></tr><tr><td align="left" valign="bottom">Group × SNR 5</td><td align="left" valign="bottom">0.37</td><td align="left" valign="bottom">1.43</td><td align="left" valign="bottom">[–2.43, 3.16]</td><td align="left" valign="bottom">0.26</td><td align="left" valign="bottom">0.796</td></tr><tr><td align="left" valign="bottom">Group × SNR 10</td><td align="left" valign="bottom">3.16</td><td align="left" valign="bottom">1.43</td><td align="left" valign="bottom">[0.36, 5.97]</td><td align="left" valign="bottom">2.21</td><td align="left" valign="bottom">0.027*</td></tr><tr><td align="left" valign="bottom">Group × SNR 15</td><td align="left" valign="bottom">3.79</td><td align="left" valign="bottom">1.45</td><td align="left" valign="bottom">[0.95, 6.63]</td><td align="left" valign="bottom">2.62</td><td align="left" valign="bottom">0.009*</td></tr><tr><td align="left" valign="bottom">Group × SNR 20</td><td align="left" valign="bottom">2.63</td><td align="left" valign="bottom">1.45</td><td align="left" valign="bottom">[–0.22, 5.47]</td><td align="left" valign="bottom">1.81</td><td align="left" valign="bottom">0.071</td></tr><tr><td align="left" valign="bottom">ot1 × Group</td><td align="left" valign="bottom">3.28</td><td align="left" valign="bottom">8.67</td><td align="left" valign="bottom">[–13.72, 20.27]</td><td align="left" valign="bottom">0.38</td><td align="left" valign="bottom">0.706</td></tr><tr><td align="left" valign="bottom">ot1 × Group × SNR 0</td><td align="left" valign="bottom">–0.89</td><td align="left" valign="bottom">10.33</td><td align="left" valign="bottom">[–21.13, 19.36]</td><td align="left" valign="bottom">–0.09</td><td align="left" valign="bottom">0.932</td></tr><tr><td align="left" valign="bottom">ot1 × Group × SNR 5</td><td align="left" valign="bottom">4.05</td><td align="left" valign="bottom">10.23</td><td align="left" valign="bottom">[–15.99, 24.10]</td><td align="left" valign="bottom">0.40</td><td align="left" valign="bottom">0.692</td></tr><tr><td align="left" valign="bottom">ot1 × Group × SNR 10</td><td align="left" valign="bottom">25.33</td><td align="left" valign="bottom">10.26</td><td align="left" valign="bottom">[5.21, 45.44]</td><td align="left" valign="bottom">2.47</td><td align="left" valign="bottom">0.014*</td></tr><tr><td align="left" valign="bottom">ot1 × Group × SNR 15</td><td align="left" valign="bottom">14.01</td><td align="left" valign="bottom">10.40</td><td align="left" valign="bottom">[–6.37, 34.39]</td><td align="left" valign="bottom">1.35</td><td align="left" valign="bottom">0.178</td></tr><tr><td align="left" valign="bottom">ot1 × Group × SNR 20</td><td align="left" valign="bottom">6.24</td><td align="left" valign="bottom">10.43</td><td align="left" valign="bottom">[–14.20, 26.67]</td><td align="left" valign="bottom">0.60</td><td align="left" valign="bottom">0.550</td></tr><tr><td align="left" valign="bottom">ot2 × Group</td><td align="left" valign="bottom">5.50</td><td align="left" valign="bottom">4.48</td><td align="left" valign="bottom">[–3.29, 14.29]</td><td align="left" valign="bottom">1.23</td><td align="left" valign="bottom">0.220</td></tr><tr><td align="left" valign="bottom">ot2 × Group × SNR 0</td><td align="left" valign="bottom">–11.67</td><td align="left" valign="bottom">6.04</td><td align="left" valign="bottom">[–23.51, 0.18]</td><td align="left" valign="bottom">–1.93</td><td align="left" valign="bottom">0.053</td></tr><tr><td align="left" valign="bottom">ot2 × Group × SNR 5</td><td align="left" valign="bottom">3.62</td><td align="left" valign="bottom">5.99</td><td align="left" valign="bottom">[–8.11, 15.36]</td><td align="left" valign="bottom">0.61</td><td align="left" valign="bottom">0.545</td></tr><tr><td align="left" valign="bottom">ot2 × Group × SNR 10</td><td align="left" valign="bottom">–6.72</td><td align="left" valign="bottom">6.01</td><td align="left" valign="bottom">[–18.50, 5.06]</td><td align="left" valign="bottom">–1.12</td><td align="left" valign="bottom">0.264</td></tr><tr><td align="left" valign="bottom">ot2 × Group × SNR 15</td><td align="left" valign="bottom">–18.83</td><td align="left" valign="bottom">6.09</td><td align="left" valign="bottom">[-30.77,–6.90]</td><td align="left" valign="bottom">–3.09</td><td align="left" valign="bottom">0.002*</td></tr><tr><td align="left" valign="bottom">ot2 × Group × SNR 20</td><td align="left" valign="bottom">–17.10</td><td align="left" valign="bottom">6.10</td><td align="left" valign="bottom">[-29.06,–5.15]</td><td align="left" valign="bottom">–2.80</td><td align="left" valign="bottom">0.005*</td></tr></tbody></table><table-wrap-foot><fn><p>Growth curve formula: <italic>lmer(Pupil ~ (ot1 +ot2)*Group*SNR + (ot1 +ot2 | participant) + (ot1 + ot2 | participant:SNR), control = lmerControl(optimizer = 'bobyqa'), REML = FALSE</italic>). Orthogonal polynomial terms: ot1=linear (slope); ot2=quadratic (curvature).</p></fn><fn><p>*<italic>p</italic>&lt;0.05; ***<italic>p</italic>&lt;0.001.</p></fn></table-wrap-foot></table-wrap><p>Pupil-indexed listening effort measured during listening was modulated by task difficulty, with pupil diameters showing a larger increase at more challenging SNRs (<xref ref-type="fig" rid="fig3">Figure 3D</xref>). Both younger and middle-aged adults showed increases in pupil-indexed effort prior to overt decreases in behavioral performance (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). While MAs exhibited larger increases in listening effort compared to YAs, this change was not statistically significant (<xref ref-type="fig" rid="fig3">Figure 3E</xref>, <xref ref-type="table" rid="table9">Table 9</xref>). Trends seen in the pupillary responses for the listening window were further amplified in the integration window (<xref ref-type="fig" rid="fig3">Figure 3F</xref>). Pupillary slopes obtained from the GCA increased with task difficulty for both YA and MA. However, middle-aged adults showed a larger increase in listening effort than younger adults with decreasing SNRs, with significant age group listening effort differences at 10 dB SNR, even though behavioral performance was matched (<xref ref-type="fig" rid="fig3">Figure 3G</xref>, <xref ref-type="table" rid="table10">Table 10</xref>). These results suggest that middle-aged adults may maintain comparable performance to younger listeners at moderate task difficulty, but at the cost of recruiting listening effort.</p></sec><sec id="s2-3"><title>Pupil-indexed listening effort and CND provide synergistic contributions to speech-in-noise intelligibility</title><p>We sought to understand the relationships between CND, listening effort, and speech-in-noise intelligibility in normal-hearing, middle-aged adults. Behavioral performance in QuickSIN at 0 dB SNR, where there was a group effect of age, was significantly correlated with putative CND assessed using EFRs at 1024 Hz (<xref ref-type="fig" rid="fig4">Figure 4A</xref>). This suggests that peripheral deafferentation may manifest as overt behavioral deficits under the most challenging listening conditions. Pupil-indexed listening effort was also greater in the integration window in middle-aged adults at 10 dB SNR compared to younger adults (<xref ref-type="fig" rid="fig3">Figure 3G</xref>), even though behavioral performance was near-ceiling for both age groups. Pupillary slopes at 10 dB SNR in the integration window were correlated with behavioral deficits at 0 dB SNR (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). These results add to the growing evidence, suggesting that pupil-indexed listening effort to maintain behavioral performance at moderate task difficulties is predictive of behavioral performance at more challenging listening conditions (<xref ref-type="bibr" rid="bib51">McHaney et al., 2024</xref>). There were significant correlations between pupillary slopes in the listening window as well, even though there were no group-level differences with age (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). These data suggest that CND and increased listening effort are both associated with listening challenges in middle-aged adults.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Listening effort and cochlear neural degeneration (CND) provide complementary contributions to speech-in-noise intelligibility.</title><p>(<bold>A</bold>) Behavioral performance at the most challenging signal-to-noise ratio (SNR) was significantly correlated with the envelope following response (EFR) measures of CND, with lower EFR amplitudes being associated with poorer behavioral performance. (<bold>B</bold>) Pupillary responses at 10 dB SNR from the integration window were significantly correlated with behavioral performance at 0 dB SNR. (<bold>B</bold>) These correlations between pupillary responses at 10 dB SNR and behavioral performance at 0 dB SNR were also found in the listening window, even though there were no group differences in age, further strengthening the link between listening effort at moderate SNRs and behavioral performance at challenging SNRs. (<bold>D</bold>) An elastic net regression model with 10-fold cross-validation (cv) was fit to the Quick Speech-in-Noise (QuickSIN) scores at 0 dB SNR. The tuning parameter Lambda controls the extent to which coefficients contributing least to predictive accuracy are suppressed. (<bold>E</bold>) A lollipop plot displaying the coefficients (<italic>β</italic>) contributing to explaining variance on QuickSIN performance suggests that CND, listening effort, and subclinical changes in hearing thresholds all contribute to QuickSIN performance. (<bold>F</bold>) QuickSIN scores predicted by the elastic net regression are correlated with actual participant QuickSIN scores.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102823-fig4-v1.tif"/></fig><p>Is the increase in listening effort synergistic with CND? To understand the multifactorial contributions of sensory and top-down factors that may affect speech perception in noise, we performed a penalized regression with elastic net penalty (<xref ref-type="bibr" rid="bib108">Zou and Hastie, 2005</xref>). QuickSIN performance at 0 dB SNR (scaled to 0–100) was used as the outcome variable and all other measured variables were inserted as input variables. The elastic net penalized regression framework is a robust method that blends Lasso’s ability to perform variable selection and Ridge’s ability to handle multicollinearity and grouped covariates. The fitted elastic net regression model showed an R<sup>2</sup> value of 0.5981 and five significant predictors – hearing thresholds averaged across 500 Hz to 4 kHz (PTA4k), EFR amplitudes at 1024 Hz AM, pupillary slopes at 10 dB SNR and 0 dB SNR in the listening window, and pupillary slopes at 10 dB SNR in the integration window (<xref ref-type="fig" rid="fig4">Figure 4D and E</xref>). This model was significantly related to QuickSIN performance and predicted the observed QuickSIN scores across younger and middle-aged adults (r=0.64/(pseudo-)R<sup>2</sup>=0.41, <xref ref-type="fig" rid="fig4">Figure 4F</xref>). Hence, the output of the elastic net regression suggests that CND and pupil-indexed listening, in addition to subclinical changes in hearing thresholds, all provided complementary contributions to speech perception in noise.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Middle age, typically defined as the fifth and sixth decade of life, has been historically understudied compared to older age ranges (<xref ref-type="bibr" rid="bib16">Dohm-Hansen et al., 2024</xref>). Increasing evidence suggests that middle age is a critical period of rapid changes in brain function (<xref ref-type="bibr" rid="bib81">Schaum et al., 2020</xref>; <xref ref-type="bibr" rid="bib79">Salthouse, 2019</xref>). The resilience of the brain in keeping with degenerative processes that begin to occur in middle age predicts further age-related degeneration in later life and presents a critical opportunity for early intervention (<xref ref-type="bibr" rid="bib16">Dohm-Hansen et al., 2024</xref>; <xref ref-type="bibr" rid="bib18">Elliott et al., 2021a</xref>; <xref ref-type="bibr" rid="bib19">Elliott et al., 2021b</xref>; <xref ref-type="bibr" rid="bib31">Hughes et al., 2018</xref>). Hearing loss in middle age has recently been identified as the largest modifiable risk factor for dementia and Alzheimer’s disease later in life (<xref ref-type="bibr" rid="bib46">Livingston et al., 2017</xref>). However, the number of middle-aged patients who seek help for hearing difficulties but show no abnormal clinical indicators suggests the need for the development of sensitive biomarkers for hearing challenges experienced by this population (<xref ref-type="bibr" rid="bib28">Hind et al., 2011</xref>; <xref ref-type="bibr" rid="bib13">Cancel et al., 2023</xref>; <xref ref-type="bibr" rid="bib66">Parthasarathy et al., 2020</xref>; <xref ref-type="bibr" rid="bib88">Spehar and Lichtenhan, 2018</xref>).</p><p>Anatomical evidence from human temporal bones suggests a 40% deafferentation of cochlear synapses in middle-aged adults, even without substantial noise exposure history (<xref ref-type="bibr" rid="bib103">Wu et al., 2019</xref>; <xref ref-type="bibr" rid="bib105">Wu et al., 2023</xref>; <xref ref-type="bibr" rid="bib104">Wu et al., 2020</xref>). Peripheral deafferentation triggers compensatory mechanisms across sensory, language, and attentional systems (<xref ref-type="bibr" rid="bib2">Auerbach et al., 2019</xref>; <xref ref-type="bibr" rid="bib14">Chambers et al., 2016</xref>; <xref ref-type="bibr" rid="bib75">Resnik and Polley, 2021</xref>; <xref ref-type="bibr" rid="bib7">Bharadwaj et al., 2015</xref>). But our understanding of the perceptual consequences of cochlear deafferentation is limited by the lack of consensus on sensitive biomarkers for CND (<xref ref-type="bibr" rid="bib10">Bramhall et al., 2019</xref>). Recent studies have identified multiple promising biomarkers for CND in animal models and human populations (<xref ref-type="bibr" rid="bib9">Bharadwaj et al., 2022</xref>; <xref ref-type="bibr" rid="bib55">Mepani et al., 2021</xref>; <xref ref-type="bibr" rid="bib8">Bharadwaj et al., 2019</xref>). Reduced wave I amplitudes in the auditory brainstem response are a reliable marker of CND in animal models (<xref ref-type="bibr" rid="bib41">Kujawa and Liberman, 2009</xref>; <xref ref-type="bibr" rid="bib65">Parthasarathy and Kujawa, 2018</xref>; <xref ref-type="bibr" rid="bib82">Sergeyenko et al., 2013</xref>), but can be challenging to obtain in humans (<xref ref-type="bibr" rid="bib53">Mehraei et al., 2016</xref>; <xref ref-type="bibr" rid="bib8">Bharadwaj et al., 2019</xref>). The middle-ear muscle reflex, an acoustic measurement of middle-ear immittance driven by efferent feedback to the middle-ear muscles, has also been identified as a promising marker for CND (<xref ref-type="bibr" rid="bib96">Valero et al., 2018</xref>; <xref ref-type="bibr" rid="bib9">Bharadwaj et al., 2022</xref>; <xref ref-type="bibr" rid="bib95">Valero et al., 2016</xref>). Here, we used the EFR to identify CND in middle-aged adults with normal audiometric thresholds. As opposed to the middle-ear muscle reflex, EFRs measure peripheral neural coding and central auditory activity by exploiting the divergent phase-locking abilities of the ascending auditory pathway (<xref ref-type="bibr" rid="bib34">Joris et al., 2004</xref>; <xref ref-type="bibr" rid="bib61">Parida et al., 2024</xref>). EFRs with modulation rates greater than ~1000 Hz have been associated with CND and are considered to reflect the integrity of the auditory nerve (<xref ref-type="bibr" rid="bib65">Parthasarathy and Kujawa, 2018</xref>; <xref ref-type="bibr" rid="bib83">Shaheen et al., 2015</xref>), given that midbrain and cortical neurons cannot phase-lock to such high rates (<xref ref-type="bibr" rid="bib34">Joris et al., 2004</xref>). We observed decreases in EFRs at modulation rates that were selective to the auditory periphery (i.e. 1024 Hz) in middle-aged adults, while EFRs at slower modulation rates, likely generated from the central auditory structures, were not different from those in younger adults (<xref ref-type="fig" rid="fig1">Figure 1K</xref>). The use of a more rapid onset time in the stimulus modulation envelope, such as the rectangular amplitude modulated tones (RAM EFRs), may result in a larger separation of these groups, even at slower modulation rates (<xref ref-type="bibr" rid="bib97">Vasilkov et al., 2021</xref>; <xref ref-type="bibr" rid="bib21">Garrett et al., 2025</xref>), as sharper onset times result in greater EFR amplitudes (<xref ref-type="bibr" rid="bib55">Mepani et al., 2021</xref>; <xref ref-type="bibr" rid="bib62">Parthasarathy and Bartlett, 2011</xref>). However, a more intriguing possibility is that middle-aged adults exhibited an increase in relative central auditory activity, or ‘gain’, in the presence of decreased peripheral neural coding (<xref ref-type="bibr" rid="bib2">Auerbach et al., 2019</xref>; <xref ref-type="bibr" rid="bib75">Resnik and Polley, 2021</xref>). The perceptual consequences of this gain are unclear, but our findings align with emerging evidence, suggesting that gain is associated with selective deficits in speech-in-noise abilities (<xref ref-type="bibr" rid="bib75">Resnik and Polley, 2021</xref>; <xref ref-type="bibr" rid="bib17">Dougherty et al., 2021</xref>; <xref ref-type="bibr" rid="bib76">Rumschlag et al., 2022</xref>). EFRs at suprathreshold levels presented here also have contributions from higher-frequency regions due to a broader excitation at the cochlea (<xref ref-type="bibr" rid="bib64">Parthasarathy et al., 2016</xref>; <xref ref-type="bibr" rid="bib43">Lai and Bartlett, 2018</xref>). Since cochlear synapse loss is also believed to be flat across frequencies with age, EFRs used here likely index cochlear synapse loss equally across a broad range of frequencies (<xref ref-type="bibr" rid="bib103">Wu et al., 2019</xref>; <xref ref-type="bibr" rid="bib65">Parthasarathy and Kujawa, 2018</xref>; <xref ref-type="bibr" rid="bib82">Sergeyenko et al., 2013</xref>). This notion is further supported by emerging evidence that suggests that phase-locking measured to lower frequency pure tones also indexes cochlear synaptopathy in ways that are similar to using a faster modulation rate on a higher-frequency tone (<xref ref-type="bibr" rid="bib48">Märcher-Rørsted et al., 2022</xref>; <xref ref-type="bibr" rid="bib70">Ponsot et al., 2024</xref>).</p><p>The Mongolian gerbil provides a robust model for cross-species comparisons with aging humans, due to overlapping hearing frequency ranges and experimentally tractable lifespans. Here, using young and middle-aged gerbils, we showed similar EFR decreases as seen in human listeners (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). Additionally, age-related changes in the EFR were associated with confirmed CND (<xref ref-type="fig" rid="fig2">Figure 2F</xref>). CND in gerbils reached ~20% in the middle-aged 80-week group tested here, which is less than what has been observed in middle-aged humans, where CND estimates typically reach 40–50% by the fifth decade of life (<xref ref-type="bibr" rid="bib103">Wu et al., 2019</xref>). However, our EFRs were still sensitive to this degree of CND, reiterating that EFRs are a sensitive metric for measuring cochlear deafferentation. Additionally, we confirmed that the gerbils used in this study did not show any changes in hearing thresholds (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Hence, they were unlikely to have strial degenerations that are known to occur in older gerbils that affect auditory thresholds (<xref ref-type="bibr" rid="bib25">Gratton and Schulte, 1995</xref>). The synapse loss patterns and EFR amplitude changes seen here in gerbils were in agreement with earlier studies using alternate rodent models (<xref ref-type="bibr" rid="bib65">Parthasarathy and Kujawa, 2018</xref>; <xref ref-type="bibr" rid="bib83">Shaheen et al., 2015</xref>; <xref ref-type="bibr" rid="bib62">Parthasarathy and Bartlett, 2011</xref>), further confirming that age-related cochlear synapse loss is a pervasive mammalian phenomenon that can be captured using EFRs to rapid modulation frequencies (~1000 Hz).</p><p>Strong evidence links CND with altered neural coding of sounds in multiple ascending auditory stations (<xref ref-type="bibr" rid="bib65">Parthasarathy and Kujawa, 2018</xref>; <xref ref-type="bibr" rid="bib14">Chambers et al., 2016</xref>; <xref ref-type="bibr" rid="bib75">Resnik and Polley, 2021</xref>). However, the perceptual consequences of CND on speech-in-noise abilities remain unclear (<xref ref-type="bibr" rid="bib10">Bramhall et al., 2019</xref>). Evidence for overt behavioral deficits has been mixed and may depend on the specific type of task used for assessment (<xref ref-type="bibr" rid="bib23">Grant et al., 2020</xref>; <xref ref-type="bibr" rid="bib72">Prendergast et al., 2017b</xref>). Here, we used QuickSIN, a clinically-relevant test that we recently identified as being sensitive to changes in normal-hearing, adult populations with perceived hearing deficits (<xref ref-type="bibr" rid="bib13">Cancel et al., 2023</xref>). However, tests that are further challenging in spectrotemporal complexity, such as the addition of time compression or reverberation, may further tease apart these differences (<xref ref-type="bibr" rid="bib23">Grant et al., 2020</xref>; <xref ref-type="bibr" rid="bib55">Mepani et al., 2021</xref>). In the current study, behavioral deficits began to emerge only at the most challenging SNR levels (<xref ref-type="fig" rid="fig3">Figure 3</xref>). However, perceptual deficits in terms of listening effort began to appear prior to behavioral changes.</p><p>Listening effort is an umbrella term that may assess multiple forms of executive functions such as cognitive resource allocation, working memory, and attention, and can be assessed by measuring isoluminous task-related changes in pupil diameter (<xref ref-type="bibr" rid="bib67">Peelle, 2018</xref>; <xref ref-type="bibr" rid="bib5">Beatty, 1982</xref>; <xref ref-type="bibr" rid="bib99">Winn et al., 2015</xref>; <xref ref-type="bibr" rid="bib38">Kuchinsky et al., 2013</xref>; <xref ref-type="bibr" rid="bib11">Brown et al., 2006</xref>). The mechanisms underlying these pupillary changes are still under study (<xref ref-type="bibr" rid="bib49">McGinley et al., 2015</xref>; <xref ref-type="bibr" rid="bib15">de Gee et al., 2020</xref>), but are hypothesized to involve the locus coeruleus – norepinephrine system (<xref ref-type="bibr" rid="bib35">Joshi et al., 2016</xref>; <xref ref-type="bibr" rid="bib74">Reimer et al., 2016</xref>). Here, we observed that pupil-indexed listening effort increased in middle-aged adults, even when behavioral performance was matched with yonger adults (<xref ref-type="fig" rid="fig3">Figure 3E and F</xref>). This suggests that middle-aged adults expend more effort to maintain behavioral performance, which may lead to more listening fatigue or disengagement from conversations (<xref ref-type="bibr" rid="bib68">Pichora-Fuller et al., 2016</xref>; <xref ref-type="bibr" rid="bib30">Hornsby et al., 2016</xref>; <xref ref-type="bibr" rid="bib29">Hornsby, 2013</xref>). Potentially confounding factors impacting pupil measurement, such as the decrease of pupil dynamic range with aging (<xref ref-type="bibr" rid="bib89">Telek, 2018</xref>; <xref ref-type="bibr" rid="bib69">Piquado et al., 2010</xref>), participant fatigue, or task habituation (<xref ref-type="bibr" rid="bib50">McHaney et al., 2021</xref>; <xref ref-type="bibr" rid="bib11">Brown et al., 2006</xref>; <xref ref-type="bibr" rid="bib92">Tryon, 1975</xref>), can vary between individuals for a multitude of reasons (<xref ref-type="bibr" rid="bib1">Ansari et al., 2021</xref>). Here, the effects of these factors were minimized by applying trial-by-trial baseline corrections prior to analysis to match the magnitude of response between young and middle-aged adults.</p><p>Interestingly, pupil-indexed listening effort at a moderate SNR was a better predictor of behavioral performance at a more challenging SNR using two separate approaches – a Pearson’s correlation and the elastic net regression model (<xref ref-type="fig" rid="fig4">Figure 4B–D</xref>). We have previously demonstrated similar results in a different test group of young adult participants (<xref ref-type="bibr" rid="bib51">McHaney et al., 2024</xref>). These results suggest that the amount of effort required to maintain ceiling performance at moderate SNRs is predictive of behavioral performance at harder task difficulties. Pupillary indices at the harder task conditions may be rolling over into hyperexcitability (<xref ref-type="bibr" rid="bib49">McGinley et al., 2015</xref>; <xref ref-type="bibr" rid="bib15">de Gee et al., 2020</xref>) and, thus, being a poorer predictor of concomitant behavioral performance. Additionally, our elastic net regression model suggested that CND and listening effort provided complementary contributions to explaining variance on the QuickSIN task.</p><p>Even though both young and middle-aged adults had clinically normal-hearing thresholds, subtle changes within this normal range affected speech-in-noise performance (<xref ref-type="fig" rid="fig4">Figure 4D</xref>), lending support to studies suggesting that the definition of clinically ‘normal’ may need revision (<xref ref-type="bibr" rid="bib28">Hind et al., 2011</xref>; <xref ref-type="bibr" rid="bib32">Hunter et al., 2020</xref>). Our findings demonstrate a need for next-generation diagnostic measures of auditory processing that incorporate both neurophysiological encoding of the temporal elements of sound and cognitive factors associated with listening effort to better capture one’s listening abilities. Future studies will directly test the link between cochlear and peripheral neural deficits and listening effort and explore further contributions of other top-down mechanisms that may influence listening effort, such as selective attention or semantic load (<xref ref-type="bibr" rid="bib85">Shinn-Cunningham and Best, 2008</xref>; <xref ref-type="bibr" rid="bib52">McLaughlin et al., 2022</xref>).</p></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Humans</title><sec id="s4-1-1"><title>Participants</title><sec id="s4-1-1-1"><title>Recruitment</title><p>Young (<italic>n</italic>=38; 18–25 years of age, male = 10) and middle-aged (<italic>n</italic>=45; 40–55 years of age, male = 16) adult participants were recruited from the University of Pittsburgh Pitt+Me research participant registry, the University of Pittsburgh Department of Communication Science and Disorders research participant pool, and the broader community under a protocol approved by the University of Pittsburgh Institutional Review Board (IRB#21040125). Participants were compensated for their time, travel, and given an additional monetary incentive for completing all study sessions.</p></sec><sec id="s4-1-1-2"><title>Eligibility</title><p>Participant eligibility was determined during the first session of the study. Eligible participants had normal cognition determined by the MoCA≥25 (<xref ref-type="bibr" rid="bib59">Nasreddine et al., 2005</xref>), normal-hearing thresholds (≤25 dB HL 250–8000 Hz), no severe tinnitus as self-reported via the THI (<xref ref-type="bibr" rid="bib60">Newman et al., 1996</xref>), and LDLs&gt;80 dB HL at 0.5, 1, and 3 kHz (<xref ref-type="bibr" rid="bib84">Sherlock and Formby, 2005</xref>). Participants were not required to have specific complaints of speech perception in noise difficulties. The Beck Depression Inventory (<xref ref-type="bibr" rid="bib6">Beck et al., 1988</xref>) was administered, and participants were excluded if they reported thoughts of self-harm, determined by any response to survey item nine greater than 0. Participants self-reported American English fluency. Thirty-five young (18–25 years of age, male = 10) and 37 middle-aged participants (40–55 years of age, male = 10) met all eligibility criteria and were tested further using the battery described below.</p></sec></sec></sec><sec id="s4-2"><title>Audiological assessment</title><sec id="s4-2-1"><title>Otoscopy</title><p>An otoscopic examination was conducted using a Welch Allyn otoscope to examine the participant’s external auditory canal, tympanic membrane, and middle ear space for excess cerumen, ear drainage, and other abnormalities. The presence of any such abnormality resulted in exclusion from the study, as these may lead to a conductive hearing loss.</p></sec><sec id="s4-2-2"><title>Audiogram</title><p>Hearing thresholds were collected inside a sound-attenuating booth using a MADSEN Astera<sup>2</sup> audiometer, Otometrics transducers (Natus Medical, Inc Middleton, WI, USA), and foam insert eartips sized to the participants’ ear canal width. Tones were presented using a pulsed beat, and participants were instructed to press a response plunger if they believed that they perceived a tone being played, even if they were unsure. Extended high-frequency hearing thresholds were collected at frequencies 8, 12.5, and 16 kHz using Sennheiser circumaural headphones and Sennheiser HDA 300 transducers using the same response instructions.</p></sec><sec id="s4-2-3"><title>LDLs</title><p>LDLs were collected binaurally using the Otometrics transducer (Natus Medical, Inc, Middleton, WI, USA) and foam tip ear inserts. Warble tones were presented, and participants were instructed to rate the loudness on a scale of 1–7, with 7 being so loud that they would leave the room.</p></sec><sec id="s4-2-4"><title>DPOAEs</title><p>Outer hair cell function was assessed using DPOAEs. DPOAEs were collected from both the right and left ear individually, with a starting frequency of 500 Hz and an ending frequency of 16 kHz. The stimulus had an L1 of 75 dB SPL and an L2 of 65 dB SPL and was presented in 8 blocks of 24 sweeps in alternating polarities. Responses were collected using rubber ear inserts sized to participants’ ear canal width and an ER-10D DPOAE Probe transducer (Etymotic Research Inc, Elk Grove, IL, USA).</p></sec><sec id="s4-2-5"><title>Noise exposure history</title><p>Participants completed the NEQ (<xref ref-type="bibr" rid="bib33">Johnson et al., 2017</xref>) as a self-reported assay of annual noise exposure, accounting for both occupational and nonoccupational sources. Annual noise exposure was expressed using L<sub>Aeq8760h</sub>, representing the annual hourly duration of noise exposure presented in sound pressure level in dB. Calculation of the L<sub>Aeq8760h</sub> followed the original article (<xref ref-type="bibr" rid="bib33">Johnson et al., 2017</xref>).</p></sec><sec id="s4-2-6"><title>OSPAN</title><p>Participants also completed the automated version of the OSPAN task (<xref ref-type="bibr" rid="bib94">Unsworth et al., 2005</xref>), as a metric of working memory (<xref ref-type="bibr" rid="bib93">Turner and Engle, 1989</xref>). Participants were shown simple arithmetic problems and asked to decide whether presented solutions to the problems were correct or incorrect. A letter was displayed on the screen after each math problem. Following a series of arithmetic-letter presentations, participants were required to recall the letters that were displayed in the order that they appeared. The task consisted of 15 letter sequences that spanned three to seven letters (three repetitions of each span). If a participant correctly recalled all letters from a sequence, the span length was added to their score. The maximum possible score on the OSPAN task was 75.</p></sec></sec><sec id="s4-3"><title>Speech perception in noise</title><sec id="s4-3-1"><title>Sentence-level speech perception in noise</title><p>Speech perception in noise was indexed using moderate-predictability sentences masked in multitalker babble at six different SNRs from the QuickSIN test (<xref ref-type="bibr" rid="bib36">Killion et al., 2004</xref>). QuickSIN is a standardized measure of speech perception in noise that is commonly used in audiology clinics and is representative of a naturalistic listening environment (<xref ref-type="bibr" rid="bib56">Meyer et al., 2013</xref>). Each QuickSIN test list consisted of six sentences masked in four-talker babble at the following SNR levels: 25, 20, 15, 10, 5, and 0 dB. All participants completed four test lists. Participants listened to the sentences through Sennheiser circumaural headphones. The masker was presented at 60 dB SPL, and the sound level of the target sentences was varied to obtain the required SNR level. Participants were instructed to repeat the target sentence to the best of their ability. Each target sentence contained five keywords for identification. The number of keywords identified per sentence was recorded. Then, the proportion of keywords correctly identified for each SNR across all four test lists (20 total keywords per SNR) was calculated for each participant (<xref ref-type="bibr" rid="bib36">Killion et al., 2004</xref>; <xref ref-type="bibr" rid="bib98">Wilson et al., 2003</xref>). Additionally, we calculated the standard clinical QuickSIN score of dB SNR loss, which reflects the lowest SNR level that an individual can accurately identify words 50% of the time. For each participant, the dB SNR loss score was calculated for each test list separately using the following equation: <inline-formula><alternatives><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>25.5</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>∑</mml:mo><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>k</mml:mi><mml:mi>e</mml:mi><mml:mi>y</mml:mi><mml:mi>w</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>d</mml:mi><mml:mi>s</mml:mi><mml:mspace width="thinmathspace"/><mml:mi>i</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mo>∈</mml:mo><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="inft1">\begin{document}$25.5- \left (\sum of\,keywords\,identified\in list\right)$\end{document}</tex-math></alternatives></inline-formula> (<xref ref-type="bibr" rid="bib36">Killion et al., 2004</xref>). Then, the mean dB SNR loss across all four test lists was calculated and used for analysis.</p></sec></sec><sec id="s4-4"><title>Pupillometry</title><sec id="s4-4-1"><title>Acquisition</title><p>Pupillary responses were recorded while participants completed the QuickSIN task. Participants were seated facing a monitor in a testing room with consistent, moderate ambient lighting. Monocular left-eye pupillary responses were recorded at a 1000 Hz sampling rate using an EyeLink 1000 Plus Desktop Mount camera and chin rest (SR Research). Nine-point eye-tracker calibration was performed prior to the start of the experiment. To start each trial, participants were required to fixate on a cross in the center of the screen for a minimum of 500 ms. This fixation criterion was applied to control for the effects of saccades, which can alter pupil diameter, and to minimize pupil foreshortening errors (<xref ref-type="bibr" rid="bib107">Zekveld et al., 2013</xref>; <xref ref-type="bibr" rid="bib100">Winn et al., 2018</xref>; <xref ref-type="bibr" rid="bib37">Koelewijn et al., 2018</xref>). After meeting the 500 ms fixation criteria, a 100 ms 1000 Hz beep was presented to alert the participant to the start of the trial. There was a 2 s delay after the beep before the QuickSIN stimulus was presented. The background masker began 3 s before the target sentence and continued for 2 s after the target sentence. After the end of the background masker, there was a 2 s delay followed by a 100 ms 1000 Hz beep to signal the start of the verbal response period. Manual drift correction was performed at the end of each trial by the experimenter to ensure high-quality tracking of the pupil.</p></sec><sec id="s4-4-2"><title>Preprocessing</title><p>Pupillary data were processed in R (<xref ref-type="bibr" rid="bib73">R Core Team, 2022</xref>) using the <italic>eyelinker</italic> package (<xref ref-type="bibr" rid="bib3">Barthelme, 2024</xref>). Pupillary responses were analyzed in two windows of interest: (1) listening window, from multi-talker babble onset through 5800 ms, and (2) integration window, from target sentence offset to 1000 ms prior to behavioral response period. Separately for each window of interest, data were first processed to remove noise from blinks and saccades. Any trial with more than 15% of the samples detected as saccades or blinks was removed. For the remaining trials, blinks were linearly interpolated from 60 ms before to 160 ms after the detected blinks. Saccades were linearly interpolated from 60 ms before to 60 ms after any detected saccade. The de-blinked data were then downsampled to 50 Hz. Pupillary responses were baseline-corrected and normalized on a trial-by-trial basis to account for a downward drift in baseline that can occur across a task and for individual differences in pupil dynamic range (<xref ref-type="bibr" rid="bib100">Winn et al., 2018</xref>). Baseline pupil size was defined as the average pupil size in the 1000 ms period prior to the start of the window of interest (<inline-formula><alternatives><mml:math id="inf2"><mml:mfrac><mml:mrow><mml:mi>p</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mo>−</mml:mo><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>b</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mfrac></mml:math><tex-math id="inft2">\begin{document}$\frac{pupil- baseline}{baseline}$\end{document}</tex-math></alternatives></inline-formula> × 100). The pupillary response was then averaged across all four test lists for each SNR per participant in each window of interest. The outcome reported is percent change in pupil size from baseline.</p><p>GCAs (<xref ref-type="bibr" rid="bib57">Mirman, 2014</xref>) were used to obtain a measure of the slope of the pupillary response during QuickSIN. GCA uses orthogonal polynomial time terms to model distinct functional forms of the pupillary response over time. Two GCAs were fit using a second-order orthogonal polynomial to model the interaction of age group with SNR level, separately for the listening window and the integration window. This second-order model provides three parameters to explain the pupillary response. The first is the intercept, which refers to the overall change in the pupillary response over the time-window of interest. The second is the linear term (ot1), which represents the slope of the pupillary response over time, or the rate of dilation. The third is the quadratic term (ot2), representing the curvature of the pupil response, or the change in the rate of the pupillary response over time. GCAs were conducted in R (<xref ref-type="bibr" rid="bib73">R Core Team, 2022</xref>) using the <italic>lme4</italic> package (<xref ref-type="bibr" rid="bib4">Bates et al., 2015</xref>), and p-values were estimated using the <italic>lmerTest</italic> package (<xref ref-type="bibr" rid="bib42">Kuznetsova et al., 2017</xref>).</p><p>For the listening window, the best-fit GCA model included fixed effects of each time term (ot1, ot2), SNR (reference = 25), Group (reference = younger), and all two- and three-way interactions between SNR, Group, and time terms. The random effect structure consisted of a random slope of each time term per participant that removed the correlation between random effects, and a random slope of each time term per the interaction of participant and SNR level.<disp-formula id="equ1"><alternatives><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>S</mml:mi><mml:mi>N</mml:mi><mml:mi>R</mml:mi><mml:mo>∗</mml:mo><mml:mi>G</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>+</mml:mo><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>:</mml:mo><mml:mi>S</mml:mi><mml:mi>N</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="t1">\begin{document}$$\displaystyle Pupil\sim \left (ot1+ot2\right)\ast SNR\ast Group+\left (0+ot1+ot2|participant\right)+\left (ot1+ot2| participant\colon SNR\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p>For the integration window, the best-fit GCA model included fixed effects of each time term (ot1, ot2), SNR (reference = 25), Group (reference = younger), and all two- and three-way interactions between SNR, Group, and time terms. The random effect structure consisted of a random slope of each time term per participant, and a random slope of each time term per the interaction of participant and SNR level.<disp-formula id="equ2"><alternatives><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mi>i</mml:mi><mml:mi>l</mml:mi><mml:mo>∼</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>∗</mml:mo><mml:mi>S</mml:mi><mml:mi>N</mml:mi><mml:mi>R</mml:mi><mml:mo>∗</mml:mo><mml:mi>G</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>p</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>:</mml:mo><mml:mi>S</mml:mi><mml:mi>N</mml:mi><mml:mi>R</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math><tex-math id="t2">\begin{document}$$\displaystyle Pupil\sim \left (ot1+ot2\right)\ast SNR\ast Group+\left (ot1+ot2|participant\right)+\left (ot1+ot2| participant\colon SNR\right)$$\end{document}</tex-math></alternatives></disp-formula></p></sec></sec><sec id="s4-5"><title>Electrophysiology</title><sec id="s4-5-1"><title>EFRs</title><p>EFRs were collected in a sound-attenuating booth using a BioSemi ActiveTwo EEG system while participants were seated in a recliner. Stimuli were presented using ER-3C transducers (Etymotic Research Inc, Elk Grove, IL, USA) with gold-foil tiptrodes placed in the ear canals to deliver sound stimuli and record additional channels of evoked potentials. EFRs were recorded to a 250 ms tone with a carrier frequency of 3000 Hz, amplitude modulated (AM) at 40, 110, 512, and 1024 Hz. Stimuli were presented in alternating polarity, with 500 repetitions, each at 85 dB SPL to the right ear. Each token was presented at 3.1 repetitions/s, for a period of 322 ms.</p></sec><sec id="s4-5-2"><title>Preprocessing</title><p>EFRs from the Fz to the ipsilateral (right) tiptrode were processed and analyzed using MATLAB v. 2022a (Mathworks Inc, Natick, MA, USA). EFRs were processed using a fourth-order Butterworth filter with a low-pass filter of 3000 Hz. The high-pass filter cutoffs used were 5 Hz, 80 Hz, 200 Hz, and 300 Hz for 40 Hz, 110 Hz, 512 Hz, and 1024 Hz AM stimuli, respectively. Fast Fourier transforms (FFTs) were performed on the averaged time domain waveforms for each participant at each AM rate, starting 10 ms after stimulus onset to exclude auditory brain stem responses (ABRs) and ending 10 ms after stimulus offset. The maximum amplitude of the FFT peak at one of three adjacent bins (~3 Hz) around the modulation frequency of the AM rate was reported as the EFR amplitude.</p></sec></sec><sec id="s4-6"><title>Animals</title><sec id="s4-6-1"><title>Subjects</title><p>Fourteen young adult Mongolian gerbils aged 18–27 weeks (male = 9) and thirteen middle-aged Mongolian gerbils aged 75–82 weeks (male = 6) were used in this study. All animals are born and raised in our animal care facility and sourced from Charles River breeders. The acoustic environment within the holding facility was characterized by noise-level data logging and was periodically monitored. Data logging revealed an average noise level of 56 dB, with transients not exceeding 74 dB during regular housing conditions, and 88 dB once a week during cage changes. All animal procedures were approved by the Institutional Animal Care and Use Committee of the University of Pittsburgh (Protocol #21046600).</p></sec><sec id="s4-6-2"><title>Experimental setup</title><p>Experiments were performed in a double-walled acoustic chamber. Animals were placed on a water-circulated warming blanket set to 37°C with the pump placed outside the recording chamber to eliminate audio and electrical interferences. Gerbils were initially anesthetized with isoflurane gas anesthesia (4%) in an induction chamber. The animals were transferred post-induction to a manifold and maintained at 1–1.5% isoflurane. Subdermal electrodes (Ambu) were then placed on the animals’ scalps for the recordings. A positive electrode was placed along the vertex. The negative electrode was placed under the ipsilateral ear along the mastoid, while the ground electrode was placed in the base of the tail. Impedances from the electrodes were always less than 1 kHz, as tested using the head-stage (RA4LI, Tucker Davis Technologies [TDT]). The average duration of isoflurane anesthesia during the electrode setup process was approximately 10 min. After placing electrodes, animals were injected with dexmedetomidine (Dexdomitor, 0.3 mg/kg subdermal) and taken off of the isoflurane. Dexmedetomidine is an alpha-adrenergic agonist that acts as a sedative and an analgesic and is known to decrease motivation, but preserve behavioral and neural responses in rodents (<xref ref-type="bibr" rid="bib77">Ruotsalainen et al., 1997</xref>; <xref ref-type="bibr" rid="bib90">Ter-Mikaelian et al., 2013</xref>). This helps to maintain animals in an un-anesthetized state where they still respond to pain stimuli, such as a foot pinch, but are otherwise compliant to recordings for a period of about 3 hours. The time window for the effects of isoflurane to wear off was determined empirically as 9 min, based on ABRs’ waveforms and latencies, as well as the response to foot pinch stimuli. Recordings then commenced 15 min after cessation of isoflurane.</p></sec><sec id="s4-6-3"><title>Stimulus presentation, acquisition, and analysis</title><p>Stimuli were presented to the right ear of the animal using insert earphones (ER3C, Etymotic), which matched the stimulus presentation in humans. Stimuli presentation and acquisition were done for gerbils via LabView. The output from the insert earphones was calibrated using a Bruel Kjaer microphone and was found to be within ±6 dB for the frequency range tested. Digitized waveforms were recorded with a multichannel recording and stimulation system (RZ-6, TDT) and analyzed in MATLAB (MathWorks).</p><p>Hearing thresholds were obtained using ABRs presented to 5 ms long tone stimuli, with a 2.5 ms on- and off- ramp, at 27.1 repetitions per second. ABRs were filtered from 300 Hz to 30,000 Hz, and thresholds were determined as the minimum sound level that produced a response, as assessed using visual inspection by two blinded, trained observers.</p><p>EFRs were elicited to sinusoidally AM tones (5 ms rise/fall, 250 ms duration, 3.1 repetitions/s, alternating polarity) at a 3 kHz carrier frequency presented 30 dB above auditory thresholds obtained using ABRs at 3 kHz. The modulation frequency was systematically varied from 16 Hz to 1024 Hz AM. Responses were amplified (×10,000; TDT Medusa 4z amplifier) and filtered (0.1–3 kHz). Trials in which the response amplitude exceeded 200 μV were rejected. 250 artifact-free trials of each polarity were averaged to compute the EFR waveform. FFTs were performed on the averaged time-domain waveforms starting 10 ms after stimulus onset to exclude ABRs and ending at stimulus offset using MATLAB (MathWorks). The maximum amplitude of the FFT peak at one of three frequency bins (~3 Hz each) around the modulation frequency was recorded as the peak FFT amplitude. The FFT amplitude at the AM frequency was reported as the EFR amplitude. The noise floor of the EFR was calculated as the average of five frequency bins (~3 Hz each) above and below the central three bins. A response was deemed significantly above the noise floor if the FFT amplitude was at least 6 dB greater than the noise floor.</p></sec><sec id="s4-6-4"><title>Immunohistology</title><p>Animals were transcardially perfused using a 4% paraformaldehyde solution (Sigma-Aldrich, 441244) for approximately 5 min before decapitation and isolation of the right and left cochlea. Following intra-labyrinthine perfusion with 4% paraformaldehyde, cochleas were stored in paraformaldehyde for 1 hr. Cochleae were decalcified in EDTA (Fisher Scientific, BP120500) for 3–5 days, followed by cryoprotection with sucrose (Fisher Scientific, D16500) and flash-freezing. All chemicals were of reagent grade. Cochleae were thawed prior to dissection, then dissected in PBS solution. Immunostaining was accomplished by incubation with the following primary antibodies: (1) mouse anti-CtBP2 (BD Biosciences) at 1:200, (2) mouse anti-GluA2 (Millipore) at 1:2000, (3) rabbit anti-myosin VIIa (Proteus Biosciences) at 1:200, followed by incubation with secondary antibodies coupled to Alexa Fluor in the red, green, and blue channels. Piece lengths were measured and converted to cochlear frequency using established cochlear maps (<xref ref-type="bibr" rid="bib26">Greenwood, 1990</xref>) in ImageJ. Cochlear stacks were obtained at the target frequency (3 kHz) spanning the cuticular plate to the synaptic pole of ∼10 hair cells (in 0.25 μm z-steps). Images were collected in a 1024×1024 raster using a high-resolution, oil-immersion objective (×60) and 1.59× digital zoom using a Nikon A1 confocal microscope. Images were denoised in NIS elements and loaded into an image-processing software platform (Imaris; Oxford Instruments), where inner hair cells were quantified based on their Myosin VIIa-stained cell bodies and CtBP2-stained nuclei. Presynaptic ribbons and postsynaptic glutamate receptor patches were counted using 3D representations of each confocal z-stack. Juxtaposed ribbons and receptor puncta constitute a synapse, and these synaptic associations were determined using IMARIS workflows that calculated and displayed the x-y projection of the voxel space (<xref ref-type="bibr" rid="bib65">Parthasarathy and Kujawa, 2018</xref>; <xref ref-type="bibr" rid="bib44">Liberman et al., 2011</xref>).</p></sec></sec><sec id="s4-7"><title>Statistical analysis</title><sec id="s4-7-1"><title>Analysis of variance</title><p>Normality of all variables was first checked visually using Q-Q plots and statistically using the Shapiro-Wilk test with alpha = 0.05. Homogeneity of variance was assessed using Levene’s test. <italic>N</italic>-way analyses of variance (ANOVAs) were completed using R 2022.07.1 for each measure to determine statistically significant differences between groups (<xref ref-type="bibr" rid="bib22">Girden, 1992</xref>). The function employed, <italic>aov</italic>, uses treatment contrasts in which the first baseline level is compared to each of the following levels. The number of factors was determined based on the conditions tested in each measure. Bonferroni corrections were used to control familywise error rate due to multiple comparisons.</p></sec><sec id="s4-7-2"><title>Correlations</title><p>Outliers were detected using Tukey’s Fence with a boundary distance of k=1.5 and removed. Correlations were computed using Pearson’s correlations. Degrees of freedom, <italic>r</italic>, and p<italic>-</italic>values were reported.</p></sec><sec id="s4-7-3"><title>Elastic net regression</title><p>We used a linear model with elastic net penalization/regularization (<xref ref-type="bibr" rid="bib108">Zou and Hastie, 2005</xref>) to simultaneously estimate the underlying contributions of the various predictor variables measured in our studies and perform model selection. This approach has been previously validated for model selection using multidimensional data related to hearing pathologies like tinnitus and hyperacusis (<xref ref-type="bibr" rid="bib87">Smith et al., 2024</xref>). The relative strength of selection and shrinkage is controlled by the hyper-parameters <inline-formula><alternatives><mml:math id="inf3"><mml:mi>λ</mml:mi></mml:math><tex-math id="inft3">\begin{document}$\lambda $\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf4"><mml:mi>α</mml:mi></mml:math><tex-math id="inft4">\begin{document}$\alpha $\end{document}</tex-math></alternatives></inline-formula>: a higher <inline-formula><alternatives><mml:math id="inf5"><mml:mi>λ</mml:mi></mml:math><tex-math id="inft5">\begin{document}$\lambda $\end{document}</tex-math></alternatives></inline-formula> implies more stringent penalization pushing toward the null model, and <inline-formula><alternatives><mml:math id="inf6"><mml:mn>0</mml:mn><mml:mo>≤</mml:mo><mml:mi>α</mml:mi><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:math><tex-math id="inft6">\begin{document}$0\leq \alpha \leq 1$\end{document}</tex-math></alternatives></inline-formula> controls the degree of convexity and hence the amount of sparsity, with <inline-formula><alternatives><mml:math id="inf7"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math><tex-math id="inft7">\begin{document}$\alpha =0$\end{document}</tex-math></alternatives></inline-formula> implying a Ridge regression with no variable selection. Elastic net is a regularized regression method that minimizes the negative log-likelihood with a penalty on the parameters that combines the <inline-formula><alternatives><mml:math id="inf8"><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft8">\begin{document}$l_{1}$\end{document}</tex-math></alternatives></inline-formula> (LASSO) and <inline-formula><alternatives><mml:math id="inf9"><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft9">\begin{document}$l_{2}$\end{document}</tex-math></alternatives></inline-formula> (Ridge) penalty, i.e., the elastic net penalty on the regression parameters <inline-formula><alternatives><mml:math id="inf10"><mml:mi>β</mml:mi></mml:math><tex-math id="inft10">\begin{document}$\beta $\end{document}</tex-math></alternatives></inline-formula> can be written as <inline-formula><alternatives><mml:math id="inf11"><mml:mi>P</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mi>λ</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi>α</mml:mi><mml:msub><mml:mrow><mml:mfenced open="‖" close="‖" separators="|"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfenced separators="|"><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mi>α</mml:mi></mml:mrow></mml:mfenced><mml:mtext>/</mml:mtext><mml:mn>2</mml:mn><mml:msubsup><mml:mrow><mml:mfenced open="‖" close="‖" separators="|"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfenced></mml:math><tex-math id="inft11">\begin{document}$Pen\left (\beta \right)=\lambda \left (\alpha \left \| \beta \right \| _{1}+\left (1- \alpha \right)\text{/}2\left \| \beta \right \| _{2}^{2}\right)$\end{document}</tex-math></alternatives></inline-formula>. Elastic net regularization has several advantages over both LASSO and Ridge, as well as a simple linear model. The <inline-formula><alternatives><mml:math id="inf12"><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft12">\begin{document}$l_{1}$\end{document}</tex-math></alternatives></inline-formula> part of the elastic net (<inline-formula><alternatives><mml:math id="inf13"><mml:msub><mml:mrow><mml:mfenced open="‖" close="‖" separators="|"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft13">\begin{document}$\left \| \beta \right \| _{1}$\end{document}</tex-math></alternatives></inline-formula>) leads to a sparse model where some of the coefficients are shrunk to exact zeroes, thereby performing an automatic model selection without the combinatorial computational complexities of a best-subset selection approach. Further, the quadratic <inline-formula><alternatives><mml:math id="inf14"><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math><tex-math id="inft14">\begin{document}$l_{2}$\end{document}</tex-math></alternatives></inline-formula> part (<inline-formula><alternatives><mml:math id="inf15"><mml:msubsup><mml:mrow><mml:mfenced open="‖" close="‖" separators="|"><mml:mrow><mml:mi>β</mml:mi></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><tex-math id="inft15">\begin{document}$\left \| \beta \right \| _{2}^{2}$\end{document}</tex-math></alternatives></inline-formula>) encourages grouped variable selection and removes the limitation of the number of selected variables, unlike LASSO, while stabilizing the selection path. To choose the tuning parameters <inline-formula><alternatives><mml:math id="inf16"><mml:mi>λ</mml:mi></mml:math><tex-math id="inft16">\begin{document}$\lambda $\end{document}</tex-math></alternatives></inline-formula> and <inline-formula><alternatives><mml:math id="inf17"><mml:mi>α</mml:mi></mml:math><tex-math id="inft17">\begin{document}$\alpha $\end{document}</tex-math></alternatives></inline-formula>, we used a 10-fold cross-validation that minimizes the out-of-sample root mean-squared error. We used the R packages <italic>glmnet</italic> (<xref ref-type="bibr" rid="bib20">Friedman et al., 2010</xref>) and <italic>caret</italic> (<xref ref-type="bibr" rid="bib40">Kuhn, 2008</xref>) for training the elastic net regularizer.</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Data curation, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Data curation, Formal analysis, Supervision, Investigation, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Data curation, Formal analysis, Supervision, Investigation, Visualization, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Data curation, Investigation</p></fn><fn fn-type="con" id="con5"><p>Data curation, Investigation</p></fn><fn fn-type="con" id="con6"><p>Data curation, Investigation</p></fn><fn fn-type="con" id="con7"><p>Data curation, Formal analysis, Investigation, Project administration</p></fn><fn fn-type="con" id="con8"><p>Data curation, Formal analysis, Investigation</p></fn><fn fn-type="con" id="con9"><p>Data curation, Formal analysis, Visualization, Methodology</p></fn><fn fn-type="con" id="con10"><p>Supervision, Funding acquisition, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con11"><p>Conceptualization, Supervision, Funding acquisition, Investigation, Visualization, Methodology, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Informed consent and consent to publish were obtained from participants. Participants were recruited and tested under a protocol approved by the University of Pittsburgh Institutional Review Board (IRB#21040125). Participants were compensated for their time, travel, and given an additional monetary incentive for completing all study sessions.</p></fn><fn fn-type="other"><p>This study was performed in strict accordance with the recommendations in the Guide for the Care and Use of Laboratory Animals of the National Institutes of Health. All animal procedures were approved by the Institutional Animal Care and Use Committee of the University of Pittsburgh (Protocol #21046600).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-102823-mdarchecklist1-v1.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All data reported and analyzed in this study can be found on the Open Science Framework at <ext-link ext-link-type="uri" xlink:href="http://doi.org/10.17605/OSF.IO/4BGDA">http://doi.org/10.17605/OSF.IO/4BGDA</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>McHaney</surname><given-names>JR</given-names></name><name><surname>Zink</surname><given-names>M</given-names></name><name><surname>Zhen</surname><given-names>L</given-names></name><name><surname>Klara</surname><given-names>J</given-names></name><name><surname>Yurasits</surname><given-names>K</given-names></name><name><surname>Cancel</surname><given-names>V</given-names></name><name><surname>Flemm</surname><given-names>O</given-names></name><name><surname>Mitchell</surname><given-names>C</given-names></name><name><surname>Datta</surname><given-names>J</given-names></name><name><surname>Chandrasekaran</surname><given-names>B</given-names></name><name><surname>Parthasarathy</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Increased listening effort and cochlear neural degeneration underlie behavioral deficits in speech perception in normal hearing middle-aged adults</data-title><source>Open Science Framework</source><pub-id pub-id-type="doi">10.17605/OSF.IO/4BGDA</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported by the National Institute on Deafness and Other Communication Disorders-National Institutes of Health Grants R21DC018882 to AP, T32DC011499 to K Kandler and B Yates (Trainee: MEZ) and F31DC020085 to JRM, and the PNC-Trees Charitable Trust (PNC to BC and AP). We thank Dr. Carl Snyderman for collaboration on the PNC-Trees grant, and Megan Hallihan, Kathryn Bergstrom, Sarah Anthony, and Shaina Wasileski for their assistance with participant recruitment and data collection. Thanks also to Dr. Simon Warkins, Katherine Helfrich, and Mike Calderon at the Center for Biological Imaging at the University of Pittsburgh, supported by NIH grant 1S10RR028478-01 for collaboration on confocal imaging, and the Clinical and Translational Science Institute at the University of Pittsburgh, supported by the NIH Clinical and Translational Science Award (CTSA) program, grant UL1 TR001857 for assistance with participant recruitment.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ansari</surname><given-names>AS</given-names></name><name><surname>Vehof</surname><given-names>J</given-names></name><name><surname>Hammond</surname><given-names>CJ</given-names></name><name><surname>Bremner</surname><given-names>FD</given-names></name><name><surname>Williams</surname><given-names>KM</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Evidence that pupil size and reactivity are determined more by your parents than by your environment</article-title><source>Frontiers in Neurology</source><volume>12</volume><elocation-id>651755</elocation-id><pub-id pub-id-type="doi">10.3389/fneur.2021.651755</pub-id><pub-id pub-id-type="pmid">34012416</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Auerbach</surname><given-names>BD</given-names></name><name><surname>Radziwon</surname><given-names>K</given-names></name><name><surname>Salvi</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Testing the central gain model: Loudness growth correlates with central auditory gain enhancement in a rodent model of hyperacusis</article-title><source>Neuroscience</source><volume>407</volume><fpage>93</fpage><lpage>107</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2018.09.036</pub-id><pub-id pub-id-type="pmid">30292765</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Barthelme</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>A-hurst/eyelinker: an r package for importing data from eyelink ASC files</data-title><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/a-hurst/eyelinker">https://github.com/a-hurst/eyelinker</ext-link></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bates</surname><given-names>D</given-names></name><name><surname>Mächler</surname><given-names>M</given-names></name><name><surname>Bolker</surname><given-names>B</given-names></name><name><surname>Walker</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Fitting linear mixed-effects models using lme4</article-title><source>Journal of Statistical Software</source><volume>67</volume><fpage>1</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.18637/jss.v067.i01</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beatty</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Phasic not tonic pupillary responses vary with auditory vigilance performance</article-title><source>Psychophysiology</source><volume>19</volume><fpage>167</fpage><lpage>172</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.1982.tb02540.x</pub-id><pub-id pub-id-type="pmid">7071295</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Beck</surname><given-names>AT</given-names></name><name><surname>Steer</surname><given-names>RA</given-names></name><name><surname>Carbin</surname><given-names>MG</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Psychometric properties of the Beck Depression Inventory: Twenty-five years of evaluation</article-title><source>Clinical Psychology Review</source><volume>8</volume><fpage>77</fpage><lpage>100</lpage><pub-id pub-id-type="doi">10.1016/0272-7358(88)90050-5</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bharadwaj</surname><given-names>HM</given-names></name><name><surname>Masud</surname><given-names>S</given-names></name><name><surname>Mehraei</surname><given-names>G</given-names></name><name><surname>Verhulst</surname><given-names>S</given-names></name><name><surname>Shinn-Cunningham</surname><given-names>BG</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Individual differences reveal correlates of hidden hearing deficits</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>2161</fpage><lpage>2172</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3915-14.2015</pub-id><pub-id pub-id-type="pmid">25653371</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bharadwaj</surname><given-names>HM</given-names></name><name><surname>Mai</surname><given-names>AR</given-names></name><name><surname>Simpson</surname><given-names>JM</given-names></name><name><surname>Choi</surname><given-names>I</given-names></name><name><surname>Heinz</surname><given-names>MG</given-names></name><name><surname>Shinn-Cunningham</surname><given-names>BG</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Non-invasive assays of cochlear synaptopathy - Candidates and considerations</article-title><source>Neuroscience</source><volume>407</volume><fpage>53</fpage><lpage>66</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2019.02.031</pub-id><pub-id pub-id-type="pmid">30853540</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bharadwaj</surname><given-names>HM</given-names></name><name><surname>Hustedt-Mai</surname><given-names>AR</given-names></name><name><surname>Ginsberg</surname><given-names>HM</given-names></name><name><surname>Dougherty</surname><given-names>KM</given-names></name><name><surname>Muthaiah</surname><given-names>VPK</given-names></name><name><surname>Hagedorn</surname><given-names>A</given-names></name><name><surname>Simpson</surname><given-names>JM</given-names></name><name><surname>Heinz</surname><given-names>MG</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Cross-species experiments reveal widespread cochlear neural damage in normal hearing</article-title><source>Communications Biology</source><volume>5</volume><elocation-id>733</elocation-id><pub-id pub-id-type="doi">10.1038/s42003-022-03691-4</pub-id><pub-id pub-id-type="pmid">35869142</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bramhall</surname><given-names>N</given-names></name><name><surname>Beach</surname><given-names>EF</given-names></name><name><surname>Epp</surname><given-names>B</given-names></name><name><surname>Le Prell</surname><given-names>CG</given-names></name><name><surname>Lopez-Poveda</surname><given-names>EA</given-names></name><name><surname>Plack</surname><given-names>CJ</given-names></name><name><surname>Schaette</surname><given-names>R</given-names></name><name><surname>Verhulst</surname><given-names>S</given-names></name><name><surname>Canlon</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The search for noise-induced cochlear synaptopathy in humans: Mission impossible?</article-title><source>Hearing Research</source><volume>377</volume><fpage>88</fpage><lpage>103</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2019.02.016</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>VA</given-names></name><name><surname>McLaughlin</surname><given-names>DJ</given-names></name><name><surname>Strand</surname><given-names>JF</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Rapid adaptation to fully intelligible nonnative-accented speech reduces listening effort</article-title><source>The Quarterly Journal of Experimental Psychology</source><volume>73</volume><fpage>1431</fpage><lpage>1443</lpage><pub-id pub-id-type="doi">10.1177/1747021820916726</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buran</surname><given-names>BN</given-names></name><name><surname>McMillan</surname><given-names>GP</given-names></name><name><surname>Keshishzadeh</surname><given-names>S</given-names></name><name><surname>Verhulst</surname><given-names>S</given-names></name><name><surname>Bramhall</surname><given-names>NF</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Predicting synapse counts in living humans by combining computational models with auditory physiology</article-title><source>The Journal of the Acoustical Society of America</source><volume>151</volume><elocation-id>561</elocation-id><pub-id pub-id-type="doi">10.1121/10.0009238</pub-id><pub-id pub-id-type="pmid">35105019</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cancel</surname><given-names>VE</given-names></name><name><surname>McHaney</surname><given-names>JR</given-names></name><name><surname>Milne</surname><given-names>V</given-names></name><name><surname>Palmer</surname><given-names>C</given-names></name><name><surname>Parthasarathy</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>A data-driven approach to identify a rapid screener for auditory processing disorder testing referrals in adults</article-title><source>Scientific Reports</source><volume>13</volume><elocation-id>13636</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-023-40645-0</pub-id><pub-id pub-id-type="pmid">37604867</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chambers</surname><given-names>AR</given-names></name><name><surname>Resnik</surname><given-names>J</given-names></name><name><surname>Yuan</surname><given-names>Y</given-names></name><name><surname>Whitton</surname><given-names>JP</given-names></name><name><surname>Edge</surname><given-names>AS</given-names></name><name><surname>Liberman</surname><given-names>MC</given-names></name><name><surname>Polley</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Central gain restores auditory processing following near-complete cochlear denervation</article-title><source>Neuron</source><volume>89</volume><fpage>867</fpage><lpage>879</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.12.041</pub-id><pub-id pub-id-type="pmid">26833137</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Gee</surname><given-names>JW</given-names></name><name><surname>Tsetsos</surname><given-names>K</given-names></name><name><surname>Schwabe</surname><given-names>L</given-names></name><name><surname>Urai</surname><given-names>AE</given-names></name><name><surname>McCormick</surname><given-names>D</given-names></name><name><surname>McGinley</surname><given-names>MJ</given-names></name><name><surname>Donner</surname><given-names>TH</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Pupil-linked phasic arousal predicts a reduction of choice bias across species and decision domains</article-title><source>eLife</source><volume>9</volume><elocation-id>e54014</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.54014</pub-id><pub-id pub-id-type="pmid">32543372</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dohm-Hansen</surname><given-names>S</given-names></name><name><surname>English</surname><given-names>JA</given-names></name><name><surname>Lavelle</surname><given-names>A</given-names></name><name><surname>Fitzsimons</surname><given-names>CP</given-names></name><name><surname>Lucassen</surname><given-names>PJ</given-names></name><name><surname>Nolan</surname><given-names>YM</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>The “middle-aging” brain</article-title><source>Trends in Neurosciences</source><volume>47</volume><fpage>259</fpage><lpage>272</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2024.02.001</pub-id><pub-id pub-id-type="pmid">38508906</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dougherty</surname><given-names>K</given-names></name><name><surname>Hustedt-Mai</surname><given-names>A</given-names></name><name><surname>Hagedorn</surname><given-names>A</given-names></name><name><surname>Bharadwaj</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Central gain in aging, tinnitus, and temporary hearing loss</article-title><source>The Journal of the Acoustical Society of America</source><volume>150</volume><elocation-id>A341</elocation-id><pub-id pub-id-type="doi">10.1121/10.0008520</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elliott</surname><given-names>ML</given-names></name><name><surname>Belsky</surname><given-names>DW</given-names></name><name><surname>Knodt</surname><given-names>AR</given-names></name><name><surname>Ireland</surname><given-names>D</given-names></name><name><surname>Melzer</surname><given-names>TR</given-names></name><name><surname>Poulton</surname><given-names>R</given-names></name><name><surname>Ramrakha</surname><given-names>S</given-names></name><name><surname>Caspi</surname><given-names>A</given-names></name><name><surname>Moffitt</surname><given-names>TE</given-names></name><name><surname>Hariri</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2021">2021a</year><article-title>Brain-age in midlife is associated with accelerated biological aging and cognitive decline in a longitudinal birth cohort</article-title><source>Molecular Psychiatry</source><volume>26</volume><fpage>3829</fpage><lpage>3838</lpage><pub-id pub-id-type="doi">10.1038/s41380-019-0626-7</pub-id><pub-id pub-id-type="pmid">31822815</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elliott</surname><given-names>ML</given-names></name><name><surname>Caspi</surname><given-names>A</given-names></name><name><surname>Houts</surname><given-names>RM</given-names></name><name><surname>Ambler</surname><given-names>A</given-names></name><name><surname>Broadbent</surname><given-names>JM</given-names></name><name><surname>Hancox</surname><given-names>RJ</given-names></name><name><surname>Harrington</surname><given-names>H</given-names></name><name><surname>Hogan</surname><given-names>S</given-names></name><name><surname>Keenan</surname><given-names>R</given-names></name><name><surname>Knodt</surname><given-names>A</given-names></name><name><surname>Leung</surname><given-names>JH</given-names></name><name><surname>Melzer</surname><given-names>TR</given-names></name><name><surname>Purdy</surname><given-names>SC</given-names></name><name><surname>Ramrakha</surname><given-names>S</given-names></name><name><surname>Richmond-Rakerd</surname><given-names>LS</given-names></name><name><surname>Righarts</surname><given-names>A</given-names></name><name><surname>Sugden</surname><given-names>K</given-names></name><name><surname>Thomson</surname><given-names>WM</given-names></name><name><surname>Thorne</surname><given-names>PR</given-names></name><name><surname>Williams</surname><given-names>BS</given-names></name><name><surname>Wilson</surname><given-names>G</given-names></name><name><surname>Hariri</surname><given-names>AR</given-names></name><name><surname>Poulton</surname><given-names>R</given-names></name><name><surname>Moffitt</surname><given-names>TE</given-names></name></person-group><year iso-8601-date="2021">2021b</year><article-title>Disparities in the pace of biological aging among midlife adults of the same chronological age have implications for future frailty risk and policy</article-title><source>Nature Aging</source><volume>1</volume><fpage>295</fpage><lpage>308</lpage><pub-id pub-id-type="doi">10.1038/s43587-021-00044-4</pub-id><pub-id pub-id-type="pmid">33796868</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedman</surname><given-names>J</given-names></name><name><surname>Hastie</surname><given-names>T</given-names></name><name><surname>Tibshirani</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Regularization paths for generalized linear models via coordinate descent</article-title><source>Journal of Statistical Software</source><volume>33</volume><fpage>1</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.18637/jss.v033.i01</pub-id><pub-id pub-id-type="pmid">20808728</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garrett</surname><given-names>M</given-names></name><name><surname>Vasilkov</surname><given-names>V</given-names></name><name><surname>Mauermann</surname><given-names>M</given-names></name><name><surname>Devolder</surname><given-names>P</given-names></name><name><surname>Wilson</surname><given-names>JL</given-names></name><name><surname>Gonzales</surname><given-names>L</given-names></name><name><surname>Henry</surname><given-names>KS</given-names></name><name><surname>Verhulst</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>Deciphering compromised speech-in-noise intelligibility in older listeners: The role of cochlear synaptopathy</article-title><source>eNeuro</source><volume>12</volume><elocation-id>ENEURO.0182-24.2024</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0182-24.2024</pub-id><pub-id pub-id-type="pmid">39788732</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Girden</surname><given-names>ER</given-names></name></person-group><year iso-8601-date="1992">1992</year><source>ANOVA: Repeated Measures</source><publisher-name>Sage Publications, Inc</publisher-name></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grant</surname><given-names>KJ</given-names></name><name><surname>Mepani</surname><given-names>AM</given-names></name><name><surname>Wu</surname><given-names>P</given-names></name><name><surname>Hancock</surname><given-names>KE</given-names></name><name><surname>de Gruttola</surname><given-names>V</given-names></name><name><surname>Liberman</surname><given-names>MC</given-names></name><name><surname>Maison</surname><given-names>SF</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Electrophysiological markers of cochlear function correlate with hearing-in-noise performance among audiometrically normal subjects</article-title><source>Journal of Neurophysiology</source><volume>124</volume><fpage>418</fpage><lpage>431</lpage><pub-id pub-id-type="doi">10.1152/jn.00016.2020</pub-id><pub-id pub-id-type="pmid">32639924</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grant</surname><given-names>KJ</given-names></name><name><surname>Parthasarathy</surname><given-names>A</given-names></name><name><surname>Vasilkov</surname><given-names>V</given-names></name><name><surname>Caswell-Midwinter</surname><given-names>B</given-names></name><name><surname>Freitas</surname><given-names>ME</given-names></name><name><surname>de Gruttola</surname><given-names>V</given-names></name><name><surname>Polley</surname><given-names>DB</given-names></name><name><surname>Liberman</surname><given-names>MC</given-names></name><name><surname>Maison</surname><given-names>SF</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Predicting neural deficits in sensorineural hearing loss from word recognition scores</article-title><source>Scientific Reports</source><volume>12</volume><elocation-id>8929</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-022-13023-5</pub-id><pub-id pub-id-type="pmid">35739134</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gratton</surname><given-names>MA</given-names></name><name><surname>Schulte</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Alterations in microvasculature are associated with atrophy of the stria vascularis in quiet-aged gerbils</article-title><source>Hearing Research</source><volume>82</volume><fpage>44</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1016/0378-5955(94)00161-i</pub-id><pub-id pub-id-type="pmid">7744712</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greenwood</surname><given-names>DD</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>A cochlear frequency-position function for several species—29 years later</article-title><source>The Journal of the Acoustical Society of America</source><volume>87</volume><fpage>2592</fpage><lpage>2605</lpage><pub-id pub-id-type="doi">10.1121/1.399052</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guest</surname><given-names>H</given-names></name><name><surname>Munro</surname><given-names>KJ</given-names></name><name><surname>Plack</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Tinnitus with a normal audiogram: Role of high-frequency sensitivity and reanalysis of brainstem-response measures to avoid audiometric over-matching</article-title><source>Hearing Research</source><volume>356</volume><fpage>116</fpage><lpage>117</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2017.10.002</pub-id><pub-id pub-id-type="pmid">29056432</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hind</surname><given-names>SE</given-names></name><name><surname>Haines-Bazrafshan</surname><given-names>R</given-names></name><name><surname>Benton</surname><given-names>CL</given-names></name><name><surname>Brassington</surname><given-names>W</given-names></name><name><surname>Towle</surname><given-names>B</given-names></name><name><surname>Moore</surname><given-names>DR</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Prevalence of clinical referrals having hearing thresholds within normal limits</article-title><source>International Journal of Audiology</source><volume>50</volume><fpage>708</fpage><lpage>716</lpage><pub-id pub-id-type="doi">10.3109/14992027.2011.582049</pub-id><pub-id pub-id-type="pmid">21714709</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hornsby</surname><given-names>BWY</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The effects of hearing aid use on listening effort and mental fatigue associated with sustained speech processing demands</article-title><source>Ear and Hearing</source><volume>34</volume><fpage>523</fpage><lpage>534</lpage><pub-id pub-id-type="doi">10.1097/AUD.0b013e31828003d8</pub-id><pub-id pub-id-type="pmid">23426091</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hornsby</surname><given-names>BWY</given-names></name><name><surname>Naylor</surname><given-names>G</given-names></name><name><surname>Bess</surname><given-names>FH</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A taxonomy of fatigue concepts and their relation to hearing loss</article-title><source>Ear and Hearing</source><volume>37 Suppl 1</volume><fpage>136S</fpage><lpage>44S</lpage><pub-id pub-id-type="doi">10.1097/AUD.0000000000000289</pub-id><pub-id pub-id-type="pmid">27355763</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hughes</surname><given-names>ML</given-names></name><name><surname>Agrigoroaei</surname><given-names>S</given-names></name><name><surname>Jeon</surname><given-names>M</given-names></name><name><surname>Bruzzese</surname><given-names>M</given-names></name><name><surname>Lachman</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Change in cognitive performance from midlife into old age: Findings from the Midlife in the United States (MIDUS) Study</article-title><source>Journal of the International Neuropsychological Society</source><volume>24</volume><fpage>805</fpage><lpage>820</lpage><pub-id pub-id-type="doi">10.1017/S1355617718000425</pub-id><pub-id pub-id-type="pmid">30019663</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hunter</surname><given-names>LL</given-names></name><name><surname>Monson</surname><given-names>BB</given-names></name><name><surname>Moore</surname><given-names>DR</given-names></name><name><surname>Dhar</surname><given-names>S</given-names></name><name><surname>Wright</surname><given-names>BA</given-names></name><name><surname>Munro</surname><given-names>KJ</given-names></name><name><surname>Zadeh</surname><given-names>LM</given-names></name><name><surname>Blankenship</surname><given-names>CM</given-names></name><name><surname>Stiepan</surname><given-names>SM</given-names></name><name><surname>Siegel</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Extended high frequency hearing and speech perception implications in adults and children</article-title><source>Hearing Research</source><volume>397</volume><elocation-id>107922</elocation-id><pub-id pub-id-type="doi">10.1016/j.heares.2020.107922</pub-id><pub-id pub-id-type="pmid">32111404</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>TA</given-names></name><name><surname>Cooper</surname><given-names>S</given-names></name><name><surname>Stamper</surname><given-names>GC</given-names></name><name><surname>Chertoff</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Noise exposure questionnaire: A tool for quantifying annual noise exposure</article-title><source>Journal of the American Academy of Audiology</source><volume>28</volume><fpage>14</fpage><lpage>35</lpage><pub-id pub-id-type="doi">10.3766/jaaa.15070</pub-id><pub-id pub-id-type="pmid">28054909</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joris</surname><given-names>PX</given-names></name><name><surname>Schreiner</surname><given-names>CE</given-names></name><name><surname>Rees</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Neural processing of amplitude-modulated sounds</article-title><source>Physiological Reviews</source><volume>84</volume><fpage>541</fpage><lpage>577</lpage><pub-id pub-id-type="doi">10.1152/physrev.00029.2003</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Joshi</surname><given-names>S</given-names></name><name><surname>Li</surname><given-names>Y</given-names></name><name><surname>Kalwani</surname><given-names>RM</given-names></name><name><surname>Gold</surname><given-names>JI</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Relationships between pupil diameter and neuronal activity in the Locus Coeruleus, Colliculi, and Cingulate Cortex</article-title><source>Neuron</source><volume>89</volume><fpage>221</fpage><lpage>234</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.028</pub-id><pub-id pub-id-type="pmid">26711118</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Killion</surname><given-names>MC</given-names></name><name><surname>Niquette</surname><given-names>PA</given-names></name><name><surname>Gudmundsen</surname><given-names>GI</given-names></name><name><surname>Revit</surname><given-names>LJ</given-names></name><name><surname>Banerjee</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Development of a quick speech-in-noise test for measuring signal-to-noise ratio loss in normal-hearing and hearing-impaired listeners</article-title><source>The Journal of the Acoustical Society of America</source><volume>116</volume><fpage>2395</fpage><lpage>2405</lpage><pub-id pub-id-type="doi">10.1121/1.1784440</pub-id><pub-id pub-id-type="pmid">15532670</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koelewijn</surname><given-names>T</given-names></name><name><surname>Zekveld</surname><given-names>AA</given-names></name><name><surname>Lunner</surname><given-names>T</given-names></name><name><surname>Kramer</surname><given-names>SE</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The effect of reward on listening effort as reflected by the pupil dilation response</article-title><source>Hearing Research</source><volume>367</volume><fpage>106</fpage><lpage>112</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2018.07.011</pub-id><pub-id pub-id-type="pmid">30096490</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuchinsky</surname><given-names>SE</given-names></name><name><surname>Ahlstrom</surname><given-names>JB</given-names></name><name><surname>Vaden</surname><given-names>KI</given-names><suffix>Jr</suffix></name><name><surname>Cute</surname><given-names>SL</given-names></name><name><surname>Humes</surname><given-names>LE</given-names></name><name><surname>Dubno</surname><given-names>JR</given-names></name><name><surname>Eckert</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Pupil size varies with word listening and response selection difficulty in older adults with hearing loss</article-title><source>Psychophysiology</source><volume>50</volume><fpage>23</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2012.01477.x</pub-id><pub-id pub-id-type="pmid">23157603</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuchinsky</surname><given-names>SE</given-names></name><name><surname>Ahlstrom</surname><given-names>JB</given-names></name><name><surname>Cute</surname><given-names>SL</given-names></name><name><surname>Humes</surname><given-names>LE</given-names></name><name><surname>Dubno</surname><given-names>JR</given-names></name><name><surname>Eckert</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Speech-perception training for older adults with hearing loss impacts word recognition and effort</article-title><source>Psychophysiology</source><volume>51</volume><fpage>1046</fpage><lpage>1057</lpage><pub-id pub-id-type="doi">10.1111/psyp.12242</pub-id><pub-id pub-id-type="pmid">24909603</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuhn</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Building predictive models in R Using the caret Package</article-title><source>Journal of Statistical Software</source><volume>28</volume><fpage>1</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.18637/jss.v028.i05</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kujawa</surname><given-names>SG</given-names></name><name><surname>Liberman</surname><given-names>MC</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Adding insult to injury: cochlear nerve degeneration after “temporary” noise-induced hearing loss</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>14077</fpage><lpage>14085</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2845-09.2009</pub-id><pub-id pub-id-type="pmid">19906956</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kuznetsova</surname><given-names>A</given-names></name><name><surname>Brockhoff</surname><given-names>PB</given-names></name><name><surname>R. H.</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Christensen, lmerTest Package: Tests in linear mixed effects models</article-title><source>Journal of Statistical Software</source><volume>82</volume><fpage>1</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.18637/jss.v082.i13</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lai</surname><given-names>J</given-names></name><name><surname>Bartlett</surname><given-names>EL</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Masking differentially affects envelope-following responses in young and aged animals</article-title><source>Neuroscience</source><volume>386</volume><fpage>150</fpage><lpage>165</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2018.06.004</pub-id><pub-id pub-id-type="pmid">29953908</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liberman</surname><given-names>LD</given-names></name><name><surname>Wang</surname><given-names>HB</given-names></name><name><surname>Liberman</surname><given-names>MC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Opposing gradients of ribbon size and AMPA receptor expression underlie sensitivity differences among cochlear-nerve/hair-cell synapses</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>801</fpage><lpage>808</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3389-10.2011</pub-id><pub-id pub-id-type="pmid">21248103</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>FR</given-names></name><name><surname>Thorpe</surname><given-names>R</given-names></name><name><surname>Gordon-Salant</surname><given-names>S</given-names></name><name><surname>Ferrucci</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Hearing loss prevalence and risk factors among older adults in the United States</article-title><source>The Journals of Gerontology Series A: Biological Sciences and Medical Sciences</source><volume>66</volume><fpage>582</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1093/gerona/glr002</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Livingston</surname><given-names>G</given-names></name><name><surname>Sommerlad</surname><given-names>A</given-names></name><name><surname>Orgeta</surname><given-names>V</given-names></name><name><surname>Costafreda</surname><given-names>SG</given-names></name><name><surname>Huntley</surname><given-names>J</given-names></name><name><surname>Ames</surname><given-names>D</given-names></name><name><surname>Ballard</surname><given-names>C</given-names></name><name><surname>Banerjee</surname><given-names>S</given-names></name><name><surname>Burns</surname><given-names>A</given-names></name><name><surname>Cohen-Mansfield</surname><given-names>J</given-names></name><name><surname>Cooper</surname><given-names>C</given-names></name><name><surname>Fox</surname><given-names>N</given-names></name><name><surname>Gitlin</surname><given-names>LN</given-names></name><name><surname>Howard</surname><given-names>R</given-names></name><name><surname>Kales</surname><given-names>HC</given-names></name><name><surname>Larson</surname><given-names>EB</given-names></name><name><surname>Ritchie</surname><given-names>K</given-names></name><name><surname>Rockwood</surname><given-names>K</given-names></name><name><surname>Sampson</surname><given-names>EL</given-names></name><name><surname>Samus</surname><given-names>Q</given-names></name><name><surname>Schneider</surname><given-names>LS</given-names></name><name><surname>Selbæk</surname><given-names>G</given-names></name><name><surname>Teri</surname><given-names>L</given-names></name><name><surname>Mukadam</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dementia prevention, intervention, and care</article-title><source>The Lancet</source><volume>390</volume><fpage>2673</fpage><lpage>2734</lpage><pub-id pub-id-type="doi">10.1016/S0140-6736(17)31363-6</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lough</surname><given-names>M</given-names></name><name><surname>Plack</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Extended high-frequency audiometry in research and clinical practice</article-title><source>The Journal of the Acoustical Society of America</source><volume>151</volume><fpage>1944</fpage><lpage>1955</lpage><pub-id pub-id-type="doi">10.1121/10.0009766</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Märcher-Rørsted</surname><given-names>J</given-names></name><name><surname>Encina-Llamas</surname><given-names>G</given-names></name><name><surname>Dau</surname><given-names>T</given-names></name><name><surname>Liberman</surname><given-names>MC</given-names></name><name><surname>Wu</surname><given-names>P-Z</given-names></name><name><surname>Hjortkjær</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Age-related reduction in frequency-following responses as a potential marker of cochlear neural degeneration</article-title><source>Hearing Research</source><volume>414</volume><elocation-id>108411</elocation-id><pub-id pub-id-type="doi">10.1016/j.heares.2021.108411</pub-id><pub-id pub-id-type="pmid">34929535</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McGinley</surname><given-names>MJ</given-names></name><name><surname>David</surname><given-names>SV</given-names></name><name><surname>McCormick</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Cortical membrane potential signature of optimal states for sensory signal detection</article-title><source>Neuron</source><volume>87</volume><fpage>179</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.05.038</pub-id><pub-id pub-id-type="pmid">26074005</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McHaney</surname><given-names>JR</given-names></name><name><surname>Tessmer</surname><given-names>R</given-names></name><name><surname>Roark</surname><given-names>CL</given-names></name><name><surname>Chandrasekaran</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Working memory relates to individual differences in speech category learning: Insights from computational modeling and pupillometry</article-title><source>Brain and Language</source><volume>222</volume><elocation-id>105010</elocation-id><pub-id pub-id-type="doi">10.1016/j.bandl.2021.105010</pub-id><pub-id pub-id-type="pmid">34454285</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McHaney</surname><given-names>JR</given-names></name><name><surname>Hancock</surname><given-names>KE</given-names></name><name><surname>Polley</surname><given-names>DB</given-names></name><name><surname>Parthasarathy</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Sensory representations and pupil-indexed listening effort provide complementary contributions to multi-talker speech intelligibility</article-title><source>Scientific Reports</source><volume>14</volume><elocation-id>30882</elocation-id><pub-id pub-id-type="doi">10.1038/s41598-024-81673-8</pub-id><pub-id pub-id-type="pmid">39730737</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McLaughlin</surname><given-names>DJ</given-names></name><name><surname>Zink</surname><given-names>ME</given-names></name><name><surname>Gaunt</surname><given-names>L</given-names></name><name><surname>Van Engen</surname><given-names>KJ</given-names></name><name><surname>Sommers</surname><given-names>MS</given-names></name><name><surname>Peelle</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Pupillometry reveals cognitive demands of lexical competition during spoken word recognition in young and older adults</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>29</volume><fpage>268</fpage><lpage>280</lpage><pub-id pub-id-type="doi">10.3758/s13423-021-01991-0</pub-id><pub-id pub-id-type="pmid">34405386</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mehraei</surname><given-names>G</given-names></name><name><surname>Hickox</surname><given-names>AE</given-names></name><name><surname>Bharadwaj</surname><given-names>HM</given-names></name><name><surname>Goldberg</surname><given-names>H</given-names></name><name><surname>Verhulst</surname><given-names>S</given-names></name><name><surname>Liberman</surname><given-names>MC</given-names></name><name><surname>Shinn-Cunningham</surname><given-names>BG</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Auditory brainstem response latency in noise as a marker of cochlear synaptopathy</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>3755</fpage><lpage>3764</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4460-15.2016</pub-id><pub-id pub-id-type="pmid">27030760</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mepani</surname><given-names>AM</given-names></name><name><surname>Kirk</surname><given-names>SA</given-names></name><name><surname>Hancock</surname><given-names>KE</given-names></name><name><surname>Bennett</surname><given-names>K</given-names></name><name><surname>de Gruttola</surname><given-names>V</given-names></name><name><surname>Liberman</surname><given-names>MC</given-names></name><name><surname>Maison</surname><given-names>SF</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Middle ear muscle reflex and word recognition in “Normal-Hearing” adults: Evidence for cochlear synaptopathy?</article-title><source>Ear and Hearing</source><volume>41</volume><fpage>25</fpage><lpage>38</lpage><pub-id pub-id-type="doi">10.1097/AUD.0000000000000804</pub-id><pub-id pub-id-type="pmid">31584501</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mepani</surname><given-names>AM</given-names></name><name><surname>Verhulst</surname><given-names>S</given-names></name><name><surname>Hancock</surname><given-names>KE</given-names></name><name><surname>Garrett</surname><given-names>M</given-names></name><name><surname>Vasilkov</surname><given-names>V</given-names></name><name><surname>Bennett</surname><given-names>K</given-names></name><name><surname>de Gruttola</surname><given-names>V</given-names></name><name><surname>Liberman</surname><given-names>MC</given-names></name><name><surname>Maison</surname><given-names>SF</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Envelope following responses predict speech-in-noise performance in normal-hearing listeners</article-title><source>Journal of Neurophysiology</source><volume>125</volume><fpage>1213</fpage><lpage>1222</lpage><pub-id pub-id-type="doi">10.1152/jn.00620.2020</pub-id><pub-id pub-id-type="pmid">33656936</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>J</given-names></name><name><surname>Dentel</surname><given-names>L</given-names></name><name><surname>Meunier</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Speech recognition in natural background noise</article-title><source>PLOS ONE</source><volume>8</volume><elocation-id>e79279</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pone.0079279</pub-id><pub-id pub-id-type="pmid">24260183</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mirman</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><source>Growth Curve Analysis and Visualization Using R</source><publisher-name>Chapman and Hall/CRC</publisher-name></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mishra</surname><given-names>SK</given-names></name><name><surname>Saxena</surname><given-names>U</given-names></name><name><surname>Rodrigo</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Extended high-frequency hearing impairment despite a normal audiogram: relation to early aging, speech-in-noise perception, cochlear function, and routine earphone use</article-title><source>Ear and Hearing</source><volume>43</volume><fpage>822</fpage><lpage>835</lpage><pub-id pub-id-type="doi">10.1097/AUD.0000000000001140</pub-id><pub-id pub-id-type="pmid">34700326</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nasreddine</surname><given-names>ZS</given-names></name><name><surname>Phillips</surname><given-names>NA</given-names></name><name><surname>Bédirian</surname><given-names>V</given-names></name><name><surname>Charbonneau</surname><given-names>S</given-names></name><name><surname>Whitehead</surname><given-names>V</given-names></name><name><surname>Collin</surname><given-names>I</given-names></name><name><surname>Cummings</surname><given-names>JL</given-names></name><name><surname>Chertkow</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>The Montreal Cognitive Assessment, MoCA: A brief screening tool for mild cognitive impairment</article-title><source>Journal of the American Geriatrics Society</source><volume>53</volume><fpage>695</fpage><lpage>699</lpage><pub-id pub-id-type="doi">10.1111/j.1532-5415.2005.53221.x</pub-id><pub-id pub-id-type="pmid">15817019</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newman</surname><given-names>CW</given-names></name><name><surname>Jacobson</surname><given-names>GP</given-names></name><name><surname>Spitzer</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Development of the tinnitus handicap inventory</article-title><source>Archives of Otolaryngology--Head &amp; Neck Surgery</source><volume>122</volume><fpage>143</fpage><lpage>148</lpage><pub-id pub-id-type="doi">10.1001/archotol.1996.01890140029007</pub-id><pub-id pub-id-type="pmid">8630207</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parida</surname><given-names>S</given-names></name><name><surname>Yurasits</surname><given-names>K</given-names></name><name><surname>Cancel</surname><given-names>VE</given-names></name><name><surname>Zink</surname><given-names>ME</given-names></name><name><surname>Mitchell</surname><given-names>C</given-names></name><name><surname>Ziliak</surname><given-names>MC</given-names></name><name><surname>Harrison</surname><given-names>AV</given-names></name><name><surname>Bartlett</surname><given-names>EL</given-names></name><name><surname>Parthasarathy</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Rapid and objective assessment of auditory temporal processing using dynamic amplitude-modulated stimuli</article-title><source>Communications Biology</source><volume>7</volume><elocation-id>1517</elocation-id><pub-id pub-id-type="doi">10.1038/s42003-024-07187-1</pub-id><pub-id pub-id-type="pmid">39548272</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parthasarathy</surname><given-names>A</given-names></name><name><surname>Bartlett</surname><given-names>EL</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Age-related auditory deficits in temporal processing in F-344 rats</article-title><source>Neuroscience</source><volume>192</volume><fpage>619</fpage><lpage>630</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2011.06.042</pub-id><pub-id pub-id-type="pmid">21723376</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parthasarathy</surname><given-names>A</given-names></name><name><surname>Bartlett</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Two-channel recording of auditory-evoked potentials to detect age-related deficits in temporal processing</article-title><source>Hearing Research</source><volume>289</volume><fpage>52</fpage><lpage>62</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2012.04.014</pub-id><pub-id pub-id-type="pmid">22560961</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parthasarathy</surname><given-names>A</given-names></name><name><surname>Lai</surname><given-names>J</given-names></name><name><surname>Bartlett</surname><given-names>EL</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Age-related changes in processing simultaneous amplitude modulated sounds assessed using envelope following responses</article-title><source>Journal of the Association for Research in Otolaryngology</source><volume>17</volume><fpage>119</fpage><lpage>132</lpage><pub-id pub-id-type="doi">10.1007/s10162-016-0554-z</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parthasarathy</surname><given-names>A</given-names></name><name><surname>Kujawa</surname><given-names>SG</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Synaptopathy in the Aging Cochlea: Characterizing early-neural deficits in auditory temporal envelope processing</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>7108</fpage><lpage>7119</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3240-17.2018</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Parthasarathy</surname><given-names>A</given-names></name><name><surname>Hancock</surname><given-names>KE</given-names></name><name><surname>Bennett</surname><given-names>K</given-names></name><name><surname>DeGruttola</surname><given-names>V</given-names></name><name><surname>Polley</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Bottom-up and top-down neural signatures of disordered multi-talker speech perception in adults with normal hearing</article-title><source>eLife</source><volume>9</volume><elocation-id>e51419</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.51419</pub-id><pub-id pub-id-type="pmid">31961322</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peelle</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Listening effort: How the cognitive consequences of acoustic challenge are reflected in brain and behavior</article-title><source>Ear and Hearing</source><volume>39</volume><fpage>204</fpage><lpage>214</lpage><pub-id pub-id-type="doi">10.1097/AUD.0000000000000494</pub-id><pub-id pub-id-type="pmid">28938250</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pichora-Fuller</surname><given-names>MK</given-names></name><name><surname>Kramer</surname><given-names>SE</given-names></name><name><surname>Eckert</surname><given-names>MA</given-names></name><name><surname>Edwards</surname><given-names>B</given-names></name><name><surname>Hornsby</surname><given-names>BWY</given-names></name><name><surname>Humes</surname><given-names>LE</given-names></name><name><surname>Lemke</surname><given-names>U</given-names></name><name><surname>Lunner</surname><given-names>T</given-names></name><name><surname>Matthen</surname><given-names>M</given-names></name><name><surname>Mackersie</surname><given-names>CL</given-names></name><name><surname>Naylor</surname><given-names>G</given-names></name><name><surname>Phillips</surname><given-names>NA</given-names></name><name><surname>Richter</surname><given-names>M</given-names></name><name><surname>Rudner</surname><given-names>M</given-names></name><name><surname>Sommers</surname><given-names>MS</given-names></name><name><surname>Tremblay</surname><given-names>KL</given-names></name><name><surname>Wingfield</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Hearing impairment and cognitive energy: The framework for Understanding Effortful Listening (FUEL)</article-title><source>Ear and Hearing</source><volume>37 Suppl 1</volume><fpage>5S</fpage><lpage>27S</lpage><pub-id pub-id-type="doi">10.1097/AUD.0000000000000312</pub-id><pub-id pub-id-type="pmid">27355771</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piquado</surname><given-names>T</given-names></name><name><surname>Isaacowitz</surname><given-names>D</given-names></name><name><surname>Wingfield</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Pupillometry as a measure of cognitive effort in younger and older adults</article-title><source>Psychophysiology</source><volume>47</volume><fpage>560</fpage><lpage>569</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2009.00947.x</pub-id><pub-id pub-id-type="pmid">20070575</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Ponsot</surname><given-names>E</given-names></name><name><surname>Devolder</surname><given-names>P</given-names></name><name><surname>Dhooge</surname><given-names>I</given-names></name><name><surname>Verhulst</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Agee-related decline in neural phase-locking to envelope and temporal fine structure revealed by frequency following responses: A potential signature of cochlear synaptopathy impairing speech intelligibility</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2024.12.11.628010v1</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prendergast</surname><given-names>G</given-names></name><name><surname>Guest</surname><given-names>H</given-names></name><name><surname>Munro</surname><given-names>KJ</given-names></name><name><surname>Kluk</surname><given-names>K</given-names></name><name><surname>Léger</surname><given-names>A</given-names></name><name><surname>Hall</surname><given-names>DA</given-names></name><name><surname>Heinz</surname><given-names>MG</given-names></name><name><surname>Plack</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2017">2017a</year><article-title>Effects of noise exposure on young adults with normal audiograms I: Electrophysiology</article-title><source>Hearing Research</source><volume>344</volume><fpage>68</fpage><lpage>81</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2016.10.028</pub-id><pub-id pub-id-type="pmid">27816499</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prendergast</surname><given-names>G</given-names></name><name><surname>Millman</surname><given-names>RE</given-names></name><name><surname>Guest</surname><given-names>H</given-names></name><name><surname>Munro</surname><given-names>KJ</given-names></name><name><surname>Kluk</surname><given-names>K</given-names></name><name><surname>Dewey</surname><given-names>RS</given-names></name><name><surname>Hall</surname><given-names>DA</given-names></name><name><surname>Heinz</surname><given-names>MG</given-names></name><name><surname>Plack</surname><given-names>CJ</given-names></name></person-group><year iso-8601-date="2017">2017b</year><article-title>Effects of noise exposure on young adults with normal audiograms II: Behavioral measures</article-title><source>Hearing Research</source><volume>356</volume><fpage>74</fpage><lpage>86</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2017.10.007</pub-id><pub-id pub-id-type="pmid">29126651</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="web"><person-group person-group-type="author"><collab>R Core Team</collab></person-group><year iso-8601-date="2022">2022</year><article-title>R: a language and environment for statistical computing</article-title><ext-link ext-link-type="uri" xlink:href="https://www.gbif.org/tool/81287/r-a-language-and-environment-for-statistical-computing">https://www.gbif.org/tool/81287/r-a-language-and-environment-for-statistical-computing</ext-link><date-in-citation iso-8601-date="2022-12-11">December 11, 2022</date-in-citation></element-citation></ref><ref id="bib74"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reimer</surname><given-names>J</given-names></name><name><surname>McGinley</surname><given-names>MJ</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Rodenkirch</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>Q</given-names></name><name><surname>McCormick</surname><given-names>DA</given-names></name><name><surname>Tolias</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Pupil fluctuations track rapid changes in adrenergic and cholinergic activity in cortex</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>13289</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms13289</pub-id><pub-id pub-id-type="pmid">27824036</pub-id></element-citation></ref><ref id="bib75"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Resnik</surname><given-names>J</given-names></name><name><surname>Polley</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Cochlear neural degeneration disrupts hearing in background noise by increasing auditory cortex internal noise</article-title><source>Neuron</source><volume>109</volume><fpage>984</fpage><lpage>996</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.01.015</pub-id><pub-id pub-id-type="pmid">33561398</pub-id></element-citation></ref><ref id="bib76"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rumschlag</surname><given-names>JA</given-names></name><name><surname>McClaskey</surname><given-names>CM</given-names></name><name><surname>Dias</surname><given-names>JW</given-names></name><name><surname>Kerouac</surname><given-names>LB</given-names></name><name><surname>Noble</surname><given-names>KV</given-names></name><name><surname>Panganiban</surname><given-names>C</given-names></name><name><surname>Lang</surname><given-names>H</given-names></name><name><surname>Harris</surname><given-names>KC</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Age-related central gain with degraded neural synchrony in the auditory brainstem of mice and humans</article-title><source>Neurobiology of Aging</source><volume>115</volume><fpage>50</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1016/j.neurobiolaging.2022.03.014</pub-id><pub-id pub-id-type="pmid">35468552</pub-id></element-citation></ref><ref id="bib77"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruotsalainen</surname><given-names>S</given-names></name><name><surname>Haapalinna</surname><given-names>A</given-names></name><name><surname>Riekkinen</surname><given-names>PJ</given-names></name><name><surname>Sirviö</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Dexmedetomidine reduces response tendency, but not accuracy of rats in attention and short-term memory tasks</article-title><source>Pharmacology Biochemistry and Behavior</source><volume>56</volume><fpage>31</fpage><lpage>40</lpage><pub-id pub-id-type="doi">10.1016/S0091-3057(96)00151-7</pub-id></element-citation></ref><ref id="bib78"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ryan</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1976">1976</year><article-title>Hearing sensitivity of the mongolian gerbil, Meriones unguiculatis</article-title><source>The Journal of the Acoustical Society of America</source><volume>59</volume><fpage>1222</fpage><lpage>1226</lpage><pub-id pub-id-type="doi">10.1121/1.380961</pub-id><pub-id pub-id-type="pmid">956517</pub-id></element-citation></ref><ref id="bib79"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Salthouse</surname><given-names>TA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Trajectories of normal cognitive aging</article-title><source>Psychology and Aging</source><volume>34</volume><fpage>17</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1037/pag0000288</pub-id><pub-id pub-id-type="pmid">30211596</pub-id></element-citation></ref><ref id="bib80"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaette</surname><given-names>R</given-names></name><name><surname>McAlpine</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Tinnitus with a normal audiogram: Physiological evidence for hidden hearing loss and computational model</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>13452</fpage><lpage>13457</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2156-11.2011</pub-id><pub-id pub-id-type="pmid">21940438</pub-id></element-citation></ref><ref id="bib81"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaum</surname><given-names>N</given-names></name><name><surname>Lehallier</surname><given-names>B</given-names></name><name><surname>Hahn</surname><given-names>O</given-names></name><name><surname>Pálovics</surname><given-names>R</given-names></name><name><surname>Hosseinzadeh</surname><given-names>S</given-names></name><name><surname>Lee</surname><given-names>SE</given-names></name><name><surname>Sit</surname><given-names>R</given-names></name><name><surname>Lee</surname><given-names>DP</given-names></name><name><surname>Losada</surname><given-names>PM</given-names></name><name><surname>Zardeneta</surname><given-names>ME</given-names></name><name><surname>Fehlmann</surname><given-names>T</given-names></name><name><surname>Webber</surname><given-names>JT</given-names></name><name><surname>McGeever</surname><given-names>A</given-names></name><name><surname>Calcuttawala</surname><given-names>K</given-names></name><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>Berdnik</surname><given-names>D</given-names></name><name><surname>Mathur</surname><given-names>V</given-names></name><name><surname>Tan</surname><given-names>W</given-names></name><name><surname>Zee</surname><given-names>A</given-names></name><name><surname>Tan</surname><given-names>M</given-names></name><collab>Tabula Muris Consortium</collab><name><surname>Pisco</surname><given-names>AO</given-names></name><name><surname>Karkanias</surname><given-names>J</given-names></name><name><surname>Neff</surname><given-names>NF</given-names></name><name><surname>Keller</surname><given-names>A</given-names></name><name><surname>Darmanis</surname><given-names>S</given-names></name><name><surname>Quake</surname><given-names>SR</given-names></name><name><surname>Wyss-Coray</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Ageing hallmarks exhibit organ-specific temporal signatures</article-title><source>Nature</source><volume>583</volume><fpage>596</fpage><lpage>602</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-2499-y</pub-id><pub-id pub-id-type="pmid">32669715</pub-id></element-citation></ref><ref id="bib82"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sergeyenko</surname><given-names>Y</given-names></name><name><surname>Lall</surname><given-names>K</given-names></name><name><surname>Liberman</surname><given-names>MC</given-names></name><name><surname>Kujawa</surname><given-names>SG</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Age-related cochlear synaptopathy: an early-onset contributor to auditory functional decline</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>13686</fpage><lpage>13694</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1783-13.2013</pub-id><pub-id pub-id-type="pmid">23966690</pub-id></element-citation></ref><ref id="bib83"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shaheen</surname><given-names>LA</given-names></name><name><surname>Valero</surname><given-names>MD</given-names></name><name><surname>Liberman</surname><given-names>MC</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Towards a diagnosis of cochlear neuropathy with envelope following responses</article-title><source>Journal of the Association for Research in Otolaryngology</source><volume>16</volume><fpage>727</fpage><lpage>745</lpage><pub-id pub-id-type="doi">10.1007/s10162-015-0539-3</pub-id><pub-id pub-id-type="pmid">26323349</pub-id></element-citation></ref><ref id="bib84"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sherlock</surname><given-names>LP</given-names></name><name><surname>Formby</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Estimates of loudness, loudness discomfort, and the auditory dynamic range: Normative estimates, comparison of procedures, and test-retest reliability</article-title><source>Journal of the American Academy of Audiology</source><volume>16</volume><fpage>85</fpage><lpage>100</lpage><pub-id pub-id-type="doi">10.3766/jaaa.16.2.4</pub-id><pub-id pub-id-type="pmid">15807048</pub-id></element-citation></ref><ref id="bib85"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shinn-Cunningham</surname><given-names>BG</given-names></name><name><surname>Best</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Selective attention in normal and impaired hearing</article-title><source>Trends in Amplification</source><volume>12</volume><fpage>283</fpage><lpage>299</lpage><pub-id pub-id-type="doi">10.1177/1084713808325306</pub-id><pub-id pub-id-type="pmid">18974202</pub-id></element-citation></ref><ref id="bib86"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Škerková</surname><given-names>M</given-names></name><name><surname>Kovalová</surname><given-names>M</given-names></name><name><surname>Rychlý</surname><given-names>T</given-names></name><name><surname>Tomášková</surname><given-names>H</given-names></name><name><surname>Šlachtová</surname><given-names>H</given-names></name><name><surname>Čada</surname><given-names>Z</given-names></name><name><surname>Maďar</surname><given-names>R</given-names></name><name><surname>Mrázková</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Extended high-frequency audiometry: hearing thresholds in adults</article-title><source>European Archives of Oto-Rhino-Laryngology</source><volume>280</volume><fpage>565</fpage><lpage>572</lpage><pub-id pub-id-type="doi">10.1007/s00405-022-07498-1</pub-id><pub-id pub-id-type="pmid">35763083</pub-id></element-citation></ref><ref id="bib87"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>SS</given-names></name><name><surname>Jahn</surname><given-names>KN</given-names></name><name><surname>Sugai</surname><given-names>JA</given-names></name><name><surname>Hancock</surname><given-names>KE</given-names></name><name><surname>Polley</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>The human pupil and face encode sound affect and provide objective signatures of tinnitus and auditory hypersensitivity disorders</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2023.12.22.571929</pub-id></element-citation></ref><ref id="bib88"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spehar</surname><given-names>BP</given-names></name><name><surname>Lichtenhan</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Patients with normal hearing thresholds but difficulty hearing in noisy environments: a study on the willingness to try auditory training</article-title><source>Otology &amp; Neurotology</source><volume>39</volume><fpage>950</fpage><lpage>956</lpage><pub-id pub-id-type="doi">10.1097/MAO.0000000000001903</pub-id></element-citation></ref><ref id="bib89"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Telek</surname><given-names>HH</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The effects of age pupil diameters at different light amplitudes</article-title><source>Beyoglu Eye Journal</source><volume>3</volume><elocation-id>43534</elocation-id><pub-id pub-id-type="doi">10.14744/bej.2018.43534</pub-id></element-citation></ref><ref id="bib90"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ter-Mikaelian</surname><given-names>M</given-names></name><name><surname>Semple</surname><given-names>MN</given-names></name><name><surname>Sanes</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Effects of spectral and temporal disruption on cortical encoding of gerbil vocalizations</article-title><source>Journal of Neurophysiology</source><volume>110</volume><fpage>1190</fpage><lpage>1204</lpage><pub-id pub-id-type="doi">10.1152/jn.00645.2012</pub-id><pub-id pub-id-type="pmid">23761696</pub-id></element-citation></ref><ref id="bib91"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tremblay</surname><given-names>KL</given-names></name><name><surname>Pinto</surname><given-names>A</given-names></name><name><surname>Fischer</surname><given-names>ME</given-names></name><name><surname>Klein</surname><given-names>BEK</given-names></name><name><surname>Klein</surname><given-names>R</given-names></name><name><surname>Levy</surname><given-names>S</given-names></name><name><surname>Tweed</surname><given-names>TS</given-names></name><name><surname>Cruickshanks</surname><given-names>KJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Self-reported hearing difficulties among adults with normal audiograms: The Beaver Dam offspring study</article-title><source>Ear and Hearing</source><volume>36</volume><fpage>e290</fpage><lpage>e299</lpage><pub-id pub-id-type="doi">10.1097/AUD.0000000000000195</pub-id><pub-id pub-id-type="pmid">26164105</pub-id></element-citation></ref><ref id="bib92"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tryon</surname><given-names>WW</given-names></name></person-group><year iso-8601-date="1975">1975</year><article-title>Pupillometry: a survey of sources of variation</article-title><source>Psychophysiology</source><volume>12</volume><fpage>90</fpage><lpage>93</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.1975.tb03068.x</pub-id><pub-id pub-id-type="pmid">1114216</pub-id></element-citation></ref><ref id="bib93"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turner</surname><given-names>ML</given-names></name><name><surname>Engle</surname><given-names>RW</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Is working memory capacity task dependent?</article-title><source>Journal of Memory and Language</source><volume>28</volume><fpage>127</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1016/0749-596X(89)90040-5</pub-id></element-citation></ref><ref id="bib94"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Unsworth</surname><given-names>N</given-names></name><name><surname>Heitz</surname><given-names>RP</given-names></name><name><surname>Schrock</surname><given-names>JC</given-names></name><name><surname>Engle</surname><given-names>RW</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>An automated version of the operation span task</article-title><source>Behavior Research Methods</source><volume>37</volume><fpage>498</fpage><lpage>505</lpage><pub-id pub-id-type="doi">10.3758/BF03192720</pub-id></element-citation></ref><ref id="bib95"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Valero</surname><given-names>MD</given-names></name><name><surname>Hancock</surname><given-names>KE</given-names></name><name><surname>Liberman</surname><given-names>MC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The middle ear muscle reflex in the diagnosis of cochlear neuropathy</article-title><source>Hearing Research</source><volume>332</volume><fpage>29</fpage><lpage>38</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2015.11.005</pub-id><pub-id pub-id-type="pmid">26657094</pub-id></element-citation></ref><ref id="bib96"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Valero</surname><given-names>MD</given-names></name><name><surname>Hancock</surname><given-names>KE</given-names></name><name><surname>Maison</surname><given-names>SF</given-names></name><name><surname>Liberman</surname><given-names>MC</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Effects of cochlear synaptopathy on middle-ear muscle reflexes in unanesthetized mice</article-title><source>Hearing Research</source><volume>363</volume><fpage>109</fpage><lpage>118</lpage><pub-id pub-id-type="doi">10.1016/j.heares.2018.03.012</pub-id><pub-id pub-id-type="pmid">29598837</pub-id></element-citation></ref><ref id="bib97"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vasilkov</surname><given-names>V</given-names></name><name><surname>Garrett</surname><given-names>M</given-names></name><name><surname>Mauermann</surname><given-names>M</given-names></name><name><surname>Verhulst</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Enhancing the sensitivity of the envelope-following response for cochlear synaptopathy screening in humans: The role of stimulus envelope</article-title><source>Hearing Research</source><volume>400</volume><elocation-id>108132</elocation-id><pub-id pub-id-type="doi">10.1016/j.heares.2020.108132</pub-id><pub-id pub-id-type="pmid">33333426</pub-id></element-citation></ref><ref id="bib98"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>RH</given-names></name><name><surname>Abrams</surname><given-names>HB</given-names></name><name><surname>Pillion</surname><given-names>AL</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>A word-recognition task in multitalker babble using a descending presentation mode from 24 dB to 0 dB signal to babble</article-title><source>The Journal of Rehabilitation Research and Development</source><volume>40</volume><elocation-id>321</elocation-id><pub-id pub-id-type="doi">10.1682/JRRD.2003.07.0321</pub-id></element-citation></ref><ref id="bib99"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winn</surname><given-names>MB</given-names></name><name><surname>Edwards</surname><given-names>JR</given-names></name><name><surname>Litovsky</surname><given-names>RY</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The impact of auditory spectral resolution on listening effort revealed by pupil dilation</article-title><source>Ear and Hearing</source><volume>36</volume><fpage>e153</fpage><lpage>e165</lpage><pub-id pub-id-type="doi">10.1097/AUD.0000000000000145</pub-id><pub-id pub-id-type="pmid">25654299</pub-id></element-citation></ref><ref id="bib100"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winn</surname><given-names>MB</given-names></name><name><surname>Wendt</surname><given-names>D</given-names></name><name><surname>Koelewijn</surname><given-names>T</given-names></name><name><surname>Kuchinsky</surname><given-names>SE</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Best practices and advice for using pupillometry to measure listening effort: An introduction for those who want to get started</article-title><source>Trends in Hearing</source><volume>22</volume><elocation-id>2331216518800869</elocation-id><pub-id pub-id-type="doi">10.1177/2331216518800869</pub-id><pub-id pub-id-type="pmid">30261825</pub-id></element-citation></ref><ref id="bib101"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winn</surname><given-names>MB</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Time scales and moments of listening effort revealed in pupillometry</article-title><source>Seminars in Hearing</source><volume>44</volume><fpage>106</fpage><lpage>123</lpage><pub-id pub-id-type="doi">10.1055/s-0043-1767741</pub-id><pub-id pub-id-type="pmid">37122881</pub-id></element-citation></ref><ref id="bib102"><element-citation publication-type="web"><person-group person-group-type="author"><collab>World Health Organization</collab></person-group><year iso-8601-date="2024">2024</year><article-title>International Classification of Functioning, disability and health (ICF)</article-title><ext-link ext-link-type="uri" xlink:href="https://www.who.int/standards/classifications/international-classification-of-functioning-disability-and-health">https://www.who.int/standards/classifications/international-classification-of-functioning-disability-and-health</ext-link><date-in-citation iso-8601-date="2024-04-04">April 4, 2024</date-in-citation></element-citation></ref><ref id="bib103"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>PZ</given-names></name><name><surname>Liberman</surname><given-names>LD</given-names></name><name><surname>Bennett</surname><given-names>K</given-names></name><name><surname>de Gruttola</surname><given-names>V</given-names></name><name><surname>O’Malley</surname><given-names>JT</given-names></name><name><surname>Liberman</surname><given-names>MC</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Primary neural degeneration in the human cochlea: Evidence for hidden hearing loss in the aging ear</article-title><source>Neuroscience</source><volume>407</volume><fpage>8</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2018.07.053</pub-id><pub-id pub-id-type="pmid">30099118</pub-id></element-citation></ref><ref id="bib104"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>P-Z</given-names></name><name><surname>O’Malley</surname><given-names>JT</given-names></name><name><surname>de Gruttola</surname><given-names>V</given-names></name><name><surname>Liberman</surname><given-names>MC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Age-related hearing loss is dominated by damage to inner ear sensory cells, not the cellular battery that powers them</article-title><source>The Journal of Neuroscience</source><volume>40</volume><fpage>6357</fpage><lpage>6366</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0937-20.2020</pub-id><pub-id pub-id-type="pmid">32690619</pub-id></element-citation></ref><ref id="bib105"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>PZ</given-names></name><name><surname>O’Malley</surname><given-names>JT</given-names></name><name><surname>Liberman</surname><given-names>MC</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Neural degeneration in normal-aging human cochleas: machine-learning counts and 3D mapping in archival sections</article-title><source>Journal of the Association for Research in Otolaryngology</source><volume>24</volume><fpage>499</fpage><lpage>511</lpage><pub-id pub-id-type="doi">10.1007/s10162-023-00909-y</pub-id><pub-id pub-id-type="pmid">37957485</pub-id></element-citation></ref><ref id="bib106"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zekveld</surname><given-names>AA</given-names></name><name><surname>Kramer</surname><given-names>SE</given-names></name><name><surname>Festen</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cognitive load during speech perception in noise: the influence of age, hearing loss, and cognition on the pupil response</article-title><source>Ear and Hearing</source><volume>32</volume><fpage>498</fpage><lpage>510</lpage><pub-id pub-id-type="doi">10.1097/AUD.0b013e31820512bb</pub-id><pub-id pub-id-type="pmid">21233711</pub-id></element-citation></ref><ref id="bib107"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zekveld</surname><given-names>AA</given-names></name><name><surname>Festen</surname><given-names>JM</given-names></name><name><surname>Kramer</surname><given-names>SE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Task difficulty differentially affects two measures of processing load: The pupil response during sentence processing and delayed cued recall of the sentences</article-title><source>Journal of Speech, Language, and Hearing Research</source><volume>56</volume><fpage>1156</fpage><lpage>1165</lpage><pub-id pub-id-type="doi">10.1044/1092-4388(2012/12-0058)</pub-id></element-citation></ref><ref id="bib108"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zou</surname><given-names>H</given-names></name><name><surname>Hastie</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Regularization and variable selection via the elastic net</article-title><source>Journal of the Royal Statistical Society Series B</source><volume>67</volume><fpage>301</fpage><lpage>320</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9868.2005.00503.x</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><table-wrap id="app1keyresource" position="anchor"><label>Appendix 1—key resources table</label><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Reagent type (species) or resource</th><th align="left" valign="bottom">Designation</th><th align="left" valign="bottom">Source or reference</th><th align="left" valign="bottom">Identifiers</th><th align="left" valign="bottom">Additional information</th></tr></thead><tbody><tr><td align="left" valign="bottom">Genetic reagent (<italic>Meriones unguiculatus</italic>)</td><td align="left" valign="bottom">Crl:MON(Tum)</td><td align="left" valign="bottom">Charles River</td><td align="left" valign="bottom">243</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Antibody</td><td align="left" valign="bottom">ms(1gG1) α CtBP2 (mouse monoclonal)</td><td align="left" valign="bottom">BD Transduction Labs</td><td align="left" valign="bottom">BDB612044</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Antibody</td><td align="left" valign="bottom">rb α MyosinVIIa (rabbit polyclonal)</td><td align="left" valign="bottom">Proteus Biosciences</td><td align="left" valign="bottom">25-670</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Antibody</td><td align="left" valign="bottom">ms(1gG2a) α GluA2 (mouse monoclonal)</td><td align="left" valign="bottom">Millipore</td><td align="left" valign="bottom">MAB397</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Antibody</td><td align="left" valign="bottom">gt α ms (IgG2a) AF 488 (goat polyclonal)</td><td align="left" valign="bottom">Thermo Fisher</td><td align="left" valign="bottom">A-21131</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Antibody</td><td align="left" valign="bottom">gt α ms (IgG1) AF 568 (goat polyclonal)</td><td align="left" valign="bottom">Thermo Fisher</td><td align="left" valign="bottom">A-21124</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Antibody</td><td align="left" valign="bottom">dk α rb AF 647 (donkey polyclonal)</td><td align="left" valign="bottom">Thermo Fisher</td><td align="left" valign="bottom">A-31573</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Chemical compound, drug</td><td align="left" valign="bottom">Isoflurane</td><td align="left" valign="bottom">Covetrus</td><td align="left" valign="bottom">29405</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Chemical compound, drug</td><td align="left" valign="bottom">Dexmedetomidine</td><td align="left" valign="bottom">Covetrus</td><td align="left" valign="bottom">60984</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">Labview</td><td align="left" valign="bottom">National Instruments</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://www.ni.com/en-us/shop/labview.html">https://www.ni.com/en-us/shop/labview.html</ext-link></td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Software, algorithm</td><td align="left" valign="bottom">MATLAB</td><td align="left" valign="bottom">MathWorks</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://www.mathworks.com/products/matlab.html">https://www.mathworks.com/products/matlab.html</ext-link></td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">Eyelink 1000 Plus</td><td align="left" valign="bottom">SR Research</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://www.sr-research.com/eyelink-1000-plus/">https://www.sr-research.com/eyelink-1000-plus/</ext-link></td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">BioSemi Active Two EEG</td><td align="left" valign="bottom">BioSemi</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://www.biosemi.com/Products_ActiveTwo.htm">https://www.biosemi.com/Products_ActiveTwo.htm</ext-link></td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">Insert earphones</td><td align="left" valign="bottom">Etymotic</td><td align="left" valign="bottom">ER-3C</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">Multi-I/O Processor- RZ6-A-P1</td><td align="left" valign="bottom">TDT</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://www.tdt.com/product/rz6-multi-i-o-processor/">https://www.tdt.com/product/rz6-multi-i-o-processor/</ext-link></td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Other</td><td align="left" valign="bottom">ABR Amplifier, Medusa 4Z</td><td align="left" valign="bottom">TDT</td><td align="left" valign="bottom"><ext-link ext-link-type="uri" xlink:href="https://www.tdt.com/product/medusa4z-amplifier/">https://www.tdt.com/product/medusa4z-amplifier/</ext-link></td><td align="left" valign="bottom"/></tr></tbody></table></table-wrap></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.102823.3.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Obleser</surname><given-names>Jonas</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>University of Lübeck</institution><country>Germany</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Compelling</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>This study aims to clarify the effects of cochlear neural degeneration on auditory processing in listeners with normal audiograms (sometimes referred to as 'hidden hearing loss'). The authors provide <bold>important</bold> new data demonstrating associations between cochlear neural degeneration, non-invasive assays of auditory processing, and speech perception. Based on a cross-species comparison, the findings pose <bold>compelling</bold> evidence that cochlear synaptopathy is associated with a significant part of hearing difficulties in complex environments.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.102823.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>This study is part of an ongoing effort to clarify the effects of cochlear neural degeneration (CND) on auditory processing in listeners with normal audiograms. This effort is important because ~10% of people who seek help for hearing difficulties have normal audiograms and current hearing healthcare has nothing to offer them.</p><p>The authors identify two shortcomings in previous work that they intend to fix. The first is a lack of cross-species studies that make direct comparisons between animal models in which CND can be confirmed and humans for which CND must be inferred indirectly. The second is the low sensitivity of purely perceptual measures to subtle changes in auditory processing. To fix these shortcomings, the authors measure envelope following responses (EFRs) in gerbils and humans using the same sounds, while also performing histological analysis of the gerbil cochleae, and testing speech perception while measuring pupil size in the humans.</p><p>The study begins with a comprehensive assessment of the hearing status of the human listeners. The only differences found between the young adult (YA) and middle aged (MA) groups are in thresholds at frequencies &gt; 10 kHz and DPOAE amplitudes at frequencies &gt; 5 kHz. The authors then present the EFR results, first for the humans and then for the gerbils, showing that amplitudes decrease more rapidly with increasing envelope frequency for MA than for YA in both species. The histological analysis of the gerbil cochleae shows that there were, on average, 20% fewer IHC-AN synapses at the 3 kHz place in MA relative to YA, and the number of synapses per IHC was correlated with the EFR amplitude at 1024 Hz.</p><p>The study then returns to the humans to report the results of the speech perception tests and pupillometry. The correct understanding of keywords decreased more rapidly with decreasing SNR in MA than in YA, with a noticeable difference at 0 dB, while pupillary slope (a proxy for listening effort) increased more rapidly with decreasing SNR for MA than for YA, with the largest differences at SNRs between 5 and 15 dB. Finally, the authors report that a linear combination of audiometric threshold, EFR amplitude at 1024 Hz, and a few measures of pupillary slope is predictive of speech perception at 0 dB SNR.</p><p>I only have two questions/concerns about the specific methodologies used:</p><p>(1) Synapse counts were made only at the 3 kHz place on the cochlea. But the EFR sounds were presented at 85 dB SPL, which means that a rather large section of the cochlea will actually be excited. Do we know how much of the EFR actually reflects AN fibers coming from the 3 kHz place? And are we sure that this is the same for gerbils and humans given the differences in cochlear geometry, head size, etc.?</p><p>[Note added after revision: the authors have added new data, references, and discussion that have answered my initial questions].</p><p>(2) Unless I misunderstood, the predictive power of the final model was not tested on held out data. The standard way to fit and test such model would be to split the data into two segments, one for training and hyperparameter optimization, and one for testing. But it seems that the only spilt was for training and hyperparameter optimization.</p><p>[Note added after revision: the authors now make it clear in their response that the modeling tells us how much of the current data can be explained but not necessary about generalization to other datasets.]</p><p>While I find the study to be generally well executed, I am left wondering what to make of it all. The purpose of the study with respect to fixing previous methodological shortcomings was clear, but exactly how fixings these shortcomings has allowed us to advance is not. I think we can be more confident than before that EFR amplitude is sensitive to CND, and we now know that measures of listening effort may also be sensitive to CND. But where is this leading us?</p><p>I think what this line of work is eventually aiming for is to develop a clinical tool that can be used to infer someone's CND profile. That seems like a worthwhile goal but getting there will require going beyond exploratory association studies. I think we're ready to start being explicit about what properties a CND inference tool would need to be practically useful. I have no idea whether the associations reported in this study are encouraging or not because I have no idea what level of inferential power is ultimately required.</p><p>[Note added after revision: the authors have added to the Discussion to put their work into a broader perspective.]</p><p>That brings me to my final comment: there is an inappropriate emphasis on statistical significance. The sample size was chosen arbitrarily. What if the sample had been half the size? Then few, if any, of the observed effects would have been significant. What if the sample had been twice the size? Then many more of the observed effects would have been significant (particularly for the pupillometry). I hope that future studies will follow a more principled approach in which relevant effect sizes are pre-specified (ideally as the strength of association that would be practically useful) and sample sizes are determined accordingly.</p><p>[Note added after revision: my intention with this comment was not to make a philosophical or nitty-gritty point about statistics. It was more of a follow on to the previous point. Because I don't know what sort of effect size is big enough to matter (for whatever purpose), I don't find the statistical significance (or lack thereof) of the effect size observed to be informative. But I don't think there is anything more that the authors can or should do in this regard.]</p><p>So, in summary, I think this study is a valuable but limited advance. The results increase my confidence that non-invasive measures can be used to infer underlying CND, but I am unsure how much closer we are to anything that is practically useful.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.102823.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This paper addresses the bottom-up and top-down causes of hearing difficulties in middle-aged adults with clinically-normal audiograms using a cross-species approach (humans vs. gerbils, each with two age groups) mixing behavioral tests and electrophysiology.. The study is not only a follow-up of Parthasarathy et al (eLife 2020), since there are several important differences. Parthasarathy et al. (2020) only considered a group of young normal-hearing individuals with normal audiograms yet with high complaints for hearing in noisy situations. Here, this issue is considered specifically regarding aging, using a between-subject design comparing young NH and older NH individuals recruited from the general population, without additional criterion (i.e. no specifically high problems of hearing in noise). In addition, this is a cross-species approach, with the same physiological EFR measurements with the same stimuli deployed on gerbils.</p><p>This article is of very high quality. It is extremely clear, and the results show clearly a decrease of neural phase-locking to high modulation frequencies in both middle-aged humans and gerbils, compared to younger groups/cohorts. In addition, pupillometry measurements conducted during the QuickSIN task suggest increased listening efforts in middle-aged participants, and a statistical model including both EFRs and pupillometry features suggest that both factors contribute to reduced speech-in-noise intelligibility evidenced in middle-aged individuals, beyond their slight differences in audiometric thresholds (although they were clinically normal in both groups).</p><p>These provide strong support to the view that normal aging in humans leads to auditory nerve synaptic loss (cochlear neural degeneration - CND- or, put differently, cochlear synaptopathy) as well as increased listening effort, before any clearly visible audiometric deficits as defined in current clinical standards. This result is very important for the community, since we are still missing direct evidence that cochlear synaptopathy might likely underly a significant part of hearing difficulties in complex environments for listeners with normal thresholds, such as middle-aged and senior listeners. This paper shows that these difficulties can be reasonably well accounted for by this sensory disorder (CND), but also that listening effort, i.e. a top-down factor, further contributes to this problem. The methods are sound, well described and I would like to emphasize that they are presented concisely yet in a very precise manner, so that they can be understood very easily - even for a reader that is not familiar with the employed techniques. I believe this study will be of interest to a broad readership.I have some comments and questions which I think would make the paper even stronger once addressed.</p><p>Main comments:</p><p>(1) Presentation of EFR analyses / Interpretation of EFR differences found in both gerbils and humans</p><p>(a) Could you comment further on why you think you found a significant difference only at the highest mod. frequency of 1024 Hz in your study? Indeed, previous studies employing SAM or RAM tones very similar to the ones employed here were able to show age effects already at lower modulation freqs. of ~100H; e.g. there are clear age effects reported in human studies of Vasilikov et al. (2021) or Mepani et al. (2021), and also in animals (see Garrett et al. bioRxiv : <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/biorxiv/early/2024/04/30/2020.06.09.142950.full.pdf">https://www.biorxiv.org/content/biorxiv/early/2024/04/30/2020.06.09.142950.full.pdf</ext-link>)</p><p>Furthermore, some previous EEG experiments in humans that SAM tones with modulation freqs. of ~100Hz showed that EFRs do not exhibit a single peak, i.e. there are peaks not only at fm but also for the first harmonics (e.g. 2<italic>fm or 3</italic>fm) see e.g. Garrett et al. bioRxiv <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/biorxiv/early/2024/04/30/2020.06.09.142950.full.pdf">https://www.biorxiv.org/content/biorxiv/early/2024/04/30/2020.06.09.142950.full.pdf</ext-link></p><p>Did you try to extract EFR strength by looking at the summed amplitude of multiple peaks (Vasilikov Hear Res. 2021), in particular for the lower modulation frequencies? (Indeed, there will be no harmonics for the higher mod. freqs).</p><p>b) How the present EFR results relate to FFR results, where effects of age are already at low carrier freqs? (e.g. Märcher-Rørsted et al., Hear. Res., 2022 for pure tones with freq &lt; 500 Hz)Do you think it could be explained by the fact that this is not the same cochlear region, and that synapses die earlier in higher compared to lower CFs. This should be discussed.Beyond the main group effect of age, there were no negative correlations of EFRs with age in your data?</p><p>(2) Size of the effects / comparing age effects between two species:Although the size of the age effect on EFRs cannot be directly compared between humans and gerbils - the comparison remains qualitative - could you a least provide references regarding the rate of synaptic loss with aging in both humans and gerbils, so that we understand that the yNH/MA difference can be compared between the two age groups used for gerbils; it would have been critical in case of a non-significant age effect in one species.</p><p>Equalization / control of stimuli differences across the two species: For measuring EFRs, SAM stimuli were presented at 85 dB SPL for humans vs. 30 dB above detection threshold (inferred from ABRs) for gerbils - I do not think the results strongly depend on this choice, but it would be good to comment on why you did not choose also to present stimuli 30 dB above thresholds in humans.</p><p>Simulations of EFRs using functional models could have been used to understand (at least in humans) how the differences in EFRs obtained between the two groups are <italic>quantitatively</italic> compatible with the differences in % of remaining synaptic connections known from histopathological studies for their age range (see the approach in Märcher-Rørsted et al., Hear. Res., 2022)</p><p>(3) Synergetic effects of CND and listening effortCould you test whether there is an interaction between CNR and listening effort? (e.g. one could hypothesize that MA subjects with largest CND have also the higher listening effort)</p><p>Comments on revised version:</p><p>The authors did well to address all the points raised in my review. This paper will make an important contribution to our assessment of the sources of age-related auditory processing deficits beyond the cochlea that impair speech intelligibility.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.102823.3.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Zink</surname><given-names>Maggie E</given-names></name><role specific-use="author">Author</role><aff><institution>University of Pittsburgh</institution><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Zhen</surname><given-names>Leslie</given-names></name><role specific-use="author">Author</role><aff><institution>University of Pittsburgh</institution><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>McHaney</surname><given-names>Jacie R</given-names></name><role specific-use="author">Author</role><aff><institution>Northwestern University</institution><addr-line><named-content content-type="city">Chicago</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Klara</surname><given-names>Jennifer</given-names></name><role specific-use="author">Author</role><aff><institution>University of Pittsburgh</institution><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Yurasits</surname><given-names>Kimberly</given-names></name><role specific-use="author">Author</role><aff><institution>University of Pittsburgh</institution><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Cancel</surname><given-names>Victoria E</given-names></name><role specific-use="author">Author</role><aff><institution>University of Pittsburgh</institution><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Flemm</surname><given-names>Olivia</given-names></name><role specific-use="author">Author</role><aff><institution>University of Pittsburgh</institution><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Mitchell</surname><given-names>Claire</given-names></name><role specific-use="author">Author</role><aff><institution>University of Pittsburgh</institution><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Datta</surname><given-names>Jyotishka</given-names></name><role specific-use="author">Author</role><aff><institution>Virginia Tech</institution><addr-line><named-content content-type="city">Blacksburg</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Chandresekaran</surname><given-names>Bharath</given-names></name><role specific-use="author">Author</role><aff><institution>University of Pittsburgh</institution><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Parthasarathy</surname><given-names>Aravindakshan</given-names></name><role specific-use="author">Author</role><aff><institution>University of Pittsburgh</institution><addr-line><named-content content-type="city">Pittsburgh</named-content></addr-line><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public review):</bold></p><p>This study is part of an ongoing effort to clarify the effects of cochlear neural degeneration (CND) on auditory processing in listeners with normal audiograms. This effort is important because ~10% of people who seek help for hearing difficulties have normal audiograms and current hearing healthcare has nothing to offer them.</p><p>The authors identify two shortcomings in previous work that they intend to fix. The first is a lack of cross-species studies that make direct comparisons between animal models in which CND can be confirmed and humans for which CND must be inferred indirectly. The second is the low sensitivity of purely perceptual measures to subtle changes in auditory processing. To fix these shortcomings, the authors measure envelope following responses (EFRs) in gerbils and humans using the same sounds, while also performing histological analysis of the gerbil cochleae, and testing speech perception while measuring pupil size in the humans.</p><p>The study begins with a comprehensive assessment of the hearing status of the human listeners. The only differences found between the young adult (YA) and middle-aged (MA) groups are in thresholds at frequencies &gt; 10 kHz and DPOAE amplitudes at frequencies &gt; 5 kHz. The authors then present the EFR results, first for the humans and then for the gerbils, showing that amplitudes decrease more rapidly with increasing envelope frequency for MA than for YA in both species. The histological analysis of the gerbil cochleae shows that there were, on average, 20% fewer IHC-AN synapses at the 3 kHz place in MA relative to YA, and the number of synapses per IHC was correlated with the EFR amplitude at 1024 Hz.</p><p>The study then returns to the humans to report the results of the speech perception tests and pupillometry. The correct understanding of keywords decreased more rapidly with decreasing SNR in MA than in YA, with a noticeable difference at 0 dB, while pupillary slope (a proxy for listening effort) increased more rapidly with decreasing SNR for MA than for YA, with the largest differences at SNRs between 5 and 15 dB. Finally, the authors report that a linear combination of audiometric threshold, EFR amplitude at 1024 Hz, and a few measures of pupillary slope is predictive of speech perception at 0 dB SNR.</p><p>I only have two questions/concerns about the specific methodologies used:</p><p>(1) Synapse counts were made only at the 3 kHz place on the cochlea. However, the EFR sounds were presented at 85 dB SPL, which means that a rather large section of the cochlea will actually be excited. Do we know how much of the EFR actually reflects AN fibers coming from the 3 kHz place? And are we sure that this is the same for gerbils and humans given the differences in cochlear geometry, head size, etc.?</p></disp-quote><p>Thank you for raising this important point. The frequency regions that contribute to the generation of EFRs, especially at the suprathreshold sound levels presented here are expected to be broad, with a greater leaning towards higher frequencies and reaching up to one octave above the center frequency. We have investigated this phenomenon in earlier published articles using both low/high pass masking noise and computational models using data from rodent models and humans (Encina-Llamas et al. 2017; Parthasarathy, Lai, and Bartlett 2016). So, the expectation here is that the EFRs reflect a wider frequency region centered at 3 kHz. The difference in cochlear activation regions between humans and gerbils for EFRs have not been systematically studied to our knowledge but given the general agreement between humans and other rodent models stated above, we expect this to be similar to gerbils as well. Additionally, all current evidence points to cochlear synapse loss with age being flat across frequencies, in contrast to cochlear synapse loss with noise which is dependent on the bandwidth of the noise exposure.</p><p>Histological evidence for this flat loss across frequencies is found in mice and human temporal bones (Parthasarathy and Kujawa 2018; Sergeyenko et al. 2013; Wu et al. 2018). We find this to be true in our gerbils as well. Author response image 1 shows the patterns of synapse loss as a function of cochlear place. We focused on synapse loss at 3 kHz to keep the analysis focused on the center frequency of the stimulus and minimize compounding errors due to averaging synapse counts across multiple frequency regions. We have now added some explanatory language in the discussion.</p><fig id="sa3fig1" position="float"><label>Author response image 1.</label><caption><title>Cochlear synapse counts per inner hair cell (IHC) in young and middle-aged gerbils as a function of cochlear frequency.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102823-sa3-fig1-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>(2) Unless I misunderstood, the predictive power of the final model was not tested on heldout data. The standard way to fit and test such a model would be to split the data into two segments, one for training and hyperparameter optimization, and one for testing. But it seems that the only split was for training and hyperparameter optimization.</p></disp-quote><p>The goal of the analysis in this current manuscript was inference, rather than prediction, i.e., to find the important/significant variables that contribute to speech intelligibility in noise, rather than predicting the behavioral deficit of speech performance in a yet-unforeseen sample of adults.</p><p>Additionally, we used a repeated 10-fold cross-validation approach for our model building exercise as detailed in the Elastic Net Regression section of the methods. This repeated-cross validation calculated the mean square error on a held-out fold and average it repeatedly to reduce the inherent variability of randomly choosing a validation set. The repeated 10-fold CV approach is both more stable and efficient compared to a validation set approach, or splitting the data into two segments: training and test, and provides a better estimate of the test error by utilizing more observations for training (vide Chapter 5,James et al. 2021). These predictive MSEs along with the R-squared for the final model give us a good idea of the predictive performance, as, for the linear model the R-squared is the correlation between the observed and the predicted response. Future studies with a larger sample size can facilitate having a designated test set and still have enough statistical power to perform predictive analyses.</p><disp-quote content-type="editor-comment"><p>While I find the study to be generally well executed, I am left wondering what to make of it all. The purpose of the study with respect to fixing previous methodological shortcomings was clear, but exactly how fixing these shortcomings has allowed us to advance is not. I think we can be more confident than before that EFR amplitude is sensitive to CND, and we now know that measures of listening effort may also be sensitive to CND. But where is this leading us? I think what this line of work is eventually aiming for is to develop a clinical tool that can be used to infer someone's CND profile. That seems like a worthwhile goal but getting there will require going beyond exploratory association studies. I think we're ready to start being explicit about what properties a CND inference tool would need to be practically useful. I have no idea whether the associations reported in this study are encouraging or not because I have no idea what level of inferential power is ultimately required.</p></disp-quote><p>Studies with CND have so far been largely inferential in humans, since currently we cannot confirm CND in vivo. Hence any measures of putative CND in humans can only be interpreted based on evidence from other animal studies. Our translational approach is partly meant to address this deficit, as mentioned in the Introduction section. By using identical stimuli, recording, acquisition and analysis parameters we hope to reduce some of the variability that may be associated with this inference between human and other animal models. Until direct measurements of CND in humans are possible, the intended goal is to provide diagnostic biomarkers that have face validity – i.e., that explain variance related to speech intelligibility deficits in this population.</p><p>We’ve added more to the discussion to state that our work demonstrates the need for next generation diagnostic measures of auditory processing that incorporate cognitive factors associated with listening effort to better capture speech in noise perceptual abilities.</p><disp-quote content-type="editor-comment"><p>That brings me to my final comment: there is an inappropriate emphasis on statistical significance. The sample size was chosen arbitrarily. What if the sample had been half the size? Then few, if any, of the observed effects would have been significant. What if the sample had been twice the size? Then many more of the observed effects would have been significant (particularly for the pupillometry). I hope that future studies will follow a more principled approach in which relevant effect sizes are pre-specified (ideally as the strength of association that would be practically useful) and sample sizes are determined accordingly.</p></disp-quote><p>We agree that pre-determining sample sizes is the optimal approach towards designing a study. The sample sizes here were chosen a priori based on previously published data in young adults with normal hearing thresholds (McHaney et al. 2024; Parthasarathy et al. 2020). With the lack of published literature especially for the EFRs at 1024Hz AM in middle aged adults, there are practical challenges in pre-determining the sample size (given a prefixed power and an effect size) with limited precursors to supply good estimates of the parameters (e.g., mean, s.d. for each age group for a two-sample test). We hope that this data set now shared will enable us and other researchers to conduct power analyses for successive studies that use similar metrics on this population.</p><p>Several authors, including Heinsburg and Weeks (2022) argue that post-hoc power could be “misleading and simply not informative” and encourage using other indicators of poorly powered studies such as the width of the confidence interval. Since the elastic net estimate is a non-linear and non-differentiable function of the response values—even for fixed tuning parameters—it is difficult to obtain an accurate estimate of its standard error (Tibshirani and Taylor 2012). While acknowledging the limitations of post-hoc power analyses, we performed a retrospective power calculation for our linear model with the predictors that we selected (EFR @ 1024Hz, Pupil slope for QuickSIN at selected SNRs and analyses windows, and PTA). The calculated Cohen’s effect size was 0.56, which is considered large (Cohen 2013). With this effect size, a power analysis with our sample size revealed a very high retrospective power of 0.99 with a significance level of 0.05. The minimum number of subjects needed to get 80% power with this effect size was N = 21. Hence for the final model, we are confident that our results hold true with adequate statistical power.</p><disp-quote content-type="editor-comment"><p>So, in summary, I think this study is a valuable but limited advance. The results increase my confidence that non-invasive measures can be used to infer underlying CND, but I am unsure how much closer we are to anything that is practically useful.</p></disp-quote><p>Thank you for your comments. We hope that this study establishes a framework for the eventual development of the next generation of objective diagnostics tests in the hearing clinic that provide insights into the underlying neurophysiology of the auditory pathway and take into effect top-down contributors such as listening effort.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public review):</bold></p><p>Summary:</p><p>This paper addresses the bottom-up and top-down causes of hearing difficulties in middleaged adults with clinically-normal audiograms using a cross-species approach (humans vs. gerbils, each with two age groups) mixing behavioral tests and electrophysiology. The study is not only a follow-up of Parthasarathy et al (eLife 2020), since there are several important differences.</p><p>Parthasarathy et al. (2020) only considered a group of young normal-hearing individuals with normal audiograms yet with high complaints of hearing in noisy situations. Here, this issue is considered specifically regarding aging, using a between-subject design comparing young NH and older NH individuals recruited from the general population, without additional criterion (i.e. no specifically high problems of hearing in noise). In addition, this is a cross-species approach, with the same physiological EFR measurements with the same stimuli deployed on gerbils.</p><p>This article is of very high quality. It is extremely clear, and the results show clearly a decrease of neural phase-locking to high modulation frequencies in both middle-aged humans and gerbils, compared to younger groups/cohorts. In addition, pupillometry measurements conducted during the QuickSIN task suggest increased listening efforts in middle-aged participants, and a statistical model including both EFRs and pupillometry features suggests that both factors contribute to reduced speech-in-noise intelligibility evidenced in middle-aged individuals, beyond their slight differences in audiometric thresholds (although they were clinically normal in both groups).</p><p>These provide strong support to the view that normal aging in humans leads to auditory nerve synaptic loss (cochlear neural degeneration - CNR- or, put differently, cochlear synaptopathy) as well as increased listening effort, before any clearly visible audiometric deficits as defined in current clinical standards. This result is very important for the community since we are still missing direct evidence that cochlear synaptopathy might likely underlie a significant part of hearing difficulties in complex environments for listeners with normal thresholds, such as middle-aged and senior listeners. This paper shows that these difficulties can be reasonably well accounted for by this sensory disorder (CND), but also that listening effort, i.e. a top-down factor, further contributes to this problem. The methods are sound and well described and I would like to emphasize that they are presented concisely yet in a very precise manner so that they can be understood very easily - even for a reader who is not familiar with the employed techniques. I believe this study will be of interest to a broad readership.</p><p>I have some comments and questions which I think would make the paper even stronger once addressed.</p><p>Main comments:</p><p>(1) Presentation of EFR analyses / Interpretation of EFR differences found in both gerbils and humans:</p><p>a) Could the authors comment further on why they think they found a significant difference only at the highest mod. frequency of 1024 Hz in their study? Indeed, previous studies employing SAM or RAM tones very similar to the ones employed here were able to show age effects already at lower modulation freqs. of ~100H; e.g. there are clear age effects reported in human studies of Vasilikov et al. (2021) or Mepani et al. (2021), and also in animals (see Garrett et al. bioRxiv: <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/biorxiv/early/2024/04/30/2020.06.09.142950.full.pdf">https://www.biorxiv.org/content/biorxiv/early/2024/04/30/2020.06.09.142950.full.pdf</ext-link>).</p></disp-quote><p>Previously published studies in animal models by us and others suggests that EFRs elicited to AM rates &gt; 700Hz are most sensitive to confirmed CND (Parthasarathy and Kujawa 2018; Shaheen, Valero, and Liberman 2015). This is likely because these AM rates fall well outside of phase-locking limits in the auditory midbrain and cortex (Joris, Schreiner, and Rees 2004), and hence represent a ‘cleaner’ signal from the auditory periphery that may not be modulated by complex excitatory/inhibitory feedback circuits present more centrally (Caspary et al. 2008). We have also demonstrated that we are able to acquire high quality EFRs at 1024Hz AM rates both in a previously published study in young normal hearing adults (McHaney et al. 2024), and in middle aged adults in the present study as seen in Fig. 1 H-J. We posit that the lack of age-related differences at the lower AM rates may be indicative of compensatory plasticity with age (central ‘gain’) that occurs with age in more central regions of the auditory pathway (Auerbach, Radziwon, and Salvi 2019; Parthasarathy and Kujawa 2018). We now expand on this in the discussion. A secondary reason for the lack of change in slower modulation rates may be the difference in stimulus between sinusoidally amplitude modulated tones used here, and the rectangular amplitude modulated tones in other studies, as discussed in response to the comment below.</p><disp-quote content-type="editor-comment"><p>Furthermore, some previous EEG experiments in humans that SAM tones with modulation freqs. of ~100Hz showed that EFRs do not exhibit a single peak, i.e. there are peaks not only at fm but also for the first harmonics (e.g. 2<italic>fm or 3</italic>fm) see e.g. Garrett et al. bioRxiv <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/biorxiv/early/2024/04/30/2020.06.09.142950.full.pdf">https://www.biorxiv.org/content/biorxiv/early/2024/04/30/2020.06.09.142950.full.pdf</ext-link>. Did the authors try to extract EFR strength by looking at the summed amplitude of multiple peaks (Vasilikov Hear Res. 2021), in particular for the lower modulation frequencies? (indeed, there will be no harmonics for the higher mod. freqs).</p></disp-quote><p>We examined peak amplitudes for the AM rate and harmonics for the 110 Hz AM condition as shown in Author response image 2. The quantified amplitudes of the first four harmonics did not differ with age (ps &gt; .08).</p><p>Additionally, the harmonic structures obtained were also not as robust as would be expected with rectangular amplitude modulated stimuli. The choice of sinusoidal modulation may explain why. We have previously published studies systematically modulating the rise time of the envelope per cycle in amplitude modulated tones, where the individual period of the envelope is described by Env (t) = t<sup>x</sup> (1-t), where t goes from 0 to 1 in one period, and where x = 0.05 represents a highly damped envelope akin to the rising envelope f a rectangular modulation, and x = 1 representing a symmetric, near-sinusoidal envelope (Parthasarathy and Bartlett 2011). The harmonic structure was much more developed in the damped envelopes compared to the symmetric envelopes and response amplitudes were also higher for the damped envelopes overall, a result also observed in Mepani et. al., 2021. Hence, we believe the rapid rise time may contribute to the harmonic structures evidenced in studies using RAM stimuli, and the absence of this rapid onset may result in reduced harmonic structures in our EFRs. Some language regarding this issue is now added to the discussion.</p><fig id="sa3fig2" position="float"><label>Author response image 2.</label><caption><title>Harmonics analysis for the first four harmonics of envelope following responses elicited to the 110Hz AM stimulus.</title></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-102823-sa3-fig2-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>b) How do the present EFR results relate to FFR results, where effects of age are already at low carrier freqs? (e.g. Märcher-Rørsted et al., Hear. Res., 2022 for pure tones with freq &lt; 500 Hz). Do the authors think it could be explained by the fact that this is not the same cochlear region, and that synapses die earlier in higher compared to lower CFs? This should be discussed. Beyond the main group effect of age, there were no negative correlations of EFRs with age in the data?</p></disp-quote><p>We believe the current results are in close agreement with these studies showing deficits in pure tone phase locking with age. These tones are typically at ~300-500Hz or above, and phase locking to these tones likely involves the same or similar peripheral neural generators in the auditory nerve and brainstem. Emerging evidence also seems to suggest that TFS coding measured using pure tone phase locking is closely related to sound with amplitude modulation in the same range (Ponsot et al. 2024). Unpublished observations from our lab support this view as well. In this data set, we begin to see EFR responses at 512 Hz diverge with age, but this difference does not reach statistical significance. This may be due to specific AM frequencies selected or a lack of statistical power. Using more continuous AM frequency sweeps such as with our recently published dynamic amplitude modulated tones (Parida et al. 2024) may help resolve these AM frequency specific challenges and help us investigate changes over a broader range of AM frequencies. Ongoing studies are currently exploring this hypothesis. Some explanatory language is now presented in the discussion.</p><disp-quote content-type="editor-comment"><p>(2) Size of the effects / comparing age effects between two species:</p><p>Although the size of the age effect on EFRs cannot be directly compared between humans and gerbils - the comparison remains qualitative - could the authors at least provide references regarding the rate of synaptic loss with aging in both humans and gerbils, so that we understand that the yNH/MA difference can be compared between the two age groups used for gerbils; it would have been critical in case of a non-significant age effect in one species.</p></disp-quote><p>Current evidence seems to suggest that humans have more synaptic loss than gerbils, though exact comparison of lifespan between the two species is challenging due to differences in slopes of growth trajectories between species. Post-mortem temporal bone studies demonstrate a ~40-50% loss of synapses in humans by the fifth decade of life. On the other hand, our gerbils in the current study showed approximately 15-20% loss. Based on our findings and previous studies, it is reasonable to assume that our gerbil data underestimate the temporal processing deficits that would be seen in humans due to CND.</p><p>We have added this information and citations to the discussion section.</p><disp-quote content-type="editor-comment"><p>Equalization/control of stimuli differences across the two species: For measuring EFRs, SAM stimuli were presented at 85 dB SPL for humans vs. 30 dB above the detection threshold (inferred from ABRs) for gerbils - I do not think the results strongly depend on this choice, but it would be good to comment on why you did not choose also to present stimuli 30 dB above thresholds in humans.</p></disp-quote><p>We chose to record EFRs to stimuli presented at 85 dB SPL in humans, as opposed to 30 dB SL, because 30 dB SL in humans would have corresponded to an intensity that makes EEG recordings unfeasible. The average PTA across younger and middle-aged adults was 7.51 dB HL (~19.51 dB SPL), which would have resulted in an average stimulus intensity of ~50 dB SPL at 30 dB SL. This intensity level would have been far too low to reliably record EFRs without presenting many thousands of trials. In a pilot study, we recorded EFRs at 75 dB SL, which equated to an average of 83.9 dB SPL. Thus, we chose the suprathreshold level of 85 dB SPL for the current study to obtain reliable responses with just 1000 trials.</p><disp-quote content-type="editor-comment"><p>Simulations of EFRs using functional models could have been used to understand (at least in humans) how the differences in EFRs obtained between the two groups are <italic>quantitatively</italic> compatible with the differences in % of remaining synaptic connections known from histopathological studies for their age range (see the approach in Märcher-Rørsted et al., Hear. Res., 2022)</p></disp-quote><p>We agree with the reviewer that phenomenological models would be a useful approach to examining differences between age groups and species. We have previously used the Zilany/Carney model to examine differences in EFRs with age in rats (Parthasarathy, Lai, and Bartlett 2016). It is unclear if such models will directly translate to responses form gerbils. However, this is a subject of ongoing study in our lab.</p><disp-quote content-type="editor-comment"><p>(3) Synergetic effects of CND and listening effort:</p><p>Could you test whether there is an interaction between CND and listening effort? (e.g. one could hypothesize that MA subjects with the largest CND have also higher listening effort).</p></disp-quote><p>We have previously reported that EFRs and listening effort are not linearly related (McHaney et al. 2024). We found the same to be largely true in the current study as well. We ran correlations between EFR amplitudes at 1024 Hz and listening effort at each SNR level in the listening and integrations windows. We did not observe any significant relationships between EFRs at 1024 Hz and listening effort in the listening window (all <italic>ps</italic> &gt; .05). In the integration window, we did see a significant correlation between listening effort at SNR 5 and EFRs at 1024 Hz, which was significant after correcting for multiple comparisons (<italic>r</italic> = -.42, <italic>p</italic>-adj = .021). However, we chose to not report these multiple oneto-one correlations in the current study and instead opted for the elastic net regression analysis to better understand the multifactorial contributions to speech-in-noise abilities. These results also do not preclude non-linear relationships between listening effort and EFRs which may be present based on emerging results (Bramhall, Buran, and McMillan 2025), and will be explored in future studies.</p><disp-quote content-type="editor-comment"><p><bold>Recommendations for the authors:</bold></p><p><bold>Reviewer #1 (Recommendations for the authors):</bold></p><p>A few more minor comments/questions:</p><p>(1) How old were the YA gerbils on average? 18 weeks, or 19 weeks, or 22 weeks?</p></disp-quote><p>Young gerbils were on average 22 weeks. We have updated the manuscript accordingly.</p><disp-quote content-type="editor-comment"><p>(2) &quot;Gerbils share the same hearing frequency range as humans&quot; is misleading; the gerbil hearing range extends to much higher frequencies.</p></disp-quote><p>We have revised the statement to say: “The hearing range of gerbils largely overlaps with that of humans, making them an ideal animal model for direct comparison in crossspecies studies.”</p><disp-quote content-type="editor-comment"><p>(3) The writing contains more than a few typos and grammatical errors.</p></disp-quote><p>We have completed a thorough revision to correct for grammatical and typographical errors.</p><disp-quote content-type="editor-comment"><p>(4) Suggesting that correlation and linear modelling are &quot;independent&quot; methods is misleading since they are both measuring linear associations. A better word would be &quot;different&quot;.</p></disp-quote><p>Thank you for this suggestion. We have rephrased the sentence as “two separate approaches”</p><disp-quote content-type="editor-comment"><p>(5) The phrase &quot;Our results reveal perceptual deficits ... driven by CND&quot; in the abstract is too strong. Correlation is not causation.</p></disp-quote><p>We have revised this phrase to say they “are associated with CND.”</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations for the authors):</bold></p><p>More general comments:</p><p>(1) Recruitment criterion related to hearing-in-noise difficulties:</p><p>If I understood correctly, the middle-aged participants recruited for this study do not have specific hearing in noise difficulties, some could, as with 10% in the general population, but they were not recruited using this criterion. If this is correct, this should be stated explicitly, as it constitutes an important methodological choice and a difference with your eLife 2020 study. If you were to use this specific recruitment criterion for both groups here, what differences would you expect?</p></disp-quote><p>Our participants were not required to have specific complaints of speech perception in noise challenges to be eligible for this study. We included middle-aged adults here, as opposed to only younger adults as in Parthasarathy et al. (2020), with the assumption that middle-aged adults were likely to have some cochlear synapse loss and individual variability in the degree of synapse loss based on post-mortem data from human temporal bones. We have recently published studies identifying the specific clinical populations of patients with self-perceived hearing loss, including those adults who have received assessments for auditory processing disorders (Cancel et al. 2023). Ongoing studies in the lab are aimed at recruiting from this population.</p><disp-quote content-type="editor-comment"><p>It is striking here that the QuickSIN test does not exhibit the same variability at low SNRS here as with the digits-in-noise used in your eLife 2020 study. Why would QuickSIN more appropriate than the Digits-in-noise test? Would you expect the same results with the Digits-in-noise test?</p></disp-quote><p>Our 2020 eLife study investigated the effects of TFS coding in multi-talker speech intelligibility. TFS coding is specifically hypothesized to be related to multi-talker speech, compared to broadband maskers. The digits test was appropriate in that context as the ‘masker’ there was two competing speakers also speaking digits. In this study, we wanted to test the effects of CND on speech in noise perception using clinically relevant speech in noise tests. The Digits test is devoid of linguistic context and is essentially closed set (participants know that only a digit will be presented). However, QuickSIN consists of open set sentences of moderate context, making it closer to real world listening situations. Additionally, we recently published pupillometry recorded in response to QuickSIN in young adults (McHaney et al. 2024) and identified QuickSIN as a promising screening tool for self-perceived hearing difficulties (Cancel et al. 2023). These factors informed our choice of using QuickSIN in the current study.</p><disp-quote content-type="editor-comment"><p>(2) Why is the increase in listening effort interpreted as an increase in gain? please clarify (p10, 1st paragraph; [these data suggest a decrease in peripheral neural coding, with a concomitant increase in central auditory activity or 'gain'])</p></disp-quote><p>In the above referenced paragraph, we were discussing the increase in 40 Hz AM rate EFRs in middle-aged adults as an increase in central gain. We have revised parts of this paragraph to better communicate that we were discussing the EFRs and not listening effort: “We observed decreases in EFRs at modulation rates that were selective to the auditory periphery (i.e., 1024 Hz) in middle-aged adults, while EFRs primarily generated from the central auditory structures were not different from those in younger adults (Fig. 1K). These data suggest that middle-aged adults exhibited an increase in central auditory activity, or ‘gain’, in the presence of decreased peripheral neural coding. The perceptual consequences of this gain are unclear, but our findings align with emerging evidence suggesting that gain is associated with selective deficits in speech-in-noise abilities”</p><disp-quote content-type="editor-comment"><p>(3) Further discussion on the relationship/differences between markers EFR marker of CND (this study) and MEMR marker of CND(Bharadwaj et al., 2022) is needed.</p></disp-quote><p>We now make mention of other candidate markers of CND (ABR wave I and MEMRs) in the discussion and expand on why we chose the EFR.</p><disp-quote content-type="editor-comment"><p>(4) Further analyses and discussion would be needed to be related to extended high-freq thresholds:</p><p>Did you test for a potential correlation of your EFR marker of CND with extended high-freq. thresholds ? (could be paralleling the amount of CND in these individuals) Why won't you also consider measuring extended HF in Gerbils?</p></disp-quote><p>We acknowledge that there is increasing evidence to suggest extended high frequency thresholds may be an early marker for hidden hearing loss/CND. We have examined an additional correlation for extended high frequency pure tone averages (8k-16k Hz) with EFR amplitudes at 1024 Hz AM rate, which revealed a significant relationship (<italic>r</italic> = -.43, <italic>p</italic> &lt; .001). However, we opted to exclude this analysis from our current study as we wanted to reduce reporting on several one-to-one correlations. Therefore, we chose the elastic net regression model to examine individual contributions to speech in noise abilities. EHF thresholds were included in the elastic net regression models, but were not found to be significant upon accounting for individual differences in PTA.</p><p>Additionally, our electrophysiological experimental paradigm was not designed with the consideration of extended high frequencies—we used ER3C transducers which are not optimal for frequencies above ~6kHz. Future studies could use transducers such as the ER2 or free field speakers to examine the influence of extended high frequencies on the EFRs and measure high frequency thresholds in gerbils.</p><disp-quote content-type="editor-comment"><p>Minor Comments:</p><p>(1) Abstract: repetition of 'later in life' in the first two sentences - please reformulate.</p></disp-quote><p>We have revised the first two sentences to state: “Middle-age is a critical period of rapid changes in brain function that presents an opportunity for early diagnostics and intervention for neurodegenerative conditions later in life. Hearing loss is one such early indicator linked to many comorbidities in older age.”</p><disp-quote content-type="editor-comment"><p>(2) Sentence on page 3 [However, these behavioral readouts may minimize subliminal changes in perception that are reflected in listening effort but not in accuracies (26-28)] is not clear.</p></disp-quote><p>We’ve added a sentence just after that states: “Specifically, two individuals may show similar accuracies on a listening task, but one individual may need to exert substantially more listening effort to achieve the same accuracy as the other.”</p><disp-quote content-type="editor-comment"><p>(3) The second paragraph of page 11 should go to a methods (model) section, not to the discussion.</p></disp-quote><p>We have now moved a portion of this paragraph to the Elastic Net Regression subsection of the Statistical Analysis in the Methods.</p><disp-quote content-type="editor-comment"><p>(4) Please checks references: references 13 and 25 are identical.</p></disp-quote><p>Fixed</p><p>References</p><p>Auerbach, Benjamin D., Kelly Radziwon, and Richard Salvi. 2019. “Testing the Central Gain Model: Loudness Growth Correlates with Central Auditory Gain Enhancement in a Rodent Model of Hyperacusis.” Neuroscience 407:93–107. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroscience.2018.09.036">https://doi.org/10.1016/j.neuroscience.2018.09.036</ext-link>.</p><p>Bramhall, Naomi F., Brad N. Buran, and Garnett P. McMillan. 2025. “Associations Between Physiological Indicators of Cochlear Deafferentation and Listening Effort in Military Veterans with Normal Audiograms.” Hearing Research, April, 109263. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.heares.2025.109263">https://doi.org/10.1016/j.heares.2025.109263</ext-link>.</p><p>Cancel, Victoria E., Jacie R. McHaney, Virginia Milne, Catherine Palmer, and Aravindakshan Parthasarathy. 2023. “A Data-Driven Approach to Identify a Rapid Screener for Auditory Processing Disorder Testing Referrals in Adults.” Scientific Reports 13 (1): 13636. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41598-023-40645-0">https://doi.org/10.1038/s41598-023-40645-0</ext-link>.</p><p>Caspary, D. M., L. Ling, J. G. Turner, and L. F. Hughes. 2008. “Inhibitory Neurotransmission, Plasticity and Aging in the Mammalian Central Auditory System.” Journal of Experimental Biology 211 (11): 1781–91. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1242/jeb.013581">https://doi.org/10.1242/jeb.013581</ext-link>.</p><p>Cohen, Jacob. 2013. Statistical Power Analysis for the Behavioral Sciences. 2nd ed. New York: Routledge. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.4324/9780203771587">https://doi.org/10.4324/9780203771587</ext-link>.</p><p>Encina-Llamas, Gerard, Aravindakshan Parthasarathy, James Michael Harte, Torsten Dau, Sharon G. Kujawa, Barbara Shinn-Cunningham, and Bastian Epp. 2017. “Hidden Hearing Loss with Envelope Following Responses (EFRs): The off-Frequency Problem: 40th MidWinter Meeting of the Association for Research in Otolaryngology.” In .</p><p>James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2021. An Introduction to Statistical Learning: With Applications in R. Springer Texts in Statistics. New York, NY: Springer US. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/978-1-0716-1418-1">https://doi.org/10.1007/978-1-0716-1418-1</ext-link>.</p><p>Joris, P. X., C. E. Schreiner, and A. Rees. 2004. “Neural Processing of Amplitude-Modulated Sounds.” Physiological Reviews 84 (2): 541–77. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/physrev.00029.2003">https://doi.org/10.1152/physrev.00029.2003</ext-link>.</p><p>McHaney, Jacie R., Kenneth E. Hancock, Daniel B. Polley, and Aravindakshan Parthasarathy. 2024. “Sensory Representations and Pupil-Indexed Listening Effort Provide Complementary Contributions to Multi-Talker Speech Intelligibility.” Scientific Reports 14 (1): 30882. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41598-024-81673-8">https://doi.org/10.1038/s41598-024-81673-8</ext-link>.</p><p>Parida, Satyabrata, Kimberly Yurasits, Victoria E. Cancel, Maggie E. Zink, Claire Mitchell, Meredith C. Ziliak, Audrey V. Harrison, Edward L. Bartlett, and Aravindakshan Parthasarathy. 2024. “Rapid and Objective Assessment of Auditory Temporal Processing Using Dynamic Amplitude-Modulated Stimuli.” Communications Biology 7 (1): 1–10. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s42003-024-07187-1">https://doi.org/10.1038/s42003-024-07187-1</ext-link>.</p><p>Parthasarathy, A., and E. L. Bartlett. 2011. “Age-Related Auditory Deficits in Temporal Processing in F-344 Rats.” Neuroscience 192:619–30. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroscience.2011.06.042">https://doi.org/10.1016/j.neuroscience.2011.06.042</ext-link>.</p><p>Parthasarathy, A., J. Lai, and E. L. Bartlett. 2016. “Age-Related Changes in Processing Simultaneous Amplitude Modulated Sounds Assessed Using Envelope Following Responses.” Jaro-Journal of the Association for Research in Otolaryngology 17 (2): 119–32. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10162-016-0554-z">https://doi.org/10.1007/s10162-016-0554-z</ext-link>.</p><p>Parthasarathy, A., Kenneth E Hancock, Kara Bennett, Victor DeGruttola, and Daniel B Polley. 2020. “Bottom-up and Top-down Neural Signatures of Disordered Multi-Talker Speech Perception in Adults with Normal Hearing.” Edited by Barbara G Shinn-Cunningham, Huan Luo, Fan-Gang Zeng, and Christian Lorenzi. eLife 9 (January):e51419. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7554/eLife.51419">https://doi.org/10.7554/eLife.51419</ext-link>.</p><p>Parthasarathy, Aravindakshan, and Sharon G. Kujawa. 2018. “Synaptopathy in the Aging Cochlea: Characterizing Early-Neural Deficits in Auditory Temporal Envelope Processing.” The Journal of Neuroscience. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/jneurosci.324017.2018">https://doi.org/10.1523/jneurosci.324017.2018</ext-link>.</p><p>Ponsot, Emmanuel, Pauline Devolder, Ingeborg Dhooge, and Sarah Verhulst. 2024. “AgeRelated Decline in Neural Phase-Locking to Envelope and Temporal Fine Structure Revealed by Frequency Following Responses: A Potential Signature of Cochlear Synaptopathy Impairing Speech Intelligibility.” bioRxiv. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/2024.12.11.628010">https://doi.org/10.1101/2024.12.11.628010</ext-link>.</p><p>Sergeyenko, Yevgeniya, Kumud Lall, M. Charles Liberman, and Sharon G. Kujawa. 2013. “Age-Related Cochlear Synaptopathy: An Early-Onset Contributor to Auditory Functional Decline.” Journal of Neuroscience 33 (34): 13686–94. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/jneurosci.1783-13.2013">https://doi.org/10.1523/jneurosci.1783-13.2013</ext-link>.</p><p>Shaheen, L. A., M. D. Valero, and M. C. Liberman. 2015. “Towards a Diagnosis of Cochlear Neuropathy with Envelope Following Responses.” J Assoc Res Otolaryngol. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10162-015-0539-3">https://doi.org/10.1007/s10162-015-0539-3</ext-link>.</p><p>Tibshirani, Ryan J., and Jonathan Taylor. 2012. “Degrees of Freedom in Lasso Problems.” The Annals of Statistics 40 (2): 1198–1232. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1214/12-AOS1003">https://doi.org/10.1214/12-AOS1003</ext-link>.</p><p>Wu, P. Z., L. D. Liberman, K. Bennett, V. de Gruttola, J. T. O’Malley, and M. C. Liberman. 2018. “Primary Neural Degeneration in the Human Cochlea: Evidence for Hidden Hearing Loss in the Aging Ear.” Neuroscience. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuroscience.2018.07.053">https://doi.org/10.1016/j.neuroscience.2018.07.053</ext-link>.</p></body></sub-article></article>