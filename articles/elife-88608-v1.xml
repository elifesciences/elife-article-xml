<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">88608</article-id><article-id pub-id-type="doi">10.7554/eLife.88608</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.88608.3</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>A neural network model of differentiation and integration of competing memories</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Ritvo</surname><given-names>Victoria JH</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Nguyen</surname><given-names>Alex</given-names></name><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Turk-Browne</surname><given-names>Nicholas B</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7519-3001</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Norman</surname><given-names>Kenneth A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-5887-9682</contrib-id><email>knorman@princeton.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hx57361</institution-id><institution>Department of Psychology, Princeton University</institution></institution-wrap><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hx57361</institution-id><institution>Princeton Neuroscience Institute, Princeton University</institution></institution-wrap><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Department of Psychology, Yale University</institution></institution-wrap><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03v76x132</institution-id><institution>Wu Tsai Institute, Yale University</institution></institution-wrap><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Schlichting</surname><given-names>Margaret L</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03dbr7087</institution-id><institution>University of Toronto</institution></institution-wrap><country>Canada</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>25</day><month>09</month><year>2024</year></pub-date><volume>12</volume><elocation-id>RP88608</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-04-18"><day>18</day><month>04</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-04-13"><day>13</day><month>04</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.04.02.535239"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-06-14"><day>14</day><month>06</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.88608.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-08-14"><day>14</day><month>08</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.88608.2"/></event></pub-history><permissions><copyright-statement>© 2023, Ritvo et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Ritvo et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-88608-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-88608-figures-v1.pdf"/><abstract><p>What determines when neural representations of memories move together (integrate) or apart (differentiate)? Classic supervised learning models posit that, when two stimuli predict similar outcomes, their representations should integrate. However, these models have recently been challenged by studies showing that pairing two stimuli with a shared associate can sometimes cause differentiation, depending on the parameters of the study and the brain region being examined. Here, we provide a purely unsupervised neural network model that can explain these and other related findings. The model can exhibit integration or differentiation depending on the amount of activity allowed to spread to competitors — inactive memories are not modified, connections to moderately active competitors are weakened (leading to differentiation), and connections to highly active competitors are strengthened (leading to integration). The model also makes several novel predictions — most importantly, that when differentiation occurs as a result of this unsupervised learning mechanism, it will be rapid and asymmetric, and it will give rise to anticorrelated representations in the region of the brain that is the source of the differentiation. Overall, these modeling results provide a computational explanation for a diverse set of seemingly contradictory empirical findings in the memory literature, as well as new insights into the dynamics at play during learning.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>neural networks</kwd><kwd>unsupervised learning</kwd><kwd>memory</kwd><kwd>computational modeling</kwd><kwd>representational change</kwd><kwd>fMRI</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>MH069456</award-id><principal-award-recipient><name><surname>Turk-Browne</surname><given-names>Nicholas B</given-names></name><name><surname>Norman</surname><given-names>Kenneth A</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>A computational neural network model leverages a simple unsupervised learning principle to account for recent findings on when memories move apart (differentiate) or together (integrate) in the brain.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>As we learn, our neural representations change: The representations of some memories move together (i.e. they integrate), allowing us to generalize, whereas the representations of other memories move apart (i.e. they differentiate), allowing us to discriminate. In this way, our memory system plays a delicate balancing act to create the complicated and vast array of knowledge we hold. But ultimately, learning itself is a very simple process: strengthening or weakening individual neural connections. How can a simple learning rule on the level of individual neural connections account for both differentiation and integration of entire memories, and what factors lead to both outcomes?</p><p>Classic supervised learning models (<xref ref-type="bibr" rid="bib49">Rumelhart et al., 1986</xref>; <xref ref-type="bibr" rid="bib19">Gluck and Myers, 1993</xref>) provide one potential solution. These theories posit that the brain adjusts representations to predict outcomes in the world: When two stimuli predict similar outcomes, their representations become more similar; when they predict different outcomes, their representations become more distinct. Numerous fMRI studies have obtained evidence supporting these theories, by utilizing representational similarity analysis to track how the patterns evoked by similar stimuli change over time (e.g. <xref ref-type="bibr" rid="bib51">Schapiro et al., 2013</xref>; <xref ref-type="bibr" rid="bib52">Schapiro et al., 2016</xref>; <xref ref-type="bibr" rid="bib58">Tompary and Davachi, 2017</xref>).</p><p>However, other studies have found that linking stimuli to shared associates can lead to differentiation rather than integration. For instance, in one fMRI study, differentiation was observed in the hippocampus when participants were tasked with predicting the same face in response to two similar scenes (i.e. two barns), so much so that the two scenes became less neurally similar to each other than they were to unrelated stimuli (<xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>; for related findings, see <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>; <xref ref-type="bibr" rid="bib36">Molitor et al., 2021</xref>; for reviews, see <xref ref-type="bibr" rid="bib7">Brunec et al., 2020</xref>; <xref ref-type="bibr" rid="bib16">Duncan and Schlichting, 2018</xref>; <xref ref-type="bibr" rid="bib48">Ritvo et al., 2019</xref>).</p><p>Findings of this sort present a challenge to supervised learning models, which predict that the connection weights underlying these memories should be adjusted to make them more (not less) similar to each other. This kind of ‘similarity reversal’, whereby stimuli that have more features in common (or share a common associate) show <italic>less</italic> hippocampal pattern similarity, has now been observed in a wide range of studies (e.g. <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>; <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>; <xref ref-type="bibr" rid="bib36">Molitor et al., 2021</xref>; <xref ref-type="bibr" rid="bib8">Chanales et al., 2017</xref>; <xref ref-type="bibr" rid="bib14">Dimsdale-Zucker et al., 2018</xref>; <xref ref-type="bibr" rid="bib61">Wanjia et al., 2021</xref>; <xref ref-type="bibr" rid="bib64">Zeithamova et al., 2018</xref>; <xref ref-type="bibr" rid="bib25">Jiang et al., 2020</xref>; <xref ref-type="bibr" rid="bib18">Fernandez et al., 2023</xref>; <xref ref-type="bibr" rid="bib59">Wammes et al., 2022</xref>).</p><sec id="s1-1"><title>Nonmonotonic plasticity hypothesis</title><p>How can we make sense of these findings? Supervised learning algorithms cannot explain the aforementioned results on their own, so they need to be supplemented by other learning principles. We previously argued (<xref ref-type="bibr" rid="bib48">Ritvo et al., 2019</xref>) that learning algorithms positing a U-shaped relationship between neural activity and synaptic weight change — where low levels of activity at retrieval lead to no change, moderate levels of activity lead to synaptic weakening, and high levels of activity lead to synaptic strengthening — may be able to account for these results; the Bienenstock-Cooper-Munro (BCM) learning rule (<xref ref-type="bibr" rid="bib6">Bienenstock et al., 1982</xref>; <xref ref-type="bibr" rid="bib10">Cooper, 2004</xref>) is the most well-known learning algorithm with this property, but other algorithms with this property have also been proposed (<xref ref-type="bibr" rid="bib41">Norman et al., 2006</xref>; <xref ref-type="bibr" rid="bib13">Diederich and Opper, 1987</xref>). We refer to the U-shaped learning function posited by this type of algorithm as the nonmonotonic plasticity hypothesis (NMPH; <xref ref-type="bibr" rid="bib12">Detre et al., 2013</xref>; <xref ref-type="bibr" rid="bib38">Newman and Norman, 2010</xref>).</p><p>In addition to explaining how individual memories get stronger and weaker, the NMPH also explains how memory representations change with respect to each other as a function of competition during retrieval (<xref ref-type="bibr" rid="bib24">Hulbert and Norman, 2015</xref>; <xref ref-type="bibr" rid="bib41">Norman et al., 2006</xref>). If the activity of a competing memory is low while retrieving a target memory (<xref ref-type="fig" rid="fig1">Figure 1C</xref>), the NMPH predicts no representational change. If competitor activity is moderate (<xref ref-type="fig" rid="fig1">Figure 1B</xref>), the connections to the shared units will be weakened, leading to differentiation. If competitor activity is high (<xref ref-type="fig" rid="fig1">Figure 1A</xref>), the connections to the shared units will be strengthened, leading to integration. Consequently, the NMPH may provide a unified explanation for the divergent studies discussed above: Depending on the amount of excitation allowed to spread to the competitor (which may be affected by task demands, neural inhibition levels, and the similarity of stimuli, among other things), learning may result in no change, differentiation, or integration (for further discussion of the empirical justification for the NMPH, see the Learning subsection in the <italic>Methods</italic>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Nonmonotonic plasticity hypothesis: A has been linked to X, and B has some initial hidden-layer overlap with A.</title><p>In this network, activity is allowed to spread bidirectionally. When B is presented along with X (corresponding to a BX study trial), activity can spread downward from X to the hidden-layer units associated with A, and also — from there — to the input-layer representation of A. (<bold>A</bold>) If activity spreads strongly to the input and hidden representations of A, integration of A and B occurs due to strengthening of connections between all of the strongly activated features (green connections indicate strengthened weights; AB integration can be seen by noting the increase in the number of hidden units receiving projections from both A and B). (<bold>B</bold>) If activity spreads only moderately to the input and hidden representations of A, differentiation of A and B occurs due to weakening of connections between the moderately activated features of A and the strongly activated features of B (green and red connections indicate weights that are strengthened and weakened, respectively; AB differentiation can be seen by noting the decrease in the number of hidden units receiving strong connections from both A and B — in particular, the middle hidden unit no longer receives a strong connection from A). (<bold>C</bold>) If activity does not spread to the features of A, then neither integration nor differentiation occurs. Note that the figure illustrates the consequences of differences in competitor activation for learning, without explaining why these differences would arise. For discussion of circumstances that could lead to varying levels of competitor activation, see the simulations described in the text.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-fig1-v1.tif"/><permissions><copyright-statement>© 2019, Elsevier Science &amp; Technology Journals</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Elsevier Science &amp; Technology Journals</copyright-holder><ali:free_to_read/><license><license-p> Figure 1 was reprinted from Figure 2 of <xref ref-type="bibr" rid="bib48">Ritvo et al., 2019</xref> with permission. It is not covered by the CC-BY 4.0 license and further reproduction of this panel would need permission from the copyright holder.</license-p></license></permissions></fig></sec><sec id="s1-2"><title>Research goal</title><p>In this paper, we present a neural network model that instantiates the aforementioned NMPH learning principles, with the goal of assessing how well these principles can account for extant data on when differentiation and integration occur. In <xref ref-type="bibr" rid="bib48">Ritvo et al., 2019</xref>, we provided a sketch of how certain findings could potentially be explained in terms of the NMPH. However, intuitions about how a complex system should behave are not always accurate in practice, and verbally stated theories can contain ambiguities or internal contradictions that are only exposed when building a working model. Building a model also allows us to generate more detailed predictions (i.e. we can use the model to see what follows from a core set of principles). Relatedly, there are likely boundary conditions on how a model behaves (i.e. it will show a pattern of results in some conditions but not others). Here, we use the model to characterize these boundary conditions, which (in turn) can be translated into new, testable predictions.</p><p>We use the model to simulate three experiments: (1) <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref>, which looked at how the amount of stimulus similarity affected the distortion of color memories; (2) <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>, which looked at representational change for items that were paired with the same or different associates; and (3) <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>, which looked at how the learning curriculum (whether pairs were presented in a blocked or interleaved fashion) modulated representational change in different brain regions. We chose these three experiments because each reported that similar stimuli (neurally) differentiate or (behaviorally) are remembered as being less similar than they actually are, and because they allow us to explore three different ways in which the amount of competitor activity can be modulated.</p><p>The model can account for the results of these studies, and it provides several novel insights. Most importantly, the model shows that differentiation must happen quickly (or it will not happen at all), and that representational change effects are often asymmetric (i.e. one item’s representation changes but the other stays the same).</p><p>The following section provides an overview of general properties of the model. Later sections describe how we implemented the model separately for the three studies.</p></sec><sec id="s1-3"><title>Basic network properties</title><p>We set out to build the simplest possible model that would allow us to explore the role of the NMPH in driving representational change. The model was constructed such that it <italic>only</italic> used unsupervised, U-shaped learning and not supervised learning. Importantly, we do not think that unsupervised, U-shaped learning function is a replacement for error-driven learning; instead, we view it as a supplementary tool the brain uses to reduce interference of competitors (<xref ref-type="bibr" rid="bib48">Ritvo et al., 2019</xref>). Nonetheless, we intentionally omitted supervised learning in order to explore whether unsupervised, U-shaped learning on its own would be sufficient to account for extant findings on differentiation and integration. Achieving a better understanding of unsupervised learning is an important goal for computational neuroscience, given that learning agents have vastly more opportunities to learn in an unsupervised fashion than from direct supervision (for additional discussion of this point, see, e.g., <xref ref-type="bibr" rid="bib68">Zhuang et al., 2021</xref>).</p><p>Because we were specifically interested in the way competition affects learning, we decided to focus on the key moment <italic>after</italic> the memories have been formed, when they first come into competition with each other. Consequently, we pre-wired the initial connections into the network for each stimulus, rather than the allowing the connections to self-organize through learning (see <italic>Methods</italic> for details). Doing so meant we could have control over the exact level of competition between pairmates. We then used the model to simulate different studies, with the goal of assessing how different manipulations that affect competitor activity modulate representational change. In the interest of keeping the simulations simple, we modeled a single task from each study rather than modeling all of them comprehensively. Our goal was to qualitatively fit key patterns of results from each of the aforementioned studies. We fit the parameters of the model by hand as they are highly interdependent (see the <italic>Methods</italic> section for more details).</p></sec><sec id="s1-4"><title>Model architecture</title><p>The model was built using the Emergent simulation framework (<xref ref-type="bibr" rid="bib1">Aisa et al., 2008</xref>). All versions of the model have the same basic architecture (<xref ref-type="fig" rid="fig2">Figure 2</xref>; see the following sections for how the model was adapted for each version, and the <italic>Methods</italic> section for the details of all parameters).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Basic network architecture: The characteristics of the model common to all versions we tested, with hidden- and input-layer activity for pairmate A.</title><p>Black arrows indicate projections common to all versions of the model. All projections were fully connected. Pre-wired, stronger connections between the input A unit (top row of item layer) and hidden A units (purple) are shown, and pre-wired, stronger connections between the input B unit (bottom row of item layer) and hidden B units (pink) are shown. The category unit is pre-wired to connect strongly to all hidden A and B units. Hidden A units have strong connections to other hidden A units (not shown); the same is true for hidden B units. Pre-wired, stronger connections also exist between hidden and output layers (not shown). The arrangement of these hidden-to-output connections varies for each version of the model.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-fig2-v1.tif"/></fig><p>We wanted to include the minimal set of layers needed to account for the data. Importantly, the model is meant to be as generic as possible, so none of the layers are meant to correspond to a particular brain region (we discuss possible anatomical correspondences in the <italic>Discussion</italic> section). With those points in mind, we built the model to include four layers: category, item, hidden, and output. The category and item layers are input layers that represent the sensory or semantic features of the presented stimuli; generally speaking, we use the category layer to represent features that are shared across multiple stimuli, and we use the item layer to represent features that are unique to particular stimuli. The hidden layer contains the model’s internal representation of these stimuli, and the output layer represents either additional sensory features of the input stimulus, or else other stimuli that are associated with the input stimulus. In all models, the category and item layers are bidirectionally connected to the hidden layer; the hidden layer is bidirectionally connected to the output layer; and the hidden layer also has recurrent connections back to itself. All of these connections are modifiable through learning. Note that the hidden layer has modifiable connections to all layers in the network (including itself), which makes it ideally positioned to bind together the features of individual stimuli.</p><p>Each version of the model learns two pairmates, which are stimuli (binary vectors) represented by units in the input layers. The presentation of a stimulus involves activating a single unit in each of the input layers (i.e. the category and item layers). Pairmates share the same unit in the category layer, but differ in their item-layer unit.</p><p>We labeled the item-layer units such that the unit in the top row was associated with pairmate A and the unit in the bottom row was associated with pairmate B. Since either pairmate could be shown first, we refer to them as pairmate 1 or 2 when the order is relevant: Pairmate 1 is whichever pairmate is shown on the first trial and pairmate 2 is the item shown second.</p><p>All projections as described above have weak, randomly-sampled weight values, but we additionally pre-built some structured knowledge into the network. The item-layer input units have pre-wired, stronger connections to a selection of six pre-assigned ‘pairmate A’ hidden units and six pre-assigned ‘pairmate B’ units. The A and B hidden representations overlap to some degree (for instance, with two units shared, as shown in <xref ref-type="fig" rid="fig2">Figure 2</xref>). We decided to arrange the hidden layer along a single dimension so that the amount of overlap could be easily visualized and interpreted.</p><p>Hidden units representing each individual item start out strongly interconnected (that is, the six pairmate A units are linked together by maximally strong recurrent connections, as are the six pairmate B units). We also pre-wired some stronger connections between these hidden A and B units and the output units, but the setup of the hidden-to-output pre-wired connections depends on the modeled experiment.</p></sec><sec id="s1-5"><title>Inhibitory dynamics</title><p>Within a layer, inhibitory competition between units was enforced through an adapted version of the k-winners-take-all (kWTA) algorithm (<xref ref-type="bibr" rid="bib43">O’Reilly and Munakata, 2000</xref>; see <italic>Methods</italic>) which limits the amount of activity in a layer to at most <inline-formula><mml:math id="inf1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi></mml:mstyle></mml:math></inline-formula> units. The kWTA algorithm provides a useful way of capturing the ‘set-point’ quality of inhibitory neurons without requiring the inclusion of these neurons directly.</p><p>The main method we use to allow activity to spread to the competitor is through inhibitory oscillations. Prior work has argued that inhibitory oscillations could play a key role in this kind of competition-dependent learning (<xref ref-type="bibr" rid="bib41">Norman et al., 2006</xref>; <xref ref-type="bibr" rid="bib42">Norman et al., 2007</xref>; <xref ref-type="bibr" rid="bib56">Singh et al., 2022</xref>). Depending on how much excitation a competing memory is receiving, lowering the level of inhibition can allow competing memories that are inactive at baseline levels of inhibition to become moderately active (causing their connections to the target memory to be weakened) or even strongly active (causing their connections to the target memory to be strengthened). Our model implements oscillations through a sinusoidal function which lowers and raises inhibition over the course of the trial, allowing competitors to ‘pop up’ when inhibition is lower.</p></sec><sec id="s1-6"><title>Learning</title><p>Connection strengths in the model between pairs of connected units <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>x</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula> were adjusted at the end of each trial (i.e. after each stimulus presentation) as a U-shaped function of the coactivity of <inline-formula><mml:math id="inf4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>x</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>y</mml:mi></mml:mstyle></mml:math></inline-formula>, defined as the product of their activations on that trial. The parameters of the U-shaped learning function relating coactivity to change in connection strength (i.e. weakening / strengthening) were specified differently for each projection where learning occurs (bidirectionally between the input and hidden layers, the hidden layer to itself, and the hidden to output layer). Once the U-shaped learning function for each projection in each version of the model was specified, we did not change it for any of the various conditions. Details of how we computed coactivity and how we specified the U-shaped function can be found in the <italic>Methods</italic> section.</p></sec><sec id="s1-7"><title>Competition</title><p>Constructing the network in this way allows us to precisely control the amount of competition between pairmates. There are several ways beside amplitude of oscillations to alter the amount of excitation spreading to the competitor. For instance, competitor activity could be modulated by altering the pre-wired weights to force the hidden-layer representations for A and B to share more units. Each version of the model (for each experiment) relies on a different method to modulate the amount of competitor activity.</p></sec><sec id="s1-8"><title>Model of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref>: repulsion and attraction of color memories</title><sec id="s1-8-1"><title>Key experimental findings</title><p>The first experiment we modeled was <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref>. The study was inspired by recent neuroimaging studies showing ‘similarity reversals’, wherein stimuli that have more features in common (or share a common associate) show less hippocampal pattern similarity (<xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>; <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>; <xref ref-type="bibr" rid="bib36">Molitor et al., 2021</xref>; <xref ref-type="bibr" rid="bib8">Chanales et al., 2017</xref>; <xref ref-type="bibr" rid="bib14">Dimsdale-Zucker et al., 2018</xref>; <xref ref-type="bibr" rid="bib61">Wanjia et al., 2021</xref>; <xref ref-type="bibr" rid="bib64">Zeithamova et al., 2018</xref>; <xref ref-type="bibr" rid="bib25">Jiang et al., 2020</xref>; <xref ref-type="bibr" rid="bib59">Wammes et al., 2022</xref>). <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> tested whether a similar ‘repulsion’ effect is observed with respect to how the specific features of competing events are retrieved. In their experiments, participants learned associations between objects and faces (<xref ref-type="fig" rid="fig3">Figure 3A</xref>). Specifically, participants studied pairs of objects that were identical except for their color value; each of these object pairmates was associated with a unique face. Participants’ memory was tested in several ways; in one of these tests — the color recall task — the face was shown as a cue alongside the colorless object, and participants were instructed to report the color of the object on a continuous color wheel.</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Modeling <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref>.</title><p>(<bold>A</bold>) Participants in <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> learned to associate objects and faces (faces not shown here due to bioRxiv rules). The objects consisted of pairs that were identical except for their color value, and the difference between pairmate color values was systematically manipulated to adjust competition. Color memory was tested in a task where the face and colorless object were given as a cue, and participants had to use a continuous color wheel to report the color of the object. Color reports could be biased toward (+) or away from the competitor (-). (<bold>B</bold>) When color similarity was low (48°), color reports were accurate. When color similarity was raised to a moderate level (24°), repulsion occurred, such that color reports were biased systematically away from the competitor. When color similarity was raised further (6°), the repulsion effect was eliminated. (<bold>C</bold>) To model this study, we used the network structure described in <italic>Basic Network Properties</italic>, with the following modifications: This model additionally has a non-modifiable recurrent projection in the output layer, to represent the continuous nature of the color space: Each output unit was pre-wired with fixed, maximally strong weights connecting it to the seven units on either side of it (one such set of connections is shown to the output unit colored in green); background output-to-output connections (outside of these seven neighboring units) were set up to be fixed, weak, and random. The hidden layer additionally was initialized to have maximally strong (but learnable) one-to-one connections with units in the output layer, thereby ensuring that the color topography of the output layer was reflected in the hidden layer. Each of the six hidden A units were connected in an all-to-all fashion to the six pre-assigned A units in the output layer via maximally strong, pre-wired weights (purple lines). The same arrangement was made for the hidden B units (pink lines). Other connections between the output and hidden layers were initialized to lower values. In the figure, activity is shown after pairmate A is presented — the recurrent output-to-output connections let activity spread to units on either side. (<bold>D</bold>) We included six conditions in this model, corresponding to different numbers of shared units in the hidden and output layers. Three conditions are shown here. The conditions are labeled by the number of hidden/output units shared by A and B. Thus, one unit is shared by A and B in 1/6, two units are shared by A and B in 2/6, and so on. Increased overlap in the hidden and output layers is meant to reflect higher levels of color similarity in the experiment. We included overlap types from 0/6 to 5/6.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-fig3-v1.tif"/><permissions><copyright-statement>© 2021, Sage Publications</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Sage Publications</copyright-holder><license><license-p>Figure 3A was adapted from Figures 1 and 3 of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> with permission, and Figure 3B was adapted from Figure 3 of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> with permission. These panels are not covered by the CC-BY 4.0 license and further reproduction of these panels would need permission from the copyright holder.</license-p></license></permissions></fig><p><xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> found that, for low levels of pairmate color similarity (i.e. 72° and 48° color difference), participants were able to recall the colors accurately when cued with a face and an object. However, when color similarity was increased (i.e. 24° color difference), the color reports were biased <italic>away</italic> from the pairmate, leading to a repulsion effect. For instance, if the pairmates consisted of a red jacket and a red-but-slightly-orange jacket, repulsion would mean that the slightly-orange jacket would be recalled as less red and more yellow than it actually was. When the color similarity was increased even further (i.e. 6° color difference), the repulsion effects were eliminated (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). For a related result showing repulsion with continuously varying face features (gender, age) instead of color, see <xref ref-type="bibr" rid="bib15">Drascher and Kuhl, 2022</xref>.</p></sec><sec id="s1-8-2"><title>Potential NMPH explanation</title><p>Typical error-driven learning would not predict this outcome, because it would adjust weights to align the guess more closely with the true outcome, leading to no repulsion effects. In contrast, the NMPH potentially explains the results of this study well; as the authors note, “the relationship between similarity and the repulsion effect followed an inverted-U-shape function, suggesting a sweet spot at which repulsion occurs” (<xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref>).</p><p>The amount of color similarity provides a way of modulating the amount of excitation that can flow to the competitor’s neural representation. When color similarity is lower (i.e. 72° and 48°), the competing pairmate is less likely to come to mind. Consequently, the competitor’s activity will be on the low/left side of the U-shaped function (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). No weakening or strengthening will occur for the competitor, and both pairmate representations remain intact.</p><p>However, when color similarity is higher (i.e. 24°), the additional color overlap means the memories compete more. When the red jacket is shown, the competing red-but-slightly-orange jacket may come to mind moderately, so it falls in the dip of the U-shaped function. If this occurs, the NMPH predicts that the two pairmates will show differentiation, resulting in repulsion in color space.</p><p>When color overlap is highest (i.e. 6°), the repulsion effect was eliminated. The NMPH could explain this result in terms of the competitor getting so much excitation from the high similarity that it falls on the high/right side of the U-shaped function, in the direction of integration (or ‘attraction’ for the behavioral reports of color). <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> did not observe an attraction effect, but this can be explained in terms of the similarity of the pairmates in this condition (at 6° of color separation, there is a limit on how much more similar the color reports could become, given the precision of manual responses).</p></sec></sec><sec id="s1-9"><title>Model set-up</title><sec id="s1-9-1"><title>Model architecture</title><p>To model this task (<xref ref-type="fig" rid="fig3">Figure 3C</xref>), we used the two input layers (i.e. category and item) to represent the colorless object and face associates, respectively. To represent a particular stimulus, we activated a single unit in each of the input layers; pairmates share the same unit in the object layer (i.e. ‘jacket’), but differ in the unit for the face layer (i.e. ‘face-for-jacket-A’ and ‘face-for-jacket B’). The output layer represents the color-selective units. Units that are closer to each other can be thought of as representing colors that are more similar to each other.</p></sec><sec id="s1-9-2"><title>Knowledge built into the network</title><p>As described in <italic>Basic Network Properties</italic>, each of the two input face units is pre-wired to connect strongly to the six corresponding hidden units (either the six hidden A units, or the six hidden B units). In this version of our model, we added several extra pre-wired connections, specifically, recurrent output-to-output connections (although we did not include learning for this projection). Neighboring units were pre-wired to have stronger connections, to instantiate the idea that color is represented in a continuous way in the brain (<xref ref-type="bibr" rid="bib21">Hanazawa et al., 2000</xref>; <xref ref-type="bibr" rid="bib28">Komatsu et al., 1992</xref>).</p><p>The six hidden A units were connected to the corresponding six units in the output layer in an all-to-all fashion via maximally strong weights (such that each A hidden unit was connected to each A output unit); an analogous arrangement was made for the units representing pairmate B. Additionally, each non-pairmate unit in the hidden layer was pre-wired to have a maximally strong connection with the unit directly above it in the output layer. Arranging the units in this way (so the hidden layer matches the topography of the output layer) makes it easier to interpret the types of distortion that occur in the hidden layer.</p></sec><sec id="s1-9-3"><title>Manipulation of competitor activity</title><p>In this experiment, competition is manipulated through the level of color similarity in each condition. We operationalized this by adjusting the level of overlap between the hidden (and output) color A and B units. One advantage of modeling is that, because there is no constraint on experiment length, we were able to sample a wider range of overlap types than the actual study, which was limited to three conditions per experiment. Instead, we used six overlap conditions in the model. For all conditions, the two pairmates were each assigned six units in the hidden layer. However, for the different overlap conditions, we pre-wired the weights from the input layers to the hidden layer so that the two pairmates differed in the number of hidden-layer units that were shared (note that this overlap manipulation was also reflected in the output layer, because of the pre-wired connections between the hidden and output layers described above).</p><p>We labeled the six conditions based on the number of overlapping units between the pairmates (which varied) and the number of total units per pairmate (which was always six): 0/6 overlap means that the two pairmates are side-by-side but share zero units; 1/6 overlap means they share one unit out of six each; 2/6 overlap means they share two units out of six each, and so on.</p></sec><sec id="s1-9-4"><title>Task</title><p>The task simulated in the model is a simplified version of the paradigm used in <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref>. Specifically, we focused on the color recall task, where the colorless object was shown alongside the face cue, and the participant had to report the object’s color on a color wheel. To model this, the external input is clamped to the network (object and face units), and activity is allowed to flow through the hidden layer to the color layer so the network can make a color ‘guess’. We ran a test epoch after each training epoch so we could track the representations of pairmates A and B over time.</p><p>As described in <italic>Basic Network Properties</italic>, inhibitory oscillations allow units that are inactive at baseline levels of inhibition to ‘pop up’ toward the end of the trial. This is important for allowing potential competitor units to activate. There is no ‘correct’ color shown to the network, and all learning is based purely on an unsupervised U-shaped learning rule that factors in the coactivity of presynaptic and postsynaptic units (see <italic>Methods</italic> for parameter details).</p></sec></sec><sec id="s1-10"><title>Results</title><sec id="s1-10-1"><title>Effects of color similarity on color recall and neural representations</title><p><xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> showed that, as color similarity was raised, a repulsion effect occurred where the colors of pairmates were remembered as being less similar to each other than they were in reality. When color similarity was raised even further, this repulsion effect went away. In our model, we expected to find a similar U-shaped pattern as hidden-layer overlap increased.</p><p>To measure repulsion, we operationalized the color memory ‘report’ as the center-of-mass of activity in the color output layer at test. Because the topography of the output layer is meaningful for this version of the model (with nearby units representing similar colors), we could measure color attraction and repulsion by the change in the distance between the centers-of-mass (<xref ref-type="fig" rid="fig4">Figure 4A</xref>): If A and B undergo attraction after learning, the distance between the color centers-of-mass should decrease. If A and B undergo repulsion, the distance should increase.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Model of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> results.</title><p>(<bold>A</bold>) The distance (number of units apart) between the centers-of-mass of output activity for A and B is used to measure repulsion vs. attraction. The gray bar indicates what the color difference would be after learning if no change happens from before (gray dots) to after (black dots) learning; above the gray bar indicates repulsion and below indicates attraction. For lower levels of overlap (0/6 and 1/6), color distance remains unchanged. For a medium level of overlap (2/6), repulsion occurs, shown by the increase in the number of units between A and B. For higher levels of overlap (3/6, 4/6, and 5/6), attraction occurs, shown by the decrease in the number of units between A and B. (<bold>B</bold>) Color error (output-layer distance between the ‘guess’ and ‘correct’ centers-of-mass) is shown for each pairmate and condition (negative values indicate repulsion). When repulsion occurs (2/6), the change is driven by a distortion of pairmate 2, whereas pairmate 1 is unaffected. (<bold>C</bold>) Pairmate similarity is measured by the correlation of the hidden-layer patterns before and after learning. Here, above the gray line indicates integration and below indicates repulsion. The within-pair correlation decreases (differentiation) when competitor overlap is moderate (2/6). Within-pair correlation increases (integration) when competitor overlap is higher (3/6, 4/6, and 5/6). (<bold>D</bold>) Four hidden-layer activity patterns from a sample run in the 2/6 condition are shown: pairmate 1<sub>before</sub>, pairmate 1<sub>after</sub>, pairmate 2<sub>before</sub>, and pairmate 2<sub>after</sub>. The subscripts refer to the state of the memory before/after the learning that occurs in the color recall task; pairmate 1 designates the first of the pairmates to be presented during color recall. Brighter colors indicate the unit is more active. In this run, pairmate 1 stays in place and pairmate 2 distorts away from pairmate 1. (<bold>E</bold>) Multidimensional scaling (MDS) plots for each condition are shown, to illustrate the pattern of representational change in the hidden layer. The same four patterns as in D are plotted for each run. MDS plots were rotated, shifted, and scaled such that pairmate 1<sub>before</sub> is located at (0,0), pairmate 2<sub>before</sub> is located directly to the right of pairmate 1<sub>before</sub>, and the distance between pairmate 1<sub>before</sub> and pairmate 2<sub>before</sub> is proportional to the baseline distance between the pairmates. A jitter was applied to all points. Asymmetry in distortion can be seen in 2/6 by the movement of pairmate 2<sub>after</sub> away from pairmate 1. In conditions that integrate, most runs lead to symmetric distortion, although some runs in the 3/6 condition lead to asymmetric integration, where pairmate 2 moves toward pairmate 1<sub>before</sub>. For panels A, B, and C, error bars indicate the 95% confidence interval around the mean (computed based on 50 model runs).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-fig4-v1.tif"/></fig><p>We found no difference in the color center-of-mass before and after training in the 0/6 and 1/6 conditions. As similarity increased to the 2/6 condition, the distance between the centers-of-mass increased after learning, indicating repulsion. When similarity increased further to the 3/6, 4/6, and 5/6 conditions, the distance between the centers-of-mass decreased with learning, indicating attraction. The overall pattern of results here mirrors what was found in the <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> study: Low levels of color similarity were associated with no change in color perception, moderate levels of color similarity were associated with repulsion, and the repulsion effect went away when color similarity increased further.</p><p>The only salient difference between the simulation results and the experiment results is that our repulsion effects cross over into attraction for the highest levels of similarity, whereas <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> did not observe attraction effects. It is possible that <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> would have observed an attraction effect if they had sampled the color similarity space more densely (i.e. somewhere between 24°, where they observed repulsion, and 6°, where they observed neither attraction nor repulsion). As a practical matter, it may have been difficult for <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> to observe attraction in the 6<italic>°</italic> condition given that color similarity was so high to begin with (i.e. there was no more room for the objects to ‘attract’).</p><p>We also measured representational change in the model’s hidden layer, by computing the Pearson correlation of the patterns of activity evoked by A and B in the hidden layer from before to after learning in the color recall test. If no representational change occurred, then this within-pair correlation should not change over time. In contrast, differentiation (or integration) would result in a decrease (or increase) in within-pair correlation over time.</p><p>We found that representational change tracked the repulsion/attraction results <xref ref-type="fig" rid="fig4">Figure 4C</xref>: Lower overlap (i.e. 0/6 and 1/6), which did not lead to any change in color recall, also did not lead to change in the hidden layer; moderate overlap (i.e. 2/6), which showed repulsion in color recall, also showed a decrease in within-pair correlation (differentiation); and higher overlap (3/6, 4/6, and 5/6), which showed attraction in color recall, also showed an increase in within-pair correlation (integration). The association between behavioral repulsion/attraction and neural differentiation/integration that we observed in the model aligns well with results from <xref ref-type="bibr" rid="bib65">Zhao et al., 2021</xref>. They used a similar paradigm to <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> and found that the level of distortion of color memories was predicted by the amount of neural differentiation for those pairmates in parietal cortex (<xref ref-type="bibr" rid="bib65">Zhao et al., 2021</xref>).</p><p>Crucially, we can inspect the model to see why it gives rise to the pattern of results outlined above. In the low-overlap conditions (0/6, 1/6), the competitor did not activate enough during target recall to trigger any competition-dependent learning (see <xref ref-type="video" rid="video1">Video 1</xref>). When color similarity increased in the 2/6 condition, the competitor pop-up during target recall was high enough for co-activity between shared units and unique competitor units to fall into the dip of the U-shaped function, severing the connections between these units. On the next trial, when the competitor was presented, the unique parts of the competitor activated in the hidden layer but — because of the severing that occurred on the previous trial — the formerly shared units did not. Because the activity ‘set point’ for the hidden layer (determined by the kWTA algorithm) involves having 6 units active, and the unique parts of the competitor only take up 4 of these 6 units, this leaves room for activity to spread to additional units. Given the topographic projections in the output layer, the model is biased to ‘pick up’ units that are adjacent in color space to the currently active units; because activity cannot flow easily from the competitor back to the target (as a result of the aforementioned severing of connections), it flows instead <italic>away</italic> from the target, activating two additional units, which are then incorporated into the competitor representation. This sequence of events (first a severing of the shared units, then a shift away from the target) completes the process of neural differentiation, and is what leads to the behavioral repulsion effect in color recall (because the center-of-mass of the color representation has now shifted away from the target) — the full sequence of events is illustrated in <xref ref-type="video" rid="video2">Video 2</xref>. Lastly, when similarity increased further (to 3/6 units or above), competitor pop-up increased — the co-activity between the shared units and the unique competitor units now falls on the right side of the U-shaped function, strengthening the connections between these units (instead of being severed). This strengthening leads to neural integration and behavioral attraction in color space, as shown in <xref ref-type="video" rid="video3">Video 3</xref>.</p><media mimetype="video" mime-subtype="mp4" xlink:href="elife-88608-video1.mp4" id="video1"><label>Video 1.</label><caption><title>Model of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> 1/6 (low overlap) condition.</title><p>This video illustrates how the competitor does not pop up given low levels of hidden-layer overlap, so no representational change occurs.</p></caption></media><media mimetype="video" mime-subtype="mp4" xlink:href="elife-88608-video2.mp4" id="video2"><label>Video 2.</label><caption><title>Model of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> 2/6 (medium overlap) condition.</title><p>This video illustrates how the competitor pops up moderately and differentiates given medium levels of hidden-layer overlap.</p></caption></media><media mimetype="video" mime-subtype="mp4" xlink:href="elife-88608-video3.mp4" id="video3"><label>Video 3.</label><caption><title>Model of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> 3/6 (high overlap) condition.</title><p>This video illustrates how the competitor pops up strongly and integrates given high levels of hidden-layer overlap.</p></caption></media><p>In summary, this version of our model qualitatively replicates the key pattern of results in <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref>, whereby increasing color similarity led to a repulsion effect in color recall, which went away as similarity increased further. The reasons why the model gives rise to these effects align well with the <italic>Potential NMPH Explanation</italic> provided earlier: Higher color similarity increases competitor activity, which first leads to differentiation of the underlying representations, and then — as competitor activity increases further — to integration of these representations.</p></sec><sec id="s1-10-2"><title>Asymmetry of representational change</title><p>A striking feature of the model is that the repulsion effect in the 2/6 condition is <italic>asymmetric</italic>: One pairmate anchors in place and the other pairmate shifts its color representation. <xref ref-type="fig" rid="fig4">Figure 4B</xref> illustrates this asymmetry, by tracking how the center-of-mass for both pairmates changes over time in the output layer. Specifically, for each pairmate, we calculated the difference between the center-of-mass at the end of learning compared to the initial center-of-mass. A distortion away from the competitor is coded as negative, and toward the competitor is positive. When repulsion occurred in the 2/6 condition, the item shown first (pairmate 1) anchored in place (i.e., the final color report was unchanged and accurate), whereas the item shown second (pairmate 2) moved away from its competitor.</p><p>This asymmetry was also observed in the hidden layer (<xref ref-type="fig" rid="fig4">Figure 4D and E</xref>). In <xref ref-type="fig" rid="fig4">Figure 4E</xref>, we used multidimensional scaling (MDS) to visualize how the hidden-layer representations changed over time. MDS represents patterns of hidden-layer activity as points in a 2D plot, such that the distance between each pair of points corresponds to the Euclidean distance between their hidden-layer patterns. We made an MDS plot for four patterns per run: the initial hidden-layer pattern for the item shown first (pairmate 1<sub>before</sub>), the initial hidden-layer pattern for the item shown second (pairmate 2<sub>before</sub>), the final hidden-layer pattern for the item shown first (pairmate 1<sub>after</sub>), and the final hidden-layer pattern for the item shown second (pairmate 2<sub>after</sub>). Since the 0/6 and 1/6 conditions did not give rise to representational change, the MDS plot unsurprisingly shows that the before and after patterns of both pairmates remain unchanged. For the 2/6 condition (which shows differentiation), the pairmate 1<sub>before</sub> item remains clustered around pairmate 1<sub>after</sub>. However, pairmate 2<sub>after</sub> distorts, becoming relatively more dissimilar to pairmate 1, indicating that the differentiation is driven by pairmate 2 distorting away from its competitor. This asymmetry in differentiation arises for reasons described in the previous section — when pairmate 2 pops up as a competitor during recall of pairmate 1, the unique units of pairmate 2 are severed from the units that it (formerly) shared with pairmate 1, allowing it to acquire new units elsewhere given the inhibitory set point. After pairmate 2 has shifted away from pairmate 1, they are no longer in competition, so there is no need for pairmate 1 to adjust its representation and it stays in its original location in representational space (see <xref ref-type="video" rid="video2">Video 2</xref>).</p><p>In our model, the asymmetry in differentiation manifested as a clear order effect — pairmate 1 anchors in place and pairmate 2 shifts away from pairmate 1. It is important to remember, however, this effect is contingent on pairmate 2 popping up as a competitor when pairmate 1 is first shown as a target. If the dynamics had played out differently then different results might be obtained. For example, if pairmate 2 does not pop up as a competitor when pairmate 1 is first presented, and instead pairmate 1 pops up as a competitor when pairmate 2 is first presented, we would expect the opposite pattern of results (i.e. pairmate 2 will anchor in place and pairmate 1 will shift away from pairmate 2). We return to these points, and their implications for empirically testing the model’s predictions about asymmetry, in the <italic>Discussion</italic> section.</p></sec><sec id="s1-10-3"><title>Two kinds of integration</title><p>We also observed that integration could take two different forms, symmetric and asymmetric (<xref ref-type="fig" rid="fig4">Figure 4B and E</xref>). In this version of the model, the symmetric integration is more common. This can be seen in the MDS plots for conditions 3/6, 4/6, and 5/6: Both pairmate 1<sub>after</sub> and pairmate 2<sub>after</sub> mutually move toward each other. This is because both pairmates end up connecting to all the units that were previously connected to either pairmate individually. Essentially, the hidden units for pairmate 1 and pairmate 2 are ‘tied’ in terms of strength of excitation, so they are all allowed to be active at once (see Activity and inhibitory dynamics in the <italic>Methods</italic>). However, in the 3/6 condition, some runs show asymmetric integration where pairmate 2 distorts toward pairmate 1. (<xref ref-type="fig" rid="fig4">Figure 4E</xref>).</p><p>Whether symmetric or asymmetric integration occurs depends on the relative strengths of connections between pairs of unique competitor units (<italic>competitor-competitor connections</italic>) compared to connections between unique competitor units and shared units (<italic>competitor-shared connections</italic>) after the first trial (<xref ref-type="fig" rid="fig5">Figure 5</xref>; note that the figure focuses on connections between hidden units, but the principle also applies to connections that span across layers). Generally, coactivity between unique competitor units (<italic>competitor-competitor coactivity</italic>) is less than coactivity between unique competitor units and shared units (<italic>competitor-shared coactivity</italic>), which is less than coactivity between unique target units and shared units (<italic>target-shared coactivity</italic>). In the 2/6 condition (<xref ref-type="fig" rid="fig5">Figure 5A</xref>), competitor-competitor coactivities fall on the left side of the U-shaped function, and remain unchanged. In the 4/6 and 5/6 conditions, because competitor activity is so high, competitor-competitor coactivities fall on the right side of the U-shaped function (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). It follows, then, that there is some overlap amount where competitor-competitor coactivities fall in the dip of the U-shaped function (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). This is what happens in some runs in the 3/6 condition: On trial 1, some competitor-competitor connections (i.e. internal connections within pairmate 2) are severed, while — at the same time — competitor-shared connections are strengthened. On the next trial, when the model is asked to recall pairmate 2, activity flows out of the pairmate 2 representation into the shared units, which are connected to the representations of both pairmate 1 and pairmate 2. Because the representation of pairmate 2 has been weakened by the severing of its internal connections, while the representation of pairmate 1 is still strong, the representation of pairmate 1 outcompetes the representation of pairmate 2 (i.e. pairmate 1 receives substantially more excitation via recurrent connections than pairmate 2) and the neural pattern in the hidden layer ‘flips over’ to match the original pairmate 1 representation. This hidden-layer pattern is then associated with the pairmate 2 input, resulting in asymmetric integration — from this point forward, both pairmate 2 and pairmate 1 evoke the original pairmate 1 representation (see <xref ref-type="video" rid="video4">Video 4</xref>).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Schematic of coactivities on Trial 1.</title><p>Generally, coactivity between pairs of units that are unique to the competitor (<italic>competitor-competitor coactivity</italic>) is less than coactivity between unique competitor units and shared units (<italic>competitor-shared coactivity</italic>), which is less than target-target, target-shared, or shared-shared coactivity. The heights of the vertical bars in the bottom row indicate activity levels for particular hidden units. The top row plots coactivity values for a subset of the pairings between units (those highlighted by the arcs in the bottom row), illustrating where they fall on the U-shaped learning function. (<bold>A</bold>) Schematic of the typical arrangement of coactivity in the hidden-hidden connections and item-hidden connections in the 2/6 condition. The competitor units do not activate strongly. As a result, the competitor-shared connections are severed because they fall in the dip of the U-shaped function; this, in turn, leads to differentiation. (<bold>B</bold>) Typical arrangement of coactivity in the higher overlap conditions, 4/6 and 5/6. Here, the competitor units are highly active. Consequently, all connection types fall on the right side of the U-shaped function, leading to integration. Specifically, all units connect to each other more strongly, leading units previously associated with either pairmate A or B to join together. (<bold>C</bold>) As competitor pop-up increases, moving from the situation depicted in panel A to panel B, intermediate levels of competitor activity can result in competitor-competitor coactivity levels falling into the dip of the U-shaped function. If enough competitor-competitor connections weaken, while competitor-shared connections strengthen, this imbalance can lead to an asymmetric form of integration where pairmate 2 moves toward pairmate 1 (see text for details). This happens in some runs of the 3/6 overlap condition.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-fig5-v1.tif"/></fig><media mimetype="video" mime-subtype="mp4" xlink:href="elife-88608-video4.mp4" id="video4"><label>Video 4.</label><caption><title>Two different types of integration.</title><p>This video illustrates how integration can either be symmetric or asymmetric depending on the amount of competitor pop-up.</p></caption></media><p>Thus, two kinds of integration can occur — one where both pairmates pick up all units that initially belonged to either pairmate (symmetric), and one where pairmate 2 moves toward pairmate 1 (asymmetric). Generally, as competitor activity is raised, competitor-competitor coactivity is raised, and it is more likely the integration will become symmetric.</p></sec><sec id="s1-10-4"><title>Differentiation</title><p>We found that differentiation requires a high learning rate. In our model, the change in connection weights on each trial is multiplied by a learning rate (<italic>LRate</italic>), which is usually set to 1. Lowering the <italic>LRate</italic> value, consequently, leads to smaller learning increments. When we cycle through <italic>LRate</italic> values for all projections other than the output-to-output connection (where <italic>LRate</italic> is zero), we find that differentiation fails to occur in the 2/6 condition if <italic>LRate</italic> is too low (<xref ref-type="fig" rid="fig6">Figure 6A</xref>): If the connections between competitor (pairmate 2) and shared units are not fully severed on Trial 1, the (formerly) shared units may still receive enough excitation to strongly activate when the model is asked to recall pairmate 2 on Trial 2. This can lead to two possible outcomes: Sometimes the activity pattern in the hidden layer ends up matching the original pairmate 2 representation (i.e. the shared units are co-active with the unique pairmate 2 units), resulting in a re-forming of the original representation. In other cases, asymmetric integration occurs: If connections between pairmate 2 units and shared units have weakened somewhat, while the connections between shared units and pairmate 1 units are still strong, then spreading activity from the (re-activated) shared units on Trial 2 can lead to the original pairmate 1 hidden-layer representation outcompeting the original pairmate 2 hidden-layer representation, in which case the pairmate 2 inputs will become associated with the original pairmate 1 hidden-layer representation. See <xref ref-type="video" rid="video5">Video 5</xref> for illustrations of both possible outcomes. A useful analogy may be escape velocity from astrophysics. Spaceships need to be going a certain speed to escape the pull of gravity. Similarly, the competitor representation needs to get a certain distance away from its pairmate in one trial, or else it will get pulled back in.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Learning rate and representational change.</title><p>(<bold>A</bold>) The learning rate (<italic>LRate</italic>) parameter was adjusted and the within-pair correlation in the hidden layer was calculated for each overlap condition. In each plot, the gray horizontal bar indicates baseline similarity (prior to NMPH learning); values above the gray bar indicate integration and values below the gray bar indicate differentiation. Error bars indicate the 95% confidence interval around the mean (computed based on 50 model runs). The default <italic>LRate</italic> for simulations in this paper is 1. In the low overlap conditions (0/6 and 1/6), adjusting the <italic>LRate</italic> has no impact on representational change. In the 2/6 condition, differentiation does not occur if the <italic>LRate</italic> is lowered. In the high overlap conditions (3/6, 4/6, and 5/6), integration occurs regardless of the <italic>LRate</italic> (assuming it is set above zero). (<bold>B</bold>) For each <italic>LRate</italic> value tested, the within-pair correlation over time in the 2/6 condition is shown, where each purple line is a separate run (darker purple lines indicate many lines superimposed on top of each other). When <italic>LRate</italic> is set to 0.50 or higher, some model runs show abrupt, strong differentiation, resulting in negative within-pair correlation values; these negative values indicate that the hidden representation of one pairmate specifically excludes units that belong to the other pairmate.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-fig6-v1.tif"/></fig><media mimetype="video" mime-subtype="mp4" xlink:href="elife-88608-video5.mp4" id="video5"><label>Video 5.</label><caption><title>Effects of lowering learning rate.</title><p>This video illustrates how differentiation can fail to occur when the learning rate is too low.</p></caption></media><p>A corollary of the fact that differentiation requires a high learning rate is that, when it does happen in the model, it happens abruptly. After competitor-shared connections are weakened, this can have two possible effects. If the learning rate is high enough to sever the competitor-shared connections, differentiation will be evident the next time the competitor is presented. If the amount of weakening is insufficient, the formerly shared units will be reactivated and no differentiation will occur. The abruptness of differentiation can be seen in <xref ref-type="fig" rid="fig6">Figure 6B</xref>, which shows learning across trials for individual model runs (with different random seeds) as a function of <italic>LRate</italic>: When the learning rate is high enough to cause differentiation, it always happens between the first and second epochs of training. The prediction that differentiation should be abrupt is also supported by empirical studies. For instance, <xref ref-type="bibr" rid="bib61">Wanjia et al., 2021</xref> showed that behavioral expressions of successful learning are coupled with a temporally abrupt, stimulus-specific decorrelation of CA3/dentate gyrus activity patterns for highly similar memories.</p><p>In contrast to these results showing that differentiation requires a large <italic>LRate</italic>, the integration effects observed in the higher-overlap conditions do not depend on <italic>LRate</italic>. Once two items are close enough to each other in representational space to strongly coactivate, a positive feedback loop ensues: Any learning that occurs (no matter how small) will pull the competitor closer to the target, making them even more likely to strongly coactivate (and thus further integrate) in the future.</p></sec><sec id="s1-10-5"><title>Pairs of items that differentiate show anticorrelated representations</title><p><xref ref-type="fig" rid="fig6">Figure 6B</xref> also highlights that, for learning rates where robust differentiation effects occur in aggregate (i.e. there is a reduction in mean pattern similarity, averaging across model runs), these aggregate effects involve a bimodal distribution across model runs: For some model runs, learning processes give rise to anticorrelated representations, and for other model runs the model shows integration; this variance across model runs is attributable to random differences in the initial weight configuration of the model and/or in the order of item presentations across training epochs. The aggregate differentiation effect is therefore a function of the proportion of model runs showing differentiation (here, anticorrelation) and the proportion of model runs showing integration. The fact that differentiation shows up as anticorrelation in the model’s hidden layer relates to the learning effects discussed earlier: Unique competitor units are sheared away from (formerly) shared units, so the competitor ends up not having any overlap with the target representation (i.e. the level of overlap is less than you would expect due to chance, which mathematically translates into anticorrelation). We return to this point and discuss how to test for anticorrelation in the <italic>Discussion</italic> section.</p></sec></sec><sec id="s1-11"><title>Take-home lessons</title><p>Our model of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> shows that the NMPH can explain the results observed in the study, namely that moderate color similarity can lead to repulsion and that, if color similarity is increased beyond that point, the repulsion is eliminated. Furthermore, our model shows how the behavioral changes in this paradigm are linked to differentiation and integration of the underlying neural representations. The simulations also enrich our NMPH account of these phenomena in several ways, beyond the verbal account provided in <xref ref-type="bibr" rid="bib48">Ritvo et al., 2019</xref>. In particular, the simulations expose some important boundary conditions for when representational change can occur according to the NMPH (e.g. that differentiation depends on a large learning rate, but integration does not), and the simulations provide a more nuanced account of exactly how representations change (e.g. that differentiation driven by the NMPH is always asymmetric, whereas integration is sometimes asymmetric and sometimes symmetric; and that, when differentiation occurs on a particular model run, it tends to give rise to anticorrelated representations in the model’s hidden layer).</p><p>There are several aspects of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> left unaddressed by our model. For instance, they interleaved the color recall task (simulated here) with an associative memory test (not simulated here) where a colored object appeared as a cue and participants had to select the associated face. Our goal was to show how the simplest form of their paradigm could lead to the distortion effects that were observed; future simulations can assess whether these other experiment details affect the predictions of the model.</p></sec><sec id="s1-12"><title>Model of <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>: similar and different predictive associations</title><sec id="s1-12-1"><title>Key experimental findings</title><p><xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref> provided neural evidence for differentiation following competition, using a shared associate to induce competition between pairmates. In this study (<xref ref-type="fig" rid="fig7">Figure 7A</xref>), participants were instructed to learn scene-face associations. Later, during the repeated face-test task, participants were shown a scene and asked to pick the correct face from a bank of faces. Scenes were made up of highly similar pairs (e.g. two bridges, two barns). Sometimes, two paired scenes predicted the same face, sometimes different faces, and sometimes no face at all (in the latter case, the paired scenes appeared in the study task and not the face-test task). Participants were never explicitly told that some scene pairs shared a common face associate.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Modeling <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>.</title><p>(<bold>A</bold>) Participants learned to associate individual scenes with faces (faces not shown here due to bioRxiv rules). Each scene had a pairmate (another, similar image from the same scene category, e.g., another barn), and categories were not re-used across pairs (e.g. if the stimulus set included a pair of barns, then none of the other scenes would be barns). Pairmates could be associated with the same face, different faces, or no face at all (not shown). Participants were scanned while looking at each individual scene in order to get a measure of neural representations for each scene. This panel was adapted from Figure 1 of <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>. (<bold>B</bold>) Neural similarity was measured by correlating scene-evoked patterns of fMRI activity. A scene pair difference score was calculated by subtracting non-pairmate similarity from pairmate similarity; this measure shows the relative representational distance of pairmates. Results for the different-face and same-face condition in the hippocampus are shown here: Linking scenes to the same face led to a negative scene pair difference score, indicating that scenes became less similar to each other than they were to non-pairmates (differentiation). This panel was adapted from Figure 2 of <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>. (<bold>C</bold>) To model this study, we used the same basic structure that was described in <italic>Basic Network Properties</italic>. In this model, the category layer represents the type of scene (e.g. barn, bridge, etc.), and the item layer represents an individual scene. The output layer represents the face associate. Activity shown is for pairmate A in the same-face condition. Category-to-hidden, item-to-hidden and hidden-to-hidden connections are pre-wired similarly to the 2/6 condition of our model of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> (see <xref ref-type="fig" rid="fig2">Figure 2</xref>). The hidden A and B units have random, low-strength connections to all output units, but are additionally pre-wired to connect strongly to either one or two units in the output layer. In the different-face condition, hidden A and B units are pre-wired to connect to two different face units, but in the same-face condition, they are pre-wired to connect to the same face unit. (<bold>D</bold>) This model has two conditions: same face and different face. The only difference between conditions is whether the hidden A and B units connect to the same or different face unit in the output layer.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-fig7-v1.tif"/></fig><p>When the two scenes predicted different faces, the hippocampal representations for each scene were relatively orthogonalized — hippocampal representations of the two pairmate scenes were just as similar to each other as to non-pairmate scenes. However, when the two scenes predicted the same face, differentiation resulted, such that the hippocampal representations of the two pairmate scenes were less similar to each other than to non-pairmate scenes (<xref ref-type="fig" rid="fig7">Figure 7B</xref>).</p></sec><sec id="s1-12-2"><title>Potential NMPH explanation</title><p>As noted earlier, these results contradict supervised learning models, which predict that pairing two stimuli with the same associate would lead to integration, not differentiation. The NMPH, however, can potentially explain these results: Linking the pairmates to a shared face associate provides an additional pathway for activity to spread from the target to the competitor (i.e. activity can spread from scene A, to the shared face, to scene B). If competitor activity falls on the left side of the U-shaped function in the different-face condition, then the extra spreading activity in the same-face condition could push the activity of the competitor into the ‘dip’ of the function, leading to differentiation.</p></sec></sec><sec id="s1-13"><title>Model set up</title><sec id="s1-13-1"><title>Model architecture</title><p>Our model of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> can be adapted for <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>. Instead of mapping from an object and face to a color, as in <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref>, the <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref> study involves learning mappings between scenes and faces. Also, the way in which competition is manipulated is different across the studies: In <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref>, competition is manipulated by varying the similarity of the stimuli (specifically, the color difference of the objects), whereas in <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>, competition is manipulated by varying whether pairmate scenes are linked to the same vs. different face.</p><p>To adapt our model for <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>, the interpretation of each layer must be altered to fit the new paradigm (<xref ref-type="fig" rid="fig7">Figure 7C</xref>). The category layer now represents the category for the scene pairmates (e.g. barn, bridge, etc.). The item layer represents the individual scene (e.g. where A represents barn 1 and B represents barn 2). Just as before, the input for each stimulus is composed of two units (one in each of the two input layers); the category-layer unit is consistent for A and B, but the item-layer unit differs.</p><p>The output layer in this model represents the face associate, such that each individual output-layer unit could be thought of as a single face. For this model, the ordering of units in the output layer is not meaningful — two units next to each other in the output layer are no more similar than to any other units.</p></sec><sec id="s1-13-2"><title>Knowledge built into the network</title><p>As before, we were interested in the moment that competition first happens, so we pre-wired connections as if some initial learning had occurred. We pre-wired the connections between the hidden layer and both input layers (and from hidden layer to itself) to be similar to the 2/6 condition of our model of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref>, so there is some baseline amount of overlap between A and B (i.e. reflecting the similar-looking scenes).</p><p>To mimic the learning of scene-face associates, all hidden A units are connected to a single unit in the face layer, and all hidden B units are connected to a single unit in the face layer. In the different-face condition, A and B hidden units are connected to different face units, to reflect that the two scenes were predictive of two separate faces. In the same-face condition, A and B hidden units connect to the same face unit, to reflect that A and B predict the same face.</p></sec><sec id="s1-13-3"><title>Manipulation of competitor activity</title><p>Competitor activity is modulated by the similarity of predictive consequences in this version of the model — that is, whether the hidden units for pairmates A and B are pre-wired to connect strongly to the same unit or different units in the output layer. Stronger connections to the same face unit should provide an extra conduit for excitation to flow to the competitor units.</p></sec><sec id="s1-13-4"><title>Task</title><p>The task performed by the model was to guess the face associated with each scene. We clamped the external input for the scenes and allowed activity to spread through the hidden layer to the output layer so it could make a guess for the correct face. No correct answer was shown, and no error-driven learning was used. Although the exact parameter values used in this simulation were slightly different from the values used in the previous simulation (see <italic>Methods</italic> for details), inhibition and oscillations were implemented in the same way as before.</p></sec></sec><sec id="s1-14"><title>Results</title><p>For this study, the key dependent measure was representational change within the hidden layer. Specifically, we sought to capture the hippocampal pattern similarity results reported by <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>.</p><sec id="s1-14-1"><title>Differentiation and integration</title><p>The different-face condition in this model led to no representational change (see <xref ref-type="video" rid="video6">Video 6</xref>) whereas the same-face condition led to differentiation (see <xref ref-type="video" rid="video7">Video 7</xref>), as measured using within-pair correlation (<xref ref-type="fig" rid="fig8">Figure 8A</xref>). Differentiation is indicated by the fact that new units are added that did not previously belong to either pairmate. In this version of the model, the topography of the hidden layer is not meaningful other than the units assigned to A and B, so the new units that are added to the representation could be on either side. The reason why the model shows differentiation in the same-face condition (but not in the different-face condition) aligns with the <italic>Potential NMPH Explanation</italic> provided earlier: The shared face associate in the same-face condition provides an conduit for extra activity to spread to the competitor scene pairmate, leading to moderate activity that triggers differentiation. Note also that the exact levels of differentiation that are observed in the different-face and same-face conditions are parameter dependent; for an alternative set of results showing some differentiation in the different-face condition (but still less than is observed in the same-face condition), see <xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>.</p><media mimetype="video" mime-subtype="mp4" xlink:href="elife-88608-video6.mp4" id="video6"><label>Video 6.</label><caption><title>Model of <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref> different face condition.</title><p>This video illustrates how no representational change occurs in the different face condition of our simulation of <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>.</p></caption></media><media mimetype="video" mime-subtype="mp4" xlink:href="elife-88608-video7.mp4" id="video7"><label>Video 7.</label><caption><title>Model of <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref> same face condition.</title><p>This video illustrates how differentiation occurs in the same face condition of our simulation of <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>.</p></caption></media><fig-group><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Model of <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref> results.</title><p>(<bold>A</bold>) Within-pair correlation between A and B hidden layer representations before and after learning. Error bars indicate the 95% confidence interval around the mean (computed based on 50 model runs). In the same-face condition, the within-pair correlation is reduced after learning, indicating differentiation. (<bold>B</bold>) Activity patterns of both pairmates in the hidden layer before and after learning for a sample “same-face” run are shown. Asymmetry in distortion can be seen in how pairmate 1’s representation is unchanged and pairmate 2 picks up additional units that did not previously belong to either item (note that there is no topography in the hidden layer in this simulation, so we would not expect the newly-acquired hidden units to fall on one side or the other of the layer). (<bold>C</bold>) MDS plots for each condition illustrate representational change in the hidden layer. The differentiation in the same-face condition is asymmetric: Pairmate 2<sub>after</sub> generally moves further away from pairmate 1 in representational space, while pairmate 1 generally does not change.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-fig8-v1.tif"/></fig><fig id="fig8s1" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 1.</label><caption><title>Results from an alternative parameterization, where the different-face condition shows some differentiation and the same-face condition shows more differentiation.</title><p>Results from our model of <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>, using an alternative parameterization where the oscillation amplitude <italic>Osc</italic> for the hidden layer is set to 0.1 instead of 0.067: (<bold>A</bold>) Within-pair correlation between A and B hidden layer representations before and after learning. Error bars indicate the 95% confidence interval around the mean (computed based on 50 model runs). Compare with <xref ref-type="fig" rid="fig8">Figure 8A</xref>. When <italic>Osc</italic> is set to 0.1, both the different-face and same-face conditions show a reduction in pattern similarity compared to baseline, but the size of this decrease is larger in the same-face condition. This pattern of results qualitatively aligns with the actual results observed by <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>. (<bold>B</bold>) Plots of the within-pair correlation across learning epochs, shown separately for the different-face and same-face conditions. Each purple line is a separate run of the model (darker purple lines indicate many lines superimposed on top of each other). The plots show that individual model runs exhibit one of three discrete outcomes (integration, reflected by a within-pair correlation of 1; no change; or differentiation, reflected by a negative within-pair correlation). The differences in average levels of representational change shown in part (<bold>A</bold>) for the same-face and different-face conditions are due to differences in the frequencies-of-occurrence of these three discrete outcomes.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-fig8-figsupp1-v1.tif"/></fig></fig-group></sec><sec id="s1-14-2"><title>Nature of representational change</title><p>The representational change in the hidden layer shows the same kind of asymmetry that occurred in our model of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref>; <xref ref-type="fig" rid="fig8">Figure 8B and C</xref>: In the same-face condition, pairmate 1 typically anchors in place, whereas pairmate 2 acquires new units that did not previously belong to either either pairmate (<xref ref-type="fig" rid="fig8">Figure 8B</xref>), resulting in it shifting away from pairmate 1 (<xref ref-type="fig" rid="fig8">Figure 8C</xref>). Although this pattern is present on most runs, the MDS plot also shows that some runs fail to differentiate and instead show integration (see the <italic>Discussion</italic> for an explanation of how conditions that usually lead to differentiation may sometimes lead to integration instead). Note that the neural measure of differentiation used by <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref> does not speak to the question of whether representational change was symmetric or asymmetric in their experiment — to measure the (a)symmetry of representation change, it is necessary to take ‘snapshots’ of the representations both before and after learning (e.g. <xref ref-type="bibr" rid="bib50">Schapiro et al., 2012</xref>), but the method used by <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref> only looked at post-learning snapshots (comparing the neural similarity of pairmates and non-pairmates). We return in the <italic>Discussion</italic> to this question of how to test predictions about asymmetric differentiation.</p><p><xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref> also indicates that, as in our simulation of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref>, individual model runs where differentiation occurs show anticorrelation between the pairmate representations, and gradations in the aggregate level of differentiation that is observed across conditions reflect differences in the proportion of trials showing this anticorrelation effect.</p></sec><sec id="s1-14-3"><title>Differentiation requires a high learning rate</title><p>As in our model of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref>, we again found that a high <italic>LRate</italic> is needed for differentiation. Specifically, lowering <italic>LRate</italic> below its standard value (e.g, to a value of 0.10) eliminated the differentiation effect in the same-face condition. Changing the learning rate did not impact the different-face condition. In this condition, the pop-up is low enough that all competitor-shared connections on Trial 1 fall on the left side of the U-shaped function, so no weight change occurs, regardless of the learning rate setting.</p></sec></sec><sec id="s1-15"><title>Take-home lessons</title><p>This simulation demonstrates that the NMPH can explain the results of <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>, where learning about stimuli that share a paired associate can lead to differentiation. The model shows how linking items with the same or different associates can modulate competitor activity and, through this, modulate representational change. As in our simulation of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref>, we found that the NMPH-mediated differentiation was asymmetric, manifested as anticorrelation between pairmate representations on individual model runs, and required a high learning rate, leading to abrupt representational change.</p></sec><sec id="s1-16"><title>Model of <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>: blocked and interleaved learning</title><sec id="s1-16-1"><title>Key experimental findings</title><p>For our third simulation, we focused on a study by <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>. This study examined how the learning curriculum affects representational change in different brain regions. Participants learned to link novel objects with a common associate (i.e. AX and BX). Sometimes these associates were presented in a blocked fashion (all AX before any BX) and sometimes they were presented in an interleaved fashion (<xref ref-type="fig" rid="fig9">Figure 9A</xref>).</p><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>Modeling <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>.</title><p>(<bold>A</bold>) Participants in <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref> learned to link novel objects with a common associate (i.e., AX and BX). Sometimes these associates were learned in a blocked design (i.e. all AX before any BX), and sometimes they were learned in an interleaved design. The items were shown side-by-side, and participants were not explicitly told the structure of the shared items. Before and after learning, participants were scanned while observing each item alone, in order to get a measure of the neural representation of each object. This panel was adapted from Figure 1 of <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>. (<bold>B</bold>) Some brain regions (e.g. right posterior hippocampus) showed differentiation for both blocked and interleaved conditions, some regions (e.g. left mPFC) showed integration for both conditions, and other regions (e.g. right anterior hippocampus) showed integration in the blocked condition but differentiation in the interleaved condition. This panel was adapted from Figures 3, 4 and 5 of <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>. (<bold>C</bold>) To model this study, we used the network structure described in <italic>Basic Network Properties</italic>, with the following modifications: The structure of the network was similar to the same-face condition in our model of <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref> (see <xref ref-type="fig" rid="fig7">Figure 7</xref>), except we altered the connection strength from units in the hidden layer to the output unit corresponding to the shared item (item X) to simulate what would happen depending on the learning curriculum. In both conditions, the pre-wired connection linking the item B hidden units to the item X output unit is set to .7. In the interleaved condition, the connection linking the item A hidden units to the item X output unit is set to .8, to reflect some amount of initial AX learning. In the blocked condition, the connection linking the item A hidden units to the item X output unit is set a higher value (0.999), to reflect extra AX learning. (<bold>D</bold>) Illustration of the input and output patterns, which were the same for the blocked and interleaved conditions (the only difference in how we modeled the conditions was in the initial connection strengths, as described above).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-fig9-v1.tif"/></fig><p>The analysis focused on the hippocampus, the medial prefrontal cortex (mPFC), and the inferior frontal gyrus (IFG). Some brain regions (e.g. right posterior hippocampus) showed differentiation for both blocked and interleaved conditions, some regions (e.g. left mPFC) showed integration for both conditions, and others (e.g. right anterior hippocampus) showed integration in the blocked condition but differentiation in the interleaved condition (<xref ref-type="fig" rid="fig9">Figure 9B</xref>).</p></sec></sec><sec id="s1-17"><title>Potential NMPH explanation</title><p>The NMPH can potentially explain how the results differ by brain region, since the overall level of inhibition in a region can limit the competitor’s activity. For instance, regions that tend to show differentiation (like posterior hippocampus) have sparser activity (<xref ref-type="bibr" rid="bib4">Barnes et al., 1990</xref>). Higher inhibition in these areas could cause the activity of the competitor to fall into the moderate range, leading to differentiation. For regions with lower inhibition, competitor activity may fall into the high range, leading to integration.</p><p>The result that some regions (e.g. right anterior hippocampus) show differentiation in the interleaved condition and integration in the blocked condition could also be explained by the NMPH. By the first BX trial, we would expect that the connections between A and X would be much stronger in the blocked condition (after many AX trials) compared to the interleaved condition (after one or a few AX trials). This stronger A-X connection could allow more activity to flow from B through X to the A competitor. Consequently, competitor activity in the blocked condition would fall farther to the right of the U-shaped function compared to the interleaved condition, allowing for integration in the blocked condition but differentiation in the interleaved condition.</p></sec><sec id="s1-18"><title>Model set up</title><sec id="s1-18-1"><title>Model architecture</title><p>In <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>, A, B, and X were all individual pictures of objects shown in the same fashion; the only difference is that X was paired with two distinct items (A and B) but A and B were only paired with one other item (X). We decided to represent A and B pairmates in the input layer and X as a single unit in the output layer. Concretely, we represented A and B in the input layer by having a unique (single) unit in the item layer for each of A and B; the same (single) unit is active in the category layer for both stimuli (it can be thought of as representing the category of ‘novel objects’ to which both A and B belong). Putting A and B in the same layer, where their representations directly compete, captures the fact that A and B were mutually exclusive (i.e. they were never viewed together). Putting X in a different layer made it easier for the model to represent X at the same time as A or B. Note that, because connections in the model are bidirectional and symmetric in strength, the X output was able to influence activity elsewhere in the network, which proves to be critical for the learning effects described below. This approach also makes the isomorphism to <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref> clearer — just as a shared face associate in that study served as a conduit for activity to spread to the scene pairmate, the shared X object associate in <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref> serves as a conduit for activity to spread between B and A pairmates.</p></sec><sec id="s1-18-2"><title>Knowledge built into the network</title><p>The connections between layers for this model are similar to the connections we used in the same-face condition in our model of <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>. Since both A and B have a shared associate (X), all hidden A and B units are connected to the same unit in the output layer. However, we adjusted the connection strength to the shared X unit in order to simulate blocked or interleaved learning (see <xref ref-type="fig" rid="fig9">Figure 9C</xref> caption for details).</p><p>Matching the previous two simulations, we pretrained the weights so the hidden representations of the stimuli initially had 2/6 units in common. Even though the A and B stimuli used in the actual experiment did not have obvious feature overlap (they were randomly selected novel objects), it is important to note that the hidden layer is not simply a representation of the sensory features of the A and B stimuli; the hidden layer also receives input from the output layer, which represents the shared associate of A and B (X). We think that the presence of this shared associate justifies our use of initially-overlapping hidden representations.</p></sec><sec id="s1-18-3"><title>Modulation of competitor activity</title><p>We hypothesized that competition would be modulated by the blocked vs. interleaved manipulation. If AX and BX are learned in a blocked design, then the connections between A (in the hidden layer) and X (in the output layer) will be stronger before the first BX trial than in the interleaved condition. That extra strength can provide a pathway for more excitation to flow from X to A during BX trials. In our simulations, we operationalized this difference by varying the strength of the connection between A units (in the hidden layer) and X units (in the output layer; see <xref ref-type="fig" rid="fig9">Figure 9</xref> caption for details).</p></sec><sec id="s1-18-4"><title>Task</title><p>External inputs corresponding to the A or B stimuli (given by the two input layers) are clamped, and activity is allowed to flow through the hidden layer to the output layer, producing a guess of its associate. This deviates somewhat from the task in the original study, which showed AX or BX stimuli side-by-side. We could have clamped the X external values so it would be shown rather than guessed, but we decided to let the activity flow through the network to be consistent with the other versions of our model. This change does not have any impact on the outcome of the simulation — X ends up being strongly active here even though it is not being externally clamped, so the dynamics of activity elsewhere in the network (and the resulting learning) end up the same as if external clamping had been applied.</p><p>In the blocked condition, we assume AX has been fully learned, so we start with a BX training trial and no AX trials follow. To be consistent, we also start the interleaved condition with a BX training trial; however, in the interleaved condition, both AX and BX may follow after that initial BX trial.</p><p>Although the exact values of parameters used in this simulation were slightly different than the values used in the previous simulations (see <italic>Methods</italic> for details), inhibition and oscillations were implemented in the same manner as before.</p></sec><sec id="s1-18-5"><title>Modulation of inhibitory dynamics</title><p>For this version of our model, we added an extra manipulation. To model the fact that some brain regions showed overall differentiation and others overall integration, we varied the amplitude of the inhibitory oscillations in the hidden layer. If the amplitude of the sinusoidal function on inhibition is larger (or smaller), then the competitor is allowed to pop up more (or less), affecting the outcome of learning. We first present results from a version of the model where the amplitude is set to an intermediate level (0.0623); we also present results from model variants where we allowed less competitor pop-up (by lowering the oscillation amplitude to 0.0535) and more competitor pop-up (by raising the oscillation amplitude to 0.09), in order to simulate representational change in brain regions that have more or fewer restrictions on competitor activity.</p></sec></sec></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Differentiation and integration</title><p>Examining the correlation between the hidden-layer representations of A and B, we found that the interleaved condition leads to differentiation (see <xref ref-type="video" rid="video8">Video 8</xref>) whereas the blocked condition (where the AX connection is stronger) leads to integration (see <xref ref-type="video" rid="video9">Video 9</xref>; <xref ref-type="fig" rid="fig10">Figure 10A</xref>). The reason why the model shows this pattern of results aligns with the <italic>Potential NMPH Explanation</italic> provided earlier: Because the X output unit is more strongly connected to A’s hidden-layer representation in the blocked condition, more activity spreads from B via X to A in the blocked condition. This increased competitor activity results in the two representations integrating (as opposed to differentiating).</p><media mimetype="video" mime-subtype="mp4" xlink:href="elife-88608-video8.mp4" id="video8"><label>Video 8.</label><caption><title>Model of <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref> interleaved condition.</title><p>This video illustrates how differentiation occurs in the interleaved condition of our simulation of <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>.</p></caption></media><media mimetype="video" mime-subtype="mp4" xlink:href="elife-88608-video9.mp4" id="video9"><label>Video 9.</label><caption><title>Model of <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref> blocked condition.</title><p>This video illustrates how integration occurs in the blocked condition of our simulation of <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>.</p></caption></media><fig-group><fig id="fig10" position="float"><label>Figure 10.</label><caption><title>Model of <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref> results: in this model, pairmate B is always the stimulus shown first during the competitive learning part of the simulation (after initial AX learning), so we refer to pairmate B as ‘pairmate 1’ in the figure and to pairmate A as ‘pairmate 2’.</title><p>(<bold>A</bold>) Within-pair correlation between hidden-layer A and B representations is shown before and after learning; here, the oscillation amplitude <italic>Osc</italic> was set to 0.0623. In the interleaved condition, the within-pair correlation is reduced after learning, indicating differentiation. In the blocked condition, the within-pair correlation increases, indicating integration. (<bold>B</bold>) Activity patterns of both pairmates in the hidden layer before and after learning are shown for a sample run in the interleaved condition. Asymmetry in distortion can be seen in how pairmate 2, but not pairmate 1, picks up additional units that did not previously belong to either representation. (<bold>C</bold>) MDS plots for each condition illustrate the pattern of representational change in the hidden layer. In the blocked condition, the pairmates integrate and move toward each other. This integration is mostly symmetric, but on many trials it is asymmetric: Pairmate 2 moves toward pairmate 1 rather than pairmates 1 and 2 meeting in the middle. In the interleaved condition, asymmetric differentiation occurs: Pairmate 2 moves away from pairmate 1. (<bold>D</bold>) To investigate how these results might vary across brain regions with different inhibitory dynamics, we manipulated the inhibitory oscillation amplitude to change the amount of competitor pop-up. No parameters other than the inhibitory oscillation amplitude were changed. When oscillation amplitude is reduced to 0.0525, less competitor pop-up happens, and the blocked, but not interleaved, condition leads to differentiation. When oscillation amplitude is raised to 0.09, more competitor pop-up happens, and both conditions lead to integration. For panels A and D, error bars indicate the 95% confidence intervals around the mean (computed based on 50 model runs).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-fig10-v1.tif"/></fig><fig id="fig10s1" position="float" specific-use="child-fig"><label>Figure 10—figure supplement 1.</label><caption><title>Results from an alternative parameterization, where reducing the amplitude of inhibitory oscillations leads to differentiation in both the interleaved and blocked conditions.</title><p>Results from our model of <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>, using an alternative parameterization where the connection strength between X (in the output layer) and A (in the hidden layer) is set to 0.9 in the blocked condition (instead of 0.999). (<bold>A</bold>) Within-pair correlation between hidden-layer A and B representations is shown before and after learning; here, the oscillation amplitude <italic>Osc</italic> was set to 0.0635. In the interleaved condition, the within-pair correlation is reduced after learning, indicating differentiation. In the blocked condition, the within-pair correlation increases, indicating integration. (<bold>B</bold>) Activity patterns of both pairmates in the hidden layer before and after learning are shown for a sample run in the interleaved condition. Asymmetry in distortion can be seen in how pairmate 2, but not pairmate 1, picks up additional units that did not previously belong to either representation. (<bold>C</bold>) MDS plots for each condition illustrate the pattern of representational change in the hidden layer. In the blocked condition, the pairmates integrate and move toward each other on most (but not all) trials — a subset of the trials show differentiation. In the interleaved condition, differentiation occurs on most (but not all) trials — a subset of the trials show integration. (<bold>D</bold>) To investigate how these results might vary across brain regions with different inhibitory dynamics, we manipulated the inhibitory oscillation amplitude to change the amount of competitor pop-up. No parameters other than the inhibitory oscillation amplitude were changed. When oscillation amplitude is reduced to 0.0615, less competitor pop-up happens, and here this results in both conditions showing differentiation (compare to our original results in <xref ref-type="fig" rid="fig10">Figure 10D</xref>, where differentiation occurred in the blocked condition but not the interleaved condition). When oscillation amplitude is raised to 0.07, more competitor pop-up happens, and both conditions lead to integration. For panels A and D, error bars indicate the 95% confidence intervals around the mean (computed based on 100 model runs).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-fig10-figsupp1-v1.tif"/></fig></fig-group><p>Note that the key feature driving integration in the blocked condition of this simulation is not the high strength of the connection from X to A <italic>on its own</italic> — rather, it is the <italic>asymmetry</italic> in the pretrained connection strengths from X to A (0.999) and from X to B (0.7). This asymmetry, which is meant to reflect the extensive training on A-X that occurred before the initial presentation of B-X, results in the A-X hidden representation decisively winning the competition during B-X presentation, which then leads to the B input also being linked to this representation (i.e. integration). It is instructive to compare this to the same-face condition from our simulation of <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>: In that simulation, the two pairmates are also linked strongly (0.99 initial connection strength) to a shared associate, but in that case the connections are equally strong, so there is more balanced competition — in this case, the competitor representation only comes to mind moderately (instead of displacing the target representation), so the result is differentiation instead of integration.</p><sec id="s2-1-1"><title>Nature of representational hange</title><p>The results of this simulation again indicate that differentiation is asymmetric. <xref ref-type="fig" rid="fig10">Figure 10B</xref> shows a single run in the interleaved condition: Pairmate 1 anchors in place and pairmate 2 picks up units that did not previously belong to either representation. The MDS plot (<xref ref-type="fig" rid="fig10">Figure 10C</xref>) shows how, in the interleaved condition, pairmate 2 consistently shifts away from pairmate 1. Also, as in our other simulations, when differentiation occurs on a particular model run it tends to give rise to anticorrelated representations (results not shown).</p><p>The MDS results from the blocked condition show that integration is mostly symmetric, but there are many runs that show asymmetric integration (just like in the 3/6 condition of our model of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref>). The reason for asymmetric integration is the same here: Sometimes not all of the competitor-competitor coactivity values reach the right side of the U-shaped function, and connections that fall into the ‘dip’ of the U-shaped function are weakened. When these competitor-competitor connections weaken and the competitor-shared connections strengthen, this imbalance can cause pairmate 2 to flip from its original representation to sharing pairmate 1’s original representation.</p></sec><sec id="s2-1-2"><title>Differentiation requires a high learning rate, but integration does not</title><p>Just as in our previous simulations, a high learning rate is needed for differentiation. Specifically, lowering <italic>LRate</italic> below its standard value (e.g. to a value of 0.1) eliminated differentiation in the interleaved condition. Lowering the learning rate to 0.1 did not, however, eliminate the integration observed in the blocked condition.</p></sec><sec id="s2-1-3"><title>Adjusting oscillation amplitude modulates representational change</title><p>In this model, we additionally adjusted the amplitude of inhibitory oscillations, to simulate different inhibitory dynamics across brain regions (<xref ref-type="fig" rid="fig10">Figure 10D</xref>). When the competitor was less able to activate (as a result of smaller inhibitory oscillations), only the blocked condition led to differentiation. When the competitor was allowed to activate more (because of larger inhibitory oscillations), both conditions led to integration. <xref ref-type="fig" rid="fig10s1">Figure 10—figure supplement 1</xref> shows results from an alternative parameterization where, in the low-oscillation-amplitude condition, differentiation is observed in both the blocked and interleaved conditions (mirroring results from <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>, who found differentiation in both conditions in several regions of interest, including parts of the hippocampus and medial prefrontal cortex). Taken together, these simulations provide an ‘in principle’ account of how differences in levels of inhibition across brain regions can modulate representational change.</p><p>It is worth emphasizing that — in this simulation, as in our simulation of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> — manipulations that raise competitor activity (here, increasing oscillation strength) are associated with a transition from no representational change to differentiation to integration; this is a straightforward consequence of the U shape of the NMPH curve. Notably, this appears to be inconsistent with some recent results from <xref ref-type="bibr" rid="bib36">Molitor et al., 2021</xref>, who used a paradigm similar to <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref> and measured competitor activity with a multivariate fMRI pattern classifier. <xref ref-type="bibr" rid="bib36">Molitor et al., 2021</xref> found that — in a combined DG / CA2,3 hippocampal ROI — lower levels of competitor activity were associated with integration and higher levels of competitor activity were associated with differentiation. Although there are several potential ways that any single finding of this sort could be explained away (see e.g., <xref ref-type="bibr" rid="bib57">Tarder-Stoll et al., 2021</xref>), such a pattern of results could prove troublesome for the model if it turns out to be reliable across studies.</p></sec></sec><sec id="s2-2"><title>Take-home lessons</title><p>This version of our model shows that the NMPH can account for the results of <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>, where the learning curriculum (blocked or interleaved) had been shown to affect representational change. Additionally, the model reveals how the inhibitory dynamics of different brain regions can affect these outcomes. As in the other versions of our model, differentiation requires a high learning rate, and — on model runs when it occurs — it is asymmetric and gives rise to anticorrelated representations.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Recent studies have presented a challenge to supervised learning models, showing that linking items to a shared associate can result in differentiation rather than integration. The goal of the current research was to instantiate our unsupervised-learning account of representational change in a neural network model and assess how well it can account for extant data on differentiation and integration. We simulated three studies, each of which modulated the amount of competitor activity in different ways: <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> modulated competitor activity with stimulus similarity; <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref> modulated competitor activity through the use of shared (vs. unshared) predictive consequences; and <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref> modulated competitor activity by organizing learning in a blocked or interleaved order. The <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref> model also explored the effects of (simulated) regional differences in the strength of local inhibition, and the <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> model additionally explored the effect of varying the learning rate.</p><p>Our model provides an existence proof that a network imbued with NMPH learning can explain these findings. Using unsupervised NMPH learning alone, we showed how: (1) Increasing the similarity of color memories leads progressively to a repulsion effect and then an attraction effect; (2) pairing two stimuli with the same associate can lead to differentiation; and (3) learning in an interleaved vs. blocked fashion can lead to differentiation and integration, respectively, and that changing inhibitory dynamics can affect these outcomes. In addition to qualitatively replicating the results from the studies we simulated, our model gives rise to several novel predictions — most notably, that differentiation driven by the NMPH requires a rapid learning rate, and when it occurs for a particular pair of items, it is asymmetric and gives rise to anticorrelated representations.</p><sec id="s3-1"><title>Differentiation requires a high learning rate and is sensitive to activity dynamics</title><p>Our model predicts that a high learning rate is required for differentiation: As shown in our simulation of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref>, if connections between the unique features of the competitor and the (formerly) shared features are not sufficiently weakened after one trial, the shared features will be strongly reactivated when the competitor is next presented; in the model, this reactivation of shared features leads to either restrengthening of the previously weakened connections (‘undoing’ the differentiation) or integration of the target and competitor memories.</p><p>We also found that differentiation is highly sensitive to activity dynamics. Anything that affects how strongly the competitor comes to mind can impact the kinds of representational change that are observed. We used a variety of methods to influence how strongly competitors come to mind in the three models, but this is shown particularly clearly in the simulation of <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref> where we modulated the oscillation amplitude. The results from this simulation show that the direction of representational change (i.e. differentiation vs. integration) within a given condition (interleaved or blocked) can switch depending on how much the competitor comes to mind.</p><p>These results have implications for where to look for differentiation in the brain. Our finding that differentiation requires a high learning rate suggests that differentiation will be more evident in the hippocampus than in neocortex, insofar as hippocampus is thought to have a higher learning rate than neocortex (<xref ref-type="bibr" rid="bib32">McClelland et al., 1995</xref>). In keeping with this prediction, numerous studies have found differentiation effects in hippocampus but not in neocortical regions involved in sensory processing (e.g. <xref ref-type="bibr" rid="bib8">Chanales et al., 2017</xref>; <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>; <xref ref-type="bibr" rid="bib64">Zeithamova et al., 2018</xref>). At the same time, some studies have found differentiation effects in neocortex (e.g. <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>; <xref ref-type="bibr" rid="bib59">Wammes et al., 2022</xref>). One possible explanation of these neocortical differentiation effects is that they are being ‘propped up’ by top-down feedback from differentiated representations in the hippocampus. This explanation implies that disruptions of hippocampal processing (e.g. lesions, stimulation) will eliminate these neocortical differentiation effects; we plan to test this prediction in future work.</p><p>Additionally, the simulations where we adjusted the oscillation amount (using our model of <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>) imply that differentiation will be most evident in brain regions where it is relatively hard to activate competitors. Given the U shape of the NMPH learning rule, limiting competitor activity makes it less likely that plasticity will ‘cross over’ from weakening (and differentiation) to strengthening (and integration). Thus, within the hippocampus, subregions with sparser activity (e.g. dentate gyrus, and to a lesser extent, CA3; <xref ref-type="bibr" rid="bib4">Barnes et al., 1990</xref>; <xref ref-type="bibr" rid="bib20">GoodSmith et al., 2017</xref>; <xref ref-type="bibr" rid="bib62">West et al., 1991</xref>) will be more prone to differentiation. There is strong empirical support for this prediction. For example, <xref ref-type="bibr" rid="bib59">Wammes et al., 2022</xref> manipulated the similarity of stimuli in a statistical learning experiment and found that moderate levels of visual similarity were associated with significant differentiation in the dentate gyrus but not other subregions. Also, numerous studies have found greater differentiation in dentate gyrus / CA3 than in CA1 (e.g. <xref ref-type="bibr" rid="bib14">Dimsdale-Zucker et al., 2018</xref>; <xref ref-type="bibr" rid="bib61">Wanjia et al., 2021</xref>; <xref ref-type="bibr" rid="bib36">Molitor et al., 2021</xref>; <xref ref-type="bibr" rid="bib27">Kim et al., 2017</xref>; but see <xref ref-type="bibr" rid="bib66">Zheng et al., 2021</xref>).</p><p>A corollary of the model’s prediction that a high learning rate is required for differentiation is that, when differentiation does occur, it should happen abruptly. That is, when the preconditions for differentiation (fast learning, moderate competitor activity) are met, differentiation should be fully evident the next time the competitor is presented. In practice, testing this prediction about abrupt differentiation is challenging because it is not always clear <italic>when</italic> (in the time course of learning) to look for the abrupt change. For the sake of simplicity, we set up our model so the key moment of competition that drives differentiation occurs on the first trial. However, in actual experiments, the timing of this key moment of competition (and the ensuing differentiation) may vary across stimuli. For example, if a participant was inattentive the first time a stimulus was presented, this could delay the onset of competition. If each pair of items has an abrupt change at a different point in the experiment, it could look as though learning is gradual if the time courses of all pairs are averaged during analysis. For instance, <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> found that the percentage of color responses away from the pairmate (indicating repulsion) increased gradually over learning blocks; this could reflect a truly gradual change or it may be an aggregate of multiple abrupt changes occurring at different times.</p><p>One way to address this problem would be to model each item’s repulsion timecourse using either a gradual function or a step function and see which fits better. Another approach is to use converging behavioral data to identify the moment of differentiation, and then ‘time lock’ the neural analysis to that moment. <xref ref-type="bibr" rid="bib61">Wanjia et al., 2021</xref> did exactly this: They identified the moment when participants were first able to confidently recall the correct associates that had been linked to a set of pairmates (visually similar scenes, as in <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>), and then looked before and after that moment at the neural similarity of the pairmates. As predicted by our model, differentiation was not evident before this point, and it was clearly evident after this point. Yet another approach would be to use neural activity to identify the trial when a competitor first activates, and then look for differentiation after this point. There are several practical challenges with this approach, however. One challenge is that, although moderate activity is predicted to lead to differentiation, stronger activity is predicted to lead to integration, and there is no a priori way to determine whether a given level of measured activity (e.g. using fMRI decoding) corresponds to the moderate-activity or high-activity portion of the U-shaped curve (<xref ref-type="bibr" rid="bib48">Ritvo et al., 2019</xref>). Another issue is that, for similar pairmates, it can be difficult to tease them apart neurally (e.g. if you are looking at one barn, it can be difficult to sensitively detect additional neural activity of a competing, similar barn). One way to address this challenge is to link pairmates to associates from other categories (e.g. linking one pairmate to a scene and other pairmate to a face), and then look for activity of the associated category (e.g. during viewing of the face-linked pairmate, look for scene activity as a proxy for retrieval of the scene-linked pairmate); for an example of this approach see <xref ref-type="bibr" rid="bib36">Molitor et al., 2021</xref>.</p><p>Although the results from <xref ref-type="bibr" rid="bib61">Wanjia et al., 2021</xref> provide strong support for the model’s prediction that differentiation will be abrupt, they raise another question: What explains variance across items in <italic>when</italic> this abrupt change takes place? The answer to this question remains to be seen, but one possibility is encoding variability: If we assume that participants stochastically sample (i.e. attend to) the features of the scene pairmates, it is possible that participants might initially fail to sample the features that distinguish the scene pairmates, which can be quite subtle — and if the distinguishing features of the pairmates are not represented in high-level visual regions (i.e. the pairmates are represented in these regions as having the same features), this could delay the onset of differentiation until the point at which the distinguishing features happen (by chance) to be sampled.</p></sec><sec id="s3-2"><title>Asymmetry of representational change</title><p>Our model predicts that representational change will often be asymmetric. Specifically, the model predicts that differentiation will always be asymmetric, such that the item that first pops up as a competitor is the one that distorts. By contrast, integration in the model is sometimes symmetric and sometimes asymmetric (such that the hidden-layer representation of one item flips to the hidden-layer representation of the other).</p><p>As discussed earlier, testing predictions about asymmetric representational change requires a measurement of how much <italic>each individual item</italic> has moved as a result of learning. To make this measurement, it is necessary to collect both pre-learning and post-learning snapshots for each pairmate, although some fMRI studies of differentiation have done this (<xref ref-type="bibr" rid="bib59">Wammes et al., 2022</xref>; <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>; <xref ref-type="bibr" rid="bib50">Schapiro et al., 2012</xref>; <xref ref-type="bibr" rid="bib27">Kim et al., 2017</xref>; <xref ref-type="bibr" rid="bib36">Molitor et al., 2021</xref>; <xref ref-type="bibr" rid="bib61">Wanjia et al., 2021</xref>), others have not (<xref ref-type="bibr" rid="bib8">Chanales et al., 2017</xref>; <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>; <xref ref-type="bibr" rid="bib14">Dimsdale-Zucker et al., 2018</xref>; <xref ref-type="bibr" rid="bib64">Zeithamova et al., 2018</xref>). Importantly, even with a pre-post comparison, there is still the matter of determining which pairmate will anchor and which will distort. Our model predicts that the pairmate that pops up first as the competitor is the one that will distort, but in practice it is not trivial to identify which pairmate will pop up first. For example, we simplified our simulation of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> by pre-wiring strong memories for both pairmates before presenting one of the pairmates (pairmate 1) to the network. In this situation, pairmate 2 pops up as a competitor when pairmate 1 is studied, so pairmate 2 repels away from pairmate 1 and not vice versa (<xref ref-type="fig" rid="fig4">Figure 4B</xref>). However, in the actual <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> experiments, encoding strength can vary across trials for numerous reasons (e.g. fluctuating attention); if pairmate 1 is the first to establish a strong representation, it will pop up and distort when pairmate 2 is next studied, but if pairmate 2 is the first to establish a strong representation, it will pop up and distort when pairmate 1 is next studied. Just as encoding variability in <xref ref-type="bibr" rid="bib61">Wanjia et al., 2021</xref> could affect how long it takes to learn to discriminate between pairmates, encoding variability could also make it difficult to predict a priori which item in a given pair will distort in the actual <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> study.</p><p>One way to predict the asymmetry is to use a paradigm where we can be more confident which item will be the first to pop up as a competitor. For instance, an AX-BX paradigm using blocked trials like the one used by <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref> may be useful, because all AX trials occur before any BX trials. As such, we can expect that A will pop up as a competitor in response to B (and thus be the memory that distorts) and not vice versa. Studies that rely on the retrieval practice paradigm (or the reverse retrieval-induced forgetting paradigm) to look at representational change (<xref ref-type="bibr" rid="bib24">Hulbert and Norman, 2015</xref>) may also be useful, because one item in each pair (Rp+) undergoes retrieval practice whereas the other (Rp-) item does not (it is either restudied, or not presented at all during the retrieval practice phase). This arrangement makes it more likely that the Rp- item will pop up as a competitor in response to the Rp +item than vice versa. Another approach would be to use neural activity to predict which item would distort. For instance, competitor activity could be measured on a trial-by-trial basis as pairmates are studied to determine which pairmate is the first to pop up as a competitor; this approach would face the same challenges noted above (i.e. the difficulty of teasing apart target-related activity from competitor-related activity, which could possibly be addressed using the approach described by <xref ref-type="bibr" rid="bib36">Molitor et al., 2021</xref> the difficulty of determining whether activity is moderate or strong, which is less easily addressed).</p><p>Another way to test the model’s prediction about asymmetry, without having to predict which item will move and which item will anchor in place, would be to look for a bimodal distribution of results: In a paradigm like the one used by <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref>, one could look for a bimodal distribution of behavioral repulsion values across pairs (i.e. in some pairs, pairmate 1 would repel from its original color value and pairmate 2’s color value would stay relatively constant, and in other pairs the opposite would hold). The same logic could be applied to neural analysis: In some pairs, pairmate 1 would show a large change from the pre-learning to the post-learning snapshot, but pairmate 2 would not, and in other pairs the opposite would hold. The viability of this approach (i.e. trying to establish whether the results are best described by a bimodal or a unimodal distribution) will depend on the level of noise in the individual-trial data — if the measurements are too noisy, this will make it difficult to distinguish between the bimodal and unimodal alternatives.</p><p>The asymmetry of differentiation also has implications for how to measure behavioral repulsion effects, even when one is not trying to detect asymmetry. In paradigms like <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref>, our model predicts that only one item in each pair will repel. This implies that, if you measure differentiation by looking at all items (i.e. both items in a pair), you will be averaging across the pairmate that moved and the pairmate that stayed put, weakening the measured effect. Statistically, it is more powerful to use designs where there is a way of predicting a priori which item will shift and which will anchor, so you can focus on the subset of items that shift without diluting the analysis by including items that anchor.</p></sec><sec id="s3-3"><title>Testing the model’s prediction about anticorrelation</title><p>Even though we operationally define differentiation as a reduction in similarity with learning, the way that it actually shows up on individual model runs is as anticorrelation between pairmates; in the model, the size of the aggregate differentiation effect is determined by the proportion of model runs that show this anticorrelation effect (vs. no change or integration). This implies that, if we could get a clean measurement of the similarity of pairmates in an experiment, we might see a multimodal distribution, with some pairmates showing anticorrelation, and others showing increased correlation (integration) or no change in similarity. This kind of clean readout of the similarity of individual pairs might be difficult to obtain with fMRI; it is more feasible that this could be obtained with electrophysiology. Another challenge with using fMRI to test this prediction is that anticorrelation at the individual-neuron level might not scale up to yield anticorrelation at the level of the BOLD response; also, fMRI pattern similarity values can be strongly affected by preprocessing choices — so a negative pattern similarity value does not necessarily reflect anticorrelation at the individual-neuron level. A final caveat is that, while we predict that differentiation will show up as anticorrelation in the brain region that <italic>gives rise to</italic> the differentiation effect, this might not translate into anticorrelation in areas that are downstream of this region (e.g. if the hippocampus is the source of the differentiation effect, we would expect anticorrelation there, but not necessarily in neocortical regions that receive input from the hippocampus; we revisit this point later in the <italic>Discussion</italic>, when we address limitations and open questions).</p></sec><sec id="s3-4"><title>Reconciling the prevalence of differentiation in the model and in the data</title><p>A key lesson from our model is that, from a computational perspective, it is challenging to obtain differentiation effects: The region of parameter space that gives rise to differentiation is much smaller than the one that gives rise to integration (for further discussion of this issue, see the section in <italic>Methods</italic> on Practical advice for getting the model to show differentiation). However, the fact that integration is more prevalent in our simulations across parameter configurations does not mean that integration will be more prevalent than differentiation in real-life circumstances. What really matters in predicting the prevalence of differentiation in real life is how the parameters of the brain map on to parameters of the model: If the parameters of the brain align with regions of model parameter space that give rise to differentiation (even if these regions are small), this would explain why differentiation has been so robustly observed in extant studies. Indeed, this is exactly the case that we sought to make above about the hippocampus — that is its use of especially sparse coding and a high learning rate will give rise to the kinds of neural dynamics that cause differentiation (as opposed to integration). As another example, while it is true that half of the overlap conditions in our simulation of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> give rise to integration, this does not imply that integration will occur half of the time in the <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> study; it may be that the levels of overlap that are actually observed in the brain in <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> are more in line with the levels of overlap that give rise to differentiation in our model.</p></sec><sec id="s3-5"><title>Limitations and open questions</title><p>Our model can account for differentiation and integration across several scenarios. We think this provides important computational support for the NMPH explanation of representational change, and useful predictions for future work. Nonetheless, there are several ways our model can be extended in the future.</p><p>We intentionally kept our model very simple in order to create a ‘sandbox’ to explore the dynamics at play during learning. We used no initial study task for our model, and we instead opted for pre-wired connections in order to precisely manipulate the initial hidden-layer overlap between the pairmates and the relative strengths of their representations.</p><p>Rather than skipping initial stimulus learning and focusing on the first moment that competition happens, future work can investigate the trials leading up to this moment in the course of learning. For instance, our model of <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref> instantiates interleaved vs. blocked learning by changing the initial weights connecting the hidden layer to the unit representing the shared associate in the output layer. Future models could instead show stimuli in a blocked or interleaved fashion with learning turned on, which should lead to the kind of weights we pre-wired into the model.</p><p>The model could also be expanded to be more biologically realistic. For example, instantiating the NMPH in a more detailed model of the hippocampus (e.g. <xref ref-type="bibr" rid="bib53">Schapiro et al., 2017</xref>; <xref ref-type="bibr" rid="bib40">Norman and O’Reilly, 2003</xref>) would allow us to simulate the contributions of different hippocampal subfields to representational change (e.g. contrasting the monosynaptic and trisynaptic pathways; <xref ref-type="bibr" rid="bib53">Schapiro et al., 2017</xref>). Extending this further, building a model that incorporates both hippocampal and neocortical regions would make it possible to explore how NMPH learning in the hippocampus can support neocortical learning. Although our simulations suggest that neocortex on its own cannot enact differentiation via NMPH learning (due to neocortex’s slow learning rate, which causes it to ‘relapse’ and reabsorb formerly shared units), we hypothesize that — in the longer term — hippocampus may be able to act as a teacher to support long-lasting differentiation within neocortex. Specifically, we hypothesize that — once differentiated hippocampal representations have been formed — these representations can provide a source of top-down activity to the unique features of the corresponding neocortical representations (e.g. unique features of the similar barns in <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>). This hippocampally-mediated attention to unique features in neocortex may help neocortex (gradually) learn to represent and leverage subtle differences between pairmates. Importantly, while hippocampus can boost the representation of unique features in neocortex, we expect that neocortex will continue to represent shared perceptual features (e.g. in <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>, the fact that both pairmates are photos of barns). For this reason, in paradigms like the one used by <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>, the predicted effect of hippocampal differentiation on neocortical representations will be a reduction in pattern similarity (due to upregulation in the representation of unique pairmate features) but neocortex should not cross over into anticorrelation in these paradigms (due to its continued representation of shared perceptual features). Indeed, this is exactly the pattern that <xref ref-type="bibr" rid="bib61">Wanjia et al., 2021</xref> observed in their study, which used similar stimuli to those used in <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref>. We will explore these ideas in future simulations.</p><p>Our keep-things-simple approach led us to focus on NMPH learning in the simulations presented here; in future work, we plan to explore how NMPH interacts with error-driven (supervised) learning. As discussed in the <italic>Introduction</italic>, supervised learning is not sufficient to explain effects modeled here. However, there is widespread agreement that error-driven learning happens in the brain (although its mechanisms are still under active investigation; <xref ref-type="bibr" rid="bib47">Richards et al., 2019</xref>; <xref ref-type="bibr" rid="bib46">Payeur et al., 2021</xref>; <xref ref-type="bibr" rid="bib30">Lillicrap et al., 2020</xref>; <xref ref-type="bibr" rid="bib63">Whittington and Bogacz, 2019</xref>), and it may interact with and/or complement the NMPH principles explored here in interesting ways. In the computer vision literature, supplementing supervised learning algorithms with unsupervised learning algorithms (some of which are very similar to the NMPH, in that they pull together the representations of strongly similar items and push apart the embeddings of moderately similar items; <xref ref-type="bibr" rid="bib67">Zhuang et al., 2019</xref>) can boost model performance in some circumstances (<xref ref-type="bibr" rid="bib68">Zhuang et al., 2021</xref>). However, mixing unsupervised with supervised learning in models of neocortex has a substantial drawback: Once an unsupervised learning algorithm has decided that two stimuli are similar enough to pull together their representations, it can be very difficult to pull them apart again, even if this needs to be done to solve a task; this point was initially demonstrated in the domain of auditory learning by <xref ref-type="bibr" rid="bib33">McClelland et al., 1999</xref> and <xref ref-type="bibr" rid="bib31">Mccandliss et al., 2002</xref>. In this situation, hippocampal differentiation (which is <italic>not</italic> part of extant computer vision models) may play a key role in helping neocortex avoid this kind of ‘premature collapse’ of representations. In future work, we also plan to explore the influence of other biologically inspired learning principles, including the principle of metaplasticity (whereby the transition points between strengthening and weakening are adjusted as a function of activity), which has previously been shown to play an important role in NMPH-style learning (<xref ref-type="bibr" rid="bib5">Bear, 2003</xref>).</p><p>Another important future direction is to apply the model to a wider range of learning phenomena involving representational change — for example, acquired equivalence, which (like some of the studies modeled here) involves linking distinct stimuli to a shared associate (see, e.g. <xref ref-type="bibr" rid="bib23">Honey and Hall, 1989</xref>; <xref ref-type="bibr" rid="bib55">Shohamy and Wagner, 2008</xref>; <xref ref-type="bibr" rid="bib37">Myers et al., 2003</xref>; <xref ref-type="bibr" rid="bib35">Meeter et al., 2009</xref>; <xref ref-type="bibr" rid="bib11">de Araujo Sanchez and Zeithamova, 2023</xref>). It is possible that some of these phenomena might be better explained by supervised learning, or a mixture of unsupervised and supervised learning, than by unsupervised learning alone.</p><p>Yet another direction to explore is how cognitive control and attention modulate representational change. The simulations described in this paper provide an existence proof of how — if the conditions are right (e.g. moderate competitor activity, suitably high learning rate) — differentiation can occur automatically, without participants having to deliberately focus their attention on discriminative features of the pairmates. However, it is surely the case that attention can modulate these learning effects (<xref ref-type="bibr" rid="bib2">Amer and Davachi, 2023</xref>; see the Practical advice section in the <italic>Methods</italic> for a brief discussion of this point).</p></sec><sec id="s3-6"><title>Summary</title><p>The model presented in this paper provides a concrete computational instantiation of the NMPH account of representational change set forth in <xref ref-type="bibr" rid="bib48">Ritvo et al., 2019</xref>. By modulating competitor activity in different ways (by varying stimulus similarity, presence of shared associates, learning curriculum, and inhibitory dynamics) and tracking how this affects learning, our model serves several purposes: It provides an existence proof of how the NMPH can explain otherwise-puzzling findings regarding representational change (e.g. why linking to a shared associate can promote differentiation); it provides principled new explanations of certain patterns in the literature (e.g. why differentiation is more frequently observed in the hippocampus than in neocortex); and it makes novel, testable predictions (e.g. regarding the asymmetry of differentiation). Although more work remains to be done to explore the consequences of this U-shaped learning function for representational change, we hope our model can be useful in framing future modeling and empirical research on learning.</p></sec></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Model architecture</title><p>We built our computational model using the Leabra algorithm (<xref ref-type="bibr" rid="bib44">O’Reilly, 2012</xref>) within the Emergent neural network simulation software (<xref ref-type="bibr" rid="bib1">Aisa et al., 2008</xref>), which is written in the programming language Go. We constructed the model as described in <italic>Basic Network Properties</italic>, and adapted the parameters to model the three individual studies.</p></sec><sec id="s4-2"><title>Approach to parameterization and data fitting</title><p>The overall goal of this modeling work is to account for key empirical regularities regarding differentiation and integration and to establish boundary conditions on these regularities. As such, the modeling work described below focuses more on qualitative fits to general properties of the data space than on quantitative fits to results from specific studies. Automatic parameter optimization is not feasible for this kind of model, given the large number of model parameters and the highly interactive, nonlinear nature of competitive dynamics in the model; consequently, model fitting was done by hand.</p><p>These complex interactions between parameters also make it infeasible to list ‘critical parameter ranges’ for generating particular model outcomes. Our experience in working with the model has been that activation dynamics are what matter most for learning, and that disparate parameter sets can give rise to the same activation dynamics and — through this — the same learning effects; likewise, similar parameter sets can give rise to different activation dynamics and different learning outcomes. Consequently, in this paper we have focused on characterizing the dynamics that give rise to different learning effects (and how they can be affected by local parameter perturbations, e.g. relating to learning rate and oscillation size), rather than the — impossible, we believe — task of enumerating the full set of parameter configurations that give rise to a particular result.</p><p>While the core model architecture and dynamics were the same for all three simulations, the specific parameters that we used differed in small ways across the three simulations. The need to make these parameter adjustments is a consequence of the small-scale nature of the model. In a more realistic, large-scale model with more stored knowledge, changing the structure of what is being learned in the to-be-simulated paradigm would not meaningfully affect the overall knowledge state of the model (adding two memories if you already have thousands is not a big deal) and thus would not require parameter changes. However, if you are starting with a ‘blank brain’, the exact way that you structure the to-be-learned memories matters; for example, having a topographic color projection to represent repulsion effects in our simulation of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref> can have large effects on network dynamics that require downstream adjustments in other parameters.</p><p>To generate the results shown in the figures here, we ran the model 50 times, each time starting with a different random seed. Results plots show the mean level of performance across model runs and the 95% confidence interval around the mean.</p><sec id="s4-2-1"><title>Activity and inhibitory dynamics</title><p>Emergent simplifies the discrete on-off firing of individual neurons into a rate code approximation where a unit’s activity can range from 0 to 1; this rate code reflects the unit’s current level of excitatory and inhibitory inputs. A given unit M’s excitatory input is a function of the activity of all other units N connected to it, weighted by the strengths of the connections between the N units and M. The function relating excitatory input to activity (after accounting for inhibition; see below and <xref ref-type="bibr" rid="bib44">O’Reilly, 2012</xref>) is S-shaped and bounded between 0–1, where the steepness of the function is modulated by a gain factor. Lowering the gain creates a more graded response, which enables moderate pop up of competitor units. The gain for each layer is written in <xref ref-type="table" rid="table1">Table 1</xref> (<italic>XX1 Gain</italic>), along with the other activity and inhibitory parameters for these models. When an external input is clamped to a layer, the external input is multiplied by a <italic>Clamp Gain</italic> factor, which modulates how strongly it should contribute to activity compared to other excitatory inputs that the unit is receiving (from elsewhere in the network).</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Parameters for layer inhibitory and activity dynamics.</title><p><italic>kWTA Point</italic> = a value between 0 and 1, which indicates how far toward the <inline-formula><mml:math id="inf6"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mn>1</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> unit to place the current inhibitory level (the higher <italic>kWTA Point</italic>, the lower the inhibition value). <italic>Target Diff</italic> = the threshold for determining whether units after the <inline-formula><mml:math id="inf7"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>k</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> unit should be allowed to be active (see text). <italic>Osc</italic> = the amplitude of the oscillation function that multiplies the overall inhibition level of the layer. Note that for the model of <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>, we tested three different hidden-layer oscillation amounts: 0.0623, 0.0525 and 0.09. <italic>XX1 Gain</italic> = the multiplier on the S-shaped activity function, where lower values means that activity will be more graded. <italic>Clamp Gain</italic> multiplies the external input, modifying how strongly it contributes to the activity of the layer.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Model</th><th align="left" valign="bottom">Layer</th><th align="left" valign="bottom">K</th><th align="left" valign="bottom">K Max</th><th align="left" valign="bottom">kWTA Point</th><th align="left" valign="bottom">Target Diff</th><th align="left" valign="bottom">Osc</th><th align="left" valign="bottom">XX1 Gain</th><th align="left" valign="bottom">Clamp Gain</th></tr></thead><tbody><tr><td align="left" valign="bottom">Chanales</td><td align="left" valign="bottom">Output</td><td align="left" valign="bottom">6</td><td align="left" valign="bottom">15</td><td align="left" valign="bottom">0.95</td><td align="left" valign="bottom">0.05</td><td align="left" valign="bottom">0.115</td><td align="left" valign="bottom">30</td><td align="left" valign="bottom">—</td></tr><tr><td align="left" valign="bottom">Chanales</td><td align="left" valign="bottom">Hidden</td><td align="left" valign="bottom">6</td><td align="left" valign="bottom">10</td><td align="left" valign="bottom">0.75</td><td align="left" valign="bottom">0.03</td><td align="left" valign="bottom">0.11</td><td align="left" valign="bottom">100</td><td align="left" valign="bottom">—</td></tr><tr><td align="left" valign="bottom">Chanales</td><td align="left" valign="bottom">Category</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf8"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">∞</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.75</td><td align="left" valign="bottom">0</td><td align="left" valign="bottom">0</td><td align="left" valign="bottom">100</td><td align="left" valign="bottom">2</td></tr><tr><td align="left" valign="bottom">Chanales</td><td align="left" valign="bottom">Item</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">∞</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.95</td><td align="left" valign="bottom">0.2</td><td align="left" valign="bottom">0.22</td><td align="left" valign="bottom">100</td><td align="left" valign="bottom">0.3</td></tr><tr><td align="left" valign="bottom">Favila</td><td align="left" valign="bottom">Output</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf10"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">∞</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.75</td><td align="left" valign="bottom">0.03</td><td align="left" valign="bottom">0.07</td><td align="left" valign="bottom">100</td><td align="left" valign="bottom">—</td></tr><tr><td align="left" valign="bottom">Favila</td><td align="left" valign="bottom">Hidden</td><td align="left" valign="bottom">6</td><td align="left" valign="bottom">10</td><td align="left" valign="bottom">0.8</td><td align="left" valign="bottom">0.02</td><td align="left" valign="bottom">0.067</td><td align="left" valign="bottom">100</td><td align="left" valign="bottom">—</td></tr><tr><td align="left" valign="bottom">Favila</td><td align="left" valign="bottom">Category</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">∞</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.75</td><td align="left" valign="bottom">0</td><td align="left" valign="bottom">0</td><td align="left" valign="bottom">100</td><td align="left" valign="bottom">2</td></tr><tr><td align="left" valign="bottom">Favila</td><td align="left" valign="bottom">Item</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">∞</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.95</td><td align="left" valign="bottom">0.2</td><td align="left" valign="bottom">0.2</td><td align="left" valign="bottom">100</td><td align="left" valign="bottom">0.3</td></tr><tr><td align="left" valign="bottom">Schlichting</td><td align="left" valign="bottom">Output</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">∞</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.75</td><td align="left" valign="bottom">0.03</td><td align="left" valign="bottom">0.03</td><td align="left" valign="bottom">100</td><td align="left" valign="bottom">—</td></tr><tr><td align="left" valign="bottom">Schlichting</td><td align="left" valign="bottom">Hidden</td><td align="left" valign="bottom">6</td><td align="left" valign="bottom">10</td><td align="left" valign="bottom">0.8</td><td align="left" valign="bottom">0.02</td><td align="left" valign="bottom">0.0623</td><td align="left" valign="bottom">100</td><td align="left" valign="bottom">—</td></tr><tr><td align="left" valign="bottom">Schlichting</td><td align="left" valign="bottom">Category</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf14"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">∞</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.75</td><td align="left" valign="bottom">0</td><td align="left" valign="bottom">0</td><td align="left" valign="bottom">100</td><td align="left" valign="bottom">2</td></tr><tr><td align="left" valign="bottom">Schlichting</td><td align="left" valign="bottom">Item</td><td align="left" valign="bottom">1</td><td align="left" valign="bottom"><inline-formula><mml:math id="inf15"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi mathvariant="normal">∞</mml:mi></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.95</td><td align="left" valign="bottom">0.2</td><td align="left" valign="bottom">0.156</td><td align="left" valign="bottom">100</td><td align="left" valign="bottom">0.3</td></tr></tbody></table></table-wrap><p>A unit’s activity is also modulated by the inhibitory dynamics in the layer. We implemented inhibition using a variant of the <italic>k-winners take all</italic> (kWTA) algorithm (<xref ref-type="bibr" rid="bib43">O’Reilly and Munakata, 2000</xref>). This algorithm imposes a ‘set point’-like behavior on inhibition, ensuring that at most <inline-formula><mml:math id="inf16"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi></mml:mstyle></mml:math></inline-formula> units are allowed to activate in a layer. In the standard version of the kWTA algorithm, the units in a layer are ranked in terms of the amount of inhibition that would be needed to put that unit at the threshold of activating, given its current excitatory input. Then, inhibition is set such that only the <inline-formula><mml:math id="inf17"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi></mml:mstyle></mml:math></inline-formula> highest-ranked units are able to reach the activity threshold.</p><p>In our simulations, we adjusted the kWTA algorithm to give the model the ability to activate more than <inline-formula><mml:math id="inf18"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi></mml:mstyle></mml:math></inline-formula> units in certain circumstances (<xref ref-type="fig" rid="fig11">Figure 11</xref>). This flexibility is helpful for integration: Allowing more than <inline-formula><mml:math id="inf19"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi></mml:mstyle></mml:math></inline-formula> units to be active makes it possible for the model to incorporate units from both pairmates into the new, integrated representation. To provide this flexibility, we adjusted the kWTA algorithm to allow units that are tied in the ranking (within a threshold amount reflected by the <italic>Target Diff</italic> parameter) to activate as well. We also included a cap on the total number of units allowed to activate even with the tie (reflected by the <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>K</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mstyle></mml:math></inline-formula> parameter). So if <inline-formula><mml:math id="inf21"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>6</mml:mn></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf22"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>K</mml:mi><mml:mi mathvariant="normal">_</mml:mi><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mstyle></mml:math></inline-formula>, the top 6 units will be allowed to activate, as well as optionally any units beyond the top 6 that are tied (within some threshold specified by <italic>Target Diff</italic>), but no more than 10 units can be active.</p><fig id="fig11" position="float"><label>Figure 11.</label><caption><title>Schematic of adjusted KWTA algorithm.</title><p>Units are ranked according to the amount of inhibition that would be needed to put the unit at threshold of activity. This is proportional to excitation: The more excitation the unit receives, the more inhibition is needed to cancel out the excitation and put the unit at threshold. In the classic KWTA algorithm, inhibition is set such that only the <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi></mml:mstyle></mml:math></inline-formula> highest ranked units activate. We added a <italic>Target Diff</italic> parameter to potentially allow more units to activate, if units are ‘tied’ with the <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>k</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> unit. If a unit below the <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>k</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> unit in the rank ordering of units is within <italic>Target Diff</italic> of the <inline-formula><mml:math id="inf26"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>k</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> unit, then it is considered to be ‘tied’ with the <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>k</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> unit, and it is allowed to activate. In this example, the 6th, 7th, and 8th unit are tied in the ranking, because the difference is less than <italic>Target Diff</italic>. Consequently, inhibition is set such that 8 units activate.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-fig11-v1.tif"/></fig><p>Note that, in addition to allowing more than <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi></mml:mstyle></mml:math></inline-formula> units to be active, this modification also helps to solve an issue with the classic implementation of kWTA that emerges when the inhibition needed to put the <inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>k</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> unit at threshold is very close to the value needed for the <inline-formula><mml:math id="inf30"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mn>1</mml:mn><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> unit. In the classic implementation of kWTA, this situation results in the <inline-formula><mml:math id="inf31"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>k</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> unit’s activity being very close to zero (since it is only slightly above threshold); effectively, fewer than <inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>k</mml:mi></mml:mstyle></mml:math></inline-formula> units end up being active. This issue would occur, for example, with the configuration of values shown in <xref ref-type="fig" rid="fig11">Figure 11</xref>; with classic kWTA, the 5th and 6th units would be just above threshold and thus barely active. This issue can make it difficult for the competitor to pick up new units in conditions that lead to differentiation (because the new units often receive very similar levels of excitation). With the modified kWTA algorithm, the model is free to find a ‘break point’ beyond the <inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>k</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> unit that allows the new units to be more robustly active.</p><p>Lastly, inhibition is modulated by oscillations; these inhibitory oscillations play a key role in regulating the amount of competitor activity. The layer’s inhibition is initially constant (determined by the kWTA calculation described above), and then at cycle 125 is varied according to a sine wave (with amplitude set by the parameter <italic>Osc</italic>) until the end of the trial at cycle 200. Concretely, inhibition is sinusoidally raised above baseline from cycles 125–163, and then lowered below baseline from cycles 164–200. The raising of inhibition does not have much impact on the network activity (because the external clamping is strong enough to offset the raising of inhibition), but lowering the inhibition allows the competitors to activate.</p></sec><sec id="s4-2-2"><title>Projections between layers</title><p>The weight of any given connection between two units could range from 0 to 1. The two input layers are connected to the hidden layer, which is in turn connected to the output layer. The hidden layer also has recurrent connections. Generally the output layer does not have recurrent connections, except for our model of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref>, where we included fixed-strength recurrent output-to-output connections to simulate topographically organized color representations. All projections were bidirectional: Activity was allowed to flow forwards and backwards through the network. Parameters for each bidirectional projection were identical except for the <italic>Wt Scale</italic>, which indicated the overall strength of the projection from one layer to another.</p><p>All layers that were connected were connected fully — that is, all units in one layer were connected to all units in the other layer. Most of these connections were random and low in magnitude, except for a set of pre-wired connections that were stronger, as described in <italic>Basic Network Properties</italic>. Any pre-wired connections that differed between versions of the model are included in the sections of this paper on the set up of each model. All pre-wired, non-random connections were set to have a strength of 0.99 unless otherwise indicated. The parameters for the random connections are shown in <xref ref-type="table" rid="table2">Table 2</xref>.</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Projection parameters: <italic>Wt Range</italic> = range of the uniform distribution used to initialize the random weights between each projection (range does not include the maximally strong pre-wired connections described in the text, which were set to 0.99 unless stated otherwise).</title><p><italic>Wt Scale</italic> = the scaling of the projection, operationalized as an absolute multiplier on the weights in the projection.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Model</th><th align="left" valign="bottom">Projection</th><th align="left" valign="bottom">Wt Range</th><th align="left" valign="bottom">Wt Scale (Forwards / Backwards)</th></tr></thead><tbody><tr><td align="left" valign="bottom">Chanales</td><td align="left" valign="bottom">Hidden ↔ Hidden</td><td align="left" valign="bottom">0.45–0.55</td><td align="left" valign="bottom">1.8/1.8</td></tr><tr><td align="left" valign="bottom">Chanales</td><td align="left" valign="bottom">Hidden↔ Output</td><td align="left" valign="bottom">0.01–0.03</td><td align="left" valign="bottom">3.0/2.0</td></tr><tr><td align="left" valign="bottom">Chanales</td><td align="left" valign="bottom">Category↔Hidden</td><td align="left" valign="bottom">0.01–0.03</td><td align="left" valign="bottom">0.2/0.2</td></tr><tr><td align="left" valign="bottom">Chanales</td><td align="left" valign="bottom">Item ↔Hidden</td><td align="left" valign="bottom">0.45–0.55</td><td align="left" valign="bottom">0.2/0.2</td></tr><tr><td align="left" valign="bottom">Chanales</td><td align="left" valign="bottom">Output ↔Output</td><td align="left" valign="bottom">0.01–0.03</td><td align="left" valign="bottom">1.0/1.0</td></tr><tr><td align="left" valign="bottom">Favila</td><td align="left" valign="bottom">Hidden ↔Hidden</td><td align="left" valign="bottom">0.45–0.55</td><td align="left" valign="bottom">1.8/1.8</td></tr><tr><td align="left" valign="bottom">Favila</td><td align="left" valign="bottom">Hidden ↔Output</td><td align="left" valign="bottom">0.01–0.03</td><td align="left" valign="bottom">1.2/1.7</td></tr><tr><td align="left" valign="bottom">Favila</td><td align="left" valign="bottom">Category ↔Hidden</td><td align="left" valign="bottom">0.01–0.03</td><td align="left" valign="bottom">0.1/0.1</td></tr><tr><td align="left" valign="bottom">Favila</td><td align="left" valign="bottom">Item ↔Hidden</td><td align="left" valign="bottom">0.45–0.55</td><td align="left" valign="bottom">0.3/0.2</td></tr><tr><td align="left" valign="bottom">Schlichting</td><td align="left" valign="bottom">Hidden ↔Hidden</td><td align="left" valign="bottom">0.45–0.55</td><td align="left" valign="bottom">1.9/1.9</td></tr><tr><td align="left" valign="bottom">Schlichting</td><td align="left" valign="bottom">Hidden ↔Output</td><td align="left" valign="bottom">0.01–0.03</td><td align="left" valign="bottom">1.2/1.7</td></tr><tr><td align="left" valign="bottom">Schlichting</td><td align="left" valign="bottom">Category ↔Hidden</td><td align="left" valign="bottom">0.01–0.03</td><td align="left" valign="bottom">0.2/0.1</td></tr><tr><td align="left" valign="bottom">Schlichting</td><td align="left" valign="bottom">Item ↔Hidden</td><td align="left" valign="bottom">0.45–0.55</td><td align="left" valign="bottom">0.3/0.2</td></tr></tbody></table></table-wrap><p>The random low-level connections constitute one of two sources of variance in the model, the other being the trial order for most simulations (described below in <italic>Stimulus Presentation</italic>).</p></sec><sec id="s4-2-3"><title>A note on prewiring representations</title><p>In our model, our practice of ‘prewiring’ memory representations for the A and B pairmates serves two functions. In some cases, it is meant to stand in for actual training (as in the blocked / interleaved manipulation; the connections supporting the AX association are prewired to be stronger in the blocked condition than in the interleaved condition). However, the other, more fundamental role of prewiring is to ensure that the A and B input patterns evoke sparse distributed representations in the hidden layer (i.e. where some units are strongly active but most other units are inactive). In the real brain, this happens automatically because the weight landscape has been extensively sculpted by both experience and evolution. For example, in the real hippocampus, when the second pairmate is presented for the first time, it will evoke a sparse distributed representation in the CA3 subfield (potentially overlapping with the first pairmate’s CA3 representation) even before any learning of the second pairmate has occurred, due to the strong, sparse mossy fiber projections that connect the dentate gyrus to CA3 (<xref ref-type="bibr" rid="bib34">McNaughton and Morris, 1987</xref>). As discussed above, we hypothesize that this initial, partial overlap between the second pairmate’s representation and the first pairmate’s representation can lead to pop-up of the unique features of the first pairmate’s representation, triggering learning that leads to differentiation or integration. In our small-scale model, we are effectively starting with a ‘blank brain’; in the absence of prewiring, the A and B inputs would activate overly diffuse representations that do not support these kinds of competitive dynamics. As such, prewiring in our model is necessary for its proper functioning. The presence of prewired A and B representations should therefore not be interpreted as reflecting a particular training history (except in the blocked / interleaved case above); rather, these prewired representations constitute the minimum step we would take to ensure well-defined competitive dynamics in our small-scale model.</p><p>The fact that connection strengths serve this dual function — sometimes reflecting effects of training (as in our simulation of <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>) and in other cases reflecting necessary prewiring — complicates the interpretation of these strength values in the model. Our view is that this is a necessary limitation of our simplified modeling approach — one that can eventually be surmounted through the use of more biologically-detailed architectures (see the <italic>Limitations and Open Questions</italic> section in the <italic>Discussion</italic>).</p></sec></sec><sec id="s4-3"><title>Learning</title><p>We used only unsupervised NMPH learning in this model since we wanted to test whether the NMPH was sufficient to produce the representational changes observed in these experiments. Each of the projections in the model could be modified through learning, except for the topographic output-to-output projection in the model of <xref ref-type="bibr" rid="bib9">Chanales et al., 2021</xref>.</p><p>After each training trial, connection weights were adjusted based on the coactivity of the units on that trial. For each pair of connected units, the coactivity is computed as the product of both units’ medium-term running average activity (defined below). The U-shaped function is defined by five parameters (<xref ref-type="fig" rid="fig12">Figure 12</xref>), and is applied to this coactivity value to calculate the magnitude and direction of the weight change.</p><fig id="fig12" position="float"><label>Figure 12.</label><caption><title>U-shaped learning function.</title><p><inline-formula><mml:math id="inf34"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>D</mml:mi><mml:mi>T</mml:mi><mml:mi>h</mml:mi><mml:mi>r</mml:mi></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf35"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>D</mml:mi><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>T</mml:mi><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mi>P</mml:mi></mml:mstyle></mml:math></inline-formula> are X-axis coordinates. <inline-formula><mml:math id="inf37"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>D</mml:mi><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf38"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>D</mml:mi><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi></mml:mstyle></mml:math></inline-formula> are Y-axis coordinates, and indicate the amount of peak weakening or strengthening.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-fig12-v1.tif"/></fig><p>Intuitively, medium-term running average activity is an integrated measure of the unit’s activity across the trial and is hierarchically computed from the unit’s super-short- and short-term average activity. The equations for computing medium-term running average activity were taken from the Leabra algorithm described in <xref ref-type="bibr" rid="bib45">O’Reilly, 2018</xref>; for additional conceptual motivation for approach, see <xref ref-type="bibr" rid="bib44">O’Reilly, 2012</xref>. First, the activity of each unit is integrated to yield a super-short-term average of unit activity:<disp-formula id="equ1"><mml:math id="m1"><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mi>t</mml:mi><mml:mtext>super-short</mml:mtext></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mtext>super-short</mml:mtext></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>α</mml:mi><mml:mtext>super-short</mml:mtext></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mtext>super-short</mml:mtext></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf39"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>x</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:math></inline-formula> is the activity of the unit at time <inline-formula><mml:math id="inf40"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi></mml:mstyle></mml:math></inline-formula>, <inline-formula><mml:math id="inf41"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>super-short</mml:mtext></mml:mrow></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> is the super-short-term average activity at time <inline-formula><mml:math id="inf42"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf43"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>α</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>super-short</mml:mtext></mml:mrow></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> is the super-short-term time scale constant. Next, super-short-term average activity is integrated to yield short-term average activity:<disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mi>t</mml:mi><mml:mtext>short</mml:mtext></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mtext>short</mml:mtext></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>α</mml:mi><mml:mtext>short</mml:mtext></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mi>t</mml:mi><mml:mtext>super-short</mml:mtext></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mtext>short</mml:mtext></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf44"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>short</mml:mtext></mml:mrow></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> is the short-term activity at time <inline-formula><mml:math id="inf45"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf46"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>α</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>short</mml:mtext></mml:mrow></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> is the short-term time scale constant. Lastly, short-term average activity is integrated to yield the raw medium-term average activity:<disp-formula id="equ3"><mml:math id="m3"><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mi>t</mml:mi><mml:mtext>raw medium</mml:mtext></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mtext>raw medium</mml:mtext></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>α</mml:mi><mml:mtext>raw medium</mml:mtext></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mi>t</mml:mi><mml:mtext>short</mml:mtext></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mtext>raw medium</mml:mtext></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf47"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>raw medium</mml:mtext></mml:mrow></mml:mrow></mml:msubsup></mml:mstyle></mml:math></inline-formula> is the raw medium-term activity at time <inline-formula><mml:math id="inf48"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>α</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>raw medium</mml:mtext></mml:mrow></mml:mrow></mml:msup></mml:mstyle></mml:math></inline-formula> is the medium-term time scale constant. The final medium-term average activity is computed as a linear combination of raw medium-term average activity and the short-term average activity:<disp-formula id="equ4"><mml:math id="m4"><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mtext>medium</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>α</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mtext>raw medium</mml:mtext></mml:mrow></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>β</mml:mi><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mtext>short</mml:mtext></mml:mrow></mml:mrow></mml:msubsup></mml:mrow></mml:math></disp-formula></p><p>The coactivity <inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>κ</mml:mi></mml:mstyle></mml:math></inline-formula> between the receiver unit and the sender unit is the product between the final medium-long term average activity between those two units:<disp-formula id="equ5"><mml:math id="m5"><mml:mrow><mml:mi>κ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>μ</mml:mi><mml:mtext>receiver</mml:mtext><mml:mtext>medium</mml:mtext></mml:msubsup><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>μ</mml:mi><mml:mtext>sender</mml:mtext><mml:mtext>medium</mml:mtext></mml:msubsup></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>This coactivity is fed into the U-shaped function, and then the resulting value is multiplied by a scalar learning rate parameter, <italic>LRate</italic>, to obtain the final weight change value. <italic>LRate</italic> was set to 1 for all of our simulations except for the simulations where we explicitly manipulated learning rate.</p><p>The values of the time scale parameters used to compute running averages were unchanged from the defaults used in <xref ref-type="bibr" rid="bib45">O’Reilly, 2018</xref>: <inline-formula><mml:math id="inf51"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msup><mml:mi>α</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>super-short</mml:mtext></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>α</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>short</mml:mtext></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>α</mml:mi><mml:mrow class="MJX-TeXAtom-ORD"><mml:mrow class="MJX-TeXAtom-ORD"><mml:mtext>% raw medium</mml:mtext></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mstyle></mml:math></inline-formula>. The linear combination parameters were set to <inline-formula><mml:math id="inf52"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn></mml:mstyle></mml:math></inline-formula> (whereas in the original Leabra models they were set to <inline-formula><mml:math id="inf53"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo><mml:mi>β</mml:mi><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>).</p><p>The five parameters that define the U-shaped function were set separately for each projection in each model, such that — when moderate competitor pop-up occurred — the competitor-shared connections would be severed. All reciprocal connections (e.g. output-to-hidden and hidden-to-output) had identical U-shaped functions. Once the U-shaped function was set for a connection, those were the parameters used for all runs of the model, in all conditions. The parameters for each learning function can be found in <xref ref-type="table" rid="table3">Table 3</xref>.</p><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Learning parameters: All parameters are defined in <xref ref-type="fig" rid="fig12">Figure 12</xref>.</title><p>All bidirectional connections used the same parameters for the U-shaped learning function (e.g. the parameters for item-to-hidden matched the parameters for hidden-to-item).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Model</th><th align="left" valign="bottom">Projection</th><th align="left" valign="bottom">DThr</th><th align="left" valign="bottom">DRev</th><th align="left" valign="bottom">DRevMag</th><th align="left" valign="bottom">ThrP</th><th align="left" valign="bottom">DMaxMag</th></tr></thead><tbody><tr><td align="left" valign="bottom">Chanales</td><td align="left" valign="bottom">Hidden↔Hidden</td><td align="char" char="." valign="bottom">0.15</td><td align="char" char="." valign="bottom">0.24</td><td align="char" char="." valign="bottom">–4.5</td><td align="char" char="." valign="bottom">0.4</td><td align="char" char="." valign="bottom">0.1</td></tr><tr><td align="left" valign="bottom">Chanales</td><td align="left" valign="bottom">Hidden↔Output</td><td align="char" char="." valign="bottom">0.1</td><td align="char" char="." valign="bottom">0.44</td><td align="char" char="." valign="bottom">–10</td><td align="char" char="." valign="bottom">0.6</td><td align="char" char="." valign="bottom">1.5</td></tr><tr><td align="left" valign="bottom">Chanales</td><td align="left" valign="bottom">Category ↔Hidden</td><td align="char" char="." valign="bottom">0.2</td><td align="char" char="." valign="bottom">0.3</td><td align="char" char="." valign="bottom">–0.1</td><td align="char" char="." valign="bottom">0.46</td><td align="char" char="." valign="bottom">0.06</td></tr><tr><td align="left" valign="bottom">Chanales</td><td align="left" valign="bottom">Item ↔Hidden</td><td align="char" char="." valign="bottom">0.2</td><td align="char" char="." valign="bottom">0.3</td><td align="char" char="." valign="bottom">–2.5</td><td align="char" char="." valign="bottom">0.46</td><td align="char" char="." valign="bottom">0.3</td></tr><tr><td align="left" valign="bottom">Chanales</td><td align="left" valign="bottom">Output ↔Output</td><td align="char" char="." valign="bottom">0.53</td><td align="char" char="." valign="bottom">0.6</td><td align="char" char="." valign="bottom">–0.3</td><td align="char" char="." valign="bottom">0.68</td><td align="char" char="." valign="bottom">0.3</td></tr><tr><td align="left" valign="bottom">Favila</td><td align="left" valign="bottom">Hidden ↔Hidden</td><td align="char" char="." valign="bottom">0.11</td><td align="char" char="." valign="bottom">0.23</td><td align="char" char="." valign="bottom">–1.5</td><td align="char" char="." valign="bottom">0.4</td><td align="char" char="." valign="bottom">0.1</td></tr><tr><td align="left" valign="bottom">Favila</td><td align="left" valign="bottom">Hidden ↔Output</td><td align="char" char="." valign="bottom">0.11</td><td align="char" char="." valign="bottom">0.23</td><td align="char" char="." valign="bottom">–0.01</td><td align="char" char="." valign="bottom">0.4</td><td align="char" char="." valign="bottom">0.5</td></tr><tr><td align="left" valign="bottom">Favila</td><td align="left" valign="bottom">Category ↔Hidden</td><td align="char" char="." valign="bottom">0.2</td><td align="char" char="." valign="bottom">0.3</td><td align="char" char="." valign="bottom">–0.1</td><td align="char" char="." valign="bottom">0.46</td><td align="char" char="." valign="bottom">0.06</td></tr><tr><td align="left" valign="bottom">Favila</td><td align="left" valign="bottom">Item ↔Hidden</td><td align="char" char="." valign="bottom">0.215</td><td align="char" char="." valign="bottom">0.4</td><td align="char" char="." valign="bottom">–2.5</td><td align="char" char="." valign="bottom">0.6</td><td align="char" char="." valign="bottom">0.3</td></tr><tr><td align="left" valign="bottom">Schlichting</td><td align="left" valign="bottom">Hidden ↔Hidden</td><td align="char" char="." valign="bottom">0.11</td><td align="char" char="." valign="bottom">0.23</td><td align="char" char="." valign="bottom">–1.5</td><td align="char" char="." valign="bottom">0.4</td><td align="char" char="." valign="bottom">1</td></tr><tr><td align="left" valign="bottom">Schlichting</td><td align="left" valign="bottom">Hidden ↔Output</td><td align="char" char="." valign="bottom">0.11</td><td align="char" char="." valign="bottom">0.23</td><td align="char" char="." valign="bottom">–0.01</td><td align="char" char="." valign="bottom">0.4</td><td align="char" char="." valign="bottom">0.5</td></tr><tr><td align="left" valign="bottom">Schlichting</td><td align="left" valign="bottom">Category ↔Hidden</td><td align="char" char="." valign="bottom">0.2</td><td align="char" char="." valign="bottom">0.3</td><td align="char" char="." valign="bottom">–0.1</td><td align="char" char="." valign="bottom">0.46</td><td align="char" char="." valign="bottom">0.06</td></tr><tr><td align="left" valign="bottom">Schlichting</td><td align="left" valign="bottom">Item ↔Hidden</td><td align="char" char="." valign="bottom">0.11</td><td align="char" char="." valign="bottom">0.23</td><td align="char" char="." valign="bottom">–1.5</td><td align="char" char="." valign="bottom">0.4</td><td align="char" char="." valign="bottom">1</td></tr></tbody></table></table-wrap><p>Evidence for the U-shaped plasticity function used here (where low activation leads to no change, moderate activation leads to weakening, and higher levels of activation lead to strengthening) was previously reviewed in <xref ref-type="bibr" rid="bib48">Ritvo et al., 2019</xref>. In brief, there are three lines of work that support the U shape: First, multiple neurophysiological studies have found that moderate postsynaptic depolarization leads to synaptic weakening and higher levels of depolarization lead to synaptic strengthening (e.g. <xref ref-type="bibr" rid="bib3">Artola et al., 1990</xref>; <xref ref-type="bibr" rid="bib22">Hansel, 1996</xref>). Second, human neuroscience studies have used pattern classifiers, applied to fMRI and EEG data, to measure memory activation, and have related this measure to subsequent memory accessibility; several studies using this approach have found that low levels of activation lead to no change in memory strength, moderate levels of activation lead to impaired subsequent memory, and higher levels of activation lead to increased subsequent memory (e.g. <xref ref-type="bibr" rid="bib38">Newman and Norman, 2010</xref>; <xref ref-type="bibr" rid="bib12">Detre et al., 2013</xref>; <xref ref-type="bibr" rid="bib26">Kim et al., 2014</xref>; for related findings, see <xref ref-type="bibr" rid="bib29">Lewis-Peacock and Norman, 2014</xref>; <xref ref-type="bibr" rid="bib60">Wang et al., 2019</xref>). Third, a recent human fMRI study by <xref ref-type="bibr" rid="bib59">Wammes et al., 2022</xref> manipulated memory activation by varying the visual similarity of pairmates and observed a U-shaped function relating visual similarity to representational change in the hippocampus, whereby low levels of pairmate similarity were associated with no change, moderate levels of similarity were associated with differentiation, and the differentiation effect went away at higher levels of similarity.</p></sec><sec id="s4-4"><title>Stimulus presentation</title><p>Each model run included only two stimuli — pairmates A and B. This modeling choice reflects our assumption that the competitive dynamics of interest occur between pairmates and not across pairs (given that pairs are typically constructed to be dissimilar to other pairs and thus are not confusable with them). The middle unit in the category layer was active for both pairmates (reflecting input features shared between them) and distinct units in the item layer were active for pairmates A and B. These external inputs were the same for all models. Every epoch consisted of a single presentation of A and B, in a random order, except in our model of <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref> where B was always shown first (and, in the blocked condition, no A trials followed).</p><p>We ran a test epoch before the first training epoch to attain a ‘baseline’ measure of the representations of A and B, and we ran another test epoch after each subsequent training epoch. The only difference between test and training epochs was that (1) test epochs included no oscillations, so we could get a pure guess for the state of the representation, and (2) connection weights were not adjusted at the end of test epochs (i.e. learning was turned off). We ran the model for 20 train/test epochs, and the final pattern of unit activity for each test epoch was recorded and used for the analyses.</p></sec><sec id="s4-5"><title>Practical advice for getting the model to show differentiation</title><p>As discussed above, differentiation is highly sensitive to activity dynamics. To obtain differentiation, pairmate 2 (the competitor) must activate moderately on trial 1, and the following criteria must be met on trial 2:</p><list list-type="order"><list-item><p>On trial 2 (when pairmate 2 is presented), hidden-layer units that were initially shared between the pairmates cannot be reactivated.</p></list-item><list-item><p>On trial 2, the unique hidden-layer units associated with pairmate 2 must be reactivated.</p></list-item></list><p>This seems straightforward, but meeting these conditions can be difficult. Sometimes the parameter adjustments needed to satisfy #1 make #2 harder to satisfy, and vice versa. Most of the failures to differentiate that we observed happened if these two conditions were not fully met.</p><sec id="s4-5-1"><title>On trial 2, pairmate 1 hidden units cannot be reactivated</title><p>Even if some weakening of competitor-shared connections has occurred on trial 1, it is possible for pairmate 1 units to activate on trial 2. If this happens, any initial differentiation effects are undone. This happens if the excitation for pairmate 1 units remains too high, and there are several potential reasons why this might occur.</p><p>We have discussed one potential cause already, when learning rate is low and the competitor-shared connections are only mildly weakened on trial 1. Additionally, if only some (but not all) competitor-shared connections weaken, the intact connections may reactivate pairmate 1 on trial 2, undoing any initial differentiation. For example, if variation in the random connection weights is too high, not all competitor units will pop up the same amount. This can lead to a situation where some of the competitor-competitor coactivity values are greater than some of the competitor-shared coactivity values, making it impossible to preserve within-competitor links while simultaneously severing links between competitor units and shared units (<xref ref-type="fig" rid="fig13">Figure 13</xref>).</p><fig id="fig13" position="float"><label>Figure 13.</label><caption><title>How subtle changes to activity can affect representational change: (<bold>A</bold>) Two sample activity patterns in the hidden layer during the first trial are shown.</title><p>Units are labelled as belonging to either the target, competitor, or both (shared), and vertical bars indicate activity level (along with activity values). A moderate amount of pop-up of the competitor occurs, which should lead to differentiation if the competitor-shared connections are appropriately weakened. Although the two patterns are very similar, the bottom pattern has slightly more variable activity, which could arise if the level of random noise in the strengths of the hidden-hidden connections is higher. (<bold>B</bold>) A U-shaped function for each activity pattern is shown, with the coactivity values for a subset of the hidden-unit pairings (those highlighted by the arcs in part A) plotted along the X axis. In the top example, all competitor-competitor coactivities are lower than all competitor-shared coactivities, which are in turn lower than all target-shared and target-target coactivities. This means that it is possible to preserve all of the competitor-competitor connections while severing all of the competitor-shared connections. However, in the bottom example, there is some interlacing of the competitor-competitor coactivities and competitor-shared coactivities; this scenario makes it impossible to fully preserve all competitor-competitor connections while severing all competitor-shared connections. With the U-shaped function shown here, the pattern of activity in the bottom example will result in sparing of some of the competitor-shared connections, making it less likely that differentiation will occur.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-fig13-v1.tif"/></fig><p>Another relevant parameter is the oscillation amplitude <italic>Osc</italic>, which can shift the placement of competitor-shared coactivity on the U-shaped function. If the oscillation is not set to the appropriate amplitude, the resulting level of competitor unit activity may not cause appropriate severing of competitor-shared connections. This can be seen in the results of our model of <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>: When the oscillation amount is adjusted, this can have strong effects on the representational changes that occur (<xref ref-type="fig" rid="fig10">Figure 10A and D</xref>).</p><p>Yet another factor to consider is how much excitation the hidden representation of pairmate 1 receives on trial 2. There are some projections that will always send excitation to pairmate 1 on trial 2, so some amount of excitation of the hidden pairmate 1 units is unavoidable. One projection for which this is true (for all models) is the category-to-hidden projection, since the category unit is part of both the A and B input patterns. Some of the models also have other units that maintain a connection to both A and B; for instance, in the shared-face condition of our model of <xref ref-type="bibr" rid="bib17">Favila et al., 2016</xref> and also our model of <xref ref-type="bibr" rid="bib54">Schlichting et al., 2015</xref>, the shared output unit is connected to both items’ hidden representations. In the model, lowering the strengths of these projections (i.e. category-to-hidden, output-to-hidden) by adjusting the corresponding <italic>Wt Scale</italic> parameters will reduce the amount of excitation received by pairmate 1. In an actual experiment, participants could accomplish this by attending less to shared features. As noted earlier, selective attention is not <italic>necessary</italic> for differentiation to occur in our model, but this account suggests that attention could modulate the strength of differentiation effects by modulating the relative influence of shared vs. unique features (for discussion of potential mechanisms of these effects, see <xref ref-type="bibr" rid="bib2">Amer and Davachi, 2023</xref>).</p><p>Learning that occurs in the category-hidden and output-hidden projections can also affect the relative amount of excitation received by the hidden representations of pairmate 1 and pairmate 2. On trial 1, if shared input/output features are strongly activated and unique hidden features of pairmate 2 are moderately activated, then NMPH learning can result in weakening of the connections between the shared input/output features and the unique hidden features of pairmate 2. If this occurs, then, on trial 2, shared input/output features will selectively send excitation to pairmate 1, but not pairmate 2, which further increases the odds that pairmate 1’s hidden representation will be activated (thwarting the differentiation effect). In our simulations, we were able to avoid this problem by using a small <italic>DRevMag</italic> value for projections from shared input/output features, which effectively reduces the amount of weakening that occurs for these projections.</p></sec><sec id="s4-5-2"><title>On trial 2, unique pairmate 2 hidden units must be reactivated</title><p>If connections within the pairmate 2 representation are weakened too much on trial 1 (when it pops up as a competitor), then, when pairmate 2 is presented as the target on trial 2, its hidden representation will not be accessible (i.e. the model will fail to reactivate the unique parts of this hidden representation). When this happens, the hidden representation of pairmate 1 typically ends up being activated instead. This leads to the asymmetric form of integration, where the input units for pairmate 2 end up being linked to the hidden representation of pairmate 1.</p><p>Parameter adjustments that lower the amount of pop-up are helpful in addressing this issue; lowering pop-up shifts the competitor-competitor coactivities to the left on the U-shaped function, making it less likely that these connections will be weakened. For instance, decreasing the oscillation amount may be needed to make sure competitor-competitor connections are spared in trial 1. However, if the oscillation amount is decreased too much, it may also cause competitor-shared connections to be spared, as discussed in point #1 above. Successful differentiation requires ‘threading the needle’ such that competitor-competitor connections are (relatively) spared but connections between competitor and shared units are severed.</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Supervision, Funding acquisition, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Supervision, Funding acquisition, Methodology, Writing – original draft, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-88608-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The current manuscript is a computational study, so no data have been generated for this manuscript. Simulation code can be downloaded from <ext-link ext-link-type="uri" xlink:href="https://github.com/PrincetonCompMemLab/neurodiff_simulations">https://github.com/PrincetonCompMemLab/neurodiff_simulations</ext-link> (copy archived at <xref ref-type="bibr" rid="bib39">Nguyen, 2024</xref>).</p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported by NIH R01 MH069456 awarded to KAN and NBT-B.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aisa</surname><given-names>B</given-names></name><name><surname>Mingus</surname><given-names>B</given-names></name><name><surname>O’Reilly</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The emergent neural modeling system</article-title><source>Neural Networks</source><volume>21</volume><fpage>1146</fpage><lpage>1152</lpage><pub-id pub-id-type="doi">10.1016/j.neunet.2008.06.016</pub-id><pub-id pub-id-type="pmid">18684591</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amer</surname><given-names>T</given-names></name><name><surname>Davachi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Extra-hippocampal contributions to pattern separation</article-title><source>eLife</source><volume>12</volume><elocation-id>82250</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.82250</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Artola</surname><given-names>A</given-names></name><name><surname>Bröcher</surname><given-names>S</given-names></name><name><surname>Singer</surname><given-names>W</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Different voltage-dependent thresholds for inducing long-term depression and long-term potentiation in slices of rat visual cortex</article-title><source>Nature</source><volume>347</volume><fpage>69</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1038/347069a0</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barnes</surname><given-names>CA</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Mizumori</surname><given-names>SJ</given-names></name><name><surname>Leonard</surname><given-names>BW</given-names></name><name><surname>Lin</surname><given-names>LH</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Comparison of spatial and temporal characteristics of neuronal activity in sequential stages of hippocampal processing</article-title><source>Progress in Brain Research</source><volume>83</volume><fpage>287</fpage><lpage>300</lpage><pub-id pub-id-type="doi">10.1016/s0079-6123(08)61257-1</pub-id><pub-id pub-id-type="pmid">2392566</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bear</surname><given-names>MF</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Bidirectional synaptic plasticity: from theory to reality</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>358</volume><fpage>649</fpage><lpage>655</lpage><pub-id pub-id-type="doi">10.1098/rstb.2002.1255</pub-id><pub-id pub-id-type="pmid">12740110</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bienenstock</surname><given-names>EL</given-names></name><name><surname>Cooper</surname><given-names>LN</given-names></name><name><surname>Munro</surname><given-names>PW</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Theory for the development of neuron selectivity: orientation specificity and binocular interaction in visual cortex</article-title><source>The Journal of Neuroscience</source><volume>2</volume><fpage>32</fpage><lpage>48</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.02-01-00032.1982</pub-id><pub-id pub-id-type="pmid">7054394</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunec</surname><given-names>IK</given-names></name><name><surname>Robin</surname><given-names>J</given-names></name><name><surname>Olsen</surname><given-names>RK</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name><name><surname>Barense</surname><given-names>MD</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Integration and differentiation of hippocampal memory traces</article-title><source>Neuroscience &amp; Biobehavioral Reviews</source><volume>118</volume><fpage>196</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1016/j.neubiorev.2020.07.024</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chanales</surname><given-names>AJH</given-names></name><name><surname>Oza</surname><given-names>A</given-names></name><name><surname>Favila</surname><given-names>SE</given-names></name><name><surname>Kuhl</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Overlap among spatial memories triggers repulsion of hippocampal representations</article-title><source>Current Biology</source><volume>27</volume><fpage>2307</fpage><lpage>2317</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.06.057</pub-id><pub-id pub-id-type="pmid">28736170</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chanales</surname><given-names>AJH</given-names></name><name><surname>Tremblay-McGaw</surname><given-names>AG</given-names></name><name><surname>Drascher</surname><given-names>ML</given-names></name><name><surname>Kuhl</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Adaptive repulsion of long-term memory representations is triggered by event similarity</article-title><source>Psychological Science</source><volume>32</volume><fpage>705</fpage><lpage>720</lpage><pub-id pub-id-type="doi">10.1177/0956797620972490</pub-id><pub-id pub-id-type="pmid">33882251</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cooper</surname><given-names>LN</given-names></name></person-group><year iso-8601-date="2004">2004</year><source>Theory of cortical plasticity</source><publisher-name>World Scientific</publisher-name></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Araujo Sanchez</surname><given-names>MA</given-names></name><name><surname>Zeithamova</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Generalization and false memory in acquired equivalence</article-title><source>Cognition</source><volume>234</volume><elocation-id>105385</elocation-id><pub-id pub-id-type="doi">10.1016/j.cognition.2023.105385</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Detre</surname><given-names>GJ</given-names></name><name><surname>Natarajan</surname><given-names>A</given-names></name><name><surname>Gershman</surname><given-names>SJ</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Moderate levels of activation lead to forgetting in the think/no-think paradigm</article-title><source>Neuropsychologia</source><volume>51</volume><fpage>2371</fpage><lpage>2388</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2013.02.017</pub-id><pub-id pub-id-type="pmid">23499722</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Diederich</surname><given-names>S</given-names></name><name><surname>Opper</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Learning of correlated patterns in spin-glass networks by local learning rules</article-title><source>Physical Review Letters</source><volume>58</volume><fpage>949</fpage><lpage>952</lpage><pub-id pub-id-type="doi">10.1103/PhysRevLett.58.949</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dimsdale-Zucker</surname><given-names>HR</given-names></name><name><surname>Ritchey</surname><given-names>M</given-names></name><name><surname>Ekstrom</surname><given-names>AD</given-names></name><name><surname>Yonelinas</surname><given-names>AP</given-names></name><name><surname>Ranganath</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>CA1 and CA3 differentially support spontaneous retrieval of episodic contexts within human hippocampal subfields</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>294</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-017-02752-1</pub-id><pub-id pub-id-type="pmid">29348512</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drascher</surname><given-names>ML</given-names></name><name><surname>Kuhl</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Long-term memory interference is resolved via repulsion and precision along diagnostic memory dimensions</article-title><source>Psychonomic Bulletin &amp; Review</source><volume>29</volume><fpage>1898</fpage><lpage>1912</lpage><pub-id pub-id-type="doi">10.3758/s13423-022-02082-4</pub-id><pub-id pub-id-type="pmid">35380409</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duncan</surname><given-names>KD</given-names></name><name><surname>Schlichting</surname><given-names>ML</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Hippocampal representations as a function of time, subregion, and brain state</article-title><source>Neurobiology of Learning and Memory</source><volume>153</volume><fpage>40</fpage><lpage>56</lpage><pub-id pub-id-type="doi">10.1016/j.nlm.2018.03.006</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Favila</surname><given-names>SE</given-names></name><name><surname>Chanales</surname><given-names>AJH</given-names></name><name><surname>Kuhl</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Experience-dependent hippocampal pattern differentiation prevents interference during subsequent learning</article-title><source>Nature Communications</source><volume>7</volume><elocation-id>11066</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms11066</pub-id><pub-id pub-id-type="pmid">27925613</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fernandez</surname><given-names>C</given-names></name><name><surname>Jiang</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>S-F</given-names></name><name><surname>Choi</surname><given-names>HL</given-names></name><name><surname>Wagner</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Representational integration and differentiation in the human hippocampus following goal-directed navigation</article-title><source>eLife</source><volume>12</volume><elocation-id>e80281</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.80281</pub-id><pub-id pub-id-type="pmid">36786678</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gluck</surname><given-names>MA</given-names></name><name><surname>Myers</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Hippocampal mediation of stimulus representation: a computational theory</article-title><source>Hippocampus</source><volume>3</volume><fpage>491</fpage><lpage>516</lpage><pub-id pub-id-type="doi">10.1002/hipo.450030410</pub-id><pub-id pub-id-type="pmid">8269040</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>GoodSmith</surname><given-names>D</given-names></name><name><surname>Chen</surname><given-names>X</given-names></name><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Kim</surname><given-names>SH</given-names></name><name><surname>Song</surname><given-names>H</given-names></name><name><surname>Burgalossi</surname><given-names>A</given-names></name><name><surname>Christian</surname><given-names>KM</given-names></name><name><surname>Knierim</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Spatial representations of granule cells and mossy cells of the dentate gyrus</article-title><source>Neuron</source><volume>93</volume><fpage>677</fpage><lpage>690</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.12.026</pub-id><pub-id pub-id-type="pmid">28132828</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanazawa</surname><given-names>A</given-names></name><name><surname>Komatsu</surname><given-names>H</given-names></name><name><surname>Murakami</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Neural selectivity for hue and saturation of colour in the primary visual cortex of the monkey</article-title><source>European Journal of Neuroscience</source><volume>12</volume><fpage>1753</fpage><lpage>1763</lpage><pub-id pub-id-type="doi">10.1046/j.1460-9568.2000.00041.x</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hansel</surname><given-names>C</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Different threshold levels of postsynaptic [Ca2+]i have to be reached to induce LTP and LTD in neocortical pyramidal cells</article-title><source>Journal of Physiology, Paris</source><volume>90</volume><fpage>317</fpage><lpage>319</lpage><pub-id pub-id-type="doi">10.1016/s0928-4257(97)87906-5</pub-id><pub-id pub-id-type="pmid">9089500</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Honey</surname><given-names>RC</given-names></name><name><surname>Hall</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Acquired equivalence and distinctiveness of cues</article-title><source>Journal of Experimental Psychology. Animal Behavior Processes</source><volume>15</volume><fpage>338</fpage><lpage>346</lpage><pub-id pub-id-type="pmid">2794870</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hulbert</surname><given-names>JC</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Neural differentiation tracks improved recall of competing memories following interleaved study and retrieval practice</article-title><source>Cerebral Cortex</source><volume>25</volume><fpage>3994</fpage><lpage>4008</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhu284</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>J</given-names></name><name><surname>Wang</surname><given-names>S-F</given-names></name><name><surname>Guo</surname><given-names>W</given-names></name><name><surname>Fernandez</surname><given-names>C</given-names></name><name><surname>Wagner</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Prefrontal reinstatement of contextual task demand is predicted by separable hippocampal patterns</article-title><source>Nature Communications</source><volume>11</volume><fpage>1</fpage><lpage>12</lpage><pub-id pub-id-type="doi">10.1038/s41467-020-15928-z</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>G</given-names></name><name><surname>Lewis-Peacock</surname><given-names>JA</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Pruning of memories by context-based prediction error</article-title><source>PNAS</source><volume>111</volume><fpage>8997</fpage><lpage>9002</lpage><pub-id pub-id-type="doi">10.1073/pnas.1319438111</pub-id><pub-id pub-id-type="pmid">24889631</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>G</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neural differentiation of incorrectly predicted memories</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>2022</fpage><lpage>2031</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3272-16.2017</pub-id><pub-id pub-id-type="pmid">28115478</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Komatsu</surname><given-names>H</given-names></name><name><surname>Ideura</surname><given-names>Y</given-names></name><name><surname>Kaji</surname><given-names>S</given-names></name><name><surname>Yamane</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Color selectivity of neurons in the inferior temporal cortex of the awake macaque monkey</article-title><source>The Journal of Neuroscience</source><volume>12</volume><fpage>408</fpage><lpage>424</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.12-02-00408.1992</pub-id><pub-id pub-id-type="pmid">1740688</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis-Peacock</surname><given-names>JA</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Competition between items in working memory leads to forgetting</article-title><source>Nature Communications</source><volume>5</volume><elocation-id>5768</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms6768</pub-id><pub-id pub-id-type="pmid">25519874</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lillicrap</surname><given-names>TP</given-names></name><name><surname>Santoro</surname><given-names>A</given-names></name><name><surname>Marris</surname><given-names>L</given-names></name><name><surname>Akerman</surname><given-names>CJ</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Backpropagation and the brain</article-title><source>Nature Reviews Neuroscience</source><volume>21</volume><fpage>335</fpage><lpage>346</lpage><pub-id pub-id-type="doi">10.1038/s41583-020-0277-3</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mccandliss</surname><given-names>BD</given-names></name><name><surname>Fiez</surname><given-names>JA</given-names></name><name><surname>Protopapas</surname><given-names>A</given-names></name><name><surname>Conway</surname><given-names>M</given-names></name><name><surname>Mcclelland</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Success and failure in teaching the [r]-[l] contrast to Japanese adults: Tests of a Hebbian model of plasticity and stabilization in spoken language perception</article-title><source>Cognitive, Affective, &amp; Behavioral Neuroscience</source><volume>2</volume><fpage>89</fpage><lpage>108</lpage><pub-id pub-id-type="doi">10.3758/CABN.2.2.89</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClelland</surname><given-names>JL</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>O’Reilly</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory</article-title><source>Psychological Review</source><volume>102</volume><fpage>419</fpage><lpage>457</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.102.3.419</pub-id><pub-id pub-id-type="pmid">7624455</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McClelland</surname><given-names>JL</given-names></name><name><surname>Thomas</surname><given-names>AG</given-names></name><name><surname>McCandliss</surname><given-names>BD</given-names></name><name><surname>Fiez</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Understanding failures of learning: Hebbian learning, competition for representational space, and some preliminary experimental data</article-title><source>Progress in Brain Research</source><volume>121</volume><fpage>75</fpage><lpage>80</lpage><pub-id pub-id-type="doi">10.1016/s0079-6123(08)63068-x</pub-id><pub-id pub-id-type="pmid">10551021</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McNaughton</surname><given-names>BL</given-names></name><name><surname>Morris</surname><given-names>RGM</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Hippocampal synaptic enhancement and information storage within a distributed memory system</article-title><source>Trends in Neurosciences</source><volume>10</volume><fpage>408</fpage><lpage>415</lpage><pub-id pub-id-type="doi">10.1016/0166-2236(87)90011-7</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meeter</surname><given-names>M</given-names></name><name><surname>Shohamy</surname><given-names>D</given-names></name><name><surname>Myers</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Acquired equivalence changes stimulus representations</article-title><source>Journal of the Experimental Analysis of Behavior</source><volume>91</volume><fpage>127</fpage><lpage>141</lpage><pub-id pub-id-type="doi">10.1901/jeab.2009.91-127</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Molitor</surname><given-names>RJ</given-names></name><name><surname>Sherrill</surname><given-names>KR</given-names></name><name><surname>Morton</surname><given-names>NW</given-names></name><name><surname>Miller</surname><given-names>AA</given-names></name><name><surname>Preston</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Memory reactivation during learning simultaneously promotes dentate Gyrus/CA<sub>2,3</sub> pattern differentiation and CA<sub>1</sub> memory integration</article-title><source>The Journal of Neuroscience</source><volume>41</volume><fpage>726</fpage><lpage>738</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0394-20.2020</pub-id><pub-id pub-id-type="pmid">33239402</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Myers</surname><given-names>CE</given-names></name><name><surname>Shohamy</surname><given-names>D</given-names></name><name><surname>Gluck</surname><given-names>MA</given-names></name><name><surname>Grossman</surname><given-names>S</given-names></name><name><surname>Kluger</surname><given-names>A</given-names></name><name><surname>Ferris</surname><given-names>S</given-names></name><name><surname>Golomb</surname><given-names>J</given-names></name><name><surname>Schnirman</surname><given-names>G</given-names></name><name><surname>Schwartz</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Dissociating hippocampal versus basal ganglia contributions to learning and transfer</article-title><source>Journal of Cognitive Neuroscience</source><volume>15</volume><fpage>185</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1162/089892903321208123</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Newman</surname><given-names>EL</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Moderate excitation leads to weakening of perceptual representations</article-title><source>Cerebral Cortex</source><volume>20</volume><fpage>2760</fpage><lpage>2770</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhq021</pub-id><pub-id pub-id-type="pmid">20181622</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Nguyen</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>neurodiff_simulations</data-title><version designator="swh:1:rev:b71ce7ceff56a69139dc82ae1e6a90a64978fa80">swh:1:rev:b71ce7ceff56a69139dc82ae1e6a90a64978fa80</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:f0889b1d742b96d942759b73c1fd091ce6f0a05c;origin=https://github.com/PrincetonCompMemLab/neurodiff_simulations;visit=swh:1:snp:4eeb03d357c12e7c6cc8b1f29ceb74431b59ae74;anchor=swh:1:rev:b71ce7ceff56a69139dc82ae1e6a90a64978fa80">https://archive.softwareheritage.org/swh:1:dir:f0889b1d742b96d942759b73c1fd091ce6f0a05c;origin=https://github.com/PrincetonCompMemLab/neurodiff_simulations;visit=swh:1:snp:4eeb03d357c12e7c6cc8b1f29ceb74431b59ae74;anchor=swh:1:rev:b71ce7ceff56a69139dc82ae1e6a90a64978fa80</ext-link></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>O’Reilly</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Modeling hippocampal and neocortical contributions to recognition memory: A complementary-learning-systems approach</article-title><source>Psychological Review</source><volume>110</volume><fpage>611</fpage><lpage>646</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.110.4.611</pub-id><pub-id pub-id-type="pmid">14599236</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Newman</surname><given-names>E</given-names></name><name><surname>Detre</surname><given-names>G</given-names></name><name><surname>Polyn</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>How inhibitory oscillations can train neural networks and punish competitors</article-title><source>Neural Computation</source><volume>18</volume><fpage>1577</fpage><lpage>1610</lpage><pub-id pub-id-type="doi">10.1162/neco.2006.18.7.1577</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Newman</surname><given-names>EL</given-names></name><name><surname>Detre</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A neural network model of retrieval-induced forgetting</article-title><source>Psychological Review</source><volume>114</volume><fpage>887</fpage><lpage>953</lpage><pub-id pub-id-type="doi">10.1037/0033-295X.114.4.887</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>O’Reilly</surname><given-names>RC</given-names></name><name><surname>Munakata</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2000">2000</year><source>Computational Explorations in Cognitive Neuroscience</source><publisher-name>MIT Press</publisher-name><pub-id pub-id-type="doi">10.7551/mitpress/2014.001.0001</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>O’Reilly</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2012">2012</year><data-title>Computational cognitive neuroscience</data-title><version designator="36555c2">36555c2</version><source>Github</source><ext-link ext-link-type="uri" xlink:href="https://github.com/CompCogNeuro/ed4">https://github.com/CompCogNeuro/ed4</ext-link></element-citation></ref><ref id="bib45"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>O’Reilly</surname><given-names>RC</given-names></name></person-group><year iso-8601-date="2018">2018</year><data-title>Leabra</data-title><version designator="c82bc99">c82bc99</version><source>Github</source><ext-link ext-link-type="uri" xlink:href="https://github.com/emer/leabra">https://github.com/emer/leabra</ext-link></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Payeur</surname><given-names>A</given-names></name><name><surname>Guerguiev</surname><given-names>J</given-names></name><name><surname>Zenke</surname><given-names>F</given-names></name><name><surname>Richards</surname><given-names>BA</given-names></name><name><surname>Naud</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Burst-dependent synaptic plasticity can coordinate learning in hierarchical circuits</article-title><source>Nature Neuroscience</source><volume>24</volume><fpage>1010</fpage><lpage>1019</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00857-x</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Richards</surname><given-names>BA</given-names></name><name><surname>Lillicrap</surname><given-names>TP</given-names></name><name><surname>Beaudoin</surname><given-names>P</given-names></name><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name><name><surname>Christensen</surname><given-names>A</given-names></name><name><surname>Clopath</surname><given-names>C</given-names></name><name><surname>Costa</surname><given-names>RP</given-names></name><name><surname>de Berker</surname><given-names>A</given-names></name><name><surname>Ganguli</surname><given-names>S</given-names></name><name><surname>Gillon</surname><given-names>CJ</given-names></name><name><surname>Hafner</surname><given-names>D</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name><name><surname>Kriegeskorte</surname><given-names>N</given-names></name><name><surname>Latham</surname><given-names>P</given-names></name><name><surname>Lindsay</surname><given-names>GW</given-names></name><name><surname>Miller</surname><given-names>KD</given-names></name><name><surname>Naud</surname><given-names>R</given-names></name><name><surname>Pack</surname><given-names>CC</given-names></name><name><surname>Poirazi</surname><given-names>P</given-names></name><name><surname>Roelfsema</surname><given-names>P</given-names></name><name><surname>Sacramento</surname><given-names>J</given-names></name><name><surname>Saxe</surname><given-names>A</given-names></name><name><surname>Scellier</surname><given-names>B</given-names></name><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Senn</surname><given-names>W</given-names></name><name><surname>Wayne</surname><given-names>G</given-names></name><name><surname>Yamins</surname><given-names>D</given-names></name><name><surname>Zenke</surname><given-names>F</given-names></name><name><surname>Zylberberg</surname><given-names>J</given-names></name><name><surname>Therien</surname><given-names>D</given-names></name><name><surname>Kording</surname><given-names>KP</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A deep learning framework for neuroscience</article-title><source>Nature Neuroscience</source><volume>22</volume><fpage>1761</fpage><lpage>1770</lpage><pub-id pub-id-type="doi">10.1038/s41593-019-0520-2</pub-id><pub-id pub-id-type="pmid">31659335</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritvo</surname><given-names>VJH</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Nonmonotonic plasticity: how memory retrieval drives learning</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>726</fpage><lpage>742</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.06.007</pub-id><pub-id pub-id-type="pmid">31358438</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rumelhart</surname><given-names>DE</given-names></name><name><surname>Hinton</surname><given-names>GE</given-names></name><name><surname>Williams</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="1986">1986</year><article-title>Learning representations by back-propagating errors</article-title><source>Nature</source><volume>323</volume><fpage>533</fpage><lpage>536</lpage><pub-id pub-id-type="doi">10.1038/323533a0</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Kustner</surname><given-names>LV</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Shaping of object representations in the human medial temporal lobe based on temporal regularities</article-title><source>Current Biology</source><volume>22</volume><fpage>1622</fpage><lpage>1627</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.06.056</pub-id><pub-id pub-id-type="pmid">22885059</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name><name><surname>Cordova</surname><given-names>NI</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neural representations of events arise from temporal community structure</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>486</fpage><lpage>492</lpage><pub-id pub-id-type="doi">10.1038/nn.3331</pub-id><pub-id pub-id-type="pmid">23416451</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Statistical learning of temporal community structure in the hippocampus</article-title><source>Hippocampus</source><volume>26</volume><fpage>3</fpage><lpage>8</lpage><pub-id pub-id-type="doi">10.1002/hipo.22523</pub-id><pub-id pub-id-type="pmid">26332666</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Complementary learning systems within the hippocampus: a neural network modelling approach to reconciling episodic memory with statistical learning</article-title><source>Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences</source><volume>372</volume><elocation-id>20160049</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2016.0049</pub-id><pub-id pub-id-type="pmid">27872368</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schlichting</surname><given-names>ML</given-names></name><name><surname>Mumford</surname><given-names>JA</given-names></name><name><surname>Preston</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Learning-related representational changes reveal dissociable integration and separation signatures in the hippocampus and prefrontal cortex</article-title><source>Nature Communications</source><volume>6</volume><elocation-id>8151</elocation-id><pub-id pub-id-type="doi">10.1038/ncomms9151</pub-id><pub-id pub-id-type="pmid">26303198</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shohamy</surname><given-names>D</given-names></name><name><surname>Wagner</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Integrating memories in the human brain: hippocampal-midbrain encoding of overlapping events</article-title><source>Neuron</source><volume>60</volume><fpage>378</fpage><lpage>389</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.09.023</pub-id><pub-id pub-id-type="pmid">18957228</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Singh</surname><given-names>D</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Schapiro</surname><given-names>AC</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A model of autonomous interactions between hippocampus and neocortex driving sleep-dependent memory consolidation</article-title><source>PNAS</source><volume>119</volume><elocation-id>e2123432119</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2123432119</pub-id><pub-id pub-id-type="pmid">36279437</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tarder-Stoll</surname><given-names>H</given-names></name><name><surname>Gasser</surname><given-names>C</given-names></name><name><surname>Yu</surname><given-names>W</given-names></name><name><surname>Dimsdale-Zucker</surname><given-names>HR</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Challenges in understanding the role of reactivation in modifying hippocampal representations</article-title><source>The Journal of Neuroscience</source><volume>41</volume><fpage>4750</fpage><lpage>4753</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0334-21.2021</pub-id><pub-id pub-id-type="pmid">34078645</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tompary</surname><given-names>A</given-names></name><name><surname>Davachi</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Consolidation promotes the emergence of representational overlap in the hippocampus and medial prefrontal cortex</article-title><source>Neuron</source><volume>96</volume><fpage>228</fpage><lpage>241</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.09.005</pub-id><pub-id pub-id-type="pmid">28957671</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wammes</surname><given-names>J</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name><name><surname>Turk-Browne</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Increasing stimulus similarity drives nonmonotonic representational change in hippocampus</article-title><source>eLife</source><volume>11</volume><elocation-id>e68344</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.68344</pub-id><pub-id pub-id-type="pmid">34989336</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>TH</given-names></name><name><surname>Placek</surname><given-names>K</given-names></name><name><surname>Lewis-Peacock</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>More is less: increased processing of unwanted memories facilitates forgetting</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>3551</fpage><lpage>3560</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2033-18.2019</pub-id><pub-id pub-id-type="pmid">30858162</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wanjia</surname><given-names>G</given-names></name><name><surname>Favila</surname><given-names>SE</given-names></name><name><surname>Kim</surname><given-names>G</given-names></name><name><surname>Molitor</surname><given-names>RJ</given-names></name><name><surname>Kuhl</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Abrupt hippocampal remapping signals resolution of memory interference</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>4816</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-25126-0</pub-id><pub-id pub-id-type="pmid">34376652</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>West</surname><given-names>MJ</given-names></name><name><surname>Slomianka</surname><given-names>L</given-names></name><name><surname>Gundersen</surname><given-names>HJG</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Unbiased stereological estimation of the total number of neurons in thesubdivisions of the rat hippocampus using the optical fractionator</article-title><source>The Anatomical Record</source><volume>231</volume><fpage>482</fpage><lpage>497</lpage><pub-id pub-id-type="doi">10.1002/ar.1092310411</pub-id><pub-id pub-id-type="pmid">1793176</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JCR</given-names></name><name><surname>Bogacz</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Theories of error back-propagation in the brain</article-title><source>Trends in Cognitive Sciences</source><volume>23</volume><fpage>235</fpage><lpage>250</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2018.12.005</pub-id><pub-id pub-id-type="pmid">30704969</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeithamova</surname><given-names>D</given-names></name><name><surname>Gelman</surname><given-names>BD</given-names></name><name><surname>Frank</surname><given-names>L</given-names></name><name><surname>Preston</surname><given-names>AR</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Abstract representation of prospective reward in the hippocampus</article-title><source>The Journal of Neuroscience</source><volume>38</volume><fpage>10093</fpage><lpage>10101</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0719-18.2018</pub-id><pub-id pub-id-type="pmid">30282732</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>Y</given-names></name><name><surname>Chanales</surname><given-names>AJH</given-names></name><name><surname>Kuhl</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Adaptive memory distortions are predicted by feature representations in parietal cortex</article-title><source>The Journal of Neuroscience</source><volume>41</volume><fpage>3014</fpage><lpage>3024</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2875-20.2021</pub-id><pub-id pub-id-type="pmid">33619210</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>L</given-names></name><name><surname>Gao</surname><given-names>Z</given-names></name><name><surname>McAvan</surname><given-names>AS</given-names></name><name><surname>Isham</surname><given-names>EA</given-names></name><name><surname>Ekstrom</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Partially overlapping spatial environments trigger reinstatement in hippocampus and schema representations in prefrontal cortex</article-title><source>Nature Communications</source><volume>12</volume><elocation-id>6231</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-021-26560-w</pub-id><pub-id pub-id-type="pmid">34711830</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Zhuang</surname><given-names>C</given-names></name><name><surname>Zhai</surname><given-names>A</given-names></name><name><surname>Yamins</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Local aggregation for unsupervised learning of visual embeddings</article-title><conf-name>IEEE/CVF International Conference on Computer Vision (ICCV)</conf-name><conf-loc>Seoul, Korea (South)</conf-loc><fpage>6002</fpage><lpage>6012</lpage><pub-id pub-id-type="doi">10.1109/ICCV.2019.00610</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhuang</surname><given-names>C</given-names></name><name><surname>Yan</surname><given-names>S</given-names></name><name><surname>Nayebi</surname><given-names>A</given-names></name><name><surname>Schrimpf</surname><given-names>M</given-names></name><name><surname>Frank</surname><given-names>MC</given-names></name><name><surname>DiCarlo</surname><given-names>JJ</given-names></name><name><surname>Yamins</surname><given-names>DLK</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Unsupervised neural network models of the ventral visual stream</article-title><source>PNAS</source><volume>118</volume><elocation-id>e2014196118</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2014196118</pub-id><pub-id pub-id-type="pmid">33431673</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.88608.3.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Schlichting</surname><given-names>Margaret L</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>University of Toronto</institution><country>Canada</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Convincing</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group></front-stub><body><p>This paper presents <bold>important</bold> computational modeling work that provides a mechanistic account for how memory representations become integrated or differentiated (i.e., having distinct neural representations despite being similar in content). The authors provide <bold>convincing</bold> evidence that simple unsupervised learning in a neural network model, which critically weakens connections of units that are moderately activated by multiple memories, can account for three empirical findings of differentiation in the literature. The paper also provides insightful discussion on the factors contributing to differentiation as opposed to integration, and makes new predictions for future empirical work.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.88608.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Ritvo and colleagues present an impressive suite of simulations that can account for three findings of differentiation in the literature. This is important because differentiation-in which items that have some features in common, or share a common associate are less similar to one another than are unrelated items-is difficult to explain with classic supervised learning models, as these predict the opposite (i.e., an increase in similarity). A few of their key findings are that differentiation requires a high learning rate and low inhibitory oscillations, and is virtually always asymmetric in nature.</p><p>This paper was very clear and thoughtful-an absolute joy to read. The model is simple and elegant, and powerful enough to re-create many aspects of existing differentiation findings. The interrogation of the model and presentation of the findings were both extremely thorough. The potential for this model to be used to drive future work is huge.</p><p>The authors have been very responsive to my previous reviews and I have no further concerns and identify no major weaknesses.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.88608.3.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>This paper addresses an important computational problem in learning and memory. Why do related memory representations sometimes become more similar to each other (integration) and sometimes more distinct (differentiation)? Classic supervised learning models predict that shared associations should cause memories to integrate, but these models have recently been challenged by empirical data showing that shared associations can sometimes cause differentiation. The authors have previously proposed that unsupervised learning may account for these unintuitive data. Here, they follow up on this idea by actually implementing an unsupervised neural network model that updates the connections between memories based on the amount of coactivity between them. The authors use their modeling framework to simulate three recent empirical studies, showing that their model captures aspects of these findings that are hard to account for with supervised learning.</p><p>Overall, this is a strong and clearly described work that is likely to have a positive impact on computational and empirical work in learning and memory. While the authors have written about some of the ideas discussed in this paper previously, a fully implemented and openly available model is a clear advance that will benefit the field. It is not easy to translate a high-level description of a learning rule into a model that actually runs and behaves as expected. The fact that the authors have made all their code available makes it likely that other researchers will extend the model in numerous interesting ways, many of which the authors have discussed and highlighted in their paper.</p><p>Strengths:</p><p>The authors succeed in demonstrating that unsupervised learning with a simple u-shaped rule can produce results that are qualitatively in line with the empirical reports. In each of the three models, the authors manipulate stimulus similarity (following Chanales et al.), shared vs distinct associations (following Favila et al.), or learning strength (a stand-in for blocked versus interleaved learning schedule; following Schlichting et al.). In all cases, with hand-tuning of additional parameters, the authors are able to produce model representations that fit the empirical results, but that can't easily be accounted for by supervised learning. Demonstrating these effects isn't trivial and a formal modeling framework for doing so is a valuable contribution. Overall, the work is very thorough. The authors investigate many different aspects of the learning dynamics (learning rate, oscillation strength, hidden layer overlap etc) in these models and produce several key insights. Of particular value are their demonstrations that when differentiation occurs, it occurs very quickly and asymmetrically and results in anti-correlated representations, as well as the distinction between symmetric and asymmetric integration in their model. The authors thoroughly acknowledge the relative difficulty of producing differentiation in their models relative to integration, and are now more clear about why they don't necessarily view this as mismatch with the empirical data. The authors are also more clear about the complicated activation dynamics in their model and why critical ranges for some parameters can't be given -- the number of interacting parameters mean that there are many combinations that could produce the critical activation dynamics and thus the same result. Despite this complexity, the paper is very clearly written; the authors do a good job of both formally describing their model as well as giving readers a high level sense of how many of their critical model components work.</p><p>Weaknesses:</p><p>Though the u-shaped learning rule is essential to this framework, the paper doesn't do any formal investigation of this learning rule or comparison with other learning rules. The authors do have a strong theoretical interest in this rule as well as experimental precedent for testing this rule, which they now thoroughly discuss in the paper. Still, a stronger argument in support of the non monotonic plasticity hypothesis could have been made by comparing this learning rule to alternatives. Additionally, the authors' choice of strongly prewiring associations makes it difficult to think about how their model maps onto experimental contexts where associations are only weakly learned. However, the authors thoroughly acknowledge why this was necessary and discuss this limitation in the paper.</p></body></sub-article><sub-article article-type="referee-report" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.88608.3.sa3</article-id><title-group><article-title>Reviewer #3 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>This paper proposes a computational account for the phenomenon of pattern differentiation (i.e., items having distinct neural representations when they are similar). The computational model relies on a learning mechanism of the nonmonotonic plasticity hypothesis, fast learning rate and inhibitory oscillations. In the revised paper, the authors justified the initialization of the model, added empirical evidence supporting the use of two turning points in the NMPH function and provided details of the learning mechanisms of the model. The relatively simple architecture of the model makes its dynamics accessible to the human mind. Furthermore, using similar model parameters, this model produces simulated data consistent with empirical data of pattern differentiation. The authors also provide insightful discussion on the factors contributing to differentiation as opposed to integration.</p></body></sub-article><sub-article article-type="author-comment" id="sa4"><front-stub><article-id pub-id-type="doi">10.7554/eLife.88608.3.sa4</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Ritvo</surname><given-names>Victoria JH</given-names></name><role specific-use="author">Author</role><aff><institution>Princeton University</institution><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Nguyen</surname><given-names>Alex</given-names></name><role specific-use="author">Author</role><aff><institution>Princeton University</institution><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Turk-Browne</surname><given-names>Nicholas</given-names></name><role specific-use="author">Author</role><aff><institution>Yale University</institution><addr-line><named-content content-type="city">New Haven</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Norman</surname><given-names>Kenneth A</given-names></name><role specific-use="author">Author</role><aff><institution>Princeton University</institution><addr-line><named-content content-type="city">Princeton</named-content></addr-line><country>United States</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public Review):</bold></p><p>Ritvo and colleagues present an impressive suite of simulations that can account for three findings of differentiation in the literature. This is important because differentiation-in which items that have some features in common, or share a common associate are less similar to one another than are unrelated items-is difficult to explain with classic supervised learning models, as these predict the opposite (i.e., an increase in similarity). A few of their key findings are that differentiation requires a high learning rate and low inhibitory oscillations, and is virtually always asymmetric in nature.</p><p>This paper was very clear and thoughtful-an absolute joy to read. The model is simple and elegant, and powerful enough to re-create many aspects of existing differentiation findings. The interrogation of the model and presentation of the findings were both extremely thorough. The potential for this model to be used to drive future work is huge. I have only a few comments for the authors, all of which are relatively minor.</p><p>(1) I was struck by the fact that the &quot;zone&quot; of repulsion is quite narrow, compared with the zone of attraction. This was most notable in the modeling of Chanales et al. (i.e., just one of the six similarity levels yielded differentiation). Do the authors think this is a generalizable property of the model or phenomenon, or something idiosyncratic to do with the current investigation? It seems curious that differentiation findings (e.g., in hippocampus) are so robustly observed in the literature despite the mechanism seemingly requiring a very particular set of circumstances. I wonder if the authors could speculate on this point a bit-for example, might the differentiation zone be wider when competitor &quot;pop up&quot; is low (i.e., low inhibitory oscillations), which could help explain why it's often observed in hippocampus? This seems related a bit to the question about what makes something &quot;moderately&quot; active, or how could one ensure &quot;moderate&quot; activation if they were, say, designing an experiment looking at differentiation.</p></disp-quote><p>We thank the reviewer for this comment. In the previous version of the manuscript, in the section entitled “Differentiation Requires a High Learning Rate and Is Sensitive to Activation Dynamics”, we discussed some reasons why differentiation may be more likely to be found in the hippocampus – namely, the high learning rate of the hippocampus and the sparsity of hippocampal activation patterns (pp. 27-28):</p><p>“These results have implications for where to look for differentiation in the brain. Our finding that differentiation requires a high learning rate suggests that differentiation will be more evident in the hippocampus than in neocortex, insofar as hippocampus is thought to have a higher learning rate than neocortex (McClelland et al., 1995). In keeping with this prediction, numerous studies have found differentiation effects in hippocampus but not in neocortical regions involved in sensory processing (e.g., Chanales et al., 2017; Favila et al., 2016; Zeithamova et al., 2018). At the same time, some studies have found differentiation effects in neocortex (e.g., Schlichting et al., 2015; Wammes et al., 2022). One possible explanation of these neocortical differentiation effects is that they are being ``propped up’’ by top-down feedback from differentiated representations in the hippocampus. This explanation implies that disruptions of hippocampal processing (e.g., lesions, stimulation) will eliminate these neocortical differentiation effects; we plan to test this prediction in future work.</p><p>Additionally, the simulations where we adjusted the oscillation amount (using our model of Schlichting et al., 2015) imply that differentiation will be most evident in brain regions where it is relatively hard to activate competitors. Given the U shape of the NMPH learning rule, limiting competitor activity makes it less likely that plasticity will ``cross over'' from weakening (and differentiation) to strengthening (and integration). Thus, within the hippocampus, subregions with sparser activity (e.g., dentate gyrus, and to a lesser extent, CA3; Barnes et al., 1990, GoodSmith et al., 2017; West et al., 1991) will be more prone to differentiation. There is strong empirical support for this prediction. For example, Wammes et al. (2022) manipulated the similarity of stimuli in a statistical learning experiment and found that moderate levels of visual similarity were associated with significant differentiation in the dentate gyrus but not other subregions. Also, numerous studies have found greater differentiation in dentate gyrus / CA3 than in CA1 (e.g., Dimsdale-Zucker et al., 2018; Wanjia et al., 2021; Molitor et al., 2021; Kim et al., 2017; but see Zheng et al., 2021).”</p><p>In the revised draft we have supplemented this discussion with a new section entitled “Reconciling the Prevalence of Differentiation in the Model and in the Data” (pp. 30-31):</p><p>“A key lesson from our model is that, from a computational perspective, it is challenging to obtain differentiation effects: The region of parameter space that gives rise to differentiation is much smaller than the one that gives rise to integration (for further discussion of this issue, see the section in Methods on Practical Advice for Getting the Model to Show Differentiation). However, the fact that integration is more prevalent in our simulations across parameter configurations does not mean that integration will be more prevalent than differentiation in real-life circumstances. What really matters in predicting the prevalence of differentiation in real life is how the parameters of the brain map on to parameters of the model: If the parameters of the brain align with regions of model parameter space that give rise to differentiation (even if these regions are small), this would explain why differentiation has been so robustly observed in extant studies. Indeed, this is exactly the case that we sought to make above about the hippocampus – i.e., that its use of especially sparse coding and a high learning rate will give rise to the kinds of neural dynamics that cause differentiation (as opposed to integration). As another example, while it is true that half of the overlap conditions in our simulation of Chanales et al. (2021) give rise to integration, this does not imply that integration will occur half of the time in the Chanales et al. (2021) study; it may be that the levels of overlap that are actually observed in the brain in Chanales et al. (2021) are more in line with the levels of overlap that give rise to differentiation in our model.”</p><disp-quote content-type="editor-comment"><p>(2) With real fMRI data we know that the actual correlation value doesn't matter all that much, and anti-correlations can be induced by things like preprocessing decisions. I am wondering if the important criterion in the model is that the correlations (e.g., as shown in Figure 6) go down from pre to post, versus that they are negative in sign during the post learning period. I would think that here, similar to in neural data, a decrease in correlation would be sufficient to conclude differentiation, but would love the authors' thoughts on that.</p></disp-quote><p>We thank the reviewer for bringing this up. In the paper, we define differentiation as the moving apart of representations – so we agree with the reviewer that it would be appropriate to conclude that differentiation is taking place when correlations go down from pre to post.</p><p>In addition to the definitional question (“what counts as differentiation”), one can also ask the <italic>mechanistic</italic> question of what is happening in the model at the (simulated) neuronal level in conditions where differentiation (i.e., an average decrease in similarity from pre to post) occurs. Here, the model’s answer is clear: When the similarity of two pairmates decreases, it is because the pairmates have acquired anticorrelated representations at the (simulated) neuronal level. When similarity decreases on average from pre to post, but the average “post” similarity value is not negative, this is because there is a mix of outcomes across runs of the model (due to variance in the initial, random model weights and also variance in the order in which items are presented across training epochs) – some runs lead to differentiation (manifested as anticorrelated pairmate representations) whereas others lead to no change or integration. The average pre-to-post change depends on the relative frequencies with which these different outcomes occur.</p><p>We have made several edits to the paper to clarify this point.</p><p>We added a new section under “Results” in our simulation of Chanales et al. (2021) entitled, “Pairs of Items that Differentiate Show Anticorrelated Representations” (p. 15):</p><p>“Figure 6B also highlights that, for learning rates where robust differentiation effects occur in aggregate (i.e., there is a reduction in mean pattern similarity, averaging across model runs), these aggregate effects involve a bimodal distribution across model runs: For some model runs, learning processes give rise to anticorrelated representations, and for other model runs the model shows integration; this variance across model runs is attributable to random differences in the initial weight configuration of the model. The aggregate differentiation effect is therefore a function of the proportion of model runs showing differentiation (here, anticorrelation) and the proportion of model runs showing integration. The fact that differentiation shows up as anticorrelation in the model's hidden layer relates to the learning effects discussed earlier:</p><p>Unique competitor units are sheared away from (formerly) shared units, so the competitor ends up not having any overlap with the target representation (i.e., the level of overlap is less than you would expect due to chance, which mathematically translates into anticorrelation). We return to this point and discuss how to test for anticorrelation in the <italic>Discussion</italic> section.”</p><p>We added new text to the “Take-Home Lessons” section in the Chanales et al. (2021) simulation (p. 17):</p><p>“In particular, the simulations expose some important boundary conditions for when representational change can occur according to the NMPH (e.g., that differentiation depends on a large learning rate, but integration does not), and the simulations provide a more nuanced account of exactly how representations change (e.g., that differentiation driven by the NMPH is always asymmetric, whereas integration is sometimes asymmetric and sometimes symmetric; and that, when differentiation occurs on a particular model run, it tends to give rise to anticorrelated representations in the model's hidden layer).”</p><p>We added new text to the “Nature of Representational Change” section in the Favila et al. (2016) simulation (p. 21):</p><p>“Figure 8 - Supplement 1 also indicates that, as in our simulation of Chanales et al. (2021), individual model runs where differentiation occurs show anticorrelation between the pairmate representations, and gradations in the aggregate level of differentiation that is observed across conditions reflect differences in the proportion of trials showing this anticorrelation effect.”</p><p>We added new text to the “Take-Home Lessons” section in the Favila et al. (2016) simulation (p.21):</p><p>“As in our simulation of Chanales et al., 2021, we found that the NMPH-mediated differentiation was asymmetric, manifested as anticorrelation between pairmate representations on individual model runs, and required a high learning rate, leading to abrupt representational change.”</p><p>We added new text to the “Nature of Representational Change” section in the Schlichting et al. (2015) simulation (p. 26):</p><p>“Also, as in our other simulations, when differentiation occurs on a particular model run it tends to give rise to anticorrelated representations (results not shown).”</p><p>We added new text to the “Take-Home Lessons” section in the Schlichting et al. (2015) simulation (pp. 26-27):</p><p>“As in the other versions of our model, differentiation requires a high learning rate, and – on model runs when it occurs – it is asymmetric and gives rise to anticorrelated representations.”</p><p>We added new text at the start of the Discussion (p. 27):</p><p>“In addition to qualitatively replicating the results from the studies we simulated, our model gives rise to several novel predictions – most notably, that differentiation driven by the NMPH requires a rapid learning rate and, when it occurs for a particular pair of items, it is asymmetric and gives rise to anticorrelated representations.”</p><p>We also added a new section in the Discussion entitled “Testing the Model's Prediction about Anticorrelation”, which (among other things) highlights the reviewer’s point that fMRI pattern similarity values can be affected by preprocessing choices (p. 30):</p><p>“Even though we operationally define differentiation as a reduction in similarity with learning, the way that it actually shows up on individual model runs is as anticorrelation between pairmates; in the model, the size of the aggregate differentiation effect is determined by the proportion of model runs that show this anticorrelation effect (vs. no change or integration). This implies that, if we could get a clean measurement of the similarity of pairmates in an experiment, we might see a multimodal distribution, with some pairmates showing anticorrelation, and others showing increased correlation (integration) or no change in similarity. This kind of clean readout of the similarity of individual pairs might be difficult to obtain with fMRI; it is more feasible that this could be obtained with electrophysiology. Another challenge with using fMRI to test this prediction is that anticorrelation at the individual-neuron level might not scale up to yield anticorrelation at the level of the BOLD response; also, fMRI pattern similarity values can be strongly affected by preprocessing choices – so a negative pattern similarity value does not necessarily reflect anticorrelation at the individual-neuron level. A final caveat is that, while we predict that differentiation will show up as anticorrelation in the brain region that <italic>gives rise to</italic> the differentiation effect, this might not translate into anticorrelation in areas that are downstream of this region (e.g., if the hippocampus is the source of the differentiation effect, we would expect anticorrelation there, but not necessarily in neocortical regions that receive input from the hippocampus; we revisit this point later in the discussion, when we address limitations and open questions).”</p><p>We added new text in the Discussion, under “Limitations and Open Questions” (p. 31):</p><p>“Importantly, while hippocampus can boost the representation of unique features in neocortex, we expect that neocortex will continue to represent shared perceptual features (e.g., in Favila et al., 2016, the fact that both pairmates are photos of barns). For this reason, in paradigms like the one used by Favila et al. (2016), the predicted effect of hippocampal differentiation on neocortical representations will be a reduction in pattern similarity (due to upregulation in the representation of unique pairmate features) but neocortex should not cross over into anticorrelation in these paradigms (due to its continued representation of shared perceptual features). Indeed, this is exactly the pattern that Wanjia et al. (2021) observed in their study, which used similar stimuli to those used in Favila et al. (2016).”</p><p>Lastly, we updated the Abstract (p. 1)</p><p>“What determines when neural representations of memories move together (integrate) or apart (differentiate)? Classic supervised learning models posit that, when two stimuli predict similar outcomes, their representations should integrate. However, these models have recently been challenged by studies showing that pairing two stimuli with a shared associate can sometimes cause differentiation, depending on the parameters of the study and the brain region being examined. Here, we provide a purely unsupervised neural network model that can explain these and other related findings. The model can exhibit integration or differentiation depending on the amount of activity allowed to spread to competitors – inactive memories are not modified, connections to moderately active competitors are weakened (leading to differentiation), and connections to highly active competitors are strengthened (leading to integration). The model also makes several novel predictions – most importantly, that when differentiation occurs as a result of this unsupervised learning mechanism, it will be rapid and asymmetric, and it will give rise to anticorrelated representations in the region of the brain that is the source of the differentiation. Overall, these modeling results provide a computational explanation for a diverse set of seemingly contradictory empirical findings in the memory literature, as well as new insights into the dynamics at play during learning.”</p><disp-quote content-type="editor-comment"><p>(3) For the modeling of the Favila et al. study, the authors state that a high learning rate is required for differentiation of the same-face pairs. This made me wonder what happens in the low learning rate simulations. Does integration occur?</p></disp-quote><p>For the same-face condition of the Favila simulation, lowering learning rate does not result in an overall integration effect:</p><fig id="sa4fig1" position="float"><label>Author response image 1.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-sa4-fig1-v1.tif"/></fig><p>In other cases, we do see integration emerge at lower learning rates – e.g., in the Schlichting interleaved condition we see a small integration effect emerge for a learning rate value of 0.3:</p><fig id="sa4fig2" position="float"><label>Author response image 2.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-sa4-fig2-v1.tif"/></fig><p>Our view is that, while integration can emerge at low learning rates, it is not a reliable property of the model – in some cases, there is a “window” of learning rates where there is enough learning to drive integration but not enough to drive differentiation, and in other cases there is not. Given this lack of reliability across simulations, we would prefer not to discuss this in the paper.</p><disp-quote content-type="editor-comment"><p>This paradigm has a lot of overlap with acquired equivalence, and so I am thinking about whether these are the sorts of small differences (e.g., same-category scenes and perhaps a high learning rate) that bias the system to differentiate instead of integrate.</p></disp-quote><p>We agree that it would be very interesting to use the model to explore acquired equivalence and related phenomena, but we think it is out of scope of the current paper. We have added some text to the Discussion under “Limitations and Open Questions” (p. 32):</p><p>“Another important future direction is to apply the model to a wider range of learning phenomena involving representational change – for example, acquired equivalence, which (like some of the studies modeled here) involves linking distinct stimuli to a shared associate (see, e.g., Honey and Hall, 1989; Shohamy and Wagner, 2008; Myers et al., 2003; Meeter et al., 2009; de Araujo Sanchez and Zeithamova, 2023). It is possible that some of these phenomena might be better explained by supervised learning, or a mixture of unsupervised and supervised learning, than by unsupervised learning alone.”</p><disp-quote content-type="editor-comment"><p>(4) For the simulations of the Schlichting et al. study, the A and B appear to have overlap in the hidden layer based on Figure 9, despite there being no similarity between the A and B items in the study (in contrast to Favila et al., in which they were similar kinds of scenes, and Chanales et al., in which they were similar colors). Why was this decision made? Do the effects depend on some overlap within the hidden layer? (This doesn't seem to be explained in the paper that I saw though, so maybe just it's a visualization error?)</p></disp-quote><p>Overlap in the pretrained hidden representations of A and B is not strictly necessary for these effects – it would be possible to reconfigure other parameters to get high levels of competition even if there were no overlap (e.g., by upregulating the strengths of connections from shared input features). Having said that, it is definitely true that overlap between the pretrained hidden representations boosts competition, and we think it is justified to posit this in the Schlichting simulation. We have now added an explanation for this in the paper (p. 23):</p><p>“New text in Schlichting, “Knowledge Built into the Network”</p><p>Matching the previous two simulations, we pretrained the weights so the hidden representations of the stimuli initially had 2/6 units in common. Even though the A and B stimuli used in the actual experiment did not have obvious feature overlap (they were randomly selected novel objects), it is important to note that the hidden layer is not simply a representation of the sensory features of the A and B stimuli; the hidden layer also receives input from the output layer, which represents the shared associate of A and B (X). We think that the presence of this shared associate justifies our use of initially-overlapping hidden representations.”</p><disp-quote content-type="editor-comment"><p>(5) It seems as though there were no conditions under which the simulations produced differentiation in both the blocked and intermixed conditions, which Schlichting et al. observed in many regions (as the present authors note). Is there any way to reconcile this difference?</p></disp-quote><p>We thank the reviewer for bringing this up. If we set the connection strength between X (in the output layer) and A (in the hidden layer) in the blocked condition to .9 instead of .999 (keeping this connection strength at .8 for the interleaved condition) and we set <italic>Osc</italic> to .0615, we observe differentiation in both conditions.</p><p>Rather than replacing the original results in the paper, which would entail re-making the associated videos, etc., we have added a supplementary figure (Figure 10 - Supplement 1), which is included on p. 46.</p><p>We also added the following to the Results section of the Schlichting simulation in the main text (p. 26):</p><p>“Figure 10 - Supplement 1 shows results from an alternative parameterization where, in the low-oscillation-amplitude condition, differentiation is observed in both the blocked and interleaved conditions (mirroring results from Schlichting et al., 2015, who found differentiation in both conditions in several regions of interest, including parts of the hippocampus and medial prefrontal cortex).”</p><disp-quote content-type="editor-comment"><p>(6) A general question about differentiation/repulsion and how it affects the hidden layer representation in the model: Is it the case that the representation is actually &quot;shifted&quot; or repelled over so it is no longer overlapping? Or do the shared connections just get pruned, such that the item that has more &quot;movement&quot; in representational space is represented by fewer units on the hidden layer (i.e., is reduced in size)? I think, if I understand correctly, that whether it gets shifted vs. reduce would depend on the strength of connections along the hidden layer, which would in turn depend on whether it represents some meaningful continuous dimension (like color) or not. But, if the connections within the hidden layer are relatively weak and it is the case that representations become reduced in size, would there be any anticipated consequences of this (e.g., cognitively/behaviorally)?</p></disp-quote><p>The representations are shifted – this is discussed in the Chanales results section:</p><p>“Because the activity ``set point'' for the hidden layer (determined by the kWTA algorithm) involves having 6 units active, and the unique parts of the competitor only take up 4 of these 6 units, this leaves room for activity to spread to additional units. Given the topographic projections in the output layer, the model is biased to ``pick up'' units that are adjacent in color space to the currently active units; because activity cannot flow easily from the competitor back to the target (as a result of the aforementioned severing of connections), it flows instead {\em away} from the target, activating two additional units, which are then incorporated into the competitor representation. This sequence of events (first a severing of the shared units, then a shift away from the target) completes the process of neural differentiation, and is what leads to the behavioral repulsion effect in color recall (because the center-of-mass of the color representation has now shifted away from the target).”</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public Review):</bold></p><p>This paper addresses an important computational problem in learning and memory. Why do related memory representations sometimes become more similar to each other (integration) and sometimes more distinct (differentiation)? Classic supervised learning models predict that shared associations should cause memories to integrate, but these models have recently been challenged by empirical data showing that shared associations can sometimes cause differentiation. The authors have previously proposed that unsupervised learning may account for these unintuitive data. Here, they follow up on this idea by actually implementing an unsupervised neural network model that updates the connections between memories based on the amount of coactivity between them. The goal of the authors' paper is to assess whether such a model can account for recent empirical data at odds with supervised learning accounts. For each empirical finding they wish to explain, the authors built a neural network model with a very simple architecture (two inputs layers, one hidden layer, and one output layer) and with prewired stimulus representations and associations. On each trial, a stimulus is presented to the model, and inhibitory oscillations allow competing memories to pop up. Pre-specified u-shaped learning rules are used to update the weights in the model, such that low coactivity leaves model connections unchanged, moderate coactivity weakens connections, and high coactivity strengthens connections. In each of the three models, the authors manipulate stimulus similarity (following Chanales et al), shared vs distinct associations (following Favila et al), or learning strength (a stand in for blocked versus interleaved learning schedule; following Schlichting et al) and evaluate how the model representations evolve over trials.</p><p>As a proof of principle, the authors succeed in demonstrating that unsupervised learning with a</p><p>simple u-shaped rule can produce qualitative results in line with the empirical reports. For instance, they show that pairing two stimuli with a common associate (as in Favila et al) can lead to *differentiation* of the model representations. Demonstrating these effects isn't trivial and a formal modeling framework for doing so is a valuable contribution. Overall, the authors do a good job of both formally describing their model and giving readers a high level sense of how their critical model components work, though there are some places where the robustness of the model to different parameter choices is unclear. In some cases, the authors are very clear about this (e.g. the fast learning rate required to observe differentiation)<bold>.</bold> However, in other instances, the paper would be strengthened by a clearer reporting of the critical parameter ranges.</p></disp-quote><p>We thank the reviewer for raising this point. The interdependence of parameters in our model makes it infeasible to identify critical parameter ranges. We have added a paragraph to the “Approach to Parameterization and Data Fitting” section in the Methods to address this point (p. 33):</p><p>“The overall goal of this modeling work is to account for key empirical regularities regarding differentiation and integration and to establish boundary conditions on these regularities. As such, the modeling work described below focuses more on qualitative fits to general properties of the data space than on quantitative fits to results from specific studies. Automatic parameter optimization is not feasible for this kind of model, given the large number of model parameters and the highly interactive, nonlinear nature of competitive dynamics in the model; consequently, model fitting was done by hand.</p><p>These complex interactions between parameters also make it infeasible to list “critical parameter ranges” for generating particular model outcomes. Our experience in working with the model has been that activation dynamics are what matter most for learning, and that disparate parameter sets can give rise to the same activation dynamics and -- through this -- the same learning effects; likewise, similar parameter sets can give rise to different activation dynamics and different learning outcomes. Consequently, in this paper we have focused on characterizing the dynamics that give rise to different learning effects (and how they can be affected by local parameter perturbations, e.g., relating to learning rate and oscillation size), rather than the – impossible, we believe – task of enumerating the full set of parameter configurations that give rise to a particular result.”</p><disp-quote content-type="editor-comment"><p>For instance, it's clear from the manipulation of oscillation strength in the model of Schlichting et al that this parameter can dramatically change the direction of the results. The authors do report the oscillation strength parameter values that they used in the other two models, but it is not clear how sensitive these models are to small changes in this value.</p></disp-quote><p>In some cases, the effects of oscillation strength are relatively smooth. For example, in the Favila simulation, increasing the oscillation amplitude <italic>Osc</italic> effectively recapitulates the U-shaped curve (i.e., higher levels of <italic>Osc</italic> lead to more competitor activation, which initially leads to weakening / differentiation but then gives way to strengthening / integration), as is shown for the Favila Different Face condition in this plot:</p><fig id="sa4fig3" position="float"><label>Author response image 3.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-sa4-fig3-v1.tif"/></fig><p>In the Chanales 2/6 overlap condition, the effects of varying <italic>Osc</italic> are more nonlinear:</p><fig id="sa4fig4" position="float"><label>Author response image 4.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-sa4-fig4-v1.tif"/></fig><p>We think this is attributable to the increased “all-or-none” recurrent dynamics in this simulation (due to the recurrent projections within the output layer), which make it more difficult to evoke moderate (vs. high) levels of activation. This difficulty in reliably obtaining graded activation dynamics is likely a consequence of the small-scale (“toy”) nature of the model and the simple inhibitory mechanisms employed here, as opposed to being a generalizable property of the brain – presumably, the actual brain employs more nuanced and effective means of controlling activation. Furthermore, we don’t think that the high prevalence of integration in the model’s parameter space necessarily translates into a prediction that integration should be more prevalent overall – see the new “Reconciling the Prevalence of Differentiation in the Model and in the Data” section described in response to one of the reviewer’s other points below. Due to the paper already being quite long, we have opted not to include the above plots / discussion in the paper.</p><disp-quote content-type="editor-comment"><p>Similarly, it's not clear whether the 2/6 hidden layer overlap (only explicitly manipulated in the model of Chanales et al) is required for the other two models to work.</p></disp-quote><p>When we were parameterizing the model, we opted to keep the 2/6 level of overlap for all of the simulations and we adjusted other parameters to fit the data; in part, this was because overlap can only be adjusted in discrete jumps, whereas other influential parameters in the model can be adjusted in a more graded, real-valued way. Our use of 2/6 overlap (as opposed to, say, 1/6 or 3/6 overlap) for the Favila and Schlichting models was done out of convenience, and should not be interpreted as a strong statement that this particular level of overlap is necessary for obtaining differentiation; we could easily get the model to show differentiation given other overlap levels by adjusting other parameters.</p><disp-quote content-type="editor-comment"><p>Finally, though the u-shaped learning rule is essential to this framework, the paper does little formal investigation of this learning rule. It seems obvious that allowing the u-shape to collapse too much toward a horizontal line would reduce the model's ability to account for empirical results, but there may be other more interesting features of the learning rule parameterization that are essential for the model to function properly.</p></disp-quote><p>Given that the paper is already quite long, we have opted not to include further exploration of the parameters of the U-shaped learning rule in the paper. However, for the reviewer’s information, we report the effects of a few illustrative manipulations of these parameters below. As a general principle, the effects of these manipulations make sense in light of the theoretical framework described in the paper.</p><p>For example, the parameter “DRevMag” controls the size of the negative “dip” in the U-shaped curve (more negative values = a larger dip). Given that this negative dip is essential for severing weights to competitors and causing differentiation, shifting DRevMag upwards towards zero should shift the balance of the model away from differentiation and towards integration. This is indeed what we observe, as shown in this parameter sweep from the Chanales simulation:</p><fig id="sa4fig5" position="float"><label>Author response image 5.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-sa4-fig5-v1.tif"/></fig><p>As another example: The “DRev” parameter controls where the U-shaped curve transitions from negative weight change to positive weight change. Lower values of DRev mean that the region of coactivity values leading to negative weight change will be smaller, and the region of coactivity values leading to positive weight change will be larger. As such, we would expect that lower values of DRev would bias the model toward integration. That is indeed the case, as shown in this parameter sweep from the Schlichting Blocked simulation:</p><fig id="sa4fig6" position="float"><label>Author response image 6.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-88608-sa4-fig6-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>There are a few other points that may limit the model's ability to clearly map onto or make predictions about empirical data. The model(s) seems very keen to integrate and do so more completely than the available empirical data suggest. For instance, there is a complete collapse of representations in half of the simulations in the Chanales et al model and the blocked simulation in the Schlichting et al model also seems to produce nearly complete integration Even if the Chanales et al paper had observed some modest behavioral attraction effects, this model would seem to over-predict integration. The author's somewhat implicitly acknowledge this when they discuss the difficulty of producing differentiation (&quot;Practical Advice for Getting the Model to Show Differentiation&quot;) and not of producing integration, but don't address it head on.</p></disp-quote><p>We thank the reviewer for this comment – R1 had a similar comment. We have added a new section to the Discussion to address this point (p. 30):</p><p>“Reconciling the Prevalence of Differentiation in the Model and in the Data.</p><p>A key lesson from our model is that, from a computational perspective, it is challenging to obtain differentiation effects: The region of parameter space that gives rise to differentiation is much smaller than the one that gives rise to integration (for further discussion of this issue, see the section in Methods on Practical Advice for Getting the Model to Show Differentiation). However, the fact that integration is more prevalent in our simulations across parameter configurations does not mean that integration will be more prevalent than differentiation in real-life circumstances. What really matters in predicting the prevalence of differentiation in real life is how the parameters of the brain map on to parameters of the model: If the parameters of the brain align with regions of model parameter space that give rise to differentiation (even if these regions are small), this would explain why differentiation has been so robustly observed in extant studies. Indeed, this is exactly the case that we sought to make above about the hippocampus – i.e., that its use of especially sparse coding and a high learning rate will give rise to the kinds of neural dynamics that cause differentiation (as opposed to integration). As another example, while it is true that half of the overlap conditions in our simulation of Chanales et al. (2021) give rise to integration, this does not imply that integration will occur half of the time in the Chanales et al. (2021) study; it may be that the levels of overlap that are actually observed in the brain in Chanales et al. (2021) are more in line with the levels of overlap that give rise to differentiation in our model.”</p><disp-quote content-type="editor-comment"><p>Second, the authors choice of strongly prewiring associations in the Chanales and Favila models makes it difficult to think about how their model maps onto experimental contexts where competition is presumably occurring while associations are only weakly learned. In the Chanales et al paper, for example, the object-face associations are not well learned in initial rounds of the color memory test. While the authors do justify their modeling choice and their reasons have merit, the manipulation of AX association strength in the Schlichting et al model also makes it clear that the association strength has a substantial effect on the model output. Given the effect of this manipulation, more clarity around this assumption for the other two models is needed.</p></disp-quote><p>We thank the reviewer for bringing this up. We have edited the section entitled “A Note on Prewiring Representations” in the Methods to further justify our choice to prewire associations in the Chanales and Favila models (p. 37):</p><p>“In our model, our practice of ``prewiring'' memory representations for the A and B pairmates serves two functions. In some cases, it is meant to stand in for actual training (as in the blocked / interleaved manipulation; the connections supporting the AX association are prewired to be stronger in the blocked condition than in the interleaved condition). However, the other, more fundamental role of prewiring is to ensure that the A and B input patterns evoke sparse distributed representations in the hidden layer (i.e., where some units are strongly active but most other units are inactive). In the real brain, this happens automatically because the weight landscape has been extensively sculpted by both experience and evolution. For example, in the real hippocampus, when the second pairmate is presented for the first time, it will evoke a sparse distributed representation in the CA3 subfield (potentially overlapping with the first pairmate’s CA3 representation) even before any learning of the second pairmate has occurred, due to the strong, sparse mossy fiber projections that connect the dentate gyrus to CA3 (McNaughton &amp; Morris, 1987). As discussed above, we hypothesize that this initial, partial overlap between the second pairmate’s representation and the first pairmate’s representation can lead to pop-up of the unique features of the first pairmate’s representation, triggering learning that leads to differentiation or integration. In our small-scale model, we are effectively starting with a ``blank brain''; in the absence of prewiring, the A and B inputs would activate overly diffuse representations that do not support these kinds of competitive dynamics. As such, prewiring in our model is necessary for proper functioning. The presence of prewired A and B representations should therefore not be interpreted as reflecting a particular training history (except in the blocked / interleaved case above); rather, these prewired representations constitute the minimum step we would take to ensure well-defined competitive dynamics in our small-scale model.</p><p>The fact that connection strengths serve this dual function – sometimes reflecting effects of training (as in our simulation of Schlichting et al., 2015) and in other cases reflecting necessary prewiring – complicates the interpretation of these strength values in the model. Our view is that this is a necessary limitation of our simplified modeling approach – one that can eventually be surmounted through the use of more biologically-detailed architectures (see <italic>Limitations and Open Questions</italic> in the <italic>Discussion</italic>).”</p><disp-quote content-type="editor-comment"><p>Overall, this is strong and clearly described work that is likely to have a positive impact on computational and empirical work in learning and memory. While the authors have written about some of the ideas discussed in this paper previously, a fully implemented and openly available model is a clear advance that will benefit the field. It is not easy to translate a high-level description of a learning rule into a model that actually runs and behaves as expected. The fact that the authors have made all their code available makes it likely that other researchers will extend the model in numerous interesting ways, many of which the authors have discussed and highlighted in their paper.</p><p><bold>Reviewer #3 (Public Review):</bold></p><p>This paper proposes a computational account for the phenomenon of pattern differentiation (i.e., items having distinct neural representations when they are similar). The computational model relies on a learning mechanism of the nonmonotonic plasticity hypothesis, fast learning rate and inhibitory oscillations. The relatively simple architecture of the model makes its dynamics accessible to the human mind. Furthermore, using similar model parameters, this model produces simulated data consistent with empirical data of pattern differentiation. The authors also provide insightful discussion on the factors contributing to differentiation as opposed to integration. The authors may consider the following to further strengthen this paper:</p><p>The model compares different levels of overlap at the hidden layer and reveals that partial overlap seems necessary to lead to differentiation. While I understand this approach from the perspective of modeling, I have concerns about whether this is how the human brain achieves differentiation. Specifically, if we view the hidden layer activation as a conjunctive representation of a pair that is the outcome of encoding, differentiation should precede the formation of the hidden layer activation pattern of the second pairmate. Instead, the model assumes such pattern already exists before differentiation. Maybe the authors indeed argue that mechanistically differentiation follows initial encoding that does not consider similarity with other memory traces?</p><p>Related to the point above, because the simulation setup is different from how differentiation actually occurs, I wonder how valid the prediction of asymmetric reconfiguration of hidden layer connectivity pattern is.</p></disp-quote><p>We thank the reviewer for this comment. In the revised manuscript, we have edited the “Note on Prewiring Representations” in the Methods to clarify how our assumptions about prewiring relate to what we really think is happening in the brain (p. 37):</p><p>“In our model, our practice of ``prewiring'' memory representations for the A and B pairmates serves two functions. In some cases, it is meant to stand in for actual training (as in the blocked / interleaved manipulation; the connections supporting the AX association are prewired to be stronger in the blocked condition than in the interleaved condition). However, the other, more fundamental role of prewiring is to ensure that the A and B input patterns evoke sparse distributed representations in the hidden layer (i.e., where some units are strongly active but most other units are inactive). In the real brain, this happens automatically because the weight landscape has been extensively sculpted by both experience and evolution. For example, in the real hippocampus, when the second pairmate is presented for the first time, it will evoke a sparse distributed representation in the CA3 subfield (potentially overlapping with the first pairmate’s CA3 representation) even before any learning of the second pairmate has occurred, due to the strong, sparse mossy fiber projections that connect the dentate gyrus to CA3 (McNaughton &amp; Morris, 1987). As discussed above, we hypothesize that this initial, partial overlap between the second pairmate’s representation and the first pairmate’s representation can lead to pop-up of the unique features of the first pairmate’s representation, triggering learning that leads to differentiation or integration. In our small-scale model, we are effectively starting with a ``blank brain''; in the absence of prewiring, the A and B inputs would activate overly diffuse representations that do not support these kinds of competitive dynamics. As such, prewiring in our model is necessary for proper functioning. The presence of prewired A and B representations should therefore not be interpreted as reflecting a particular training history (except in the blocked / interleaved case above); rather, these prewired representations constitute the minimum step we would take to ensure well-defined competitive dynamics in our small-scale model.</p><p>The fact that connection strengths serve this dual function – sometimes reflecting effects of training (as in our simulation of Schlichting et al., 2015) and in other cases reflecting necessary prewiring – complicates the interpretation of these strength values in the model. Our view is that this is a necessary limitation of our simplified modeling approach – one that can eventually be surmounted through the use of more biologically-detailed architectures (see <italic>Limitations and Open Questions</italic> in the <italic>Discussion</italic>).”</p><disp-quote content-type="editor-comment"><p>Although as the authors mentioned, there haven't been formal empirical tests of the relationship between learning speed and differentiation/integration, I am also wondering to what degree the prediction of fast learning being necessary for differentiation is consistent with current data. According to Figure 6, the learning rates lead to differentiation in the 2/6 condition achieved differentiation after just one-shot most of the time. On the other hand, For example, Guo et al (2021) showed that humans may need a few blocks of training and test to start showing differentiation.</p></disp-quote><p>We thank the reviewer for mentioning this. We have added a paragraph to the “Differentiation Requires a High Learning Rate and Is Sensitive to Activity Dynamics” section of the Discussion that addresses this point (pp. 28-29):</p><p>“Although the results from Wanjia et al. (2021) provide strong support for the model's prediction that differentiation will be abrupt, they raise another question: What explains variance across items in <italic>when</italic> this abrupt change takes place? The answer to this question remains to be seen, but one possibility is encoding variability: If we assume that participants stochastically sample (i.e., attend to) the features of the scene pairmates, it is possible that participants might initially fail to sample the features that distinguish the scene pairmates, which can be quite subtle – and if the distinguishing features of the pairmates are not represented in high-level visual regions (i.e., the pairmates are represented in these regions as having the same features), this could delay the onset of differentiation until the point at which the distinguishing features happen (by chance) to be sampled.”</p><disp-quote content-type="editor-comment"><p>Related to the point above, the high learning rate prediction also seems to be at odds with the finding that the cortex, which has slow learning (according to the theory of complementary learning systems), also shows differentiation in Wammes et al (2022).</p></disp-quote><p>We now address this point in the section of the Discussion entitled “Differentiation Requires a High Learning Rate and Is Sensitive to Activity Dynamics” (p. 27):</p><p>“Our finding that differentiation requires a high learning rate suggests that differentiation will be more evident in the hippocampus than in neocortex, insofar as hippocampus is thought to have a higher learning rate than neocortex (McClelland et al., 1995). In keeping with this prediction, numerous studies have found differentiation effects in hippocampus but not in neocortical regions involved in sensory processing (e.g., Chanales et al., 2017; Favila et al., 2016; Zeithamova et al., 2018). At the same time, some studies have found differentiation effects in neocortex (e.g., Schlichting et al., 2015; Wammes et al., 2022). One possible explanation of these neocortical differentiation effects is that they are being ``propped up’’ by top-down feedback from differentiated representations in the hippocampus.”</p><disp-quote content-type="editor-comment"><p>More details about the learning dynamics would be helpful. For example, equation(s) showing how activation, learning rate and the NMPH function work together to change the weight of connections may be added. Without the information, it is unclear how each connection changes its value after each time point.</p></disp-quote><p>We thank the reviewer for this comment. We have made two major changes to address this concern. First, we have edited the “Learning” section within “Basic Network Properties” in the main text (pp. 6-7):</p><p>“Connection strengths in the model between pairs of connected units <italic>x</italic> and <italic>y</italic> were adjusted at the end of each trial (i.e., after each stimulus presentation) as a U-shaped function of the coactivity of <italic>x</italic> and <italic>y</italic>, defined as the product of their activations on that trial. The parameters of the U-shaped learning function relating coactivity to change in connection strength (i.e., weakening / strengthening) were specified differently for each projection where learning occurs (bidirectionally between the input and hidden layers, the hidden layer to itself, and the hidden to output layer). Once the U-shaped learning function for each projection in each version of the model was specified, we did not change it for any of the various conditions. Details of how we computed coactivity and how we specified the U-shaped function can be found in the <italic>Methods</italic> section.”</p><p>Second, we have added the requested equations to the “Learning” part of the Methods (pp. 37-38):</p><disp-quote content-type="editor-comment"><p>The right side of the function, strong activation leads to strengthening of the connectivity, which I assume will lead to stronger activation on the next time point. The model has an upper limit of connection strength to prevent connection from strengthening too much. The same idea can be applied to the left side of the function: instead of having two turning points, it can be a linear function such that low activation keeps weakening connection until the lower limit is reached. This way the NMPH function can take a simpler form (e.g., two line-segments if you think the weakening and strengthening take different rates) and may still simulate the data.</p></disp-quote><p>We thank the reviewer for mentioning this. We have added a new paragraph in the “Learning” section of the Methods to justify the particular shape of the learning curve (pp. 38-39):</p><p>“Evidence for the U-shaped plasticity function used here (where low activation leads to no change, moderate activation leads to weakening, and higher levels of activation lead to strengthening) was previously reviewed in Ritvo et al. (2019). In brief, there are three lines of work that support the U shape: First, multiple neurophysiological studies have found that moderate postsynaptic depolarization leads to synaptic weakening and higher levels of depolarization lead to synaptic strengthening (e.g., Artola et al., 1990; Hansel et al., 1996). Second, human neuroscience studies have used pattern classifiers, applied to fMRI and EEG data, to measure memory activation, and have related this measure to subsequent memory accessibility; several studies using this approach have found that low levels of activation lead to no change in memory strength, moderate levels of activation lead to impaired subsequent memory, and higher levels of activation lead to increased subsequent memory (e.g., Newman and Norman, 2010; Detre et al., 2013; Kim et al., 2014; for related findings, see Lewis-Peacock and Norman, 2014; Wang et al., 2019). Third, a recent human fMRI study by Wammes et al. (2022) manipulated memory activation by varying the visual similarity of pairmates and observed a U-shaped function relating visual similarity to representational change in the hippocampus, whereby low levels of pairmate similarity were associated with no change, moderate levels of similarity were associated with differentiation, and the differentiation effect went away at higher levels of similarity.</p><p>We have also included a pointer to this new paragraph in the “Nonmonotonic Plasticity Hypothesis” section of Introduction (p. 2):</p><p>(for further discussion of the empirical justification for the NMPH, see the Learning subsection in the <italic>Methods</italic>)”</p><disp-quote content-type="editor-comment"><p><bold>Recommendations for the authors:</bold></p><p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p><p>A few additional minor things about data presentation and the like:</p><p>(1) Figure 1 legend - a more general description of how to interpret the figure might be helpful for more naive readers (e.g., explaining how one can visualize in the schematic that there is overlap in the hidden layer between A and B). Also, from the Figure 1 depiction, it's not clear what is different about the setup from the initial left hand side panels in A, B, C, to make it such that activity spreads strongly to A in panel A, weakly in panel B, and not at all in panel C since the weights are the same. Is there a way to incorporate this into the graphic, or describe it in words?</p></disp-quote><p>To address this point, we have added the following text to the Figure 1 caption (p. 3):</p><p>“Note that the figure illustrates the consequences of differences in competitor activation for learning, without explaining why these differences would arise. For discussion of circumstances that could lead to varying levels of competitor activation, see the simulations described in the text.”</p><disp-quote content-type="editor-comment"><p>(2) I believe not all of the papers cited on lines 193-195 actually have similarity manipulations in them. I'd recommend double checking this list and removing those less relevant to the statement.</p></disp-quote><p>Thank you for pointing this out; we have removed the Ballard reference and we have clarified what we mean by similarity reversal (p. 7):</p><p>“The study was inspired by recent neuroimaging studies showing ``similarity reversals'', wherein stimuli that have more features in common (or share a common associate) show less hippocampal pattern similarity (Favila et al., 2016; Schlichting et al., 2015; Molitor et al., 2021; Chanales et al., 2017; Dimsdale-Zucker et al., 2018; Wanjia et al., 2021; Zeithamova et al., 2018; Jiang et al., 2020; Wammes et al., 2022).”</p><disp-quote content-type="editor-comment"><p>(3) I wanted a bit more detail about how the parameters were set in the main paper, not just in the methods. Even something as brief as noting that model fitting was done by hand by tweaking parameters to re-create the empirical patterns (if I'm understanding correctly) would have been helpful for me.</p></disp-quote><p>To address this point, we have added the following text under “Basic Network Properties” (p. 4):</p><p>“Our goal was to qualitatively fit key patterns of results from each of the aforementioned studies. We fit the parameters of the model by hand as they are highly interdependent (see the <italic>Methods</italic> section for more details).”</p><disp-quote content-type="editor-comment"><p>(4) In Figure 4E, it would be helpful to describe the x and y axes of the MDS plots in the legend.</p></disp-quote><p>To address this point, we have added the following new text to the Figure 4 caption that clarifies how the MDS plots were generated (p. 11):</p><p>“MDS plots were rotated, shifted, and scaled such that pairmate 1before is located at (0,0), pairmate 2before is located directly to the right of pairmate 1before, and the distance between pairmate 1before and pairmate 2before is proportional to the baseline distance between the pairmates.”</p><disp-quote content-type="editor-comment"><p>(5) Figure 6 - at first I thought the thicker line was some sort of baseline, but I think it is just many traces on top of one another. If other readers may be similarly confused, perhaps this could be stated.</p></disp-quote><p>Thanks for this comment. We have updated Figure 6 (p. 16).</p><p>We have also updated the caption.</p><disp-quote content-type="editor-comment"><p>I am having a lot of difficulty understanding the terms &quot;competitor-to-competitor,&quot;</p><p>&quot;competitor-to-target/shared,&quot; and &quot;target/shared-to-target/shared,&quot; and therefore I don't fully get Figure 5. I think it might be helpful to expand the description of these terms where they are first introduced in the paper (p. 13?). I think I am missing something crucial here, and I am not quite sure what that is-which I know is not very helpful! But, to narrate my confusion a bit, I thought that these terms would somehow relate to connections between different connections of the network. For example is competitor-to-competitor within the hidden layer? Or is this somehow combining across relevant connections that might span different pairs of layers in the model? And, I really have no idea why it is &quot;target/shared.&quot;</p></disp-quote><p>Thank you for these comments. We have updated Figure 5 and we have also made several changes to the main text and the figure caption to address these points.</p><p>Changes to the main text (p. 13):</p><p>“Whether symmetric or asymmetric integration occurs depends on the relative strengths of connections between pairs of unique competitor units (<italic>competitor-competitor connections</italic>) compared to connections between unique competitor units and shared units (<italic>competitor-shared connections</italic>) after the first trial (Figure 5; note that the figure focuses on connections between hidden units, but the principle also applies to connections that span across layers). Generally, coactivity between unique competitor units (<italic>competitor-competitor coactivity</italic>) is less than coactivity between unique competitor units and shared units (<italic>competitor-shared coactivity</italic>), which is less than coactivity between unique target units and shared units (<italic>target-shared coactivity</italic>).”</p><disp-quote content-type="editor-comment"><p>(7) Relatedly in Figure 13, I understand how some competitor-to-target/shared connections could be spared in the bottom instance given panel B. However, I'm struggling to understand how that relates to the values in the corresponding chart in panel A. What about panel A, bottom (vs. the top) means lower coactivities between some competitor-to-target/shared? Is it because if the noise level is higher, the &quot;true&quot; activation of competitor-to-target/shared connections is weaker? I think again, I'm missing something critical here! and wonder if other readers may be in the same situation. (I know the authors described this also on p. 36, but I'm still confused!)</p></disp-quote><p>We have updated Figure 13 to clarify these points.</p><disp-quote content-type="editor-comment"><p>(8) In Figure 9, I believe there is no caption for panel D. Also, it looks as though the item unit active for A and B is the same. I wonder if this is an error?</p></disp-quote><p>Thank you for catching these errors! They have both been fixed.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p><p>-Perhaps I missed it, but I think defining coactivity (how it is computed) in the main text would be useful for readers, as this is critical for understanding the model. I did find it in the methods.</p></disp-quote><p>We thank the reviewer for this suggestion. We have updated the “Learning” section within “Basic Network Properties” in the main text to address this point (pp. 6-7):</p><p>“Connection strengths in the model between pairs of connected units <italic>x</italic> and <italic>y</italic> were adjusted at the end of each trial (i.e., after each stimulus presentation) as a U-shaped function of the coactivity of <italic>x</italic> and <italic>y</italic>, defined as the product of their activations on that trial. The parameters of the U-shaped learning function relating coactivity to change in connection strength (i.e., weakening / strengthening) were specified differently for each projection where learning occurs (bidirectionally between the input and hidden layers, the hidden layer to itself, and the hidden to output layer). Once the U-shaped learning function for each projection in each version of the model was specified, we did not change it for any of the various conditions. Details of how we computed coactivity and how we specified the U-shaped function can be found in the <italic>Methods</italic> section.”</p><disp-quote content-type="editor-comment"><p>-The modeling results in the different face condition are at odds with the data for the Favila et al model (they observe some differentiation in the paper and the model predicts no change). This could be due to a number of unmodeled factors, but it is perhaps worth noting.</p></disp-quote><p>Thank you for pointing this out. It is possible to better capture the pattern of results observed by Favila et al. in their paper (with some differentiation in the different-face condition and even more differentiation in the same-face condition) by slightly adjusting the model parameters (specifically, by setting the oscillation amplitude <italic>Osc</italic> for the hidden layer to .1 instead of .067).</p><p>Rather than replacing the old (<italic>Osc</italic> = .067) results in the paper, which would entail re-making the associated videos, etc., we have added a supplementary figure (Figure 8 - Supplement 1; see p.45):</p><p>We also added new text to the Favila Results, under “Differentiation and Integration” (p. 20):</p><p>“Note also that the exact levels of differentiation that are observed in the different-face and same-face conditions are parameter dependent; for an alternative set of results showing some differentiation in the different-face condition (but still less than is observed in the same-face condition), see Figure 8 - Supplement 1.”</p><disp-quote content-type="editor-comment"><p>-Related to my comment in the public review about pre-wiring associations, in the caption for Figure 9 (Schlichting model), the authors report &quot;In both conditions, the pre-wired connection linking the &quot;item B&quot; hidden units to the &quot;item X&quot; output unit is set to .7. In the interleaved condition, the connection linking the &quot;item A&quot; hidden units to the &quot;item X&quot; output unit is set to .8, to reflect some amount of initial AX learning. In the blocked condition, the connection linking the &quot;item A&quot; hidden units to the &quot;item X&quot; output unit is set a higher value (.999), to reflect extra AX learning.&quot; What are the equivalent values for the other models, especially the Favila model since the structure is the same as Schlichting? I understood all the &quot;strong&quot; connections to be .99 unless otherwise stated. If that's the case, I don't understand why the blocked Schlichting model and the Favila model produce opposite effects. More clarity would be useful here.</p></disp-quote><p>We have added a new paragraph to the results section for the Schlicting model (under “Differentiation and Integration”) to clarify why the blocked Schlichting model and the Favila model show different results (p. 24):</p><p>“Note that the key feature driving integration in the blocked condition of this simulation is not the high strength of the connection from X to A <italic>on its own</italic> – rather, it is the <italic>asymmetry</italic> in the pretrained connection strengths from X to A (.999) and from X to B (.7). This asymmetry, which is meant to reflect the extensive training on A-X that occurred before the initial presentation of B-X, results in the A-X hidden representation decisively winning the competition during B-X presentation, which then leads to the B input also being linked to this representation (i.e., integration). It is instructive to compare this to the same-face condition from our simulation of Favila et al. (2016): In that simulation, the two pairmates are also linked strongly (.99 initial connection strength) to a shared associate, but in that case the connections are equally strong, so there is more balanced competition -- in this case, the competitor representation only comes to mind moderately (instead of displacing the target representation), so the result is differentiation instead of integration.”</p><disp-quote content-type="editor-comment"><p>-The meaning of the different colored dots in Figure 5 is bit hard to keep track of, even given the legend labels. The figure might benefit from a model sketch highlighting each of the different coactivity types. The left side of Fig 13 was useful but again somehow mapping on the colors would help further. Another note on these figures: what does having two dots of each color mean? Is it just an illustration of the variance? There would be more dots if there was one dot per coactivity value.</p></disp-quote><p>We have updated Figure 5 and Figure 13 to clarify these points (including a clarification that the dots only represent a subset of the possible pairings between units).</p><disp-quote content-type="editor-comment"><p>-While I appreciate the goal of the paper is to account for these three studies, readers who aren't familiar with or specifically interested in these studies may appreciate a small amount of intuition on why formalizing unsupervised learning models may be broadly important for computational investigations of learning/memory/cognition.</p></disp-quote><p>We have added the following text under “Basic Network Properties” in the Introduction to address this point (p. 4):</p><p>“Achieving a better understanding of unsupervised learning is an important goal for computational neuroscience, given that learning agents have vastly more opportunities to learn in an unsupervised fashion than from direct supervision (for additional discussion of this point, see, e.g., Zhuang et al., 2021).”</p></body></sub-article></article>