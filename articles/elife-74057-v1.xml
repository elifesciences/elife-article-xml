<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1d3" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">74057</article-id><article-id pub-id-type="doi">10.7554/eLife.74057</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Archerfish number discrimination</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-254078"><name><surname>Potrich</surname><given-names>Davide</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0928-628X</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor1">*</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-255400"><name><surname>Zanon</surname><given-names>Mirko</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-4062-1496</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-75752"><name><surname>Vallortigara</surname><given-names>Giorgio</given-names></name><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-8192-9062</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="corresp" rid="cor2">*</xref><xref ref-type="other" rid="par-1"/><xref ref-type="other" rid="par-2"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><institution content-type="dept">Center for Mind/Brain Sciences</institution>, <institution>University of Trento</institution>, <addr-line><named-content content-type="city">Rovereto</named-content></addr-line>, <country>Italy</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor" id="author-41470"><name><surname>Nieder</surname><given-names>Andreas</given-names></name><role>Reviewing editor</role><aff><institution>University of Tübingen</institution>, <country>Germany</country></aff></contrib></contrib-group><author-notes><corresp id="cor1"><label>*</label>For correspondence: <email>davide.potrich@unitn.it</email> (DP);</corresp><corresp id="cor2"><label>*</label>For correspondence: <email>giorgio.vallortigara@unitn.it</email> (GV);</corresp></author-notes><pub-date date-type="pub" publication-format="electronic"><day>10</day><month>01</month><year>2022</year></pub-date><volume>11</volume><elocation-id>e74057</elocation-id><history><date date-type="received"><day>20</day><month>09</month><year>2021</year></date><date date-type="accepted"><day>07</day><month>01</month><year>2022</year></date></history><permissions><copyright-statement>© 2022, Potrich et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Potrich et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link> permitting unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-74057-v1.pdf"/><abstract><p>Debates have arisen as to whether non-human animals actually can learn abstract non-symbolic numerousness or whether they always rely on some continuous physical aspect of the stimuli, covarying with number. Here we investigated archerfish (<italic>Toxotes jaculatrix</italic>) non-symbolic numerical discrimination with accurate control for co-varying continuous physical stimulus attributes. Archerfish were trained to select one of two groups of black dots (Exp. 1: 3 <italic>vs. </italic>6 elements; Exp. 2: 2 <italic>vs.</italic> 3 elements); these were controlled for several combinations of physical variables (elements’ size, overall area, overall perimeter, density and sparsity), ensuring that only numerical information was available. Generalization tests with novel numerical comparisons (2 <italic>vs.</italic> 3, 5 <italic>vs.</italic> 8 and 6 <italic>vs.</italic> 9 in Exp. 1; 3 <italic>vs.</italic> 4, 3 <italic>vs.</italic> 6 in Exp. 2) revealed choice for the largest or smallest numerical group according to the relative number that was rewarded at training. None of the continuous physical variables, including spatial frequency, were affecting archerfish performance. Results provide evidence that archerfish spontaneously use abstract relative numerical information for both small and large numbers when only numerical cues are available.</p></abstract><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Other</kwd></kwd-group><funding-group><award-group id="par-1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100010663</institution-id><institution>H2020 European Research Council</institution></institution-wrap></funding-source><award-id>833504</award-id><principal-award-recipient><name><surname>Vallortigara</surname><given-names>Giorgio</given-names></name></principal-award-recipient></award-group><award-group id="par-2"><funding-source><institution-wrap><institution>Progetti di Rilevante Interesse Nazionale</institution></institution-wrap></funding-source><award-id>2017PSRHPZ</award-id><principal-award-recipient><name><surname>Vallortigara</surname><given-names>Giorgio</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group></article-meta></front><back><sec id="s1" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interest</title><fn fn-type="conflict" id="conf1"><p>The authors declare that no competing interests exist.</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Animal experimentation: The present research was carried out at the Animal Cognition and Neuroscience Laboratory (ACN Lab) of the CIMeC (Center for Mind/Brain Sciences), at the University of Trento (Italy). All husbandry and experimental procedures complied with European Legislation for the Protection of Animals used for Scientific Purposes (Directive 2010/63/EU) and were approved by the Scientific Committee on Animal Health and Animal Welfare (Organismo Preposto al Benessere Animale, OPBA) of the University of Trento and by the Italian Ministry of Health (Protocol n. 932/2020-PR).</p></fn></fn-group></sec><sec id="s2" sec-type="supplementary-material"><title>Additional Files</title><sec id="s3" sec-type="data-availability"><title>Data availability</title><p>All data generated or analysed during this study have been deposited in Dryad.</p><p>The following datasets were generated:</p><p><element-citation id="dataset1" publication-type="data" specific-use="isSupplementedBy"><person-group person-group-type="author"><collab>Potrich D</collab><collab>Zanon M</collab><collab>Vallortigara G</collab></person-group><year iso-8601-date="2021">2021</year><source>Numerical discrimination of sets of elements by Archerfish</source><ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5061/dryad.4f4qrfjdg">https://doi.org/10.5061/dryad.4f4qrfjdg</ext-link><comment>Dryad Digital Repository, doi:10.5061/dryad.4f4qrfjdg</comment></element-citation></p></sec><supplementary-material><ext-link xlink:href="elife-74057-supp-v1.zip">Download zip</ext-link><p>Any figures and tables for this article are included in the PDF. The zip folder contains additional supplemental files.</p></supplementary-material></sec></back></article>