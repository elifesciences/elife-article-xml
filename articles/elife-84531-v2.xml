<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">84531</article-id><article-id pub-id-type="doi">10.7554/eLife.84531</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Are single-peaked tuning curves tuned for speed rather than accuracy?</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes" id="author-297727"><name><surname>Lenninger</surname><given-names>Movitz</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6165-4900</contrib-id><email>movitzle@kth.se</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-297728"><name><surname>Skoglund</surname><given-names>Mikael</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-138557"><name><surname>Herman</surname><given-names>Pawel Andrzej</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6553-823X</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-31619"><name><surname>Kumar</surname><given-names>Arvind</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8044-9195</contrib-id><email>arvkumar@kth.se</email><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/026vcq606</institution-id><institution>Division of Information Science and Engineering, KTH Royal Institute of Technology</institution></institution-wrap><addr-line><named-content content-type="city">Stockholm</named-content></addr-line><country>Sweden</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/026vcq606</institution-id><institution>Division of Computational Science and Technology, KTH Royal Institute of Technology</institution></institution-wrap><addr-line><named-content content-type="city">Stockholm</named-content></addr-line><country>Sweden</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Latham</surname><given-names>Peter</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Poirazi</surname><given-names>Panayiota</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/052rphn09</institution-id><institution>Foundation for Research and Technology Hellas</institution></institution-wrap><country>Greece</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>16</day><month>05</month><year>2023</year></pub-date><pub-date pub-type="collection"><year>2023</year></pub-date><volume>12</volume><elocation-id>e84531</elocation-id><history><date date-type="received" iso-8601-date="2022-10-28"><day>28</day><month>10</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2023-05-11"><day>11</day><month>05</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2022-09-10"><day>10</day><month>09</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.09.09.505677"/></event></pub-history><permissions><copyright-statement>© 2023, Lenninger et al</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Lenninger et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-84531-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-84531-figures-v2.pdf"/><abstract><p>According to the efficient coding hypothesis, sensory neurons are adapted to provide maximal information about the environment, given some biophysical constraints. In early visual areas, stimulus-induced modulations of neural activity (or tunings) are predominantly single-peaked. However, periodic tuning, as exhibited by grid cells, has been linked to a significant increase in decoding performance. Does this imply that the tuning curves in early visual areas are sub-optimal? We argue that the time scale at which neurons encode information is imperative to understand the advantages of single-peaked and periodic tuning curves, respectively. Here, we show that the possibility of catastrophic (large) errors creates a trade-off between decoding time and decoding ability. We investigate how decoding time and stimulus dimensionality affect the optimal shape of tuning curves for removing catastrophic errors. In particular, we focus on the spatial periods of the tuning curves for a class of circular tuning curves. We show an overall trend for minimal decoding time to increase with increasing Fisher information, implying a trade-off between accuracy and speed. This trade-off is reinforced whenever the stimulus dimensionality is high, or there is ongoing activity. Thus, given constraints on processing speed, we present normative arguments for the existence of the single-peaked tuning organization observed in early visual areas.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>neural coding</kwd><kwd>tuning curves</kwd><kwd>decoding time</kwd><kwd>high-dimensional stimuli</kwd><kwd>spiking activity</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution>Digital Futures</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Lenninger</surname><given-names>Movitz</given-names></name><name><surname>Skoglund</surname><given-names>Mikael</given-names></name><name><surname>Herman</surname><given-names>Pawel Andrzej</given-names></name><name><surname>Kumar</surname><given-names>Arvind</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100004359</institution-id><institution>Vetenskapsrådet</institution></institution-wrap></funding-source><principal-award-recipient><name><surname>Kumar</surname><given-names>Arvind</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution>Institute of Advanced Studies</institution></institution-wrap></funding-source><award-id>Fellowship</award-id><principal-award-recipient><name><surname>Kumar</surname><given-names>Arvind</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Single-peaked tuning curves found in early sensory areas are more optimized for quick decoding than accuracy, while multi-peaked tuning curves (e.g. grid cells) give higher accuracy but only at longer time scales.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>One of the fundamental problems in systems neuroscience is understanding how sensory information can be represented in the spiking activity of an ensemble of neurons. The problem is exacerbated by the fact that individual neurons are highly noisy and variable in their responses, even to identical stimuli (<xref ref-type="bibr" rid="bib2">Arieli et al., 1996</xref>). A common feature of early sensory representation is that the neocortical neurons in primary sensory areas change their average responses only to a small range of features of the sensory stimulus. For instance, some neurons in the primary visual cortex respond to moving bars oriented at specific angles (<xref ref-type="bibr" rid="bib19">Hubel and Wiesel, 1962</xref>). This observation has led to the notion of <italic>tuning curves</italic>. Together, a collection of tuning curves provides a possible basis for a neural code.</p><p>A considerable emphasis has been put on understanding how the structure of noise and correlations affect stimulus representation given a set of tuning curves (<xref ref-type="bibr" rid="bib38">Shamir and Sompolinsky, 2004</xref>; <xref ref-type="bibr" rid="bib3">Averbeck and Lee, 2006</xref>; <xref ref-type="bibr" rid="bib14">Franke et al., 2016</xref>; <xref ref-type="bibr" rid="bib49">Zylberberg et al., 2016</xref>; <xref ref-type="bibr" rid="bib28">Moreno-Bote et al., 2014</xref>; <xref ref-type="bibr" rid="bib21">Kohn et al., 2016</xref>). More recently, the issue of local and catastrophic errors, dating back to the work of Shannon (<xref ref-type="bibr" rid="bib39">Shannon, 1949</xref>), has been raised in the context of neuroscience (e.g. <xref ref-type="bibr" rid="bib48">Xie, 2002</xref>; <xref ref-type="bibr" rid="bib41">Sreenivasan and Fiete, 2011</xref>). Intuitively, local errors are small estimation errors that depend on the trial-by-trial variability of the neural responses and the local shapes of the tuning curves surrounding the true stimulus condition (<xref ref-type="fig" rid="fig1">Figure 1a</xref> bottom plot, see <italic>s</italic><sub>1</sub>). On the other hand, catastrophic errors are very large estimation errors that depend on the trial-by-trial variability and the global shape of the tuning curves (<xref ref-type="fig" rid="fig1">Figure 1a</xref> bottom plot, see <italic>s</italic><sub>2</sub>). While a significant effort has been put into studying how stimulus tuning and different noise structures affect local errors, less is known about the interactions with catastrophic errors. For example, <italic>Fisher information</italic> is a common measure of the accuracy of a neural code (<xref ref-type="bibr" rid="bib7">Brunel and Nadal, 1998</xref>; <xref ref-type="bibr" rid="bib1">Abbott and Dayan, 1999</xref>; <xref ref-type="bibr" rid="bib17">Guigon, 2003</xref>; <xref ref-type="bibr" rid="bib28">Moreno-Bote et al., 2014</xref>; <xref ref-type="bibr" rid="bib5">Benichoux et al., 2017</xref>). The Cramér-Rao bound states that a lower limit of the minimal mean squared error (MSE) for any unbiased estimator is given by the inverse of Fisher information (<xref ref-type="bibr" rid="bib23">Lehmann and Casella, 1998</xref>). Thus, increasing Fisher information reduces the lower bound on MSE. However, because Fisher information can only capture local errors, the true MSE might be considerably larger in the presence of catastrophic errors (<xref ref-type="bibr" rid="bib48">Xie, 2002</xref>; <xref ref-type="bibr" rid="bib22">Kostal et al., 2015</xref>; <xref ref-type="bibr" rid="bib26">Malerba et al., 2022</xref>), especially if the available decoding time is short (<xref ref-type="bibr" rid="bib6">Bethge et al., 2002</xref>; <xref ref-type="bibr" rid="bib13">Finkelstein et al., 2018</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Illustrations of local and catastrophic errors.</title><p>(<bold>a</bold>) Top: A two-neuron system encoding a single variable using single-peaked tuning curves (<inline-formula><mml:math id="inf1"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>). Bottom: The tuning curves create a one-dimensional activity trajectory embedded in a two-dimensional neural activity space (black trajectory). Decoding the two stimulus conditions, <italic>s</italic><sub>1</sub> and <italic>s</italic><sub>2</sub>, illustrates the two types of estimation errors that can occur due to trial-by-trial variability, local (<inline-formula><mml:math id="inf2"><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>) and catastrophic (<inline-formula><mml:math id="inf3"><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>). (<bold>b</bold>) Same as in (<bold>a</bold>) but for periodic tuning curves (<inline-formula><mml:math id="inf4"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula>). Notice that the stimulus conditions are intermingled and that the stimulus can not be determined from the firing rates. (<bold>c</bold>) Time evolution of the root mean squared error (RMSE) using maximum likelihood estimation (solid line) and the Cramér-Rao bound (dashed line) for a population of single-peaked tuning curves (<inline-formula><mml:math id="inf5"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>600</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf6"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mn>0.3</mml:mn></mml:mrow></mml:math></inline-formula>, average evoked firing rate <inline-formula><mml:math id="inf7"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mn>20</mml:mn><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> sp/s, and <inline-formula><mml:math id="inf8"><mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> sp/s). For about 50 ms the RMSE is significantly larger than the predicted lower bound. (<bold>d</bold>) The empirical error distributions for the time point indicated in (<bold>c</bold>), where the RMSE strongly deviates from the predicted lower bound. Inset: A non-zero empirical error probability spans the entire stimulus domain. (<bold>e</bold>) Same as in (<bold>d</bold>) when the RMSE roughly converges to the Cramér-Rao bound. Notice the absence of large estimation errors.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84531-fig1-v2.tif"/></fig><p>A curious observation is that the tuning curves in early visual areas predominately use single-peaked firing fields, whereas grid cells in the entorhinal cortex are known for their periodically distributed firing fields (<xref ref-type="bibr" rid="bib18">Hafting et al., 2005</xref>). It has been shown that the multiple firing locations of grid cells increase the precision of the neural code compared to single-peaked tuning curves (<xref ref-type="bibr" rid="bib41">Sreenivasan and Fiete, 2011</xref>; <xref ref-type="bibr" rid="bib27">Mathis et al., 2012</xref>; <xref ref-type="bibr" rid="bib46">Wei et al., 2015</xref>). This raises the question of why periodic firing fields are not a prominent organization of early visual processing too?</p><p>The theoretical arguments in favor of periodic tuning curves have mostly focused on local errors under the assumption that catastrophic errors are negligible (<xref ref-type="bibr" rid="bib41">Sreenivasan and Fiete, 2011</xref>). However, given the response variability, it takes a finite amount of time to accumulate a sufficient number of spikes to decode the stimulus. Given that fast processing speed is a common feature of visual processing (<xref ref-type="bibr" rid="bib44">Thorpe et al., 1996</xref>; <xref ref-type="bibr" rid="bib11">Fabre-Thorpe et al., 2001</xref>; <xref ref-type="bibr" rid="bib36">Rolls and Tovee, 1994</xref>; <xref ref-type="bibr" rid="bib33">Resulaj et al., 2018</xref>), it is crucial that each neural population in the processing chain can quickly produce a reliable stimulus-evoked signal. Therefore, the time required to produce signals without catastrophic errors will likely put fundamental constraints on any neural code, especially in early visual areas.</p><p>Here, we contrast Fisher information with the minimal decoding time required to remove catastrophic errors (i.e. the time until Fisher information becomes a reasonable descriptor of the MSE). We base the results on the maximum likelihood estimator for uniformly distributed stimuli (i.e., the maximum a posteriori estimator) using populations of tuning curves with different numbers of peaks. We show that the minimal decoding time tends to increase with increasing Fisher information in the case of independent Poissonian noise to each neuron. This suggests a trade-off between the decoding accuracy of a neural population and the speed by which it can produce a reliable signal. Furthermore, we show that the difference in minimal decoding time grows with the number of jointly encoded stimulus features (stimulus dimensionality) and in the presence of ongoing (non-specific) activity. Thus, single-peaked tuning curves require shorter decoding times and are more robust to ongoing activity than periodic tuning curves. Finally, we illustrate the issue of large estimation errors and periodic tuning in simple spiking neural network model tracking either a step-like stimulus change or a continuously time-varying stimulus.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Shapes of tuning curves, Fisher information, and catastrophic errors</title><p>To enable a comparison between single-peaked and periodic (multi-peaked) tuning curves, we consider circular tuning curves responding to a D-dimensional stimulus, <inline-formula><mml:math id="inf9"><mml:mi mathvariant="bold">s</mml:mi></mml:math></inline-formula>, according to<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.470em" minsize="2.470em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.470em" minsize="2.470em">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:math></disp-formula></p><p>where <italic>a</italic><sub><italic>i</italic></sub> is the peak amplitude of the stimulus-related tuning curve <inline-formula><mml:math id="inf10"><mml:mi>i</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf11"><mml:mi>w</mml:mi></mml:math></inline-formula> is a width scaling parameter, <inline-formula><mml:math id="inf12"><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> defines the spatial period of the tuning curve, <inline-formula><mml:math id="inf13"><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula> determines the location of the peak(s) in the <inline-formula><mml:math id="inf14"><mml:mi>j</mml:mi></mml:math></inline-formula>:th stimulus dimension, and <inline-formula><mml:math id="inf15"><mml:mi>b</mml:mi></mml:math></inline-formula> determines the amount of ongoing activity (see <xref ref-type="fig" rid="fig1">Figure 1a–b</xref>, top panels). The parameters are kept fixed for each neuron, thus ignoring any effect of learning or plasticity. In the following, the stimulus domain is set to <inline-formula><mml:math id="inf16"><mml:mrow><mml:mi mathvariant="bold">s</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> for simplicity. To avoid boundary effects, we assume that the stimulus has periodic boundaries (i.e. <inline-formula><mml:math id="inf17"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf18"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> are the same stimulus condition) and adjust any decoded value to lie within the stimulus domain, for example,<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mn>0.1</mml:mn><mml:mspace width="2.845276pt"/><mml:mo stretchy="false">(</mml:mo><mml:mtext>mod</mml:mtext><mml:mspace width="2.845276pt"/><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.1</mml:mn><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>see Materials and methods - ’Implementation of maximum likelihood estimator’ for details.</p><p>We assume that the stimulus is uniformly distributed across its domain and that its dimensions are independent. This can be seen as a worst-case scenario as it maximizes the entropy of the stimulus. In a single trial, we assume that the number of emitted spikes for each neuron is conditionally independent, and follows a Poisson distribution, given some stimulus-dependent rate <inline-formula><mml:math id="inf19"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Thus, the probability of observing a particular activity pattern, <inline-formula><mml:math id="inf20"><mml:mi mathvariant="bold">r</mml:mi></mml:math></inline-formula>, in a population of <inline-formula><mml:math id="inf21"><mml:mi>N</mml:mi></mml:math></inline-formula> neurons given the stimulus-dependent rates and decoding time, <inline-formula><mml:math id="inf22"><mml:mi>T</mml:mi></mml:math></inline-formula>, is<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>T</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>!</mml:mo></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Given a model of neural responses, the Cramér-Rao bound provides a lower bound on the accuracy by which the population can communicate a signal as the inverse of the Fisher information. For sufficiently large populations, using the population and spike count models in <xref ref-type="disp-formula" rid="equ1">Equation 1</xref> and <xref ref-type="disp-formula" rid="equ3">Equation 3</xref>, Fisher information is given by (for <inline-formula><mml:math id="inf23"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf24"><mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> for all neurons, see <xref ref-type="bibr" rid="bib41">Sreenivasan and Fiete, 2011</xref> or Appendix 2 - 'Fisher information and the Cramér-Rao bound' for details)<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mi>J</mml:mi><mml:mo>≈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mi>a</mml:mi><mml:mi>T</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mi>w</mml:mi></mml:mfrac><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf25"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes the sample average of the squared inverse of the (relative) spatial periods across the population, and <inline-formula><mml:math id="inf26"><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the modified Bessel functions of the first kind. <xref ref-type="disp-formula" rid="equ4">Equation 4</xref> (and similar expressions) suggests that populations consisting of periodic tuning curves, for which <inline-formula><mml:math id="inf27"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>≫</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, are superior at communicating a stimulus signal than a population using tuning curves with only single peaks, where <inline-formula><mml:math id="inf28"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. However, (inverse) Fisher information only predicts the amount of local errors for an efficient estimator. Hence, the presence of catastrophic errors (<xref ref-type="fig" rid="fig1">Figure 1a</xref>, bottom) can be identified by large deviations from the predicted MSE for an asymptotically efficient estimator (<xref ref-type="fig" rid="fig1">Figure 1c–d</xref>). Therefore, we define minimal decoding time as the shortest time required to approach the Cramér-Rao bound (<xref ref-type="fig" rid="fig1">Figure 1c and e</xref>).</p></sec><sec id="s2-2"><title>Periodic tuning curves and stimulus ambiguity</title><p>To understand why the amount of catastrophic error can differ with different spatial periods, consider first the problem of stimulus ambiguity that can arise with periodic tuning curves. If all tuning curves in the population share the same relative spatial period, <inline-formula><mml:math id="inf29"><mml:mi>λ</mml:mi></mml:math></inline-formula>, then the stimulus-evoked responses can only provide unambiguous information about the stimulus in the range <inline-formula><mml:math id="inf30"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Beyond this range, the response distributions are no longer unique. Thus, single-peaked tuning curves (<inline-formula><mml:math id="inf31"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) provide unambiguous information about the stimulus. Periodic tuning curves (<inline-formula><mml:math id="inf32"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>λ</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>), on the other hand, require the use of tuning curves with two or more distinct spatial periods to resolve the stimulus ambiguity (<xref ref-type="bibr" rid="bib12">Fiete et al., 2008</xref>; <xref ref-type="bibr" rid="bib27">Mathis et al., 2012</xref>; <xref ref-type="bibr" rid="bib46">Wei et al., 2015</xref>). In the following, we assume the tuning curves are organized into discrete modules, where all tuning curves within a module share spatial period (<xref ref-type="fig" rid="fig1">Figure 1b</xref>) mimicking the organization of grid cells (<xref ref-type="bibr" rid="bib42">Stensola et al., 2012</xref>). For convenience, assume that <inline-formula><mml:math id="inf33"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> where <inline-formula><mml:math id="inf34"><mml:mi>L</mml:mi></mml:math></inline-formula> is the number of modules. Thus, the first module provides the most coarse-grained resolution of the stimulus interval, and each successive module provides an increasingly fine-grained resolution. It has been suggested that a geometric progression of spatial periods, such that <inline-formula><mml:math id="inf35"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> for some spatial factor <inline-formula><mml:math id="inf36"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>c</mml:mi><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, may be optimal for maximizing the resolution of the stimulus while reducing the required number of neurons (<xref ref-type="bibr" rid="bib27">Mathis et al., 2012</xref>; <xref ref-type="bibr" rid="bib46">Wei et al., 2015</xref>). However, trial-by-trial variability can still cause stimulus ambiguity and catastrophic errors - at least for short decoding times, as we show later, even when using multiple modules with different spatial periods.</p></sec><sec id="s2-3"><title>(Very) Short decoding times - when both Fisher information and MSE fails</title><p>While it is known that Fisher information is not an accurate predictor of the MSE when the decoding time is short (<xref ref-type="bibr" rid="bib6">Bethge et al., 2002</xref>), less has been discussed about the issue of MSE. Although MSE is often interpreted as a measure of accuracy, its insensitivity to rare outliers makes it a poor measure of reliability. Therefore, comparing MSE directly between populations can be a misleading measure of reliability if the distributions of errors are qualitatively different. If the amounts of local errors differ, lower MSE does not necessarily imply fewer catastrophic errors. This is exemplified in <xref ref-type="fig" rid="fig2">Figure 2</xref>, comparing a single-peaked and a periodic population encoding a two-dimensional stimulus using the suggested optimal scale factor, <inline-formula><mml:math id="inf37"><mml:mrow><mml:mi>c</mml:mi><mml:mo>≈</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>1.44</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> (<xref ref-type="bibr" rid="bib46">Wei et al., 2015</xref>). During the first <inline-formula><mml:math id="inf38"><mml:mrow><mml:mi/><mml:mo>≈</mml:mo><mml:mn>30</mml:mn></mml:mrow></mml:math></inline-formula> ms, the single-peaked population has the lowest MSE of the two populations despite having lower Fisher information (<xref ref-type="fig" rid="fig2">Figure 2a</xref>). Furthermore, comparing the error distribution after the periodic population achieves a lower MSE (the black circle in <xref ref-type="fig" rid="fig2">Figure 2a</xref>) shows that the periodic population still suffers from rare errors that span the entire stimulus range (<xref ref-type="fig" rid="fig2">Figure 2b–c</xref>, insets). As we will show, a comparison of MSE, as a measure of reliability, only becomes valid once catastrophic errors are removed. Here we assume that catastrophic errors should strongly affect the usability of a neural code. Therefore, we argue that the first criterion for any rate-based neural code should be to satisfy its constraint on decoding time to avoid catastrophic errors.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>(Very) Short decoding times when both Fisher information and MSE fails.</title><p>(<bold>a</bold>) Time evolution of root mean squared error (RMSE), averaged across trials and stimulus dimensions, using maximum likelihood estimation (solid lines) for two populations (blue: <inline-formula><mml:math id="inf39"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf40"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, red: <inline-formula><mml:math id="inf41"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf42"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>1.44</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>). Dashed lines indicate the lower bound predicted by Cramér-Rao. The black circle indicates the point where the periodic population has become optimal in terms of MSE. (<bold>b</bold>) The empirical distribution of errors for the time indicated by the black circle in (<bold>a</bold>). The single-peaked population (blue) has a wider distribution of errors centered around 0 compared to the periodic population (red), as suggested by having a higher MSE. Inset: Zooming in on rare error events reveals that while the periodic population has a narrower distribution of errors around 0, it also has occasional errors across large parts of the stimulus domain. (<bold>c</bold>) The empirical CDF of the errors for the same two populations as in (<bold>b</bold>). Inset: a zoomed-in version (last 1%) of the empirical CDF highlights the heavy-tailed distribution of errors for the periodic population. Parameters used in the simulations: stimulus dimensionality <inline-formula><mml:math id="inf43"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>, the number of modules <inline-formula><mml:math id="inf44"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>, number of neurons <inline-formula><mml:math id="inf45"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>600</mml:mn></mml:mrow></mml:math></inline-formula>, average evoked firing rate <inline-formula><mml:math id="inf46"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mn>20</mml:mn><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> sp/s, ongoing activity <inline-formula><mml:math id="inf47"><mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> sp/s, and width parameter <inline-formula><mml:math id="inf48"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mn>0.3</mml:mn></mml:mrow></mml:math></inline-formula>. Note that the estimation errors for the two stimulus dimensions are pooled together.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84531-fig2-v2.tif"/></fig></sec><sec id="s2-4"><title>Minimal decoding times in populations with two modules</title><p>How does the choice of spatial periods impact the required decoding time to remove catastrophic errors? To get some intuition, we first consider the case of populations encoding a one-dimensional stimulus using only two different spatial scales, <inline-formula><mml:math id="inf49"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf50"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. From the perspective of a probabilistic decoder (<xref ref-type="bibr" rid="bib37">Seung and Sompolinsky, 1993</xref>; <xref ref-type="bibr" rid="bib9">Deneve et al., 1999</xref>; <xref ref-type="bibr" rid="bib25">Ma et al., 2006</xref>), assuming that the stimulus is uniformly distributed, the maximum likelihood (ML) estimator is Bayesian optimal (and asymptotically efficient). The maximum likelihood estimator aims at finding the stimulus condition which is the most likely cause of the observed activity, <inline-formula><mml:math id="inf51"><mml:mi mathvariant="bold">r</mml:mi></mml:math></inline-formula>, or<disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:munder><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf52"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is called the likelihood function. The likelihood function equals the probability of observing the observed neural activity, <inline-formula><mml:math id="inf53"><mml:mi mathvariant="bold">r</mml:mi></mml:math></inline-formula>, assuming that the stimulus condition was <inline-formula><mml:math id="inf54"><mml:mi>s</mml:mi></mml:math></inline-formula>. In the case of independent Poisson spike counts (or at least independence across modules), each module contributes to the joint likelihood function <inline-formula><mml:math id="inf55"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> with individual likelihood functions, <italic>Q</italic><sub>1</sub> and <italic>Q</italic><sub>2</sub> (<xref ref-type="bibr" rid="bib46">Wei et al., 2015</xref>). Thus, the joint likelihood function can be seen as the product of the two individual likelihood functions, where each likelihood is <inline-formula><mml:math id="inf56"><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>-periodic<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>In this sense, each module provides its own ML-estimate of the stimulus, <inline-formula><mml:math id="inf57"><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>arg</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>max</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo>⁡</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf58"><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>arg</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>max</mml:mi></mml:mrow><mml:mi>s</mml:mi></mml:msub><mml:mo>⁡</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Because of the periodicity of the tuning curves, there can be multiple modes for each of the likelihoods (e.g. <xref ref-type="fig" rid="fig3">Figure 3a and b</xref>, top panels). For the largest mode of the joint likelihood function to also be centered close to the true stimulus condition, the distance <inline-formula><mml:math id="inf59"><mml:mi>δ</mml:mi></mml:math></inline-formula> between <inline-formula><mml:math id="inf60"><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="inf61"><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> must be smaller than between any other pair of modes of <italic>Q</italic><sub>1</sub> and <italic>Q</italic><sub>2</sub>. Thus, to avoid catastrophic errors, <inline-formula><mml:math id="inf62"><mml:mi>δ</mml:mi></mml:math></inline-formula> must be smaller than some largest allowed distance <inline-formula><mml:math id="inf63"><mml:msup><mml:mi>δ</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> which guarantees this relation (see <xref ref-type="disp-formula" rid="equ25 equ26 equ27 equ28 equ29 equ30">Equations 25–30</xref> for calculation of <inline-formula><mml:math id="inf64"><mml:msup><mml:mi>δ</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> assuming the stimulus is in the middle of the domain). As <inline-formula><mml:math id="inf65"><mml:mi>δ</mml:mi></mml:math></inline-formula> varies from trial to trial, we limit the probability of the decoder experiencing catastrophic errors to some small error probability, <inline-formula><mml:math id="inf66"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, by imposing that<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:mtext>Pr</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>δ</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:msup><mml:mi>δ</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Assuming that the estimation of each module becomes efficient before the joint estimation, <xref ref-type="disp-formula" rid="equ7">Equation 7</xref> can be reinterpreted as a lower bound on the required decoding time before the estimation based on the joint likelihood function becomes efficient<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mtext>erfinv</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msup><mml:mi>δ</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mfrac><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf67"><mml:mrow><mml:mtext>erfinv</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the inverse of the error function and <inline-formula><mml:math id="inf68"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math></inline-formula> refers to the time-normalized Fisher information of module <inline-formula><mml:math id="inf69"><mml:mi>k</mml:mi></mml:math></inline-formula> (see Materials and methods for derivation). Thus, the spatial periods of the modules influence the minimal decoding time by determining: (1) the largest allowed distance <inline-formula><mml:math id="inf70"><mml:msup><mml:mi>δ</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> between the estimates of the modules and (2) the variances of the estimations given by the inverse of their respective Fisher information.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Catastophic errors and minimal decoding times in populations with two modules.</title><p>(<bold>a</bold>) Top: Sampled individual likelihood functions of two modules with very different spatial periods. Bottom: The sampled joint likelihood function for the individual likelihood functions in the top panel. (<bold>b–c</bold>) Same as in (<bold>a</bold>) but for spatial periods that are similar but not identical and for a single-peaked population, respectively. (<bold>d</bold>) Bottom: The dependence of the scale factor c on the minimal decoding time for <inline-formula><mml:math id="inf71"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. Blue circles indicate the simulated minimal decoding times, and the black line indicates the estimation of the minimal decoding times according to <xref ref-type="disp-formula" rid="equ8">Equation 8</xref>, with <inline-formula><mml:math id="inf72"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>. Top left: The predicted value of <inline-formula><mml:math id="inf73"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msup><mml:mi>δ</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>. Top right: The inverse of the Fisher information. (<bold>e</bold>) Same as (<bold>d</bold>) but for <inline-formula><mml:math id="inf74"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. (<bold>f</bold>) RMSE (lines), the 99.8th percentile (filled circles), and the maximal error (open circles) of the error distribution for several choices of scale factor, <inline-formula><mml:math id="inf75"><mml:mi>c</mml:mi></mml:math></inline-formula>, and decoding time. The color code is the same as in panels (<bold>d-e</bold>). The parameters used in (<bold>d-f</bold>) are: population size <inline-formula><mml:math id="inf76"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>600</mml:mn></mml:mrow></mml:math></inline-formula>, number of modules <inline-formula><mml:math id="inf77"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>, scale factors <inline-formula><mml:math id="inf78"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>0.05</mml:mn><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, width parameter <inline-formula><mml:math id="inf79"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mn>0.3</mml:mn></mml:mrow></mml:math></inline-formula>, average evoked firing rate <inline-formula><mml:math id="inf80"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mn>20</mml:mn><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> sp/s, ongoing activity <inline-formula><mml:math id="inf81"><mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> sp/s, and threshold factor <inline-formula><mml:math id="inf82"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84531-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Example of decoding a stimulus close to the periodic edge.</title><p>Top: Sampled likelihood functions of two modules with <inline-formula><mml:math id="inf83"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf84"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2.3</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. Bottom: The joint likelihood function is shifted across the periodic boundary. Such shifts across the periodic boundary can become more pronounced when <inline-formula><mml:math id="inf85"><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> is slightly below a multiple of <inline-formula><mml:math id="inf86"><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84531-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Same as (<xref ref-type="fig" rid="fig2">Figure 2d–e</xref>) but using threshold factor <inline-formula><mml:math id="inf87"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1.2</mml:mn></mml:mrow></mml:math></inline-formula>.</title><p>Notice the stronger deviations from the predicted minimal decoding time for <inline-formula><mml:math id="inf88"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> when c is slightly below <inline-formula><mml:math id="inf89"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi></mml:mrow></mml:math></inline-formula>, etc.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84531-fig3-figsupp2-v2.tif"/></fig></fig-group><p>To give some intuition of the approximation, if the spatial periods of the modules are very different, <inline-formula><mml:math id="inf90"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>≪</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, then there exist many peaks of <italic>Q</italic><sub>2</sub> around the peak of <italic>Q</italic><sub>1</sub> (<xref ref-type="fig" rid="fig3">Figure 3a</xref>). Additionally, there can be modes of <italic>Q</italic><sub>1</sub> and <italic>Q</italic><sub>2</sub> far away from the true stimulus close together. Thus, <inline-formula><mml:math id="inf91"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>≪</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> can create a highly multi-modal joint likelihood function where small deviations in <inline-formula><mml:math id="inf92"><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="inf93"><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> can cause a shift, or a change, of the maximal mode of the joint likelihood. To avoid this, <inline-formula><mml:math id="inf94"><mml:msup><mml:mi>δ</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> must be small, leading to longer decoding times by <xref ref-type="disp-formula" rid="equ8">Equation 8</xref>. Furthermore, suppose the two modules have similar spatial periods <inline-formula><mml:math id="inf95"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>∼</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, or <inline-formula><mml:math id="inf96"><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> is close to a multiple of <inline-formula><mml:math id="inf97"><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>. In that case, the distance between the peaks a few periods away is also small, again leading to longer decoding times (<xref ref-type="fig" rid="fig3">Figure 3b</xref>). In other words, periodic tuning suffers from the dilemma that small shifts in the individual stimulus estimates can cause catastrophic shifts in the joint likelihood function. Although these might be rare events, the possibility of such errors increases the probability of catastrophic errors. Thus, assuming <inline-formula><mml:math id="inf98"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>, both small and large scale factors <inline-formula><mml:math id="inf99"><mml:mi>c</mml:mi></mml:math></inline-formula> can lead to long decoding times. When <inline-formula><mml:math id="inf100"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, however, only small-scale factors <inline-formula><mml:math id="inf101"><mml:mi>c</mml:mi></mml:math></inline-formula> pose such problems, at least unless the stimulus is close to the periodic edge (i.e. <inline-formula><mml:math id="inf102"><mml:mrow><mml:mi>s</mml:mi><mml:mo>≈</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf103"><mml:mrow><mml:mi>s</mml:mi><mml:mo>≈</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, see <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>). On the other hand, compared to single-peaked tuning curves, periodic tuning generally leads to sharper likelihood functions, increasing the accuracy of the estimates once catastrophic errors are removed (e.g., compare the widths of the joint likelihood functions in <xref ref-type="fig" rid="fig3">Figure 3a–c</xref>).</p><p>To test the approximation in <xref ref-type="disp-formula" rid="equ8">Equation 8</xref>, we simulated a set of populations (<inline-formula><mml:math id="inf104"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>600</mml:mn></mml:mrow></mml:math></inline-formula> neurons) with different spatial periods. The populations were created using identical tuning parameters except for the spatial periods, whose distribution varied across the populations, and the amplitudes, which were adjusted to ensure an equal average firing rate (across all stimulus conditions) for all neurons (see Materials and methods for details on simulations). As described above, the spatial periods were related by a scale factor <inline-formula><mml:math id="inf105"><mml:mi>c</mml:mi></mml:math></inline-formula>. Different values of <inline-formula><mml:math id="inf106"><mml:mi>c</mml:mi></mml:math></inline-formula> were tested for the largest period being either <inline-formula><mml:math id="inf107"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> or <inline-formula><mml:math id="inf108"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. Furthermore, only populations with unambiguous codes over the stimulus interval were included (i.e. <inline-formula><mml:math id="inf109"><mml:mrow><mml:mi>c</mml:mi><mml:mo>≠</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> for <inline-formula><mml:math id="inf110"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>; <xref ref-type="bibr" rid="bib27">Mathis et al., 2012</xref>). Note, however, that there is no restriction on the periodicity of the tuning curves to align with the periodicity of the stimulus (i.e. <inline-formula><mml:math id="inf111"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> does not need to be an integer). For each population, the minimal decoding time was found by gradually increasing the decoding time until the empirical MSE was lower than twice the predicted lower bound (i.e. <inline-formula><mml:math id="inf112"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>, see <xref ref-type="disp-formula" rid="equ1">Equation 10</xref> and Materials and methods for details). Limiting the probability of catastrophic errors to <inline-formula><mml:math id="inf113"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, <xref ref-type="disp-formula" rid="equ8">Equation 8</xref> is a good predictor of the minimal decoding time (<xref ref-type="fig" rid="fig3">Figure 3d–e</xref>, bottom panels, coefficient of determination <inline-formula><mml:math id="inf114"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>≈</mml:mo><mml:mn>0.92</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf115"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>≈</mml:mo><mml:mn>0.95</mml:mn></mml:mrow></mml:math></inline-formula> for <inline-formula><mml:math id="inf116"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf117"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, respectively). For both <inline-formula><mml:math id="inf118"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf119"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, the minimal decoding time increases overall with decreasing scale factor, <inline-formula><mml:math id="inf120"><mml:mi>c</mml:mi></mml:math></inline-formula> (see <xref ref-type="fig" rid="fig3">Figure 3d–e</xref>). However, especially for <inline-formula><mml:math id="inf121"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, the trend is interrupted by large peaks (<xref ref-type="fig" rid="fig3">Figure 3e</xref>). For <inline-formula><mml:math id="inf122"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, there are deviations from the predicted minimal decoding time for small scale factors, <inline-formula><mml:math id="inf123"><mml:mi>c</mml:mi></mml:math></inline-formula>. They occur whenever <inline-formula><mml:math id="inf124"><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> is slightly below a multiple of <inline-formula><mml:math id="inf125"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, and get more pronounced when increasing the sensitivity to the threshold factor <inline-formula><mml:math id="inf126"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1.2</mml:mn></mml:mrow></mml:math></inline-formula> (see <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>). We believe one cause of these deviations is the additional shifts across the periodic boundary (as in <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>) that can occur when <inline-formula><mml:math id="inf127"><mml:mi>c</mml:mi></mml:math></inline-formula> is just below <inline-formula><mml:math id="inf128"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi></mml:mrow></mml:math></inline-formula>, etc.</p><p>To confirm that the estimated minimal decoding times have some predictive power on the error distributions, we re-simulated a subset of the populations for various decoding times, <inline-formula><mml:math id="inf129"><mml:mi>T</mml:mi></mml:math></inline-formula>, using 15,000 randomly sampled stimulus conditions (<xref ref-type="fig" rid="fig3">Figure 3f</xref>). Both the RMSE and outlier errors (99.8th percentile and the maximal error, that is, 100th percentile) agree with the shape of minimal decoding times, suggesting that a single-peaked population is good at removing large errors at very short time scales.</p></sec><sec id="s2-5"><title>Minimal decoding times for populations with more than two modules</title><p>From the two-module case above, it is clear that the choice of scale factor influences the minimal decoding time. However, <xref ref-type="disp-formula" rid="equ8">Equation 8</xref> is difficult to interpret and is only valid for two-module systems (<inline-formula><mml:math id="inf130"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>). To approximate how the minimal decoding time scales with the distribution of spatial periods in populations with more than two modules, we extended the approximation method first introduced by Xie (<xref ref-type="bibr" rid="bib48">Xie, 2002</xref>). The method was originally used to assess the number of neurons required to reach the Cramér-Rao bound for single-peaked tuning curves with additive Gaussian noise for the ML estimator. In addition, it only considered encoding a one-dimensional stimulus variable. We adapted this method to approximate the required decoding time for stimuli with arbitrary dimensions, Poisson-distributed spike counts, and tuning curves with arbitrary spatial periods. In this setting, the scaling of minimum decoding time with the spatial periods, <inline-formula><mml:math id="inf131"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, can be approximated as (see Materials and methods for derivation)<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>≫</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>a</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mfrac><mml:msup><mml:mover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:mo>≃</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mover><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow></mml:mfrac><mml:mfrac><mml:msup><mml:mover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf132"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf133"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></inline-formula> indicate the sample average across the inverse spatial periods (squared or cubed, respectively) in the population, <inline-formula><mml:math id="inf134"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mrow></mml:mstyle></mml:math></inline-formula> is the average evoked firing rate across the stimulus domain, and <inline-formula><mml:math id="inf135"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>A</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> (or <inline-formula><mml:math id="inf136"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>A</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>) is a function of <inline-formula><mml:math id="inf137"><mml:mi>w</mml:mi></mml:math></inline-formula> (see Materials and methods for detailed expression). The last approximation holds with equality whenever all tuning curves have an integer number of peaks. The derivation was carried out assuming the absence of ongoing activity and that the amplitudes within each population are similar, <inline-formula><mml:math id="inf138"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>≈</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>≈</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>N</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Importantly, the approximation also assumes the existence of a unique solution to the maximum likelihood equations. Therefore, it is ill-equipped to predict the issues of stimulus ambiguity. Thus, going back to the two-module cases, <xref ref-type="disp-formula" rid="equ9">Equation 9</xref> cannot capture the additional effects of <inline-formula><mml:math id="inf139"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>≪</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> or when <inline-formula><mml:math id="inf140"><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> is close to a multiple of <inline-formula><mml:math id="inf141"><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>, as in <xref ref-type="fig" rid="fig3">Figure 3d–e</xref>. On the other hand, complementing the theory presented in <xref ref-type="disp-formula" rid="equ8">Equation 8</xref>, <xref ref-type="disp-formula" rid="equ9">Equation 9</xref> provides a more interpretable expression of the scaling of minimal decoding time. For <inline-formula><mml:math id="inf142"><mml:mrow><mml:mi>c</mml:mi><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, the minimal decoding time, <inline-formula><mml:math id="inf143"><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, is expected to increase with decreasing scale factor, <inline-formula><mml:math id="inf144"><mml:mi>c</mml:mi></mml:math></inline-formula> (see <xref ref-type="disp-formula" rid="equ47">Equation 47</xref>). The scaling should also be similar for different choices of <inline-formula><mml:math id="inf145"><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>. Furthermore, assuming all other parameters are constant, the minimal decoding time should grow roughly exponentially with the number of stimulus dimensions.</p><p>To confirm the validity of <xref ref-type="disp-formula" rid="equ9">Equation 9</xref>, we simulated populations of <inline-formula><mml:math id="inf146"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>600</mml:mn></mml:mrow></mml:math></inline-formula> tuning curves across <inline-formula><mml:math id="inf147"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> modules. Again, the spatial periods across the modules were related by a scale factor, <inline-formula><mml:math id="inf148"><mml:mi>c</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4">Figure 4a</xref>). To avoid the effects of <inline-formula><mml:math id="inf149"><mml:mrow><mml:mi>c</mml:mi><mml:mo>≪</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, we limited the range of the scale factor to <inline-formula><mml:math id="inf150"><mml:mrow><mml:mn>0.3</mml:mn><mml:mo>≤</mml:mo><mml:mi>c</mml:mi><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. The upper bound on <inline-formula><mml:math id="inf151"><mml:mi>c</mml:mi></mml:math></inline-formula> was kept (for <inline-formula><mml:math id="inf152"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) to include entirely single-peaked populations. Again, the assumption of homogeneous amplitudes in <xref ref-type="disp-formula" rid="equ9">Equation 9</xref> was dropped in simulations (<xref ref-type="fig" rid="fig4">Figure 4b</xref>, left column) to ensure that the average firing rate across the stimulus domain is equal for all neurons (see <xref ref-type="fig" rid="fig4">Figure 4b</xref>, right column, for the empirical average firing rates). This had little effect on Fisher information, where the theoretical prediction was based on the average amplitudes across all populations with the same <inline-formula><mml:math id="inf153"><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and stimulus dimensionality <inline-formula><mml:math id="inf154"><mml:mi>D</mml:mi></mml:math></inline-formula> (see <xref ref-type="fig" rid="fig4">Figure 4c</xref>, inset). As before, Fisher information grows with decreasing scale factor, <inline-formula><mml:math id="inf155"><mml:mi>c</mml:mi></mml:math></inline-formula>, and with decreasing spatial period <inline-formula><mml:math id="inf156"><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>. As expected, increasing the stimulus dimensionality decreases Fisher information if all other parameters are kept constant. On the other hand, the minimal decoding time increases with decreasing spatial periods and increases with stimulus dimensionality (<xref ref-type="fig" rid="fig4">Figure 4c</xref>). The increase in decoding time between <inline-formula><mml:math id="inf157"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf158"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> is also very well predicted by <xref ref-type="disp-formula" rid="equ9">Equation 9</xref>, at least for <inline-formula><mml:math id="inf159"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>c</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1a</xref>). In these simulations, the choice of width parameter is compatible with experimental data (<xref ref-type="bibr" rid="bib35">Ringach et al., 2002</xref>), but similar trends were found for a range of different width parameters (although the differences become smaller for small <inline-formula><mml:math id="inf160"><mml:mi>w</mml:mi></mml:math></inline-formula>, see <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1b–d</xref>).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Minimal decoding times for populations with five modules.</title><p>(<bold>a</bold>) Illustration of the likelihood functions of a population with <inline-formula><mml:math id="inf161"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> modules using scale factor <inline-formula><mml:math id="inf162"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn></mml:mrow></mml:math></inline-formula>. (<bold>b</bold>) The peak stimulus-evoked amplitudes of each neuron (left column) were selected such that all neurons shared the same expected firing rate for a given stimulus condition (right column). (<bold>c</bold>) Inset: Plot of average Fisher information as a function of the scale factor <inline-formula><mml:math id="inf163"><mml:mi>c</mml:mi></mml:math></inline-formula> (colored lines: estimations from simulation data, black lines: theoretical approximations). Main plot: Plot of minimal decoding time as a function of scale factor <inline-formula><mml:math id="inf164"><mml:mi>c</mml:mi></mml:math></inline-formula>. Minimal decoding time tends to increase with decreasing grid scales (colored lines: estimated minimal decoding time from simulations, black lines: fitted theoretical predictions using <xref ref-type="disp-formula" rid="equ47">Equation 47</xref>). The gray color corresponds to points with large discrepancies between the predicted and the simulated minimal decoding times. (<bold>d</bold>) Plot of the average Fisher information against the minimal decoding time. Points colored in gray are the same as in panel (<bold>c</bold>). (<bold>e</bold>) RMSE (lines), the 99.8<sup>th</sup> percentile (filled circles), and the maximal error (open circles) of the error distribution when decoding a 1-dimensional stimulus for several choices of decoding time. The color code is the same as above. (<bold>f</bold>) same as (<bold>e</bold>) but for a two-dimensional stimulus. Note that the error distributions across stimulus dimensions are pooled together. Parameters used in panels (<bold>a-d</bold>): population size <inline-formula><mml:math id="inf165"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>600</mml:mn></mml:mrow></mml:math></inline-formula>, number of modules <inline-formula><mml:math id="inf166"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>, scale factors <inline-formula><mml:math id="inf167"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>0.3</mml:mn><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, width parameter <inline-formula><mml:math id="inf168"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mn>0.3</mml:mn></mml:mrow></mml:math></inline-formula>, average evoked firing rate <inline-formula><mml:math id="inf169"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mn>20</mml:mn><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mo>/</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> sp/s, ongoing activity <inline-formula><mml:math id="inf170"><mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> sp/s, and threshold factor <inline-formula><mml:math id="inf171"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84531-fig4-v2.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Scaling of minimal decoding time with stimulus dimensionality and tuning width.</title><p>(<bold>a</bold>) The predicted minimal decoding time from <inline-formula><mml:math id="inf172"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> scaled by <inline-formula><mml:math id="inf173"><mml:mfrac><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:math></inline-formula> provides a reasonable prediction of the minimal decoding time for <inline-formula><mml:math id="inf174"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>. The data used is the same as in <xref ref-type="fig" rid="fig4">Figure 4c</xref> (solid lines with circles, color code the same as in the main figure). (<bold>b–d</bold>) Minimal decoding times for various width parameters <inline-formula><mml:math id="inf175"><mml:mi>w</mml:mi></mml:math></inline-formula>. As in <xref ref-type="fig" rid="fig4">Figure 4c</xref>, there is a trend of increasing minimal decoding time with decreasing scale factor <inline-formula><mml:math id="inf176"><mml:mi>c</mml:mi></mml:math></inline-formula>. However, the range of minimal decoding times decreases with decreasing widths (for <inline-formula><mml:math id="inf177"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84531-fig4-figsupp1-v2.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Minimal decoding times using a different threshold factor.</title><p>Same as <xref ref-type="fig" rid="fig4">Figure 4a–d</xref> in the main text, but simulated using threshold factor. For each <inline-formula><mml:math id="inf178"><mml:mi>T</mml:mi></mml:math></inline-formula>, the MSE is evaluated based on 15,000 random stimulus samples.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84531-fig4-figsupp2-v2.tif"/></fig><fig id="fig4s3" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 3.</label><caption><title>Minimal decoding times based on one-sided KS-tests.</title><p>Same as <xref ref-type="fig" rid="fig4">Figure 4a–d</xref> in the main text, but simulated using the one-sided KS-test for determining minimal decoding time (see main text for details). For each <inline-formula><mml:math id="inf179"><mml:mi>T</mml:mi></mml:math></inline-formula>, the MSE is evaluated based on 15,000 random stimulus samples.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84531-fig4-figsupp3-v2.tif"/></fig><fig id="fig4s4" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 4.</label><caption><title>Time evolution of MSE and outlier errors.</title><p>(<bold>a</bold>) Time evolution of the RMSE (non-transparent lines) for periodic and single-peaked populations and the lower bound set by the Cramér-Rao bound (transparent lines) when decoding a <inline-formula><mml:math id="inf180"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> stimulus. (<bold>b</bold>) Same as in (<bold>a</bold>) but for the 99.8<sup>th</sup> (non-transparent lines) and the 100<sup>th</sup> (transparent lines) percentiles of the root squared error distributions. (<bold>c–d</bold>) same as (<bold>a-b</bold>) but for a <inline-formula><mml:math id="inf181"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> stimulus. For each decoding time <inline-formula><mml:math id="inf182"><mml:mi>T</mml:mi></mml:math></inline-formula>, the RMSE and outliers are evaluated based on 15,000 random stimulus samples.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84531-fig4-figsupp4-v2.tif"/></fig><fig id="fig4s5" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 5.</label><caption><title>Spike counts required for removing catastrophic errors.</title><p>Plot of the mean spike counts (summed over the population) required to remove catastrophic errors for the populations in <xref ref-type="fig" rid="fig4">Figure 4</xref>. Each circle indicates the minimal spike count for a single population with a constant scale factor encoding either a one-dimensional (x-axis) or a two-dimensional stimulus (y-axis). Blue circles indicate <inline-formula><mml:math id="inf183"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and red circles <inline-formula><mml:math id="inf184"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>. Being on the grey line corresponds to having the same required spike count for both stimulus cases.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84531-fig4-figsupp5-v2.tif"/></fig><fig id="fig4s6" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 6.</label><caption><title>Minimal decoding times for populations without scale factors.</title><p>Same as <xref ref-type="fig" rid="fig4">Figure 4c, e and f</xref>, but only using tuning curves with an integer number of peaks, that is, being all integers. Thus, there is no common scale factor relating the spatial frequencies of the modules within a population. The populations here have <inline-formula><mml:math id="inf185"><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>λ</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf186"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf187"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf188"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf189"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf190"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf191"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>, or <inline-formula><mml:math id="inf192"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>4</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula>. Note that for the single-peaked population, <inline-formula><mml:math id="inf193"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msup><mml:mover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>a</bold>) Shows the RMSE (solid lines) and the outliers, 99.8th (filled circles) and 100th (open circles) percentiles, for a <inline-formula><mml:math id="inf194"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> stimulus. (<bold>b</bold>) Same as (<bold>a</bold>) but for a <inline-formula><mml:math id="inf195"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> stimulus. (<bold>c</bold>) Same as <xref ref-type="fig" rid="fig4">Figure 4c</xref> but for the integer peaked populations listed above (blue: <inline-formula><mml:math id="inf196"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, green: <inline-formula><mml:math id="inf197"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84531-fig4-figsupp6-v2.tif"/></fig></fig-group><p>From <xref ref-type="disp-formula" rid="equ9">Equation 9</xref>, we fitted two constants, <italic>K</italic><sub>1</sub> (regressor) and <italic>K</italic><sub>2</sub> (intercept), using least square regression across populations sharing the same largest period, <inline-formula><mml:math id="inf198"><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula>, and stimulus dimensionality, <inline-formula><mml:math id="inf199"><mml:mi>D</mml:mi></mml:math></inline-formula> (see <xref ref-type="disp-formula" rid="equ47">Equation 47</xref>). Within the simulated range of scale factors, the regressions provide reasonable fits for the populations with <inline-formula><mml:math id="inf200"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4">Figure 4c</xref>, coefficient of determination <inline-formula><mml:math id="inf201"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>≈</mml:mo><mml:mn>0.89</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf202"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>≈</mml:mo><mml:mn>0.90</mml:mn></mml:mrow></mml:math></inline-formula> for <inline-formula><mml:math id="inf203"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf204"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>, respectively). For the populations with <inline-formula><mml:math id="inf205"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, <xref ref-type="disp-formula" rid="equ9">Equation 9</xref> becomes increasingly unable to predict the behavior of the minimal decoding time as <inline-formula><mml:math id="inf206"><mml:mi>c</mml:mi></mml:math></inline-formula> approaches 1 (see the red and yellow lines in <xref ref-type="fig" rid="fig4">Figure 4c–d</xref>). On the other hand, as was suggested above, the scaling of the minimal decoding time with <inline-formula><mml:math id="inf207"><mml:mi>c</mml:mi></mml:math></inline-formula> is, in fact, similar for <inline-formula><mml:math id="inf208"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf209"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> whenever <inline-formula><mml:math id="inf210"><mml:mi>c</mml:mi></mml:math></inline-formula> is less than <inline-formula><mml:math id="inf211"><mml:mrow><mml:mi/><mml:mo>≈</mml:mo><mml:mn>0.9</mml:mn></mml:mrow></mml:math></inline-formula>. As suggested by <xref ref-type="fig" rid="fig4">Figure 4d</xref>, there is also a strong correlation between Fisher information and minimal decoding time, again indicating a speed-accuracy trade-off. Furthermore, similar results are obtained when either decreasing the threshold factor to <inline-formula><mml:math id="inf212"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1.2</mml:mn></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>) or changing the minimal decoding time criterion to a one-sided Kolmogorov–Smirnov test (KS-test) between the empirical distribution of errors and the Gaussian error distribution predicted by the Cramér-Rao bound (<xref ref-type="fig" rid="fig4s3">Figure 4—figure supplement 3</xref>, using an ad-hoc Bonferroni-type correction for multiple sequential testing, <inline-formula><mml:math id="inf213"><mml:mrow><mml:mi>α</mml:mi><mml:mo>/</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf214"><mml:mi>j</mml:mi></mml:math></inline-formula> is the <inline-formula><mml:math id="inf215"><mml:mi>j</mml:mi></mml:math></inline-formula> th time comparison and <inline-formula><mml:math id="inf216"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>0.05</mml:mn></mml:mrow></mml:math></inline-formula> is the significance level.)</p><p>To further illustrate the relationship between minimum decoding time and the distribution of catastrophic errors, we re-simulated the same populations using fixed decoding times, evaluating the RMSE together with the 99.8th and 100th (maximal error) percentiles of the root squared error distributions across 15,000 new uniformly sampled stimuli (<xref ref-type="fig" rid="fig4">Figure 4e–f</xref>). As suggested by the minimal decoding times, there is a clear trade-off between minimizing RMSE over longer decoding times and removing outliers, especially the maximal error, over shorter decoding times. <xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref> shows the time evolution for a few of these populations.</p><p>Additionally, to verify that the minimal decoding times are good predictors of the decoding time necessary to suppress large estimation errors, we compared the same error percentiles as in <xref ref-type="fig" rid="fig4">Figure 4e–f</xref> (i.e. the 99.8th and 100th percentiles) against the minimal decoding times, <inline-formula><mml:math id="inf217"><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, estimated in <xref ref-type="fig" rid="fig4">Figure 4c</xref>. For each population, we expect a strong reduction in the magnitude of the largest errors when the decoding time, <inline-formula><mml:math id="inf218"><mml:mi>T</mml:mi></mml:math></inline-formula>, is larger than the minimal decoding time, <inline-formula><mml:math id="inf219"><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>. <xref ref-type="fig" rid="fig5">Figure 5</xref> shows a clear difference in large estimation errors between populations for which <inline-formula><mml:math id="inf220"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> and populations with <inline-formula><mml:math id="inf221"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (circles to the left and right of the magenta lines in <xref ref-type="fig" rid="fig5">Figure 5</xref>, respectively). Thus, although only using the difference between MSE and Fisher information, our criterion on minimal decoding time still carries important information about the presence of large estimation errors.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Minimal decoding time predicts the removal of large estimation errors.</title><p>(<bold>a</bold>) The 99.8th percentile (filled circles) and the maximal error (i.e., 100th percentile, open circles) of the root squared error distributions for <inline-formula><mml:math id="inf222"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> against the estimated minimal decoding time for the corresponding populations (<inline-formula><mml:math id="inf223"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>) for various choices of decoding time, <inline-formula><mml:math id="inf224"><mml:mi>T</mml:mi></mml:math></inline-formula> (indicted by the vertical magenta lines). (<bold>b</bold>) same as (<bold>a</bold>) but for <inline-formula><mml:math id="inf225"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>. (<bold>c</bold>-<bold>d</bold>) Same as for (<bold>a-b</bold>) but for <inline-formula><mml:math id="inf226"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1.2</mml:mn></mml:mrow></mml:math></inline-formula>. Note that the plots (<bold>a</bold>) and (<bold>c</bold>), or (<bold>b</bold>) and (<bold>d</bold>), illustrate the same percentile data only remapped on the x-axis by the different minimal decoding times from the different threshold factors <inline-formula><mml:math id="inf227"><mml:mi>α</mml:mi></mml:math></inline-formula>. Color code: same as in <xref ref-type="fig" rid="fig4">Figure 4</xref>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84531-fig5-v2.tif"/></fig><p>To summarize, while periodic tuning curves provide lower estimation errors for long decoding times by minimizing local errors (<xref ref-type="fig" rid="fig4">Figure 4c</xref>, inset), a population of single-peaked tuning curves is faster at producing a statistically reliable signal by removing catastrophic errors (<xref ref-type="disp-formula" rid="equ9">Equation 9</xref> and <xref ref-type="fig" rid="fig4">Figure 4c</xref>). Generalizing minimal decoding times to an arbitrary number of stimulus dimensions reveals that the minimal decoding time also depends on the stimulus dimensionality (<xref ref-type="fig" rid="fig4">Figure 4c</xref>, compare lines for <inline-formula><mml:math id="inf228"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf229"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>). Interestingly, however, the approximation predicts that although minimal decoding time grows with increasing stimulus dimensionality, the minimal required spike count might be independent of stimulus dimensionality, at least for populations with integer spatial frequencies, that is, integer number of peaks (see <xref ref-type="disp-formula" rid="equ95">Equation A5.4</xref>). The populations simulated here have non-integer spatial frequencies. However, the trend of changes in the mean spike count is still just slightly below 1 (indicating that slightly fewer spikes across the population are needed with increasing <inline-formula><mml:math id="inf230"><mml:mi>D</mml:mi></mml:math></inline-formula>, see <xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5</xref>). Thus, as the average firing rate decreases with the number of encoded features <inline-formula><mml:math id="inf231"><mml:mi>D</mml:mi></mml:math></inline-formula> (<xref ref-type="fig" rid="fig4">Figure 4b</xref>, right column), the increase in minimal decoding time for stimuli of higher dimensionality can be primarily explained by requiring a longer time to accumulate the sufficient number of spikes across the population. Lastly, to rule out that the differences in minimal decoding time cannot be explained by the periodicity of the tuning curves not aligning to that of the stimulus, we also simulated populations with different combinations of integer peaks (<xref ref-type="fig" rid="fig4s6">Figure 4—figure supplement 6</xref>). Again, the same phenomenon is observed: periodic tuning curves increase the required decoding time to remove catastrophic errors. This also highlights that the approximation of minimal decoding time does not require the spatial periods to be related by a scale factor, <inline-formula><mml:math id="inf232"><mml:mi>c</mml:mi></mml:math></inline-formula>.</p></sec><sec id="s2-6"><title>Effect of ongoing activity</title><p>Many cortical areas exhibit ongoing activity, that is, activity that is not stimulus-specific (<xref ref-type="bibr" rid="bib40">Snodderly and Gur, 1995</xref>; <xref ref-type="bibr" rid="bib4">Barth and Poulet, 2012</xref>). Thus, it is important to understand the impact of ongoing activity on the minimal decoding time, too. Unfortunately, because our approximation of the minimal decoding times did not include ongoing activity, we relied on simulations to study the effect of such non-specific activity.</p><p>When including independent ongoing (background) activity at 2 spikes/s to all neurons for the same populations as in <xref ref-type="fig" rid="fig4">Figure 4</xref>, minimal decoding times were elevated across all populations (<xref ref-type="fig" rid="fig6">Figure 6</xref>). Furthermore, the minimal decoding time increased faster with decreasing <inline-formula><mml:math id="inf233"><mml:mi>c</mml:mi></mml:math></inline-formula> in the presence of ongoing activity compared to the case without ongoing activity (ratios of fitted regressors <inline-formula><mml:math id="inf234"><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>/</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> using <xref ref-type="disp-formula" rid="equ47">Equation 47</xref> were approximately 1.69 and 1.72 for <inline-formula><mml:math id="inf235"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf236"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>, respectively). Similar results are found using <inline-formula><mml:math id="inf237"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1.2</mml:mn></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>) or the alternative criterion on minimal decoding time based on one-sided KS-tests described earlier (<xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>). Thus, ongoing activity can have a substantial impact on the time required to produce reliable signals. <xref ref-type="fig" rid="fig6">Figure 6</xref> suggests that areas with ongoing activity are less suited for periodic tuning curves. Especially, the combination of multidimensional stimuli and ongoing activity leads to much longer minimal decoding times for tuning curves with small spatial periods (<inline-formula><mml:math id="inf238"><mml:mrow><mml:mi>c</mml:mi><mml:mo>≪</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>). For example, when encoding a two-dimensional stimulus, only the populations with <inline-formula><mml:math id="inf239"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf240"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf241"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf242"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mn>0.95</mml:mn></mml:mrow></mml:math></inline-formula> could remove catastrophic errors in less than 40ms when ongoing activity at 2 sp/s was present. Thus, the ability to produce reliable signals at high speeds severely deteriorates for periodic tuning curves in the presence of non-specific ongoing activity.</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Ongoing activity increases minimal decoding time.</title><p>(<bold>a</bold>) The case of encoding a one-dimensional stimulus (<inline-formula><mml:math id="inf243"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>) with or without ongoing activity at 2 sp/s (diamond and circle shapes, respectively). (<bold>b</bold>) The case of a two-dimensional stimulus (<inline-formula><mml:math id="inf244"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>) under the same conditions as for (<bold>a</bold>). In both conditions, ongoing activity increases the time required for all populations to produce reliable signals, but the effect is strongest for <inline-formula><mml:math id="inf245"><mml:mrow><mml:mi>c</mml:mi><mml:mo>≪</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>. The parameters used in the simulations are: population size <inline-formula><mml:math id="inf246"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>600</mml:mn></mml:mrow></mml:math></inline-formula>, number of modules <inline-formula><mml:math id="inf247"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>, scale factors <inline-formula><mml:math id="inf248"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>0.3</mml:mn><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>, width parameter <inline-formula><mml:math id="inf249"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mn>0.3</mml:mn></mml:mrow></mml:math></inline-formula>, average evoked firing rate <inline-formula><mml:math id="inf250"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mn>20</mml:mn><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mo>/</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> sp/s, ongoing activity <inline-formula><mml:math id="inf251"><mml:mrow><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> sp/s, and threshold factor <inline-formula><mml:math id="inf252"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84531-fig6-v2.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Minimal decoding times using a different threshold factor.</title><p>Same as <xref ref-type="fig" rid="fig6">Figure 6</xref> in the main text, but using <inline-formula><mml:math id="inf253"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1.2</mml:mn></mml:mrow></mml:math></inline-formula>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84531-fig6-figsupp1-v2.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 2.</label><caption><title>Minimal decoding times based on one-sided KS-test.</title><p>Same as <xref ref-type="fig" rid="fig6">Figure 6</xref> in the main text, but using the one-sided KS-test criterion described before (see <xref ref-type="fig" rid="fig4s4">Figure 4—figure supplement 4</xref>).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84531-fig6-figsupp2-v2.tif"/></fig></fig-group><p>This result has an intuitive explanation. The amount of catastrophic errors depends on the probability that the trial variability reshapes the neural activity to resemble the possible activities for a distinct stimulus condition (see <xref ref-type="fig" rid="fig1">Figure 1a</xref>). From the analysis presented above, periodic tuning curves have been suggested to be more susceptible to such errors. Adding ongoing activity does not reshape the stimulus-evoked parts of the tuning curves but only increases the trial-by-trial variability. Thus, by this reasoning, it is not surprising that the systems which are already more susceptible also are even more negatively affected by the increased variability induced by ongoing activity. The importance of <xref ref-type="fig" rid="fig6">Figure 6</xref> is that even ongoing activity as low as 2 sp/s can have a clearly visible effect on minimal decoding time.</p></sec><sec id="s2-7"><title>Implications for a simple spiking neural network with sub-optimal readout</title><p>Until this point, the arguments about minimal decoding time have relied on rate-based tuning curves encoding static stimuli. To extend beyond static stimuli and to exemplify the role of decoding time for spiking neurons, we simulated simple two-layer feed-forward spiking neural networks to decode time-varying stimulus signals. The first layer (<inline-formula><mml:math id="inf254"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>500</mml:mn></mml:mrow></mml:math></inline-formula>) corresponds to the tuning curves (without connections between the simulated neurons). The stimulus-specific tuning of the Poissonian inputs to these neurons is either fully single-peaked, creating a population of single-peaked tuning curves, or periodic with different spatial periods, creating a population of periodic tuning curves (<xref ref-type="fig" rid="fig7">Figure 7a</xref>, see Materials and methods for details). The second layer instead acts as a readout layer (<inline-formula><mml:math id="inf255"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>400</mml:mn></mml:mrow></mml:math></inline-formula>, allowing a weak convergence of inputs from the first layer). This layer receives both stimulus-specific excitatory input from the first layer and external non-specific Poissonian excitation (corresponding to background activity). The connection strength between the first and second layers depends on the difference in preferred stimulus conditions between the pre- and post-synaptic neurons. Such connectivity could, for example, be obtained by unsupervised Hebbian learning. Because the tuning curves in the first layer can be periodic, they can also connect strongly to several readout neurons. We introduced lateral inhibition among the readout neurons (without explicitly modeling inhibitory neurons) to create a winner-take-all style of dynamics. The readout neurons with large differences in preferred stimulus inhibit each other more strongly. Decoding is assumed to be instantaneous and based on the preferred stimulus condition of the spiking neuron in the readout layer. However, to compare the readouts, we averaged the stimulus estimates in sliding windows.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Implications for a simple spiking neural network with suboptimal readout.</title><p>(<bold>a</bold>) Illustration of the spiking neural networks (SNNs). (<bold>b</bold>) Example of single trials. Top row: Two example trials for step-like change in stimulus (green line). The left and right plots show the readout activity for the single-peaked (blue) and periodic SSNs (orange), respectively. Note that the variance around true stimulus is larger for the single-peaked SNN (i.e. larger local errors) but that there are fewer very large errors than for the periodic SNN. Bottom row: Same as for the top row but with a continuously time-varying stimulus. (<bold>c</bold>) Bottom: The median RMSE (thick lines) over all trials in a sliding window (length 50ms) for the single-peaked (blue) and periodic (orange) SNNs. The shadings correspond to the regions between the 5th and 95th percentiles. Top: The instantaneous population firing rates of the readout layers and the standard deviations (same color code as in the bottom panel). (<bold>d</bold>) Bottom left: The median estimated stimulus across trials in a sliding window (length 10ms) for the single-peaked (blue) and periodic (orange) SNNs. Shaded areas again correspond to the regions between the 5th and 95th percentiles. The true stimulus is shown in green. Bottom right: the average firing rate of each neuron, arranged according to the preferred stimulus condition. Top: The instantaneous population firing rates of the readout layers and the standard deviations. See Materials and methods for simulation details and <xref ref-type="table" rid="table1">Table 1</xref>, <xref ref-type="table" rid="table2">Table 2</xref>, <xref ref-type="table" rid="table3">Table 3</xref> for all parameters used in the simulation.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84531-fig7-v2.tif"/></fig><p>We tested two different types of time-varying stimuli: (1) a step-like change from <inline-formula><mml:math id="inf256"><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf257"><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>0.75</mml:mn></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="fig7">Figure 7b</xref> top row, green trace) and (2) a continuously time-varying stimulus drawn from an Ornstein–Uhlenbeck process (<xref ref-type="fig" rid="fig7">Figure 7b</xref> bottom row, green trace; see Materials and methods). In the case of a step-like stimulus change, the readout layer for the single-peaked population required a shorter time to switch states than the periodic network (<xref ref-type="fig" rid="fig7">Figure 7c</xref>). The shorter switching time is consistent with the hypothesis that single-peaked tuning curves have shorter minimal decoding times than periodic tuning curves. In these simulations, the difference is mainly due to some neurons in the first layer of the periodic network responding both before and after the step change. Thus, the correct readout neurons (after the change) must compensate for the hyper-polarization built up before the change and the continuing inhibitory input from the previously correct readout neurons (which still get excitatory inputs). Note that there are only minor differences in the population firing rates between the readout layers, confirming that this is not a consequence of different excitation levels but rather of the structures of excitation.</p><p>The continuously time-varying stimulus could be tracked well by both networks. However, averaging across trials shows that SNNs with periodic tuning curves have larger sporadic fluctuations (<xref ref-type="fig" rid="fig7">Figure 7d</xref>). This suggests that decoding with periodic tuning curves has difficulties in accurately estimating the stimulus without causing sudden, brief periods of large errors. To make a statistical comparison between the populations, we investigated the distributions of root mean squared error (RMSE) across trials. In both stimulus cases, there is a clear difference between the network with single-peaked tuning curves and the network with periodic ones. For the step-like change in stimulus condition, a significant difference in RMSE arises roughly 100 ms after the stimulus change (<xref ref-type="fig" rid="fig8">Figure 8a</xref>). For the time-varying stimulus, using single-peaked tuning curves also results in significantly lower RMSE compared to a population of periodic tuning curves (<xref ref-type="fig" rid="fig8">Figure 8b</xref>, RMSE calculated across the entire trial).</p><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Statistical comparison of the SNN models.</title><p>(<bold>a</bold>) Step-like change: Comparison between the distributions of accumulated RMSEs at different decoding times (<inline-formula><mml:math id="inf258"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>0.4</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf259"><mml:mrow><mml:mn>9.0</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf260"><mml:mrow><mml:mn>8.7</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, respectively). (<bold>b</bold>) OU-stimulus: The distributions of RMSE across trials for the two SNNs (<inline-formula><mml:math id="inf261"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>4.3</mml:mn><mml:mo>⋅</mml:mo><mml:msup><mml:mn>10</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>8</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>). All statistical comparisons in (<bold>a</bold>) and (<bold>b</bold>) were based on two-sample Kolmogorov–Smirnov (KS) tests using 30 trials per network.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84531-fig8-v2.tif"/></fig></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Several studies have suggested that periodic tuning creates an unparalleled precise neural code by minimizing local errors (<xref ref-type="bibr" rid="bib41">Sreenivasan and Fiete, 2011</xref>; <xref ref-type="bibr" rid="bib27">Mathis et al., 2012</xref>; <xref ref-type="bibr" rid="bib46">Wei et al., 2015</xref>; <xref ref-type="bibr" rid="bib26">Malerba et al., 2022</xref>). Nevertheless, despite this advantage of periodic tuning, single-peaked tuning curves are widespread in early sensory areas and especially in the early visual system. There is a long history of studying information representation using rate-based tuning curves. Still, the effect of spatial periodicity and catastrophic errors on the required decoding time has not been addressed. Here, we showed that the possibility of catastrophic estimation errors (<xref ref-type="fig" rid="fig1">Figure 1a</xref>) introduces the possibility that different shapes of tuning curves can have different minimal decoding times.</p><p>The emerging question is whether there is a trade-off between the accuracy of a neural code and the minimal required decoding time for single-peaked and periodic tuning. The answer is yes. We found that minimal decoding time increased with decreasing spatial periods of the tuning curves (<xref ref-type="fig" rid="fig4">Figure 4c</xref>), suggesting a trade-off between accuracy and speed for populations of tuning curves. The differences in minimal decoding time cannot be explained by the periodicity of the tuning curves not aligning to the stimulus domain, as the same holds comparing populations with integer number of peaks (<xref ref-type="fig" rid="fig4s6">Figure 4—figure supplement 6</xref>). Furthermore, our results remained unchanged when we discarded any decoded stimuli which needed the <inline-formula><mml:math id="inf262"><mml:mrow><mml:mpadded width="+2.8pt"><mml:mtext>mod</mml:mtext></mml:mpadded><mml:mo>⁢</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> operation to lie within the stimulus domain <inline-formula><mml:math id="inf263"><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>D</mml:mi></mml:msup></mml:math></inline-formula>, thus ruling out any possible distortion effect of the periodic stimulus and decoding approach. In addition, we show that our results are valid for a range of population sizes (<xref ref-type="fig" rid="fig9">Figure 9a-b</xref>), ongoing (<xref ref-type="fig" rid="fig9">Figure 9a-b</xref>) and evoked activities (<xref ref-type="fig" rid="fig9">Figure 9c</xref>), and stimulus dimensions (<xref ref-type="fig" rid="fig9">Figure 9d</xref>). We used the more conservative threshold factor on MSE, <inline-formula><mml:math id="inf264"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1.2</mml:mn></mml:mrow></mml:math></inline-formula>, to capture all the nuances w.r.t. the level of ongoing activity even for large population sizes. In simulated networks with spiking neurons, we showed that the use of periodic tuning curves increased the chances of large estimation errors, leading to longer times before switching ‘states’ (<xref ref-type="fig" rid="fig7">Figure 7c</xref>) and difficulties tracking a time-varying, one-dimensional stimulus (<xref ref-type="fig" rid="fig7">Figure 7d</xref>).</p><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>Minimal decoding time for various tuning and stimulus parameters.</title><p>(<bold>a-b</bold>) Minimal decoding time for different combinations of population sizes (<inline-formula><mml:math id="inf265"><mml:mi>N</mml:mi></mml:math></inline-formula>) and levels of ongoing background activity (<inline-formula><mml:math id="inf266"><mml:mi>b</mml:mi></mml:math></inline-formula>) for the single-peaked population (<bold>a</bold>) and the periodic population (<bold>b</bold>). (<bold>c</bold>) Minimal decoding time as a function of average stimulus-evoked firing rate (x-axis re-scaled to the corresponding peak amplitude, <inline-formula><mml:math id="inf267"><mml:mi>a</mml:mi></mml:math></inline-formula>, for single-peaked tuning curves for easier interpretation). The corresponding amplitudes are <inline-formula><mml:math id="inf268"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mn>8</mml:mn><mml:mo>,</mml:mo><mml:mn>16</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf269"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>32</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> sp/s, respectively. (<bold>d</bold>) Minimal decoding time as a function of stimulus dimensionality. Unless indicated on the axes, the parameters are set according to the orange circles and rectangles in (<bold>a-d</bold>). Auxiliary parameters: number of modules <inline-formula><mml:math id="inf270"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>, width parameter <inline-formula><mml:math id="inf271"><mml:mrow><mml:mi>w</mml:mi><mml:mo>=</mml:mo><mml:mn>0.3</mml:mn></mml:mrow></mml:math></inline-formula>, and threshold factor <inline-formula><mml:math id="inf272"><mml:mrow><mml:mi>α</mml:mi><mml:mo>=</mml:mo><mml:mn>1.2</mml:mn></mml:mrow></mml:math></inline-formula>.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-84531-fig9-v2.tif"/></fig><p>Experimental data suggest that decoding times can be very short, of the order of tens of milliseconds, reflecting that a considerable part of the information contained in firing rates over long periods is also present in short sample periods (<xref ref-type="bibr" rid="bib45">Tovée et al., 1993</xref>). Additionally, the first few spikes have been shown to carry significant amounts of task information in both visual (<xref ref-type="bibr" rid="bib33">Resulaj et al., 2018</xref>), olfactory (<xref ref-type="bibr" rid="bib32">Resulaj and Rinberg, 2015</xref>), and somatosensory areas (<xref ref-type="bibr" rid="bib30">Panzeri et al., 2001</xref>; <xref ref-type="bibr" rid="bib31">Petersen et al., 2001</xref>). As the tuning curves in this study all have equal average firing rates, we can reinterpret the minimal decoding time in terms of the prominence of the first spikes. In our simulations, tens of spikes carry enough information to produce a reliable stimulus estimate free of catastrophic errors (<xref ref-type="fig" rid="fig4s5">Figure 4—figure supplement 5</xref>). As with decoding time, single-peaked tuning curves also need fewer spikes to produce reliable signals. Thus, the speed-accuracy trade-off can be reinterpreted as a trade-off between being accurate and efficient.</p><p>The notion of a speed-accuracy trade-off is further strengthened when considering high-dimensional stimuli that demand longer minimal decoding times. Natural stimuli typically have higher dimensionality than those used in animal experiments. Many sensory neurons are tuned to multiple features of the external stimulus, creating mixed selectivity of features (e.g. <xref ref-type="bibr" rid="bib16">Garg et al., 2019</xref>). For neurons responding to task-related variables, mixed selectivity has been shown to enable linear separability and to improve discriminability (<xref ref-type="bibr" rid="bib34">Rigotti et al., 2013</xref>; <xref ref-type="bibr" rid="bib15">Fusi et al., 2016</xref>; <xref ref-type="bibr" rid="bib20">Johnston et al., 2020</xref>). For continuous stimulus estimations, mixed selectivity has also been proposed to decrease MSE when decoding time is limited (<xref ref-type="bibr" rid="bib13">Finkelstein et al., 2018</xref>). However, to remove catastrophic errors, which, as we have argued, is not necessarily synonymous with lower MSE, the exponential increase in minimal decoding time could easily lead to very long decoding times. Thus, minimal decoding time should set a bound on the number of features a population can jointly encode reliably. In addition, neurons in sensory areas often exhibit a degree of non-specific activity (<xref ref-type="bibr" rid="bib40">Snodderly and Gur, 1995</xref>; <xref ref-type="bibr" rid="bib4">Barth and Poulet, 2012</xref>). Introducing ongoing activity to the populations in our simulations further amplified the differences in minimal decoding times (<xref ref-type="fig" rid="fig6">Figure 6</xref>). Thus, for jointly encoded stimuli, especially in areas with high degrees of ongoing activity, a population of single-peaked tuning curves might be the optimal encoding strategy for rapid and reliable communication.</p><p>We note that these results might extend beyond the visual areas, too. Although this study focused on tuning curves encoding continuous variables, catastrophic errors can also occur in systems with discrete tuning curves. Sensory stimuli can be fast-varying (or even discontinuous), and large errors can potentially harm the animal. Therefore, constraints on decoding time are likely important for any early sensory area. In addition, hippocampal place cells involved in spatial navigation (<xref ref-type="bibr" rid="bib29">O’Keefe and Dostrovsky, 1971</xref>; <xref ref-type="bibr" rid="bib47">Wilson and McNaughton, 1993</xref>) are known for their single-peaked tuning. The interesting observation in this context is that place cells produce reliable signals faster than their input signals from the medial entorhinal cortex with a combination of single- and multi-peaked tuning (<xref ref-type="bibr" rid="bib8">Cholvin et al., 2021</xref>). On the other hand, for sufficiently slow-varying stimuli, a periodic population can be used together with error correction to remove catastrophic errors (<xref ref-type="bibr" rid="bib41">Sreenivasan and Fiete, 2011</xref>). Furthermore, for non-periodic stimuli with large domains, the combinatorial nature of periodic tuning curves can create unique stimulus representations far exceeding the spatial periods of the tuning curves (<xref ref-type="bibr" rid="bib12">Fiete et al., 2008</xref>). Thus, periodic tuning curves are ideal for representing space, where the stimulus domain can be vast, and the change in position is constrained by the speed of movement. Interestingly, when faced with very large arenas, place cells can also exhibit multi-peaked tuning (<xref ref-type="bibr" rid="bib10">Eliav et al., 2021</xref>).</p><p>To summarize, we provide normative arguments for the single-peaked tuning of early visual areas. Rapid decoding of stimulus is crucial for the survival of the animals. Consistent with this, animals and humans can process sensory information at impressive speeds. For example, the human brain can generate differentiating event-related potentials to go/no-go categorization tasks using novel complex visual stimuli in as little as 150 ms (<xref ref-type="bibr" rid="bib44">Thorpe et al., 1996</xref>). These ‘decoding’ times do not decrease for highly familiar objects, suggesting that the speed of visual processing cannot be reduced by learning (<xref ref-type="bibr" rid="bib11">Fabre-Thorpe et al., 2001</xref>). Given constraints on low latency communication, it is crucial that each population can quickly produce a reliable signal. In this regard, single-peaked tuning curves are superior to periodic ones. The fact that early visual areas exhibit ongoing activity and encode multi-dimensional stimuli further strengthens the relevance of the differences in minimal decoding time.</p><p>To conclude, our work highlights that minimum decoding time is an important attribute and should be considered while evaluating candidate neural codes. Our analysis suggests that decoding of high-dimensional stimuli can be prohibitively slow with rate-based tuning curves. Experimental data on the representation of high-dimensional stimuli is rather scant as relatively low-dimensional stimuli are typically used in experiments (e.g. oriented bars). Our work gives a compelling reason to understand whether and how biological brains can reliably encode high-dimensional stimuli at behaviorally relevant time scales.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Minimal decoding times - simulation protocols</title><p>To study the dependence of decoding time <inline-formula><mml:math id="inf273"><mml:mi>T</mml:mi></mml:math></inline-formula> on MSE for populations with different distributions of spatial frequencies, we simulated populations of synthetic tuning curves (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>). The stimulus was circular with a <inline-formula><mml:math id="inf274"><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>D</mml:mi></mml:msup></mml:math></inline-formula> range. The preferred stimulus conditions <inline-formula><mml:math id="inf275"><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula> were sampled independently from a random uniform distribution over <inline-formula><mml:math id="inf276"><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>D</mml:mi></mml:msup></mml:math></inline-formula> (independently and uniformly for each stimulus dimension). To ensure equal comparison, the preferred locations <inline-formula><mml:math id="inf277"><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:math></inline-formula> were shared across all populations. Each neuron’s amplitude, <italic>a</italic><sub><italic>i</italic></sub>, was tuned according to <xref ref-type="disp-formula" rid="equ1">Equation A1.5</xref> to ensure an equal average firing rate across the stimulus domain for all neurons. In each trial, a stimulus <inline-formula><mml:math id="inf278"><mml:mrow><mml:mi mathvariant="bold">s</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>D</mml:mi></mml:msup></mml:mrow></mml:math></inline-formula> was also independently sampled from a uniform distribution over <inline-formula><mml:math id="inf279"><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>D</mml:mi></mml:msup></mml:math></inline-formula>. The spike count for each neuron was then sampled according to <xref ref-type="disp-formula" rid="equ3">Equation 3</xref>.</p><p>Minimal decoding time was defined as the shortest time for which the neural population approximately reaches the Cramér-Rao bound. To estimate the reaction time in simulations, we incrementally increased the decoding time <inline-formula><mml:math id="inf280"><mml:mi>T</mml:mi></mml:math></inline-formula> (using 1 ms increments, starting at <inline-formula><mml:math id="inf281"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> ms) until<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:mover><mml:mrow><mml:mi>M</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mi>λ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>≤</mml:mo><mml:mi>α</mml:mi><mml:mo>⋅</mml:mo><mml:mover><mml:mrow><mml:mtext>diag</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>J</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mi>λ</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>As the ML estimator is asymptotically efficient (attaining the Cramér-Rao bound in the limit of infinite data), the threshold factor, <inline-formula><mml:math id="inf282"><mml:mi>α</mml:mi></mml:math></inline-formula>, in <xref ref-type="disp-formula" rid="equ1">Equation 10</xref> was added as a relaxation (see figure captions for choices of <inline-formula><mml:math id="inf283"><mml:mi>α</mml:mi></mml:math></inline-formula>). Note that the mean bars on the left- and right-hand sides of <xref ref-type="disp-formula" rid="equ1">Equation 10</xref> refer to the means across stimulus dimensions (for multi-dimensional stimuli) and that <inline-formula><mml:math id="inf284"><mml:mrow><mml:mtext>diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> refers to taking the diagonal elements from the inverse of the Fisher information matrix, <inline-formula><mml:math id="inf285"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>J</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mi>λ</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. For a given decoding time <inline-formula><mml:math id="inf286"><mml:mi>T</mml:mi></mml:math></inline-formula>, the estimation of MSE was done by repeatedly sampling random stimulus conditions (from a uniform distribution), sampling a noisy response to the stimulus (Poisson distributed spike counts), and then applying maximum likelihood estimation (see next section ’Implementation of maximum likelihood estimator’ for details on implementation). In <xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig9">9</xref>, 15000 stimulus conditions were drawn for each <inline-formula><mml:math id="inf287"><mml:mi>T</mml:mi></mml:math></inline-formula>, and in <xref ref-type="fig" rid="fig4">Figure 4</xref>, stimulus conditions were repeatedly drawn until the two first non-zero digits of the MSE were stable for 1000 consecutive trials. However, in controls not presented here, we could not see any significant difference between these two sampling approaches. Because the Fisher information matrix <inline-formula><mml:math id="inf288"><mml:mi>J</mml:mi></mml:math></inline-formula> was analytically estimated only in the special case without ongoing activity, it was approximated in simulations by the element-wise average across 10,000 randomly sampled stimulus conditions (also uniformly distributed), where each element was calculated according to <xref ref-type="disp-formula" rid="equ66">Equation A2.12</xref>or <xref ref-type="disp-formula" rid="equ67">Equation A2.13</xref> given a random stimulus trial.</p></sec><sec id="s4-2"><title>Implementation of maximum likelihood estimator</title><p>Given some noisy neural responses, <inline-formula><mml:math id="inf289"><mml:mi mathvariant="bold">r</mml:mi></mml:math></inline-formula>, the maximum likelihood estimator (MLE) chooses the stimulus condition which maximizes the likelihood function, <inline-formula><mml:math id="inf290"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>arg</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>max</mml:mi></mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:msub><mml:mo>⁡</mml:mo><mml:mi class="ltx_font_mathcaligraphic">ℒ</mml:mi></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">r</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold">s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mpadded width="+1.7pt"><mml:mi>arg</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi>max</mml:mi></mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. A common approach is to instead search for the maximum of the log-likelihood function (the logarithm is a monotonic function and therefore preserves any maxima/minima). The stimulus-dependent terms of the log-likelihood can then be expressed as<disp-formula id="equ11"><label>(11)</label><mml:math id="m11"><mml:mrow><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>∝</mml:mo><mml:mrow><mml:mi mathvariant="script">V</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>;</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Unfortunately, the log-likelihood function is not guaranteed to be concave, and finding the stimulus condition <inline-formula><mml:math id="inf291"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> which maximizes the log-likelihood function is not trivial (a non-convex optimization problem). To overcome this difficulty, we combined grid-search with the Nelder–Mead method, an unconstrained non-linear program solver (implemented using MATLAB’s built-in function <italic>fminsearch</italic>, <ext-link ext-link-type="uri" xlink:href="https://www.mathworks.com/help/matlab/ref/fminsearch.html">https://www.mathworks.com/help/matlab/ref/fminsearch.html</ext-link>).</p><p>Grid search was used to find a small set of starting points with large log-likelihood values. To do so, we sampled 100 random stimulus conditions within the stimulus interval <inline-formula><mml:math id="inf292"><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>D</mml:mi></mml:msup></mml:math></inline-formula> and selected the four stimulus conditions with the largest log-likelihood values. The true stimulus condition, <inline-formula><mml:math id="inf293"><mml:msub><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, was always added to the set of starting points regardless of the log-likelihood value of that condition (yielding a total of 5 starting points).</p><p>Then the Nelder–Mead method was used with these starting points to find a set of 5 (possibly local) maxima. The stimulus was decoded as the stimulus, <inline-formula><mml:math id="inf294"><mml:mover accent="true"><mml:mi mathvariant="bold">s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula>, yielding the largest log-likelihood of the 5 maxima. As we always included the true stimulus condition in the Nelder-Mead search, this approach should not overestimate the amount of threshold distortion but can potentially miss some global estimation errors instead. Finally, as the Nelder–Mead method is unconstrained but the stimulus domain periodic, the output of the maximum likelihood decoder was transformed into the stimulus interval <inline-formula><mml:math id="inf295"><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>D</mml:mi></mml:msup></mml:math></inline-formula> by applying the mod 1 operation on each stimulus dimension,<disp-formula id="equ12"><label>(12)</label><mml:math id="m12"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mspace width="2.845276pt"/><mml:mo stretchy="false">(</mml:mo><mml:mtext>mod</mml:mtext><mml:mspace width="2.845276pt"/><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Given an estimated stimulus, <inline-formula><mml:math id="inf296"><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, the error was then evaluated along each stimulus dimension independently, taking into account the periodic boundary,<disp-formula id="equ13"><label>(13)</label><mml:math id="m13"><mml:mrow><mml:msubsup><mml:mi>ϵ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mtext>min</mml:mtext><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>for <inline-formula><mml:math id="inf297"><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</p><p>Lastly, to rule out that the estimates before the mod-operation, <inline-formula><mml:math id="inf298"><mml:mover accent="true"><mml:mi mathvariant="bold">s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula>, outside of the stimulus domain <inline-formula><mml:math id="inf299"><mml:msup><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mi>D</mml:mi></mml:msup></mml:math></inline-formula> did not influence the results, we also discarded these samples, but this produced similar results.</p></sec><sec id="s4-3"><title>Spiking network model</title><sec id="s4-3-1"><title>Stimuli</title><p>As in the previous simulations, we assumed that the stimulus domain was a circular stimulus defined between <inline-formula><mml:math id="inf300"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. We simulated the responses to two different types of stimuli, (1) a step-like change in stimulus condition from <inline-formula><mml:math id="inf301"><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>0.25</mml:mn></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf302"><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mn>0.75</mml:mn></mml:mrow></mml:math></inline-formula> and (2) a stimulus drawn from a modified Ornstein–Uhlenbeck process<disp-formula id="equ14"><label>(14)</label><mml:math id="m14"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>+</mml:mo><mml:msqrt><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:msqrt><mml:msub><mml:mi>ξ</mml:mi><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mspace width="1em"/><mml:mtext>(mod 1)</mml:mtext><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>For parameter values, see <xref ref-type="table" rid="table1">Table 1</xref>.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title>Parameters and parameter values for O-U stimulus.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameters</th><th align="left" valign="bottom">Parameter values</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf303"><mml:msub><mml:mi>τ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">0.5 (s)</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf304"><mml:msub><mml:mi>σ</mml:mi><mml:mi>s</mml:mi></mml:msub></mml:math></inline-formula></td><td align="char" char="." valign="bottom">0.1</td></tr></tbody></table></table-wrap></sec><sec id="s4-3-2"><title>Network model</title><p>The spiking networks were implemented as two-layer, feed-forward networks using LIF neurons with (Dirac) delta synapses. The dynamics of the membrane potential for the neurons in the first layer were described by<disp-formula id="equ15"><label>(15)</label><mml:math id="m15"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>+</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf305"><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is the voltage of neuron <inline-formula><mml:math id="inf306"><mml:mi>i</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf307"><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>⁢</mml:mo><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> the membrane time constant, <italic>t</italic><sub><italic>k</italic></sub> the timing of the <inline-formula><mml:math id="inf308"><mml:mi>k</mml:mi></mml:math></inline-formula> th input spike to neuron <inline-formula><mml:math id="inf309"><mml:mi>i</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf310"><mml:msub><mml:mi>J</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:math></inline-formula> the induced EPSP. The neurons in the first layer were constructed to correspond to either single-peaked or periodic tuning curves. Two networks were tested, one network where the first layer corresponds to single-peaked tuning curves and a second network corresponding to periodic tuning curves (with <inline-formula><mml:math id="inf311"><mml:mrow><mml:mi>L</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:math></inline-formula> modules). For each neuron <inline-formula><mml:math id="inf312"><mml:mi>i</mml:mi></mml:math></inline-formula> in module <inline-formula><mml:math id="inf313"><mml:mi>j</mml:mi></mml:math></inline-formula> in the first layer, the input was drawn from independent Poisson point processes with stimulus-dependent rates <inline-formula><mml:math id="inf314"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula><disp-formula id="equ16"><label>(16)</label><mml:math id="m16"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Here, the constants <inline-formula><mml:math id="inf315"><mml:mi>a</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf316"><mml:mi>b</mml:mi></mml:math></inline-formula> were chosen such that the baseline firing rate was slightly above zero and the maximal firing rate was slightly below 20 sp/s (see Table 3 for all network-related parameter values). Because of the choice of <inline-formula><mml:math id="inf317"><mml:msub><mml:mi>λ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula>, the modulation strengths of the inputs were such that the average input to each neuron was equal. For each module in the first layer, the preferred locations <inline-formula><mml:math id="inf318"><mml:msubsup><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> were equidistantly placed across <inline-formula><mml:math id="inf319"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>.</p><p>Similarly, for the second layer, the membrane potential was described by<disp-formula id="equ17"><label>(17)</label><mml:math id="m17"><mml:mrow><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>+</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:munder><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:munder><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msubsup><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mi>δ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf320"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mo>⁢</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf321"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mi>I</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are synapse-specific EPSPs/IPSPs which depends on the difference in preferred tuning <inline-formula><mml:math id="inf322"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> between the pre- and post-synaptic neurons (see <xref ref-type="disp-formula" rid="equ18">Equation 18</xref>), <inline-formula><mml:math id="inf323"><mml:msubsup><mml:mi>t</mml:mi><mml:mi>k</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>j</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> the timing of the <inline-formula><mml:math id="inf324"><mml:mi>k</mml:mi></mml:math></inline-formula> th spike of pre-synaptic neuron <inline-formula><mml:math id="inf325"><mml:mi>j</mml:mi></mml:math></inline-formula>, and <inline-formula><mml:math id="inf326"><mml:mi>d</mml:mi></mml:math></inline-formula> the delay (see <xref ref-type="table" rid="table2">Table 2</xref>, <xref ref-type="table" rid="table3">Table 3</xref> for parameter values). The neurons in the second layer were only tuned to a single preferred stimulus location each, equidistantly placed across <inline-formula><mml:math id="inf327"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Whenever a spike occurred in the first layer, it elicited EPSPs with a delay of 1.5 ms in all neurons in the second layer. The size of the EPSPs depended on the difference in preferred tuning, <inline-formula><mml:math id="inf328"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, between the pre- and post-synaptic neurons<disp-formula id="equ18"><label>(18)</label><mml:math id="m18"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf329"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mo>⁢</mml:mo><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> determines the maximal EPSP (mV), and the constant <inline-formula><mml:math id="inf330"><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> was chosen such that the full width at half maximum of the EPSP kernels tiled the stimulus domain without overlap. Note that for periodically tuned neurons in the first layer (i.e. with multiple preferred locations), the <inline-formula><mml:math id="inf331"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> were determined by the smallest difference in preferred tuning across the multiple preferred locations.</p><p>As for the excitatory neurons in the first layer, whenever a spike occurred in the second layer, it elicited IPSPs with a delay of 1.5 ms in all other neurons in the second layer. Again, the size of the IPSPs depended on the difference in preferred tuning, <inline-formula><mml:math id="inf332"><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> between the two neurons, but this time according to<disp-formula id="equ19"><label>(19)</label><mml:math id="m19"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>π</mml:mi><mml:msub><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Thus, the range of inhibition was much broader compared to the excitation.</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Parameters and parameter values for LIF neurons.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameters</th><th align="left" valign="bottom">Parameter values</th></tr></thead><tbody><tr><td align="left" valign="bottom">Membrane time constant, <inline-formula><mml:math id="inf333"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>m</mml:mi><mml:mi>b</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (ms)</td><td align="left" valign="bottom">20</td></tr><tr><td align="left" valign="bottom">Threshold memb. potential, <inline-formula><mml:math id="inf334"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (mV)</td><td align="left" valign="bottom">20</td></tr><tr><td align="left" valign="bottom">Reset memb. potential (mV)</td><td align="left" valign="bottom">10</td></tr><tr><td align="left" valign="bottom">Resting potential, <italic>V</italic><sub>0</sub> (mV)</td><td align="left" valign="bottom">0</td></tr><tr><td align="left" valign="bottom">Refractory period, <inline-formula><mml:math id="inf335"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (ms)</td><td align="left" valign="bottom">2</td></tr></tbody></table></table-wrap><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>Spiking network parameters and parameter values.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Parameters</th><th align="left" valign="bottom">Parameter values</th></tr></thead><tbody><tr><td align="left" valign="bottom">Number of neurons 1st layer, <italic>N</italic><sub>1</sub></td><td align="left" valign="bottom">500</td></tr><tr><td align="left" valign="bottom">Number of neurons 2nd layer, <italic>N</italic><sub>2</sub></td><td align="left" valign="bottom">400</td></tr><tr><td align="left" valign="bottom">Maximal stimulus-evoked input rate, <inline-formula><mml:math id="inf336"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>a</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (sp/s)</td><td align="left" valign="bottom">750</td></tr><tr><td align="left" valign="bottom">Baseline input rate, <inline-formula><mml:math id="inf337"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>b</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (sp/s)</td><td align="left" valign="bottom">4250</td></tr><tr><td align="left" valign="bottom">Spatial periods, <inline-formula><mml:math id="inf338"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">[1] or [1,2,3,4]</td></tr><tr><td align="left" valign="bottom">Width parameter, <inline-formula><mml:math id="inf339"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom">0.3</td></tr><tr><td align="left" valign="bottom">Width parameter (readout layer), <inline-formula><mml:math id="inf340"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>w</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula></td><td align="left" valign="bottom"><inline-formula><mml:math id="inf341"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>π</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></inline-formula></td></tr><tr><td align="left" valign="bottom">Input EPSP (1st layer), <inline-formula><mml:math id="inf342"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mi>E</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (mV)</td><td align="left" valign="bottom">0.2</td></tr><tr><td align="left" valign="bottom">Maximal EPSP (2nd layer), <inline-formula><mml:math id="inf343"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>E</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (mV)</td><td align="left" valign="bottom">2</td></tr><tr><td align="left" valign="bottom">Maximal IPSP (2nd layer), <inline-formula><mml:math id="inf344"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>I</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> (mV)</td><td align="left" valign="bottom">2</td></tr><tr><td align="left" valign="bottom">Synaptic delays, <inline-formula><mml:math id="inf345"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> (ms)</td><td align="left" valign="bottom">1.5</td></tr></tbody></table></table-wrap></sec><sec id="s4-3-3"><title>Evaluating decoding performance</title><p>We assumed that the decoder was instantaneously based on the neuron index of the firing neuron in the readout layer. Let <inline-formula><mml:math id="inf346"><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> denote a function that provides the index of the neuron firing at time <italic>t</italic><sub><italic>k</italic></sub>. Given the equidistant distribution of preferred locations for the readout neurons, the stimulus is instantaneously decoded by mapping the neuron identity to the interval <inline-formula><mml:math id="inf347"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula><disp-formula id="equ20"><label>(20)</label><mml:math id="m20"><mml:mrow><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">Φ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <italic>N</italic><sub>2</sub> is the number of neurons in the readout layer. For both stimulus cases, the decoding performance was evaluated using (1) the distribution of RMSE (<xref ref-type="fig" rid="fig7">Figure 7d</xref>) or estimated stimulus conditions (<xref ref-type="fig" rid="fig7">Figure 7e</xref>) in a sliding window or (2) the distributions of accumulated RMSE (<xref ref-type="fig" rid="fig8">Figure 8</xref>).</p></sec></sec><sec id="s4-4"><title>Parameters</title><sec id="s4-4-1"><title>Simulation tools</title><p>All the simulations were done using code written in MATLAB and Python (using Brian2 simulator <xref ref-type="bibr" rid="bib43">Stimberg et al., 2019</xref>). The simulation code is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/movitzle/Short_Decoding_Time">https://github.com/movitzle/Short_Decoding_Time</ext-link> (copy archived at <xref ref-type="bibr" rid="bib24">Lenninger, 2023</xref> ).</p></sec></sec><sec id="s4-5"><title>Approximating minimal decoding time in two-module systems</title><p>To gain an understanding of the interaction between two modules with different spatial periods, consider the likelihood function as a product of the likelihood functions of the two modules individually<disp-formula id="equ21"><label>(21)</label><mml:math id="m21"><mml:mtable columnspacing="5pt" displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd><mml:mtd/></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>Using the Laplace approximation, each of these functions can be approximated as a periodic sum of Gaussians (<xref ref-type="bibr" rid="bib46">Wei et al., 2015</xref>). Assuming that each module becomes efficient before the joint likelihood, we only focus on the largest, periodically occurring, peaks<disp-formula id="equ22"><label>(22)</label><mml:math id="m22"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf348"><mml:msup><mml:mi mathvariant="bold">r</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:math></inline-formula> denotes the activity pattern of module <inline-formula><mml:math id="inf349"><mml:mi>i</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf350"><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:math></inline-formula> the peak closest to the true stimulus condition, <italic>s</italic><sub>0</sub>, and <inline-formula><mml:math id="inf351"><mml:msub><mml:mi>K</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> is large enough for <inline-formula><mml:math id="inf352"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi>r</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>i</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> to cover the entire stimulus range <inline-formula><mml:math id="inf353"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. The approximation can be seen as ‘rolling out’ the stimulus domain from <inline-formula><mml:math id="inf354"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf355"><mml:mi>ℝ</mml:mi></mml:math></inline-formula>. Therefore, to neglect the impact of the stimulus boundary, we assume that the stimulus is in the middle of the stimulus domain and <inline-formula><mml:math id="inf356"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">⌈</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo stretchy="false">⌉</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf357"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">⌈</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mfrac><mml:mo stretchy="false">⌉</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Furthermore, assuming that each module is efficient, the width of the Gaussians can be approximated as<disp-formula id="equ23"><label>(23)</label><mml:math id="m23"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:mo>−</mml:mo><mml:mfrac><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf358"><mml:mrow><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>≈</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the Fisher information of module <inline-formula><mml:math id="inf359"><mml:mi>i</mml:mi></mml:math></inline-formula>. The joint likelihood function can thus be approximated as<disp-formula id="equ24"><label>(24)</label><mml:math id="m24"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>≈</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>As the likelihood functions depend on the particular realization of the spike counts, the distance between the modes of the respective likelihoods closest to the true stimulus condition <italic>s</italic><sub>0</sub>, <inline-formula><mml:math id="inf360"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, is a random variable. Note that in the Results section, <inline-formula><mml:math id="inf361"><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> is simply referred to as <inline-formula><mml:math id="inf362"><mml:mi>δ</mml:mi></mml:math></inline-formula> for clarity.</p><p>The joint likelihood distribution <inline-formula><mml:math id="inf363"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> has its maximal peak close to the true stimulus condition <italic>s</italic><sub>0</sub> if <inline-formula><mml:math id="inf364"><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> is the smallest distance between any pairs of peaks of <italic>Q</italic><sub>1</sub> and <italic>Q</italic><sub>2</sub> (see <xref ref-type="disp-formula" rid="equ80">Equation A3.7</xref> for details). Assuming that both modules provide efficient estimates, the distance <inline-formula><mml:math id="inf365"><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> can be approximated as a normally distributed random variable<disp-formula id="equ25"><label>(25)</label><mml:math id="m25"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>T</mml:mi></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf366"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math></inline-formula> refers to the time-normalized Fisher information of module <inline-formula><mml:math id="inf367"><mml:mi>k</mml:mi></mml:math></inline-formula>. Thus, as the decoding time <inline-formula><mml:math id="inf368"><mml:mi>T</mml:mi></mml:math></inline-formula> increases, the variance of <inline-formula><mml:math id="inf369"><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> decreases. Hence, it is necessary for the decoding time <inline-formula><mml:math id="inf370"><mml:mi>T</mml:mi></mml:math></inline-formula> to be large enough such that it is rare for <inline-formula><mml:math id="inf371"><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> not to be the smallest distance between any pair of peaks. Similarly, the distance between the other pair of peaks in <italic>Q</italic><sub>1</sub> and <italic>Q</italic><sub>2</sub> within the stimulus range becomes<disp-formula id="equ26"><label>(26)</label><mml:math id="m26"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf372"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf373"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are indexing the different Gaussians as before. Thus, the threshold for catastrophic error is reached when there is another pair of modes with the same distance between them, that is,<disp-formula id="equ27"><label>(27)</label><mml:math id="m27"><mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>for some <italic>n</italic><sub>1</sub> and <italic>n</italic><sub>2</sub> belonging to the index sets as above. Thus, to avoid catastrophic errors, it is necessary that<disp-formula id="equ28"><label>(28)</label><mml:math id="m28"><mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mo>≤</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>for all <inline-formula><mml:math id="inf374"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf375"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. By solving <xref ref-type="disp-formula" rid="equ28">Equation 28</xref>, and taking into account that <inline-formula><mml:math id="inf376"><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> can be either positive or negative, we get the maximally allowed displacement<disp-formula id="equ29"><label>(29)</label><mml:math id="m29"><mml:mrow><mml:msup><mml:mi>δ</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>≠</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>∈</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Note that for <inline-formula><mml:math id="inf377"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, all <italic>n</italic><sub>1</sub> represent the same mode (but one full rotation 1 away). Thus, we limit the search such that <inline-formula><mml:math id="inf378"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> and <inline-formula><mml:math id="inf379"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. Assuming that the period of the second module is a scaling of the first module, <inline-formula><mml:math id="inf380"><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, the above equation becomes<disp-formula id="equ30"><label>(30)</label><mml:math id="m30"><mml:mrow><mml:msup><mml:mi>δ</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>:</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>≠</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:munder><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>c</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Note that stimulus ambiguity can never be resolved if <inline-formula><mml:math id="inf381"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> for some pair <inline-formula><mml:math id="inf382"><mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>≠</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which is analogous to the condition in <xref ref-type="bibr" rid="bib27">Mathis et al., 2012</xref>. To limit the probability of catastrophic estimation errors from the joint distribution to some small error probability <inline-formula><mml:math id="inf383"><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, the following should hold<disp-formula id="equ31"><label>(31)</label><mml:math id="m31"><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:msup><mml:mi>δ</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Because <inline-formula><mml:math id="inf384"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">N</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:msubsup><mml:mi>J</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, we have<disp-formula id="equ32"><label>(32)</label><mml:math id="m32"><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mo>&gt;</mml:mo><mml:msup><mml:mi>δ</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mtext>erf</mml:mtext><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:msup><mml:mi>δ</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:msqrt><mml:mn>2</mml:mn></mml:msqrt><mml:mi>σ</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf385"><mml:mrow><mml:mtext>erf</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the error-function and <inline-formula><mml:math id="inf386"><mml:mrow><mml:mi>σ</mml:mi><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>J</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>J</mml:mi><mml:mn>2</mml:mn><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula>. By rearranging the terms and using <xref ref-type="disp-formula" rid="equ62">Equation A2.8</xref>, we can obtain a lower bound on the required decoding time<disp-formula id="equ33"><label>(33)</label><mml:math id="m33"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>2</mml:mn><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mtext>erf</mml:mtext><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msup><mml:mi>δ</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mfrac><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf387"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mo>⁢</mml:mo><mml:mi>o</mml:mi><mml:mo>⁢</mml:mo><mml:mi>r</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:math></inline-formula> is the time-normalized Fisher information of module <inline-formula><mml:math id="inf388"><mml:mi>i</mml:mi></mml:math></inline-formula>. Note that <inline-formula><mml:math id="inf389"><mml:msup><mml:mi>δ</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> can easily be found using an exhaustive search according to <xref ref-type="disp-formula" rid="equ29">Equation 29</xref> or <xref ref-type="disp-formula" rid="equ30">Equation 30</xref>.</p></sec><sec id="s4-6"><title>Approximating minimal decoding time</title><p>To approximate the order by which the population reaction time scales with the distribution of spatial periods and the stimulus dimensionality, we extended the approximation method introduced by <xref ref-type="bibr" rid="bib48">Xie, 2002</xref>. The key part of the approximation method is to use a Taylor series to reason about which conditions must hold for the distribution of errors to be normally distributed with a covariance equal to the inverse of the Fisher information matrix. Note that this approximation assumes the existence of a unique solution to the maximum likelihood equations, thus, it does not apply to ambiguous neural codes (e.g. <inline-formula><mml:math id="inf390"><mml:mrow><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>3</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>4</mml:mn></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, etc.).</p><p>First, let’s recollect the Taylor series with Lagrangian reminder for a general function g<disp-formula id="equ34"><label>(34)</label><mml:math id="m34"><mml:mrow><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>δ</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>δ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf391"><mml:msup><mml:mi>x</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> is somewhere on the interval <inline-formula><mml:math id="inf392"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mi>δ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. Thus, in the multivariate case, the derivative in the j:th direction of the log-likelihood function for stimulus condition <inline-formula><mml:math id="inf393"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> can be rewritten using a Taylor series with Lagrangian reminder as<disp-formula id="equ35"><label>(35)</label><mml:math id="m35"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mfrac><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:mi mathvariant="bold">s</mml:mi><mml:mo mathvariant="bold" stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:msub><mml:mo>=</mml:mo></mml:mtd><mml:mtd><mml:mfrac><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mo mathvariant="bold">∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>for all <inline-formula><mml:math id="inf394"><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> where <inline-formula><mml:math id="inf395"><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mo>∘</mml:mo></mml:msup></mml:math></inline-formula> is the true stimulus condition and <inline-formula><mml:math id="inf396"><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> is a stimulus point between <inline-formula><mml:math id="inf397"><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mo>∘</mml:mo></mml:msup></mml:math></inline-formula> and <inline-formula><mml:math id="inf398"><mml:mover accent="true"><mml:mi mathvariant="bold">s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula>.</p><p>If the estimated stimulus is close to the true stimulus, then the quadratic order terms are small. If so, the variance of <inline-formula><mml:math id="inf399"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>-</mml:mo><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mo>∘</mml:mo></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> converges towards <inline-formula><mml:math id="inf400"><mml:mrow><mml:mi class="ltx_font_mathcaligraphic">N</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msup><mml:mi>J</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (in distribution), where <inline-formula><mml:math id="inf401"><mml:mi>J</mml:mi></mml:math></inline-formula> is the Fisher information matrix (<xref ref-type="bibr" rid="bib23">Lehmann and Casella, 1998</xref>). However, if the estimated stimulus is not close to the true stimulus, then the quadratic terms are not negligible. Therefore, when <inline-formula><mml:math id="inf402"><mml:mi>T</mml:mi></mml:math></inline-formula> is sufficiently large, and the variance of the estimation follows the Cramér-Rao bound, the following should hold for all <inline-formula><mml:math id="inf403"><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula><disp-formula id="equ36"><label>(36)</label><mml:math id="m36"><mml:mrow><mml:mrow><mml:mo maxsize="2.470em" minsize="2.470em">|</mml:mo></mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.470em" minsize="2.470em">|</mml:mo></mml:mrow><mml:mo>≫</mml:mo><mml:mrow><mml:mo maxsize="2.470em" minsize="2.470em">|</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mo mathvariant="bold">∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.470em" minsize="2.470em">|</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>In this regime, we make the following term-wise approximations<disp-formula id="equ37"><label>(37)</label><mml:math id="m37"><mml:mrow><mml:mfrac><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">[</mml:mo></mml:mrow><mml:mfrac><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>and<disp-formula id="equ38"><label>(38)</label><mml:math id="m38"><mml:mrow><mml:mfrac><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mo mathvariant="bold">∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">[</mml:mo></mml:mrow><mml:mfrac><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mo mathvariant="bold">∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mo mathvariant="bold">∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>which gives<disp-formula id="equ39"><label>(39)</label><mml:math id="m39"><mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:mo>≫</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mo mathvariant="bold">∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Because <inline-formula><mml:math id="inf404"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> unless <inline-formula><mml:math id="inf405"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula> (see <xref ref-type="disp-formula" rid="equ84">Equation A4.3</xref>, <xref ref-type="disp-formula" rid="equ85">Equation A4.4</xref>, <xref ref-type="disp-formula" rid="equ86">Equation A4.5</xref>), <xref ref-type="disp-formula" rid="equ39">Equation 39</xref> simplifies to<disp-formula id="equ40"><label>(40)</label><mml:math id="m40"><mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:mo>≫</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mo mathvariant="bold">∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Furthermore, because <inline-formula><mml:math id="inf406"><mml:mrow><mml:mi>J</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a diagonal matrix (see <xref ref-type="disp-formula" rid="equ72">Equation A2.18</xref>), we have<disp-formula id="equ41"><label>(41)</label><mml:math id="m41"><mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:mo>≫</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mo mathvariant="bold">∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Next, by taking the square of the absolute values, we obtain<disp-formula id="equ42"><label>(42)</label><mml:math id="m42"><mml:mrow><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>≫</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>4</mml:mn></mml:mfrac><mml:msubsup><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mo mathvariant="bold">∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msubsup><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Because we assumed that <inline-formula><mml:math id="inf407"><mml:mi>N</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf408"><mml:mi>T</mml:mi></mml:math></inline-formula> are sufficiently large to meet the Cramér-Rao bound, we have that<disp-formula id="equ43"><label>(43)</label><mml:math id="m43"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msup><mml:mrow><mml:mover><mml:mi>J</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Inserting <xref ref-type="disp-formula" rid="equ43">Equation 43</xref> into <xref ref-type="disp-formula" rid="equ42">Equation 42</xref> gives<disp-formula id="equ44"><label>(44)</label><mml:math id="m44"><mml:mrow><mml:msubsup><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msup><mml:mi>J</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>≫</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>4</mml:mn></mml:mfrac><mml:msubsup><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mo mathvariant="bold">∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msup><mml:mi>J</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>or, equivalently,<disp-formula id="equ45"><label>(45)</label><mml:math id="m45"><mml:mrow><mml:mn>1</mml:mn><mml:mo>≫</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>4</mml:mn></mml:mfrac><mml:mrow><mml:msubsup><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mo mathvariant="bold">∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:msup><mml:mi>J</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>4</mml:mn></mml:mfrac><mml:mfrac><mml:mrow><mml:mrow><mml:msubsup><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mrow><mml:mo mathvariant="bold">∗</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mi>J</mml:mi><mml:msubsup><mml:mo fence="false" stretchy="false">}</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>By approximating the term <inline-formula><mml:math id="inf409"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> with an upper bound <inline-formula><mml:math id="inf410"><mml:msup><mml:mi>M</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> (see <xref ref-type="disp-formula" rid="equ91">Equation A4.10</xref>) and using the expression for Fisher information (<xref ref-type="disp-formula" rid="equ62">Equation A2.8</xref>), the expression for population reaction times can be obtained as<disp-formula id="equ46"><label>(46)</label><mml:math id="m46"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>≫</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>a</mml:mi><mml:mi>N</mml:mi></mml:mrow></mml:mfrac><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mi>D</mml:mi><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mfrac><mml:msup><mml:mover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf411"><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a function of <inline-formula><mml:math id="inf412"><mml:mi>w</mml:mi></mml:math></inline-formula>. Lastly, by casting <xref ref-type="disp-formula" rid="equ46">Equation 46</xref> in terms of the scale factor <inline-formula><mml:math id="inf413"><mml:mi>c</mml:mi></mml:math></inline-formula>, and fitting using (for example) least square regression, we obtain<disp-formula id="equ47"><label>(47)</label><mml:math id="m47"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub><mml:mo>≈</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>A</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>a</mml:mi><mml:mi>M</mml:mi></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:msup><mml:mi>c</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn><mml:mi>j</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf414"><mml:mi>M</mml:mi></mml:math></inline-formula> is the number of neurons per module, and <italic>K</italic><sub>1</sub> and <italic>K</italic><sub>2</sub> are constants. Note that in the simulations, <inline-formula><mml:math id="inf415"><mml:mi>w</mml:mi></mml:math></inline-formula> is fixed and <inline-formula><mml:math id="inf416"><mml:mrow><mml:mi>A</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> can therefore be incorporated into <italic>K</italic><sub>1</sub>.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Supervision, Funding acquisition, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Resources, Supervision, Funding acquisition, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Supervision, Methodology, Writing - original draft, Writing – review and editing</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-84531-mdarchecklist1-v2.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Code has been made publicly available on Github (<ext-link ext-link-type="uri" xlink:href="https://github.com/movitzle/Short_Decoding_Time">https://github.com/movitzle/Short_Decoding_Time</ext-link>, copy archived at <xref ref-type="bibr" rid="bib24">Lenninger, 2023</xref>).</p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank the reviewers and editors for their helpful comments on improving the manuscript and Dr. Pascal Helson for proofreading the manuscript.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abbott</surname><given-names>LF</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>The effect of correlated variability on the accuracy of a population code</article-title><source>Neural Computation</source><volume>11</volume><fpage>91</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1162/089976699300016827</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Arieli</surname><given-names>A</given-names></name><name><surname>Sterkin</surname><given-names>A</given-names></name><name><surname>Grinvald</surname><given-names>A</given-names></name><name><surname>Aertsen</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Dynamics of ongoing activity: explanation of the larger variability in evoked cortical responses</article-title><source>Science</source><volume>273</volume><fpage>1868</fpage><lpage>1871</lpage><pub-id pub-id-type="doi">10.1126/science.273.5283.1868</pub-id><pub-id pub-id-type="pmid">8791593</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Averbeck</surname><given-names>BB</given-names></name><name><surname>Lee</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Effects of noise correlations on information Encoding and decoding</article-title><source>Journal of Neurophysiology</source><volume>95</volume><fpage>3633</fpage><lpage>3644</lpage><pub-id pub-id-type="doi">10.1152/jn.00919.2005</pub-id><pub-id pub-id-type="pmid">16554512</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barth</surname><given-names>AL</given-names></name><name><surname>Poulet</surname><given-names>JFA</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Experimental evidence for sparse firing in the neocortex</article-title><source>Trends in Neurosciences</source><volume>35</volume><fpage>345</fpage><lpage>355</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2012.03.008</pub-id><pub-id pub-id-type="pmid">22579264</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benichoux</surname><given-names>V</given-names></name><name><surname>Brown</surname><given-names>AD</given-names></name><name><surname>Anbuhl</surname><given-names>KL</given-names></name><name><surname>Tollin</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Representation of multidimensional stimuli: Quantifying the most informative stimulus dimension from neural responses</article-title><source>The Journal of Neuroscience</source><volume>37</volume><fpage>7332</fpage><lpage>7346</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0318-17.2017</pub-id><pub-id pub-id-type="pmid">28663198</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bethge</surname><given-names>M</given-names></name><name><surname>Rotermund</surname><given-names>D</given-names></name><name><surname>Pawelzik</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Optimal short-term population coding: When Fisher information fails</article-title><source>Neural Computation</source><volume>14</volume><fpage>2317</fpage><lpage>2351</lpage><pub-id pub-id-type="doi">10.1162/08997660260293247</pub-id><pub-id pub-id-type="pmid">12396565</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunel</surname><given-names>N</given-names></name><name><surname>Nadal</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="1998">1998</year><article-title>Mutual information, Fisher information, and population coding</article-title><source>Neural Computation</source><volume>10</volume><fpage>1731</fpage><lpage>1757</lpage><pub-id pub-id-type="doi">10.1162/089976698300017115</pub-id><pub-id pub-id-type="pmid">9744895</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cholvin</surname><given-names>T</given-names></name><name><surname>Hainmueller</surname><given-names>T</given-names></name><name><surname>Bartos</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>The hippocampus converts dynamic entorhinal inputs into stable spatial maps</article-title><source>Neuron</source><volume>109</volume><fpage>3135</fpage><lpage>3148</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.09.019</pub-id><pub-id pub-id-type="pmid">34619088</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Deneve</surname><given-names>S</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Reading population codes: a neural implementation of ideal observers</article-title><source>Nature Neuroscience</source><volume>2</volume><fpage>740</fpage><lpage>745</lpage><pub-id pub-id-type="doi">10.1038/11205</pub-id><pub-id pub-id-type="pmid">10412064</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eliav</surname><given-names>T</given-names></name><name><surname>Maimon</surname><given-names>SR</given-names></name><name><surname>Aljadeff</surname><given-names>J</given-names></name><name><surname>Tsodyks</surname><given-names>M</given-names></name><name><surname>Ginosar</surname><given-names>G</given-names></name><name><surname>Las</surname><given-names>L</given-names></name><name><surname>Ulanovsky</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Multiscale representation of very large environments in the hippocampus of flying bats</article-title><source>Science</source><volume>372</volume><elocation-id>6545</elocation-id><pub-id pub-id-type="doi">10.1126/science.abg4020</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fabre-Thorpe</surname><given-names>M</given-names></name><name><surname>Delorme</surname><given-names>A</given-names></name><name><surname>Marlot</surname><given-names>C</given-names></name><name><surname>Thorpe</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A limit to the speed of processing in ultra-rapid visual Categorization of novel natural scenes</article-title><source>Journal of Cognitive Neuroscience</source><volume>13</volume><fpage>171</fpage><lpage>180</lpage><pub-id pub-id-type="doi">10.1162/089892901564234</pub-id><pub-id pub-id-type="pmid">11244543</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fiete</surname><given-names>IR</given-names></name><name><surname>Burak</surname><given-names>Y</given-names></name><name><surname>Brookings</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>What grid cells convey about rat location</article-title><source>The Journal of Neuroscience</source><volume>28</volume><fpage>6858</fpage><lpage>6871</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5684-07.2008</pub-id><pub-id pub-id-type="pmid">18596161</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Finkelstein</surname><given-names>A</given-names></name><name><surname>Ulanovsky</surname><given-names>N</given-names></name><name><surname>Tsodyks</surname><given-names>M</given-names></name><name><surname>Aljadeff</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Optimal dynamic coding by mixed-Dimensionality neurons in the head-direction system of bats</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>3590</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-05562-1</pub-id><pub-id pub-id-type="pmid">30181554</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Franke</surname><given-names>F</given-names></name><name><surname>Fiscella</surname><given-names>M</given-names></name><name><surname>Sevelev</surname><given-names>M</given-names></name><name><surname>Roska</surname><given-names>B</given-names></name><name><surname>Hierlemann</surname><given-names>A</given-names></name><name><surname>da Silveira</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Structures of neural correlation and how they favor coding</article-title><source>Neuron</source><volume>89</volume><fpage>409</fpage><lpage>422</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.12.037</pub-id><pub-id pub-id-type="pmid">26796692</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fusi</surname><given-names>S</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Rigotti</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Why neurons mix: high Dimensionality for higher cognition</article-title><source>Current Opinion in Neurobiology</source><volume>37</volume><fpage>66</fpage><lpage>74</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2016.01.010</pub-id><pub-id pub-id-type="pmid">26851755</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garg</surname><given-names>AK</given-names></name><name><surname>Li</surname><given-names>P</given-names></name><name><surname>Rashid</surname><given-names>MS</given-names></name><name><surname>Callaway</surname><given-names>EM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Color and orientation are jointly coded and spatially organized in Primate primary visual cortex</article-title><source>Science</source><volume>364</volume><fpage>1275</fpage><lpage>1279</lpage><pub-id pub-id-type="doi">10.1126/science.aaw5868</pub-id><pub-id pub-id-type="pmid">31249057</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guigon</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Computing with populations of Monotonically tuned neurons</article-title><source>Neural Computation</source><volume>15</volume><fpage>2115</fpage><lpage>2127</lpage><pub-id pub-id-type="doi">10.1162/089976603322297313</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Molden</surname><given-names>S</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Microstructure of a spatial map in the entorhinal cortex</article-title><source>Nature</source><volume>436</volume><fpage>801</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1038/nature03721</pub-id><pub-id pub-id-type="pmid">15965463</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hubel</surname><given-names>DH</given-names></name><name><surname>Wiesel</surname><given-names>TN</given-names></name></person-group><year iso-8601-date="1962">1962</year><article-title>Receptive fields, Binocular interaction and functional architecture in the cat's visual cortex</article-title><source>The Journal of Physiology</source><volume>160</volume><fpage>106</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1113/jphysiol.1962.sp006837</pub-id><pub-id pub-id-type="pmid">14449617</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnston</surname><given-names>WJ</given-names></name><name><surname>Palmer</surname><given-names>SE</given-names></name><name><surname>Freedman</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Nonlinear mixed selectivity supports reliable neural computation</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1007544</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007544</pub-id><pub-id pub-id-type="pmid">32069273</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kohn</surname><given-names>A</given-names></name><name><surname>Coen-Cagli</surname><given-names>R</given-names></name><name><surname>Kanitscheider</surname><given-names>I</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Correlations and neuronal population information</article-title><source>Annual Review of Neuroscience</source><volume>39</volume><fpage>237</fpage><lpage>256</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-070815-013851</pub-id><pub-id pub-id-type="pmid">27145916</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kostal</surname><given-names>L</given-names></name><name><surname>Lansky</surname><given-names>P</given-names></name><name><surname>Pilarski</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Performance breakdown in optimal stimulus decoding</article-title><source>Journal of Neural Engineering</source><volume>12</volume><elocation-id>036012</elocation-id><pub-id pub-id-type="doi">10.1088/1741-2560/12/3/036012</pub-id><pub-id pub-id-type="pmid">25946561</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lehmann</surname><given-names>EL</given-names></name><name><surname>Casella</surname><given-names>G</given-names></name></person-group><year iso-8601-date="1998">1998</year><source>Theory of Point Estimation</source><publisher-loc>New York</publisher-loc><publisher-name>Springer-Verlag</publisher-name><pub-id pub-id-type="doi">10.1007/b98854</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Lenninger</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2023">2023</year><data-title>Short_Decoding_Time</data-title><version designator="swh:1:rev:10086d954d5baaf5bf2c4e5f5b8ec75492e21c19">swh:1:rev:10086d954d5baaf5bf2c4e5f5b8ec75492e21c19</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:30e99da0da8716325b3591eb2f55bcf9686af1ba;origin=https://github.com/movitzle/Short_Decoding_Time;visit=swh:1:snp:c634ff16c59ea040408def2110bd47c0887027f2;anchor=swh:1:rev:10086d954d5baaf5bf2c4e5f5b8ec75492e21c19">https://archive.softwareheritage.org/swh:1:dir:30e99da0da8716325b3591eb2f55bcf9686af1ba;origin=https://github.com/movitzle/Short_Decoding_Time;visit=swh:1:snp:c634ff16c59ea040408def2110bd47c0887027f2;anchor=swh:1:rev:10086d954d5baaf5bf2c4e5f5b8ec75492e21c19</ext-link></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Beck</surname><given-names>JM</given-names></name><name><surname>Latham</surname><given-names>PE</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Bayesian inference with probabilistic population codes</article-title><source>Nature Neuroscience</source><volume>9</volume><fpage>1432</fpage><lpage>1438</lpage><pub-id pub-id-type="doi">10.1038/nn1790</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Malerba</surname><given-names>SB</given-names></name><name><surname>Pieropan</surname><given-names>M</given-names></name><name><surname>Burak</surname><given-names>Y</given-names></name><name><surname>Azeredo da Silveira</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Random Compressed Coding with Neurons</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2022.01.06.475186</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathis</surname><given-names>A</given-names></name><name><surname>Herz</surname><given-names>AVM</given-names></name><name><surname>Stemmler</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Optimal population codes for space: grid cells outperform place cells</article-title><source>Neural Computation</source><volume>24</volume><fpage>2280</fpage><lpage>2317</lpage><pub-id pub-id-type="doi">10.1162/NECO_a_00319</pub-id><pub-id pub-id-type="pmid">22594833</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moreno-Bote</surname><given-names>R</given-names></name><name><surname>Beck</surname><given-names>J</given-names></name><name><surname>Kanitscheider</surname><given-names>I</given-names></name><name><surname>Pitkow</surname><given-names>X</given-names></name><name><surname>Latham</surname><given-names>P</given-names></name><name><surname>Pouget</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Information-limiting correlations</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1410</fpage><lpage>1417</lpage><pub-id pub-id-type="doi">10.1038/nn.3807</pub-id><pub-id pub-id-type="pmid">25195105</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Dostrovsky</surname><given-names>J</given-names></name></person-group><year iso-8601-date="1971">1971</year><article-title>The hippocampus as a spatial map: preliminary evidence from unit activity in the freely-moving rat</article-title><source>Brain Research</source><volume>34</volume><fpage>171</fpage><lpage>175</lpage><pub-id pub-id-type="doi">10.1016/0006-8993(71)90358-1</pub-id><pub-id pub-id-type="pmid">5124915</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Panzeri</surname><given-names>S</given-names></name><name><surname>Petersen</surname><given-names>RS</given-names></name><name><surname>Schultz</surname><given-names>SR</given-names></name><name><surname>Lebedev</surname><given-names>M</given-names></name><name><surname>Diamond</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The role of spike timing in the coding of stimulus location in rat Somatosensory cortex</article-title><source>Neuron</source><volume>29</volume><fpage>769</fpage><lpage>777</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(01)00251-3</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Petersen</surname><given-names>RS</given-names></name><name><surname>Panzeri</surname><given-names>S</given-names></name><name><surname>Diamond</surname><given-names>ME</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Population coding of stimulus location in rat Somatosensory cortex</article-title><source>Neuron</source><volume>32</volume><fpage>503</fpage><lpage>514</lpage><pub-id pub-id-type="doi">10.1016/S0896-6273(01)00481-0</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Resulaj</surname><given-names>A</given-names></name><name><surname>Rinberg</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Novel behavioral paradigm reveals lower temporal limits on mouse olfactory decisions</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>11667</fpage><lpage>11673</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.4693-14.2015</pub-id><pub-id pub-id-type="pmid">26290243</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Resulaj</surname><given-names>A</given-names></name><name><surname>Ruediger</surname><given-names>S</given-names></name><name><surname>Olsen</surname><given-names>SR</given-names></name><name><surname>Scanziani</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>First spikes in visual cortex enable perceptual discrimination</article-title><source>eLife</source><volume>7</volume><elocation-id>e34044</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.34044</pub-id><pub-id pub-id-type="pmid">29659352</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rigotti</surname><given-names>M</given-names></name><name><surname>Barak</surname><given-names>O</given-names></name><name><surname>Warden</surname><given-names>MR</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Miller</surname><given-names>EK</given-names></name><name><surname>Fusi</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The importance of mixed selectivity in complex cognitive tasks</article-title><source>Nature</source><volume>497</volume><fpage>585</fpage><lpage>590</lpage><pub-id pub-id-type="doi">10.1038/nature12160</pub-id><pub-id pub-id-type="pmid">23685452</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ringach</surname><given-names>DL</given-names></name><name><surname>Shapley</surname><given-names>RM</given-names></name><name><surname>Hawken</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Orientation selectivity in Macaque V1: diversity and Laminar dependence</article-title><source>The Journal of Neuroscience</source><volume>22</volume><fpage>5639</fpage><lpage>5651</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.22-13-05639.2002</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rolls</surname><given-names>ET</given-names></name><name><surname>Tovee</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Processing speed in the cerebral cortex and the Neurophysiology of visual masking</article-title><source>Proceedings of the Royal Society of London. Series B</source><volume>257</volume><fpage>9</fpage><lpage>15</lpage><pub-id pub-id-type="doi">10.1098/rspb.1994.0087</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seung</surname><given-names>HS</given-names></name><name><surname>Sompolinsky</surname><given-names>H</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Simple models for reading neuronal population codes</article-title><source>PNAS</source><volume>90</volume><fpage>10749</fpage><lpage>10753</lpage><pub-id pub-id-type="doi">10.1073/pnas.90.22.10749</pub-id><pub-id pub-id-type="pmid">8248166</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shamir</surname><given-names>M</given-names></name><name><surname>Sompolinsky</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Nonlinear population codes</article-title><source>Neural Computation</source><volume>16</volume><fpage>1105</fpage><lpage>1136</lpage><pub-id pub-id-type="doi">10.1162/089976604773717559</pub-id><pub-id pub-id-type="pmid">15130244</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shannon</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="1949">1949</year><article-title>Communication in the presence of noise</article-title><source>Proceedings of the IRE</source><volume>37</volume><fpage>10</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1109/JRPROC.1949.232969</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Snodderly</surname><given-names>DM</given-names></name><name><surname>Gur</surname><given-names>M</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Organization of Striate cortex of alert, trained monkeys (Macaca Fascicularis): ongoing activity, stimulus selectivity, and widths of receptive field activating regions</article-title><source>Journal of Neurophysiology</source><volume>74</volume><fpage>2100</fpage><lpage>2125</lpage><pub-id pub-id-type="doi">10.1152/jn.1995.74.5.2100</pub-id><pub-id pub-id-type="pmid">8592200</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sreenivasan</surname><given-names>S</given-names></name><name><surname>Fiete</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Grid cells generate an analog error-correcting code for singularly precise neural computation</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1330</fpage><lpage>1337</lpage><pub-id pub-id-type="doi">10.1038/nn.2901</pub-id><pub-id pub-id-type="pmid">21909090</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stensola</surname><given-names>H</given-names></name><name><surname>Stensola</surname><given-names>T</given-names></name><name><surname>Solstad</surname><given-names>T</given-names></name><name><surname>Frøland</surname><given-names>K</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>The entorhinal grid map is Discretized</article-title><source>Nature</source><volume>492</volume><fpage>72</fpage><lpage>78</lpage><pub-id pub-id-type="doi">10.1038/nature11649</pub-id><pub-id pub-id-type="pmid">23222610</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stimberg</surname><given-names>M</given-names></name><name><surname>Brette</surname><given-names>R</given-names></name><name><surname>Goodman</surname><given-names>DFM</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Brian 2, an intuitive and efficient neural simulator</article-title><source>eLife</source><volume>8</volume><elocation-id>e47314</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.47314</pub-id><pub-id pub-id-type="pmid">31429824</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thorpe</surname><given-names>S</given-names></name><name><surname>Fize</surname><given-names>D</given-names></name><name><surname>Marlot</surname><given-names>C</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Speed of processing in the human visual system</article-title><source>Nature</source><volume>381</volume><fpage>520</fpage><lpage>522</lpage><pub-id pub-id-type="doi">10.1038/381520a0</pub-id><pub-id pub-id-type="pmid">8632824</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tovée</surname><given-names>MJ</given-names></name><name><surname>Rolls</surname><given-names>ET</given-names></name><name><surname>Treves</surname><given-names>A</given-names></name><name><surname>Bellis</surname><given-names>RP</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Information Encoding and the responses of single neurons in the Primate temporal visual cortex</article-title><source>Journal of Neurophysiology</source><volume>70</volume><fpage>640</fpage><lpage>654</lpage><pub-id pub-id-type="doi">10.1152/jn.1993.70.2.640</pub-id><pub-id pub-id-type="pmid">8410164</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>X-X</given-names></name><name><surname>Prentice</surname><given-names>J</given-names></name><name><surname>Balasubramanian</surname><given-names>V</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A principle of economy predicts the functional architecture of grid cells</article-title><source>eLife</source><volume>4</volume><elocation-id>September</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.08362</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>MA</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1993">1993</year><article-title>Dynamics of the hippocampal ensemble code for space</article-title><source>Science</source><volume>261</volume><fpage>1055</fpage><lpage>1058</lpage><pub-id pub-id-type="doi">10.1126/science.8351520</pub-id><pub-id pub-id-type="pmid">8351520</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xie</surname><given-names>X</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Threshold behaviour of the maximum likelihood method in population decoding</article-title><source>Network</source><volume>13</volume><fpage>447</fpage><lpage>456</lpage><pub-id pub-id-type="doi">10.1088/0954-898X_13_4_302</pub-id><pub-id pub-id-type="pmid">12463339</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zylberberg</surname><given-names>J</given-names></name><name><surname>Cafaro</surname><given-names>J</given-names></name><name><surname>Turner</surname><given-names>MH</given-names></name><name><surname>Shea-Brown</surname><given-names>E</given-names></name><name><surname>Rieke</surname><given-names>F</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Direction-selective circuits shape noise to ensure a precise population code</article-title><source>Neuron</source><volume>89</volume><fpage>369</fpage><lpage>383</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.11.019</pub-id><pub-id pub-id-type="pmid">26796691</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec sec-type="appendix" id="s8"><title>Tuning curves and spike count model</title><p>In the paper, we study the representation of a multidimensional stimulus <inline-formula><mml:math id="inf417"><mml:mrow><mml:mi>s</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>D</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. For simplicity, it is assumed that the range of the stimulus in each dimension is equal, such that <inline-formula><mml:math id="inf418"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for all <inline-formula><mml:math id="inf419"><mml:mrow><mml:mi>j</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for some stimulus range <inline-formula><mml:math id="inf420"><mml:mi>R</mml:mi></mml:math></inline-formula> (in the main text, we consider <inline-formula><mml:math id="inf421"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> for simplicity). Note that these assumption does not qualitatively change the results. Furthermore, we assume that the tuning curves were circular (von Mises) tuning curves<disp-formula id="equ48"><label>(A1.1)</label><mml:math id="m48"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:munderover><mml:mo movablelimits="false">∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:munderover><mml:mo movablelimits="false">∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <italic>a</italic><sub><italic>i</italic></sub> is the peak amplitude of the stimulus-related tuning curve of neuron <inline-formula><mml:math id="inf422"><mml:mi>i</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf423"><mml:mi>w</mml:mi></mml:math></inline-formula> is a width scaling parameter, <inline-formula><mml:math id="inf424"><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> defines the spatial period of the tuning, <inline-formula><mml:math id="inf425"><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula> determines the location of the firing field(s) in the <inline-formula><mml:math id="inf426"><mml:mi>j</mml:mi></mml:math></inline-formula>:th dimension, and <inline-formula><mml:math id="inf427"><mml:mi>b</mml:mi></mml:math></inline-formula> determines the amount of background activity. The amplitude parameters <italic>a</italic><sub><italic>i</italic></sub> were tuned such that all tuning curves had the same firing rate when averaged across all stimulus conditions (see Supplementary <xref ref-type="disp-formula" rid="equ52">Equation A1.5</xref>).</p><p>It is possible to reparametrize the stimuli into a phase variable, <inline-formula><mml:math id="inf428"><mml:mrow><mml:mi>ϕ</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mi>R</mml:mi></mml:mfrac></mml:mrow></mml:math></inline-formula>. In the article, calculations and numerical simulation are based on phase variables <inline-formula><mml:math id="inf429"><mml:mi>ϕ</mml:mi></mml:math></inline-formula>. This only changes the MSE and Fisher information by a constant scaling <inline-formula><mml:math id="inf430"><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mfrac></mml:math></inline-formula>. As we are interested in comparing the minimal decoding times, not the absolute values of the MSE, we can drop the &quot;unnormalized&quot; stimulus <inline-formula><mml:math id="inf431"><mml:mi>s</mml:mi></mml:math></inline-formula>. The tuning curves in Supplementary <xref ref-type="disp-formula" rid="equ48">Equation A1.1</xref> can thus be rewritten using the phase variable <inline-formula><mml:math id="inf432"><mml:mi>ϕ</mml:mi></mml:math></inline-formula> as<disp-formula id="equ49"><label>(A1.2)</label><mml:math id="m49"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:munderover><mml:mo movablelimits="false">∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:munderover><mml:mo movablelimits="false">∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Given stimulus condition <inline-formula><mml:math id="inf433"><mml:mi mathvariant="bold">s</mml:mi></mml:math></inline-formula> (or <inline-formula><mml:math id="inf434"><mml:mi>ϕ</mml:mi></mml:math></inline-formula>) and decoding time <inline-formula><mml:math id="inf435"><mml:mi>T</mml:mi></mml:math></inline-formula>, the spike count of each neuron was independently sampled from a Poisson distribution with rate <inline-formula><mml:math id="inf436"><mml:mrow><mml:mi>T</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Thus, the probability of observing a particular spike count pattern <inline-formula><mml:math id="inf437"><mml:mrow><mml:mi mathvariant="bold">r</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> given <inline-formula><mml:math id="inf438"><mml:mi mathvariant="bold">s</mml:mi></mml:math></inline-formula> is<disp-formula id="equ50"><label>(A1.3)</label><mml:math id="m50"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∏</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msup><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>!</mml:mo></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><sec sec-type="appendix" id="s8-1"><title>Adjusting amplitudes</title><p>In order to make a fair comparison of decoding times across populations, we constrain each neuron to have the same average firing rate across the stimulus domain, <inline-formula><mml:math id="inf439"><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula>. The average firing rate over the stimulus domain is<disp-formula id="equ51"><label>(A1.4)</label><mml:math id="m51"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mover><mml:mi>f</mml:mi><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>b</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msubsup><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msubsup><mml:munderover><mml:mo movablelimits="false">∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Thus, given a desired stimulus-evoked firing rate, <inline-formula><mml:math id="inf440"><mml:mover accent="true"><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>¯</mml:mo></mml:mover></mml:math></inline-formula>, over a normalized stimulus range (<inline-formula><mml:math id="inf441"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>), the amplitudes will be set to<disp-formula id="equ52"><label>(A1.5)</label><mml:math id="m52"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mover><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:munderover><mml:mo>∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Note that the integrals in <xref ref-type="disp-formula" rid="equ52">Equation A1.5</xref> are analytically solvable whenever the relative spatial frequency <inline-formula><mml:math id="inf442"><mml:mrow><mml:msub><mml:mi>ξ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is a positive integer, in which case we have<disp-formula id="equ53"><label>(A1.6)</label><mml:math id="m53"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:munderover><mml:mo movablelimits="false">∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mi>d</mml:mi><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msup><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>D</mml:mi><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>regardless of <inline-formula><mml:math id="inf443"><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:math></inline-formula>, here <inline-formula><mml:math id="inf444"><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the modified Bessel function of the first kind. In simulations, <inline-formula><mml:math id="inf445"><mml:mrow><mml:mover accent="true"><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mover accent="true"><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>¯</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> was set such that tuning curves with integer spatial frequencies (<inline-formula><mml:math id="inf446"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>λ</mml:mi></mml:mrow></mml:math></inline-formula>) have amplitudes of 20 sp/s, that is,<disp-formula id="equ54"><label>(A1.7)</label><mml:math id="m54"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mover><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>20</mml:mn><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msup><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>D</mml:mi><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p></sec></sec></app><app id="appendix-2"><title>Appendix 2</title><sec sec-type="appendix" id="s9"><title>Fisher information and the Cramér-Rao bound</title><p>Assuming a one-dimensional variable, the Cramér-Rao bound gives a lower bound on the MSE of any estimator <inline-formula><mml:math id="inf447"><mml:mi>G</mml:mi></mml:math></inline-formula><disp-formula id="equ55"><label>(A2.1)</label><mml:math id="m55"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mo>≥</mml:mo><mml:mfrac><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msubsup><mml:mi>b</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>J</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>G</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf448"><mml:mrow><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>G</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>E</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">r</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is the bias of the estimator <inline-formula><mml:math id="inf449"><mml:mi>G</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf450"><mml:mrow><mml:mi>J</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is Fisher information, defined as<disp-formula id="equ56"><label>(A2.2)</label><mml:math id="m56"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>J</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">[</mml:mo></mml:mrow><mml:mfrac><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">]</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">[</mml:mo></mml:mrow><mml:mfrac><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msup><mml:mi>s</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">]</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where the last equality holds if <inline-formula><mml:math id="inf451"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is twice differentiable and the neural responses are conditionally independent (<xref ref-type="bibr" rid="bib23">Lehmann and Casella, 1998</xref>). Assuming an unbiased estimator, the bound can be simplified to<disp-formula id="equ57"><label>(A2.3)</label><mml:math id="m57"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>s</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mtext>Var</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>G</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>≥</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>J</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>For multi-parameter estimation, let <inline-formula><mml:math id="inf452"><mml:mrow><mml:mi>J</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> denote the Fisher information matrix, with elements defined analogously to Supplementary <xref ref-type="disp-formula" rid="equ56">Equation A2.2</xref><disp-formula id="equ58"><label>(A2.4)</label><mml:math id="m58"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">[</mml:mo></mml:mrow><mml:mfrac><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>then (for unbiased estimators) the Cramér-Rao bound is instead stated as the following matrix inequality (<xref ref-type="bibr" rid="bib23">Lehmann and Casella, 1998</xref>)<disp-formula id="equ59"><label>(A2.5)</label><mml:math id="m59"><mml:mrow><mml:mrow><mml:mtext>Cov</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>G</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo>≥</mml:mo><mml:mrow><mml:msup><mml:mi>J</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>in the sense that the difference <inline-formula><mml:math id="inf453"><mml:mrow><mml:mi mathvariant="normal">Σ</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:msup><mml:mi>J</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is a positive semi-definite matrix. Thus, this implies the following lower bound for MSE of the k:th term<disp-formula id="equ60"><label>(A2.6)</label><mml:math id="m60"><mml:mrow><mml:mrow><mml:mtext>Var</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>≥</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:msup><mml:mi>J</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf454"><mml:mrow><mml:msup><mml:mi>G</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>s</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, that is, the estimation of <italic>s</italic><sub><italic>k</italic></sub> using estimator <inline-formula><mml:math id="inf455"><mml:mi>G</mml:mi></mml:math></inline-formula>. Note that if <inline-formula><mml:math id="inf456"><mml:mrow><mml:mi>J</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a diagonal matrix, that is, <inline-formula><mml:math id="inf457"><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mi>J</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> for all <inline-formula><mml:math id="inf458"><mml:mrow><mml:mi>j</mml:mi><mml:mo>≠</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:math></inline-formula>, then the following also holds<disp-formula id="equ61"><label>(A2.7)</label><mml:math id="m61"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:msup><mml:mi>J</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">}</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>For the tuning curves defined in Supplementary <xref ref-type="disp-formula" rid="equ48">Equation A1.1</xref>, the diagonal elements of the Fisher information matrix can be analytically solved assuming <inline-formula><mml:math id="inf459"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∼</mml:mo><mml:mi>a</mml:mi></mml:mrow></mml:math></inline-formula> within each module (see Supplementary <xref ref-type="disp-formula" rid="equ73">Equation A2.19</xref>)<disp-formula id="equ62"><label>(A2.8)</label><mml:math id="m62"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>T</mml:mi><mml:mi>N</mml:mi><mml:mfrac><mml:mi>a</mml:mi><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>w</mml:mi></mml:mrow></mml:mfrac><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>D</mml:mi><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where the bar indicates the sample average across modules and <inline-formula><mml:math id="inf460"><mml:mi>R</mml:mi></mml:math></inline-formula> is the stimulus range (note that in the main text, we assume <inline-formula><mml:math id="inf461"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>). The off-diagonal elements, on the other hand, can be shown to be 0 (see below). Thus we have equality in the last inequality of Supplementary <xref ref-type="disp-formula" rid="equ60">Equation A2.6</xref>, and the MSE for each stimulus dimension is lower bounded by the inverse of Supplementary <xref ref-type="disp-formula" rid="equ62">Equation A2.8</xref>.</p><sec sec-type="appendix" id="s9-1"><title>Approximating Fisher information</title><p>To analytically approximate the Fisher information for a given neural population, we will neglect the impact of ongoing activity <inline-formula><mml:math id="inf462"><mml:mi>b</mml:mi></mml:math></inline-formula>. Then, the tuning curves in Supplementary <xref ref-type="disp-formula" rid="equ48">Equation A1.1</xref> factorize as <inline-formula><mml:math id="inf463"><mml:mrow><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>D</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>D</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and the log-likelihood for <inline-formula><mml:math id="inf464"><mml:mi>N</mml:mi></mml:math></inline-formula> neurons with conditionally independent spike counts becomes<disp-formula id="equ63"><label>(A2.9)</label><mml:math id="m63"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>!</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>By taking the second derivatives w.r.t. stimulus dimension, we get for <inline-formula><mml:math id="inf465"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:math></inline-formula>:<disp-formula id="equ64"><label>(A2.10)</label><mml:math id="m64"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>r</mml:mi><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>−</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>and for <inline-formula><mml:math id="inf466"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≠</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:math></inline-formula><disp-formula id="equ65"><label>(A2.11)</label><mml:math id="m65"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mo>−</mml:mo><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Consequently, the elements of the Fisher information matrix are given by<disp-formula id="equ66"><label>(A2.12)</label><mml:math id="m66"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">[</mml:mo></mml:mrow><mml:mfrac><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>and for <inline-formula><mml:math id="inf467"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≠</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:math></inline-formula><disp-formula id="equ67"><label>(A2.13)</label><mml:math id="m67"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">[</mml:mo></mml:mrow><mml:mfrac><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>r</mml:mi><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>To simplify calculations, it is possible to reparametrize the stimulus as in Supplementary <xref ref-type="disp-formula" rid="equ49">Equation A1.2</xref> using the formula for Fisher information under reparametrization (<xref ref-type="bibr" rid="bib23">Lehmann and Casella, 1998</xref>)<disp-formula id="equ68"><label>(A2.14)</label><mml:math id="m68"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:munder><mml:munder><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munder><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>to obtain<disp-formula id="equ69"><label>(A2.15)</label><mml:math id="m69"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>J</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>We can approximate the elements of the Fisher information matrix <inline-formula><mml:math id="inf468"><mml:mrow><mml:mi>J</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> in the limit of large <inline-formula><mml:math id="inf469"><mml:mi>N</mml:mi></mml:math></inline-formula> by replacing the sums with integrals, for example,<disp-formula id="equ70"><label>(A2.16)</label><mml:math id="m70"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd/><mml:mtd><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>ϕ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>≈</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>≈</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>T</mml:mi><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mi>L</mml:mi><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msubsup></mml:mfrac><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>⋯</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">[</mml:mo></mml:mrow><mml:munderover><mml:mo movablelimits="false">∏</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">]</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>sin</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mi>w</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mi>d</mml:mi><mml:msup><mml:mi>ϕ</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf470"><mml:mi>L</mml:mi></mml:math></inline-formula> is the number of distinct modules, <inline-formula><mml:math id="inf471"><mml:mi>M</mml:mi></mml:math></inline-formula> is the number of neurons in each module, <inline-formula><mml:math id="inf472"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msup><mml:mi>ϕ</mml:mi><mml:mo>′</mml:mo></mml:msup></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mn>1</mml:mn><mml:mo>′</mml:mo></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>⁢</mml:mo><mml:mi>d</mml:mi><mml:mo>⁢</mml:mo><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mi>D</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, and the D-dimensional integral is taken over the interval <inline-formula><mml:math id="inf473"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>⁢</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> along each dimension. Making the variable substitution <inline-formula><mml:math id="inf474"><mml:mrow><mml:msub><mml:mi>θ</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mi>p</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> for <inline-formula><mml:math id="inf475"><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> we have<disp-formula id="equ71"><label>(A2.17)</label><mml:math id="m71"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>≈</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>M</mml:mi><mml:mi>T</mml:mi><mml:mi>a</mml:mi><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msubsup></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>π</mml:mi></mml:mrow></mml:msubsup><mml:mo>⋯</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mi>π</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">[</mml:mo></mml:mrow><mml:munderover><mml:mo movablelimits="false">∏</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">]</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>sin</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mi>w</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mfrac><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msubsup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mi>d</mml:mi><mml:mi>θ</mml:mi><mml:mo>=</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>N</mml:mi><mml:mi>T</mml:mi><mml:mi>a</mml:mi></mml:mrow><mml:mi>w</mml:mi></mml:mfrac><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>D</mml:mi><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where the sample average is taken over the population’s distribution of spatial frequencies and <inline-formula><mml:math id="inf476"><mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mi>α</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>⋅</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the modified Bessel function of the first kind. Similar calculations for the case <inline-formula><mml:math id="inf477"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≠</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:math></inline-formula> yield<disp-formula id="equ72"><label>(A2.18)</label><mml:math id="m72"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>ϕ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>≈</mml:mo><mml:mi>M</mml:mi><mml:mi>T</mml:mi><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mi>a</mml:mi><mml:msup><mml:mi>w</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>D</mml:mi><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:msubsup><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:msubsup><mml:mfrac><mml:mn>1</mml:mn><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>θ</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.</mml:mn></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Thus, the stimulus parameters will be asymptotically orthogonal for all of the populations considered in this paper. That is, the covariance matrix will be diagonal. The per-neuron average contribution to each diagonal element of the Fisher information matrix, as reported in the main text, is, therefore<disp-formula id="equ73"><label>(A2.19)</label><mml:math id="m73"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mover><mml:mi>J</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:mi>T</mml:mi><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mi>w</mml:mi></mml:mrow></mml:mfrac><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>D</mml:mi><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p></sec></sec></app><app id="appendix-3"><title>Appendix 3</title><sec sec-type="appendix" id="s10"><title>Maximum of the joint likelihood function (2 module case)</title><p>Assuming that the responses of the two modules are independent, the joint likelihood function <inline-formula><mml:math id="inf478"><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> can be decomposed into a product of the likelihood functions of the two modules. Using the approximation of each <inline-formula><mml:math id="inf479"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf480"><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> as Gaussian sums (see Materials and methods), we have the following<disp-formula id="equ74"><label>(A3.1)</label><mml:math id="m74"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Thus, the contribution of the <inline-formula><mml:math id="inf481"><mml:mi>p</mml:mi></mml:math></inline-formula>:th and <inline-formula><mml:math id="inf482"><mml:mi>q</mml:mi></mml:math></inline-formula>:th mode of <inline-formula><mml:math id="inf483"><mml:msub><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf484"><mml:msub><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> to the joint likelihood function is<disp-formula id="equ75"><label>(A3.2)</label><mml:math id="m75"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msubsup><mml:msubsup><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msubsup></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mi>q</mml:mi><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>where we in the last step renamed <inline-formula><mml:math id="inf485"><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf486"><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mrow><mml:mi>q</mml:mi><mml:mo>⁢</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> to <italic>s</italic><sub><italic>p</italic></sub> and <italic>s</italic><sub><italic>q</italic></sub>, respectively. Unless the width <inline-formula><mml:math id="inf487"><mml:mi>w</mml:mi></mml:math></inline-formula> of the tuning curves or the range <inline-formula><mml:math id="inf488"><mml:mi>R</mml:mi></mml:math></inline-formula> is very large, all the modes of <inline-formula><mml:math id="inf489"><mml:msub><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf490"><mml:msub><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>, respectively, are well separated (see the end of the section). Thus, it is a reasonable approximation that the maximum of <inline-formula><mml:math id="inf491"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi><mml:mo lspace="2.5pt" rspace="2.5pt" stretchy="false">|</mml:mo><mml:mi>s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>Q</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>Q</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is defined by the maximum of <inline-formula><mml:math id="inf492"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn><mml:mi>p</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn><mml:mi>q</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> across all combinations of <inline-formula><mml:math id="inf493"><mml:mi>p</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf494"><mml:mi>q</mml:mi></mml:math></inline-formula>. Each combination <inline-formula><mml:math id="inf495"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn><mml:mi>p</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn><mml:mi>q</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> reaches its maximum for some stimulus <inline-formula><mml:math id="inf496"><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msubsup></mml:math></inline-formula>:<disp-formula id="equ76"><label>(A3.3)</label><mml:math id="m76"><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:munder><mml:mo>⁡</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi></mml:mrow></mml:munder><mml:mo>⁡</mml:mo><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mfrac><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo>−</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Taking the derivative w.r.t. <inline-formula><mml:math id="inf497"><mml:mi>s</mml:mi></mml:math></inline-formula> on the rightmost terms and solving gives<disp-formula id="equ77"><label>(A3.4)</label><mml:math id="m77"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Thus, using <inline-formula><mml:math id="inf498"><mml:mrow><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, the maximal value of each pair <inline-formula><mml:math id="inf499"><mml:mrow><mml:msubsup><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn><mml:mi>p</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:msubsup><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn><mml:mi>q</mml:mi></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>s</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is<disp-formula id="equ78"><label>(A3.5)</label><mml:math id="m78"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msubsup><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mrow><mml:mover><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>=</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>−</mml:mo><mml:mfrac><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mn>2</mml:mn></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>.</mml:mo><mml:mo>=</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>A</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mfrac><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>J</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:msubsup><mml:mi>δ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Thus, the maximum likelihood choice will approximately be <inline-formula><mml:math id="inf500"><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msubsup></mml:math></inline-formula> for the <inline-formula><mml:math id="inf501"><mml:mi>p</mml:mi></mml:math></inline-formula>:th and <inline-formula><mml:math id="inf502"><mml:mi>q</mml:mi></mml:math></inline-formula>:th mode with the smallest <inline-formula><mml:math id="inf503"><mml:msubsup><mml:mi>δ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:math></inline-formula>, that is, the smallest distance between the modes. Lastly, all modes of <inline-formula><mml:math id="inf504"><mml:msub><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf505"><mml:msub><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>, respectively, need to be sufficiently separated such that no two pairs of <inline-formula><mml:math id="inf506"><mml:mi>p</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf507"><mml:mi>q</mml:mi></mml:math></inline-formula> reinforce each other. However, it is well known the full width at half maximum for a Gaussian function is <inline-formula><mml:math id="inf508"><mml:mrow><mml:mtext>FWHM</mml:mtext><mml:mo>=</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:msqrt><mml:mo>⁢</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, where for our functions <inline-formula><mml:math id="inf509"><mml:msubsup><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn><mml:mi>p</mml:mi></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="inf510"><mml:msubsup><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn><mml:mi>q</mml:mi></mml:msubsup></mml:math></inline-formula>, <inline-formula><mml:math id="inf511"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msqrt><mml:msub><mml:mi>J</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:msqrt></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf512"><mml:mrow><mml:msub><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:msqrt><mml:msub><mml:mi>J</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:msqrt></mml:mrow></mml:mrow></mml:math></inline-formula>. Thus, given the expression for Fisher information in <xref ref-type="disp-formula" rid="equ62">Equation A2.8</xref>, the FWHM can be expressed as<disp-formula id="equ79"><label>(A3.6)</label><mml:math id="m79"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>F</mml:mi><mml:mi>W</mml:mi><mml:mi>H</mml:mi><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msqrt><mml:mfrac><mml:mrow><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>w</mml:mi><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>a</mml:mi><mml:mi>T</mml:mi><mml:mi>M</mml:mi><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:msqrt></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Thus, for the modes to be separated, it is reasonable to require that the FWHM is no longer than one period length of the module, that is, <inline-formula><mml:math id="inf513"><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>. Hence, we have that<disp-formula id="equ80"><label>(A3.7)</label><mml:math id="m80"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msqrt><mml:mfrac><mml:mrow><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>w</mml:mi><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>a</mml:mi><mml:mi>T</mml:mi><mml:mi>M</mml:mi><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:msqrt><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Rewriting this into a bound on the time <inline-formula><mml:math id="inf514"><mml:mi>T</mml:mi></mml:math></inline-formula> needed for the assumption of separation, we get<disp-formula id="equ81"><label>(A3.8)</label><mml:math id="m81"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>T</mml:mi><mml:mo>&gt;</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mfrac><mml:mi>π</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mi>ln</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mi>w</mml:mi><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>a</mml:mi><mml:mi>M</mml:mi><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>D</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>For the parameters used in our simulations, this is satisfied very fast, on the order of tens of microseconds. However, note that the assumption of each module providing efficient estimates, which is a prerequisite for these approximations, requires significantly longer time scales. Thus, the assumption that the individual modes of <inline-formula><mml:math id="inf515"><mml:msub><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf516"><mml:msub><mml:mover accent="true"><mml:mi>Q</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula> are well-separated is, in our case, not likely to be a restrictive assumption.</p></sec></app><app id="appendix-4"><title>Appendix 4</title><sec sec-type="appendix" id="s11"><title>Calculate <inline-formula><mml:math id="inf517"><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula></title><p>To approximate the minimal decoding time, we need to calculate (see <xref ref-type="disp-formula" rid="equ38 equ39">Equations 38; 39</xref>, main text)<disp-formula id="equ82"><label>(A4.1)</label><mml:math id="m82"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">[</mml:mo></mml:mrow><mml:mfrac><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>For <inline-formula><mml:math id="inf518"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≠</mml:mo><mml:mi>l</mml:mi><mml:mo>≠</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula>, using Supplementary <xref ref-type="disp-formula" rid="equ48">Equation A1.1</xref>, <xref ref-type="disp-formula" rid="equ49">Equation A1.2</xref>, <xref ref-type="disp-formula" rid="equ50">Equation A1.3</xref>, we have<disp-formula id="equ83"><label>(A4.2)</label><mml:math id="m83"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Thus, <inline-formula><mml:math id="inf519"><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> for <inline-formula><mml:math id="inf520"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≠</mml:mo><mml:mi>l</mml:mi><mml:mo>≠</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula> becomes<disp-formula id="equ84"><label>(A4.3)</label><mml:math id="m84"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>≈</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>≈</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mi>M</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>R</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>⋯</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mi>T</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">[</mml:mo></mml:mrow><mml:munderover><mml:mo movablelimits="false">∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">]</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mi>w</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>as odd functions over even intervals integrate to zero. For <inline-formula><mml:math id="inf521"><mml:mrow><mml:mi>k</mml:mi><mml:mo>≠</mml:mo><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula> (note that <inline-formula><mml:math id="inf522"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mi>l</mml:mi><mml:mo>≠</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf523"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mo>≠</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:math></inline-formula> follows by symmetry) we have<disp-formula id="equ85"><label>(A4.4)</label><mml:math id="m85"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:msup><mml:mi mathvariant="normal">∂</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="normal">∂</mml:mi><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi mathvariant="normal">∂</mml:mi><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>and hence,<disp-formula id="equ86"><label>(A4.5)</label><mml:math id="m86"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>l</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>≈</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>≈</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mo>−</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mi>M</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>R</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>⋯</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mfrac><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mfrac><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mi>T</mml:mi><mml:mi>a</mml:mi><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">[</mml:mo></mml:mrow><mml:munderover><mml:mo movablelimits="false">∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">]</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mi>w</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mi>sin</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>0.</mml:mn></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Lastly, for <inline-formula><mml:math id="inf524"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mi>m</mml:mi></mml:mrow></mml:math></inline-formula> we have,<disp-formula id="equ87"><label>(A4.6)</label><mml:math id="m87"><mml:mrow><mml:mfrac><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi>d</mml:mi><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi><mml:mi mathvariant="normal">′</mml:mi><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mn>3</mml:mn><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Thus <inline-formula><mml:math id="inf525"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, becomes<disp-formula id="equ88"><label>(A4.7)</label><mml:math id="m88"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>∼</mml:mo><mml:mtext>Poiss</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">[</mml:mo></mml:mrow><mml:mfrac><mml:msup><mml:mi>d</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mi>d</mml:mi><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac><mml:mi>log</mml:mi><mml:mo>⁡</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">|</mml:mo></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">]</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi><mml:mi mathvariant="normal">′</mml:mi><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>−</mml:mo><mml:mn>3</mml:mn><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Each term above have a dependence on <inline-formula><mml:math id="inf526"><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, with an odd power. Therefore, when multiplying with <inline-formula><mml:math id="inf527"><mml:mrow><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and integrating as above, these terms vanish. Hence, we can focus only on the terms including <inline-formula><mml:math id="inf528"><mml:mrow><mml:mi>f</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mo>∘</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. After some calculus manipulation, it is possible to reduce the expression to include only <inline-formula><mml:math id="inf529"><mml:mrow><mml:mi>T</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi></mml:mrow><mml:mo>′</mml:mo></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold">s</mml:mi><mml:mo>∘</mml:mo></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (for all <inline-formula><mml:math id="inf530"><mml:mi>i</mml:mi></mml:math></inline-formula>).<disp-formula id="equ89"><label>(A4.8)</label><mml:math id="m89"><mml:mrow><mml:mtable columnalign="left left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo></mml:mtd><mml:mtd><mml:mi>T</mml:mi><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:munderover><mml:mi>a</mml:mi><mml:mfrac><mml:mi>M</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>R</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mi>w</mml:mi></mml:mrow></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mfrac><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mfrac><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mo>⋯</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mfrac><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mfrac><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mo>×</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>×</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo movablelimits="false">∏</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:munderover><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msup><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>=</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mstyle displaystyle="true" scriptlevel="0"><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:munderover><mml:mi>a</mml:mi><mml:mfrac><mml:mi>M</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>R</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mi>w</mml:mi></mml:mrow></mml:mfrac><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>D</mml:mi><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mo>×</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>×</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:mfrac><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mfrac><mml:mi>R</mml:mi><mml:mn>2</mml:mn></mml:mfrac><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:msubsup><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Unfortunately, as this integral includes both <inline-formula><mml:math id="inf531"><mml:msubsup><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:math></inline-formula> and <inline-formula><mml:math id="inf532"><mml:msubsup><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mo>∘</mml:mo></mml:msubsup></mml:math></inline-formula>, no simple expression can be obtained. Using the variable substitution <inline-formula><mml:math id="inf533"><mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mi>k</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mo>′</mml:mo></mml:msubsup></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, we can simplify it slightly to<disp-formula id="equ90"><label>(A4.9)</label><mml:math id="m90"><mml:mrow><mml:mtable columnalign="right left" rowspacing="4pt" columnspacing="1em"><mml:mtr><mml:mtd><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>≈</mml:mo></mml:mtd><mml:mtd><mml:mi>T</mml:mi><mml:mi>a</mml:mi><mml:mi>M</mml:mi><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mi>w</mml:mi></mml:mrow></mml:mfrac><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>D</mml:mi><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>L</mml:mi></mml:mrow></mml:munderover><mml:mfrac><mml:mn>1</mml:mn><mml:msubsup><mml:mi>λ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup></mml:mfrac><mml:mo>×</mml:mo></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd><mml:mo>×</mml:mo><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:mi>π</mml:mi></mml:mrow></mml:msubsup><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mi>λ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>R</mml:mi></mml:mrow></mml:mfrac><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>∘</mml:mo></mml:mrow></mml:msubsup><mml:mo>−</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:msubsup><mml:mi>θ</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Instead, we focus on the difference <inline-formula><mml:math id="inf534"><mml:mrow><mml:msubsup><mml:mi>ϕ</mml:mi><mml:mi>j</mml:mi><mml:mo>*</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>ϕ</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>λ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mo>∘</mml:mo></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mi>s</mml:mi><mml:mi>k</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, which maximizes the above integral for each module. Thus, all integrals can be upper bounded by a constant <inline-formula><mml:math id="inf535"><mml:msup><mml:mi>C</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula>, yielding the upper bound<disp-formula id="equ91"><label>(A4.10)</label><mml:math id="m91"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>≤</mml:mo><mml:msup><mml:mi>M</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>C</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>a</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mi>w</mml:mi></mml:mrow></mml:mfrac><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mfrac><mml:mi>D</mml:mi><mml:mi>w</mml:mi></mml:mfrac><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">(</mml:mo></mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>w</mml:mi></mml:mfrac><mml:msup><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">)</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>D</mml:mi><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Note that the constant <inline-formula><mml:math id="inf536"><mml:msup><mml:mi>C</mml:mi><mml:mo>*</mml:mo></mml:msup></mml:math></inline-formula> can be incorporated into the regression coefficient <italic>K</italic><sub>1</sub> in <xref ref-type="disp-formula" rid="equ47">Equation 47</xref> and that the stimulus range, <inline-formula><mml:math id="inf537"><mml:mi>R</mml:mi></mml:math></inline-formula>, is assumed to be <inline-formula><mml:math id="inf538"><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> in the main text.</p></sec></app><app id="appendix-5"><title>Appendix 5</title><sec sec-type="appendix" id="s12"><title>Approximating minimal required spike count</title><p>Given the approximation of minimal decoding time in <xref ref-type="disp-formula" rid="equ9">Equation 9</xref> (main text), we seek to reformulate the approximation in terms of the required total spike count, instead. The average total spike count for a given population and stimulus condition is<disp-formula id="equ92"><label>(A5.1)</label><mml:math id="m92"><mml:mrow><mml:mi>μ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mi>r</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">[</mml:mo></mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf539"><mml:mi>T</mml:mi></mml:math></inline-formula> is the decoding time. Thus, the average spike count over both stimulus conditions (assuming uniformly distributed stimulus and integer spatial frequencies) and trials for the entire population is<disp-formula id="equ93"><label>(A5.2)</label><mml:math id="m93"><mml:mrow><mml:mi>μ</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">[</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">[</mml:mo></mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">|</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">]</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="2.047em" minsize="2.047em">]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mfrac><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msubsup><mml:mo>…</mml:mo><mml:msubsup><mml:mo>∫</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mrow><mml:mi>R</mml:mi></mml:mrow></mml:msubsup><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>N</mml:mi></mml:mrow></mml:munderover><mml:mi>T</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mi>T</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>a</mml:mi><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msup><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>b</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Consequently, the number of spikes evoked by the stimulus-related tuning of the population is<disp-formula id="equ94"><label>(A5.3)</label><mml:math id="m94"><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>N</mml:mi><mml:mi>T</mml:mi><mml:mi>a</mml:mi><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mi>D</mml:mi></mml:mrow></mml:msup><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mi>D</mml:mi><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Inserting Supplementary <xref ref-type="disp-formula" rid="equ94">Equation A5.3</xref> into <xref ref-type="disp-formula" rid="equ46">Equation 46</xref> (main text) reveals the number of stimulus-evoked spikes, <inline-formula><mml:math id="inf540"><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo>*</mml:mo></mml:msubsup></mml:math></inline-formula>, the population must produce before reaching the predicted lower bound<disp-formula id="equ95"><label>(A5.4)</label><mml:math id="m95"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>μ</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msubsup><mml:mo>≫</mml:mo><mml:mi>A</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mi>w</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mfrac><mml:msup><mml:mover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mover><mml:msup><mml:mi>λ</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo accent="false">¯</mml:mo></mml:mover><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p></sec></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.84531.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Latham</surname><given-names>Peter</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2022.09.09.505677" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2022.09.09.505677"/></front-stub><body><p>This fundamental study provides important insight into coding strategies in sensory areas. The study was well done, and the analysis and simulations were highly convincing. This study should be of particular interest to anybody who cares about efficient coding.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.84531.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Latham</surname><given-names>Peter</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02jx3x895</institution-id><institution>University College London</institution></institution-wrap><country>United Kingdom</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Panzeri</surname><given-names>Stefano</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01zgy1s35</institution-id><institution>UKE</institution></institution-wrap><country>Germany</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2022.09.09.505677">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2022.09.09.505677v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Are single-peaked tuning curves tuned for speed rather than accuracy?&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 2 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Panayiota Poirazi as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Stefano Panzeri (Reviewer #2).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>While this paper makes an extremely important point, one that should definitely be communicated to the broader community, in our opinion it suffers from two (relatively easily fixable) problems:</p><p>I. Unless one is an expert, it's very hard to extract why multi-peaked tuning curves lead to catastrophic errors.</p><p>II. It's difficult to figure out under what circumstances multi-peaked tuning curves are bad. This is important, because there are a lot of neurons in sensory cortex, and one would like to know whether periodic tuning curves are really a bad idea there.</p><p>And here are the fixes:</p><p>I. Figure 1c seems like a missed opportunity to explain what's really going on, which is that on any particular trial the positions of the peaks of the log likelihood can shift in both phase and amplitude (with phase being more important). The reason it's a missed opportunity is that Figure 1c shows the average log likelihood, which makes it hard to understands why there are catastrophic errors. It would really help if Figure 1c were expanded into its own large figure, with sample log likelihoods showing catastrophic errors for multi-peaked tuning curves but not for single-peaked ones. You could also indicate why, when multi-peaked tuning curves do give the right answer, the error tends to be small.</p><p>II. What the reader really wants to know is: would sensory processing in real brains be more efficient if multi-peaked tuning curves were used? That's certainly hard to answer in all generality, but you could make a comparison between a code with single-peaked tuning curves and a _good_ code with multi-peaked tuning curves. Our guess is that a good code would have λ_1=1 and c around 0.5 (but not, of course, exactly 1/2; you could use the module ratio the grid cell people came up with -- we think 1/sqrt(2) -- although we doubt if it matters much). What would be great would be a relatively simple relation, possibly fitted empirically to simulations, that told us when multi-peaked tuning curves are better than single-peaked one, given the number of neurons, background and peak firing rates, and dimensionality. Of course, this may be impossible, but if so it's important to state that up front, so that people know how difficult this is.</p><p>In addition, we have a number of comments, all designed to improve the paper. Feel free to disagree with any of them; we don't feel massively strongly about them. Also, if you implement them, no reason to provide a reply -- we're sensitive to the fact that replies to the reviewer are becoming longer than the paper!</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>1. When catastrophic errors are possible, we agree that it's very hard to find a good measure of error. RMS error clearly isn't very good. However, it's not clear minimal decoding time is any better, since it'd defined in terms of RMS error. Finding a good measure seems critical when comparing codes, given that Fisher info can change by 5 orders of magnitude while decoding time changes by only 1 (e.g., Figure 4d). Moreover, we could be wrong, but our intuition is that when λ_1=1, catastrophic errors aren't much of an issue. Is that correct? If so, time to threshold (defined to be time for the RMS error to be twice that predicted by the inverse of the Fisher info) could be a bad measure.</p><p>Here we don't have any really great suggestions. But you might try something like [&lt;(error)^k&gt;/((2k-1)!!)]^{1/k} for k larger than 2 and even (the factor of (2k-1)!!) makes this equal to the RMS error for Gaussian distributions. But other measures are possible.</p><p>2. Are you using periodic boundary conditions? Tuning curves are clearly periodic, but decoding near the boundaries is a bit tricky. For instance, the ML estimator can put the decoded value outside the range [0, 1). This should be clarified.</p><p>3. It should be clear that the expression for Fisher info (Equation 3) applies when a_i=a and b=0.</p><p>4. Figure 1a: it would be helpful to indicate the location of s_1 and s_2 in the top panel.</p><p>Also, isn't Figure 1a a bit misleading? The problem isn't a small number of spikes; it's a phase shift in the log likelihood.</p><p>5. l 99-100: &quot;For the largest mode of the joint likelihood function to also be centered close to the true stimulus condition, the distance δ between s^(1)_ML and s^(2)_ML must be smaller than between any other pair of modes of Q_1 and Q_2.&quot; We can see why this might be reasonable, but it's not totally obvious that the distance between the modes is the only thing that matters. This needs to be shown.</p><p>6. l 100-101: &quot;Thus, to avoid catastrophic errors, δ must be smaller than some largest allowed distance δ* (see Methods for calculation of δ*).&quot; This makes it seems like δ* is something complicated. But in fact it's exactly half the smallest distance between any other pair of modes. Why not say so?</p><p>7. l 120-1: &quot;estimates can cause catastrophic shifts in the joint likelihood function. For single-peaked tuning curves (λ_1 = 1), however, only small scale factors c can pose such problems.&quot; Should &quot;For single-peaked tuning curves&quot; be &quot;When the first mode has a single peak&quot;. If not, we're lost.</p><p>8. l 128: &quot;Furthermore, only populations with unambiguous codes over the stimulus interval were included [22].&quot; Can't parse.</p><p>9. Equation 8 seems unlikely to be correct, given that it doesn't depend on c, which we know is critical (as shown in Figure 1e). However, if you do keep it, it would be helpful to express it in terms of the average firing rate. If you do that, lots of terms go away.</p><p>10. Figure caption 2c: &quot;colored lines show the estimated minimal decoding time from simulations and the black lines show the fitted theoretical predictions&quot;. Presumably the description of the fitted lines was given on on l. 178. However, we can't tell from this description what you actually did. Equations are needed.</p><p>And presumably this also comes up on l. 211: &quot;ratios of fitted regressors K1 were approximately 1.69 and 1.72 for D = 1 and D = 2, respectively&quot;.</p><p>11. l. 179: &quot;Within this range of scale factors&quot;. Within what range?</p><p>12. l 184-5: &quot;As suggested by Figure 2d, there is also a strong correlation between Fisher information and minimal decoding time again indicating a speed-accuracy trade-off.&quot; There's certainly a tradeoff between Fisher info and minimal decoding time, but, as mentioned in point 1, minimal decoding time isn't always a great measure. You should be up front about this.</p><p>13. The tables should be moved to the main text -- the parameters (especially the number of modules) are highly relevant. Or what would be even more useful would be to put the parameters in the figure captions.</p><p>14. Figure 5: by &quot;Gaussian pop.&quot; and &quot;Periodic pop.&quot; do you mean &quot;Single peaked&quot; and &quot;multi-peaked&quot;? If so, this should be clear.</p><p>15. l 303: &quot;Thus, minimal decoding time should set a bound on the number of features a population can jointly encode reliably.&quot; Very interesting prediction! Which you point out on lines 325-7: &quot;Our work gives a compelling reason to understand whether and how biological brains can reliably encode high-dimensional stimuli at behaviorally relevant time scales.&quot; But this should be quantified; see point 1.</p><p><italic>Reviewer #2 (Recommendations for the Authors):</italic></p><p>The paper makes a simple but important point. It is also remarkably well explained especially considering the complexity of the calculations. For once, I do not feel the need to make many suggestions for improvement.</p><p>One point that could be better addressed regards the justification of speed of encoding based on data on sensory cortex. The introduction seems heavy on the visual system based on the results of Thorpe and colleagues. In the discussion (lines 288-289) the authors point out (though the sentence is not very strongly linked to the overall text flow) that the first few spikes carry significant information in the visual and olfactory system. While the point of raising the importance f speed of encoding in sensory areas is valid, I am not sure that it should privilege the visual system or the visual and olfactory system. I think that somatosensory modalities encode information faster and earlier than visual modalities, including with regard to the prominence of first spikes (see e.g. Panzeri et al. Neuron 2001). If anything, visual cortical data show encoding in longer time scales. It would be nice to have a more precise introduction to and discussion of these topics to motivate this work and to evaluate its implications.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.84531.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>While this paper makes an extremely important point, one that should definitely be communicated to the broader community, in our opinion it suffers from two (relatively easily fixable) problems:</p><p>I. Unless one is an expert, it's very hard to extract why multi-peaked tuning curves lead to catastrophic errors.</p><p>II. It's difficult to figure out under what circumstances multi-peaked tuning curves are bad. This is important, because there are a lot of neurons in sensory cortex, and one would like to know whether periodic tuning curves are really a bad idea there.</p><p>And here are the fixes:</p><p>I. Figure 1c seems like a missed opportunity to explain what's really going on, which is that on any particular trial the positions of the peaks of the log likelihood can shift in both phase and amplitude (with phase being more important). The reason it's a missed opportunity is that Figure 1c shows the average log likelihood, which makes it hard to understands why there are catastrophic errors. It would really help if Figure 1c were expanded into its own large figure, with sample log likelihoods showing catastrophic errors for multi-peaked tuning curves but not for single-peaked ones. You could also indicate why, when multi-peaked tuning curves do give the right answer, the error tends to be small.</p></disp-quote><p>We thank the reviewer for this suggestion. We have now split the first figure into two.</p><p>In the new Figure 1, we provide an intuitive explanation of local vs catastrophic errors and single-peaked / periodic tuning curves. We have also added smaller panels to illustrate how the distribution of errors changes with decoding time (using a simulated single-peaked population).</p><p>The new Figure 2 shows sampled likelihoods for 3 different populations. We hope this provides some intuitive understanding of the phase shifts. Unfortunately, it proved difficult not to normalize the “height” of each module’s likelihood as they can differ by several orders of magnitude across the modules. However, due to the multiplication, the peak likelihood values can (approximately) be disregarded in the ML-decoding. Lastly, we have also added more simulation points (scale factors) compared to what we had in the earlier version of the figure (see panels d-e).</p><disp-quote content-type="editor-comment"><p>II. What the reader really wants to know is: would sensory processing in real brains be more efficient if multi-peaked tuning curves were used? That's certainly hard to answer in all generality, but you could make a comparison between a code with single-peaked tuning curves and a _good_ code with multi-peaked tuning curves. Our guess is that a good code would have λ_1=1 and c around 0.5 (but not, of course, exactly 1/2; you could use the module ratio the grid cell people came up with -- we think 1/sqrt(2) -- although we doubt if it matters much). What would be great would be a relatively simple relation, possibly fitted empirically to simulations, that told us when multi-peaked tuning curves are better than single-peaked one, given the number of neurons, background and peak firing rates, and dimensionality. Of course, this may be impossible, but if so it's important to state that up front, so that people know how difficult this is.</p></disp-quote><p>We thank the reviewer for this comment and the suggestions. We agree, ideally such an expression would be useful. However, as you note it is a very challenging task due to the large parameter space (number of neurons, peak amplitude, ongoing background firing rate, width of tuning, stimulus dimensionality etc) and is beyond the scope of the present study. We have instead included a new figure (see Figure 7 in the manuscript) detailing the minimal decoding times for various choices of parameter values. We believe this gives an indication to how minimal decoding time scales with various parameters.</p><disp-quote content-type="editor-comment"><p>In addition, we have a number of comments, all designed to improve the paper. Feel free to disagree with any of them; we don't feel massively strongly about them. Also, if you implement them, no reason to provide a reply -- we're sensitive to the fact that replies to the reviewer are becoming longer than the paper!</p><p>Reviewer #1 (Recommendations for the authors):</p><p>1. When catastrophic errors are possible, we agree that it's very hard to find a good measure of error. RMS error clearly isn't very good. However, it's not clear minimal decoding time is any better, since it'd defined in terms of RMS error. Finding a good measure seems critical when comparing codes, given that Fisher info can change by 5 orders of magnitude while decoding time changes by only 1 (e.g., Figure 4d). Moreover, we could be wrong, but our intuition is that when λ_1=1, catastrophic errors aren't much of an issue. Is that correct? If so, time to threshold (defined to be time for the RMS error to be twice that predicted by the inverse of the Fisher info) could be a bad measure.</p><p>Here we don't have any really great suggestions. But you might try something like [&lt;(error)^k&gt;/((2k-1)!!)]^{1/k} for k larger than 2 and even (the factor of (2k-1)!!) makes this equal to the RMS error for Gaussian distributions. But other measures are possible.</p></disp-quote><p>We thank the reviewer for these questions, they greatly helped us devise some additional figures for explanation. In the following we provide a reply to each of the points raised by the reviewer.</p><p>i. All populations (even single-peaked) suffer from catastrophic errors when the decoding time is too short.We have added a panel showing this for single-peaked tuning, see Figure 1c-e.</p><p>ii. We acknowledge that the choice of measure for minimal decoding time is not a perfect measure, but wedo not agree that it is not better than only studying RMSE. We believe they all have their strengths and weaknesses. The choice of minimal decoding time criteria compares the empirical RMSE with the predicted RMSE if no catastrophic distortion is present (i.e., inverse of Fisher information). Thus, this measure does provide new information that neither RMSE nor Fisher information in themselves capture. We have highlighted this in points iv-v.</p><p>iii. Regarding the order of magnitude, we believe that although the minimal decoding time differs only onone order of magnitude, ecologically it could be more beneficial to reduce the decoding time with (say) 30 ms per neural population while still providing reasonable accuracy.</p><p>iv. Regarding catastrophic errors for λ_1 = 1, we have added a comparison between single-peakedtuning curves and periodic tuning curves (λ_1 = 1, and c = 1/1.44) using the optimal scale factor for a 2-dimensional stimulus (Figure 7 a-c). It clearly shows how large estimation errors occur in the periodic population even after the periodic population has lower MSE than the single-peaked. However, only the single-peaked population have approached the CR-bound. This provides an example of when RMSE and Fisher information alone can provide a possibly erroneous conclusion.</p><p>v. About minimal decoding time being the wrong measure, we have also added a supplementary figureusing an alternative definition of minimal decoding time – instead of comparing MSE with the CR-bound, we compared the entire distribution of empirical errors against the Gaussian distribution predicted by Fisher information. Using one-sided Kolmogorov-Smirnov (KS) tests, we gradually increased the decoding time until the empirical distribution could not be distinguished from the predicted distribution with a significance level of 0.05. To correct for multiple sequential hypothesis testing, we imposed a Bonferroni-type of correction, scaling the significance level with the number of so-far considered decoding times. I.e., 0.05 / j, where “j” is the j:th comparison. This correction does not seem to change the results significantly and it is comparable to the value without the correction. This alternative definition gives qualitatively similar results (see Figure 3 – —figure supplement 4). [See lines 269-274]</p><p>Thus, we believe that all measures, MSE, Fisher information and minimal decoding time, have their strengths and weaknesses – therefore we argue they should be considered together and not in isolation!</p><disp-quote content-type="editor-comment"><p>2. Are you using periodic boundary conditions? Tuning curves are clearly periodic, but decoding near the boundaries is a bit tricky. For instance, the ML estimator can put the decoded value outside the range [0, 1). This should be clarified.</p></disp-quote><p>Yes, thank you for catching this. We assume that the stimulus is periodic in the range [0,1) for precisely this reason. We have updated the manuscript to clarify this [Line 96-99].</p><disp-quote content-type="editor-comment"><p>3. It should be clear that the expression for Fisher info (Equation 3) applies when a_i=a and b=0.</p></disp-quote><p>Thank you for noticing this. We have specified it in the text [Line 110]</p><disp-quote content-type="editor-comment"><p>4. Figure 1a: it would be helpful to indicate the location of s_1 and s_2 in the top panel.</p></disp-quote><p>Thank you for noticing this. We have mentioned it in the figure.</p><disp-quote content-type="editor-comment"><p>Also, isn't Figure 1a a bit misleading? The problem isn't a small number of spikes; it's a phase shift in the log likelihood.</p></disp-quote><p>The catastrophic errors are not just a property of Bayesian estimators, such errors are observed for any non-local estimator. This type of illustration as shown in our Figure is well established as an intuitive explanation of these errors (see Shannon, Sreevivasan, Wernersson, etc.). When presenting this work, we have found that this illustration is very useful for providing some intuition about the role of catastrophic errors. Secondly, regarding the number of spikes and phase shift, our study suggests that the phase shift is related to the number of spikes (see Figure 3 – —figure supplement 5). If the number of spikes is small, then the ambiguousness of a multi-peaked code might not be resolved. Thus, these two concepts are highly linked.</p><disp-quote content-type="editor-comment"><p>5. l 99-100: &quot;For the largest mode of the joint likelihood function to also be centered close to the true stimulus condition, the distance δ between s^(1)_ML and s^(2)_ML must be smaller than between any other pair of modes of Q_1 and Q_2.&quot; We can see why this might be reasonable, but it's not totally obvious that the distance between the modes is the only thing that matters. This needs to be shown.</p></disp-quote><p>We thank the reviewer for the suggestion. We have clarified this in the revised manuscript. See the new text in the appendix with a reference to it in the method section, but it is (of course) an approximation. [line 574-577 and Appendix 3]</p><disp-quote content-type="editor-comment"><p>6. l 100-101: &quot;Thus, to avoid catastrophic errors, δ must be smaller than some largest allowed distance δ* (see Methods for calculation of δ*).&quot; This makes it seems like δ* is something complicated. But in fact it's exactly half the smallest distance between any other pair of modes. Why not say so?</p></disp-quote><p>Strictly speaking δ* is not half the distance of any other pair of peaks.\δ* depends on \δ_{0,0} (see equations 11-16). It is unfortunately not easy to describe it in words.</p><disp-quote content-type="editor-comment"><p>7. l 120-1: &quot;estimates can cause catastrophic shifts in the joint likelihood function. For single-peaked tuning curves (λ_1 = 1), however, only small scale factors c can pose such problems.&quot; Should &quot;For single-peaked tuning curves&quot; be &quot;When the first mode has a single peak&quot;. If not, we're lost.</p></disp-quote><p>Yes, we agree with the reviewer. We have, corrected this [see Line 183]</p><disp-quote content-type="editor-comment"><p>8. l 128: &quot;Furthermore, only populations with unambiguous codes over the stimulus interval were included [22].&quot; Can't parse.</p></disp-quote><p>We have added a clarification that the only requirement is that c is not ½, ⅓, ¼ etc. [see Lines 196-197]</p><disp-quote content-type="editor-comment"><p>9. Equation 8 seems unlikely to be correct, given that it doesn't depend on c, which we know is critical (as shown in Figure 1e). However, if you do keep it, it would be helpful to express it in terms of the average firing rate. If you do that, lots of terms go away.</p></disp-quote><p>Equation 8 is correct, we clarified that it is sample averages and that the scale factor is implicitly defined within this average. We also added the suggested change, but as this is (strictly speaking) only true for integer number of peaks – we opted to add it as an approximate equation. If not integer peaks, the average firing rate is not exactly this expression for homogeneous amplitudes a_i = a. As it turns out in simulations, though, it is approximately true. [See lines 222-225]</p><disp-quote content-type="editor-comment"><p>10. Figure caption 2c: &quot;colored lines show the estimated minimal decoding time from simulations and the black lines show the fitted theoretical predictions&quot;. Presumably the description of the fitted lines was given on on l. 178. However, we can't tell from this description what you actually did. Equations are needed.</p><p>And presumably this also comes up on l. 211: &quot;ratios of fitted regressors K1 were approximately 1.69 and 1.72 for D = 1 and D = 2, respectively&quot;.</p></disp-quote><p>We have added equation references for this. [Line 259]</p><disp-quote content-type="editor-comment"><p>11. l. 179: &quot;Within this range of scale factors&quot;. Within what range?</p></disp-quote><p>We have changed the text to “Within the simulated range of scale factors” [Line 259]</p><disp-quote content-type="editor-comment"><p>12. l 184-5: &quot;As suggested by Figure 2d, there is also a strong correlation between Fisher information and minimal decoding time again indicating a speed-accuracy trade-off.&quot; There's certainly a tradeoff between Fisher info and minimal decoding time, but, as mentioned in point 1, minimal decoding time isn't always a great measure. You should be up front about this.</p></disp-quote><p>See previous comments.</p><disp-quote content-type="editor-comment"><p>13. The tables should be moved to the main text -- the parameters (especially the number of modules) are highly relevant. Or what would be even more useful would be to put the parameters in the figure captions.</p></disp-quote><p>Thank you for this suggestion, we have done so for Figures 1-4. For the spiking model, we have not included any equations in the result section and therefore we are not sure adding the parameters would make sense. Therefore, we kept the tables in the method section for Figures 5-6.</p><disp-quote content-type="editor-comment"><p>14. Figure 5: by &quot;Gaussian pop.&quot; and &quot;Periodic pop.&quot; do you mean &quot;Single peaked&quot; and &quot;multi-peaked&quot;? If so, this should be clear.</p></disp-quote><p>Thank you for catching this oversight. We have corrected this. See Figures 5-6</p><disp-quote content-type="editor-comment"><p>15. l 303: &quot;Thus, minimal decoding time should set a bound on the number of features a population can jointly encode reliably.&quot; Very interesting prediction! Which you point out on lines 325-7: &quot;Our work gives a compelling reason to understand whether and how biological brains can reliably encode high-dimensional stimuli at behaviorally relevant time scales.&quot; But this should be quantified; see point 1.</p></disp-quote><p>We thank the review for this comment. We hope the new Figure 7 will clarify this.</p><disp-quote content-type="editor-comment"><p>Reviewer #2 (Recommendations for the Authors):</p><p>The paper makes a simple but important point. It is also remarkably well explained especially considering the complexity of the calculations. For once, I do not feel the need to make many suggestions for improvement.</p><p>One point that could be better addressed regards the justification of speed of encoding based on data on sensory cortex. The introduction seems heavy on the visual system based on the results of Thorpe and colleagues. In the discussion (lines 288-289) the authors point out (though the sentence is not very strongly linked to the overall text flow) that the first few spikes carry significant information in the visual and olfactory system. While the point of raising the importance f speed of encoding in sensory areas is valid, I am not sure that it should privilege the visual system or the visual and olfactory system. I think that somatosensory modalities encode information faster and earlier than visual modalities, including with regard to the prominence of first spikes (see e.g. Panzeri et al. Neuron 2001). If anything, visual cortical data show encoding in longer time scales. It would be nice to have a more precise introduction to and discussion of these topics to motivate this work and to evaluate its implications.</p></disp-quote><p>Thank you, this is an important point. We agree that sensory modalities ought to have similar constraints, and might operate on even faster time scales. Our results might also be applicable outside of the visual areas, too. We focused on early visual processing due to the established smooth single-peaked tuning and the (often) periodic sensory features (e.g., orientation and color). For other modalities, we are not sure the tuning is continuous (e.g., odor) or periodic (e.g., somatosensory stimuli). All the simulations assumed periodic stimuli, however, we do not believe the periodic stimulus is of great importance for our results. For discrete stimuli, catastrophic errors can also occur – but the calculations made here assumed continuous variables. Extending this work to discrete stimulus points is an interesting direction.</p><p>We have expanded more on the applicability outside of the visual area in the discussion. [Lines 411, 446-450].</p></body></sub-article></article>