<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">106387</article-id><article-id pub-id-type="doi">10.7554/eLife.106387</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.106387.4</article-id><article-version article-version-type="publication-state">version of record</article-version><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Age and learning shapes sound representations in auditory cortex during adolescence</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Praegel</surname><given-names>Benedikt</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0009-0006-8253-9625</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Chen</surname><given-names>Feng</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8645-7356</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Dym</surname><given-names>Adria</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Lavi-Rudel</surname><given-names>Amichai</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author"><name><surname>Druckmann</surname><given-names>Shaul</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Mizrahi</surname><given-names>Adi</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-1743-6754</contrib-id><email>mizrahi.adi@mail.huji.ac.il</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>The Edmond and Lily Safra Center for Brain Sciences</institution><addr-line><named-content content-type="city">Jerusalem</named-content></addr-line><country>Israel</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03qxff017</institution-id><institution>Department of Neurobiology, The Institute of Life Sciences, The Hebrew University of Jerusalem</institution></institution-wrap><addr-line><named-content content-type="city">Jerusalem</named-content></addr-line><country>Israel</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00f54p054</institution-id><institution>Department of Neurobiology, Stanford University</institution></institution-wrap><addr-line><named-content content-type="city">Stanford</named-content></addr-line><country>United States</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00f54p054</institution-id><institution>Department of Applied Physics, Stanford University</institution></institution-wrap><addr-line><named-content content-type="city">Stanford</named-content></addr-line><country>United States</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00f54p054</institution-id><institution>Department of Psychiatry and Behavioral Sciences, Stanford University</institution></institution-wrap><addr-line><named-content content-type="city">Stanford</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Bathellier</surname><given-names>Brice</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00675rp98</institution-id><institution>Centre National pour la Recherche Scientifique et Technique (CNRST)</institution></institution-wrap><country>France</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>13</day><month>10</month><year>2025</year></pub-date><volume>14</volume><elocation-id>RP106387</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2025-02-12"><day>12</day><month>02</month><year>2025</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2025-02-06"><day>06</day><month>02</month><year>2025</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2025.02.03.636101"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-03-31"><day>31</day><month>03</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.106387.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-07-15"><day>15</day><month>07</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.106387.2"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2025-08-21"><day>21</day><month>08</month><year>2025</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.106387.3"/></event></pub-history><permissions><copyright-statement>© 2025, Praegel et al</copyright-statement><copyright-year>2025</copyright-year><copyright-holder>Praegel et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-106387-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-106387-figures-v1.pdf"/><abstract><p>Adolescence is a developmental period characterized by heightened plasticity. Yet, how ongoing development affects sensory processing and cognitive function is unclear. We investigated how adolescent (postnatal day 20–42) and adult (postnatal day 60–82) mice differ in performance on a pure tone Go/No-Go auditory discrimination task of varying difficulty. Using dense electrophysiological recordings, we measured spiking activity at single neuron resolution in the auditory cortex while mice were engaged in the task. As compared to adults, adolescent mice showed lower auditory discrimination performance in a difficult task. This difference in performance was due to higher response variability and weaker cognitive control expressed as higher lick bias. Adolescent and adult neuronal responses differed only slightly in representations of pure tones when measured outside the context of learning and the task. However, cortical representations after learning within the context of the task were markedly different. We found differences in stimulus- and choice-related activity at the single neuron level representations, as well as lower population-level decoding of the difficult task in adolescents. Overall, cortical decoding in adolescents was lower and slower, especially for difficult sound discrimination, reflecting immature cortical representations of sounds and choices. Notably, we found age-related differences, which were more pronounced after learning, reflecting the combined impact of age and learning. Our findings highlight distinct neurophysiological and behavioral profiles in adolescence, underscoring the ongoing development of cognitive control mechanisms and cortical plasticity during this sensitive developmental period.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>adolescence</kwd><kwd>auditory cortex</kwd><kwd>auditory learning</kwd><kwd>neuropixels</kwd><kwd>neuronal coding</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Mouse</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00j8z2m73</institution-id><institution>United States-Israel Binational Science Foundation</institution></institution-wrap></funding-source><award-id>2021776</award-id><principal-award-recipient><name><surname>Druckmann</surname><given-names>Shaul</given-names></name><name><surname>Mizrahi</surname><given-names>Adi</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>RO1 DC020874-01</award-id><principal-award-recipient><name><surname>Druckmann</surname><given-names>Shaul</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Weaker performance in adolescent mice arises from immature cortical representations and cognitive bias, linking developmental changes in behavior with underlying neural coding.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Adolescence is a developmental stage characterized by the continued refinement of perception and cognition. During this period, the brain is highly sensitive to environmental influences, making it particularly vulnerable to both negative experiences, such as substance abuse, and positive influences, such as supportive relationships (<xref ref-type="bibr" rid="bib30">Hoskins, 2014</xref>; <xref ref-type="bibr" rid="bib27">Hawkins et al., 1992</xref>). While the adolescent brain exhibits greater plasticity compared to adults (<xref ref-type="bibr" rid="bib20">Fuhrmann et al., 2015</xref>), the extent to which specific sensory and cognitive traits are fully developed versus those that remain malleable is still debated. For instance, some studies on sensory perception have demonstrated that adolescent learning is slower and more variable (<xref ref-type="bibr" rid="bib9">Caras and Sanes, 2019</xref>; <xref ref-type="bibr" rid="bib31">Huyck and Wright, 2011</xref>), while others have found that adolescents learn faster in novel contexts, such as reversal learning (<xref ref-type="bibr" rid="bib33">Johnson and Wilbrecht, 2011</xref>). Certain traits, such as cognitive flexibility, are more pronounced in adolescents compared to adults, whereas other behaviors, such as impulsive control, are still immature (<xref ref-type="bibr" rid="bib55">Romer, 2010</xref>). Furthermore, results across studies that target sensory or cognitive traits are often inconsistent (<xref ref-type="bibr" rid="bib71">Wilbrecht and Davidow, 2024</xref>). Therefore, understanding the degree to which sensory and cognitive functions have matured, and the underlying brain mechanisms that support them, remain an ongoing challenge.</p><p>A key concept in brain development is that of critical periods (CPs), which are specific time windows during which the brain’s neural circuits are highly plastic and particularly sensitive to external experiences (<xref ref-type="bibr" rid="bib29">Hensch, 2005</xref>; <xref ref-type="bibr" rid="bib28">Hensch, 2004</xref>). The early postnatal development of sensory cortices provides classical examples of this phenomenon. In mice, neurons in the visual cortex undergo several CPs such as those for orientation selectivity, direction selectivity, and ocular dominance. During the CP, which occurs in different developmental time windows for different functional attributes, visual experience shapes the specific neuronal attribute to a long-term state (e.g. ocular dominance reaches its adult form, <xref ref-type="bibr" rid="bib29">Hensch, 2005</xref>; <xref ref-type="bibr" rid="bib53">Reh et al., 2020</xref>). The CPs for simple neuronal features in primary sensory cortices are typically complete by the onset of puberty. In the auditory cortex (ACx) of mice, the CP for pure tone processing begins as early as postnatal day 12 (P12), shortly after the ear canals open, and closes by ~P15 (<xref ref-type="bibr" rid="bib40">Kral, 2013</xref>; <xref ref-type="bibr" rid="bib6">Barkat et al., 2011</xref>). Thus, the closure of the auditory CP to pure tones occurs before adolescence begins (<xref ref-type="bibr" rid="bib63">Sun et al., 2010</xref>; <xref ref-type="bibr" rid="bib73">Zhang et al., 2001</xref>). Yet, while some studies have found that simple neuronal properties in the ACx (like response properties to pure tones) are nearly mature by adolescence, others report continued maturation well beyond this developmental stage (<xref ref-type="bibr" rid="bib7">Bhumika et al., 2020</xref>; <xref ref-type="bibr" rid="bib48">Nakamura et al., 2020</xref>). For example, previous studies found that auditory learning and behavioral performance in auditory discrimination tasks involving amplitude modulation detection, as well as temporal interval discrimination tasks remain highly constrained during adolescence (<xref ref-type="bibr" rid="bib9">Caras and Sanes, 2019</xref>; <xref ref-type="bibr" rid="bib31">Huyck and Wright, 2011</xref>). In those tasks, ACx neurons in adolescents exhibit high neuronal variability and lower tone sensitivity as compared to adults (<xref ref-type="bibr" rid="bib9">Caras and Sanes, 2019</xref>).</p><p>The perspective shift from viewing development as involving a set of discrete CPs to a broader view of continuous development with multiple, overlapping, CPs that affect each other, calls for studies to test the extent of functional modulation in neuronal features after their CP ‘closes.’ Thus, although the CP for pure tone representation in the ACx ends by ~P15, we hypothesized that learning of pure tone discrimination would remain malleable in adolescence, because other perceptual features and particularly other cognitive features are still developing. Furthermore, it remains unclear how these features are expressed when measured in the context of active behavior. We measured cortical activity in the ACx of adolescent mice engaged in an auditory discrimination task involving pure tones. Our findings show that learning, behavior, and sound representations to pure tones in the ACx are not fully mature during adolescence.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Adult mice outperform adolescents on a difficult, but not an easy, auditory discrimination task of pure tones</title><p>To study learning and perceptual performance abilities, we trained and tested adolescent and adult mice on an auditory pure-tone discrimination Go/No-Go paradigm. For this purpose, we utilized an automated behavioral platform called the ‘Educage’ (<xref ref-type="fig" rid="fig1">Figure 1a</xref>; <xref ref-type="bibr" rid="bib45">Maor et al., 2020</xref>). We trained adolescent (n=15) and adult (n=15) mice from post-natal day 20 (P20)-P37 and P60-P77, respectively (<xref ref-type="fig" rid="fig1">Figure 1b</xref>). Following a tone association period (3 days; exposure to Go tones when mice enter the drinking port), mice learned to discriminate between two pure tones separated by 1 octave (7.07 kHz <italic>vs</italic> 14.14 kHz; <xref ref-type="fig" rid="fig1">Figure 1b–c</xref>, light blue; herein referred to as the ‘easy task’). After one week of training on the easy task (P23 to P30 in pre-adolescent mice and P63 to P70 in adult mice) mice were introduced to a second pure-tone pair, now separated by 0.25 octave (9.2 kHz <italic>vs</italic> 10.9 kHz; <xref ref-type="fig" rid="fig1">Figure 1b–c</xref>, dark blue; herein referred to as the ‘hard task’). We completed the experiment after 1 week of learning on the easy and hard tasks simultaneously (i.e. at P37 for adolescents and P77 for adults). During the whole period of training, we also presented mice with low-probability, unrewarded ‘probe’ trials of pure tones spanning the range of learned stimuli (<xref ref-type="fig" rid="fig1">Figure 1c</xref>, gray). <xref ref-type="fig" rid="fig1">Figure 1d</xref> shows example learning curves (of d’) from one adolescent and one adult mouse over the 14 day course of tone discrimination. Adolescents and adults learned the procedure of the task similarly well, as measured by the number of trials it took mice to reach a discriminability threshold of d’ value ≥1 (<xref ref-type="fig" rid="fig1">Figure 1e</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Adolescent mice exhibit lower performance during self-initiated auditory learning in the ‘Educage’.</title><p>(<bold>A</bold>) Schematic model of the ‘Educage’ (left), the trial structure and trial types (FA, false alarm; CR, correct reject). Created with <ext-link ext-link-type="uri" xlink:href="https://biorender.com/t3ce8pk">Biorender.com</ext-link>. (<bold>B</bold>) Experimental timeline. Total training time was 21 days (±2). (<bold>C</bold>) The sounds used for training. Light blue: easy task; Dark blue: hard task; Gray: catch-trials. (<bold>D</bold>) Learning curve examples. Adolescent mouse left, (P20–to–P37); adult mouse right, (P60–to–P77). Vertical dashed lines indicate the easy-hard transition. Horizontal line is d'=1. (<bold>E</bold>) Number of trials to reach threshold (d’ ≥ 1; adolescents, n=15; adults, n=15; z=–0.1659; p=0.8682, two-sample Wilcoxon rank sum test). (<bold>F</bold>) Discriminability (<bold>d’</bold>) of the easy task in adolescent mice at P30 (gray; n=15, d’=2.0001 ± 0.1791; # trials = 8317 ± 712) and adult mice at P70 (black; n=15, d’=2.1986 ± 0.2441; # trials = 13229 ± 514, top: marked by the arrowhead). Dashed lines: mean trials per group (t-stat=–5.6314, df = 28, p=4.9566e-06, two-sample independent t-test, solid vertical line), and mean d’ per age group (z=0.2074; p=0.8357, two-sample Wilcoxon rank sum test, solid horizontal line) (<bold>G</bold>) Change in discriminability (Δd’) of the easy task before and after the introduction of the hard task (Top: arrowheads; left: adolescent, signed rank = 14, p=0.0067; right: adult, signed rank = 14, p=0.1514, one-sample Wilcoxon signed rank test; Δd’ between adult and adolescent mice: z=–2.0739; p=0.0381, two-sample Wilcoxon rank sum test) (<bold>H</bold>) Same as ‘G’ for the first 100 and last 100 trials of the experiment in the easy task (adolescent signed rank = 120, p=6.1035e-05; adult signed rank = 120, p=6.1035e-05, one-sample Wilcoxon signed rank test; Δd’ between adult and adolescent mice: z=–1.0370; p=0.2998, two-sample Wilcoxon rank sum test). (<bold>I</bold>) Same as ‘F’ for the hard task (adolescent-gray; n=15, d’=1.1895 ± 0.1783; # trials = 4163 ± 297; adult-black; n=15, d’=1.8342 ± 0.1743; # trials = 4102 ± 475; mean trials per group: t-stat=0.1306, df = 28, p=0.8970, two-sample independent t-test, solid vertical line; mean d’ per group: z=–2.2398; p=0.0251, two-sample Wilcoxon rank sum test, solid horizontal line). (<bold>J</bold>) Same as ‘G’ for the hard task. (adolescent signed rank = 73, p=0.4887; adult signed rank = 114, p=8.5449e-04, one-sample Wilcoxon signed rank test; Δd’ between adult and adolescent mice: z=–1.9495; p=0.0512, two-sample Wilcoxon rank sum test).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106387-fig1-v1.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title><italic>Behavioral criteria of auditory learning</italic>.</title><p>(<bold>A</bold>) Learning curves per mouse throughout the experiment (n=5 adolescents, n=4 adults). (<bold>B</bold>) Discriminability of novice (Nov.; first 100 trials) compared to expert (Exp.; last 100 trials) mice in the adolescent and adult groups (Novice vs Expert — Adolescents, p=0.0625; Adults, p=0.0625, Wilcoxon sign ranked test after Bonferroni correction; Adolescents vs Adults — Novice, p=0.4444, Expert, p=0.5476, Wilcoxon rank sum test after Bonferroni correction). (<bold>C</bold>) Discriminability (<bold>d’</bold>) of the easy task at the minimal number of trials (5087 trials) shared between all mice (z=–1.0370; p=0.2998, two-sample Wilcoxon rank sum test). (<bold>D</bold>) Discriminability (<bold>d’</bold>) of the easy task at the mean number of trials of adolescent mice (8317 trials) shared between all mice (n=15 per group; z=0.9125; p=0.3615, two-sample Wilcoxon rank sum test). (<bold>E</bold>) Same as A. but for the mean number of trials (13229 trials) of adult mice (adolescent n=4; adult n=15; z=0.9125; p=0.5304, two-sample Wilcoxon rank sum test).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106387-fig1-figsupp1-v1.tif"/></fig></fig-group><p>We tested for differences in auditory discrimination by comparing the performance of mice at different epochs along training. First, by the end of the first week of training, all mice performed above the discrimination threshold (<xref ref-type="fig" rid="fig1">Figure 1f</xref>). Although adolescent mice performed significantly fewer trials during the first week of training (<xref ref-type="fig" rid="fig1">Figure 1f</xref>; vertical lines: mean # of trials), there was no significant difference between the performance of adult and adolescent mice at the end of the first week (<xref ref-type="fig" rid="fig1">Figure 1f</xref>; horizontal lines: mean d’; d’ calculated from the last 100 trials). Following one week of training on the easy task, we introduced the second pair of pure tones (<xref ref-type="fig" rid="fig1">Figure 1b</xref>; ‘Easy + Hard’). Immediately after introducing the hard pair, the performance of adolescent mice on the easy task dropped, while those of adults remained unaffected (<xref ref-type="fig" rid="fig1">Figure 1g</xref>). During the second week of training, adolescents regained their high d’ values on the easy task, such that by the end of the experiment both groups had similarly high performance on the easy task (<xref ref-type="fig" rid="fig1">Figure 1h</xref>).</p><p>We then compared how mice learned the hard task during the second week while training on both the easy and hard tasks simultaneously. While both groups now performed a similar number of trials (<xref ref-type="fig" rid="fig1">Figure 1i</xref>, vertical lines: mean # of trials), adult mice outperformed adolescent mice on the hard task (<xref ref-type="fig" rid="fig1">Figure 1i</xref>, horizontal lines: mean d’), suggesting that adolescents struggled with this harder level of discrimination. Indeed, on average, adolescent mice did not improve on the hard task during the second week of training (<xref ref-type="fig" rid="fig1">Figure 1j</xref>, ‘adolescent’). Adults, on the other hand, improved their performance on the hard task during the second week (<xref ref-type="fig" rid="fig1">Figure 1j</xref>, ‘adult’). Notably, neither group could learn the hard task if it was not preceded by the easy task (<xref ref-type="fig" rid="fig1">Figure 1</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1, b</xref>).</p><p>Each mouse performed a unique number of trials, as these were initiated by the mice spontaneously. As noted above, pre-adolescent mice performed fewer trials/day as compared to adults but, notably, only during the first week of training (mean ± STE: adolescents, 8317±712 trials, adults 13229±514 trials, t-stat=–5.6314, df = 28, p=4.9566e-06, two-sample independent t-test). Still, this difference raises the question whether the different number of trials affected our conclusions from the first week of training. Thus, to evaluate the possible connection between the number of trials and performance in our data, we carried out several analyses. First, we found that the number of trials and d’ were not correlated in either age-group during the first week of discrimination on the easy task (Pearson-r; adolescent: <italic>r</italic>=0.1880, p=0.5023; adult: <italic>r</italic>=–0.0730, p=0.7959), nor on the second week of discrimination on both the easy and the hard task (Pearson-r; adolescent: <italic>r</italic>=0. 2264, p=0. 4171; adult: <italic>r</italic>=0. 0194, p=0. 9454). Second, we compared performance at three time points along the task with reference to times with shared number of trials: (1) evaluating d’ after the minimal number of trials performed by all mice during the first week of training, and (2) evaluating d’ at the mean number of trials of each group as a reference. We found no significant differences between adolescents and adults in all comparisons (<xref ref-type="fig" rid="fig1">Figure 1</xref>, <xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1c-e</xref>). Additionally, we found no significant differences between males and females, nor among experiments that had different numbers of co-housed mice in the Educage (<xref ref-type="table" rid="table1">Table 1</xref>). Taken together, despite the different absolute number of trials during the first week, we conclude that adolescents and adults learned the easy task equally quickly and effectively. The central difference between the age groups was in their ability to learn the hard task during the second week, when adults outperformed adolescents.</p><table-wrap id="table1" position="float"><label>Table 1.</label><caption><title><italic>Behavioral differences between adolescent and adult mice are age-, but not sex-related</italic>.</title><p>Fixed effects of age and sex, and the random effects of co-housing in the ‘Educage’ on the discriminability (mean d’ of the last 100 trials of the easy and hard task to avoid pseudo replication) of all mice (Number of observations=30, Fixed effects coefficients = 3, Random effects coefficients = 7, Covariance parameters = 2). Coefficient estimates, STE, T-statistic, degrees of freedom, p-values (adjusted for multiple comparisons with the Bonferroni method) and the lower and upper Confidence Interval (95%). The model includes random effects coefficients of the Cage ID in each group of co-housed mice (7 cages in total; see <italic>methods,</italic> equation 7). Model structure: discriminability(d’)~age + sex + (1|cage ID).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Fixed effects</th><th align="left" valign="bottom">Estimate</th><th align="left" valign="bottom">STE</th><th align="left" valign="bottom">T-statistic</th><th align="left" valign="bottom">DF</th><th align="left" valign="bottom">P-value</th><th align="left" valign="bottom">CI (lower)</th><th align="left" valign="bottom">CI (upper)</th></tr></thead><tbody><tr><td align="left" valign="bottom">Intercept</td><td align="left" valign="bottom">1.6001</td><td align="left" valign="bottom">0.2312</td><td align="left" valign="bottom">6.9222</td><td align="left" valign="bottom">27</td><td align="left" valign="bottom"><bold>3.8798e-07</bold></td><td align="left" valign="bottom">1.1258</td><td align="left" valign="bottom">2.0744</td></tr><tr><td align="left" valign="bottom">Age</td><td align="left" valign="bottom">0.5994</td><td align="left" valign="bottom">0.2266</td><td align="left" valign="bottom">2.6457</td><td align="left" valign="bottom">27</td><td align="left" valign="bottom">0.0269</td><td align="left" valign="bottom">0.1346</td><td align="left" valign="bottom">1.0643</td></tr><tr><td align="left" valign="bottom">Sex</td><td align="left" valign="bottom">–0.0428</td><td align="left" valign="bottom">0.2476</td><td align="left" valign="bottom">–0.1729</td><td align="left" valign="bottom">27</td><td align="left" valign="bottom">0.9999</td><td align="left" valign="bottom">–0.5509</td><td align="left" valign="bottom">0.4653</td></tr></tbody></table></table-wrap></sec><sec id="s2-2"><title>Adolescents have higher lick bias and higher behavioral variability</title><p>We next asked what perceptual and/or cognitive aspect of behavior is different among the age groups. We plotted psychometric curves based on both learned and probe trials from the last 2000 trials of the experiment (<xref ref-type="fig" rid="fig2">Figure 2a</xref>). The false alarm rate but not the hit rate of adolescent mice was significantly higher as compared to adults (<xref ref-type="fig" rid="fig2">Figure 2b</xref>). To calculate the decision boundary of mice and their perceptual sensitivity we normalized the psychometric curves of each mouse using a unity-based normalization and sigmoid fitting (<xref ref-type="fig" rid="fig2">Figure 2c</xref>). We found no differences in the decision boundary or slopes of the curves, suggesting that perceptual sensitivity is not different between the groups (<xref ref-type="fig" rid="fig2">Figure 2c</xref>). To test whether the differences arise from a cognitive effect (e.g. lick bias), we calculated the decision threshold as the maximal lick bias, also known as the criterion bias (C-bias). C-bias reflects the tendency to respond in a liberal (i.e. negative C-bias) or a conservative (i.e. positive C-bias) manner to the sounds during the task. C-bias was negative for both groups, yet significantly lower in adolescents, suggesting that their cognitive ability to withhold licking is inferior to that of adults (<xref ref-type="fig" rid="fig2">Figure 2d</xref>).</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Adolescent mice exhibit lower performance in the head-fixed discrimination task.</title><p>(<bold>A</bold>) Experimental timeline of training followed by recordings. (<bold>B</bold>) Trial structure during the recording. Solid lines indicate the tone period. Dashed lines show the reward or punishment delay (0.6 s), and the response window (2 sec). (<bold>C</bold>) Example session. Licks (gray ticks) and trial outcomes (hit = green, false alarm = yellow, miss = red, and correct reject = blue) across all trials in one recording session. (<bold>D</bold>) Discriminability during training sessions for the easy task (light blue) and hard task (dark blue). (<bold>E</bold>) Change in d’ after the introduction of the hard task (last 100 trials of the last session of the easy task compared to last 100 trials of the first hard session; adolescent: sign-rank=1, p=0.0625; adult: sign-rank=10, p=0.9998; rank-sum=14, p=0.0381, two-sample Wilcoxon rank sum test). (<bold>F</bold>) Expert d’ of the last 100 trials during the last training session of the easy task (rank-sum=21, p=0.1255, two-sample Wilcoxon rank sum test). (<bold>G</bold>) Same as ‘F,’ but for the hard task (rank-sum=17, p=0.0173, two-sample Wilcoxon rank sum test). (<bold>H</bold>) Behavioral performance (average d’ of the easy and the hard task) per mouse during recording sessions for adolescents (n=13, left) and adults (n=14, right; trials per recording: adolescent: 340.5385±45.0650; adult: 431.1429±30.3367; independent t-test, t-statistic=–203.7581, p=0.1116). (<bold>I</bold>) Same as ‘H’ but only for the first 148 trials. The color bar shows the p-values between the groups. (<bold>J</bold>) Average cumulative licks per trial in adolescents (dashed-line) and adults (solid-line) from –200 ms before tone-onset until the reward or punishment delay, 500 ms after tone-offset. (<bold>K</bold>) Lick latency per trial for adolescent (left) and adult (right) groups during electrophysiological recordings (LME statistics are shown in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). (<bold>J</bold>) Same as ‘K’ for the Lick count.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106387-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Inter-trial interval after different trial outcomes.</title><p>(<bold>A</bold>) Average inter-trial interval (ITI) per mouse to the next trial after a previous hit (z=1.6176; p=0.1057, two-sample Wilcoxon rank sum test). (<bold>B</bold>) Same as A. after a previous miss hit (z=0.0830; p=0.9339, two-sample Wilcoxon rank sum test). (<bold>C</bold>) Same as A. after a previous false alarm hit (z=–3.9823; p=6.8241e-05, two-sample Wilcoxon rank sum test). (<bold>D</bold>) Same A. after a previous correct reject hit (z=0.3733; p=0.7089, two-sample Wilcoxon rank sum test).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106387-fig2-figsupp1-v1.tif"/></fig></fig-group><p>Given that adolescents and adults show different dynamics in their performance along the task (<xref ref-type="fig" rid="fig1">Figure 1</xref>), we tested whether the differences we found in the lick bias are consistent at different times along the task. To normalize for different numbers of trials in each mouse, we divided their training episodes into the first and last tertiles during the first week and second week of training separately (<xref ref-type="fig" rid="fig2">Figure 2e</xref>). The maximal lick bias was significantly higher in adolescents in all but the very first training episode, when mice learned the procedure (<xref ref-type="fig" rid="fig2">Figure 2f</xref>). These data highlight the general cognitive difficulty of adolescents to withhold licking during the task.</p><p>The cognitive sensitivity of adolescents was further evident when their performance dropped right after the task was switched from ‘easy only’ to ‘easy +hard’ (<xref ref-type="fig" rid="fig1">Figure 1f</xref>). The lick bias of adolescent mice became significantly stronger after the introduction of the hard task (<xref ref-type="fig" rid="fig2">Figure 2g</xref>). In contrast, the lick bias of adult mice remained stable (<xref ref-type="fig" rid="fig2">Figure 2g</xref>). These data further suggest that this cognitive trait (i.e. to withhold licking) has not yet matured in the young mice. To test if the lick bias was stimulus-related or a result of general impulsivity, we also compared the inter-trial interval (ITI) after different trial outcomes, and observed similar ITIs across groups, except for false alarm trials, where adolescents initiated the trials significantly faster (<xref ref-type="fig" rid="fig2">Figure 2</xref>, <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1</xref>). This, too, suggests that adolescent mice exhibit more impulsive responses following punishments (or alternatively are less impacted by punishments), contributing to their immature lick bias.</p><p>Prior studies have shown that a dominant feature of adolescent behavior is that it is more variable compared to adults (<xref ref-type="bibr" rid="bib9">Caras and Sanes, 2019</xref>). To examine behavioral variability in our data, we calculated the coefficient of variation (CV) of the discriminability (d’) for each mouse across training. While there was no significant difference in d’ variability when training on the easy task during the first week of training (<xref ref-type="fig" rid="fig2">Figure 2h</xref>), adult mice showed significantly lower variability during the second week of training while training on the ‘easy +hard’ versions of the task (<xref ref-type="fig" rid="fig2">Figure 2i and j</xref>). Thus, adolescent learning and behavior are characterized by both lower response inhibition and higher variability, particularly during the second week when the task involved more challenging discrimination for the younger mice.</p></sec><sec id="s2-3"><title>Adult mice outperform adolescent mice on a head-fixed discrimination task</title><p>To enable electrophysiological recordings during expert task performance, we trained adolescent (n=5) and adult (n=6) mice on a head-fixed learning paradigm, using a similar protocol as in the Educage (<xref ref-type="fig" rid="fig3">Figure 3a</xref>). In the head-fixed protocol, water access was limited to training sessions. Head-fixed mice were trained to lick after a 100 ms tone and were rewarded (with water) or punished (by a 2 s white noise) only after a 600 ms delay (<xref ref-type="fig" rid="fig3">Figure 3b</xref>). Each session was concluded after the mice became satiated and stopped licking. Water supply was limited to 0.0125 ml per day per gram of body weight, and mice that did not consume this amount were compensated after training (see Methods; <xref ref-type="fig" rid="fig3">Figure 3c</xref> shows an example session from one mouse). The number of trials per training session was significantly lower in adolescents (mean ±STE: adolescents: 410±35, adults: 580±37 t-statistic=–27.9855, p=0.0012, independent two-sample t-test). However, the number of sessions to reach the behavioral threshold (d’ ≥ 1 in the easy task) was not significantly different between adolescents and adults (mean ±STE: adolescents: 3.7±0.8, adults: 3.8±0.7; t-statistic = - 0.8531, p=0.1971, independent two-sample t-test, <xref ref-type="fig" rid="fig3">Figure 3d</xref> shows all learning curves). Similar to learning in the Educage, adolescent performance (but not that of adults) decreased after we introduced the hard task (<xref ref-type="fig" rid="fig3">Figure 3e</xref>). Another similarity between the head-fixed and Educage versions of the task was that we found no significant differences between adolescents and adults in the performance of the easy task (<xref ref-type="fig" rid="fig3">Figure 3f</xref>), and that adults outperformed adolescents on the hard discrimination (<xref ref-type="fig" rid="fig3">Figure 3g</xref>). Also similar to the behavior in the Educage, lick responses of adolescent mice were generally higher (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>), and adolescents exhibited a stronger lick bias (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1b</xref>). In line with this result, in the head-fixed task, we found higher impulsiveness in the proportion and the number of licks during the inter-trial intervals after FA trials in adolescents (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1c, d</xref>).</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Adolescent mice exhibit lower performance in the head-fixed discrimination task.</title><p>(<bold>A</bold>) Experimental timeline of training followed by recordings. Created with <ext-link ext-link-type="uri" xlink:href="https://biorender.com/qbe14qe">Biorender.com</ext-link>. (<bold>B</bold>) Trial structure during the recording. Solid lines indicate the tone period. Dashed lines show the reward or punishment delay (0.6 s), and the response window (2 s). (<bold>C</bold>) Example session. Licks (gray ticks) and trial outcomes (hit = green, false alarm = yellow, miss = red and correct reject = blue) across all trials in one recording session. (<bold>D</bold>) Discriminability during training sessions for the easy task (light blue) and hard task (dark blue). (<bold>E</bold>). Change in d’ after the introduction of the hard task (last 100 trials of the last session of the easy task compared to last 100 trials of the first hard session; adolescent: sign-rank=1, p=0.0625; adult: sign-rank=10, p=0.9998; rank-sum=14; p=0.0381, two-sample Wilcoxon rank sum test). (<bold>F</bold>) Expert d’ of the last 100 trials during the last training session of the easy task (rank-sum=21; p=0.1255, two-sample Wilcoxon rank sum test). (<bold>G</bold>) Same as ‘F,’ but for the hard task (rank-sum=17; p=0.0173, two-sample Wilcoxon rank sum test). (<bold>H</bold>) Behavioral performance (average d’ of the easy and the hard task) per mouse during recording sessions for adolescents (n=13, left) and adults (n=14, right; trials per recording: adolescent: 340.5385±45.0650; adult: 431.1429±30.3367; independent t-test, t-statistic=–203.7581, p=0.1116). (<bold>I</bold>) Same as ‘H’ but only for the first 148 trials. The color bar shows the p-values between the groups. (<bold>J</bold>) Average cumulative licks per trial in adolescents (dashed-line) and adults (solid-line) from –200 ms before tone-onset until the reward or punishment delay, 500 ms after tone-offset. (<bold>K</bold>) Lick latency per trial for adolescent (left) and adult (right) groups during electrophysiological recordings (LME statistics are shown in <xref ref-type="supplementary-material" rid="supp1">Supplementary file 1</xref>). (<bold>J</bold>) Same as ‘K’ for the Lick count.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106387-fig3-v1.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Lick bias and impulsivity in adolescent and adult mice during head-fixed recordings.</title><p>(<bold>A</bold>) Average psychometric curve of adult recordings (solid line) and adolescent recordings (dashed line) (<bold>B</bold>) Lick bias (i.e. criterion bias) per recording (c-bias: z=–2.1366, p=0.0326, Wilcoxon rank sum test). (<bold>C</bold>) Proportion of licks within inter-trial intervals (ITIs) after False Alarms (FAs) (z=–2.6447, p=0.0082, Wilcoxon rank sum test). (<bold>D</bold>) Average number of licks during ITIs after FAs(z=–2.7230, p=0.0063, Wilcoxon rank sum test).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106387-fig3-figsupp1-v1.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Auditory Cortex is necessary for task execution in adult mice.</title><p>(<bold>A</bold>) Experimental design for testing the role of ACx during tone discrimination in expert mice (adults only). (<bold>B</bold>) Protocol for transient optogenetic suppression (light pulse duration was –50 ms from tone onset, to +50 ms from tone offset). Created with <ext-link ext-link-type="uri" xlink:href="https://biorender.com/tp52v9e">Biorender.com</ext-link>. (<bold>C</bold>) Injection sites and optical fiber implantation for the experimental (GtACR2; top) and control groups (dTomato; bottom). (<bold>D</bold>) Lick ratio for Go and No-Go stimuli under light-off conditions (gray) as compared to light-on conditions (red) in experimental (GtACR2, n=13; left; Go stimuli: p=0.0001; No-Go stimuli: p=0.0107; one-sample Wilcoxon sign ranked test after Bonferroni correction) and control mice (dTomato, n=8; right; Go stimuli: p=0.4263; No-Go stimuli: p=0.2953; one-sample Wilcoxon sign ranked test after Bonferroni correction). (<bold>E</bold>) Lick ratio under light-off trials after light-on (red) or light off trials (gray) in experimental (GtACR2, n=13; left; Go stimuli: p=0.3864; No-Go stimuli: p=0.2231; one-sample Wilcoxon sign ranked test after Bonferroni correction) and control (dTomato, n=8; right; Go stimuli: p=0.58341; No-Go stimuli: p=0.3214; one-sample Wilcoxon sign ranked test after Bonferroni correction). (<bold>F</bold>) Behavioral performance (<bold>d’</bold>) per session under light-off conditions in easy (light blue) and hard (dark blue) task, as compared to light-on conditions (red) in experimental (GtACR2, n=13; left; easy task: p=0.0010, hard task: p=0.0007, two-sample Wilcoxon rank sum test after Bonferroni correction; light-on p=0.0010; light-off: p=0.0398, one-sample Wilcoxon sign ranked test after Bonferroni correction) and control mice (dTomato, n=8; right, easy task: p=0.9999, hard task: p=0.7422, two-sample Wilcoxon rank sum test after Bonferroni correction; light on p=0.0312; light off: p=0.0234, one-sample Wilcoxon sign ranked test after Bonferroni correction).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106387-fig3-figsupp2-v1.tif"/></fig><fig id="fig3s3" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 3.</label><caption><title>Verification of GtACR2 expression.</title><p>Photomicrograph (left), and reconstruction (right) of the GtACR2 infected area (red) per mouse. Reconstruction followed the coordinates of the Allen-CFF template-atlas. ACx is highlighted in white and GtACR2-expression in red.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106387-fig3-figsupp3-v1.tif"/></fig><fig id="fig3s4" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 4.</label><caption><title>Adolescent and adult mice performed similarly throughout recordings as well as between the head-fixed configuration and the Educage.</title><p>(<bold>A</bold>) Behavioral performance (<bold>d’</bold>) in the easy task (light blue) and hard task (dark blue) for adolescent (recording = 13; left) and adult (recording = 14; right) recordings at the behavioral criterion of d’&gt;1 (adolescent mice: signed rank: 91, p=2.4414e-04; adult mice: signed rank: 105, p=1.2207e-04, Wilcoxon sign ranked test). Behavioral threshold of d’=1 highlighted in the dashed line. (<bold>B</bold>) Behavioral performance (average d’ of the easy and the hard task) for every mouse per recording for adolescent mice (n=5; left; 1st rec.: p=0.8125; 2nd rec.: p=0.9999; 3rd rec.: p=0.9999, Wilcoxon sign ranked test, after Bonferroni correction), and adult mice (n=6; right; 1st rec.: p=0. 8438; 2nd rec.: p=0.9999; 3rd rec.: p=0.9999, Wilcoxon sign ranked test, after Bonferroni correction). Behavioral threshold of d’=1 highlighted in the dashed line. (<bold>C</bold>) Comparison of behavioral performance in the head-fixed configuration and the Educage for adult mice (left; easy task: p=0.9960; hard task: p=0.2159, Kruskal Wallis test after Bonferroni correction), and adolescent mice (right; easy task: p=0.9973; hard task: p=0.1505, Kruskal Wallis test after Bonferroni correction) in the easy (light blue) and the hard (dark blue) task.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106387-fig3-figsupp4-v1.tif"/></fig></fig-group><p>To test whether ACx was necessary for expert discrimination in this task, we performed a causal experiment in adult mice. Adult mice (n=3) were injected bilaterally with AAV5-CAMKII-GtACR2-FRED_kv_2.1 into the ACx, and optical fibers were implanted over the injection sites (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2a, c</xref>; <xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s3">Figure 3—figure supplement 3</xref>). This viral construct enables optogenetic silencing of excitatory neurons via GtACR2 (<italic>Guillardia theta</italic> Anion Channelrhodopsin 2), under the control of the CaMKII promoter. It includes a red fluorescent protein for expression verification (FRED) and a soma-targeting motif derived from the Kv2.1 potassium channel to enhance membrane localization.</p><p>Mice were trained identically on the head-fixed Go/No-Go paradigm as described above. At the end of training, we attached a light source to the implanted fibers to allow optogenetic suppression during several sessions (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2a</xref>). In these sessions, light was applied in 50% of trials in a pseudo-random fashion, with light-on trials starting from –50 ms prior to tone onset up to 50 ms after tone offset (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2b</xref>). A control group of mice (n=3) were injected with AAV9-CaMKII-dTomato and went through the exact same procedure (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2a, c</xref>). We compared the lick responses for both Go and No-Go stimuli under light-on and light-off conditions. We found that lick responses were strongly affected in the GtACR2-injected mice (n=13 sessions), but not in controls (n=8 sessions) (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2d</xref>). Light-on conditions only affected the lick responses of the inhibited trial and not the light-off trials (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2e</xref>). Discriminability (d’) decreased significantly with optogenetic suppression for both easy and hard tasks, although all mice still performed better in the easy task under both conditions (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2f</xref>). These results confirm findings by others in similar (though not identical) tasks (<xref ref-type="bibr" rid="bib49">O’Sullivan et al., 2019</xref>; <xref ref-type="bibr" rid="bib10">Ceballo et al., 2019</xref>), suggesting that the ACx is necessary for executing the behavior during the expert stage of this task (but see Discussion for limitations of this experiment).</p><p>To measure neural responses during behavioral performance, head-fixed expert mice underwent multiple recording sessions targeting the ACx (adults, n=14 recording sessions from 6 mice, age: P77-P82; adolescents, n=13 recordings from 5 mice, age: P37-P42). During the recordings, the performance of all mice on the easy task was at least d’&gt;1, and the d’ on the hard task was smaller for both groups (often smaller than 1; <xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4a</xref>). Performance was not significantly different across the multiple recording sessions in each mouse (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4b</xref>). Behavioral performance during recordings was not significantly different from performance in the Educage (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s4">Figure 3—figure supplement 4c</xref>). <xref ref-type="fig" rid="fig3">Figure 3h</xref> shows the evolution of behavioral discriminability (d’) during all recordings for adolescents and adults. The performance was heterogeneous across mice as well as within recording-sessions. However, the total number of trials performed was not significantly different between age groups (trials per recording: adolescent: 340.5±45; adult: 431.1±30.3; independent t-test, t-statistic=–203.7581, p=0.1116).</p><p>We found additional differences between the behavior of adults and adolescents in the head-restrained configuration. The average adolescent discriminability was lower at the beginning of the session (initial 78 trials) but then rapidly leveled out (<xref ref-type="fig" rid="fig3">Figure 3i</xref>). <xref ref-type="fig" rid="fig3">Figure 3j</xref> shows the cumulative lick curves of adults and adolescents. Adolescent mice had shorter lick latencies (<xref ref-type="fig" rid="fig3">Figure 3k</xref>), and higher lick counts (<xref ref-type="fig" rid="fig3">Figure 3l</xref>, Supplementary File 1). While the lick latencies were independent of the discriminability (d’), we found a significant interaction effect between lick count and the d’ (Supplemetary File 1). Together, these behavioral differences suggest that the weaker response inhibition (here, expressed as lick latency) and higher reward anticipation (here, expressed as lick count) may contribute to the weaker performance of adolescents during the beginning of the recording session.</p></sec><sec id="s2-4"><title>Neuronal representations of stimulus- and choice-related activity are immature in adolescents</title><p>To compare the activity of neurons in adolescent and adult mice, we recorded spiking activity from the ACx using the high-density Neuropixels-1 probes in expert mice engaged in the task. We targeted the ACx by inserting the probe in a diagonal angle, traversing four auditory regions: Dorsal Auditory Cortex (AUDd), Primary Auditory Cortex (AUDp), ventral auditory cortex (AUDv), and Temporal Association Cortex (Tea; <xref ref-type="fig" rid="fig4">Figure 4a</xref>; <xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1a, b</xref> show an example voltage trace and one example recording). We recorded multiple times from each mouse and used DiI- or DiO-coatings for different penetrations to verify probe trajectories postmortem. We used the 3D-allen CCF-slice reconstruction platform (<ext-link ext-link-type="uri" xlink:href="https://github.com/cortex-lab/allenCCF">https://github.com/cortex-lab/allenCCF</ext-link>; <xref ref-type="bibr" rid="bib60">Shamash et al., 2025</xref>), for high resolution anatomical registration (<xref ref-type="fig" rid="fig4">Figure 4b</xref>; <xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1c, d</xref>).</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Auditory cortex (ACx) neurons in adolescents exhibit lower discriminability in stimulus- and choice-<italic> </italic>related activity.</title><p>(<bold>A</bold>) Recordings in ACx when the mouse is engaged in the task, using Neuropixels-1 probes. Left: Recordings were performed in AUDd, AUDp, AUDv, and TEa. Right: Fluorescent micrograph of a coronal brain slice showing the probe tracks of three recordings (red = DiI, yellow = DiO). Created with <ext-link ext-link-type="uri" xlink:href="https://biorender.com/lupfjof">Biorender.com</ext-link>. (<bold>B</bold>) Top: 3D-Reconstruction of recording sites in adolescents (n=13; gray) and adults (n=14; black). Bottom: distribution of the spike-depth of all excitatory tone-responsive L5/6 neurons in adolescents (n=455; gray) and adults (n=607; black). (<bold>C</bold>) Normalized PSTH (FR in Hz) and lick-rate (LR in Hz) from –200 ms to +600 ms after tone-onset in adolescents (gray) and adults (black). (<bold>D</bold>) Spiking activity from one example neuron sorted by trial outcome (hit, miss, false alarm, correct reject). Top: PSTH per trial outcome. Bottom: Heat map of the firing rate (FR) sorted per trial outcome. (<bold>E</bold>) Discriminability values (AUC) over time (from –200 ms to 600 ms after tone onset) for one example neuron (same neuron as in ‘D’). AUC values are shown for stimulus-related activity (left: easy task, middle: hard task) and choice-related activity (right). Shuffled distribution in all curves is shown in gray. (<bold>F</bold>) Same as ‘E’ for all neurons. The curves are average (+- STE) neuronal discriminability of adult neurons (solid line) and adolescent neurons (dashed line), for easy (adolescent neurons = 190, mice = 4, recordings = 7; adult n=358, mice = 4, recordings = 8; left) and hard stimulus-related activity (adolescent n=429; adult n=562, mice = 5, recordings = 9; middle), and choice-related activity (adolescent n=429; adult n=562, mice = 5, recordings = 9; right). (<bold>G</bold>) 3D plots of the onset-latency of discriminability (ms), duration of discriminability (ms), and maximal discriminability (AUC) of all neurons that showed significant discriminability. Left: easy task (adolescent neurons = 178 (93%), mice = 4, recordings = 6; adult n=346 (97%), mice = 4, recordings = 8; left); Center: hard task (adolescent neurons = 399 (93%), mice = 5, recordings = 10; adult n=544 (97%), mice = 6, recordings = 12; middle); Right: choice-related activity (adolescent neurons = 181 (95%), mice = 4, recordings = 9; adult n=339 (95%), mice = 4, recordings = 7; right).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106387-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Probe reconstruction and activity profile across auditory cortex (ACx) regions.</title><p>(<bold>A</bold>) Example voltage trace during a tone (100 ms) across 11 channels. (<bold>B</bold>) Example PSTH per depth (50 μm bins) across AUDd, AUDp, AUDv, and TEa (3850 maximal depth μm). (<bold>C</bold>) 3D-Reconstruction of recording sites in adolescent (n=5; left) and adult (n=6; right) mice. (<bold>D</bold>) Spike-depth of excitatory tone-responsive L5/6 neurons in AUDd, AUDp, AUDv, and TEa of adolescent (top) and adult (bottom) recordings. (<bold>E</bold>) Population PSTH from – 200 ms to 600 ms after tone onset in AUDd (blue), AUDp (purple), AUDv (magenta), and TEa (green) for adolescent neurons (dashed line) and adult neurons (solid line).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106387-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>The neuronal discriminability of stimulus- and choice-related activity is similar across auditory sub-regions.</title><p>(<bold>A</bold>) Onset-latency of discriminability (ms), duration of discriminability (ms), and maximal discriminability (AUC) of neurons that showed significant discriminability (exceeded 3 STD of the shuffled distribution) in the easy task (adolescent neurons = 178 (93%), mice = 4, recordings = 6; adult n=346 (97%), mice = 4, recordings = 8; adolescent: onset-latency of discriminability: p=0.5310, duration of discriminability: p=0.5418, maximal discriminability: p=0.7212; adult: onset-latency of discriminability: p=0.3810, duration of discriminability: p=0.6105, maximal discriminability: p=0.9115; Friedman test, correct for multiple comparisons). (<bold>B</bold>) Same as ‘A,’ but in the hard task (adolescent neurons = 399 (93%), mice = 5, recordings = 10; adult n=544 (97%), mice = 6, recordings = 12; adolescent: onset-latency of discriminability: p=0.9402, duration of discriminability: p=0.3388, maximal discriminability: p=0.6685; adult: onset-latency of discriminability: p=0.2425, duration of discriminability: p=0.5700, maximal discriminability: p=0.1011; Friedman test, correct for multiple comparisons). (<bold>C</bold>) Same as ‘A,’, but for choice-related activity (adolescent neurons = 181 (95%), mice = 4, recordings = 9; adult n=339 (95%), mice = 4, recordings = 7; adolescent: onset-latency of discriminability: p=0.3975, duration of discriminability: p=0.6823, maximal discriminability: p=0.2866; adult: onset-latency of discriminability: p=0.0881, duration of discriminability: p=0.8185, maximal discriminability: p=0.2501; Friedman test, correct for multiple comparisons), across the AUDd, AUDp, AUDv, TEa.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106387-fig4-figsupp2-v1.tif"/></fig></fig-group><p>We limited our single neuron analysis to well-isolated single units from infragranular layer 5 and layer 6 (recordings were largely restricted to these layers due to the probe angle), as two main projection layers of the cortex, which are key nodes for assessing cortical outputs (<xref ref-type="bibr" rid="bib37">Kanold et al., 2014</xref>). Recorded neurons from other layers and areas were excluded from the analysis. Together, we collected data from 1145 single neurons in 13 recordings of five adolescent mice and 1267 single neurons in 14 recordings of six adult mice (<xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>; an overview of every dataset per figure is detailed in <xref ref-type="supplementary-material" rid="supp9">Supplementary file 9</xref>). We further restricted our analysis to single neurons excited by sounds during the first 150 ms after tone onset. <xref ref-type="fig" rid="fig4">Figure 4c</xref> shows the normalized firing rate (FR) compared to the normalized lick rate (LR) from –200 ms to 600 ms after the tone onset, before the end of the reinforcement delay (<xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1e</xref> shows the FR in Hz per auditory sub-region). FR-PSTHs and LR-PSTHs were not correlated during the first 150 ms (adolescents <italic>r</italic>=–0.1515, p=0.9878; adults <italic>r</italic>=–0.0638, p=0.9942). In total, we analyzed n=463 neurons from adolescent mice and n=599 from adults.</p><p>In <xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>, we present the number of neurons in our dataset, categorized by region. A detailed overview of the differences in firing properties per auditory region is also provided in <xref ref-type="supplementary-material" rid="supp3 supp4">Supplementary files 3 and 4</xref>.</p><p>The differences in firing properties between adolescent and adult neurons varied across auditory subregions. AUDp showed differences in all firing properties that we analyzed. In AUDd, adolescent neurons had greater latency to peak, full-width half-maximum, minimal latency, and lower trial-responsiveness. AUDv also showed greater minimal latency and lower lifetime sparseness. TEa neurons of adolescents exhibited greater minimal latency and higher spontaneous FR. While these differences may partially reflect the varying number of neurons recorded per subregion and different functional attributes of each region, we observed similar trends in Cohen’s D values (effect sizes) across all four areas, supporting a generally consistent group differences in activity patterns. Consistent with previous work, we also found that firing properties such as minimal latency differed between auditory regions in both age groups (Supplementary File 4; <xref ref-type="bibr" rid="bib19">Feigin et al., 2021</xref>).</p><p>To study how adolescents and adults encode task performance, we divided neuronal responses by trial outcome (<xref ref-type="fig" rid="fig4">Figure 4d</xref> shows one example). Specifically, we assessed neuronal discriminability between stimulus-related and choice-related activity by calculating the area under the curve (AUC) from a receiver operating curve (ROC). Specifically, stimulus-related activity was calculated as the difference between hit and false alarm trials in the easy and the hard task separately (<xref ref-type="fig" rid="fig4">Figure 4e</xref>, left). Choice-related activity was calculated as the average difference between false-alarm and correct reject trials (<xref ref-type="fig" rid="fig4">Figure 4e</xref>, left). Miss trials were excluded since we had insufficient trial numbers of this outcome. <xref ref-type="fig" rid="fig4">Figure 4e</xref> (right) shows the average AUC values over time from an example neuron (same neuron shown in <xref ref-type="fig" rid="fig4">Figure 4D</xref>), and <xref ref-type="fig" rid="fig4">Figure 4f</xref> shows the average calculated from all neurons. The vast majority of neurons successfully discriminated (AUC above shuffled data) either or both stimulus- and choice-related activity (adolescent: easy stimuli = 93%, hard stimuli = 93%, choice = 95%; adult: easy stimuli = 97%, hard stimuli = 97%, choice = 95%). The onset-latency of discriminability was significantly slower, maximal discriminability significantly weaker, and the duration of discriminability significantly shorter in adolescent neurons compared to adult neurons (discriminability traces are plotted in <xref ref-type="fig" rid="fig4">Figure 4f</xref>, and all values from individual neurons and the 3 metrics are plotted together in <xref ref-type="fig" rid="fig4">Figure 4g</xref>; see <xref ref-type="table" rid="table2">Table 2</xref> for statistics). The four auditory subregions were not significantly different in all three measured metrics (<xref ref-type="fig" rid="fig4">Figure 4</xref>, <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). Thus, auditory processing of stimulus- and choice-related activity in the adolescent ACx has not yet reached full maturity.</p><table-wrap id="table2" position="float"><label>Table 2.</label><caption><title>Neuronal discrimination is later, shorter, and less precise in adolescent neurons.</title><p>Linear mixed effect models of the neuronal discriminability in adolescence and adulthood per stimulus-related activity in the easy task (Number of observations = 524, Fixed effects coefficients = 2, Random effects coefficients = 10, Covariance parameters = 3), stimulus related activity in the hard task (Number of observations = 943, Fixed effects coefficients = 2, Random effects coefficients = 14), and choice-related activity (Number of observations = 520, Fixed effects coefficients = 2, Random effects coefficients = 10, Covariance parameters = 3). The table shows the fixed effects of the coefficient estimates, STE, T-statistic, degrees of freedom, p-values (corrected for multiple comparisons with Bonferroni-correction) and the upper and lower CI of the effect of age on the onset latency of discrimination, duration of discrimination, and maximal neuronal discrimination (AUC). Each model also included random effect coefficients of each mouse, and recording per mouse. P-values for were adjusted with post-hoc tests using Bonferroni-correction (see <italic>methods,</italic> equation 9). Model structures: onset latency (ms) ~age + (1|Mouse ID) + (1| Recording ID); duration (ms) ~age + (1|Mouse ID) + (1| Recording ID); maximal discriminability (AUC) ~age + (1|Mouse ID) + (1| Recording ID).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Stimulus easy</th><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/></tr></thead><tbody><tr><td align="left" valign="bottom"><bold>Fixed effects</bold></td><td align="left" valign="bottom"><bold>Estimate</bold></td><td align="left" valign="bottom"><bold>STE</bold></td><td align="left" valign="bottom"><bold>T-statistic</bold></td><td align="left" valign="bottom"><bold>DF</bold></td><td align="left" valign="bottom"><bold>P-value</bold></td><td align="left" valign="bottom"><bold>CI lower</bold></td><td align="left" valign="bottom"><bold>CI upper</bold></td></tr><tr><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">163.6104</td><td align="char" char="." valign="bottom">7.9457</td><td align="char" char="." valign="bottom">20.591</td><td align="char" char="." valign="bottom">518</td><td align="char" char="hyphen" valign="bottom"><bold>6.29587E-69</bold></td><td align="char" char="." valign="bottom">148.0009</td><td align="char" char="." valign="bottom">179.2199</td></tr><tr><td align="left" valign="bottom">Onset (ms)</td><td align="char" char="." valign="bottom">–29.7978</td><td align="char" char="." valign="bottom">9.7626</td><td align="char" char="." valign="bottom">–3.0523</td><td align="char" char="." valign="bottom">518</td><td align="char" char="." valign="bottom"><bold>0.00716101</bold></td><td align="char" char="." valign="bottom">–48.9765</td><td align="char" char="." valign="bottom">–10.6191</td></tr><tr><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">216.2921</td><td align="char" char="." valign="bottom">13.2858</td><td align="char" char="." valign="bottom">16.2799</td><td align="char" char="." valign="bottom">518</td><td align="char" char="hyphen" valign="bottom"><bold>5.15393E-48</bold></td><td align="char" char="." valign="bottom">190.1919</td><td align="char" char="." valign="bottom">242.3924</td></tr><tr><td align="left" valign="bottom">Duration (ms)</td><td align="char" char="." valign="bottom">63.2599</td><td align="char" char="." valign="bottom">16.3499</td><td align="char" char="." valign="bottom">3.8691</td><td align="char" char="." valign="bottom">518</td><td align="char" char="." valign="bottom"><bold>0.000369146</bold></td><td align="char" char="." valign="bottom">31.1401</td><td align="char" char="." valign="bottom">95.3796</td></tr><tr><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">0.6035</td><td align="char" char="." valign="bottom">0.007</td><td align="char" char="." valign="bottom">85.6404</td><td align="char" char="." valign="bottom">518</td><td align="char" char="." valign="bottom"><bold>0.0001</bold></td><td align="char" char="." valign="bottom">0.5897</td><td align="char" char="." valign="bottom">0.6174</td></tr><tr><td align="left" valign="bottom">Max AUC</td><td align="char" char="." valign="bottom">0.0186</td><td align="char" char="." valign="bottom">0.0049</td><td align="char" char="." valign="bottom">3.7564</td><td align="char" char="." valign="bottom">518</td><td align="char" char="." valign="bottom"><bold>0.0001</bold></td><td align="char" char="." valign="bottom">0.0088</td><td align="char" char="." valign="bottom">0.02841</td></tr><tr><td align="left" valign="bottom">Stimulus hard</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Fixed Effects</td><td align="left" valign="bottom">Estimate</td><td align="left" valign="bottom">STE</td><td align="left" valign="bottom">T-Statistic</td><td align="left" valign="bottom">DF</td><td align="left" valign="bottom">P-Value</td><td align="left" valign="bottom">CI lower</td><td align="left" valign="bottom">CI upper</td></tr><tr><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">151.1905</td><td align="char" char="." valign="bottom">5.4684</td><td align="char" char="." valign="bottom">27.6479</td><td align="char" char="." valign="bottom">535</td><td align="char" char="hyphen" valign="bottom"><bold>3.6685E-123</bold></td><td align="char" char="." valign="bottom">140.4588</td><td align="char" char="." valign="bottom">161.9222</td></tr><tr><td align="left" valign="bottom">Onset (ms)</td><td align="char" char="." valign="bottom">–35.3357</td><td align="char" char="." valign="bottom">7.1998</td><td align="char" char="." valign="bottom">–4.9079</td><td align="char" char="." valign="bottom">535</td><td align="char" char="hyphen" valign="bottom"><bold>3.25392E-06</bold></td><td align="char" char="." valign="bottom">–49.4651</td><td align="char" char="." valign="bottom">–21.2063</td></tr><tr><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">220.614</td><td align="char" char="." valign="bottom">8.4357</td><td align="char" char="." valign="bottom">26.1525</td><td align="char" char="." valign="bottom">535</td><td align="char" char="hyphen" valign="bottom"><bold>2.8344E-113</bold></td><td align="char" char="." valign="bottom">204.0591</td><td align="char" char="." valign="bottom">237.1689</td></tr><tr><td align="left" valign="bottom">Duration (ms)</td><td align="char" char="." valign="bottom">55.6268</td><td align="char" char="." valign="bottom">11.1065</td><td align="char" char="." valign="bottom">5.0085</td><td align="char" char="." valign="bottom">535</td><td align="char" char="hyphen" valign="bottom"><bold>1.9647E-06</bold></td><td align="char" char="." valign="bottom">33.8305</td><td align="char" char="." valign="bottom">77.4231</td></tr><tr><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">0.5821</td><td align="char" char="." valign="bottom">0.0034</td><td align="char" char="." valign="bottom">170.2777</td><td align="char" char="." valign="bottom">535</td><td align="char" char="." valign="bottom"><bold>0.0001</bold></td><td align="char" char="." valign="bottom">0.5754</td><td align="char" char="." valign="bottom">0.5888</td></tr><tr><td align="left" valign="bottom">Max AUC</td><td align="char" char="." valign="bottom">0.02013</td><td align="char" char="." valign="bottom">0.0048</td><td align="char" char="." valign="bottom">4.1119</td><td align="char" char="." valign="bottom">535</td><td align="char" char="hyphen" valign="bottom"><bold>4.5413e-05</bold></td><td align="char" char="." valign="bottom">0.0105</td><td align="char" char="." valign="bottom">0.0297</td></tr><tr><td align="left" valign="bottom">Choice</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Fixed Effects</td><td align="left" valign="bottom">Estimate</td><td align="left" valign="bottom">STE</td><td align="left" valign="bottom">T-Statistic</td><td align="left" valign="bottom">DF</td><td align="left" valign="bottom">P-Value</td><td align="left" valign="bottom">CI lower</td><td align="left" valign="bottom">CI upper</td></tr><tr><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">174.5856</td><td align="char" char="." valign="bottom">8.259</td><td align="char" char="." valign="bottom">21.139</td><td align="char" char="." valign="bottom">518</td><td align="char" char="hyphen" valign="bottom"><bold>1.6732E-71</bold></td><td align="char" char="." valign="bottom">158.3605</td><td align="char" char="." valign="bottom">190.8108</td></tr><tr><td align="left" valign="bottom">Onset (ms)</td><td align="char" char="." valign="bottom">–24.3644</td><td align="char" char="." valign="bottom">10.2288</td><td align="char" char="." valign="bottom">–2.3819</td><td align="char" char="." valign="bottom">518</td><td align="char" char="." valign="bottom"><bold>0.052746707</bold></td><td align="char" char="." valign="bottom">–44.4595</td><td align="char" char="." valign="bottom">–4.2693</td></tr><tr><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">228.1768</td><td align="char" char="." valign="bottom">12.92</td><td align="char" char="." valign="bottom">17.6607</td><td align="char" char="." valign="bottom">518</td><td align="char" char="hyphen" valign="bottom"><bold>1.64628E-54</bold></td><td align="char" char="." valign="bottom">202.7947</td><td align="char" char="." valign="bottom">253.5589</td></tr><tr><td align="left" valign="bottom">Duration (ms)</td><td align="char" char="." valign="bottom">82.0002</td><td align="char" char="." valign="bottom">16.0017</td><td align="char" char="." valign="bottom">5.1245</td><td align="char" char="." valign="bottom">518</td><td align="char" char="hyphen" valign="bottom"><bold>1.26556E-06</bold></td><td align="char" char="." valign="bottom">50.564</td><td align="char" char="." valign="bottom">113.4363</td></tr><tr><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">0.5491</td><td align="char" char="." valign="bottom">0.0027</td><td align="char" char="." valign="bottom">200.1358</td><td align="char" char="." valign="bottom">518</td><td align="char" char="." valign="bottom"><bold>0.0001</bold></td><td align="char" char="." valign="bottom">0.5437</td><td align="char" char="." valign="bottom">0.5545</td></tr><tr><td align="left" valign="bottom">Max AUC</td><td align="char" char="." valign="bottom">0.01660</td><td align="char" char="." valign="bottom">0.0034</td><td align="char" char="." valign="bottom">4.8959</td><td align="char" char="." valign="bottom">518</td><td align="char" char="hyphen" valign="bottom"><bold>3.92843E-06</bold></td><td align="char" char="." valign="bottom">0.01</td><td align="char" char="." valign="bottom">0.0233</td></tr></tbody></table></table-wrap></sec><sec id="s2-5"><title>Adults exhibit better population decoding of the difficult task compared to adolescents</title><p>While individual neurons exhibited weaker discriminability in adolescents than in adults, at a population level, these effects could saturate out. We, therefore, tested the ability of recorded populations to decode trial outcomes. We used a linear discriminant analysis (LDA) decoder to quantify hit versus correct reject trial outcomes. We applied stringent inclusion criteria for the number of simultaneously recorded neurons (see Methods), which restricted our analysis to hit versus correct rejection trials with sufficient trial counts for statistical reliability. We note that this comparison extracts information of the combination of stimulus and choice information indiscriminately (i.e. collectively it includes the full ‘task-related’ differences). We decoded separately in easy trials and hard trials, based on population activity during the first 200 milliseconds. For the easy task there was no significant difference between decoding accuracy in adolescents and adults (<xref ref-type="fig" rid="fig5">Figure 5a</xref>). However, decoding accuracy was significantly higher in adults compared to adolescents in hard trials (<xref ref-type="fig" rid="fig5">Figure 5a</xref>). For both adults and adolescents, decoding accuracy was significantly lower in hard trials compared to easy trials (<xref ref-type="fig" rid="fig5">Figure 5a</xref>). We performed finer timescale decoding to quantify the onset latency of differences between the activity for hit vs. correct reject trials, defined as the time in which the decoding accuracy first crosses three times the standard deviation away from the baseline (see Methods). We found that the latency was shorter in adults in both the easy and hard trials (<xref ref-type="fig" rid="fig5">Figure 5b</xref>). In adolescent animals the latency was larger in hard trials (<xref ref-type="fig" rid="fig5">Figure 5b</xref>) but not in adult animals (<xref ref-type="fig" rid="fig5">Figure 5b</xref>). We then extended this analysis over a temporal window from –0.5 s to10 s relative to tone onset (<xref ref-type="fig" rid="fig5">Figure 5c</xref>). In the 200 ms window after the response period (2.0–2.2 s), there is no longer a significant difference in decoding accuracy between adult and adolescent mice as well as between the two task difficulties (<xref ref-type="fig" rid="fig5">Figure 5</xref>, <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1</xref>).</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Decoding in adult neuronal populations outperforms decoding in adolescents.</title><p>(<bold>A</bold>) Decoding accuracy for the first 200 ms across all recordings in both adults (black) and adolescents (gray) for the easy task (adolescents compared to adults, p=0.5000, Student’s t-test) and the hard task (adolescents compared to adults, p=0.0300, Student’s t-test). Decoding is better in the easy task for both age groups (adults: p=0.0030; adolescents: p=0.01, paired t-test). (<bold>B</bold>) Decoding latency for all recordings in the easy task (p=0.0200, Student’s t-test) and the hard task (p=0.0030, Student’s t-test), as well as compared between age groups (easy task, p=0.05400, paired t-test; hard task: p=0.0100). (<bold>C</bold>) Decoding accuracy over a time window from –0.5 s to 10 s (the response window highlighted in the gray) for the easy task (left) and the hard task (right). (<bold>D</bold>) Linear discriminant analysis (LDA) separation for easy and hard tasks. Lines represent robust linear regression fits without intercept (Huber loss; robust linear regression, p=0.0001) (<bold>E</bold>) Single trial variance for easy and hard tasks in adolescent and adult recordings (adults: p=0.0040; adolescents: p=0.0300, paired t-test; easy task: p=0.4500; hard task: p=0.4100, Student’s t-test). (<bold>F</bold>) Visualization of population representations for the stimuli in easy and hard tasks. Dotted lines indicate decoding dimensions, and ellipses represent the covariance of the representations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106387-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Decoding accuracy of the first 200 ms after the response window.</title><p>Linear discriminant analysis (LDA) decoding accuracy of the easy and the hard tasks of adolescent and adult mice, 200 ms after the response window.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106387-fig5-figsupp1-v1.tif"/></fig></fig-group><p>To further quantify the different decoding performance between two tasks difficulties, we plotted the Fisher separation metric (<inline-formula><alternatives><mml:math id="inf1"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>w</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:msubsup></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft1">\begin{document}$\frac{\sigma _{between}^{2}}{\sigma _{within}^{w}}$\end{document}</tex-math></alternatives></inline-formula>, see Methods) for each level of difficulty. While decoding accuracy reflects how well a classifier can distinguish between trial types, the Fisher separation metric specifically quantifies the ratio of between-category variance to within-category variance. The separation ratio of hard over easy tasks was significantly higher in adult mice than in adolescent mice (robust linear regression, see Methods). Separation could have changed due to alterations in the mean or the dispersion around the mean. Testing the dispersion, we found that the variance around the means was not equal across easy and hard trials but rather significantly increased for the hard trials (<xref ref-type="fig" rid="fig5">Figure 5d–f</xref>). However, there was no significant difference in variance between adolescent and adult mice within the same task (<xref ref-type="fig" rid="fig5">Figure 5d–f</xref>).</p></sec><sec id="s2-6"><title>Both age and learning affect cortical plasticity in mice engaged in the task</title><p>We next studied how learning contributes to cortical plasticity in the different age groups. To separate between age- and learning-related effects, we recorded from the ACx of two new groups of mice (adolescents and adults that are age-matched to expert mice) that are novice on the task (<xref ref-type="fig" rid="fig6">Figure 6a</xref>, novice P37-P42, recordings = 6; novice P77-P82, recordings = 6, n=3 mice per group). We collected data from 130 tone-responsive (by excitation) neurons in novice adolescents and 186 tone-responsive (by excitation) neurons in novice adults (<xref ref-type="fig" rid="fig6">Figure 6b</xref>;<xref ref-type="supplementary-material" rid="supp2">Supplementary file 2</xref>; <xref ref-type="fig" rid="fig6">Figure 6c</xref>) shows the normalized average FR PSTH together with the LR PSTH for novice mice. Notably, novice mice did not discriminate between sounds (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). Similar to expert mice (<xref ref-type="supplementary-material" rid="supp3">Supplementary file 3</xref>), we found diverse firing properties across auditory subregions in novice mice (<xref ref-type="supplementary-material" rid="supp5">Supplementary file 5</xref>). Also similar to expert mice, several basic firing properties were different across regions in both novice adolescents and novice adults (<xref ref-type="supplementary-material" rid="supp6">Supplementary file 6</xref>).</p><fig-group><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Cortical activity during behavior reflects both age- and learning-induced effects.</title><p>(<bold>A</bold>) Training and recording schedule for novice mice, compared to expert mice. Created with <ext-link ext-link-type="uri" xlink:href="https://biorender.com/qbe14qe">Biorender.com</ext-link>. (<bold>B</bold>) 3D-Reconstruction of recording sites in novice adolescent (n=6; gray) and novice adult (n=6; black) mice. Bottom: spike-depth of excitatory tone-responsive L5/6 adolescent (n=130; gray) and adult (n=186; black) neurons. (<bold>C</bold>) Normalized FR and lick rate (LR) PSTH from –200 ms to 600 ms after tone-onset in adolescents (gray) and adults (black). Average +-sem. (<bold>D</bold>) Single neuron data from novice adolescent mice. Left: Heat map of the firing rate (FR) per trial from one example neuron sorted by trial outcomes. Center: the AUC of the neuron from the left for the easy and hard stimulus pairs (light and dark blue, respectively). Right: Average (+-SEM) AUC of all neurons in the novice group (n=140 neurons). (<bold>E–G</bold>) Same as ‘D’ for novice adult (n=186 neurons), expert adolescents (n=455 neurons; Easy vs hard), and expert adults (n=604 neurons; Easy vs hard.). (<bold>H</bold>) Linear regression analysis between the average AUC per recording and the behavioral d’ during the recording (the correlation and p-values are indicated for each plot). (<bold>I</bold>) Same as ‘I’ for adult mice.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106387-fig6-v1.tif"/></fig><fig id="fig6s1" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 1.</label><caption><title>Behavioral performance of novice mice.</title><p>(<bold>A</bold>) Behavioral performance (d’) in the easy task (light blue) and hard task (dark blue) for adolescent (n=6; left) and adult (n=6; right) mice at the behavioral criterion of d’&gt;1 (adolescent mice: signed rank: 19, p=0.0938; adult mice: signed rank: 15, p=0.4375, Wilcoxon sign ranked test). Behavioral threshold of d’=1 highlighted in the dashed line. (<bold>B</bold>) Behavioral performance (average d’ of the easy and the hard task) for every mouse per recording for adult mice (n=3; left; signed rank: 0, p=0.2500 Wilcoxon signed-rank test). adolescent mice (n=3; right; signed rank: 0, p=0.2500, Wilcoxon sign ranked test). Behavioral threshold of d’=1 highlighted in the dashed line.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106387-fig6-figsupp1-v1.tif"/></fig><fig id="fig6s2" position="float" specific-use="child-fig"><label>Figure 6—figure supplement 2.</label><caption><title>The neuronal discriminability of Easy and Hard Go and No-Go are distributed similar across auditory sub-regions in adolescent and adult novice and expert mice.</title><p>Onset-latency of discriminability (ms), duration of discriminability (ms), and maximal discriminability (AUC) of neurons that showed significant discriminability (exceeded 3 STD of the shuffled distribution). Left: easy task (Novice, adolescent n=108 (83%), mice = 3, recording = 6; onset-latency of discriminability: <italic>P</italic>=0.2422, duration of discriminability: p=0.5639, maximal discriminability: p=0.2062. Novice, adult n=179 (97%), mice = 3, recording = 6, onset-latency of discriminability: p=0.8335, duration of discriminability: p=0.8013, maximal discriminability: p=0.1900. Expert, adolescent n=450 (97%), mice = 5, recording = 13, onset-latency of discriminability: p=0.0918, duration of discriminability: p=0.4020, maximal discriminability: p=0.0698. Expert, adult n=598 (99%), mice = 6, recording = 14, onset-latency of discriminability: p=0.6807, duration of discriminability: p=0.7223, maximal discriminability: p=0.7557; Friedman test, correct for multiple comparisons); Right: hard task (Novice, adolescent n=108 (83%), mice = 3, recording = 6, onset-latency of discriminability: p=0.6294, duration of discriminability: p=0.0693, maximal discriminability: p=0.0858. Novice, adult n=181 (96%), mice = 3, recording = 6, onset-latency of discriminability: p=0.2180, duration of discriminability: p=0.3388, maximal discriminability: p=0.0648. Expert, adolescent n=440 (95%), mice = 5, recording = 13, onset-latency of discriminability: p=0.9911, duration of discriminability: p=0.9939, maximal discriminability: p=0.4058. Expert, adult n=589 (98%), mice = 6, recording = 14, onset-latency of discriminability: p=0.7141, duration of discriminability: p=0.4084, maximal discriminability: p=0.6365; Friedman test, correct for multiple comparisons); across the AUDd, AUDp, AUDv, TEa.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106387-fig6-figsupp2-v1.tif"/></fig></fig-group><p>To reveal learning-related differences, we compared neuronal responses in novice versus expert mice in both age-groups. We computed single-neuron AUCs for Go and No-Go trials (here, we did not distinguish between stimulus and choice and computed AUCs for all trial outcomes, since expert mice mostly performed CR and novice mice mostly performed FA to No-Go tones), in both easy and hard tasks (<xref ref-type="fig" rid="fig6">Figure 6d–g</xref>). The onset-latency for AUC discrimination was significantly different between adolescents and adults (shorter in adults), but not between novice and expert mice, nor between the easy and the hard task (<xref ref-type="table" rid="table3">Table 3</xref>). The maximal AUC discriminability was higher in adults compared to adolescents. It was also higher in experts than in novice, and in the easy compared to the hard task (<xref ref-type="table" rid="table3">Table 3</xref>). Similarly, the duration of discriminability was longer in adults and after learning (<xref ref-type="table" rid="table3">Table 3</xref>). There was a significant interaction between age and learning, as well learning and task difficulty in the maximal discriminability (<xref ref-type="table" rid="table3">Table 3</xref>). The onset-latency, duration of discriminability, and maximal discriminability, were not significantly different among the AUDd, AUDp, AUDv, and TEa in the four experimental groups (<xref ref-type="fig" rid="fig6">Figure 6</xref>, <xref ref-type="fig" rid="fig6s2">Figure 6—figure supplement 2</xref>).</p><table-wrap id="table3" position="float"><label>Table 3.</label><caption><title>The effect of age, learning and task difficulty on the latency, duration, and ability to discriminate tones in ACx neurons.</title><p>Linear mixed effect models of the effect of age, learning, and task difficulty on onset-latency of discrimination, duration of discrimination and maximal discriminability (Number of observations = 2590,, Fixed effects coefficients = 8, Random effects coefficients = 20, Covariance parameters = 3). The table shows the fixed effects of the coefficient estimates, STE, T-statistic, degrees of freedom, p-values (corrected for multiple comparisons with Bonferroni-correction), and the upper and lower CI. The model also includes random effects coefficients of each mouse (adolescent novice = 3, adult novice = 3, adolescent expert = 5, adult expert = 6) and recording per mouse (n=3). P-values were adjusted with post-hoc tests using Bonferroni correction (see <italic>methods,</italic> equation 10). Model structures: onset latency (ms) ~age* learning * difficulty + (1|Mouse ID) + (1| Recording ID); duration (ms) ~age* learning * difficulty + (1|Mouse ID) + (1| Recording ID); maximal discriminability (AUC) ~age* learning * difficulty + (1|Mouse ID) + (1| Recording ID).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom">Fixed Effects</th><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/><th align="left" valign="bottom"/></tr></thead><tbody><tr><td align="left" valign="bottom"><bold>Onset latency (ms)</bold></td><td align="left" valign="bottom"><bold>Estimate</bold></td><td align="left" valign="bottom"><bold>STE</bold></td><td align="left" valign="bottom"><bold>T-statistic</bold></td><td align="left" valign="bottom"><bold>DF</bold></td><td align="left" valign="bottom"><bold>P-value</bold></td><td align="left" valign="bottom"><bold>CI lower</bold></td><td align="left" valign="bottom"><bold>CI upper</bold></td></tr><tr><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">92.6519</td><td align="char" char="." valign="bottom">3.8909</td><td align="char" char="." valign="bottom">23.8125</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="hyphen" valign="bottom"><bold>5.4024E-113</bold></td><td align="char" char="." valign="bottom">85.0223</td><td align="char" char="." valign="bottom">100.2815</td></tr><tr><td align="left" valign="bottom">Age</td><td align="char" char="." valign="bottom">–22.6378</td><td align="char" char="." valign="bottom">5.0624</td><td align="char" char="." valign="bottom">–4.4718</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="hyphen" valign="bottom"><bold>2.42782E-05</bold></td><td align="char" char="." valign="bottom">–32.5645</td><td align="char" char="." valign="bottom">–12.7111</td></tr><tr><td align="left" valign="bottom">Learning</td><td align="char" char="." valign="bottom">5.6206</td><td align="char" char="." valign="bottom">8.7235</td><td align="char" char="." valign="bottom">0.6443</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="." valign="bottom">0.9999</td><td align="char" char="." valign="bottom">–11.4851</td><td align="char" char="." valign="bottom">22.7263</td></tr><tr><td align="left" valign="bottom">Task difficulty</td><td align="char" char="." valign="bottom">0.8813</td><td align="char" char="." valign="bottom">5.4571</td><td align="char" char="." valign="bottom">0.1615</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="." valign="bottom">0.9999</td><td align="char" char="." valign="bottom">–9.8194</td><td align="char" char="." valign="bottom">11.5819</td></tr><tr><td align="left" valign="bottom">Age- Learning</td><td align="char" char="." valign="bottom">–6.8831</td><td align="char" char="." valign="bottom">11.1114</td><td align="char" char="." valign="bottom">–0.6195</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="." valign="bottom">0.9999</td><td align="char" char="." valign="bottom">–28.6713</td><td align="char" char="." valign="bottom">14.905</td></tr><tr><td align="left" valign="bottom">Age - Difficulty</td><td align="char" char="." valign="bottom">0.2461</td><td align="char" char="." valign="bottom">7.2185</td><td align="char" char="." valign="bottom">0.0341</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="." valign="bottom">0.9999</td><td align="char" char="." valign="bottom">–13.9085</td><td align="char" char="." valign="bottom">14.4006</td></tr><tr><td align="left" valign="bottom">Learning - Difficulty</td><td align="char" char="." valign="bottom">–2.5145</td><td align="char" char="." valign="bottom">12.3257</td><td align="char" char="." valign="bottom">–0.204</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="." valign="bottom">0.9999</td><td align="char" char="." valign="bottom">–26.6837</td><td align="char" char="." valign="bottom">21.6546</td></tr><tr><td align="left" valign="bottom">Age-Learning-Difficulty</td><td align="char" char="." valign="bottom">4.4526</td><td align="char" char="." valign="bottom">15.7691</td><td align="char" char="." valign="bottom">0.2824</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="." valign="bottom">0.9999</td><td align="char" char="." valign="bottom">–26.4688</td><td align="char" char="." valign="bottom">35.374</td></tr><tr><td align="left" valign="bottom">Fixed Effects</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Duration of Discrimination(ms)</td><td align="left" valign="bottom">Estimate</td><td align="left" valign="bottom">STE</td><td align="left" valign="bottom">T-Statistic</td><td align="left" valign="bottom">DF</td><td align="left" valign="bottom">P-Value</td><td align="left" valign="bottom">CI lower</td><td align="left" valign="bottom">CI upper</td></tr><tr><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">299.7098</td><td align="char" char="." valign="bottom">7.8305</td><td align="char" char="." valign="bottom">38.2747</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="hyphen" valign="bottom"><bold>8.4469E-254</bold></td><td align="char" char="." valign="bottom">284.3551</td><td align="char" char="." valign="bottom">315.0645</td></tr><tr><td align="left" valign="bottom">Age</td><td align="char" char="." valign="bottom">63.2136</td><td align="char" char="." valign="bottom">9.2513</td><td align="char" char="." valign="bottom">6.833</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="hyphen" valign="bottom"><bold>3.1017E-11</bold></td><td align="char" char="." valign="bottom">45.0729</td><td align="char" char="." valign="bottom">81.3544</td></tr><tr><td align="left" valign="bottom">Learning</td><td align="char" char="." valign="bottom">–88.8699</td><td align="char" char="." valign="bottom">15.9421</td><td align="char" char="." valign="bottom">–5.5745</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="hyphen" valign="bottom"><bold>8.21813E-08</bold></td><td align="char" char="." valign="bottom">–120.1306</td><td align="char" char="." valign="bottom">–57.6092</td></tr><tr><td align="left" valign="bottom">Task difficulty</td><td align="char" char="." valign="bottom">–53.9606</td><td align="char" char="." valign="bottom">9.9745</td><td align="char" char="." valign="bottom">–5.4098</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="hyphen" valign="bottom"><bold>2.06623E-07</bold></td><td align="char" char="." valign="bottom">–73.5194</td><td align="char" char="." valign="bottom">–34.4017</td></tr><tr><td align="left" valign="bottom">Age- Learning</td><td align="char" char="." valign="bottom">–30.6998</td><td align="char" char="." valign="bottom">20.3155</td><td align="char" char="." valign="bottom">–1.5112</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="." valign="bottom">0.3926</td><td align="char" char="." valign="bottom">–70.5361</td><td align="char" char="." valign="bottom">9.1365</td></tr><tr><td align="left" valign="bottom">Age - Difficulty</td><td align="char" char="." valign="bottom">–18.8772</td><td align="char" char="." valign="bottom">13.194</td><td align="char" char="." valign="bottom">–1.4307</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="." valign="bottom">0.4579</td><td align="char" char="." valign="bottom">–44.749</td><td align="char" char="." valign="bottom">6.9947</td></tr><tr><td align="left" valign="bottom">Learning - Difficulty</td><td align="char" char="." valign="bottom">53.8178</td><td align="char" char="." valign="bottom">22.5289</td><td align="char" char="." valign="bottom">2.3888</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="." valign="bottom">0.0509</td><td align="char" char="." valign="bottom">9.6414</td><td align="char" char="." valign="bottom">97.9943</td></tr><tr><td align="left" valign="bottom">Age-Learning-Difficulty</td><td align="char" char="." valign="bottom">12.9698</td><td align="char" char="." valign="bottom">28.823</td><td align="char" char="." valign="bottom">0.45</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="." valign="bottom">0.9999</td><td align="char" char="." valign="bottom">–43.5488</td><td align="char" char="." valign="bottom">69.4884</td></tr><tr><td align="left" valign="bottom">Fixed Effects</td><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom">Maximal Discrimination (AUC)</td><td align="left" valign="bottom">Estimate</td><td align="left" valign="bottom">STE</td><td align="left" valign="bottom">T-statistic</td><td align="left" valign="bottom">DF</td><td align="left" valign="bottom">P-value</td><td align="left" valign="bottom">CI lower</td><td align="left" valign="bottom">CI upper</td></tr><tr><td align="left" valign="bottom">Intercept</td><td align="char" char="." valign="bottom">0.6278</td><td align="char" char="." valign="bottom">0.0042</td><td align="char" char="." valign="bottom">148.636</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="." valign="bottom"><bold>0.0001</bold></td><td align="char" char="." valign="bottom">0.6195</td><td align="char" char="." valign="bottom">0.6361</td></tr><tr><td align="left" valign="bottom">Age</td><td align="char" char="." valign="bottom">0.024</td><td align="char" char="." valign="bottom">0.0056</td><td align="char" char="." valign="bottom">4.2953</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="hyphen" valign="bottom"><bold>5.42797E-05</bold></td><td align="char" char="." valign="bottom">0.0131</td><td align="char" char="." valign="bottom">0.035</td></tr><tr><td align="left" valign="bottom">Learning</td><td align="char" char="." valign="bottom">–0.0249</td><td align="char" char="." valign="bottom">0.0096</td><td align="char" char="." valign="bottom">–2.5859</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="." valign="bottom"><bold>0.029303232</bold></td><td align="char" char="." valign="bottom">–0.0438</td><td align="char" char="." valign="bottom">–0.006</td></tr><tr><td align="left" valign="bottom">Task difficulty</td><td align="char" char="." valign="bottom">–0.0438</td><td align="char" char="." valign="bottom">0.006</td><td align="char" char="." valign="bottom">–7.24</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="hyphen" valign="bottom"><bold>1.76807E-12</bold></td><td align="char" char="." valign="bottom">–0.0556</td><td align="char" char="." valign="bottom">–0.0319</td></tr><tr><td align="left" valign="bottom">Age- Learning</td><td align="char" char="." valign="bottom">–0.03</td><td align="char" char="." valign="bottom">0.0123</td><td align="char" char="." valign="bottom">–2.4376</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="." valign="bottom"><bold>0.0446</bold></td><td align="char" char="." valign="bottom">–0.0541</td><td align="char" char="." valign="bottom">–0.0059</td></tr><tr><td align="left" valign="bottom">Age - Difficulty</td><td align="char" char="." valign="bottom">–0.0023</td><td align="char" char="." valign="bottom">0.008</td><td align="char" char="." valign="bottom">–0.2846</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="." valign="bottom">0.9999</td><td align="char" char="." valign="bottom">–0.0179</td><td align="char" char="." valign="bottom">0.0134</td></tr><tr><td align="left" valign="bottom">Learning - Difficulty</td><td align="char" char="." valign="bottom">0.0394</td><td align="char" char="." valign="bottom">0.0136</td><td align="char" char="." valign="bottom">2.8893</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="." valign="bottom"><bold>0.0116</bold></td><td align="char" char="." valign="bottom">0.0127</td><td align="char" char="." valign="bottom">0.0662</td></tr><tr><td align="left" valign="bottom">Age-Learning-Difficulty</td><td align="char" char="." valign="bottom">–0.0094</td><td align="char" char="." valign="bottom">0.0175</td><td align="char" char="." valign="bottom">–0.5387</td><td align="char" char="." valign="bottom">2582</td><td align="char" char="." valign="bottom">0.9999</td><td align="char" char="." valign="bottom">–0.0437</td><td align="char" char="." valign="bottom">0.0248</td></tr></tbody></table></table-wrap><p>To compare neuronal discriminability and behavior more explicitly, we analyzed the correlations between neuronal decoding and behavioral performance using linear regression. In the easy task, both age groups showed high correlation between neuronal discriminability and behavioral discriminability (<xref ref-type="fig" rid="fig6">Figure 6h and i</xref>; light blue). In the hard task, only adult neurons had significant correlations between neuronal discriminability and behavioral discriminability (<xref ref-type="fig" rid="fig6">Figure 6h and i</xref>; dark blue).</p></sec><sec id="s2-7"><title>Effects of age and learning on tuning properties in passively listening mice</title><p>Auditory learning has been shown to induce changes in the tuning properties of sounds in the ACx (<xref ref-type="bibr" rid="bib45">Maor et al., 2020</xref>; <xref ref-type="bibr" rid="bib49">O’Sullivan et al., 2019</xref>; <xref ref-type="bibr" rid="bib37">Kanold et al., 2014</xref>; <xref ref-type="bibr" rid="bib5">Bao et al., 2013</xref>; <xref ref-type="bibr" rid="bib4">Bao et al., 2004</xref>; <xref ref-type="bibr" rid="bib26">Han et al., 2007</xref>; <xref ref-type="bibr" rid="bib3">Anbuhl et al., 2022</xref>; <xref ref-type="bibr" rid="bib32">Jaramillo and Zador, 2011</xref>; <xref ref-type="bibr" rid="bib38">Kato et al., 2015</xref>). To study whether learning-induced plasticity in ACx is distinct in adolescents and adults, we recorded from the same mice described above under passive listening conditions by simply extending the recording following the engaged session (<xref ref-type="fig" rid="fig7">Figure 7a</xref>; Adolescents recordings = 4; Adults recordings = 4). These data were compared to data from a group of novice mice, recorded under passive listening conditions following their own engaged session (; novice adolescent recordings = 6; novice adult recordings = 6).</p><fig-group><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Adult mice show greater plasticity after learning.</title><p>(<bold>A</bold>) Schematic showing that for the passive listening protocol, we continued our recording following the session of the engaged task (i.e. in satiated mice) by removing the waterspout. Created with <ext-link ext-link-type="uri" xlink:href="https://biorender.com/33iptvq">Biorender.com</ext-link>. (<bold>B</bold>) Example raster plot of a neuron from an adolescent mouse (top) and an adult mouse (bottom). (<bold>C</bold>) Frequency-response areas (FRA’s) of the neurons shown in ‘B.’ (<bold>D</bold>) Distribution of best frequencies in our dataset. Values are normalized firing rates calculated at 62 dB SPL. Matrices are sorted by BF for clarity. Dotted line marks the decision boundary. (<bold>E</bold>) Tuning bandwidth at 62 dB SPL of neurons in adolescents and adults. Side-by-side comparisons of novice versus experts. (adolescents p=0.0882, adults p=0.0001, Kruskal-Willis Test after Tukey-Kramer correction for multiple comparisons). (<bold>F</bold>) Same as E. for Population sparseness (adolescents p=0.9549, adults p=0.0013, Kruskal-Willis Test after Tukey-Kramer correction for multiple comparisons). (<bold>G</bold>) Same as E. for the distance (in octaves) between the best frequency of each neuron to the easy Go-stimulus (adolescents p=0.0816, adults p=0.6391, Kruskal-Willis Test after Tukey-Kramer correction for multiple comparisons). (<bold>H</bold>) Same as E. for the average neuronal d’ of frequencies in the learned frequency spectrum (adolescents p=0.1627, adults p=0.0026, Kruskal-Willis Test after Tukey-Kramer correction for multiple comparisons).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106387-fig7-v1.tif"/></fig><fig id="fig7s1" position="float" specific-use="child-fig"><label>Figure 7—figure supplement 1.</label><caption><title>Learning<italic> </italic>related changes in neuronal tuning properties in primary and secondary auditory cortex<italic>.</italic></title><p>(<bold>A</bold>) Tuning bandwidth in AUDp at 62 dB SPL of neurons in adolescents and adults. Side-by-side comparisons of novice versus experts. (adolescents p=0.0438, adults p=0.0001, Kruskal-Willis Test after Tukey-Kramer correction for multiple comparisons). (<bold>B</bold>) Same as ‘A’ for the population sparseness in AUDp (adolescents p=0.5724, adults p=0.0066, Kruskal-Willis Test after Tukey-Kramer correction for multiple comparisons). (<bold>C</bold>) Same as ‘A’ for the distance (in octaves) between the best frequency of each neuron to the easy Go-stimulus in AUDp (adolescents p=0.0001, adults p=0.0201, Kruskal-Willis Test after Tukey-Kramer correction for multiple comparisons). (<bold>D</bold>) Same as ‘A’ for the average neuronal d’ of pairs of frequencies limited to the learned frequency spectrum in AUDp (adolescents p=0.0471, adults p=0.0321, Kruskal-Willis Test after Tukey-Kramer correction for multiple comparisons). (<bold>E–H</bold>) Same as A-D but in the AUDv. (<bold>E</bold>) Adolescents p=0.9982, adults p=0.0427, Kruskal-Willis Test after Tukey-Kramer correction for multiple comparisons. (<bold>F</bold>) Adolescents p=0.8841, adults p=0.8031, Kruskal-Willis Test after Tukey-Kramer correction for multiple comparisons. (<bold>G</bold>) Adolescents p=0.9910, adults p=0.0042, Kruskal-Willis Test after Tukey-Kramer correction for multiple comparisons. (<bold>H</bold>) Adolescents p=0.9438, adults p=0.0108, Kruskal-Willis Test after Tukey-Kramer correction for multiple comparisons.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-106387-fig7-figsupp1-v1.tif"/></fig></fig-group><p>We characterized the response profile of ACx neurons using a ‘frequency-response area’ protocol composed of twenty pure tones (4–40 kHz, spaced at 0.1661 octaves steps), each played for 100 ms at five different attenuations (72–32 dB SPL). We limited our analysis to significant excitatory units only, determined as being auditory responsive in a window from tone onset to 50 ms after tone offset at 62 dB SPL. We then focused our tuning analysis on responses to 62 dB SPL because this sound level was close to the intensity used during the behavioral task (72 dB SPL), while still avoiding potential ceiling effects observed at higher SPLs in recordings of mice not engaged in the task.</p><p>Our dataset included four groups. The two adolescent groups were: (1) adolescent novices, and (2) adolescent experts, with 92 and 80 neurons, respectively. The two adult groups were: (3) adult novices, and (4) adult experts, with 123 and 84 neurons, respectively. Neurons in all groups responded to pure tone as expected from previous studies in adult mice, including classical V-shaped frequency response areas (<xref ref-type="bibr" rid="bib19">Feigin et al., 2021</xref>; <xref ref-type="bibr" rid="bib57">Rothschild et al., 2010</xref>; <xref ref-type="bibr" rid="bib13">Cohen and Mizrahi, 2015</xref>; <xref ref-type="bibr" rid="bib12">Cohen et al., 2011</xref>; <xref ref-type="bibr" rid="bib44">Maor et al., 2016</xref>). A representative example from a responsive neuron of an adolescent expert and one from an adult expert are shown in <xref ref-type="fig" rid="fig7">Figure 7b and c</xref>. To assess differences in pure-tone responses between auditory subregions, we quantified the firing properties of AUDp versus AUDv <xref ref-type="supplementary-material" rid="supp8">Supplementary file 8</xref>; TEa and AUDd were excluded since fewer than 20 units responded to the FRA protocol after task engagement, see (<xref ref-type="supplementary-material" rid="supp7">Supplementary file 7</xref>). We found that the latency to peak was slower in adolescent AUDp. The FWHM and minimal latency were slower in the adolescents in both AUDp and AUDv. In the adolescent AUDv, additional parameters (like spontaneous- &amp; evoked-FR, trial-responsiveness, lifetime sparseness), were different than those in adults. There were no significant differences between AUDp and AUDv within age groups (<xref ref-type="supplementary-material" rid="supp8">Supplementary file 8</xref>).</p><p>Next, we tested the learning-related effects among the different groups. The peak of frequency tuning was heterogeneous across the frequency range with no clear trends of learning or age (<xref ref-type="fig" rid="fig7">Figure 7d</xref>). To quantify these responses, we calculated tuning width (<xref ref-type="fig" rid="fig7">Figure 7e</xref>), population sparseness (<xref ref-type="fig" rid="fig7">Figure 7f</xref>), the distance between the best frequency of the neurons and the Go frequency of the easy task (<xref ref-type="fig" rid="fig7">Figure 7g</xref>), and single neuron discriminability (<xref ref-type="fig" rid="fig7">Figure 7h</xref>). As expected from previous work, learning significantly changed (3 out of 4) neuronal tuning properties in adults (<xref ref-type="fig" rid="fig7">Figure 7e–h</xref>, ‘Adults’). Surprisingly, however, learning had no significant effects on any of these single neuron parameters in the adolescent group (<xref ref-type="fig" rid="fig7">Figure 7e–h</xref>). To test this at specific brain regions, we analyzed AUDp and AUDv separately, which revealed specificity in learning-induced changes. Learning significantly affected 3 out of the 4 parameters in AUDp of adolescents (<xref ref-type="fig" rid="fig7">Figure 7</xref>, <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1a-d</xref>). However, neurons from AUDv of adolescents showed no learning-induced changes (<xref ref-type="fig" rid="fig7">Figure 7</xref>, <xref ref-type="fig" rid="fig7s1">Figure 7—figure supplement 1e - h</xref>). Notably, adult learning-induced plasticity was stronger than that in adolescence in all parameters besides the ‘BF to Go’ (<xref ref-type="fig" rid="fig6s1">Figure 6—figure supplement 1</xref>). Thus, despite the notion that adolescents’ brains may be more plastic than adults, we found generally stronger learning-induced plasticity in basic tuning properties in adults. These results underscore that learning-induced plasticity manifests differently in adolescents and adults.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>The term ‘stormy adolescence’ aptly captures what we know from psychology, neuroscience, and biology—that adolescence is a period of turbulent development, which shapes the individual’s future behavior and health (<xref ref-type="bibr" rid="bib58">Sawyer et al., 2012</xref>; <xref ref-type="bibr" rid="bib62">Spear, 2000</xref>). While numerous behavioral phenomena of adolescence have been studied, particularly in humans, the neural underpinnings of these remain largely unknown (<xref ref-type="bibr" rid="bib15">Dahl et al., 2018</xref>). In this study, we focused on (auditory) cortical neurons of the adolescent brain of mice while they were engaged in an auditory discrimination task. We found numerous differences in behavior, single neuron activity, and population encoding between adolescents and adults.</p><sec id="s3-1"><title>Adolescence behavior – perceptual and cognitive differences</title><p>We utilized the Educage platform to compare between adolescents and adults (<xref ref-type="bibr" rid="bib45">Maor et al., 2020</xref>). The Educage provides an optimal environment for training young mice; its automated nature minimizes human handling, which increases efficiency and reduces to a minimum any interference during the training process. Using the Educage, we found that procedural learning was intact in pre-adolescent mice (P23-P30), and behavioral differences were found only after the mice learned the task during the hard discrimination phase (P30-37). Compared to adults, adolescent mice scored lower on the hard versions of the task (<xref ref-type="fig" rid="fig1">Figure 1i–j</xref>). Interestingly, our data suggests that the lower performance in the hard task in adolescents was not due to a deficiency in perceptual sensitivity (<xref ref-type="fig" rid="fig2">Figure 2c</xref>), but rather to a cognitive deficit – namely, lick bias (<xref ref-type="fig" rid="fig2">Figure 2d</xref>). This result is perhaps not surprising since higher lick bias is a cognitive phenomenon that has been well documented in adolescence as a maturation period of inhibitory control (<xref ref-type="bibr" rid="bib54">Reynolds et al., 2019</xref>). Indeed, additional cognitive control mechanisms are still developing during this age (<xref ref-type="bibr" rid="bib46">Meyer and Bucci, 2016</xref>; <xref ref-type="bibr" rid="bib43">Magis-Weinberg et al., 2019</xref>; <xref ref-type="bibr" rid="bib11">Cohen et al., 2010</xref>).</p><p>Another manifestation of weaker cognitive control mechanisms is the noisy behavioral performance of adolescents (<xref ref-type="fig" rid="fig2">Figure 2h–j</xref>). While this noise may reflect higher plasticity and potentially serve cognitive flexibility (<xref ref-type="bibr" rid="bib33">Johnson and Wilbrecht, 2011</xref>; <xref ref-type="bibr" rid="bib14">Crone and Dahl, 2012</xref>), it poses a disadvantage for the precision and consistency required in our task. This noise may also arise from changes in pubertal hormones, which we did not manipulate (<xref ref-type="bibr" rid="bib41">Kunkhyen et al., 2018</xref>). Notably, few studies have explicitly characterized auditory discrimination of adolescents in rodents; the majority of these have been carried out in gerbils using an amplitude modulation (AM) detection task (<xref ref-type="bibr" rid="bib9">Caras and Sanes, 2019</xref>; <xref ref-type="bibr" rid="bib3">Anbuhl et al., 2022</xref>; <xref ref-type="bibr" rid="bib8">Buran et al., 2014</xref>). Despite the different tasks, many of our age-related findings are aligned with the findings in gerbils, including lower performance in adolescents, and greater variance in adolescent behavior (<xref ref-type="bibr" rid="bib9">Caras and Sanes, 2019</xref>). However, some findings differ. For example, the lick bias which was different in our data, was similar between young and adult gerbils in an AM modulation detection task. This difference may arise from differences in task design, as well as the severity of the punishment used in the task (here, we used a milder punishment). Here, our data support a view that cognitive factors, and to a lesser extent perception of pure tones per se, are the primary contributors to the poorer performance observed in adolescent mice when performing a pure-tone sound discrimination task.</p></sec><sec id="s3-2"><title>Representation of stimulus and choice in ACx still undergoes maturation in adolescence</title><p>Motivated by the abovementioned behavioral differences, we tested how single neurons in ACx represented sounds (by comparing Hits vs FA) and choices (by comparing FA to CR). While cortical representations of sounds in ACx could be the basis of perceptual constraints, distinct processing of choices would reflect that more cognitive mechanisms are involved. We found that cortical representations of sounds and choices in mice engaged in the task were still immature as compared to adults, e.g., responses in adolescents were more delayed and less informative (<xref ref-type="fig" rid="fig4">Figures 4</xref>—<xref ref-type="fig" rid="fig6">6</xref>). These differences can be a result of age-related differences, and/or the result of a combined ‘age x learning’ effect.</p><p>We found only modest age-related differences in spiking activity of layer 5/6 neurons between adolescents and adults (<xref ref-type="fig" rid="fig7">Figure 7</xref>). This limited difference is perhaps not surprising because the CP for tonal organization in ACx is already complete by the age at which we tested the animals i.e., on P37-P42 (<xref ref-type="bibr" rid="bib29">Hensch, 2005</xref>; <xref ref-type="bibr" rid="bib6">Barkat et al., 2011</xref>). In contrast, more pronounced differences emerged from the interaction of ‘age x learning,’ specifically in mice that learned the task and were actively engaged in the behavior (<xref ref-type="fig" rid="fig4">Figure 4f</xref>; <xref ref-type="fig" rid="fig6">Figure 6d–g</xref>). This interaction is evident in the lower single-neuron discriminability (AUC) during the hard task in expert adolescent mice (<xref ref-type="fig" rid="fig6">Figure 6d</xref> vs. 6 f). While this may seem counterintuitive, it is compatible with the idea that learning can drive complex reorganization in sensory representations. For example, we recently showed that learning leads to distinct and sometimes opposing effects on single-neuron responses with respect to whether the task is perceptually easy or difficult (<xref ref-type="bibr" rid="bib25">Haimson et al., 2024</xref>). It is also important to note that our recordings were restricted to infragranular layers (5/6) and did not sample supragranular (layers 2/3) neurons, which may exhibit distinct learning-related plasticity (<xref ref-type="bibr" rid="bib37">Kanold et al., 2014</xref>). As such, the developmental differences we report may reflect layer-specific properties of the deep output layers.</p><p>We speculate that immature feedback to ACx may underlie these differences for several reasons. First, feedback from higher cortical regions to more primary cortices has been proposed as a neural substrate for difficult perceptual discriminations (<xref ref-type="bibr" rid="bib2">Ahissar and Hochstein, 2004</xref>; <xref ref-type="bibr" rid="bib1">Ahissar and Hochstein, 1997</xref>). Second, feedback activity (often referred to as ‘top down’) is thought to be the key neural pathway involved in cognitive control mechanisms (<xref ref-type="bibr" rid="bib72">Zagha, 2020</xref>). Feedback is typically expressed in the late (&gt;100 ms) phase of single neurons activity, which was significantly different between adults and adolescents across our measured parameters (onset-latency, duration of discriminability, and maximal discriminability; <xref ref-type="fig" rid="fig4">Figure 4g</xref>, <xref ref-type="table" rid="table2">Table 2</xref>, <xref ref-type="table" rid="table3">Table 3</xref>). The precise source of feedback that contributes to perceptual or cognitive differences remains to be determined, but likely candidates include regions that project to ACx (<xref ref-type="bibr" rid="bib66">Tasaka et al., 2020</xref>; <xref ref-type="bibr" rid="bib67">Tasaka et al., 2023</xref>), such as medial prefrontal cortex (<xref ref-type="bibr" rid="bib16">Delevich et al., 2021</xref>; <xref ref-type="bibr" rid="bib39">Konstantoudaki et al., 2018</xref>), orbitofrontal cortex (<xref ref-type="bibr" rid="bib34">Johnson et al., 2016</xref>), or anterior cingulate (<xref ref-type="bibr" rid="bib47">Nabel et al., 2020</xref>). Testing the causal role of these regions during adolescence will be an important direction for future research.</p><p>Cortical coding is performed by populations of neurons, which can efficiently encode stimuli on a trial-by-trial basis (<xref ref-type="bibr" rid="bib18">Druckmann and Chklovskii, 2012</xref>; <xref ref-type="bibr" rid="bib36">Kang and Druckmann, 2020</xref>; <xref ref-type="bibr" rid="bib42">Li et al., 2016</xref>; <xref ref-type="bibr" rid="bib69">Wei et al., 2019</xref>; <xref ref-type="bibr" rid="bib70">Wei et al., 2020</xref>). Population coding, as measured here by decoding accuracy, largely recapitulated the results of the single neuron data. Specifically, cortical populations in adults encoded the different tones better and faster; particularly in the hard task (<xref ref-type="fig" rid="fig5">Figure 5a–c</xref>). Interestingly, by testing the quality (i.e. separation) of the decoding performance, we revealed a correlation between decoding in the easy and hard tasks in adult (<xref ref-type="fig" rid="fig5">Figure 5d</xref>). While this result reflects the collapsed information of stimulus and choice, it suggests that the cortical network uses shared representation for decoding the easy and hard tasks, possibly by the same neurons. This is consistent with our recent work showing that indeed the same neurons in ACx respond to the same stimulus differently, depending on if the mouse is engaged in discriminating an easy sound pair or a hard sound pair (<xref ref-type="bibr" rid="bib25">Haimson et al., 2024</xref>). The shallower slopes in adolescence suggest a less efficient decoding scheme that may arise from different populations of neurons encoding task-related information.</p><p>Our optogenetic silencing of ACx in expert adult mice resulted in a marked suppression of licking behavior (<xref ref-type="fig" rid="fig3">Figure 3</xref>, <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2</xref>), consistent with the idea that ACx contributes to task performance. However, the strength of the observed effect raises the possibility that the manipulation may have impacted broader aspects of behavior—such as arousal, motivation, or motor readiness—rather than selectively disrupting auditory discrimination. Recent work (<xref ref-type="bibr" rid="bib17">Drieu et al., 2025</xref>) suggests that ACx plays a critical role during learning by supporting higher-order computations but may become less essential for task execution once mice reach expert performance. These findings, together with previous reports (<xref ref-type="bibr" rid="bib49">O’Sullivan et al., 2019</xref>; <xref ref-type="bibr" rid="bib10">Ceballo et al., 2019</xref>), indicate that the necessity of ACx for auditory-guided behavior may depend on task structure, training stage, and the exact nature of the manipulation. The robust decrease in lick rate and performance observed in our experiment may reflect the intensity, specificity, and timing of the silencing. The use of GtACR2, a highly potent silencer, may have further amplified the effect. We cannot rule out the possibility that silencing the output from ACx also disrupted the flow of information to downstream areas, thereby exerting a stronger influence on perception and behavior. Although the injection was targeted to the ACx, off-target effects are also likely to have contributed. Future experiments using graded or temporally specific perturbations will be useful to define more precisely the contribution of ACx across learning and development.</p></sec><sec id="s3-3"><title>Learning in the adolescent brain</title><p>Cortical representations of pure tones have a critical period (CP) between P12-P15 (<xref ref-type="bibr" rid="bib6">Barkat et al., 2011</xref>; <xref ref-type="bibr" rid="bib7">Bhumika et al., 2020</xref>; <xref ref-type="bibr" rid="bib48">Nakamura et al., 2020</xref>). Indeed, we chose to study animals at P37-P42 on a pure tone discrimination task precisely to avoid the hypersensitivity associated with this CP. But this may be unavoidable, as recent work has shown that ACx also has a later CP for more complex sounds features (<xref ref-type="bibr" rid="bib7">Bhumika et al., 2020</xref>; <xref ref-type="bibr" rid="bib48">Nakamura et al., 2020</xref>). Those late CPs overlap with our training schedule and the underlying biological manifestation of this CP is expected to affect learning-related plasticity in general. The underlying mechanism of the late CP to complex sounds has been associated with dynamic changes of inhibitory circuits (<xref ref-type="bibr" rid="bib65">Takesian et al., 2012</xref>; <xref ref-type="bibr" rid="bib64">Takesian et al., 2010</xref>). Thus, immature inhibitory circuits remain sensitive in adolescents, and could affect how pure tones are represented, despite the closure of the classic tonal CP. Notably, sound discrimination learning changes tonal representations even in adult mice, well after the closure of CP’s for both simple and complex sounds (<xref ref-type="bibr" rid="bib45">Maor et al., 2020</xref>; <xref ref-type="bibr" rid="bib4">Bao et al., 2004</xref>; <xref ref-type="bibr" rid="bib25">Haimson et al., 2024</xref>). We hypothesize, therefore, that the differences in performance on more difficult discriminations between adolescents and adults are shaped primarily by age-specific learning-related plasticity, rather than by differences in pure tone representation per se.</p><p>Taken together, our findings show that cortical responses in adolescents differ from those in adults. Notably, both groups learned the same pure tone discrimination task under identical training protocols. Although the CPs for pure tones are considered closed by this age, learning to discriminate between tones still varies across developmental stages. It remains unclear how later CPs, such as those shaping responses to amplitude modulation or frequency-modulated sweeps through inhibitory circuits, contribute to these differences. Likewise, the role of ongoing maturation in cognitive control, including the development of feedback pathways, warrants further investigation. Nevertheless, it is evident that developmental processes in the adolescent brain continue to influence how even simple sounds are encoded through learning. The adolescent-specific plasticity observed here directly reflects on how perceptual and cognitive features are integrated within the auditory cortex.</p></sec><sec id="s3-4"><title>Inclusion and diversity</title><p>We support inclusive, diverse, and equitable conduct of research.</p></sec></sec><sec id="s4" sec-type="methods"><title>Methods</title><sec id="s4-1"><title>Animals</title><p>A total of 47 (37 female and 10 male) C57BL/6 mice were used in this study. Adolescent mice were weaned at postnatal (P) day 20. Adult mice were trained starting from P60. All mice were housed on a 12 hr light/12 hr dark cycle with food and water ad libitum, unless used for behavioral training (see below). All experiments were approved by the Institutional Animal Care and Use Committee (IACUC) at the Hebrew University of Jerusalem, Israel (Permit Number: NS-21-16448-4, NS-21-16694-4, NS-22-16966-4).</p></sec><sec id="s4-2"><title>Surgical procedures</title><p>The details for surgical procedures were identical to those used in previous studies from our laboratory (<xref ref-type="bibr" rid="bib45">Maor et al., 2020</xref>; <xref ref-type="bibr" rid="bib19">Feigin et al., 2021</xref>; <xref ref-type="bibr" rid="bib66">Tasaka et al., 2020</xref>; <xref ref-type="bibr" rid="bib21">Gilad et al., 2020</xref>; <xref ref-type="bibr" rid="bib23">Gilday et al., 2023b</xref>; <xref ref-type="bibr" rid="bib61">Shani-Narkiss et al., 2020</xref>; <xref ref-type="bibr" rid="bib22">Gilday and Mizrahi, 2023a</xref>). The relevant procedures are briefly described below.</p><sec id="s4-2-1"><title>RFID Implantation</title><p>24 hr before the start of behavioral training in the automated home-cage, mice were implanted with a radio frequency identification (RFID) chip (Trovan, EX). Animals were anesthetized with 2% isoflurane with pure O2 as carrier. RFID chips were implanted under the scruff. After implantation, mice were injected with 0.04 mg/g of 10% Meloxicam solution to prevent infection and alleviate any possible pain from the implantation.</p></sec><sec id="s4-2-2"><title>Head-bar implantation &amp; craniotomy</title><p>48 hr before the start of behavioral training on the head-fixed recording setup, mice were anesthetized with 2% Isoflurane, the body temperature maintained at 37 °C and the eyes were covered with 5% Chloramphenicol ointment to prevent from drying. Before removal of the scalp, we applied 4% Lidocaine above the skin and skull area. Afterwards, we glued a custom-made titanium bar at the back of the mouse skull using dental cement (Meta-bond). To enable acute recordings in ACx, we performed a craniotomy on the left hemisphere at 2.5 mm posterior and 4.0 lateral to the bregma. The craniotomy was protected by a pool of dental cement and covered with a silicone elastomer (WPI; Kwik-Cast catalog #KWIK CAST). After the craniotomy, mice were injected with 0.04 mg/g of 10% Meloxicam solution and 0.2 ml of Saline. During the 48 hr of recovery, mice received two further doses of 0.04 mg/g of 10% Meloxicam solution. 24 hr before recordings, mice were again anesthetized to remove regrowth of the duramater during training. The area around the craniotomy was cleaned with hydrogen peroxide (3%), the silicon elastomer was replaced, and another dose of 10% meloxicam was injected.</p></sec><sec id="s4-2-3"><title>Virus injection &amp; cannula implantation</title><p>The surgical procedure was similar to the <italic>head-bar implantation &amp; craniotomy</italic>. The differences in the procedure are outlined below. Bilateral craniotomies were performed at 2.5 mm posterior and 4.3 mm lateral to the bregma. We injected 200 nl AAV5-CAMKII-GtACR2-FRED_kv_2.1, or 200 nl AAV9-CAMKII-dTomato. Both viruses were produced at the ELSC virus-core facility. We injected the virus at a depth of 1.1 mm at 0°. Afterwards, we inserted a 0.2 mm diameter optical fiber with an attached cannula (CFML1202; Thorlabs) at a depth of 0.9 mm at 0°, bilaterally. We chronically fixed the fiber position on the skull using dental cement (Meta bond).</p></sec></sec><sec id="s4-3"><title>Auditory stimuli</title><p>Sound stimuli were delivered from a calibrated free-field speaker (ES1 SN:4568) using a multifunction processor (ED1; Tucker-Davis Technologies). The speakers were calibrated with a free-field microphone (Type 4939, Bruel and Kjaer). The stimuli were comprised of pure tones, sampled at 500 kHz, between 7.07–14 kHz for behavioral training and 4–40 kHz for passive listening. All stimuli were played at sound pressure levels of 72 dB SPL for behavioral training, and 72-, 62-, 52-, 42-, and 32 dB SPLs for passive listening. All tones were played in randomized order.</p></sec><sec id="s4-4"><title>Behavior</title><sec id="s4-4-1"><title>Automated home-cage training (the ‘Educage’<italic>)</italic></title><p>For a detailed description of the EduCage behavioral platform, see <xref ref-type="bibr" rid="bib45">Maor et al., 2020</xref>. After RFID implantation, groups of 5 mice were placed in their home cage that was connected to a behavioral chamber called the Educage (<xref ref-type="fig" rid="fig1">Figure 1a</xref>). Mice were provided with food ad libitum. Water access was restricted to the Educage chamber. Mice could access the Educage freely to retrieve water mixed with 5% sucrose. The behavioral training was controlled by a custom LabView 2019 (National Instruments) program running on BNC-2110 (National Instruments) and FPGA (MyRIO – National Instruments) to register licks, RFIDs numbers, and deliver stimuli and reinforcements. Every time a mouse entered the water port its RFID was automatically recognized, a trial initiated, and an auditory stimulus played from a speaker vertically positioned above the behavioral chamber. We trained mice gradually for three weeks on a Go/No-Go paradigm of pure tones, spaced around a category boundary of 10 kHz. This paradigm enabled us to efficiently compare between adolescent and adult behavior, since learning was restricted from post-weaning (P20) to adolescence (P37) (correspondingly, adults were trained from P60-P77). Mice were trained in four separate training phases (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). For the first 24 hr (P20-P21 in the adolescent group of mice and P60-P61 in adult mice) mice were habituated to the behavioral chamber and could approach the port freely to retrieve water after licking the waterspout (0.0015 ml per trial). During the following 48 h (P21-P23 in the adolescent group of mice and P61-P63 in adult mice), mice underwent a tone-association phase. All tones played were 300 ms long (sampled at 500 kHz). Tone association was restricted to the lowest Go tone (7.07 kHz at 100% probability). Mice received a water reward in response to licking during the first 2 seconds after tone offset. This was followed by the first tone-discrimination stage, which contained a No-Go tone (14.14 kHz at 45% probability) at 1 octave away from the Go tone. We analyzed four response outcomes—Hits, Misses, Correct Rejections, False Alarms— in the 2 s response window after the tone-offset. ‘Hits’ were counted after five successful licks to the Go-tone and followed by a water reward. ‘Misses’ were counted when licks to the Go-tone trials did not pass the lick threshold. Correspondingly, ‘Correct Reject’ (CR) trials were all No-Go trials below the lick threshold. CR trials were not reinforced. ‘False Alarms’ (FA) were counted when 5 or more licks were registered after the No-Go. FA trials were followed by a white-noise punishment (5–20 kHz at 72 dB SPLs, 2 s) and an inter trial delay of 5 s. In addition, mice were exposed to five probe trials (tones whose trial outcome that were neither rewarded nor punished at 8.49 kHz, 9.567 kHz, 10 kHz, 10.44 kHz, and 11.89 kHz; played at 2% per tone). Mice trained on the 1-octave tone discrimination for 1 week (P23-P30 in adolescent mice and P63-P70 in adult mice). Next, we added a second pair of tone - a Go/No-Go tone pair spaced 0.25 octaves apart (9.17 kHz and 10.95 kHz) for another week of training. All tones were played in randomized order, and trial difficulties of the easy and the hard task were intermingled. The experiment was terminated at age P37 for adolescent and P77 for adult mice.</p></sec><sec id="s4-4-2"><title>Head-fixed training</title><p>We used a head-fixed paradigm that enabled us to efficiently train adolescent and adult mice on the same task and record from engaged mice after learning. We trained mice on the same Go/No-Go stimulus setup of the Educage described above with few differences which are outlined below.</p><p>The head-fixed behavioral training was controlled by a custom MATLAB 2023B (Mathworks) program running on BNC-2110 (National Instruments) to register licks and deliver stimuli and reinforcements. Mice were water-restricted for 24 hr prior to training, and their weight monitored daily. While training on the setup, mice received water supplemented with 5% sucrose, depending on their weight (0.125 ml per g of body weight). Additional water, in the form of Hydrogel (ClearH2O) was given after daily training if mice did not consume the required amount during training, or their body weight dropped below 85% of the pre-restriction weight. Mice were gradually habituated to the setup by head-fixation and received free water after licking, during the first training day (P23 in adolescent mice and P63in adult mice). Licking was measured with an optical lick-meter (Sanworks). During the second training day mice were associated with a tone. All tones of the task were 100 ms long (sampled at 500 kHz). Mice received a water reward in response to licking in the first 2 s after tone offset. Reward reinforcement was delayed to 0.5 s after the tone offset. To break the regularity of the trial sequences, we applied a dynamic inter-trial interval of 6–8 s. New trials were initiated if mice did not lick the spout at least 2 s prior to the upcoming trial. Mice were familiarized with the tone for at least two training days (P24-26 in adolescent mice and P64-66 in adult mice). Then, and when the lick rate was above 80%, mice proceeded to the first tone discrimination stage. We gradually increased the probability of No-Go trials, depending on the lick rate of the mouse. We added the 0.25 octave Go/No-Go tone pair, after a maximal of seven training days on the 1 octave tone pair (P26-33 in adolescent mice and P66-73 in adult mice), or if the behavioral performance exceeded a threshold of d’=1, as calculated using the signal detection metric. Similar to the Educage, all tones were played in randomized order and trial difficulties of the easy and the hard task were intermingled. Mice were trained until P37 in the adolescent group and P77 in the adult group.</p></sec></sec><sec id="s4-5"><title>Optogenetic manipulation</title><p>Adult mice (P60) were injected with AAV5-CAMKII-GtACR2-FRED_kv_2.1 (n=3) and implanted with cannulas prior to training as described above. Mice underwent optogenetic stimulation after training on the head-fixed task by attaching a ferrule patch cable (M79L01; Thorlabs) to the implanted cannula using a mating sleeve (ADAF1; Thorlabs). The ferrule cable end (SMA connector) was connected to an LED driver setup (LEDD1B; Thorlabs) that enabled us to send precise outputs at 476 nm (blue light; 5 mW) bilaterally. To test the effect of ACx inhibition on task performance, we timed the LED output to 50 ms before tone onset until 50 ms after tone offset. The LED consisted of pulses given at 10 Hz for 200 ms.</p><p>Behavioral sessions of optogenetic manipulation were identical to the Go/No-Go paradigm of previous training sessions. We inhibited ACx in 50% of the trials in randomized order. Optogenetic manipulations were repeated throughout multiple sessions of expert performance. As a control, we repeated the same experiment in mice injected with AAV9-CAMKII-dTomato (n=3). After completion of the experiment, animals were deeply anesthetized with ketamine and medetomidine (0.008 g/kg, and 0.65 mg/kg, respectively) and then perfused with 4% Paraformaldehyde. After the perfusion, the brain was extracted and preserved. We then sectioned the ACx using a cryostat (Leica) into 0.05 mm thick coronal slices. Afterwards, brain slices were washed one time under 1% Phosphate-buffered saline (PBS), and a second time with 1% PBS plus 0.4% Triton. Finally, slides were mounted and stained with DAPI (4%) and imaged using a wide-field fluorescent microscope (Olympus Life Science, Olympus IX83), to reconstruct the probe position offline.</p></sec><sec id="s4-6"><title>Extracellular recordings</title><sec id="s4-6-1"><title>Recording setup</title><p>Before the onset of the recording session, we removed the silicon elastomer and placed an external reference electrode (Ag/AgCl wire) on the skull of the right hemisphere. All recordings were performed using Neuropixels 1.0 (Npx; IMEC, phase 3 A), together with a base-station connected to a chassis (IMEC; NI PXIe –1071, National Instruments). Probes were mounted to a custom-made steel rod and connected to the ground. Before penetration, probes were covered with a fluorescent dye Dil Invitrogen catalog #V22885- red, or Dio (Invitrogen catalog #V22886 – yellow), to reconstruct penetration sites after the recording.</p><p>Then, Npx probes were inserted into the left ACx at 30° to a depth of 3.85 mm (this approach limited our recording to deep layers of the ACx). The skull surface was submerged in saline and the probe was allowed to settle for 10 min. We sampled recordings at 20 kHz, with action potential band filtered to contain 0.3- to 10 kHz frequencies. Action potential band gain was set to 500. Out of the 960 available sites on the 1 cm shank of the Npx probe (<xref ref-type="bibr" rid="bib35">Jun et al., 2017</xref>), we acquired the 384 lowest recording shanks in a staggered configuration. We used common-average referencing to process the voltage traces.</p></sec><sec id="s4-6-2"><title>Recording schedule</title><p>We performed recordings of both novice and expert adolescent and adult mice. Novice recordings were performed after tone-association (see <italic>head-fixed training;</italic> adolescent n=3; adult n=3). Expert recordings were performed after learning (adolescent n=5; adult n=6). Both novice and expert recordings include the easy (1 octave) and hard (0.25 octave) tone pair. Both recordings were performed after P37 for adolescent mice and after P77 for adult mice. Tone probabilities and protocol parameters were identical to the <italic>head-fixed training</italic>. Each mouse was recorded multiple times (novice recordings adolescents n=6; novice recording adults n=6; expert recordings in adolescents n=13; expert recordings in adults n=14). In some mice, after the recording in the engaged configuration, we recorded neural activity under passive listening conditions to a pure tone protocol (novice recordings adolescents n=6; novice recording adults n=6; expert recordings in adolescents n=4; expert recordings in adults n=4). The pure tone protocol was comprised of 20 different frequencies, logarithmically spaced between 4 and 40 kHz, presented at five sound pressure levels (see <italic>Auditory stimuli</italic>). Each frequency and attenuation combination were presented 16 times. The tone interval was set to 1 s. After completion of the recording schedule, animals were deeply anesthetized with ketamine and medetomidine (0.008 g/kg, and 0.65 mg/kg, respectively) and perfused with 4% Paraformaldehyde. After the perfusion, we performed histological analysis and sectioned coronal brain slices as described above (see <italic>Optogenetic Manipulation</italic>) to reconstruct the exact probe position.</p></sec><sec id="s4-6-3"><title>Preprocessing &amp; spike-sorting</title><p>All recordings were sorted using Kilosort 2.5/3 open-source software (<xref ref-type="bibr" rid="bib50">Pachitariu et al., 2016</xref>; <ext-link ext-link-type="uri" xlink:href="https://github.com/MouseLand/Kilosort">https://github.com/MouseLand/Kilosort</ext-link>; <xref ref-type="bibr" rid="bib51">Pennington and Pachitariu, 2025</xref>). After automatic sorting, we performed manual curation of the acquired units using ‘Phy-2’ open-source GUI. (UCL; <ext-link ext-link-type="uri" xlink:href="https://github.com/cortex-lab/phy">https://github.com/cortex-lab/phy</ext-link>; <xref ref-type="bibr" rid="bib56">Rossant, 2024</xref>). During manual curation, we distinguished between single units (SUs) and noise (pre-labeled multi-units in Kilosort2.5/3 were automatically labelled as noise). The following parameters were set to determine SUs: physiologically plausible waveform shape (1–2 ms, biphasic/triphasic), high spike-amplitude (&gt;50 µV, SNR &gt;3), physiologically plausible refractory period (ISI &gt;4 ms), sufficient inter-spike-interval (ISI peak 5–10 ms), sufficient firing-rate across the recording (&gt;0.1 spikes/s), and principal component cluster density (high density and low overlap). In addition, SUs were compared to neighboring units, based on waveform, firing rate, drift-pattern, and cross-correlograms to determine merging of two SUs into a single cluster (Pearson Correlation Coefficient &gt;0.8). Units that passed the above-mentioned criteria were considered single units (SUs).</p></sec></sec><sec id="s4-7"><title>Data analysis</title><p>The analysis was performed with MATLAB R2023b (MathWorks) and Python3.13 (PyCharm 2024.1.3). Violin plots are presented with the median (white dot) together with the interquartile range. Boxplots are presented with the median (horizontal line), mean (gray dot), and quartiles (box). Temporal plots are presented as the mean (line) and the standard error of the mean (patched or error bar).</p><sec id="s4-7-1"><title>Behavioral analysis</title><p>We categorized behavioral responses of the task into hit, miss, false alarm, and correct reject responses. To compare behavioral performance, we calculated the d’ value based on the signal detection metric (d’=the inverse normal distribution of the z-scored hit rate) – the z-scored (false alarm rate). Z-scored values of 1 were rounded to 0.99, to avoid d’ approaching infinity. Unless, defined differently d’ was defined for the last 100 trials. Next, we calculated psychometric curves based on the lick rate (above the lick threshold) to learned and probe trials (<xref ref-type="fig" rid="fig2">Figure 2b, c and e</xref>). Psychometric curves were normalized and fitted to a sigmoidal function, defined as follows:<disp-formula id="equ1"><label>(1)</label><alternatives><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>S</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>a</mml:mi><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mfrac><mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>c</mml:mi></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t1">\begin{document}$$\displaystyle S\left (t\right)=a\frac{1}{1+e^{\frac{- \left (t- b\right)}{c}}}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Where <italic>a</italic> denotes the lick rate, <italic>b</italic>=the time of the inflection point, and <italic>c</italic>=the steepness of the curve. Based on the normalized psychometric curve, we extracted two inflection points (random lick rate at 0.5 and category boundary at 10 kHz). To compare the heterogeneity of adolescent and adult behavior, we calculated the criterion bias as the inverse normal distribution of the –0.5*(z-scored (hit rate)+z-scored (false alarm rate)) and analyzed the coefficient of variation (CV) of behavior across the learning. We applied similar behavioral measurements to the Educage training and head-fixed training, as well as recordings and optogenetic manipulation during task performance. During expertperformance in the head-fixed task, we analyzed the running d’ as the average performance of bins of 25 trials (<xref ref-type="fig" rid="fig3">Figure 3</xref>). In addition, we also calculated the average lick trace during the reinforcement delay. Here, we also extracted the lick latency per trial per mouse, defined as the lick latency from tone-onset (<xref ref-type="fig" rid="fig3">Figure 3</xref>).</p></sec><sec id="s4-7-2"><title>Neuronal analysis</title><p>Probe trajectories and location of SUs were reconstructed using Allen CCF tools (<ext-link ext-link-type="uri" xlink:href="https://github.com/cortex-lab/allenCCF">https://github.com/cortex-lab/allenCCF</ext-link>; <xref ref-type="bibr" rid="bib60">Shamash et al., 2025</xref>; <xref ref-type="bibr" rid="bib59">Shamash et al., 2018</xref>). For further analysis, we only considered SUs that were recorded from infragranular layers 5 and layer 6. SUs from the dorsal-auditory cortex (AUDd), primary auditory cortex (AUDp), ventral auditory cortex (AUDv), and temporal association cortex (TEa) were pooled together as auditory cortex (ACx), and in some analyses presented separately (<xref ref-type="bibr" rid="bib23">Gilday et al., 2023b</xref>). Neurons were considered excitatory auditory responsive if the average spontaneous firing rate (FR) of the baseline activity preceding the tone (200 ms to 50 ms before stimulus onset) was significantly lower than the average tone-related activity (from stimulus onset until 50 ms after stimulus offset) across all trials (<xref ref-type="bibr" rid="bib19">Feigin et al., 2021</xref>). The difference was tested with a right-sided Wilcoxon signed-rank test (p&lt;0.05). Suppressed auditory responsive units and non-auditory responsive units were excluded from the analysis. Peri-stimulus time histograms (PSTHs) were smoothed with a Gaussian smoothing filter of 5 ms. To test the difference between adolescent and adult auditory firing properties in expert mice, we calculated the difference in average spontaneous FR –200 ms preceding the tone onset until tone-onset, average evoked FR (tone onset until 50 ms after tone offset) and fraction of responsive trials. We also compared the coefficient of variance of the evoked FR (mean FR divided by standard deviation of the FR across trials). Temporal differences in firing properties were compared by calculating the latency to peak (latency of the highest FR), minimal latency (first spike after tone-onset), full-width-half-maximum (FWHM; time from peak FR to baseline FR), and the lifetime sparseness, which was calculated as follows:<disp-formula id="equ2"><label>(2)</label><alternatives><mml:math id="m2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo>∑</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mi>n</mml:mi></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mo>∑</mml:mo><mml:msubsup><mml:mi>r</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mi>n</mml:mi></mml:mfrac></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mtext>/</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t2">\begin{document}$$\displaystyle  S=\left (1- \left (\frac{\left (\frac{\sum r_{i}}{n}\right)^{2}}{\frac{\sum r_{i}^{2}}{n}}\right)\right)\text{/}\left (1- \frac{1}{n}\right)$$\end{document}</tex-math></alternatives></disp-formula></p><p><inline-formula><alternatives><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><tex-math id="inft2">\begin{document}$r_{i}$\end{document}</tex-math></alternatives></inline-formula> = corresponds to the FR of each learned frequency and n equals the number of learned tones. Values of S near 0 correspond to a dense FR and values near 1 to a sparse code (<xref ref-type="bibr" rid="bib68">Vinje and Gallant, 2000</xref>).</p></sec><sec id="s4-7-3"><title>Single neuron analysis during task performance</title><p>We investigated the FR of excitatory auditory responses per trial from 200 ms preceding the stimulus up to 600 ms after the tone onset. To test how well single neurons discriminate between trial outcomes, as well as task difficulty, we calculated task-related activity per trial using receiver operating characteristics (ROC) and calculated the area under the curve (AUC) across a running window of 25 ms in bins of 50 ms (<xref ref-type="fig" rid="fig4">Figures 4</xref> and <xref ref-type="fig" rid="fig6">6</xref>). Stimulus-related activity was defined as the hit compared to the false alarm trials, separately for the 1 octave and 0.25 octave tone pair. Stimulus-related activity of miss compared to correct trials were not analyzed due to the lack of miss trials in expert performance. In addition, we also tested the average (mean of 1 octave and 0.25 octave tone pair) choice discrimination, defined as the difference between false alarm and correct reject trials (<xref ref-type="fig" rid="fig4">Figure 4</xref>). We sampled 20 trials per trial outcome and repeated the ROC encoding 100 times. Afterwards, we adjusted the average AUC values of all iterations of each neuron to its baseline AUC before the tone onset ((AUC – baseline AUC)+0.5). AUC values close to 0.5 indicate a low neuronal discriminability, and values up to 1 indicate high neuronal discriminability (<xref ref-type="bibr" rid="bib24">Green and Swets, 1966</xref>). To test significant discrimination, we repeated the ROC encoding with shuffled trial identities (20 randomly shuffled trials per trial outcomes across 100 iterations). Significant discriminability of a neuron was defined as the AUC time bins that exceed the mean ± 3 std of the shuffled distribution (<xref ref-type="bibr" rid="bib21">Gilad et al., 2020</xref>). Adolescent and adult neuronal discriminability were compared using the onset-latency of discrimination of a neuron (first timepoint &gt;mean ± 3 std of the shuffled distribution), the maximal AUC of the running window and the duration of discriminability (time duration &gt;mean ± 3 std of the shuffled distribution;). To compare novice and expert performance, we repeated the AUC encoding and compared the general discrimination of 1 octave and 0.25 octave Go and No-Go discrimination of all trial outcomes (<xref ref-type="fig" rid="fig6">Figure 6</xref>). To evaluate the correlation of behavioral performance and neuronal discriminability, we compared d’ per recording to the average of the maximal AUC of all neurons per recording. The AUC and d’ values were compared via pairwise Pearson correlation.</p></sec><sec id="s4-7-4"><title>Auditory cortex population analysis during task performance</title><p>We analyzed the population activity in the ACx of adolescent and adult mice on a trial-by-trial basis. Population activity was segregated by hit and correct-reject trials for both easy and hard tasks in each age group. We excluded recordings that contained fewer than 20 auditory-responsive neurons, fewer than 20 hit or correct-reject trials in either task. This resulted in a total of 8 adolescent sessions and 10 adult sessions. To decode the stimulus from neural activity, we applied linear-discriminant analysis (LDA) to the first 200 ms following stimulus onset. Decoding accuracy was calculated on held-out trials (10 trials per stimulus; <xref ref-type="fig" rid="fig5">Figure 5a</xref>). To examine changes in decoding accuracy over time, we used a 50 ms bin width and fitted separate LDA models at each time point, covering a period from –0.5 s to 10 s after stimulus onset (<xref ref-type="fig" rid="fig5">Figure 5c</xref>). Next, we computed the separation per session, defined as the ratio of the between-class variance to the within-class variance. Given the means <inline-formula><alternatives><mml:math id="inf3"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft3">\begin{document}$\mu _{1},\mu _{2}$\end{document}</tex-math></alternatives></inline-formula> and variances <inline-formula><alternatives><mml:math id="inf4"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft4">\begin{document}$\Sigma _{1},\Sigma _{2}$\end{document}</tex-math></alternatives></inline-formula> of the two classes, the separation is given by:<disp-formula id="equ3"><label>(3)</label><alternatives><mml:math id="m3"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>b</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi><mml:mi>w</mml:mi><mml:mi>e</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:msub><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:msup><mml:mi>w</mml:mi><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">Σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>w</mml:mi></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t3">\begin{document}$$\displaystyle S=\frac{\sigma _{between}^{2}}{\sigma _{within}^{2}}={\rm max}_{w}\frac{\left (w\left (\mu _{1}- \mu _{2}\right)\right)^{2}}{w^{T}\left (\Sigma _{1}+\Sigma _{2}\right)w}.$$\end{document}</tex-math></alternatives></disp-formula></p><p>We used robust linear regression without intercept (Huber loss) to fit the relationship between separations in easy and hard tasks (<xref ref-type="fig" rid="fig5">Figure 5d</xref>). To quantify when the decoding accuracy is significantly different from the baseline, we used the bin width with a sample frequency of 100 Hz. Baseline decoding accuracy was calculated as the mean and variance of decoding accuracy during a 500 ms window before stimulus onset, up to 50 ms before onset. Decoding latency was defined as the time from stimulus onset to the first time point where decoding accuracy exceeded three standard deviations from the baseline mean (<xref ref-type="fig" rid="fig5">Figure 5b</xref>). One adolescent session, in which behavioral d' is less than 1, has decoding accuracy that does not exceed three standard deviations from the baseline mean within the first 200 ms. Therefore, this session was excluded from the latency analysis. Finally, we assessed the single-trial variance across both age groups and tasks. Data were standardized per neuron before computing variance per stimulus (<xref ref-type="fig" rid="fig5">Figure 5e</xref>). To visualize the results, we projected the population representations to the space spanned by the two LDA decoding dimensions for the easy and hard tasks. We averaged the mean and covariance matrix across sessions for each stimulus and age group, representing the distributions with corresponding ellipses (<xref ref-type="fig" rid="fig5">Figure 5f</xref>).</p></sec><sec id="s4-7-5"><title>Single neuron analysis during passive listening</title><p>We extracted the frequency-response areas (FRAs) based on the pure-tone responses (from tone onset up to 50 ms after tone-offset) of auditory responsive neurons. The bandwidth of excited units was computed for significant excitatory responses of adjacent frequencies at 62 dB SPL and subtracted by the number of expected false-positive responses. Afterwards, the sum of significant frequency responses per neuron was multiplied by the octave distance between every frequency to receive an octave-based bandwidth measure. We then calculated the population sparseness as the fraction of significant excited responses in adolescent and adult novice and expert mice. To test the neuronal discriminability to pure tone responses, we calculated the pairwise d’ based on the FR per trial in all frequencies at 62 dB SPL (<xref ref-type="bibr" rid="bib19">Feigin et al., 2021</xref>; <xref ref-type="bibr" rid="bib61">Shani-Narkiss et al., 2020</xref>). For two given frequencies p and q, d’ values were calculated in the following way:<disp-formula id="equ4"><label>(4)</label><alternatives><mml:math id="m4"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:msub><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>μ</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:msqrt><mml:mo>∑</mml:mo></mml:msqrt><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mstyle></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="t4">\begin{document}$$\displaystyle  \frac{d\left (\mu _{p,}\mu _{q}\right)}{\mu \left (\sqrt \sum _{n}^{i=1}\left (\widehat {p_{l}}- \widehat {q_{l}}\right)^{2}\right)}$$\end{document}</tex-math></alternatives></disp-formula></p><p>Where d represents the distance between the mean FR (<italic>μ</italic>) of frequency p and q, as vectors with n entries representing the mean signal (averaged over individual trials) in n-dimensional space for frequency p/q. The average distance (d) is then divided by the mean of the inner Euclidean distance <inline-formula><alternatives><mml:math id="inf5"><mml:mstyle><mml:mrow><mml:mstyle displaystyle="false"><mml:mo stretchy="false">(</mml:mo><mml:msqrt><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:munderover><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:msub><mml:mi>p</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mrow><mml:mover><mml:msub><mml:mi>q</mml:mi><mml:mrow><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:msqrt><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:mstyle></mml:math><tex-math id="inft5">\begin{document}$(\sqrt{\sum _{n}^{i=1}({\widehat {p_{l}}-{\widehat{q_{l}}}})})$\end{document}</tex-math></alternatives></inline-formula> between each single trial (<xref ref-type="fig" rid="fig7">Figure 7h</xref>).</p></sec><sec id="s4-7-6"><title>Statistical analysis</title><p>Statistical comparisons were performed in custom-written codes in MATLAB 2023b (MathWorks) and Python 3.12. We assessed if the data was normally distributed using a Kolmogorov-Smirnov test. Normally distributed data was tested using a paired (within group comparison) or independent (between group comparison) t-test and presented with mean ± STE. Non-normally distributed data was tested using a Wilcoxon sign rank (within group comparison), or rank-sum (between group comparison) test. Multiple samples were tested with ANOVA (parametric data) and Kruskal-Wallis tests (non-parametric data). All tests corrected after multiple comparisons (Bonferroni correction for two-samples and Tukey-Kramer for multiple samples). In addition, we applied linear-mixed-effect models (LME) to account for hierarchical data structures and variability within groups of co-housed mice, as well as repeated measurements of mice and recordings, as random effects. Fixed effects, and pairwise interaction effects were adjusted with post-hoc tests and multiple comparisons. For all statistical tests, significant differences were defined as p-values below 0.05.</p></sec></sec><sec id="s4-8"><title>Data availability</title><p>The data that support the finding of this study are available through Zenodo (<ext-link ext-link-type="uri" xlink:href="https://zenodo.org/uploads/13933351">https://zenodo.org/uploads/13933351</ext-link>). Additional data is available from authors upon reasonable request.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Visualization, Methodology, Writing – original draft</p></fn><fn fn-type="con" id="con2"><p>Formal analysis, Visualization</p></fn><fn fn-type="con" id="con3"><p>Data curation, Methodology</p></fn><fn fn-type="con" id="con4"><p>Data curation</p></fn><fn fn-type="con" id="con5"><p>Supervision, Funding acquisition, Writing - review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Resources, Supervision, Funding acquisition, Methodology, Writing – original draft, Project administration</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>All experiments were approved by the Institutional Animal Care and Use Committee (IACUC) at the Hebrew University of Jerusalem, Israel (Permit Number: NS-21-16448-4, NS-21-16694-4, NS-22-16966-4).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-106387-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp1"><label>Supplementary file 1.</label><caption><title>Adolescent and adult mice exhibit different lick behavior in the task.</title><p>Linear mixed-effects models of the fixed effects of lick count (until reward or punishment delay), lick latency, cumulative discriminability (d’) (including the interaction effects of lick count and lick latency, lick count and d’, lick latency and d’, and lick latency, lick count and d’) during the minimal number of trials shared between all mice (148 trials; Number of observations = 1098, Fixed effects coefficients = 8, Random effects coefficients = 14, Covariance parameters = 3). Coefficient estimates, STE, T-statistic, degrees of freedom, p-values (adjusted for post-hoc multiple comparisons with Bonferroni method), lower and higher CI are listed in the table. The model includes random effects coefficients per mouse (11 mice in total) and 3 recordings per mouse (see methods, equation 8). Model structure: Lick Count ~ Group * Lick Latency * dprime + (1|Mouse ID) + (1|Recording ID).</p></caption><media xlink:href="elife-106387-supp1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp2"><label>Supplementary file 2.</label><caption><title>Neuronal statistics in expert and novice recordings during task engagement.</title><p>Acquired single units, acquired tone-excited units (percentage of tone-excited units relative to total units) in the AUDd, AUDp, AUDv, and TEa of adolescent and adult mice in experts (top) and novice (bottom).</p></caption><media xlink:href="elife-106387-supp2-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp3"><label>Supplementary file 3.</label><caption><title>Adolescent and adult expert mice have distinct firing properties in different sub-regions.</title><p>Mean and standard error, mean effect size (robust Cohen’s D), lower and upper Confidence Interval (CI) and p-value (Wilcoxon rank-sum test, adjusted for multiple comparisons with Bonferroni method) of the average baseline FR (Hz), evoked FR (Hz), coefficient of variance of FR, latency to peak of maximal FR (ms), full-width-half maximum of peak FR (ms), minimal latency of first spike (ms), fraction of responsive trials, lifetime sparseness of all adolescent and adult neurons from tone-onset to 50 ms after tone offset across all stimuli in AUDd, AUDp, and AUDv, and TEa (significant p-values are highlighted in bold).</p></caption><media xlink:href="elife-106387-supp3-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp4"><label>Supplementary file 4.</label><caption><title>Adolescent and adult firing properties of expert mice are distinct between different sub-regions.</title><p>P-values of Kruskal-Willis Test after Tukey-Kramer correction for multiple comparisons of the average baseline FR (Hz), evoked FR (Hz), coefficient of variance of FR, latency to peak of maximal FR (ms), full-width-half maximum of peak FR (ms), minimal latency of first spike (ms), fraction of responsive trials, lifetime sparseness of all adolescent and adult neurons from tone-onset to 50 ms after tone offset across all stimuli AUDd – AUDp, AUDd – AUDv, AUDd – TEa, AUDp – AUDv, AUDp – Tea, and AUDv –Tea (significant p-values are highlighted in bold).</p></caption><media xlink:href="elife-106387-supp4-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp5"><label>Supplementary file 5.</label><caption><title>Novice, adolescent, and adult mice have distinct firing properties in different sub-regions.</title><p>Mean and standard error (STE), mean effect size (robust Cohen’s D), lower and upper Confidence Interval (CI) and p-value (Wilcoxon rank-sum test, adjusted for multiple comparisons with Bonferroni method) of the average baseline FR (Hz), evoked FR (Hz), coefficient of variance of FR, latency to peak of maximal FR (ms), full-width-half maximum of peak FR (ms), minimal latency of first spike (ms), fraction of responsive trials, lifetime sparseness of all adolescent and adult neurons from tone-onset to 50 ms after tone offset across all stimuli in AUDd, AUDp, and AUDv, and TEa (significant p-values are highlighted in bold).</p></caption><media xlink:href="elife-106387-supp5-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp6"><label>Supplementary file 6.</label><caption><title>Adolescent and adult firing properties of novice mice are distinct between different sub-regions.</title><p>P-values of Kruskal-Willis Test after Tukey-Kramer correction for multiple comparisons of the average baseline FR (Hz), evoked FR (Hz), coefficient of variance of FR, latency to peak of maximal FR (ms), full-width-half maximum of peak FR (ms), minimal latency of first spike (ms), fraction of responsive trials, lifetime sparseness of all adolescent and adult neurons from tone-onset to 50 ms after tone offset across all stimuli AUDd – AUDp, AUDd – AUDv, AUDd – TEa, AUDp – AUDv, AUDp – Tea, and AUDv –Tea (significant p-values are highlighted in bold).</p></caption><media xlink:href="elife-106387-supp6-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp7"><label>Supplementary file 7.</label><caption><title>Neuronal statistics during passive FRA protocol in expert and novice mice.</title><p>Acquired single units, acquired tone-modulated units, and percentage of modulated units to all acquired units in the AUDd, AUDp, AUDv, and TEa of adolescent and adult mice during passive-listening recordings.</p></caption><media xlink:href="elife-106387-supp7-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp8"><label>Supplementary file 8.</label><caption><title>Adolescent and adult mice have distinct firing properties across different sub-regions of ACx—passive listening.</title><p>Mean and standard error, mean effect size (robust Cohen’s D), lower and upper Confidence Interval (CI) and p-value (Wilcoxon rank-sum test) of the average baseline FR (Hz) (AUDp vs. AUDv: adolescent p = 0.8551; adult p = 0.9711), evoked FR (Hz) (AUDp vs. AUDv: adolescent p = 0.4125; adult p = 0.9954), coefficient of variance of FR (AUDp vs. AUDv: adolescent p = 0.4354; adult p = 0.8800), latency to peak of maximal FR (ms) (AUDp vs. AUDv: adolescent p = 0.5871; adult p = 0.9985), full-width-half maximum of peak FR (ms) (AUDp vs. AUDv: adolescent p = 0.7223; adult p = 0.4628), minimal latency of first spike (ms) (AUDp vs. AUDv: adolescent p = 0.5936; adult p = 0.5669), fraction of responsive trials (AUDp vs. AUDv: adolescent p = 0.3838; adult p = 0.9924), lifetime sparseness (AUDp vs. AUDv: adolescent p = 0.3792; adult p = 0.9341) of all adolescent and adult neurons from tone-onset to 50 ms after tone offset across all stimuli in AUDp, and AUDv (significant p-values are highlighted in bold).</p></caption><media xlink:href="elife-106387-supp8-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material><supplementary-material id="supp9"><label>Supplementary file 9.</label><caption><title>Overview of datasets analyzed.Number of mice, recordings, and neurons per learning stage (left: expert, right: novice) for every figure.</title></caption><media xlink:href="elife-106387-supp9-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The data that support the findings of this study are available through Zenodo (<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.13933351">https://doi.org/10.5281/zenodo.13933351</ext-link>). The code is available through GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/benne1295/Age-and-Learning-Shapes-Sound-Representations-in-Auditory-Cortex-During-Adolescence">https://github.com/benne1295/Age-and-Learning-Shapes-Sound-Representations-in-Auditory-Cortex-During-Adolescence</ext-link> copy archived at <xref ref-type="bibr" rid="bib52">Praegel, 2025</xref>).</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Praegel</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>Age and Learning Shapes Sound Representations in Auditory Cortex During Adolescence</data-title><source>Zenodo</source><pub-id pub-id-type="doi">10.5281/zenodo.13933351</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank the Mizrahi lab for comments on the manuscript and Linda Wilbrecht, and Madeleine Klinger for discussions. We thank Ido Maor, Or Yudco, Omri Gilday, and Meirav Givon for technical assistance. We also thank Ofer Yizhar for sharing reagents and Maya Groysman for preparing the viruses. This work was supported by an NSF-BSF grant to AM and SD (#2021776), stipends from the Minerva Foundation and the Israeli Ministry of Aliya and Integration to BP, and the Gatsby Charitable Foundation. Adi Mizrahi is the Eric Roland Chair in Brain Sciences. Figures 1a and 3a, 4a, 6a, 7a were created with biorender.com.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahissar</surname><given-names>M</given-names></name><name><surname>Hochstein</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Task difficulty and the specificity of perceptual learning</article-title><source>Nature</source><volume>387</volume><fpage>401</fpage><lpage>406</lpage><pub-id pub-id-type="doi">10.1038/387401a0</pub-id><pub-id pub-id-type="pmid">9163425</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ahissar</surname><given-names>M</given-names></name><name><surname>Hochstein</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>The reverse hierarchy theory of visual perceptual learning</article-title><source>Trends in Cognitive Sciences</source><volume>8</volume><fpage>457</fpage><lpage>464</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2004.08.011</pub-id><pub-id pub-id-type="pmid">15450510</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anbuhl</surname><given-names>KL</given-names></name><name><surname>Yao</surname><given-names>JD</given-names></name><name><surname>Hotz</surname><given-names>RA</given-names></name><name><surname>Mowery</surname><given-names>TM</given-names></name><name><surname>Sanes</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Auditory processing remains sensitive to environmental experience during adolescence in a rodent model</article-title><source>Nature Communications</source><volume>13</volume><elocation-id>2872</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-022-30455-9</pub-id><pub-id pub-id-type="pmid">35610222</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bao</surname><given-names>S</given-names></name><name><surname>Chang</surname><given-names>EF</given-names></name><name><surname>Woods</surname><given-names>J</given-names></name><name><surname>Merzenich</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Temporal plasticity in the primary auditory cortex induced by operant perceptual learning</article-title><source>Nature Neuroscience</source><volume>7</volume><fpage>974</fpage><lpage>981</lpage><pub-id pub-id-type="doi">10.1038/nn1293</pub-id><pub-id pub-id-type="pmid">15286790</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bao</surname><given-names>S</given-names></name><name><surname>Chang</surname><given-names>EF</given-names></name><name><surname>Teng</surname><given-names>CL</given-names></name><name><surname>Heiser</surname><given-names>MA</given-names></name><name><surname>Merzenich</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Emergent categorical representation of natural, complex sounds resulting from the early post-natal sound environment</article-title><source>Neuroscience</source><volume>248</volume><fpage>30</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2013.05.056</pub-id><pub-id pub-id-type="pmid">23747304</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barkat</surname><given-names>TR</given-names></name><name><surname>Polley</surname><given-names>DB</given-names></name><name><surname>Hensch</surname><given-names>TK</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A critical period for auditory thalamocortical connectivity</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>1189</fpage><lpage>1194</lpage><pub-id pub-id-type="doi">10.1038/nn.2882</pub-id><pub-id pub-id-type="pmid">21804538</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bhumika</surname><given-names>S</given-names></name><name><surname>Nakamura</surname><given-names>M</given-names></name><name><surname>Valerio</surname><given-names>P</given-names></name><name><surname>Solyga</surname><given-names>M</given-names></name><name><surname>Lindén</surname><given-names>H</given-names></name><name><surname>Barkat</surname><given-names>TR</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A late critical period for frequency modulated sweeps in the mouse auditory system</article-title><source>Cerebral Cortex</source><volume>30</volume><fpage>2586</fpage><lpage>2599</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhz262</pub-id><pub-id pub-id-type="pmid">31800018</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buran</surname><given-names>BN</given-names></name><name><surname>Sarro</surname><given-names>EC</given-names></name><name><surname>Manno</surname><given-names>FAM</given-names></name><name><surname>Kang</surname><given-names>R</given-names></name><name><surname>Caras</surname><given-names>ML</given-names></name><name><surname>Sanes</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>A sensitive period for the impact of hearing loss on auditory perception</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>2276</fpage><lpage>2284</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0647-13.2014</pub-id><pub-id pub-id-type="pmid">24501366</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Caras</surname><given-names>ML</given-names></name><name><surname>Sanes</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Neural variability limits adolescent skill learning</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>2889</fpage><lpage>2902</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2878-18.2019</pub-id><pub-id pub-id-type="pmid">30755494</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ceballo</surname><given-names>S</given-names></name><name><surname>Piwkowska</surname><given-names>Z</given-names></name><name><surname>Bourg</surname><given-names>J</given-names></name><name><surname>Daret</surname><given-names>A</given-names></name><name><surname>Bathellier</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Targeted cortical manipulation of auditory perception</article-title><source>Neuron</source><volume>104</volume><fpage>1168</fpage><lpage>1179</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2019.09.043</pub-id><pub-id pub-id-type="pmid">31727548</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>JR</given-names></name><name><surname>Asarnow</surname><given-names>RF</given-names></name><name><surname>Sabb</surname><given-names>FW</given-names></name><name><surname>Bilder</surname><given-names>RM</given-names></name><name><surname>Bookheimer</surname><given-names>SY</given-names></name><name><surname>Knowlton</surname><given-names>BJ</given-names></name><name><surname>Poldrack</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A unique adolescent response to reward prediction errors</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>669</fpage><lpage>671</lpage><pub-id pub-id-type="doi">10.1038/nn.2558</pub-id><pub-id pub-id-type="pmid">20473290</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>L</given-names></name><name><surname>Rothschild</surname><given-names>G</given-names></name><name><surname>Mizrahi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Multisensory integration of natural odors and sounds in the auditory cortex</article-title><source>Neuron</source><volume>72</volume><fpage>357</fpage><lpage>369</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.08.019</pub-id><pub-id pub-id-type="pmid">22017993</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>L</given-names></name><name><surname>Mizrahi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Plasticity during motherhood: changes in excitatory and inhibitory layer 2/3 neurons in auditory cortex</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>1806</fpage><lpage>1815</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1786-14.2015</pub-id><pub-id pub-id-type="pmid">25632153</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crone</surname><given-names>EA</given-names></name><name><surname>Dahl</surname><given-names>RE</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Understanding adolescence as a period of social-affective engagement and goal flexibility</article-title><source>Nature Reviews. Neuroscience</source><volume>13</volume><fpage>636</fpage><lpage>650</lpage><pub-id pub-id-type="doi">10.1038/nrn3313</pub-id><pub-id pub-id-type="pmid">22903221</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dahl</surname><given-names>RE</given-names></name><name><surname>Allen</surname><given-names>NB</given-names></name><name><surname>Wilbrecht</surname><given-names>L</given-names></name><name><surname>Suleiman</surname><given-names>AB</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Importance of investing in adolescence from a developmental science perspective</article-title><source>Nature</source><volume>554</volume><fpage>441</fpage><lpage>450</lpage><pub-id pub-id-type="doi">10.1038/nature25770</pub-id><pub-id pub-id-type="pmid">29469094</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delevich</surname><given-names>K</given-names></name><name><surname>Klinger</surname><given-names>M</given-names></name><name><surname>Okada</surname><given-names>NJ</given-names></name><name><surname>Wilbrecht</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Coming of age in the frontal cortex: the role of puberty in cortical maturation</article-title><source>Seminars in Cell &amp; Developmental Biology</source><volume>118</volume><fpage>64</fpage><lpage>72</lpage><pub-id pub-id-type="doi">10.1016/j.semcdb.2021.04.021</pub-id><pub-id pub-id-type="pmid">33985902</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drieu</surname><given-names>C</given-names></name><name><surname>Zhu</surname><given-names>Z</given-names></name><name><surname>Wang</surname><given-names>Z</given-names></name><name><surname>Fuller</surname><given-names>K</given-names></name><name><surname>Wang</surname><given-names>A</given-names></name><name><surname>Elnozahy</surname><given-names>S</given-names></name><name><surname>Kuchibhotla</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2025">2025</year><article-title>Rapid emergence of latent knowledge in the sensory cortex drives learning</article-title><source>Nature</source><volume>641</volume><fpage>960</fpage><lpage>970</lpage><pub-id pub-id-type="doi">10.1038/s41586-025-08730-8</pub-id><pub-id pub-id-type="pmid">40108473</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Druckmann</surname><given-names>S</given-names></name><name><surname>Chklovskii</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Neuronal circuits underlying persistent representations despite time varying activity</article-title><source>Current Biology</source><volume>22</volume><fpage>2095</fpage><lpage>2103</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2012.08.058</pub-id><pub-id pub-id-type="pmid">23084992</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feigin</surname><given-names>L</given-names></name><name><surname>Tasaka</surname><given-names>G</given-names></name><name><surname>Maor</surname><given-names>I</given-names></name><name><surname>Mizrahi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Sparse coding in temporal association cortex improves complex sound discriminability</article-title><source>The Journal of Neuroscience</source><volume>41</volume><fpage>7048</fpage><lpage>7064</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3167-20.2021</pub-id><pub-id pub-id-type="pmid">34244361</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuhrmann</surname><given-names>D</given-names></name><name><surname>Knoll</surname><given-names>LJ</given-names></name><name><surname>Blakemore</surname><given-names>SJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Adolescence as a sensitive period of brain development</article-title><source>Trends in Cognitive Sciences</source><volume>19</volume><fpage>558</fpage><lpage>566</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2015.07.008</pub-id><pub-id pub-id-type="pmid">26419496</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilad</surname><given-names>A</given-names></name><name><surname>Maor</surname><given-names>I</given-names></name><name><surname>Mizrahi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Learning-related population dynamics in the auditory thalamus</article-title><source>eLife</source><volume>9</volume><elocation-id>e56307</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.56307</pub-id><pub-id pub-id-type="pmid">32639231</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilday</surname><given-names>OD</given-names></name><name><surname>Mizrahi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2023">2023a</year><article-title>Learning-induced odor modulation of neuronal activity in auditory cortex</article-title><source>The Journal of Neuroscience</source><volume>43</volume><fpage>1375</fpage><lpage>1386</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1398-22.2022</pub-id><pub-id pub-id-type="pmid">36650061</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilday</surname><given-names>OD</given-names></name><name><surname>Praegel</surname><given-names>B</given-names></name><name><surname>Maor</surname><given-names>I</given-names></name><name><surname>Cohen</surname><given-names>T</given-names></name><name><surname>Nelken</surname><given-names>I</given-names></name><name><surname>Mizrahi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2023">2023b</year><article-title>Surround suppression in mouse auditory cortex underlies auditory edge detection</article-title><source>PLOS Computational Biology</source><volume>19</volume><elocation-id>e1010861</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1010861</pub-id><pub-id pub-id-type="pmid">36656876</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Green</surname><given-names>DM</given-names></name><name><surname>Swets</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1966">1966</year><source>Signal Detection Theory and Psychophysics</source><publisher-name>John Wiley &amp; Sons Ltd</publisher-name></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haimson</surname><given-names>B</given-names></name><name><surname>Gilday</surname><given-names>OD</given-names></name><name><surname>Lavi-Rudel</surname><given-names>A</given-names></name><name><surname>Sagi</surname><given-names>H</given-names></name><name><surname>Lottem</surname><given-names>E</given-names></name><name><surname>Mizrahi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Single neuron responses to perceptual difficulty in the mouse auditory cortex</article-title><source>Science Advances</source><volume>10</volume><elocation-id>eadp9816</elocation-id><pub-id pub-id-type="doi">10.1126/sciadv.adp9816</pub-id><pub-id pub-id-type="pmid">39141740</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Han</surname><given-names>YK</given-names></name><name><surname>Köver</surname><given-names>H</given-names></name><name><surname>Insanally</surname><given-names>MN</given-names></name><name><surname>Semerdjian</surname><given-names>JH</given-names></name><name><surname>Bao</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Early experience impairs perceptual discrimination</article-title><source>Nature Neuroscience</source><volume>10</volume><fpage>1191</fpage><lpage>1197</lpage><pub-id pub-id-type="doi">10.1038/nn1941</pub-id><pub-id pub-id-type="pmid">17660815</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hawkins</surname><given-names>JD</given-names></name><name><surname>Catalano</surname><given-names>RF</given-names></name><name><surname>Miller</surname><given-names>JY</given-names></name></person-group><year iso-8601-date="1992">1992</year><article-title>Risk and protective factors for alcohol and other drug problems in adolescence and early adulthood: implications for substance abuse prevention</article-title><source>Psychological Bulletin</source><volume>112</volume><fpage>64</fpage><lpage>105</lpage><pub-id pub-id-type="doi">10.1037/0033-2909.112.1.64</pub-id><pub-id pub-id-type="pmid">1529040</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hensch</surname><given-names>TK</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Critical period regulation</article-title><source>Annual Review of Neuroscience</source><volume>27</volume><fpage>549</fpage><lpage>579</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.27.070203.144327</pub-id><pub-id pub-id-type="pmid">15217343</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hensch</surname><given-names>TK</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Critical period plasticity in local cortical circuits</article-title><source>Nature Reviews. Neuroscience</source><volume>6</volume><fpage>877</fpage><lpage>888</lpage><pub-id pub-id-type="doi">10.1038/nrn1787</pub-id><pub-id pub-id-type="pmid">16261181</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoskins</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Consequences of parenting on adolescent outcomes</article-title><source>Societies</source><volume>4</volume><fpage>506</fpage><lpage>531</lpage><pub-id pub-id-type="doi">10.3390/soc4030506</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huyck</surname><given-names>JJ</given-names></name><name><surname>Wright</surname><given-names>BA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Late maturation of auditory perceptual learning</article-title><source>Developmental Science</source><volume>14</volume><fpage>614</fpage><lpage>621</lpage><pub-id pub-id-type="doi">10.1111/j.1467-7687.2010.01009.x</pub-id><pub-id pub-id-type="pmid">21477199</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jaramillo</surname><given-names>S</given-names></name><name><surname>Zador</surname><given-names>AM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The auditory cortex mediates the perceptual effects of acoustic temporal expectation</article-title><source>Nature Neuroscience</source><volume>14</volume><fpage>246</fpage><lpage>251</lpage><pub-id pub-id-type="doi">10.1038/nn.2688</pub-id><pub-id pub-id-type="pmid">21170056</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>C</given-names></name><name><surname>Wilbrecht</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Juvenile mice show greater flexibility in multiple choice reversal learning than adults</article-title><source>Developmental Cognitive Neuroscience</source><volume>1</volume><fpage>540</fpage><lpage>551</lpage><pub-id pub-id-type="doi">10.1016/j.dcn.2011.05.008</pub-id><pub-id pub-id-type="pmid">21949556</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>CM</given-names></name><name><surname>Loucks</surname><given-names>FA</given-names></name><name><surname>Peckler</surname><given-names>H</given-names></name><name><surname>Thomas</surname><given-names>AW</given-names></name><name><surname>Janak</surname><given-names>PH</given-names></name><name><surname>Wilbrecht</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Long-range orbitofrontal and amygdala axons show divergent patterns of maturation in the frontal cortex across adolescence</article-title><source>Developmental Cognitive Neuroscience</source><volume>18</volume><fpage>113</fpage><lpage>120</lpage><pub-id pub-id-type="doi">10.1016/j.dcn.2016.01.005</pub-id><pub-id pub-id-type="pmid">26896859</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jun</surname><given-names>JJ</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name><name><surname>Siegle</surname><given-names>JH</given-names></name><name><surname>Denman</surname><given-names>DJ</given-names></name><name><surname>Bauza</surname><given-names>M</given-names></name><name><surname>Barbarits</surname><given-names>B</given-names></name><name><surname>Lee</surname><given-names>AK</given-names></name><name><surname>Anastassiou</surname><given-names>CA</given-names></name><name><surname>Andrei</surname><given-names>A</given-names></name><name><surname>Aydın</surname><given-names>Ç</given-names></name><name><surname>Barbic</surname><given-names>M</given-names></name><name><surname>Blanche</surname><given-names>TJ</given-names></name><name><surname>Bonin</surname><given-names>V</given-names></name><name><surname>Couto</surname><given-names>J</given-names></name><name><surname>Dutta</surname><given-names>B</given-names></name><name><surname>Gratiy</surname><given-names>SL</given-names></name><name><surname>Gutnisky</surname><given-names>DA</given-names></name><name><surname>Häusser</surname><given-names>M</given-names></name><name><surname>Karsh</surname><given-names>B</given-names></name><name><surname>Ledochowitsch</surname><given-names>P</given-names></name><name><surname>Lopez</surname><given-names>CM</given-names></name><name><surname>Mitelut</surname><given-names>C</given-names></name><name><surname>Musa</surname><given-names>S</given-names></name><name><surname>Okun</surname><given-names>M</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Putzeys</surname><given-names>J</given-names></name><name><surname>Rich</surname><given-names>PD</given-names></name><name><surname>Rossant</surname><given-names>C</given-names></name><name><surname>Sun</surname><given-names>W-L</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Koch</surname><given-names>C</given-names></name><name><surname>O’Keefe</surname><given-names>J</given-names></name><name><surname>Harris</surname><given-names>TD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Fully integrated silicon probes for high-density recording of neural activity</article-title><source>Nature</source><volume>551</volume><fpage>232</fpage><lpage>236</lpage><pub-id pub-id-type="doi">10.1038/nature24636</pub-id><pub-id pub-id-type="pmid">29120427</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kang</surname><given-names>B</given-names></name><name><surname>Druckmann</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Approaches to inferring multi-regional interactions from simultaneous population recordings: inferring multi-regional interactions from simultaneous population recordings</article-title><source>Current Opinion in Neurobiology</source><volume>65</volume><fpage>108</fpage><lpage>119</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2020.10.004</pub-id><pub-id pub-id-type="pmid">33227602</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kanold</surname><given-names>PO</given-names></name><name><surname>Nelken</surname><given-names>I</given-names></name><name><surname>Polley</surname><given-names>DB</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Local versus global scales of organization in auditory cortex</article-title><source>Trends in Neurosciences</source><volume>37</volume><fpage>502</fpage><lpage>510</lpage><pub-id pub-id-type="doi">10.1016/j.tins.2014.06.003</pub-id><pub-id pub-id-type="pmid">25002236</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kato</surname><given-names>HK</given-names></name><name><surname>Gillet</surname><given-names>SN</given-names></name><name><surname>Isaacson</surname><given-names>JS</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Flexible sensory representations in auditory cortex driven by behavioral relevance</article-title><source>Neuron</source><volume>88</volume><fpage>1027</fpage><lpage>1039</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.10.024</pub-id><pub-id pub-id-type="pmid">26586181</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Konstantoudaki</surname><given-names>X</given-names></name><name><surname>Chalkiadaki</surname><given-names>K</given-names></name><name><surname>Vasileiou</surname><given-names>E</given-names></name><name><surname>Kalemaki</surname><given-names>K</given-names></name><name><surname>Karagogeos</surname><given-names>D</given-names></name><name><surname>Sidiropoulou</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Prefrontal cortical-specific differences in behavior and synaptic plasticity between adolescent and adult mice</article-title><source>Journal of Neurophysiology</source><volume>119</volume><fpage>822</fpage><lpage>833</lpage><pub-id pub-id-type="doi">10.1152/jn.00189.2017</pub-id><pub-id pub-id-type="pmid">29167323</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kral</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Auditory critical periods: a review from system’s perspective</article-title><source>Neuroscience</source><volume>247</volume><fpage>117</fpage><lpage>133</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2013.05.021</pub-id><pub-id pub-id-type="pmid">23707979</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kunkhyen</surname><given-names>T</given-names></name><name><surname>Perez</surname><given-names>E</given-names></name><name><surname>Bass</surname><given-names>M</given-names></name><name><surname>Coyne</surname><given-names>A</given-names></name><name><surname>Baum</surname><given-names>MJ</given-names></name><name><surname>Cherry</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Gonadal hormones, but not sex, affect the acquisition and maintenance of a Go/No-Go odor discrimination task in mice</article-title><source>Hormones and Behavior</source><volume>100</volume><fpage>12</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1016/j.yhbeh.2018.02.009</pub-id><pub-id pub-id-type="pmid">29481807</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>N</given-names></name><name><surname>Daie</surname><given-names>K</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name><name><surname>Druckmann</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Robust neuronal dynamics in premotor cortex during motor planning</article-title><source>Nature</source><volume>532</volume><fpage>459</fpage><lpage>464</lpage><pub-id pub-id-type="doi">10.1038/nature17643</pub-id><pub-id pub-id-type="pmid">27074502</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Magis-Weinberg</surname><given-names>L</given-names></name><name><surname>Custers</surname><given-names>R</given-names></name><name><surname>Dumontheil</surname><given-names>I</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Rewards enhance proactive and reactive control in adolescence and adulthood</article-title><source>Social Cognitive and Affective Neuroscience</source><volume>14</volume><fpage>1219</fpage><lpage>1232</lpage><pub-id pub-id-type="doi">10.1093/scan/nsz093</pub-id><pub-id pub-id-type="pmid">31820793</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maor</surname><given-names>I</given-names></name><name><surname>Shalev</surname><given-names>A</given-names></name><name><surname>Mizrahi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Distinct spatiotemporal response properties of excitatory versus inhibitory neurons in the mouse auditory cortex</article-title><source>Cerebral Cortex</source><volume>26</volume><fpage>4242</fpage><lpage>4252</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw266</pub-id><pub-id pub-id-type="pmid">27600839</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maor</surname><given-names>I</given-names></name><name><surname>Shwartz-Ziv</surname><given-names>R</given-names></name><name><surname>Feigin</surname><given-names>L</given-names></name><name><surname>Elyada</surname><given-names>Y</given-names></name><name><surname>Sompolinsky</surname><given-names>H</given-names></name><name><surname>Mizrahi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Neural correlates of learning pure tones or natural sounds in the auditory cortex</article-title><source>Frontiers in Neural Circuits</source><volume>13</volume><elocation-id>82</elocation-id><pub-id pub-id-type="doi">10.3389/fncir.2019.00082</pub-id><pub-id pub-id-type="pmid">32047424</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>HC</given-names></name><name><surname>Bucci</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Age differences in appetitive Pavlovian conditioning and extinction in rats</article-title><source>Physiology &amp; Behavior</source><volume>167</volume><fpage>354</fpage><lpage>362</lpage><pub-id pub-id-type="doi">10.1016/j.physbeh.2016.10.004</pub-id><pub-id pub-id-type="pmid">27737779</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nabel</surname><given-names>EM</given-names></name><name><surname>Garkun</surname><given-names>Y</given-names></name><name><surname>Koike</surname><given-names>H</given-names></name><name><surname>Sadahiro</surname><given-names>M</given-names></name><name><surname>Liang</surname><given-names>A</given-names></name><name><surname>Norman</surname><given-names>KJ</given-names></name><name><surname>Taccheri</surname><given-names>G</given-names></name><name><surname>Demars</surname><given-names>MP</given-names></name><name><surname>Im</surname><given-names>S</given-names></name><name><surname>Caro</surname><given-names>K</given-names></name><name><surname>Lopez</surname><given-names>S</given-names></name><name><surname>Bateh</surname><given-names>J</given-names></name><name><surname>Hof</surname><given-names>PR</given-names></name><name><surname>Clem</surname><given-names>RL</given-names></name><name><surname>Morishita</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Adolescent frontal top-down neurons receive heightened local drive to establish adult attentional behavior in mice</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>3983</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-17787-0</pub-id><pub-id pub-id-type="pmid">32770078</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakamura</surname><given-names>M</given-names></name><name><surname>Valerio</surname><given-names>P</given-names></name><name><surname>Bhumika</surname><given-names>S</given-names></name><name><surname>Barkat</surname><given-names>TR</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Sequential organization of critical periods in the mouse auditory system</article-title><source>Cell Reports</source><volume>32</volume><elocation-id>108070</elocation-id><pub-id pub-id-type="doi">10.1016/j.celrep.2020.108070</pub-id><pub-id pub-id-type="pmid">32846128</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Sullivan</surname><given-names>C</given-names></name><name><surname>Weible</surname><given-names>AP</given-names></name><name><surname>Wehr</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Auditory cortex contributes to discrimination of pure tones</article-title><source>eNeuro</source><volume>6</volume><elocation-id>ENEURO.0340-19.2019</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0340-19.2019</pub-id><pub-id pub-id-type="pmid">31591138</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Pachitariu</surname><given-names>M</given-names></name><name><surname>Steinmetz</surname><given-names>N</given-names></name><name><surname>Kadir</surname><given-names>S</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Kenneth D.</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Kilosort: realtime spike-sorting for extracellular electrophysiology with hundreds of channels</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/061481</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Pennington</surname><given-names>J</given-names></name><name><surname>Pachitariu</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>Kilosort</data-title><version designator="42fd52c">42fd52c</version><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/MouseLand/Kilosort/">https://github.com/MouseLand/Kilosort/</ext-link></element-citation></ref><ref id="bib52"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Praegel</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>Age-and-learning-shapes-sound-representations-in-auditory-cortex-during-adolescence</data-title><version designator="swh:1:rev:6ff75ba54346b49062fc9455f374f1a23f793848">swh:1:rev:6ff75ba54346b49062fc9455f374f1a23f793848</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:d48c7337a11ab4c1ee552e5a1afed79f4cf3f058;origin=https://github.com/benne1295/Age-and-Learning-Shapes-Sound-Representations-in-Auditory-Cortex-During-Adolescence;visit=swh:1:snp:70bcfbd5d99f36290e96fa9242a340485e887f12;anchor=swh:1:rev:6ff75ba54346b49062fc9455f374f1a23f793848">https://archive.softwareheritage.org/swh:1:dir:d48c7337a11ab4c1ee552e5a1afed79f4cf3f058;origin=https://github.com/benne1295/Age-and-Learning-Shapes-Sound-Representations-in-Auditory-Cortex-During-Adolescence;visit=swh:1:snp:70bcfbd5d99f36290e96fa9242a340485e887f12;anchor=swh:1:rev:6ff75ba54346b49062fc9455f374f1a23f793848</ext-link></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reh</surname><given-names>RK</given-names></name><name><surname>Dias</surname><given-names>BG</given-names></name><name><surname>Nelson</surname><given-names>CA</given-names><suffix>III</suffix></name><name><surname>Kaufer</surname><given-names>D</given-names></name><name><surname>Werker</surname><given-names>JF</given-names></name><name><surname>Kolb</surname><given-names>B</given-names></name><name><surname>Levine</surname><given-names>JD</given-names></name><name><surname>Hensch</surname><given-names>TK</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Critical period regulation across multiple timescales</article-title><source>PNAS</source><volume>117</volume><fpage>23242</fpage><lpage>23251</lpage><pub-id pub-id-type="doi">10.1073/pnas.1820836117</pub-id><pub-id pub-id-type="pmid">32503914</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reynolds</surname><given-names>LM</given-names></name><name><surname>Yetnikoff</surname><given-names>L</given-names></name><name><surname>Pokinko</surname><given-names>M</given-names></name><name><surname>Wodzinski</surname><given-names>M</given-names></name><name><surname>Epelbaum</surname><given-names>JG</given-names></name><name><surname>Lambert</surname><given-names>LC</given-names></name><name><surname>Cossette</surname><given-names>MP</given-names></name><name><surname>Arvanitogiannis</surname><given-names>A</given-names></name><name><surname>Flores</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Early adolescence is a critical period for the maturation of inhibitory behavior</article-title><source>Cerebral Cortex</source><volume>29</volume><fpage>3676</fpage><lpage>3686</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhy247</pub-id><pub-id pub-id-type="pmid">30295713</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Romer</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Adolescent risk taking, impulsivity, and brain development: implications for prevention</article-title><source>Developmental Psychobiology</source><volume>52</volume><fpage>263</fpage><lpage>276</lpage><pub-id pub-id-type="doi">10.1002/dev.20442</pub-id><pub-id pub-id-type="pmid">20175097</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Rossant</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Phy</data-title><version designator="7a2494b">7a2494b</version><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/cortex-lab/phy">https://github.com/cortex-lab/phy</ext-link></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rothschild</surname><given-names>G</given-names></name><name><surname>Nelken</surname><given-names>I</given-names></name><name><surname>Mizrahi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Functional organization and population dynamics in the mouse primary auditory cortex</article-title><source>Nature Neuroscience</source><volume>13</volume><fpage>353</fpage><lpage>360</lpage><pub-id pub-id-type="doi">10.1038/nn.2484</pub-id><pub-id pub-id-type="pmid">20118927</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sawyer</surname><given-names>SM</given-names></name><name><surname>Afifi</surname><given-names>RA</given-names></name><name><surname>Bearinger</surname><given-names>LH</given-names></name><name><surname>Blakemore</surname><given-names>SJ</given-names></name><name><surname>Dick</surname><given-names>B</given-names></name><name><surname>Ezeh</surname><given-names>AC</given-names></name><name><surname>Patton</surname><given-names>GC</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Adolescence: a foundation for future health</article-title><source>Lancet</source><volume>379</volume><fpage>1630</fpage><lpage>1640</lpage><pub-id pub-id-type="doi">10.1016/S0140-6736(12)60072-5</pub-id><pub-id pub-id-type="pmid">22538178</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Shamash</surname><given-names>P</given-names></name><name><surname>Carandini</surname><given-names>M</given-names></name><name><surname>Harris</surname><given-names>KD</given-names></name><name><surname>Steinmetz</surname><given-names>NA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A tool for analyzing electrode tracks from slice histology</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/447995</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Shamash</surname><given-names>P</given-names></name><name><surname>Peters</surname><given-names>A</given-names></name><name><surname>Steinmetz</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2025">2025</year><data-title>Cortex-lab</data-title><version designator="e5a57fe">e5a57fe</version><source>GitHub</source><ext-link ext-link-type="uri" xlink:href="https://github.com/cortex-lab/allenCCF">https://github.com/cortex-lab/allenCCF</ext-link></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shani-Narkiss</surname><given-names>H</given-names></name><name><surname>Vinograd</surname><given-names>A</given-names></name><name><surname>Landau</surname><given-names>ID</given-names></name><name><surname>Tasaka</surname><given-names>G</given-names></name><name><surname>Yayon</surname><given-names>N</given-names></name><name><surname>Terletsky</surname><given-names>S</given-names></name><name><surname>Groysman</surname><given-names>M</given-names></name><name><surname>Maor</surname><given-names>I</given-names></name><name><surname>Sompolinsky</surname><given-names>H</given-names></name><name><surname>Mizrahi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Young adult-born neurons improve odor coding by mitral cells</article-title><source>Nature Communications</source><volume>11</volume><elocation-id>5867</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-020-19472-8</pub-id><pub-id pub-id-type="pmid">33203831</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spear</surname><given-names>LP</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Neurobehavioral changes in adolescence</article-title><source>Current Directions in Psychological Science</source><volume>9</volume><fpage>111</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1111/1467-8721.00072</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>YJ</given-names></name><name><surname>Wu</surname><given-names>GK</given-names></name><name><surname>Liu</surname><given-names>B-H</given-names></name><name><surname>Li</surname><given-names>P</given-names></name><name><surname>Zhou</surname><given-names>M</given-names></name><name><surname>Xiao</surname><given-names>Z</given-names></name><name><surname>Tao</surname><given-names>HW</given-names></name><name><surname>Zhang</surname><given-names>LI</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Fine-tuning of pre-balanced excitation and inhibition during auditory cortical development</article-title><source>Nature</source><volume>465</volume><fpage>927</fpage><lpage>931</lpage><pub-id pub-id-type="doi">10.1038/nature09079</pub-id><pub-id pub-id-type="pmid">20559386</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takesian</surname><given-names>AE</given-names></name><name><surname>Kotak</surname><given-names>VC</given-names></name><name><surname>Sanes</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Presynaptic GABA(B) receptors regulate experience-dependent development of inhibitory short-term plasticity</article-title><source>The Journal of Neuroscience</source><volume>30</volume><fpage>2716</fpage><lpage>2727</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3903-09.2010</pub-id><pub-id pub-id-type="pmid">20164356</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Takesian</surname><given-names>AE</given-names></name><name><surname>Kotak</surname><given-names>VC</given-names></name><name><surname>Sanes</surname><given-names>DH</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Age-dependent effect of hearing loss on cortical inhibitory synapse function</article-title><source>Journal of Neurophysiology</source><volume>107</volume><fpage>937</fpage><lpage>947</lpage><pub-id pub-id-type="doi">10.1152/jn.00515.2011</pub-id><pub-id pub-id-type="pmid">22090457</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tasaka</surname><given-names>GI</given-names></name><name><surname>Feigin</surname><given-names>L</given-names></name><name><surname>Maor</surname><given-names>I</given-names></name><name><surname>Groysman</surname><given-names>M</given-names></name><name><surname>DeNardo</surname><given-names>LA</given-names></name><name><surname>Schiavo</surname><given-names>JK</given-names></name><name><surname>Froemke</surname><given-names>RC</given-names></name><name><surname>Luo</surname><given-names>L</given-names></name><name><surname>Mizrahi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The temporal association cortex plays a key role in auditory-driven maternal plasticity</article-title><source>Neuron</source><volume>107</volume><fpage>566</fpage><lpage>579</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2020.05.004</pub-id><pub-id pub-id-type="pmid">32473095</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tasaka</surname><given-names>GI</given-names></name><name><surname>Maggi</surname><given-names>C</given-names></name><name><surname>Taha</surname><given-names>E</given-names></name><name><surname>Mizrahi</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>The local and long-range input landscape of inhibitory neurons in mouse auditory cortex</article-title><source>The Journal of Comparative Neurology</source><volume>531</volume><fpage>502</fpage><lpage>514</lpage><pub-id pub-id-type="doi">10.1002/cne.25437</pub-id><pub-id pub-id-type="pmid">36453284</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vinje</surname><given-names>WE</given-names></name><name><surname>Gallant</surname><given-names>JL</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Sparse coding and decorrelation in primary visual cortex during natural vision</article-title><source>Science</source><volume>287</volume><fpage>1273</fpage><lpage>1276</lpage><pub-id pub-id-type="doi">10.1126/science.287.5456.1273</pub-id><pub-id pub-id-type="pmid">10678835</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>Z</given-names></name><name><surname>Inagaki</surname><given-names>H</given-names></name><name><surname>Li</surname><given-names>N</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name><name><surname>Druckmann</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>An orderly single-trial organization of population dynamics in premotor cortex predicts behavioral variability</article-title><source>Nature Communications</source><volume>10</volume><elocation-id>216</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-08141-6</pub-id><pub-id pub-id-type="pmid">30644387</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wei</surname><given-names>Z</given-names></name><name><surname>Lin</surname><given-names>BJ</given-names></name><name><surname>Chen</surname><given-names>TW</given-names></name><name><surname>Daie</surname><given-names>K</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name><name><surname>Druckmann</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>A comparison of neuronal population dynamics measured with calcium imaging and electrophysiology</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1008198</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008198</pub-id><pub-id pub-id-type="pmid">32931495</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilbrecht</surname><given-names>L</given-names></name><name><surname>Davidow</surname><given-names>JY</given-names></name></person-group><year iso-8601-date="2024">2024</year><article-title>Goal-directed learning in adolescence: neurocognitive development and contextual influences</article-title><source>Nature Reviews. Neuroscience</source><volume>25</volume><fpage>176</fpage><lpage>194</lpage><pub-id pub-id-type="doi">10.1038/s41583-023-00783-w</pub-id><pub-id pub-id-type="pmid">38263216</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zagha</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Shaping the cortical landscape: functions and mechanisms of top-down cortical feedback pathways</article-title><source>Frontiers in Systems Neuroscience</source><volume>14</volume><elocation-id>33</elocation-id><pub-id pub-id-type="doi">10.3389/fnsys.2020.00033</pub-id><pub-id pub-id-type="pmid">32587506</pub-id></element-citation></ref><ref id="bib73"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>LI</given-names></name><name><surname>Bao</surname><given-names>S</given-names></name><name><surname>Merzenich</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Persistent and specific influences of early acoustic environments on primary auditory cortex</article-title><source>Nature Neuroscience</source><volume>4</volume><fpage>1123</fpage><lpage>1130</lpage><pub-id pub-id-type="doi">10.1038/nn745</pub-id><pub-id pub-id-type="pmid">11687817</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.106387.4.sa0</article-id><title-group><article-title>eLife Assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Bathellier</surname><given-names>Brice</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Centre National pour la Recherche Scientifique et Technique (CNRST)</institution><country>France</country></aff></contrib></contrib-group><kwd-group kwd-group-type="claim-importance"><kwd>Important</kwd></kwd-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group></front-stub><body><p>This <bold>important</bold> study suggests that adolescent mice exhibit less accuracy than adult mice in a sound discrimination task when the sound frequencies are very similar. The evidence supporting this observation is <bold>solid</bold> and suggests that it arises from cognitive control differences between adolescent and adult mice. The adolescent period is largely understudied, despite its contribution to shaping the adult brain, which makes this study interesting for a broad range of neuroscientists.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.106387.4.sa1</article-id><title-group><article-title>Reviewer #1 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>Praegel et al. explore the differences in learning an auditory discrimination task between adolescent and adult mice. Using freely-moving (Educage) and head-fixed paradigms, they compare behavioral performance and neuronal responses over the course of learning. The mice were initially trained for seven days on an easy pure frequency tone Go/No-go task (frequency difference of one octave), followed by seven days of a harder version (frequency difference of 0.25 octave). While adolescents and adults showed similar performance on the easy task, adults performed significantly better on the harder task. Quantifying the lick bias of both groups, the authors then argue that the difference in performance is not due to a difference in perception, but rather to a difference in cognitive control. The authors then used neuropixel recordings across 4 auditory cortical regions to quantify the neuronal activity related to the behavior. At the single cell level, the data shows earlier stimulus-related discrimination for adults compared to adolescents in both the easy and hard tasks. At the neuronal population level, adults displayed a higher decoding accuracy and lower onset latency in the hard task as compared to adolescents. Such differences were not only due to learning, but also to age as concluded from recordings in novice mice. After learning, neuronal tuning properties had changed in adults but not in adolescent. Overall, the differences between adolescent and adult neuronal data correlates with the behavior results in showing that learning a difficult task is more challenging for younger mice.</p><p>Strengths:</p><p>The behavioral task is well designed, with the comparison of easy and difficult tasks allowing for a refined conclusion regarding learning across age. The experiments with optogenetics and novice mice are completing the research question in a convincing way.</p><p>The analysis, including the systematic comparison of task performance across the two age groups, is most interesting and reveals differences in learning (or learning strategies?) that are compelling.</p><p>Neuronal recording during both behavioral training and passive sound exposure is particularly powerful, and allows interesting conclusions.</p><p>Weaknesses:</p><p>The weaknesses listed by this reviewer were addressed by adequate revisions.</p></body></sub-article><sub-article article-type="referee-report" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.106387.4.sa2</article-id><title-group><article-title>Reviewer #2 (Public review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>The authors aimed to find out how and how well adult and adolescent mice discriminate tones of different frequencies and whether there are differences in processing at the level of the auditory cortex that might explain differences in behavior between the two groups. Adolescent mice were found to be worse at sound frequency discrimination than adult mice. The performance difference between the groups was most pronounced when the sounds are close in frequency and thus difficult to distinguish and could, at least in part, be attributed to the younger mice' inability to withhold licking in no-go trials. By recording the activity of individual neurons in the auditory cortex when mice performed the task or were passively listening as well as in untrained mice the authors identified differences in the way that the adult and adolescent brains encode sounds and the animals' choice that could potentially contribute to the differences in behavior.</p><p>Strengths:</p><p>The study combines behavioural testing in freely-moving and head-fixed mice, optogenetic manipulation and high density electrophysiological recordings in behaving mice to address important open questions about age differences in sound-guided behavior and sound representation in the auditory cortex.</p><p>Weaknesses:</p><p>The weaknesses listed by this reviewer were addressed by adequate revisions.</p></body></sub-article><sub-article article-type="author-comment" id="sa3"><front-stub><article-id pub-id-type="doi">10.7554/eLife.106387.4.sa3</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Praegel</surname><given-names>Benedikt</given-names></name><role specific-use="author">Author</role><aff><institution>Hebrew University of Jerusalem</institution><addr-line><named-content content-type="city">Jerusalem</named-content></addr-line><country>Israel</country></aff></contrib><contrib contrib-type="author"><name><surname>Chen</surname><given-names>Feng</given-names></name><role specific-use="author">Author</role><aff><institution>Stanford University</institution><addr-line><named-content content-type="city">Stanford</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Dym</surname><given-names>Adria</given-names></name><role specific-use="author">Author</role><aff><institution>Hebrew University of Jerusalem</institution><addr-line><named-content content-type="city">Jerusalem</named-content></addr-line><country>Israel</country></aff></contrib><contrib contrib-type="author"><name><surname>Lavi-Rudel</surname><given-names>Amichai</given-names></name><role specific-use="author">Author</role><aff><institution>Hebrew University of Jerusalem</institution><addr-line><named-content content-type="city">Jerusalem</named-content></addr-line><country>Israel</country></aff></contrib><contrib contrib-type="author"><name><surname>Druckmann</surname><given-names>Shaul</given-names></name><role specific-use="author">Author</role><aff><institution>Stanford University</institution><addr-line><named-content content-type="city">Stanford</named-content></addr-line><country>United States</country></aff></contrib><contrib contrib-type="author"><name><surname>Mizrahi</surname><given-names>Adi</given-names></name><role specific-use="author">Author</role><aff><institution>The Hebrew University of Jerusalem</institution><addr-line><named-content content-type="city">Jerusalem</named-content></addr-line><country>Israel</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the previous reviews.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Public review):</bold></p><p>Summary:</p><p>Praegel et al. explore the differences in learning an auditory discrimination task between adolescent and adult mice. Using freely-moving (Educage) and head-fixed paradigms, they compare behavioral performance and neuronal responses over the course of learning. The mice were initially trained for seven days on an easy pure frequency tone Go/No-go task (frequency difference of one octave), followed by seven days of a harder version (frequency difference of 0.25 octave). While adolescents and adults showed similar performance on the easy task, adults performed significantly better on the harder task. Quantifying the lick bias of both groups, the authors then argue that the difference in performance is not due to a difference in perception, but rather to a difference in cognitive control. The authors then used neuropixel recordings across 4 auditory cortical regions to quantify the neuronal activity related to the behavior. At the single cell level, the data shows earlier stimulus-related discrimination for adults compared to adolescents in both the easy and hard tasks. At the neuronal population level, adults displayed a higher decoding accuracy and lower onset latency in the hard task as compared to adolescents. Such differences were not only due to learning, but also to age as concluded from recordings in novice mice. After learning, neuronal tuning properties had changed in adults but not in adolescent. Overall, the differences between adolescent and adult neuronal data correlates with the behavior results in showing that learning a difficult task is more challenging for younger mice.</p><p>Strengths:</p><p>The behavioral task is well designed, with the comparison of easy and difficult tasks allowing for a refined conclusion regarding learning across age. The experiments with optogenetics and novice mice are completing the research question in a convincing way.</p><p>The analysis, including the systematic comparison of task performance across the two age groups, is most interesting, and reveals differences in learning (or learning strategies?) that are compelling.</p><p>Neuronal recording during both behavioral training and passive sound exposure is particularly powerful, and allows interesting conclusions.</p><p>Weaknesses:</p><p>The presentation of the paper must be strengthened. Inconsistencies, missing information or confusing descriptions should be fixed.</p></disp-quote><p>We have carefully re-read the manuscript and reviewed it for inconsistencies. We made several corrections in the figures. For example, we removed redundant lines from violin plots and statistics, applied consistent labels, matched y- and x-limits of graphics, and adjusted labels. We also clarified descriptions of some experiment by adding explanations to the text.</p><disp-quote content-type="editor-comment"><p>The recording electrodes cover regions in the primary and secondary cortices. It is well known that these two regions process sounds quite differently (for example, one has tonotopy, the other not), and separating recordings from both regions is important to conclude anything about sound representations. The authors show that the conclusions are the same across regions for Figure 4, but is it also the case for the subsequent analysis? Comparing to the original manuscript, the authors have now done the analysis for AuDp and AUDv separately, and say that the differences are similar in both regions. The data however shows that this is not the case (Fig S7). And even if it were the case, how would it compatible with the published literature?</p></disp-quote><p>To address this and previous concerns about regional differences, the manuscript now includes 4 figures (4-1, 4-3, 6-2, 7-1) and 5 supplemental tables (3,4, 5, 6, 8) that explicitly compare results across brain regions.</p><p>Following the reviewer’s request for subsequent analysis, we now added a new supplemental figure (Fig. S6-2) and two new supplementary tables (Tables S5, S6). We show that similar to expert mice (supplementary Table 3, and supplementary Table 4), the firing properties of adolescent and adult novice mice differ across auditory subregions (supplementary Table 5). We also show that the different auditory subregions have different firing properties (supplementary Table 6). With respect to task engagement, we show that (similar to Fig. S4-2) the neuronal discriminability in different auditory subregions is similar in both novice and expert mice (Fig. S6-2).</p><p>Following the comment on Fig. S7-1, we made three changes to the revised manuscript. First, we now highlight that the differences firing properties between adolescent and adult neurons in AUDp and AUDv were distinct, but not significantly different within age-group comparisons. Second, we clearly state that the learning related changes in the measured parameters are different between AUDp and AUDv. Note, however, the greater changes in adult neurons after learning remains consistent between AUDp and AUDv. Third, we softened our original claim but still highlighted the stronger learning-induced plasticity in adults.</p><p>Regarding the concern that different regions should show different patterns due to their known differences (e.g. tonotopy). Of course we agree that different areas differ functionally (as shown in our own previous work and here as well). However, it is still plausible, and biologically reasonable, that developmental changes may proceed in a similar direction across different areas, even if their baseline coding properties differ.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public review):</bold></p><p>Summary:</p><p>The authors aimed to find out how and how well adult and adolescent mice discriminate tones of different frequencies and whether there are differences in processing at the level of the auditory cortex that might explain differences in behavior between the two groups. Adolescent mice were found to be worse at sound frequency discrimination than adult mice. The performance difference between the groups was most pronounced when the sounds are close in frequency and thus difficult to distinguish and could, at least in part, be attributed to the younger mice' inability to withhold licking in no-go trials. By recording the activity of individual neurons in the auditory cortex when mice performed the task or were passively listening as well as in untrained mice the authors identified differences in the way that the adult and adolescent brains encode sounds and the animals' choice that could potentially contribute to the differences in behavior.</p><p>Strengths:</p><p>The study combines behavioural testing in freely-moving and head-fixed mice, optogenetic manipulation and high density electrophysiological recordings in behaving mice to address important open questions about age differences in sound-guided behavior and sound representation in the auditory cortex.</p><p>Weaknesses:</p><p>For some of the analyses that the authors conducted it is unclear what the rationale behind them is and, consequently, what conclusion we can draw from them.</p></disp-quote><p>We have carefully re-read the manuscript and reviewed it for analyses that lacked a clear rationale or conclusion. To address this, we have made several changes to clarify the reasoning and strengthen the interpretation of the results.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #1 (Recommendations for the authors):</bold></p><p>It would have helped if the authors had highlighted the changes they made to the manuscript compared to the original version - especially since many replies to the reviewers' comments were as vague as &quot;...we fixed some of the wording so it adheres to the data shown&quot;, or &quot;we refined our interpretation&quot;, without further details.</p><p>The revised version has improved substantially, and the main claims have been discussed in a more objective way. Important new analyses have been added to allow for a refined interpretation of the results. However, the presentation of the data could still be strengthened significantly (in response to comment A from last review).</p></disp-quote><p>We apologize for the lack of detail in some of our previous responses. Our intention was to keep the replies concise, assuming that the side-by-side version with tracked changes would make the edits sufficiently clear. However, we understand the need for greater transparency. Thus, below we provide the following five lists describing the major changes: (1) List of specific reviewer recommendations, (2) list of corrections in figures, (3) list of clarity issues, (4) list of fixed mistakes, (5) list of new figures. We hope this breakdown makes the revisions clearer and more accessible.</p><p>List of specific reviewer recommendations:</p><disp-quote content-type="editor-comment"><p>l.108 mentions a significant change in the vertical line of Fig 1F - Could this significance be indicated and quantified in the figure?</p></disp-quote><p>We quantified and indicated the significance of the vertical line in Fig. 1f and Fig. 1i.</p><disp-quote content-type="editor-comment"><p>Fig.1G - the thick and thin lines should be defined, as well as the grey and white dots (same values for adolescents, not for adults).</p></disp-quote><p>(a) We removed the thin inner lines from the violin plot. We define the bar (thick line) of the violin plot in an additional sentence in the methods section under data analysis (LL820-823). (b) We adjusted the marker outlines in the adult data (Fig. 1G).</p><disp-quote content-type="editor-comment"><p>the figure axis legends should be consistent (trails in Fig D vs # trails in Fig 1F)</p></disp-quote><p>We adjusted the axis legend to # trials in Fig. 1D.</p><disp-quote content-type="editor-comment"><p>l.110: is d' always calculated based on the 100 last trials of a session, or is it just for Figure 1F? -etc...</p></disp-quote><p>d’ is always calculated based on the last 100 trials. To clarify this, we added a description in the methods section (L830).</p><p>List of corrections in the figures:</p><p>(1) We removed the internal lines from violin plots in throughout Fig. 1-7.</p><p>(2) We removed the underline of the statistics throughout Fig. 1-7.</p><p>(3) We consistently applied ‘adolescent’ and ‘adult’ figure labels and titles with lowercase letters throughout Fig. 1-7.</p><p>(4) We applied consistent labelling of ‘time (ms)’ throughout Fig. 1-7.</p><p>(5) We matched the size of dashed lines throughout Fig. 1-6.</p><p>(6) We adjusted the x-label of Fig. 1d, Fig. S-1-1 a, Fig. 3c, Fig. 3h-i, Fig, 4d to ‘# trials’.</p><p>(7) We removed the x-label of ‘Experimental Group’ from Fig. 1 to enhance consistency with other figures.</p><p>(8) We removed misaligned dots from the violin plots in Fig. 1g, Fig. 2f, Fig. 3f,g.</p><p>(9) We corrected the plot in Fig. S1-1b.</p><p>(10) We adjusted the y-limits of Fig. S1-1c to be consistent with Fig. S1-1d,e.</p><p>(11) We adjusted the x-labels and y-labels of Fig, 2, Fig. S3-1, Fig, S3-2 and Fig. 3b to ‘freq. (kHz)’.</p><p>(12) We added the age of adolescent and adult mice to the schematic timeline in Fig. 2a.</p><p>(13) We added a label of the reinforcement delay to the schematic trial structure in Fig. 3b.</p><p>(14) We added within-group statistics to Fig. 3e and the figure legend.</p><p>(15) We adjusted the x-label of Fig. 3d to ‘# sessions’.</p><p>(16) We adjusted the x-label of Fig. 3d and Fig. S3-1b to ‘# licks’.</p><p>(17) We changed the y-label in Fig. S3-1a, and Fig. S3-2d, e to ‘lick ratio’ to avoid confusion with the lick rate (Hz) that was calculated in Fig. 4 and Fig. 6.</p><p>(18) We replaced the titles ‘CAMKII’ with ‘dTomato’ in Fig. S3-2 to correctly highlight that both the experimental and control injection were CAMKII injections.</p><p>(19) We adjusted the x-labels and y-labels of Fig, 2, Fig. S3-1, Fig, S3-2 and Fig. 3b to ‘freq. (kHz)’.</p><p>(20) We adjusted the y-label of Fig. S4-1c to ‘# neurons’.</p><p>(21) We matched the x-ticks in Fig. 4e,f.</p><p>(22) We matched the x-ticks in Fig. 6d-g.</p><p>(23) We changed the x-label in Fig. 4g, S4-2 and S6-2 to ‘duration (ms)’ to match the figure label with the manuscript.</p><p>(24) We consistently label ‘Hit’, ‘Miss’, ‘FA’ and ‘CR’ with capital letters in Fig. 4d-e.</p><p>(25) We replaced the double figure label ‘C.’ in Fig. S4-2 with ‘D.’.</p><p>(26) We adjusted the dot-size in Fig. 5 to be equal for all graphs.</p><p>(27) We added ticks to the experimental timeline in Fig. 6a.</p><p>(28) We corrected the y-label in Fig.7c. Now it correctly reflects 5 attenuations from 72-32 dB SPL.</p><p>(29) We matched the y-label of Fig. 7e-h and Fig. S7-1.</p><p>List of clarity issues:</p><p>(1) We replaced the term ‘lower response bias’ with ‘higher lick bias’ (L24) to accurately describe the more negative (lower) criterion-bias, which highlights a higher tendency to lick.</p><p>(2) We replaced the term ‘response bias’ with ‘lick bias’ to consistently describe the calculated criterion-bias (L24, L149, L164, L455, L456, L468).</p><p>(3) We clarify that the age-related differences were ‘more pronounced’ instead of simply ‘higher’ to accurately reflect not simply the increase in adolescent lick-bias, but also the decrease in adult lick-bias (L31).</p><p>(4) We clarified that adolescent sound representations are not merely ’distinct’, but ‘not fully mature’ in L83.</p><p>(5) We clarified in L180 that the impulsive responses we observed in adolescent mice could be related to being ‘less impacted by punishments’.</p><p>(6) We clarified the differences in firing properties of auditory sub-regions analyzed in Supplementary Table 3 (L287-295).</p><p>(7) We explained and clarified the reference to Fig. 3j (LL252-253).</p><p>(8) We added statistics to Fig.S4-2 to support our claim that there are no differences in the onset-latency, duration of discriminability and maximal discriminability between different sub-regions within age-groups (LL 314-315).</p><p>(9) We expanded our explanation of the results in Table 3 (LL370-379).</p><p>(10) We separated the reference to Fig. 6b and Fig. 6c to clarify their meaning (LL358-361).</p><p>(11) We clarified the differences in basic firing properties during the FRA protocol in Fig. 7 (LL409-418).</p><p>(12) We expanded our explanation of the differences of the learning related firing properties in AUDp and AUDv of Fig. S7-1 (LL426-433).</p><p>(13) We changed the term ‘plasticity profiles’ to ‘learning related plasticity’ to further clarify our limitation that L5/6 and L2/3 may exhibit distinct learning related changes (L496).</p><p>(14) We changed the term ‘sluggish’ (L481) to ‘delayed’ to more precisely explain differences between adolescent and adult tuning properties.</p><p>(15) We clarified that the running d’ was calculated in bins of 25 trials, instead of ‘the last 25 trials’ (LL845-846).</p><p>List of fixed mistakes:</p><p>(1) We corrected and matched the age to more accurately reflect the age mice were recorded (P37-42 and P77-82).</p><p>(2) We corrected the attenuation range from 72-42 to 72-32 dB SPL to correctly reflect the 5 attenuations used in the protocol.</p><p>(3) We corrected the number of channels shown in the voltage trace from 10 to 11 (Fig. S4-1a)</p><p>(4) We corrected the number of neurons recorded in novice adolescent mice in the legend of Fig. 6 from 140 to 130 (Fig. 6b).</p><p>(5) We removed redundant, or double brackets, commas, dots, and semi-colons in the figure legends.</p><p>(6) We corrected the LME statistics Table 2.</p><p>List of new figures and tables:</p><p>(1) We added a new supplementary figure to accompany Figure 6. Specifically, Fig. S6-2, shows the interaction of the three measured discriminability properties (onset delay, duration of discriminability, and maximal discriminability) in novice compared to expert mice in the easy and hard task (Go compared to No Go). The figure compares the different auditory sub-regions (similar to Fig. S4-2). We show that the discriminability properties within different groups is not significantly different among the four different sub-regions.</p><p>(2) Supplementary Table 5: We compared the firing properties in different auditory subregions in novice mice, and found (similar to expert mice) that the firing properties differ between adult and adolescent mice across the four different sub-regions.</p><p>(3) Supplementary Table 6: We compared the firing properties between different subregions, separately for adolescent and adult novice mice. Similar to expert mice, we found that different auditory subregions differ in their auditory firing properties.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations for the authors):</bold></p><p>The authors largely addressed my suggestions.</p><p>Comparing hit vs correct rejection trials in the population decoding analysis (L313-314): The authors acknowledge that comparing these two trial types conflates choice and stimulus decoding but I am not convinced that the changes to the manuscript text make this clear enough to the reader.</p></disp-quote><p>Thank you for pointing this out. We have made additional revisions to clarify this, and other issues more explicitly, as follows:</p><p>(1) We have expanded the explanation of how our population decoding analysis conflates stimulus and choice, and we acknowledge the limitations of this approach in the Abstract (L28), the Results section (L324-326, LL367-370) and the Discussion (LL516-519).</p><p>(2) We replaced the analysis of impulsivity on the head-fixed task. Instead of analyzing all it is, we focus only on ITIs following FA trials (Fig. S3-1c,d). This is more consistent with the analysis in the Educage (Fig. S2-1), where we show that adolescents exhibit increased impulsivity after FA trials. We found a similar result for ITIs following FA trials in the head-fixed task.</p><p>(3) To provide complementary insight, we now further justify our use of the Fisher separation metric alongside decoding accuracy in Figure 5, with a clearer rationale provided in LL343-345</p><p>(4) We also clarified our reasoning for focusing on 62 dB SPL in the FRA-based analysis in LL400-403.</p></body></sub-article></article>