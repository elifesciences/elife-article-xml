<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">78712</article-id><article-id pub-id-type="doi">10.7554/eLife.78712</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Advance</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Parallel processing, hierarchical transformations, and sensorimotor associations along the ‘where’ pathway</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-118314"><name><surname>Doudlah</surname><given-names>Raymond</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3631-5947</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-118312"><name><surname>Chang</surname><given-names>Ting-Yu</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-3964-0905</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" id="author-118313"><name><surname>Thompson</surname><given-names>Lowell W</given-names></name><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund3"/><xref ref-type="other" rid="fund4"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-118305"><name><surname>Kim</surname><given-names>Byounghoon</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-7159-5134</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-118311"><name><surname>Sunkara</surname><given-names>Adhira</given-names></name><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="fn" rid="con5"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-117318"><name><surname>Rosenberg</surname><given-names>Ari</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8606-2987</contrib-id><email>ari.rosenberg@wisc.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund5"/><xref ref-type="other" rid="fund6"/><xref ref-type="other" rid="fund7"/><xref ref-type="other" rid="fund8"/><xref ref-type="fn" rid="con6"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01y2jtd41</institution-id><institution>Department of Neuroscience, University of Wisconsin-Madison</institution></institution-wrap><addr-line><named-content content-type="city">Madison</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02bn97g32</institution-id><institution>National Defense Medical Center</institution></institution-wrap><addr-line><named-content content-type="city">Taipei</named-content></addr-line><country>Taiwan</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03z39qd89</institution-id><institution>WiSys Technology Foundation</institution></institution-wrap><addr-line><named-content content-type="city">Madison</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Freedman</surname><given-names>David J</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/024mw5h28</institution-id><institution>The University of Chicago</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Moore</surname><given-names>Tirin</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00f54p054</institution-id><institution>Stanford University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>11</day><month>08</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e78712</elocation-id><history><date date-type="received" iso-8601-date="2022-03-22"><day>22</day><month>03</month><year>2022</year></date><date date-type="accepted" iso-8601-date="2022-08-10"><day>10</day><month>08</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at .</event-desc><date date-type="preprint" iso-8601-date="2022-03-23"><day>23</day><month>03</month><year>2022</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2022.03.22.485287"/></event></pub-history><permissions><copyright-statement>© 2022, Doudlah, Chang et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Doudlah, Chang et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-78712-v2.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-78712-figures-v2.pdf"/><related-article related-article-type="article-reference" ext-link-type="doi" xlink:href="10.7554/eLife.57968" id="ra1"/><abstract><p>Visually guided behaviors require the brain to transform ambiguous retinal images into object-level spatial representations and implement sensorimotor transformations. These processes are supported by the dorsal ‘where’ pathway. However, the specific functional contributions of areas along this pathway remain elusive due in part to methodological differences across studies. We previously showed that macaque caudal intraparietal (CIP) area neurons possess robust 3D visual representations, carry choice- and saccade-related activity, and exhibit experience-dependent sensorimotor associations (Chang et al., 2020b). Here, we used a common experimental design to reveal parallel processing, hierarchical transformations, and the formation of sensorimotor associations along the ‘where’ pathway by extending the investigation to V3A, a major feedforward input to CIP. Higher-level 3D representations and choice-related activity were more prevalent in CIP than V3A. Both areas contained saccade-related activity that predicted the direction/timing of eye movements. Intriguingly, the time course of saccade-related activity in CIP aligned with the temporally integrated V3A output. Sensorimotor associations between 3D orientation and saccade direction preferences were stronger in CIP than V3A, and moderated by choice signals in both areas. Together, the results explicate parallel representations, hierarchical transformations, and functional associations of visual and saccade-related signals at a key juncture in the ‘where’ pathway.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>3D vision</kwd><kwd>oculomotor</kwd><kwd>saccade</kwd><kwd>choice</kwd><kwd>sensorimotor</kwd><kwd>parieto-occipital junction</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Rhesus macaque</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>T32EY027721</award-id><principal-award-recipient><name><surname>Doudlah</surname><given-names>Raymond</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>DGE-1545481</award-id><principal-award-recipient><name><surname>Doudlah</surname><given-names>Raymond</given-names></name><name><surname>Thompson</surname><given-names>Lowell W</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>T32NS105602</award-id><principal-award-recipient><name><surname>Thompson</surname><given-names>Lowell W</given-names></name></principal-award-recipient></award-group><award-group id="fund4"><funding-source><institution-wrap><institution>McPherson Eye Research Institute</institution></institution-wrap></funding-source><award-id>Graduate Student Support Initiative</award-id><principal-award-recipient><name><surname>Thompson</surname><given-names>Lowell W</given-names></name></principal-award-recipient></award-group><award-group id="fund5"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000879</institution-id><institution>Alfred P. Sloan Foundation</institution></institution-wrap></funding-source><award-id>FG-2016-6468</award-id><principal-award-recipient><name><surname>Rosenberg</surname><given-names>Ari</given-names></name></principal-award-recipient></award-group><award-group id="fund6"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100001391</institution-id><institution>Whitehall Foundation</institution></institution-wrap></funding-source><award-id>2016-08-18</award-id><principal-award-recipient><name><surname>Rosenberg</surname><given-names>Ari</given-names></name></principal-award-recipient></award-group><award-group id="fund7"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100007046</institution-id><institution>Greater Milwaukee Foundation</institution></institution-wrap></funding-source><award-id>Shaw Scientist Award</award-id><principal-award-recipient><name><surname>Rosenberg</surname><given-names>Ari</given-names></name></principal-award-recipient></award-group><award-group id="fund8"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000002</institution-id><institution>National Institutes of Health</institution></institution-wrap></funding-source><award-id>EY029438</award-id><principal-award-recipient><name><surname>Rosenberg</surname><given-names>Ari</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Hierarchical transformations of visual representations, saccade-related activity, and sensorimotor associations occur in parallel at the juncture of visual and parietal cortex.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The 3D perceptual and sensorimotor capabilities of primates facilitate their ability to shape the world. For instance, 3D spatial reasoning is a key predictor of engineering problem-solving ability (<xref ref-type="bibr" rid="bib31">Hsi et al., 1997</xref>). These capabilities are supported by the dorsal ‘where’ pathway. In particular, high-level visual transformations are thought to occur in brain areas located at the parieto-occipital junction (<xref ref-type="bibr" rid="bib65">Tsao et al., 2003</xref>; <xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). Parietal cortex is thought to then implement sensorimotor transformations that map those sensory representations to motor responses (<xref ref-type="bibr" rid="bib48">Pause and Freund, 1989</xref>; <xref ref-type="bibr" rid="bib57">Rushworth et al., 1997</xref>; <xref ref-type="bibr" rid="bib7">Buneo and Andersen, 2006</xref>). However, assigning particular functions to specific areas has been challenging due to methodological differences across studies. Here, we used a common experimental design to investigate two areas that bridge the parieto-occipital junction in macaque monkeys: intermediate visual area V3A and the caudal intraparietal (CIP) area.</p><p>Area CIP is a site of 3D visual processing (<xref ref-type="bibr" rid="bib64">Taira et al., 2000</xref>; <xref ref-type="bibr" rid="bib67">Tsutsui et al., 2002</xref>; <xref ref-type="bibr" rid="bib53">Rosenberg et al., 2013</xref>; <xref ref-type="bibr" rid="bib54">Rosenberg and Angelaki, 2014a</xref>; <xref ref-type="bibr" rid="bib55">Rosenberg and Angelaki, 2014b</xref>), which is functionally correlated (<xref ref-type="bibr" rid="bib68">Tsutsui et al., 2003</xref>; <xref ref-type="bibr" rid="bib17">Elmore et al., 2019</xref>) and causally linked (<xref ref-type="bibr" rid="bib66">Tsutsui et al., 2001</xref>; <xref ref-type="bibr" rid="bib69">Van Dromme et al., 2016</xref>) to 3D perception. Saccade-related activity and sensorimotor associations in CIP may further support goal-directed behaviors (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>) via connections to oculomotor and prehensile areas (<xref ref-type="bibr" rid="bib39">Lewis and Van Essen, 2000</xref>; <xref ref-type="bibr" rid="bib49">Premereur et al., 2015</xref>; <xref ref-type="bibr" rid="bib69">Van Dromme et al., 2016</xref>; <xref ref-type="bibr" rid="bib38">Lanzilotto et al., 2019</xref>).</p><p>By comparison, V3A findings have been highly conflicting. Some imply relatively low-level image processing such as spatiotemporal filtering (<xref ref-type="bibr" rid="bib22">Gaska et al., 1987</xref>; <xref ref-type="bibr" rid="bib23">Gaska et al., 1988</xref>), basic stereoscopic depth selectivity (<xref ref-type="bibr" rid="bib2">Anzai et al., 2011</xref>), and 2D direction selectivity (<xref ref-type="bibr" rid="bib44">Nakhla et al., 2021</xref>). Other findings link V3A to high-level processes underlying stable, allocentric representations of the world. This includes combining visual and extraretinal signals to represent objects in non-retinal coordinates (<xref ref-type="bibr" rid="bib20">Galletti and Battaglini, 1989</xref>; <xref ref-type="bibr" rid="bib21">Galletti et al., 1990</xref>; <xref ref-type="bibr" rid="bib58">Sauvan and Peterhans, 1999</xref>; <xref ref-type="bibr" rid="bib43">Nakamura and Colby, 2002</xref>), distinguishing veridical object motion from self-induced retinal image motion (<xref ref-type="bibr" rid="bib21">Galletti et al., 1990</xref>), and 3D spatial processing (<xref ref-type="bibr" rid="bib65">Tsao et al., 2003</xref>; <xref ref-type="bibr" rid="bib17">Elmore et al., 2019</xref>). Furthermore, V3A activity is modulated by attention and memory-related factors, and some neurons show postsaccadic activity (<xref ref-type="bibr" rid="bib42">Nakamura and Colby, 2000</xref>).</p><p>To directly compare the functional properties of these interconnected areas, we used a common experimental design to assess (i) selectivity for the 3D pose (orientation and position) of planar surfaces, (ii) choice-related activity during a 3D orientation discrimination task (<xref ref-type="bibr" rid="bib9">Chang et al., 2020a</xref>), (iii) saccade-related activity during a visually guided saccade task (<xref ref-type="bibr" rid="bib41">Munoz and Wurtz, 1995</xref>; <xref ref-type="bibr" rid="bib27">Hanes and Schall, 1996</xref>), and (iv) sensorimotor associations (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). Multiple lines of evidence converged to support a V3A-to-CIP hierarchy. First, our findings revealed that robust 3D pose representations were most prominent in CIP. Second, choice-related activity was associated with robust 3D pose tuning in both areas but most prevalent in CIP. Third, the areas contained similar proportions of neurons with saccade-related activity that predicted the direction and timing of eye movements. Saccade-related activity started earlier in V3A than CIP and the CIP time course closely matched the temporally integrated V3A output, suggesting that saccade-related signals in CIP may originate in V3A. Notably, both areas showed sensorimotor associations (which were stronger in CIP than V3A) that were statistically moderated by choice-related activity. Together, these findings challenge classical notions of sensorimotor dichotomies, argue for a reclassification of V3A as association cortex, and implicate choice-related activity as a novel factor in sensorimotor processing.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>To investigate the contributions of areas V3A and CIP to the transformation of retinal images into object-level representations and goal-directed sensorimotor processing, we compared the 3D selectivity, saccade-related properties, and sensorimotor associations of 692 V3A neurons (Monkey L: N = 311; Monkey F: N = 263; Monkey W: N = 118) and 437 previously analyzed CIP neurons (Monkey L: N = 218; Monkey F: N = 219) (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). Areas V3A and CIP were dissociated from each other and adjacent regions using multiple anatomical and functional criteria (<xref ref-type="fig" rid="fig1">Figure 1</xref>; ‘Materials and methods’). Supporting a V3A-to-CIP hierarchy, the median visual response latency was shorter in V3A (46 ms) than CIP (52 ms) and the receptive fields were smaller in V3A than CIP (<xref ref-type="fig" rid="fig1s1">Figure 1—figure supplement 1</xref>).</p><fig-group><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Neuronal recordings.</title><p>(<bold>A</bold>) Lateral (left) and dorsal (right) views of the inflated cortical surface of Monkey L (left hemisphere). Dashed lines mark the coronal sections in (<bold>B</bold>). (<bold>B</bold>) Coronal sections (left: AP = –7 mm; right: AP = –9.5 mm) with MRI-based estimates of the boundaries of V3A, CIP, and adjacent areas. Recording locations for V3A (blue-gray circles) and CIP (red squares) were projected along the AP axis onto the closest of the two coronal sections shown. A schematic of a four-tetrode laminar probe with spike waveforms from the V3A recording marked with white circles in the right coronal section is shown (middle). CIP, caudal intraparietal area (light blue); V3A, visual area V3A (orange); PIP, posterior intraparietal area; V3, visual area V3; PO, parieto-occipital area; LIPd, dorsal aspect of the lateral intraparietal area; 7a, area 7a.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78712-fig1-v2.tif"/></fig><fig id="fig1s1" position="float" specific-use="child-fig"><label>Figure 1—figure supplement 1.</label><caption><title>Response latencies and receptive field sizes.</title><p>(<bold>A</bold>) Cumulative density functions for the visual latencies of visual area V3A (V3A) (orange) and caudal intraparietal (CIP) area (blue) neurons. Colored circles mark the median latencies. (<bold>B</bold>) Receptive field (RF) size versus eccentricity for V3A (orange circles) and CIP (blue squares). RF size was defined as the square root of the RF area. Type II regression lines are shown for V3A (solid line; RF size = 2.6 + 0.55 × eccentricity) and CIP (dashed line; RF size = 5.4 + 0.81 × eccentricity).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78712-fig1-figsupp1-v2.tif"/></fig></fig-group><sec id="s2-1"><title>Behavioral discrimination of 3D surface orientation</title><p>To investigate the transformation of visual representations into goal-directed behaviors, we trained three monkeys to report the 3D orientation of a planar surface (<xref ref-type="bibr" rid="bib9">Chang et al., 2020a</xref>). Specifically, they performed an eight-alternative forced choice (8AFC) tilt discrimination task with planar surfaces presented at different orientations and distances (<xref ref-type="fig" rid="fig2">Figure 2</xref>). The orientation was defined by two angular variables (<xref ref-type="bibr" rid="bib63">Stevens, 1983</xref>; <xref ref-type="bibr" rid="bib53">Rosenberg et al., 2013</xref>): tilt and slant. Tilt describes which side of the plane was nearest to the monkey and slant describes the rotation in depth (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). Planes were presented for 1 s while fixation was maintained on a target at the center of the screen. The monkey then reported the plane’s tilt (the near side) via a saccade to the corresponding choice target, regardless of the slant or distance (<xref ref-type="fig" rid="fig2">Figure 2B</xref>).</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Stimuli, task, and behavioral performance.</title><p>(<bold>A</bold>) Planar surfaces were defined using random dots with perspective and stereoscopic cues (illustrated here as red-green anaglyphs). For clarity, the size and number of dots differ from the actual stimuli. (<bold>B</bold>) Eight-alternative tilt discrimination task. A trial began by fixating a dot at the center of the screen (fixation was always at screen distance, 57 cm) for 300 ms (left). A plane was then presented with a given tilt (0–315°, 45° steps), slant (0–60°, 15° steps), and distance (37, 57, 97, or 137 cm) for 1 s (middle). The fixation target and plane then disappeared and eight choice targets corresponding to the eight tilts appeared (right). This cued the monkey to saccade to one of the targets to report which side of the plane was nearest. (<bold>C</bold>) Behavioral performance. Error distributions of reported tilts for each slant at 97 cm for Monkey W (left). Data points show the mean probability of a given ΔTilt (reported tilt – presented tilt), and error bars show standard error of the mean (SEM) across sessions (N = 14). Solid curves are von Mises probability density functions with sensitivities (<inline-formula><mml:math id="inf1"><mml:mi>κ</mml:mi></mml:math></inline-formula>) indicated. The black dashed line marks chance level. The heat map (right) shows the mean tilt sensitivity for each slant (rows) and distance (columns) for Monkey W across sessions. Yellow hues indicate higher sensitivities. Green arrow and purple rectangle mark the data shown in the error distribution plots (left).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78712-fig2-v2.tif"/></fig><p>Behavioral performance was quantified each session (V3A: Monkey L: N = 39; Monkey F: N = 38; Monkey W: N = 14; CIP: Monkey L: N = 26; Monkey F: N = 27) by calculating the distribution of reported tilt errors (∆Tilt = reported tilt – presented tilt) for each non-zero slant and distance (16 conditions) pooled across tilt (<xref ref-type="bibr" rid="bib9">Chang et al., 2020a</xref>; <xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). Each error distribution was then fit with a von Mises probability density function (<xref ref-type="disp-formula" rid="equ1">Equation 1</xref>) and behavioral sensitivity was quantified as the concentration parameter (<inline-formula><mml:math id="inf2"><mml:mi>κ</mml:mi></mml:math></inline-formula>) of the fit. To assess how sensitivity depended on the viewing conditions, we ran a linear mixed-effects model with distance, slant, and area as main effects and animal as a random effect. Consistent with our previous findings, sensitivity decreased with distance from fixation and increased with slant (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). Correspondingly, behavioral sensitivity significantly depended on distance (p=4.1 × 10<sup>-30</sup>) and slant (p=2.2 × 10<sup>-308</sup>). There was no significant effect of area (p=0.46), indicating that behavioral performance was similar during the V3A and CIP sessions. To relate this pattern of behavioral sensitivity to V3A and CIP activity, we next characterized the simultaneously recorded neuronal responses.</p></sec><sec id="s2-2"><title>Hierarchical transformations in the representation of 3D orientation</title><p>The visual system is thought to turn ambiguous 2D retinal signals into behaviorally relevant 3D object representations through a series of transformations. We therefore hypothesized that CIP would contain a higher-level representation of 3D pose than V3A. For a 3D pose selective neuron, the shape of its 3D orientation tuning curve will be tolerant to distance, but its overall response amplitude (gain) should be distance-dependent (<xref ref-type="bibr" rid="bib33">Janssen et al., 2000</xref>; <xref ref-type="bibr" rid="bib45">Nguyenkim and DeAngelis, 2003</xref>; <xref ref-type="bibr" rid="bib1">Alizadeh et al., 2018</xref>; <xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). In contrast, a neuron selective for lower-level visual features (e.g., binocular disparity) will have 3D orientation tuning curves whose shape and gain are highly distance-dependent. To test for 3D pose tuning, we therefore assessed how 3D orientation tuning depended on distance.</p><p>The 3D orientation tuning curves of four representative V3A neurons are shown in <xref ref-type="fig" rid="fig3">Figure 3A–D</xref> (qualitatively similar examples from CIP are shown in Figure 3 of <xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). Some neurons had similar 3D orientation tuning across all (<xref ref-type="fig" rid="fig3">Figure 3A</xref>) or most (<xref ref-type="fig" rid="fig3">Figure 3B</xref>) distances with distance-dependent gain changes, implying 3D pose tuning. Others had significant orientation tuning at a single distance (ANOVA, p&lt;0.05; Bonferroni–Holm corrected for four distances; <xref ref-type="fig" rid="fig3">Figure 3C</xref>), which may reflect intermediate selectivity for gradients of absolute binocular disparity (<xref ref-type="bibr" rid="bib45">Nguyenkim and DeAngelis, 2003</xref>). The orientation tuning of other neurons changed substantially with distance (<xref ref-type="fig" rid="fig3">Figure 3D</xref>), implying lower-level visual feature selectivity. These examples suggest that V3A contains a heterogeneous population of neurons whose functional properties range from processing low-level visual features to 3D object pose.</p><fig-group><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Comparison of 3D orientation tuning across distance.</title><p>(<bold>A–D</bold>) Four example visual area V3A (V3A) neurons from Monkey W (<bold>A, C</bold>) and Monkey F (<bold>B, D</bold>). Heat maps show firing rate plotted as a function of tilt (angular axis) and slant (radial axis). Red hues indicate higher firing rates. Black dots mark preferred 3D orientations from Bingham function fits at distances with significant tuning (ANOVA, p&lt;0.05; Bonferroni–Holm corrected for four distances). Some dots are not located on a disc because the largest tested slant was 60° but slant ranges from 0° to 90°. The preferred slant (S) and tilt (T) are indicated for each tuned distance. (<bold>E</bold>) Proportion of neurons with significant orientation tuning at each distance for V3A (orange; proportions: 37 cm = 0.57, 57 cm = 0.82, 97 cm = 0.57, 137 cm = 0.46) and caudal intraparietal (CIP) area (blue; proportions: 37 cm = 0.70, 57 cm = 0.87, 97 cm = 0.65, 137 cm = 0.55). (<bold>F</bold>) Proportion of neurons with significant orientation tuning at each possible number of distances for V3A (proportions: #0 = 0.11, #1 = 0.17, #2 = 0.22, #3 = 0.20, #4 = 0.30) and CIP (proportions: #0 = 0.06, #1 = 0.12, #2 = 0.23, #3 = 0.18, #4 = 0.41). (<bold>G</bold>) Comparison of surface orientation discrimination index (SODI) values at each distance for V3A (orange) and CIP (blue). Data points and error bars are mean and SEM across neurons with significant orientation tuning, respectively. The asterisk indicates a significant difference between V3A and CIP SODI values at 57 cm only (ANOVA followed by Tukey’s HSD test, p&lt;0.05).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78712-fig3-v2.tif"/></fig><fig id="fig3s1" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 1.</label><caption><title>Distributions of 3D orientation preferences.</title><p>Tilt and slant preferences in visual area V3A (V3A) (top row; 37 cm: N = 397 neurons; 57 cm: N = 570; 97 cm: N = 394; 137 cm: N = 317) and caudal intraparietal (CIP) area (bottom row; 37 cm: N = 304; 57 cm: N = 380; 97 cm: N = 283; 137 cm: N = 240) plotted using an equal area projection (<xref ref-type="bibr" rid="bib53">Rosenberg et al., 2013</xref>). Marginal histograms show the distributions of tilt and slant. Black triangles mark mean values.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78712-fig3-figsupp1-v2.tif"/></fig><fig id="fig3s2" position="float" specific-use="child-fig"><label>Figure 3—figure supplement 2.</label><caption><title>Cross-area comparison of 3D orientation tuning curve shape.</title><p>Three Bingham function parameters set the bandwidth (λ<sub>2</sub>), isotropy (λ<sub>1</sub>), and axis about which tuning anisotropy occurred (Φ). (<bold>A</bold>) Bandwidth (λ<sub>2</sub> ≥ 0). Larger values indicate narrower tuning. Fixed parameters in the schematic: λ<sub>1</sub> = 0, Φ = undefined since λ<sub>1</sub> = 0. (<bold>B</bold>) Distribution of λ<sub>2</sub> in visual area V3A (V3A) (orange bars) and caudal intraparietal (CIP) area (blue bars). (<bold>C</bold>) Isotropy (λ<sub>1</sub> ≤ 0). More negative values indicate greater anisotropy. Fixed parameters in the schematic: λ<sub>2</sub> = 0.7 and Φ = 90°. (<bold>D</bold>) Distributions of λ<sub>1</sub>. (<bold>E</bold>) Axis about which tuning anisotropy occurred (0° ≤ Φ &lt; 180°). Fixed parameters within the schematic: λ<sub>2</sub> = 0.7 and λ<sub>1</sub> = –1.5. (<bold>F</bold>) Distributions of Φ. Bars at 0° and 180° are identical. Distributions in (<bold>C</bold>, <bold>E</bold>, <bold>G</bold>) include all distances (V3A: N = 1,799; CIP: N = 1,276) and triangles mark median values. Asterisks in (<bold>B</bold>, <bold>D</bold>) mark significant cross-area differences (linear mixed-effects model with area and absolute distance from fixation as fixed effects and neuron as a random effect, p&lt;0.05 for main effect of area).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78712-fig3-figsupp2-v2.tif"/></fig></fig-group><p>In both areas, more neurons had 3D orientation tuning at 57 cm (fixation distance) than at the other distances (<xref ref-type="fig" rid="fig3">Figure 3E</xref>). Although the proportion of neurons with significant tuning at each distance was greater in CIP than V3A, the cross-area difference was not significant (chi-squared test, across animals: χ<sup>2</sup> = 2.4, p=0.50; Monkey L: χ<sup>2</sup> = 0.62, p=0.89; Monkey F: χ<sup>2</sup> = 1.6, p=0.67). However, CIP neurons were typically tuned for 3D orientation at more distances than V3A neurons (chi-squared test, across animals: χ<sup>2</sup> = 21.2, p=2.9 × 10<sup>–4</sup>; Monkey L: χ<sup>2</sup> = 13.0, p=0.01; Monkey F: χ<sup>2</sup> = 8.7, p=0.07), implying greater convergence of orientation information across distance within CIP than V3A (<xref ref-type="fig" rid="fig3">Figure 3F</xref>).</p><p>We next examined the 3D orientation preferences and tuning curve shapes by fitting each significant orientation tuning curve (ANOVA, p&lt;0.05; Bonferroni–Holm corrected for four distances) with a Bingham function (<xref ref-type="bibr" rid="bib5">Bingham, 1974</xref>). The Bingham function is a low-dimensional, parametric model over tilt and slant that describes V3A and CIP 3D orientation tuning curves (<xref ref-type="bibr" rid="bib53">Rosenberg et al., 2013</xref>; <xref ref-type="bibr" rid="bib54">Rosenberg and Angelaki, 2014a</xref>; <xref ref-type="bibr" rid="bib17">Elmore et al., 2019</xref>; <xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). The preferred orientation taken from these fits is marked with a black dot for the example neurons in <xref ref-type="fig" rid="fig3">Figure 3A–D</xref>. In both V3A and CIP, the full span of 3D orientations was represented at each distance (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>), indicating that both areas can support neural codes for 3D pose. To compare the shape of the orientation tuning curves, we used the Bingham parameters describing the bandwidth (λ<sub>2</sub>), isotropy (λ<sub>1</sub>), and axis about which any anisotropy occurred (Φ). First, there was a slight but significant tendency for V3A neurons (median λ<sub>2</sub> = 0.80) to be more narrowly tuned than CIP neurons (median λ<sub>2</sub> = 0.65; linear mixed-effects model with area, absolute distance from fixation, and animal as fixed effects, and neuron as a random effect, p=1.5 × 10<sup>–3</sup>; <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2A and B</xref>). This difference may reflect convergent input from multiple V3A neurons onto individual CIP neurons. The tuning bandwidths also increased with distance from fixation (p=6.5 × 10<sup>–6</sup>), implying information loss that mirrored the behavioral finding that tilt discrimination performance decreased with distance from fixation (<xref ref-type="bibr" rid="bib9">Chang et al., 2020a</xref>; <xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>; <xref ref-type="fig" rid="fig2">Figure 2</xref>, see Figure 5). No difference was observed across animals (p=0.77). Second, the V3A tuning curves were less isotropic (more elongated; median λ<sub>1</sub> = –1.62) than the CIP tuning curves (median λ<sub>1</sub> = – 0.92), and the difference was significant (p=1.3 × 10<sup>–9</sup>; <xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2C and D</xref>). The level of anisotropy also significantly increased with distance from fixation (p=9.4 × 10<sup>–6</sup>). No difference was observed across animals (p=0.78). Lastly, the distributions of Φ peaked at approximately 90° in both V3A (median Φ = 88°) and CIP (median Φ = 89°), indicating that any anisotropy in the tuning curves generally occurred along the tilt/slant axes (<xref ref-type="fig" rid="fig3s2">Figure 3—figure supplement 2E and F</xref>). These findings indicate greater orientation tuning symmetry in CIP than V3A, which may be important for perceptual sensitivity to changes in object orientation to not depend on the axis of rotation (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>).</p><p>A previous study found that 3D orientation was better discriminated based on the responses of individual V3A than CIP neurons (<xref ref-type="bibr" rid="bib17">Elmore et al., 2019</xref>). To follow up on that finding, we computed a surface orientation discrimination index (SODI) that quantifies the difference in responses to preferred and non-preferred orientations relative to the response variability (<xref ref-type="disp-formula" rid="equ2">Equation 2</xref>). Neurons with stronger 3D orientation selectivity have SODI values closer to one, whereas those with weaker selectivity have values closer to zero. For each neuron, we calculated the SODI at each distance with significant orientation tuning. In both areas, the mean SODI had an inverted U-shape as a function of distance that peaked at 57 cm (fixation distance; <xref ref-type="fig" rid="fig3">Figure 3G</xref>). This indicates that 3D orientation was most discriminable at the fixation distance, which may be a downstream consequence of V1 neurons tending to prefer smaller binocular disparities (<xref ref-type="bibr" rid="bib50">Prince et al., 2002</xref>). Consistent with the <xref ref-type="bibr" rid="bib17">Elmore et al., 2019</xref> study, which measured 3D orientation tuning at the fixation distance only, we found that the SODI values across animals were significantly larger in V3A than CIP at the fixation distance (ANOVA followed by Tukey’s HSD test, p=1.1 × 10<sup>–5</sup>). However, the differences were not significant at any other distance (p≥0.47). For Monkey L, the SODI values were significantly larger in V3A than CIP at 37, 57, and 97 cm (p≤8.5 × 10<sup>–3</sup>), but not 137 cm (p=0.95). For Monkey F, they were not significantly different at any distance (p≥0.52). Taken together with the <xref ref-type="bibr" rid="bib17">Elmore et al., 2019</xref> findings, these results are consistent with a cross-area difference that, as we consider next, may reflect a transformation from lower-level visual feature selectivity to higher-level 3D pose tuning.</p></sec><sec id="s2-3"><title>Hierarchical refinement of 3D pose representations</title><p>To test for cross-area differences in lower-level visual feature selectivity versus higher-level 3D pose tuning, we assessed how the 3D orientation tuning curves depended on distance (<xref ref-type="bibr" rid="bib33">Janssen et al., 2000</xref>; <xref ref-type="bibr" rid="bib45">Nguyenkim and DeAngelis, 2003</xref>; <xref ref-type="bibr" rid="bib1">Alizadeh et al., 2018</xref>). This approach recently revealed 3D pose tuning in CIP (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>) but has not been applied to V3A. It thus remains unknown if 3D pose tuning in CIP is simply inherited or reflects a qualitative transformation of feedforward input.</p><p>To quantify the distance-dependence of 3D orientation tuning curve shape, we fit each 3D pose tuning curve with a separable model (<xref ref-type="disp-formula" rid="equ3">Equation 3</xref>) and computed a tolerance index (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). Tolerance values near zero indicate that the shape of the orientation tuning curve changed substantially with distance (as expected for neurons selective for low-level visual features). Values near one indicate that the shape changed minimally with distance (implying 3D pose tuning). As shown for the example neurons, larger tolerance values were associated with 3D pose tuning (tolerance = 0.96, 0.74; <xref ref-type="fig" rid="fig3">Figure 3A and B</xref>, respectively), modest values with more intermediate representations (tolerance = 0.41; <xref ref-type="fig" rid="fig3">Figure 3C</xref>), and low values with low-level feature selectivity (tolerance = 0.17; <xref ref-type="fig" rid="fig3">Figure 3D</xref>). Across the V3A population, the tolerance values revealed a heterogeneous population in which neurons ranged from having low-level visual feature selectivity to high-level 3D pose tuning (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, orange bars).</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Robust 3D pose tuning was less prevalent in visual area V3A (V3A) than the caudal intraparietal (CIP) area.</title><p>(<bold>A</bold>) Distribution of tolerance values in V3A (orange; N = 692) and CIP (blue; N = 437). Triangles mark mean tolerance values, and the asterisk indicates a statistically significant difference (two-sample <italic>t</italic>-test, p&lt;0.05). (<bold>B</bold>) Cumulative density functions over the angular deviations between the orientation preference at each distance and the principal orientation for each neuron.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78712-fig4-v2.tif"/></fig><p>To test our hypothesis that 3D pose tuning would be more prevalent in CIP than V3A, we performed two complementary analyses. First, we evaluated if there was a cross-area difference in the extent to which the shape of the 3D orientation tuning curves depended on distance by comparing the tolerance distributions. In V3A, the mean tolerance was 0.57 ± 6.7 × 10<sup>–3</sup> SEM across animals (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, orange bars; N = 692). Individually, the mean tolerances in V3A were 0.56 ± 8.5 × 10<sup>–3</sup> (Monkey L, N = 311), 0.58 ± 0.01 (Monkey F, N = 263), and 0.55 ± 0.02 (Monkey W, N = 118). In CIP, the mean tolerance was 0.66 ± 7.7 × 10<sup>–3</sup> SEM across animals (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, blue bars; N = 437). Individually, the mean tolerances in CIP were 0.65 ± 0.01 (Monkey L, N = 218) and 0.66 ± 0.01 (Monkey F, N = 219). As predicted, the tolerance values in CIP were significantly larger than in V3A (two-sample <italic>t</italic>-test, across animals: p=7.4 × 10<sup>–19</sup>; Monkey L: p=4.7 × 10<sup>–11</sup>; Monkey F: p=3.7 × 10<sup>–7</sup>), indicating that the shape of 3D orientation tuning curves was more similar across distance in CIP than V3A. Second, we evaluated if there was a cross-area difference in the extent to which the orientation preferences (independent of other tuning parameters such as bandwidth) depended on distance. For each neuron, we calculated the angular deviation between the preferred orientation at each distance and the principal orientation (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>; ‘Materials and methods’). Across neurons, we then computed cumulative density functions over the angular deviations (<xref ref-type="fig" rid="fig4">Figure 4B</xref>) and found that the deviations were significantly greater in V3A than CIP (Kolmogorov–Smirnov test, across animals: p=1.2 × 10<sup>–9</sup>; Monkey L: p=5.1 × 10<sup>–6</sup>; Monkey F: p=5.9 × 10<sup>–4</sup>). Thus, although both areas represented the full span of 3D orientations at each distance (<xref ref-type="fig" rid="fig3s1">Figure 3—figure supplement 1</xref>), the orientation preferences of individual neurons were more similar across distance in CIP than V3A. These analyses together suggest that a transformation from lower-level visual features to higher-level 3D object representations occurs between V3A and CIP.</p></sec><sec id="s2-4"><title>Neuronal correlates of behavioral tilt sensitivity</title><p>We previously found that behavioral tilt sensitivity, which increases as a function of slant and has an inverted U-shape pattern as a function of distance from fixation (<xref ref-type="bibr" rid="bib9">Chang et al., 2020a</xref>; <xref ref-type="fig" rid="fig2">Figure 2C</xref> and black curves in <xref ref-type="fig" rid="fig5">Figure 5</xref>), is correlated with neuronal tilt discriminability in CIP (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). To test if a functional correlation between behavior and neuronal activity also exists for V3A, we calculated a tilt discrimination index (TDI; <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>) at each slant–distance combination for each neuron, following <xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>. Analogous to the SODI, the TDI quantifies the difference in responses to preferred and non-preferred tilts relative to the response variability. Notably, the mean TDI values in V3A followed the same trends as the behavioral sensitivity for slant (<xref ref-type="fig" rid="fig5">Figure 5A</xref>) and distance (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). Indeed, the behavioral tilt sensitivities and TDI values were highly correlated across all 16 slant–distance combinations (Monkey L: Spearman <italic>r</italic> = 0.92, p=2.2 × 10<sup>–308</sup>; Monkey F: <italic>r</italic> = 0.98, p=2.2 × 10<sup>–308</sup>; Monkey W: <italic>r</italic> = 0.74, p=1.5 × 10<sup>–3</sup>). Thus, neuronal tilt discriminability in both V3A and CIP was functionally correlated with the 3D tilt sensitivities of the monkeys across a wide range of viewing conditions.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Neuronal correlates of tilt sensitivity.</title><p>(<bold>A</bold>) Mean visual area V3A (V3A) tilt discrimination index (TDI) (gray) and behavioral tilt sensitivity (black) increased with slant. TDI values (and behavioral sensitivities) were averaged across neurons (or monkeys) and distances. (<bold>B</bold>) Mean V3A TDI and behavioral tilt sensitivity had an inverted U-shape relationship with distance. TDI values (behavioral sensitivities) were averaged across neurons (monkeys) and slants. Error bars are SEM.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78712-fig5-v2.tif"/></fig></sec><sec id="s2-5"><title>V3A carries choice-related activity during 3D orientation discrimination</title><p>Previous studies found that roughly half of CIP neurons carried choice-related activity during 3D orientation discrimination tasks (<xref ref-type="bibr" rid="bib17">Elmore et al., 2019</xref>; <xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). In contrast, one of those studies also reported that choice-related activity was essentially non-existent in V3A, but only tested 23 neurons (<xref ref-type="bibr" rid="bib17">Elmore et al., 2019</xref>). Given that choice-related activity is preferentially carried by CIP neurons with robust 3D pose tuning (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>), the dearth of V3A choice-related activity in the Elmore study could have occurred if the small sample mostly included neurons with low-level feature selectivity. Because that study was not designed to distinguish between low-level visual feature selectivity and 3D pose tuning, we wanted to reassess if V3A carries choice-related activity.</p><p>To dissociate choice-related and orientation-selective activity, we analyzed responses to frontoparallel planes (S = 0° and tilt undefined, making them task ambiguous) only. To remove any distance-related response differences, we z-scored the responses at each distance and then pooled across distance. The responses were then grouped according to the monkey’s reported tilt. We first computed eight population-level time courses aligned to the tilt choice that elicited the maximum response for each neuron (<xref ref-type="fig" rid="fig6">Figure 6A</xref>). Following an initial transient response, the eight time courses began to separate and showed parametric tuning with amplitudes that symmetrically fell off from the preferred choice (note the similarity of the ±45°, ±90°, and ±135° time courses), thus revealing choice-related activity in V3A. The onset of choice-related activity was defined as the first time point that the eight time courses significantly diverged (191 ms; ANOVA, p&lt;0.05). In contrast, the onset of choice-related activity in CIP was 202 ms (see Figure 5A in <xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). The finding that choice-related activity appeared first in V3A may reflect that choice signals in CIP contain a large bottom-up contribution from V3A.</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Choice tuning in visual area V3A (V3A) and its relationship to tilt tuning.</title><p>(<bold>A</bold>) Population time courses for each choice option relative to the preferred choice. Curves show z-scored responses averaged over neurons. Stimulus onset = 0 ms. Vertical dashed lines mark the median visual response latency (46 ms) and the onset of choice-related activity (191 ms). (<bold>B</bold>) Comparison of noise and signal correlations in V3A (orange; N = 404 pairs) and the caudal intraparietal (CIP) area (blue; N = 244 pairs). Solid lines show type II linear regression fits. Marginal histograms show the distributions of noise (right) and signal (top) correlations. Triangles mark mean values. Inset shows proportion of neurons with choice-related activity in V3A (25%) and CIP (46%). (<bold>C–F</bold>) Choice tuning curves (left axis, purple) and tilt tuning curves marginalized over slant and distance (right axis, black) for the four example V3A neurons from <xref ref-type="fig" rid="fig3">Figure 3</xref>. Data points show mean firing rate, and error bars are SEM. Solid purple curves are von Mises fits for neurons with significant choice tuning (ANOVA, p&lt;0.05). Black lines are linear interpolations. (<bold>G</bold>) Comparison of preferred surface tilt and choice preferences in V3A (left, N = 168) and CIP (right, N = 194). The peaks near 0° indicate that the preferences generally aligned. Bars at ±180° are identical.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78712-fig6-v2.tif"/></fig><p>Across the populations, 172 (25%) V3A and 201 (46%) CIP neurons carried significant choice-related activity (ANOVA, p&lt;0.05; <xref ref-type="fig" rid="fig6">Figure 6B</xref>, inset bar plot). The proportion of neurons with choice-related activity varied across monkeys but was always more prevalent in CIP (Monkey L: N = 72, 33%; Monkey F: N = 129, 59%) than V3A (Monkey L: N = 23, 7%; Monkey F: N = 127, 48%; Monkey W: N = 22, 19%). To test if the strength of choice-related activity differed between the areas, we computed a choice discrimination index (CDI; <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>) for each neuron with significant choice tuning (Appendix 1 shows that this index is unaffected by z-scoring, which was used in calculating the choice tuning curves). The CDI values were highly similar in V3A (mean CDI = 0.38 ± 5.6 × 10<sup>–3</sup> SEM, N = 172) and CIP (mean CDI = 0.38 ± 5.7 × 10<sup>–3</sup> SEM, N = 201) and not significantly different (Wilcoxon rank-sum test, p=0.20). Thus, although there was a cross-area difference in the prevalence of choice-related activity, it was nevertheless present in V3A and similar in strength to CIP.</p><p>One potential reason that choice-related activity was more prevalent in CIP than V3A is a difference in the structure of correlated variability between the areas (<xref ref-type="bibr" rid="bib46">Nienborg and Cumming, 2006</xref>). To test this, we computed noise and signal correlations using the 3D pose data for pairs of neurons simultaneously recorded on the same tetrode (‘Materials and methods’). The noise correlations were almost identical in V3A (across animals: mean <italic>r</italic> = 0.17 ± 0.01 SEM, N = 404 pairs; Monkey L: 0.15 ± 0.01, N = 206; Monkey F: 0.15 ± 0.03, N = 121; Monkey W: 0.25 ± 0.03, N = 77) and CIP (across animals: 0.17 ± 0.01, N = 244 pairs; Monkey L: 0.14 ± 0.02, N = 107; Monkey F: 0.19 ± 0.02, N = 137), and not significantly different (Wilcoxon rank-sum test, across animals: p=0.62; Monkey L: p=0.58; Monkey F: p=0.49; <xref ref-type="fig" rid="fig6">Figure 6B</xref>, right marginal histogram). However, noise correlations alone are not sufficient to account for differences in choice-related activity. Instead, the relationship between noise and signal correlations matters (<xref ref-type="bibr" rid="bib40">Liu et al., 2013</xref>; <xref ref-type="bibr" rid="bib13">Cumming and Nienborg, 2016</xref>). We therefore quantified the signal correlations for the same pairs of neurons and found that they were also similar in V3A (across animals: mean <italic>r</italic> = 0.40 ± 0.02 SEM; Monkey L: 0.32 ± 0.03; Monkey F: 0.41 ± 0.04; Monkey W: 0.61 ± 0.04) and CIP (across animals: 0.36 ± 0.03; Monkey L: 0.26 ± 0.04; Monkey F: 0.43 ± 0.03), and not significantly different (across animals: p=0.15; Monkey L: p=0.32; Monkey F: p=0.86; <xref ref-type="fig" rid="fig6">Figure 6B</xref>, top marginal histogram). We then compared the relationship between noise and signal correlations (<xref ref-type="fig" rid="fig6">Figure 6B</xref>). As expected, higher noise correlations were associated with higher signal correlations (<xref ref-type="bibr" rid="bib60">Shadlen et al., 1996</xref>; <xref ref-type="bibr" rid="bib12">Cohen and Maunsell, 2009</xref>; <xref ref-type="bibr" rid="bib24">Gu et al., 2011</xref>). Importantly, the linear relationship between noise and signal correlation was not significantly different between the areas (ANCOVA, across animals: p=0.37; Monkey L: p=0.06; Monkey F: p=0.30). Furthermore, between pairs of neurons within each area in which (i) both had choice-related activity, (ii) neither had choice-related activity, or (iii) one had but the other did not have choice-related activity, we found no significant differences in the magnitudes of noise (Kruskal–Wallis test, both p≥0.15) and signal (both p≥0.19) correlations or their linear relationship (ANCOVA, both p≥0.23). These results suggest that differences in the structure of correlated variability either within or across areas did not account for the presence of choice-related activity. As such, the cross-area difference in prevalence of choice-related activity was consistent with a stronger functional correlation between neuronal activity and 3D perceptual decisions in CIP than V3A.</p><p>Choice tuning curves are shown for the four example V3A neurons from <xref ref-type="fig" rid="fig3">Figure 3</xref> in <xref ref-type="fig" rid="fig6">Figure 6C–F</xref>. The two neurons with higher tolerances (<xref ref-type="fig" rid="fig3">Figure 3A and B</xref>) both carried choice-related activity (<xref ref-type="fig" rid="fig6">Figure 6C and D</xref>, purple curves). Notably, the tilt tuning curves (marginalized over slant and distance; <xref ref-type="fig" rid="fig6">Figure 6C and D</xref>, black curves) were well aligned with the choice tuning curves. In contrast, the neurons with intermediate and low tolerances (<xref ref-type="fig" rid="fig3">Figure 3C and D</xref>) did not carry choice-related activity (<xref ref-type="fig" rid="fig6">Figure 6E and F</xref>, purple points). To quantify the relationship between tilt and choice preferences for neurons with significant orientation and choice tuning, we took the circular difference between each neuron’s preferred tilt (from the principal orientation) and preferred tilt choice (from the von Mises fit). In both areas, the median circular difference between the preferences (V3A: 1.57°, N = 168; CIP: –0.75°, N = 194) was not significantly different from 0° (circular median test, both p≥0.49), indicating that the tilt and choice preferences tended to align (<xref ref-type="fig" rid="fig6">Figure 6G</xref>). To assess if the relationship between tilt and choice preferences differed between the areas, we compared the widths of the two distributions and found that they had similar circular variance (CV) values (V3A: CV = 0.34; CIP: CV = 0.33), which were not significantly different (two-sample concentration difference test, p=0.88) (<xref ref-type="bibr" rid="bib19">Fisher, 1995</xref>). Thus, the strength of the association between tilt and choice preferences was similar in V3A and CIP.</p></sec><sec id="s2-6"><title>Choice-related activity was associated with robust 3D tuning</title><p>We previously found that CIP neurons with more robust 3D pose tuning (higher tolerance values) preferentially carried choice-related activity (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). To assess this relationship in V3A, we compared the tolerance values of V3A neurons with and without choice-related activity (<xref ref-type="fig" rid="fig7">Figure 7A</xref>). Indeed, V3A neurons with choice-related activity had a mean tolerance of 0.65 ± 1.3 × 10<sup>–2</sup> SEM (N = 172), whereas those without choice-related activity had a mean tolerance of 0.54 ± 7.2 × 10<sup>–3</sup> SEM (N = 520), and the difference was significant (ANOVA followed by Tukey’s HSD test, p=3.8 × 10<sup>–9</sup>). Thus, choice-related activity was preferentially carried by V3A neurons with more robust 3D pose tuning, as in CIP.</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Robust 3D pose tuning was associated with choice-related activity.</title><p>(<bold>A</bold>) Distribution of tolerance values for visual area V3A (V3A) neurons with (orange bars, N = 172) and without (gray bars, N = 520) choice-related activity. Triangles mark mean tolerances. (<bold>B</bold>) Cross-area comparison of tolerance values for neurons with (colored bars) and without (gray bars) choice-related activity. The V3A data in (<bold>A</bold>) is reproduced in (<bold>B</bold>) for comparison with the caudal intraparietal (CIP) area. Bar height indicates mean tolerance, and error bars are SEM. Horizontal lines and asterisks indicate significant differences in (<bold>A, B</bold>) (ANOVA followed by Tukey’s HSD test, p&lt;0.05). (<bold>C</bold>) Cumulative density functions over the angular deviations between the orientation preference at each distance and the principal orientation for neurons with (solid lines) and without (dashed lines) choice-related activity.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78712-fig7-v2.tif"/></fig><p>Because more robust 3D pose tuning was associated with choice-related activity, we were concerned that the difference in 3D selectivity between V3A and CIP (<xref ref-type="fig" rid="fig4">Figure 4</xref>) simply reflected a cross-area difference in the prevalence of choice signals. However, this was not the case. First, tolerance values were greater in CIP than V3A both for neurons with (ANOVA followed by Tukey’s HSD test, p=1.7 × 10<sup>–7</sup>) and without (p=1.6 × 10<sup>–4</sup>) choice-related activity (<xref ref-type="fig" rid="fig7">Figure 7B</xref>). Second, comparisons of the cumulative density functions over the angular deviations between orientation preferences at each distance and the principal orientation (<xref ref-type="fig" rid="fig7">Figure 7C</xref>) revealed significantly smaller deviations for neurons with than without choice-related activity in both areas (Kolmogorov–Smirnov test, p≤1.1 × 10<sup>–5</sup>). The deviations were also significantly smaller in CIP than V3A both for neurons with (p=1.3 × 10<sup>–4</sup>) and without (p=8.8 × 10<sup>–4</sup>) choice-related activity. Thus, 3D pose tuning was more robust in CIP than V3A, regardless of whether the neurons carried choice-related activity.</p></sec><sec id="s2-7"><title>V3A carries saccade-related activity</title><p>Previous studies reported that V3A contains extraretinal signals associated with creating stable, allocentric representations of the world (<xref ref-type="bibr" rid="bib20">Galletti and Battaglini, 1989</xref>; <xref ref-type="bibr" rid="bib21">Galletti et al., 1990</xref>; <xref ref-type="bibr" rid="bib58">Sauvan and Peterhans, 1999</xref>; <xref ref-type="bibr" rid="bib43">Nakamura and Colby, 2002</xref>), as well as postsaccadic activity (<xref ref-type="bibr" rid="bib42">Nakamura and Colby, 2000</xref>). Recently, we discovered saccade-related activity in CIP that predicted the direction and timing of eye movements (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). We therefore hypothesized that V3A may possess similar saccade-related activity. To test this possibility, we trained the monkeys to perform a visually guided (pop-up) saccade task (<xref ref-type="bibr" rid="bib41">Munoz and Wurtz, 1995</xref>; <xref ref-type="bibr" rid="bib27">Hanes and Schall, 1996</xref>; <xref ref-type="fig" rid="fig8">Figure 8A</xref>).</p><fig-group><fig id="fig8" position="float"><label>Figure 8.</label><caption><title>Saccade-related activity in visual area V3A (V3A).</title><p>(<bold>A</bold>) Visually guided (pop-up) saccade task. A target was fixated for 1.3 s (matching the tilt discrimination task duration; left) after which it disappeared and a single saccade target appeared at one of eight locations (matching the choice targets in the tilt discrimination task; right). A saccade was then made to the target. (<bold>B</bold>) Population time courses for each saccade direction relative to the preferred direction. Curves show responses averaged over neurons. Saccade initiation = 0 ms. Vertical dashed line marks the start of saccade-related activity (–108 ms). (<bold>C</bold>) Histogram of saccade latencies divided into quartiles (Q). Triangles mark mean values (black for the full distribution). (<bold>D</bold>) Time courses of saccade-related activity conditioned on the saccade latency quartile. Colored circles mark the start of V3A activity for each quartile (ANOVA, p&lt;0.05). Open black circle marks the point at which the V3A curves approximately coalesced. (<bold>E</bold>) Inverse linear relationship between the growth rate (GR) of saccade-related activity and mean saccade latency (SL) for each quartile. (<bold>F</bold>) The temporally integrated V3A time courses for each quartile (dashed curves) were well-aligned to the observed caudal intraparietal (CIP) area time courses (solid curves). Circles mark the start of CIP activity for each quartile and the point at which the curves approximately coalesced.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78712-fig8-v2.tif"/></fig><fig id="fig8s1" position="float" specific-use="child-fig"><label>Figure 8—figure supplement 1.</label><caption><title>Comparison of saccade-related activity and responses to visual flashes without eye movements.</title><p>(<bold>A</bold>) Screen schematic. Filled red and black circles show the fixation and choice/saccade targets, respectively. Dashed black circle shows the envelope of the planar stimuli. Squares show the tessellation for receptive field (RF) mapping in caudal intraparietal (CIP) area. Filled green squares are locations included in the analysis shown in (<bold>B</bold>). In visual area V3A (V3A), the mapped area was matched to the RFs (not shown). All elements are drawn to scale. (<bold>B</bold>) The saccade-related activity and responses to visual flashes had distinct time courses. The curves are population-averaged responses to the preferred saccade directions (solid curves) and visual flashes at nearby RF mapping tiles (bright flashes only; dashed curves). For V3A, 390/415 neurons with saccade-related activity were included. The others were removed because the preferred saccade target was outside of where the visual RF was mapped. For CIP, all 274 neurons with saccade-related activity were included. Visual flashes were 150 ms in duration. Saccade targets were present until the eyes entered the saccade target window (triangles mark median saccade onset times). Despite the visual flashes being of higher contrast (Weber contrast = 2.2) and larger (1.9° × 1.9° in V3A, 3.9° × 3.9° in CIP) than the saccade targets (Weber contrast = 1.0; 0.7° diameter), the flash responses were weaker and more transient than the saccade-related activity. The saccade-related activity also had conspicuous inflection points at 71 ms in V3A and 78 ms in CIP (marked by open black circles; calculated by finding when the second derivative equaled zero), which speculatively reflect the addition of presaccadic activity to an otherwise visual transient.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78712-fig8-figsupp1-v2.tif"/></fig></fig-group><p>To first determine if V3A carries saccade-related activity, we computed eight population-level time courses relative to the saccade direction that elicited the maximum response for each neuron (<xref ref-type="fig" rid="fig8">Figure 8</xref>). Noting that the time courses were parametrically tuned, we calculated the start of the activity by finding the first time point at which they significantly diverged (ANOVA, p&lt;0.05). Intriguingly, saccade-related activity started in V3A (a classically defined ‘intermediate’ visual area) 108 ms prior to saccade initiation, which was earlier than in CIP (102 ms; see Figure 8B in <xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). In both areas, the time course of saccade-related activity was distinct from the visually evoked response measured during receptive field mapping, consistent with presaccadic activity (<xref ref-type="fig" rid="fig8s1">Figure 8—figure supplement 1</xref>; see ‘Discussion’).</p><p>The finding of saccade-related activity in V3A prompted us to test if that activity predicted the timing of the saccades. Each trial in which a saccade was made in the preferred saccade direction was labeled with the saccade latency (the time from target appearance to saccade initiation). The distribution of latencies was then divided into quartiles (<xref ref-type="fig" rid="fig8">Figure 8C</xref>) and the time course of saccade-related activity computed for each quartile (<xref ref-type="fig" rid="fig8">Figure 8D</xref>). On trials that the saccade latency was shorter, saccade-related activity started closer to the saccade initiation. Indeed, the growth rate (linear slope) from the start of saccade-related activity (ANOVA, p&lt;0.05) to when the four curves approximately coalesced (59 ms before saccade initiation; ‘Materials and methods’) was highly correlated and inversely related to the mean saccade latency (<italic>r</italic> = –0.98, p=1.9 × 10<sup>–2</sup>; <xref ref-type="fig" rid="fig8">Figure 8E</xref>). Intriguingly, these results indicate that V3A activity predicts the direction and timing of upcoming saccadic eye movements.</p><p>We further noted that the V3A time courses were visually more similar to step functions than the CIP time courses, which more closely resembled ramping activity. This informal observation was reflected in steeper growth rates for each quartile in V3A (Q1 = 1.8; Q2 = 1.1; Q3 = 0.82; Q4 = 0.44) than CIP (Q1 = 0.73; Q2 = 0.61; Q3 = 0.56; Q4 = 0.39) and led us to speculate that CIP might temporally integrate saccade-related signals from V3A. For each latency quartile, we therefore integrated the V3A time courses from the onset of V3A activity to when the CIP time courses approximately coalesced (15 ms before saccade initiation; ‘Materials and methods’; <xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>) and compared them to the observed CIP time courses. Notably, the integrated V3A output (<xref ref-type="fig" rid="fig8">Figure 8F</xref>, dashed curves) aligned well with the CIP activity (solid curves) for each quartile, as might be expected if CIP accumulates evidence from V3A in favor of particular oculomotor responses. Consistent with CIP being closer to the site of saccade initiation than V3A, the CIP time courses coalesced 15 ms before saccade initiation compared to 59 ms in V3A. These results imply that V3A is not simply a ‘visual area’ and may suggest that there are parallel visual and saccade-related V3A-to-CIP hierarchies.</p><p>We next examined the saccade direction tuning of individual V3A neurons. Saccade direction tuning curves for the four example V3A neurons are shown in <xref ref-type="fig" rid="fig9">Figure 9A–D</xref> (green curves) along with von Mises fits for those with significant tuning (ANOVA, p&lt;0.05). Across animals, 415 (60%) of the V3A neurons had significant saccade direction tuning (Monkey L: 172, 55%; Monkey F: 154, 58%; Monkey W: 89, 75%), similar to that observed in CIP (across animals: 274, 63%; Monkey L: 153, 70%; Monkey F: 121, 55%) (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). Like CIP neurons, the V3A neurons showed parametric tuning for saccade direction with responses that fell off symmetrically from the preferred direction. Correspondingly, the tuning curves were well described by von Mises functions (mean <italic>r</italic> = 0.92 ± 0.47 × 10<sup>–3</sup> SEM, N = 415).</p><fig-group><fig id="fig9" position="float"><label>Figure 9.</label><caption><title>Sensorimotor associations were moderated by choice-related activity.</title><p>(<bold>A–D</bold>) Saccade direction tuning curves (left axis, green) and tilt tuning curves marginalized over slant and distance (right axis, black) for the four example visual area V3A (V3A) neurons from <xref ref-type="fig" rid="fig3">Figures 3</xref> and <xref ref-type="fig" rid="fig6">6</xref>. Data points are mean firing rates and error bars are SEM across trials. Solid green curves are von Mises fits for neurons with significant saccade direction tuning (ANOVA, p&lt;0.05). Black lines are linear interpolations. (<bold>E</bold>) Differences between choice and saccade direction preferences in V3A (N = 124). (<bold>F</bold>) Differences between principal surface tilts and saccade direction preferences for neurons with (colored bars) and without (gray bars) choice-related activity in V3A (left) and caudal intraparietal (CIP) area (right). Bars at ±180° are identical in (<bold>E, F</bold>). (<bold>G</bold>) Comparison of circular variances for the distributions in (<bold>F</bold>). Horizontal lines and asterisks indicate significant differences (two-sample concentration difference test, p&lt;0.05).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78712-fig9-v2.tif"/></fig><fig id="fig9s1" position="float" specific-use="child-fig"><label>Figure 9—figure supplement 1.</label><caption><title>Saccade-related activity was associated with less robust 3D tuning in visual area V3A (V3A), but not caudal intraparietal (CIP) area.</title><p>Tolerance values were compared for neurons with and without saccade-related activity, condition on the presence of choice-related activity in V3A and CIP. Four neuronal subpopulations were defined: those with (1) choice- and saccade-related activity (C+S + , V3A: N = 124; CIP: N = 137), (2) choice- but not saccade-related activity (C+S-, V3A: N = 48; CIP: N = 64), (3) no choice- but saccade-related activity (C-S+, V3A: N = 291; CIP: N = 137), and (4) neither choice- nor saccade-related activity (C-S-, V3A: N = 229; CIP: N = 99). First, we compared neurons with choice-related activity (C+S + and C+S-). Tolerance values were significantly lower for C+S+ than C+S- neurons in V3A (p=6.9 × 10<sup>-3</sup>) but not CIP (p=0.23). Second, we compared neurons without choice-related activity (C-S+ and C-S-). Tolerance values were significantly lower for C-S+ than C-S- neurons in V3A (p=1.9 × 10<sup>-3</sup>) but not CIP (p=0.94). Thus, saccade-related activity was associated with less robust 3D tuning in V3A. There was no significant relationship between saccade-related activity and the robustness of 3D tuning in CIP. Horizontal lines and asterisks indicate significant differences (ANOVA followed by Tukey’s HSD test, p&lt;0.05).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-78712-fig9-figsupp1-v2.tif"/></fig></fig-group><p>To test for cross-area differences in saccade direction tuning, we first calculated a saccade discrimination index (SDI; <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>) for neurons with significant tuning. Surprisingly, saccade direction was more discriminable based on V3A (across animals: mean SDI = 0.49 ± 6.2 × 10<sup>–3</sup> SEM, N = 415; Monkey L: 0.48 ± 0.02, N = 172; Monkey F: 0.51 ± 9.3 × 10<sup>–3</sup>, N = 154; Monkey W: 0.48 ± 0.01, N = 89) than CIP (across animals: 0.41 ± 6.2 × 10<sup>–3</sup>, N = 274; Monkey L: 0.40 ± 8.7 × 10<sup>–3</sup>, N = 153; Monkey F: 0.42 ± 8.7 × 10<sup>–3</sup>, N = 121) responses, and the difference was statistically significant (Wilcoxon rank-sum test, across animals: p=4.8 × 10<sup>–17</sup>; Monkey L: p=5.1 × 10<sup>–8</sup>; Monkey F: p=2.6 × 10<sup>–11</sup>). We further compared the tuning bandwidths (<inline-formula><mml:math id="inf3"><mml:mi>κ</mml:mi></mml:math></inline-formula> from the von Mises fits) and found that the V3A tuning curves were narrower (across animals: mean  <inline-formula><mml:math id="inf4"><mml:mi>κ</mml:mi></mml:math></inline-formula> = 6.3 ± 0.26 SEM; Monkey L: 6.1 ± 0.45; Monkey F: 6.6 ± 0.40; Monkey W: 6.2 ± 0.53) than the CIP tuning curves (across animals: 4.7 ± 0.29; Monkey L: 4.4 ± 0.38; Monkey F: 5.0 ± 0.46), and the difference was statistically significant (Wilcoxon rank-sum test, across animals: p=1.9 × 10<sup>–7</sup>; Monkey L: p=0.01; Monkey F: p=8.4 × 10<sup>–5</sup>). These results are consistent with convergent input from multiple V3A neurons onto individual CIP neurons and parallel the cross-area difference in 3D orientation tuning.</p><p>We additionally assessed if choice- and saccade-related activity were functionally dissociable in V3A as they are in CIP (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). Across the V3A population, 124 neurons (18%) had both choice- and saccade-related activity. For this subpopulation, choice and saccade preferences generally aligned (<xref ref-type="fig" rid="fig9">Figure 9E</xref>). The median circular difference (–1.7°) between the preferences was not significantly different from 0° (circular median test, p=0.65). Although the preferences aligned, other characteristics were distinct. First, the saccade tuning curves were narrower (mean  <inline-formula><mml:math id="inf5"><mml:mi>κ</mml:mi></mml:math></inline-formula> = 6.3 ± 0.26 SEM) than the choice tuning curves (mean  <inline-formula><mml:math id="inf6"><mml:mi>κ</mml:mi></mml:math></inline-formula> = 4.7 ± 0.46 SEM), and the difference was significant (Wilcoxon rank-sum test, p=6.4 × 10<sup>–11</sup>). Second, some neurons carried choice- (48, 7%) or saccade-related (291, 42%) activity only, indicating that the properties were not mutually inclusive. Third, choice-related activity was associated with more robust 3D tuning, whereas saccade-related activity was associated with less robust 3D tuning (<xref ref-type="fig" rid="fig9s1">Figure 9—figure supplement 1</xref>), indicating that choice and saccade signals had opposite functional relationships with 3D selectivity in V3A. These results together suggest that the choice- and saccade-related activities were functionally distinct.</p></sec><sec id="s2-8"><title>Sensorimotor associations are moderated by choice-related activity</title><p>Neurons in CIP form associations between their surface orientation and choice/saccade direction preferences such that the alignment of the tuning curves reflects whether the monkey was trained to report the near or far side of the plane (<xref ref-type="bibr" rid="bib17">Elmore et al., 2019</xref>; <xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). However, the existence of a similar sensorimotor association was not immediately evident based on the saccade direction and tilt tuning curves (marginalized over slant and distance) of the example V3A neurons (<xref ref-type="fig" rid="fig9">Figure 9A–D</xref>). Assuming that decision-related processing occupies an intermediate position between sensory and motor activity, it is possible that choice signals have a moderating effect on the sensorimotor association that could obscure the relationship if not taken into consideration. Indeed, we previously found that the strength of the sensorimotor association in CIP depended on the presence of choice signals (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>).</p><p>To test for sensorimotor associations in V3A and evaluate the potential moderating effect of choice signals, we therefore calculated the angular difference between the principal tilt (from the principal orientation) and saccade direction preference for neurons with and without choice-related activity (<xref ref-type="fig" rid="fig9">Figure 9F</xref>, left, orange and gray bars, respectively). For neurons without choice-related activity, there was no discernible association between the tilt and saccade direction preferences since the distribution was not significantly different from uniform (Rayleigh test, p=0.08, N = 270). However, for neurons with choice-related activity, the distribution was significantly different from uniform (p=1.2 × 10<sup>–18</sup>, N = 122) and the median circular difference (–1.6°) was not significantly different from 0° (circular median test, p=0.42), revealing a sensorimotor association. Correspondingly, the distribution of preference differences was significantly narrower for neurons with (CV = 0.44) than without (CV = 0.9) choice-related activity (two-sample concentration difference test, p=1.4 × 10<sup>–5</sup>; <xref ref-type="fig" rid="fig9">Figure 9G</xref>). Thus, a sensorimotor association was only evident for V3A neurons with choice-related activity.</p><p>When we repeated this analysis for CIP, we found a striking difference from V3A (<xref ref-type="fig" rid="fig9">Figure 9F</xref>, right). Specifically, sensorimotor associations were evident regardless of whether the neurons carried choice signals. The distributions of preference differences were significantly different from uniform both for neurons with (blue bars; p=3.7 × 10<sup>–29</sup>, N = 134) and without (gray bars; p=9.7 × 10<sup>–5</sup>, N = 122) choice-related activity. Likewise, the median differences were not significantly different from 0° both for neurons with (–4.2°, p=0.14) and without (–3.2°, p=0.65) choice-related activity. This reveals that choice signals were not necessary for sensorimotor associations in CIP, but the distribution was significantly narrower for neurons with (CV = 0.34) than without (CV = 0.73) choice-related activity (two-sample concentration difference test, p=2.6 × 10<sup>–5</sup>; <xref ref-type="fig" rid="fig9">Figure 9G</xref>), indicating that sensorimotor associations were strongest for neurons with choice-related activity.</p><p>We further assessed the cross-area difference in the overall strength of sensorimotor associations by comparing the widths of the V3A and CIP preference difference distributions (including neurons with and without choice-related activity). The distribution was significantly broader in V3A (CV = 0.77) than CIP (CV = 0.53; p=1.2 × 10<sup>–3</sup>), indicating that sensorimotor associations were strongest in CIP (<xref ref-type="fig" rid="fig9">Figure 9G</xref>). These results thus imply a hierarchical transformation in the strength of sensorimotor associations along the ‘where’ pathway and suggest a novel role for choice-related activity in sensorimotor processing as explored next.</p><p>The above analyses showed that neurons with choice-related activity exhibited more robust 3D pose tuning (<xref ref-type="fig" rid="fig7">Figure 7</xref>) and formed stronger sensorimotor associations (<xref ref-type="fig" rid="fig9">Figure 9G</xref>). If choice signals occupy an intermediate position between sensory and motor processing, the strength of sensorimotor associations might depend on the robustness of 3D tuning for neurons with choice-related activity but not those without choice-related activity. In other words, choice-related activity may statistically moderate (<xref ref-type="bibr" rid="bib34">Judd et al., 2014</xref>) the relationship between the robustness of 3D pose tuning and the strength of sensorimotor associations. To test this, we ran a linear regression model where the absolute angular difference between the principal tilt and saccade direction preference depended on tolerance, choice-related activity, and their interaction. Both areas showed a significant interaction (both p≤1.6 × 10<sup>–3</sup>) such that tolerance had a negligible impact on the strength of the sensorimotor association for neurons without choice-related activity (V3A: slope = 0.16; CIP: slope = –0.15) but a strong impact for neurons with choice-related activity (V3A: slope = –2.2; CIP: slope = –2.5). Thus, this analysis revealed an intricate relationship between sensory, choice, and saccade-related activity in which choice signals moderated the relationship between the robustness of 3D tuning and sensorimotor associations.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Transforming ambiguous 2D retinal images into relevant 3D object representations that can guide action is a fundamental function of the dorsal ‘where’ pathway. Here, we explicated the parallel processing, hierarchical transformations, and functional associations of visual, choice, and saccade-related signals at the juncture of visual and parietal cortex. Our findings challenge classical notions of sensorimotor dichotomies by revealing that V3A possesses saccade-related activity and defining properties of association cortex, and further implicate choice-related activity as a novel factor in moderating sensorimotor processing.</p><sec id="s3-1"><title>Parallel processing, hierarchical transformations, and sensorimotor associations</title><p>Multiple lines of evidence converged to support a V3A-to-CIP hierarchy. Focusing first on the visual properties, we found that the median visual response latency in V3A was 6 ms shorter than in CIP and that the receptive fields were smaller in V3A than CIP. At a functional level, 3D orientation and position information (which are confounded in retinal images) were more separable in CIP than V3A, implying a hierarchical resolution of sensory ambiguities that limit the ability to make 3D perceptual inferences.</p><p>Intriguingly, our findings may also reveal a V3A-to-CIP hierarchy related to oculomotor processing. While saccade-related activity that predicted the direction and timing of eye movements was prevalent in both areas, it began 6 ms earlier in V3A than CIP (in agreement with the difference in visual response latencies). The finding that the time course of saccade-related activity in CIP closely resembled the temporally integrated V3A output may further suggest that some presaccadic signals originate in a region of visual cortex whose feedforward input includes V1 and V2 (<xref ref-type="bibr" rid="bib71">Zeki, 1980</xref>; <xref ref-type="bibr" rid="bib18">Felleman and Van Essen, 1991</xref>), thus challenging classical notions of sensorimotor dichotomies. This finding is also consistent with CIP accumulating evidence provided by V3A in favor of particular oculomotor responses, which raises the possibility that some of the integration-like properties of LIP (<xref ref-type="bibr" rid="bib61">Shadlen and Newsome, 1996</xref>; <xref ref-type="bibr" rid="bib52">Roitman and Shadlen, 2002</xref>) may reflect bottom-up input (<xref ref-type="bibr" rid="bib39">Lewis and Van Essen, 2000</xref>; <xref ref-type="bibr" rid="bib49">Premereur et al., 2015</xref>; <xref ref-type="bibr" rid="bib69">Van Dromme et al., 2016</xref>). In that case, inactivating CIP, which is architectonically distinct from LIP (<xref ref-type="bibr" rid="bib35">Katsuyama et al., 2010</xref>; <xref ref-type="bibr" rid="bib47">Niu et al., 2020</xref>), might impair saccadic responses during decision-making tasks. Consistent with this, reversible inactivation of CIP during a depth structure categorization task was found to delay saccadic responses (<xref ref-type="bibr" rid="bib69">Van Dromme et al., 2016</xref>). While that delay may have reflected degraded visual discrimination, the current findings also point to the possibility of impaired saccade preparation.</p><p>While these experiments revealed saccade-related activity in V3A and CIP, the protocol was not designed to dissociate the potential contributions of visual and presaccadic signals. Nevertheless, several lines of evidence suggest that the observed saccade-related activity cannot be explained by visual responses alone. First, the time course of saccade-related activity was distinct from that of the visual flash response. Examination of the time courses provided some evidence that a presaccadic signal may begin in V3A 7 ms before CIP, consistent with the possibility of a V3A-to-CIP oculomotor hierarchy. Second, there was a pronounced relationship between the growth rate of the saccade-related activity and saccade latency. Third, there was an apparent integrative relationship between the V3A and CIP saccade-related activity, which does not exist for the visual responses. Fourth, the sensorimotor association between tilt and saccade direction preferences as well as the moderation by choice-related activity would not be expected for visual flash responses. The current findings therefore suggest that V3A and CIP may contain presaccadic signals, but a thorough evaluation of this possibility will require future studies.</p><p>Many V3A neurons showed functional associations between their orientation, choice, and saccade direction preferences, as in CIP (<xref ref-type="bibr" rid="bib17">Elmore et al., 2019</xref>; <xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). Finding these associations in V3A implies that sensorimotor processing traditionally linked to parietal cortex already occurs in an ‘intermediate visual area,’ suggesting that V3A may be more appropriately classified as an early association region. Intriguingly, saccade direction discrimination was greater in V3A (where saccade-related activity was associated with poorer 3D pose tuning) while sensorimotor associations were stronger in CIP (where no relationship between saccade-related activity and the robustness of 3D tuning was evident). These cross-area differences may reflect a transition from lower-level representations of saccade-related signals to higher-level sensorimotor associations and parallel the observed changes in visual feature selectivity.</p></sec><sec id="s3-2"><title>Visual processing in V3A</title><p>Previous studies arrived at categorically different conclusions regarding visual processing in V3A (<xref ref-type="bibr" rid="bib22">Gaska et al., 1987</xref>, <xref ref-type="bibr" rid="bib23">Gaska et al., 1988</xref>; <xref ref-type="bibr" rid="bib20">Galletti and Battaglini, 1989</xref>; <xref ref-type="bibr" rid="bib21">Galletti et al., 1990</xref>; <xref ref-type="bibr" rid="bib58">Sauvan and Peterhans, 1999</xref>; <xref ref-type="bibr" rid="bib42">Nakamura and Colby, 2000</xref>; <xref ref-type="bibr" rid="bib43">Nakamura and Colby, 2002</xref>; <xref ref-type="bibr" rid="bib65">Tsao et al., 2003</xref>; <xref ref-type="bibr" rid="bib2">Anzai et al., 2011</xref>; <xref ref-type="bibr" rid="bib17">Elmore et al., 2019</xref>). Our large V3A sample revealed a heterogeneous population in which neurons ranged from representing low-level visual features to high-level object properties. Earlier discrepancies may reflect a combination of this heterogeneity, small sample sizes, and the possibility of functionally distinct modules within V3A. Another factor that may have contributed to the discrepancies is variability in how V3A was defined (<xref ref-type="bibr" rid="bib44">Nakhla et al., 2021</xref>), highlighting the continued importance of using functional and anatomical localization methods in future investigations of this relatively understudied area.</p><p>For some V3A neurons, we found that orientation tuning curve shape (but not gain) was highly tolerant to distance, implying 3D pose tuning. Because the perspective cues in our stimuli were independent of distance, the gain changes must have been driven by stereoscopic cues. This implies that these neurons were selective for gradients of relative disparity. Other V3A neurons showed orientation tuning at a single distance. These neurons may have been selective for absolute disparity gradients, similar to some middle temporal (MT) area neurons (<xref ref-type="bibr" rid="bib45">Nguyenkim and DeAngelis, 2003</xref>). Such neurons may reflect an intermediate stage of visual processing whose outputs are combined to create 3D pose representations. Selectivity for absolute disparity gradients may further account for suppressive effects previously reported within the classical receptive fields of V3A neurons (<xref ref-type="bibr" rid="bib22">Gaska et al., 1987</xref>) since the stimuli were presented at screen distance only and therefore would stimulate portions of the receptive field with non-preferred disparities. Lastly, the orientation tuning curve shape of some V3A neurons was highly distance-dependent, which may reflect tuning for a single absolute disparity. Future studies that perform detailed receptive field submapping of disparity selectivity will be important to explicate the heterogeneity of V3A as well as the transformations by which the visual system achieves 3D pose tuning. One possibility is that absolute disparity representations (in V1) are used to construct absolute disparity gradient detectors (in V3A, MT) and then pose selectivity (in V3A, PIP, CIP).</p></sec><sec id="s3-3"><title>Origins and functional implications of choice signals</title><p>Contemporary interpretations of choice signals include a mix of feedforward contributions to decision processes, the structure of correlated variability, attention, cognitive and behavioral factors, as well as feedback (<xref ref-type="bibr" rid="bib8">Celebrini and Newsome, 1994</xref>; <xref ref-type="bibr" rid="bib6">Britten et al., 1996</xref>; <xref ref-type="bibr" rid="bib16">Dodd et al., 2001</xref>; <xref ref-type="bibr" rid="bib26">Haefner et al., 2013</xref>; <xref ref-type="bibr" rid="bib25">Gu et al., 2014</xref>; <xref ref-type="bibr" rid="bib56">Ruff and Cohen, 2014</xref>; <xref ref-type="bibr" rid="bib62">Smolyanskaya et al., 2015</xref>; <xref ref-type="bibr" rid="bib13">Cumming and Nienborg, 2016</xref>). Despite these complexities, the current findings are consistent with a feedforward cascade and build-up of choice signals, which may reflect greater contributions of CIP than V3A to 3D perceptual decisions. First, choice-related activity appeared 11 ms earlier in V3A than CIP. Second, it was about twice as prevalent in CIP as V3A. Notably, the structure of correlated variability could not account for the prevalence of choice-related activity either within or across areas. Third, choice-related activity was preferentially carried by neurons with 3D orientation tuning that was more tolerant to distance. This is consistent with reports that neurons that carry choice signals tend to have resolved sensory ambiguities about the information being discriminated, allowing them to more directly contribute to decisions (<xref ref-type="bibr" rid="bib40">Liu et al., 2013</xref>; <xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). Although choice signals may be confounded with feature-based attentional modulation (<xref ref-type="bibr" rid="bib11">Cohen and Newsome, 2008</xref>), this is unlikely to explain our findings. Attention is largely associated with changes in response magnitude (<xref ref-type="bibr" rid="bib51">Reynolds and Heeger, 2009</xref>). However, we found more intricate relationships in which choice-related activity (i) was associated with changes in tuning curve shape that made 3D orientation tuning more tolerant to distance (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>) and (ii) statistically moderated the strength of sensorimotor associations such that visual and saccade direction preferences were best aligned for neurons that carried choice signals. Indeed, the strength of sensorimotor associations strongly depended on the robustness of 3D pose tuning for neurons with (but not without) choice-related activity. These findings thus reveal a multifaceted landscape of functional associations between sensory, choice-, and motor-related activity. They further imply a novel role for choice signals in sensorimotor processing that might reflect the temporal cascade of sensory processing, response selection, and motor action.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Animal preparation</title><p>All procedures followed the National Institutes of Health’s Guide for the Care and Use of Laboratory Animals and were approved by the Institutional Animal Care and Use Committee at the University of Wisconsin–Madison (Protocol G005229). Three male rhesus monkeys (<italic>Macaca mulatta</italic>; Monkey L: 6 years of age; Monkey F: 5 years; Monkey W: 5 years) were surgically implanted with a Delrin ring for head restraint and a removable recording grid for guiding electrodes. After recovery, they were trained to sit in a primate chair with head restraint and to fixate visual targets within 2° version and 1° vergence windows for liquid rewards.</p></sec><sec id="s4-2"><title>Experimental control and stimulus presentation</title><p>Experimental control was performed using the REC-GUI software (RRID:<ext-link ext-link-type="uri" xlink:href="https://identifiers.org/RRID/RRID:SCR_019008">SCR_019008</ext-link>) (<xref ref-type="bibr" rid="bib36">Kim et al., 2019</xref>). Stimuli were rendered using Psychtoolbox 3 (MATLAB R2016b; NVIDIA GeForce GTX 970) and rear-projected onto a polarization preserving screen (Stewart Film Screen, Inc) using a DLP LED projector (PROPixx; VPixx Technologies, Inc) with 1280 × 720 pixel resolution (70° × 43° of visual angle) at 240 Hz. A circular polarizer was used to sequence the presentation of stereoscopic ‘half-images’ to each eye (120 Hz/eye). Polarized glasses were worn. A phototransistor circuit was used to confirm the synchronization of the left and right eye images as well as align neuronal responses to the stimulus onset. Eye tracking was performed optically at 1 kHz (EyeLink 1000 plus, SR Research). The monkeys sat 57 cm from the screen.</p></sec><sec id="s4-3"><title>Visual stimuli</title><p>The stimuli were previously described in detail (<xref ref-type="bibr" rid="bib9">Chang et al., 2020a</xref>; <xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). Briefly, planar surfaces subtending 20° of visual angle were presented at the center of the screen. They were defined by 250 nonoverlapping dots that were uniformly distributed across the plane and rendered with stereoscopic and perspective cues. Surface orientation was described using tilt and slant (<xref ref-type="bibr" rid="bib63">Stevens, 1983</xref>; <xref ref-type="bibr" rid="bib53">Rosenberg et al., 2013</xref>). All combinations of eight tilts (0–315°, 45° steps) and four slants (15–60°, 15° steps) plus the frontoparallel plane (tilt undefined, slant = 0°) were presented (N = 33). All orientations were presented at four distances (37, 57, 97, and 137 cm; N = 132 unique poses). The dots were scaled with distance such that their screen size only depended on slant. At a slant of 0°, each dot subtended 0.35°.</p><p>The fixation point subtended 0.3° and was always at 57 cm (screen distance). Keeping its distance constant while varying the plane’s distance was a key design feature (<xref ref-type="bibr" rid="bib45">Nguyenkim and DeAngelis, 2003</xref>; <xref ref-type="bibr" rid="bib28">Hegdé and Van Essen, 2005</xref>; <xref ref-type="bibr" rid="bib3">Ban and Welchman, 2015</xref>; <xref ref-type="bibr" rid="bib1">Alizadeh et al., 2018</xref>; <xref ref-type="bibr" rid="bib29">Henderson et al., 2019</xref>) that conferred two advantages over yoking the distance of the stimulus and fixation point (<xref ref-type="bibr" rid="bib4">Banks et al., 2001</xref>; <xref ref-type="bibr" rid="bib30">Hillis et al., 2004</xref>). First, it ensured that the monkeys could not rely on local absolute disparity cues to judge 3D orientation (<xref ref-type="bibr" rid="bib17">Elmore et al., 2019</xref>; <xref ref-type="bibr" rid="bib9">Chang et al., 2020a</xref>; <xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). Second, it allowed us to dissociate the effects of stimulus distance and vergence signals (which would have otherwise been confounded) on the neuronal responses, which is important because V3A and CIP carry extraretinal signals.</p></sec><sec id="s4-4"><title>Experimental protocol</title><sec id="s4-4-1"><title>Tilt discrimination task</title><p>The monkeys performed an 8AFC tilt discrimination task (<xref ref-type="bibr" rid="bib9">Chang et al., 2020a</xref>; <xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). Each trial began by fixating a circular target at the center of the screen for 300 ms. A planar surface then appeared for 1 s. The fixation target and plane then disappeared and eight choice targets corresponding to the eight possible tilts appeared at polar angles of 0–315° in 45° steps (11° eccentricity). The nearest side of the plane was indicated by making a saccade to the corresponding target (e.g., the right target for a right-near plane) in exchange for a liquid reward for correct responses. Because frontoparallel planes were task ambiguous (tilt is undefined at slant = 0°), responses to those stimuli were rewarded with equal probability (12.5%).</p></sec><sec id="s4-4-2"><title>Visually guided saccade task</title><p>The monkeys also performed a visually guided (pop-up) saccade task (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). The timing was matched to the tilt discrimination task. Each trial began by fixating a target (identical to the target in the tilt discrimination task) at the center of the screen for 1.3 s. The fixation target then disappeared and a single saccade target appeared at one of the eight choice target locations. A saccade to the target was made for a liquid reward.</p><p>The two tasks were interleaved within a block design. For all CIP and 422 V3A neurons, each block included one completed trial for each of the following: (i) tilt discrimination task: (8 tilts × 4 non-zero slants + 8 frontoparallel planes) × 4 distances (160 trials) and (ii) saccade task: 8 directions × 4 repeats (32 trials). For 270 V3A neurons, each saccade direction was repeated once per block. Trials were aborted and the data discarded if fixation was broken before the choice/saccade target(s) appeared, or if a response was not provided within 500 ms. A minimum of five blocks was required to include a neuron for analysis.</p></sec></sec><sec id="s4-5"><title>Behavioral data analysis</title><p>Tilt discrimination performance was quantified by calculating the distribution of reported tilt errors (ΔTilt = reported tilt – presented tilt) and fitting a von Mises probability density function:<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mi>V</mml:mi><mml:mi>M</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mi>κ</mml:mi><mml:mo>⋅</mml:mo><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="normal">Δ</mml:mi><mml:mrow><mml:mi mathvariant="normal">T</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">t</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mi>μ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mo>⋅</mml:mo><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>κ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The mean (<italic>µ</italic>) and concentration (<inline-formula><mml:math id="inf7"><mml:mi>κ</mml:mi></mml:math></inline-formula>) parameters describe the accuracy and sensitivity, respectively (<xref ref-type="bibr" rid="bib59">Seilheimer et al., 2014</xref>; <xref ref-type="bibr" rid="bib14">Dakin and Rosenberg, 2018</xref>). Values of <italic>µ</italic> closer to 0° indicate greater accuracy and larger <inline-formula><mml:math id="inf8"><mml:mi>κ</mml:mi></mml:math></inline-formula> indicate greater sensitivity. An upper bound of  <inline-formula><mml:math id="inf9"><mml:mi>κ</mml:mi></mml:math></inline-formula> = 18 was set in the estimation routine (<xref ref-type="bibr" rid="bib9">Chang et al., 2020a</xref>; <xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). A modified Bessel function of order 0, <inline-formula><mml:math id="inf10"><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi>κ</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula>, normalizes the function to have unit area.</p></sec><sec id="s4-6"><title>Neuronal recordings</title><p>To target the areas, magnetic resonance imaging (MRI) scans were collected on a 3-Tesla GE MR750 scanner before and after implanting the head restraint ring. To estimate the penetration trajectories, the CARET software was used to register the structural scans to the F99 atlas (<xref ref-type="bibr" rid="bib70">Van Essen et al., 2001</xref>) and align the recording grid (<xref ref-type="bibr" rid="bib53">Rosenberg et al., 2013</xref>; <xref ref-type="bibr" rid="bib54">Rosenberg and Angelaki, 2014a</xref>; <xref ref-type="bibr" rid="bib55">Rosenberg and Angelaki, 2014b</xref>; <xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). During penetrations, observed gray/white matter and sulcal transitions were referenced to the MRI. Area CIP is located in the caudal portion of the lateral bank of the intraparietal sulcus and ventral to LIP. Area V3A is located adjacent to and ventral-laterally to CIP. There is a swath of white matter dorsal to V3A and lateral to CIP.</p><p>The order of the recording sessions went as follows. First, 41 V3A sessions were performed (Monkey L: N = 21; Monkey F: N = 20). Then, all 53 CIP sessions were performed (Monkey L: N = 26; Monkey F: N = 27). Finally, 50 more V3A sessions were performed (Monkey L: N = 18; Monkey F: N = 18; Monkey W: N = 14). The recordings were performed using linear array probes with either four or eight tetrodes (NeuroNexus, Inc). The tetrodes were separated by 300 μm and electrodes within a tetrode were separated by 25 μm. Neuronal signals (sampled at 30 kHz) along with eye position and phototransistor signals (each sampled at 1 kHz) were stored using a Scout Processor (Ripple, Inc). Tetrode-based spike sorting was performed offline using the KlustaKwik (K. Harris) semi-automatic clustering algorithm in MClust (MClust-4.0, A.D. Redish et al.) followed by manual refinement using Offline Sorter (Plexon, Inc). Only well-isolated single neurons verified by at least two authors were included.</p></sec><sec id="s4-7"><title>Receptive field mapping and analysis</title><p>Initial receptive field (RF) estimates were made by hand-mapping with patches of random dots, sinusoidal gratings, and/or orientated bars. During hand-mapping, fixation was maintained on a target (0.3°) at the center of the screen and a liquid reward was provided every 2–3 s of continuous fixation. Breaks in fixation resulted in the disappearance of the fixation point and stimulus for 1 s. An automated stimulus in which bright and dark squares were flashed one square at a time was then presented on a gray background. For V3A, 2° × 2° squares tiled a region centered on and larger than the hand estimate. For CIP, the squares were 4° × 4° and tiled the entire screen. A monkey was required to first fixate a target (0.3°) at the center of the screen for 300 ms. Then, while maintaining fixation, the squares were flashed (150 ms duration) in an alternating sequence at pseudorandom locations. A liquid reward was provided after every 20 flashes. If fixation was broken, the monkey was required to again fixate the target for 300 ms before the sequence resumed. A single repetition was completed when both bright and dark squares had been flashed at every location. At least five repetitions were collected each session.</p><p>The RF boundary was estimated offline by calculating the firing rate at each tiled location, averaging over the bright and dark square responses. The responses at each location were then compared to baseline, calculated using the last 150 ms of the fixation periods preceding the stimulus sequences, to identify significant responses (ANOVA, p&lt;0.05). The RF map was then manually smoothed and an envelope contour drawn. This procedure produced RF estimates for 355 (51%) V3A and 112 (26%) CIP neurons. The cross-area difference in the proportion of neurons for which a RF could be estimated may reflect that the mapping stimulus was likely more appropriate for lower- than higher-level visual areas.</p></sec><sec id="s4-8"><title>Neuronal data analyses</title><sec id="s4-8-1"><title>Visual response latency</title><p>For each neuron, spike trains were aligned to the stimulus onset using the phototransistor signal. Each spike train (1 ms bins) was convolved with a double exponential function and then averaged across trials to create spike density functions (SDFs) (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). A neuron’s visual latency was defined as the first time point after the stimulus onset where the SDF significantly deviated (ANOVA followed by Tukey’s HSD test, p&lt;0.05) from the baseline activity (calculated using the last 150 ms of the fixation periods preceding the stimuli) for at least 30 ms. Firing rates were calculated from the area’s median visual latency to the end of the stimulus presentation.</p></sec><sec id="s4-8-2"><title>Discrimination indices (DIs)</title><p>We calculated DIs to quantify how well preferred and non-preferred conditions could be discriminated from single-neuron responses (<xref ref-type="bibr" rid="bib50">Prince et al., 2002</xref>):<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">I</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mn>2</mml:mn><mml:msqrt><mml:mfrac><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mfrac></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>where <italic>R<sub>max</sub></italic> and <italic>R<sub>min</sub></italic> are the maximum and minimum mean responses across the tuning curve, <italic>SSE</italic> is the sum squared error around the mean responses for each condition, <italic>N</italic> is the total number of trials, and <italic>M</italic> is the number of conditions. For neurons with large response modulation and low response variability, responses to preferred and non-preferred stimuli will be highly discriminable, and the DI correspondingly closer to one. Otherwise, the DI will be closer to zero. Four DIs were computed following <xref ref-type="disp-formula" rid="equ2">Equation 2</xref>. The SODI was used to quantify how well the 3D orientation (over all slant–tilts) could be discriminated at each distance (M = 33). The TDI was used to quantify how well the tilt could be discriminated at given slant–distance combinations (M = 8). The CDI was used to quantify how well the choice could be discriminated (M = 8). SDI was used to quantify how well the saccade direction could be discriminated (M = 8).</p></sec><sec id="s4-8-3"><title>Quantifying the dependency of orientation tuning on distance</title><p>The tolerance of the 3D orientation tuning curves to distance was quantified as previously described (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). Briefly, we fit the 3D pose (orientation × distance) tuning curve with a multiplicatively separable model:<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:mi>C</mml:mi><mml:mo>+</mml:mo><mml:mi>g</mml:mi><mml:mo>⋅</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>⋅</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>D</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>where <italic>R</italic> is the response to orientation θ (tilt and slant) and distance <italic>D, DC</italic> is an offset, <italic>g</italic> sets the response amplitude, <italic>H(θ</italic>) is the orientation tuning curve, and <italic>F(D</italic>) is the distance tuning curve. A tolerance index quantifying the dependence of the 3D orientation tuning curve shape on distance was calculated as the average correlation between the observed tuning curve and fit at each distance. We additionally tested an additively separable model <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>D</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:mi>C</mml:mi><mml:mo>+</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>θ</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mi>F</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>D</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, but did not present the results because the multiplicative model better described the responses of 690/692 V3A and 437/437 CIP neurons.</p><p>We also quantified the extent to which orientation preferences differed across distance. For each neuron, the preferred orientation was estimated at each distance with significant orientation selectivity (ANOVA, p&lt;0.05; Bonferroni–Holm corrected for four distances) by fitting a Bingham function (<xref ref-type="bibr" rid="bib53">Rosenberg et al., 2013</xref>). The principal orientation, the axis about which the preferences clustered, was determined by arranging the surface normal vectors corresponding to the preferences into a matrix and calculating the eigenvectors. The principal orientation was defined by the eigenvector with the largest eigenvalue (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>).</p></sec><sec id="s4-8-4"><title>Choice-related activity</title><p>Choice-related activity was calculated using frontoparallel plane trials only. In every session, each monkey chose every choice target, and the choice distributions were broad (Monkey L: mean circular variance = 0.79 ± 0.09 standard deviation, N = 65 sessions; Monkey F: 0.82 ± 0.09, N = 65; Monkey W: 0.64 ± 0.14, N = 14). Importantly, there were no significant correlations between the mean choices of the monkeys and the choice preferences of the simultaneously recorded neurons (Monkey L: <italic>r</italic> = 0.13, p=0.24; Monkey F: <italic>r</italic> = –0.11, p=0.08; Monkey W: <italic>r</italic> = 0.21, p=0.18).</p><p>Choice tuning was assessed from the onset of choice-related activity for the area (calculated in an iterative fashion following <xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>) to the end of the stimulus presentation, as briefly described here. Response differences associated with the plane’s distance were removed by z-scoring the baseline-subtracted responses separately for each distance. For neurons with significant choice tuning (ANOVA, p&lt;0.05), responses were then grouped according to the tilt choice. For each tuned neuron, the average SDF was then computed for each choice direction and labeled relative to the neuron’s preferred choice (preferred choice, ±45°, ±90°, ±135°, and 180°). The SDFs were then averaged across neurons to create eight population-level time courses. The onset was defined as the first time point that the time courses significantly differed (ANOVA, p&lt;0.05) for at least 30 ms (<xref ref-type="bibr" rid="bib53">Rosenberg et al., 2013</xref>). This process was iteratively performed until the onset no longer changed.</p></sec><sec id="s4-8-5"><title>Saccade-related activity</title><p>Saccade onset was defined as the first time point that the velocity of either eye was ≥150°/s. Saccade direction tuning was assessed from the start of saccade-related activity for the area to the saccade onset. A neuron was classified as having saccade-related activity if the baseline-subtracted firing rates significantly depended on the saccade direction (ANOVA, p&lt;0.05). The onset of saccade-related activity was calculated following the procedure described above for the choice-related activity (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>).</p><p>The time point at which the time courses of saccade-related activity conditioned on saccade latency approximately coalesced was defined as when the sum squared error between the time courses and their mean was smallest (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>). To visually compare the temporally integrated V3A and CIP time courses, we applied a DC offset and multiplicative gain to each integrated V3A time course to minimize the sum squared error with the CIP time course.</p></sec><sec id="s4-8-6"><title>Noise and signal correlations</title><p>We calculated noise and signal correlations between pairs of simultaneously recorded neurons on the same tetrode in V3A (N = 404 pairs) and CIP (N = 244 pairs). To calculate noise correlations, we took the spike counts across trials for each 3D pose condition (N = 132) and removed outliers (&gt;3 standard deviations from the mean response) (<xref ref-type="bibr" rid="bib72">Zohary et al., 1994</xref>; <xref ref-type="bibr" rid="bib37">Kohn and Smith, 2005</xref>; <xref ref-type="bibr" rid="bib32">Huang and Lisberger, 2009</xref>; <xref ref-type="bibr" rid="bib24">Gu et al., 2011</xref>). To remove stimulus-dependent response differences, the remaining spike counts were z-scored separately for each condition. The correlation between the two neurons’ responses was then computed across conditions and trials. Signal correlations were computed between the 3D pose tuning curves.</p></sec><sec id="s4-8-7"><title>Vergence control</title><p>To determine if the 3D pose responses were significantly affected by small vergence eye movements that did not violate the vergence window, we performed an ANCOVA to test for main effects of stimulus tuning with vergence included as a covariate. Tilt (linearized into cosine and sine components), slant, and distance were independent factors and the mean vergence was a covariate. Only 67 (9.7%) V3A neurons showed a significant effect of vergence (p&lt;0.05). Importantly, the significance of the main effects did not depend on whether vergence was included as a covariate for all but 13 (1.9%) V3A neurons. These results are comparable to those in the CIP data (<xref ref-type="bibr" rid="bib10">Chang et al., 2020b</xref>) and other studies (<xref ref-type="bibr" rid="bib15">DeAngelis and Uka, 2003</xref>; <xref ref-type="bibr" rid="bib17">Elmore et al., 2019</xref>), and suggest that vergence errors had a minimal impact on the findings.</p></sec></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Software, Formal analysis, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing - original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Data curation, Software, Formal analysis, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Software, Formal analysis, Funding acquisition, Validation, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Validation, Methodology, Project administration, Writing – review and editing</p></fn><fn fn-type="con" id="con5"><p>Conceptualization, Resources, Software, Methodology, Writing – review and editing</p></fn><fn fn-type="con" id="con6"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Supervision, Funding acquisition, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing – review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>This study was performed in strict accordance with the recommendations of the National Institutes of Health's Guide for the Care and Use of Laboratory Animals. All experimental procedures and surgeries were approved by the Institutional Animal Care and Use Committee (IACUC) at the University of Wisconsin-Madison (Protocol #: G005229).</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media xlink:href="elife-78712-transrepform1-v2.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>All data generated or analyzed during this study are available through the Open Science Framework via our lab's profile at <ext-link ext-link-type="uri" xlink:href="https://osf.io/8wxk7/">https://osf.io/8wxk7/</ext-link>.</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><collab>Rosenberg A</collab><name><surname>Doudlah</surname><given-names>R</given-names></name><name><surname>Chang</surname><given-names>T-Y</given-names></name><name><surname>Thompson</surname><given-names>L</given-names></name><name><surname>Kim</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>Parallel processing, hierarchical transformations, and sensorimotor associations along the 'where' pathway</data-title><source>Open Science Framework</source><pub-id pub-id-type="accession" xlink:href="https://osf.io/a89gx/">a89gx</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Zikang Zhu for helpful discussion, as well as Meghan Lowe and Satchal Postlewaite for help with spike sorting. Further support was provided by the National Institutes of Health Grant P51OD011106 to the Wisconsin National Primate Research Center and the National Institute of Child Health and Human Development Grant P50HD105353 to the Waisman Center.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alizadeh</surname><given-names>AM</given-names></name><name><surname>Van Dromme</surname><given-names>I</given-names></name><name><surname>Verhoef</surname><given-names>BE</given-names></name><name><surname>Janssen</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Caudal intraparietal sulcus and three-dimensional vision: A combined functional magnetic resonance imaging and single-cell study</article-title><source>NeuroImage</source><volume>166</volume><fpage>46</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.10.045</pub-id><pub-id pub-id-type="pmid">29080712</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anzai</surname><given-names>A</given-names></name><name><surname>Chowdhury</surname><given-names>SA</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Coding of stereoscopic depth information in visual areas V3 and V3A</article-title><source>The Journal of Neuroscience</source><volume>31</volume><fpage>10270</fpage><lpage>10282</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5956-10.2011</pub-id><pub-id pub-id-type="pmid">21753004</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ban</surname><given-names>H</given-names></name><name><surname>Welchman</surname><given-names>AE</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>FMRI analysis-by-synthesis reveals a dorsal hierarchy that extracts surface slant</article-title><source>The Journal of Neuroscience</source><volume>35</volume><fpage>9823</fpage><lpage>9835</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.1255-15.2015</pub-id><pub-id pub-id-type="pmid">26156985</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Banks</surname><given-names>MS</given-names></name><name><surname>Hooge</surname><given-names>IT</given-names></name><name><surname>Backus</surname><given-names>BT</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Perceiving slant about a horizontal axis from stereopsis</article-title><source>Journal of Vision</source><volume>1</volume><fpage>55</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1167/1.2.1</pub-id><pub-id pub-id-type="pmid">12678602</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bingham</surname><given-names>C</given-names></name></person-group><year iso-8601-date="1974">1974</year><article-title>An antipodally symmetric distribution on the sphere</article-title><source>The Annals of Statistics</source><volume>2</volume><fpage>1201</fpage><lpage>1225</lpage><pub-id pub-id-type="doi">10.1214/aos/1176342874</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Britten</surname><given-names>KH</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Celebrini</surname><given-names>S</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>A relationship between behavioral choice and the visual responses of neurons in macaque MT</article-title><source>Visual Neuroscience</source><volume>13</volume><fpage>87</fpage><lpage>100</lpage><pub-id pub-id-type="doi">10.1017/s095252380000715x</pub-id><pub-id pub-id-type="pmid">8730992</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buneo</surname><given-names>CA</given-names></name><name><surname>Andersen</surname><given-names>RA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The posterior parietal cortex: sensorimotor interface for the planning and online control of visually guided movements</article-title><source>Neuropsychologia</source><volume>44</volume><fpage>2594</fpage><lpage>2606</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2005.10.011</pub-id><pub-id pub-id-type="pmid">16300804</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Celebrini</surname><given-names>S</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Neuronal and psychophysical sensitivity to motion signals in extrastriate area MST of the macaque monkey</article-title><source>The Journal of Neuroscience</source><volume>14</volume><fpage>4109</fpage><lpage>4124</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.14-07-04109.1994</pub-id><pub-id pub-id-type="pmid">8027765</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>TY</given-names></name><name><surname>Thompson</surname><given-names>L</given-names></name><name><surname>Doudlah</surname><given-names>R</given-names></name><name><surname>Kim</surname><given-names>B</given-names></name><name><surname>Sunkara</surname><given-names>A</given-names></name><name><surname>Rosenberg</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020a</year><article-title>Optimized but not maximized cue integration for 3D visual perception</article-title><source>ENeuro</source><volume>7</volume><elocation-id>ENEURO.0411-19.2019</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0411-19.2019</pub-id><pub-id pub-id-type="pmid">31836597</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>TY</given-names></name><name><surname>Doudlah</surname><given-names>R</given-names></name><name><surname>Kim</surname><given-names>B</given-names></name><name><surname>Sunkara</surname><given-names>A</given-names></name><name><surname>Thompson</surname><given-names>LW</given-names></name><name><surname>Lowe</surname><given-names>ME</given-names></name><name><surname>Rosenberg</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020b</year><article-title>Functional links between sensory representations, choice activity, and sensorimotor associations in parietal cortex</article-title><source>eLife</source><volume>9</volume><elocation-id>e57968</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.57968</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>M.R</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Context-dependent changes in functional circuitry in visual area MT</article-title><source>Neuron</source><volume>60</volume><fpage>162</fpage><lpage>173</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2008.08.007</pub-id><pub-id pub-id-type="pmid">18940596</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>MR</given-names></name><name><surname>Maunsell</surname><given-names>JHR</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Attention improves performance primarily by reducing interneuronal correlations</article-title><source>Nature Neuroscience</source><volume>12</volume><fpage>1594</fpage><lpage>1600</lpage><pub-id pub-id-type="doi">10.1038/nn.2439</pub-id><pub-id pub-id-type="pmid">19915566</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cumming</surname><given-names>BG</given-names></name><name><surname>Nienborg</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Feedforward and feedback sources of choice probability in neural population responses</article-title><source>Current Opinion in Neurobiology</source><volume>37</volume><fpage>126</fpage><lpage>132</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2016.01.009</pub-id><pub-id pub-id-type="pmid">26922005</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dakin</surname><given-names>CJ</given-names></name><name><surname>Rosenberg</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2018">2018</year><chapter-title>Gravity estimation and verticality perception</chapter-title><person-group person-group-type="editor"><name><surname>Brian</surname><given-names>LD</given-names></name><name><surname>Stephen</surname><given-names>RL</given-names></name></person-group><source>Handbook of Clinical Neurology</source><publisher-name>Elsevier</publisher-name><fpage>43</fpage><lpage>59</lpage><pub-id pub-id-type="doi">10.1016/B978-0-444-63916-5.00003-3</pub-id><pub-id pub-id-type="pmid">30482332</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Uka</surname><given-names>T</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Coding of horizontal disparity and velocity by MT neurons in the alert macaque</article-title><source>Journal of Neurophysiology</source><volume>89</volume><fpage>1094</fpage><lpage>1111</lpage><pub-id pub-id-type="doi">10.1152/jn.00717.2002</pub-id><pub-id pub-id-type="pmid">12574483</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dodd</surname><given-names>JV</given-names></name><name><surname>Krug</surname><given-names>K</given-names></name><name><surname>Cumming</surname><given-names>BG</given-names></name><name><surname>Parker</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Perceptually bistable three-dimensional figures evoke high choice probabilities in cortical area MT</article-title><source>The Journal of Neuroscience</source><volume>21</volume><fpage>4809</fpage><lpage>4821</lpage><pub-id pub-id-type="pmid">11425908</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Elmore</surname><given-names>LC</given-names></name><name><surname>Rosenberg</surname><given-names>A</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Choice-related activity during visual slant discrimination in macaque CIP but not V3A</article-title><source>ENeuro</source><volume>6</volume><elocation-id>ENEURO.0248-18.2019</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0248-18.2019</pub-id><pub-id pub-id-type="pmid">30923736</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Felleman</surname><given-names>DJ</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="1991">1991</year><article-title>Distributed hierarchical processing in the primate cerebral cortex</article-title><source>Cerebral Cortex</source><volume>1</volume><fpage>1</fpage><lpage>47</lpage><pub-id pub-id-type="doi">10.1093/cercor/1.1.1-a</pub-id><pub-id pub-id-type="pmid">1822724</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fisher</surname><given-names>N</given-names></name></person-group><year iso-8601-date="1995">1995</year><source>Statistical Analysis Of Circular Data</source><publisher-loc>Cambridge</publisher-loc><publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1017/CBO9780511564345</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Galletti</surname><given-names>C</given-names></name><name><surname>Battaglini</surname><given-names>PP</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Gaze-dependent visual neurons in area V3A of monkey prestriate cortex</article-title><source>The Journal of Neuroscience</source><volume>9</volume><fpage>1112</fpage><lpage>1125</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.09-04-01112.1989</pub-id><pub-id pub-id-type="pmid">2703870</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Galletti</surname><given-names>C</given-names></name><name><surname>Battaglini</surname><given-names>PP</given-names></name><name><surname>Fattori</surname><given-names>P</given-names></name></person-group><year iso-8601-date="1990">1990</year><article-title>Real-motion cells in area V3A of macaque visual cortex</article-title><source>Experimental Brain Research</source><volume>82</volume><fpage>67</fpage><lpage>76</lpage><pub-id pub-id-type="doi">10.1007/BF00230838</pub-id><pub-id pub-id-type="pmid">2257915</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gaska</surname><given-names>JP</given-names></name><name><surname>Jacobson</surname><given-names>LD</given-names></name><name><surname>Pollen</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="1987">1987</year><article-title>Response suppression by extending sine-wave gratings within the receptive fields of neurons in visual cortical area V3A of the macaque monkey</article-title><source>Vision Research</source><volume>27</volume><fpage>1687</fpage><lpage>1692</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(87)90098-8</pub-id><pub-id pub-id-type="pmid">3445460</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gaska</surname><given-names>JP</given-names></name><name><surname>Jacobson</surname><given-names>LD</given-names></name><name><surname>Pollen</surname><given-names>DA</given-names></name></person-group><year iso-8601-date="1988">1988</year><article-title>Spatial and temporal frequency selectivity of neurons in visual cortical area V3A of the macaque monkey</article-title><source>Vision Research</source><volume>28</volume><fpage>1179</fpage><lpage>1191</lpage><pub-id pub-id-type="doi">10.1016/0042-6989(88)90035-1</pub-id><pub-id pub-id-type="pmid">3253990</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gu</surname><given-names>Y</given-names></name><name><surname>Liu</surname><given-names>S</given-names></name><name><surname>Fetsch</surname><given-names>CR</given-names></name><name><surname>Yang</surname><given-names>Y</given-names></name><name><surname>Fok</surname><given-names>S</given-names></name><name><surname>Sunkara</surname><given-names>A</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Perceptual learning reduces interneuronal correlations in macaque visual cortex</article-title><source>Neuron</source><volume>71</volume><fpage>750</fpage><lpage>761</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.06.015</pub-id><pub-id pub-id-type="pmid">21867889</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gu</surname><given-names>Y</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Contribution of correlated noise and selective decoding to choice probability measurements in extrastriate visual cortex</article-title><source>eLife</source><volume>3</volume><elocation-id>e02670</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.02670</pub-id><pub-id pub-id-type="pmid">24986734</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haefner</surname><given-names>RM</given-names></name><name><surname>Gerwinn</surname><given-names>S</given-names></name><name><surname>Macke</surname><given-names>JH</given-names></name><name><surname>Bethge</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Inferring decoding strategies from choice probabilities in the presence of correlated variability</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>235</fpage><lpage>242</lpage><pub-id pub-id-type="doi">10.1038/nn.3309</pub-id><pub-id pub-id-type="pmid">23313912</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanes</surname><given-names>DP</given-names></name><name><surname>Schall</surname><given-names>JD</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Neural control of voluntary movement initiation</article-title><source>Science</source><volume>274</volume><fpage>427</fpage><lpage>430</lpage><pub-id pub-id-type="doi">10.1126/science.274.5286.427</pub-id><pub-id pub-id-type="pmid">8832893</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hegdé</surname><given-names>J</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Role of primate visual area V4 in the processing of 3-D shape characteristics defined by disparity</article-title><source>Journal of Neurophysiology</source><volume>94</volume><fpage>2856</fpage><lpage>2866</lpage><pub-id pub-id-type="doi">10.1152/jn.00802.2004</pub-id><pub-id pub-id-type="pmid">15987759</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henderson</surname><given-names>M</given-names></name><name><surname>Vo</surname><given-names>V</given-names></name><name><surname>Chunharas</surname><given-names>C</given-names></name><name><surname>Sprague</surname><given-names>T</given-names></name><name><surname>Serences</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Multivariate analysis of BOLD activation patterns recovers graded depth representations in human visual and parietal cortex</article-title><source>ENeuro</source><volume>6</volume><elocation-id>eNeuro</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0362-18.2019</pub-id><pub-id pub-id-type="pmid">31285275</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hillis</surname><given-names>JM</given-names></name><name><surname>Watt</surname><given-names>SJ</given-names></name><name><surname>Landy</surname><given-names>MS</given-names></name><name><surname>Banks</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Slant from texture and disparity cues: optimal cue combination</article-title><source>Journal of Vision</source><volume>4</volume><fpage>967</fpage><lpage>992</lpage><pub-id pub-id-type="doi">10.1167/4.12.1</pub-id><pub-id pub-id-type="pmid">15669906</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hsi</surname><given-names>S</given-names></name><name><surname>Linn</surname><given-names>MC</given-names></name><name><surname>Bell</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>The role of spatial reasoning in engineering and the design of spatial instruction</article-title><source>Journal of Engineering Education</source><volume>86</volume><fpage>151</fpage><lpage>158</lpage><pub-id pub-id-type="doi">10.1002/j.2168-9830.1997.tb00278.x</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>X</given-names></name><name><surname>Lisberger</surname><given-names>SG</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Noise correlations in cortical area MT and their potential impact on trial-by-trial variation in the direction and speed of smooth-pursuit eye movements</article-title><source>Journal of Neurophysiology</source><volume>101</volume><fpage>3012</fpage><lpage>3030</lpage><pub-id pub-id-type="doi">10.1152/jn.00010.2009</pub-id><pub-id pub-id-type="pmid">19321645</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Janssen</surname><given-names>P</given-names></name><name><surname>Vogels</surname><given-names>R</given-names></name><name><surname>Orban</surname><given-names>GA</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Three-dimensional shape coding in inferior temporal cortex</article-title><source>Neuron</source><volume>27</volume><fpage>385</fpage><lpage>397</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(00)00045-3</pub-id><pub-id pub-id-type="pmid">10985357</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Judd</surname><given-names>CM</given-names></name><name><surname>Yzerbyt</surname><given-names>VY</given-names></name><name><surname>Muller</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2014">2014</year><chapter-title>Mediation and moderation</chapter-title><person-group person-group-type="editor"><name><surname>Judd</surname><given-names>CM</given-names></name></person-group><source>Handbook of Research Methods in Social and Personality Psychology</source><publisher-name>Elsevier</publisher-name><fpage>653</fpage><lpage>676</lpage></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Katsuyama</surname><given-names>N</given-names></name><name><surname>Yamashita</surname><given-names>A</given-names></name><name><surname>Sawada</surname><given-names>K</given-names></name><name><surname>Naganuma</surname><given-names>T</given-names></name><name><surname>Sakata</surname><given-names>H</given-names></name><name><surname>Taira</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Functional and histological properties of caudal intraparietal area of macaque monkey</article-title><source>Neuroscience</source><volume>167</volume><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2010.01.028</pub-id><pub-id pub-id-type="pmid">20096334</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>B</given-names></name><name><surname>Kenchappa</surname><given-names>SC</given-names></name><name><surname>Sunkara</surname><given-names>A</given-names></name><name><surname>Chang</surname><given-names>TY</given-names></name><name><surname>Thompson</surname><given-names>L</given-names></name><name><surname>Doudlah</surname><given-names>R</given-names></name><name><surname>Rosenberg</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Real-time experimental control using network-based parallel processing</article-title><source>eLife</source><volume>8</volume><elocation-id>e40231</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.40231</pub-id><pub-id pub-id-type="pmid">30730290</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kohn</surname><given-names>A</given-names></name><name><surname>Smith</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Stimulus dependence of neuronal correlation in primary visual cortex of the macaque</article-title><source>The Journal of Neuroscience</source><volume>25</volume><fpage>3661</fpage><lpage>3673</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5106-04.2005</pub-id><pub-id pub-id-type="pmid">15814797</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lanzilotto</surname><given-names>M</given-names></name><name><surname>Ferroni</surname><given-names>CG</given-names></name><name><surname>Livi</surname><given-names>A</given-names></name><name><surname>Gerbella</surname><given-names>M</given-names></name><name><surname>Maranesi</surname><given-names>M</given-names></name><name><surname>Borra</surname><given-names>E</given-names></name><name><surname>Passarelli</surname><given-names>L</given-names></name><name><surname>Gamberini</surname><given-names>M</given-names></name><name><surname>Fogassi</surname><given-names>L</given-names></name><name><surname>Bonini</surname><given-names>L</given-names></name><name><surname>Orban</surname><given-names>GA</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Anterior intraparietal area: A hub in the observed manipulative action network</article-title><source>Cerebral Cortex</source><volume>29</volume><fpage>1816</fpage><lpage>1833</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhz011</pub-id><pub-id pub-id-type="pmid">30766996</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>JW</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Corticocortical connections of visual, sensorimotor, and multimodal processing areas in the parietal lobe of the macaque monkey</article-title><source>The Journal of Comparative Neurology</source><volume>428</volume><fpage>112</fpage><lpage>137</lpage><pub-id pub-id-type="doi">10.1002/1096-9861(20001204)428:1&lt;112::aid-cne8&gt;3.0.co;2-9</pub-id><pub-id pub-id-type="pmid">11058227</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>S</given-names></name><name><surname>Gu</surname><given-names>Y</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Choice-related activity and correlated noise in subcortical vestibular neurons</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>89</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1038/nn.3267</pub-id><pub-id pub-id-type="pmid">23178975</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Munoz</surname><given-names>DP</given-names></name><name><surname>Wurtz</surname><given-names>RH</given-names></name></person-group><year iso-8601-date="1995">1995</year><article-title>Saccade-related activity in monkey superior colliculus. I. characteristics of burst and buildup cells</article-title><source>Journal of Neurophysiology</source><volume>73</volume><fpage>2313</fpage><lpage>2333</lpage><pub-id pub-id-type="doi">10.1152/jn.1995.73.6.2313</pub-id><pub-id pub-id-type="pmid">7666141</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakamura</surname><given-names>K</given-names></name><name><surname>Colby</surname><given-names>CL</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Visual, saccade-related, and cognitive activation of single neurons in monkey extrastriate area V3A</article-title><source>Journal of Neurophysiology</source><volume>84</volume><fpage>677</fpage><lpage>692</lpage><pub-id pub-id-type="doi">10.1152/jn.2000.84.2.677</pub-id><pub-id pub-id-type="pmid">10938295</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakamura</surname><given-names>K</given-names></name><name><surname>Colby</surname><given-names>CL</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Updating of the visual representation in monkey striate and extrastriate cortex during saccades</article-title><source>PNAS</source><volume>99</volume><fpage>4026</fpage><lpage>4031</lpage><pub-id pub-id-type="doi">10.1073/pnas.052379899</pub-id><pub-id pub-id-type="pmid">11904446</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakhla</surname><given-names>N</given-names></name><name><surname>Korkian</surname><given-names>Y</given-names></name><name><surname>Krause</surname><given-names>MR</given-names></name><name><surname>Pack</surname><given-names>CC</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Neural selectivity for visual motion in macaque area V3A</article-title><source>ENeuro</source><volume>8</volume><elocation-id>eNeuro</elocation-id><pub-id pub-id-type="doi">10.1523/ENEURO.0383-20.2020</pub-id><pub-id pub-id-type="pmid">33303620</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nguyenkim</surname><given-names>JD</given-names></name><name><surname>DeAngelis</surname><given-names>GC</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Disparity-based coding of three-dimensional surface orientation by macaque middle temporal neurons</article-title><source>The Journal of Neuroscience</source><volume>23</volume><fpage>7117</fpage><lpage>7128</lpage><pub-id pub-id-type="pmid">12904472</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nienborg</surname><given-names>H</given-names></name><name><surname>Cumming</surname><given-names>BG</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Macaque V2 neurons, but not V1 neurons, show choice-related activity</article-title><source>The Journal of Neuroscience</source><volume>26</volume><fpage>9567</fpage><lpage>9578</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2256-06.2006</pub-id><pub-id pub-id-type="pmid">16971541</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niu</surname><given-names>M</given-names></name><name><surname>Impieri</surname><given-names>D</given-names></name><name><surname>Rapan</surname><given-names>L</given-names></name><name><surname>Funck</surname><given-names>T</given-names></name><name><surname>Palomero-Gallagher</surname><given-names>N</given-names></name><name><surname>Zilles</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Receptor-driven, multimodal mapping of cortical areas in the macaque monkey intraparietal sulcus</article-title><source>eLife</source><volume>9</volume><elocation-id>e55979</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.55979</pub-id><pub-id pub-id-type="pmid">32613942</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pause</surname><given-names>M</given-names></name><name><surname>Freund</surname><given-names>HJ</given-names></name></person-group><year iso-8601-date="1989">1989</year><article-title>Role of the parietal cortex for sensorimotor transformation</article-title><source>Brain, Behavior and Evolution</source><volume>33</volume><fpage>136</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1159/000115916</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Premereur</surname><given-names>E</given-names></name><name><surname>Van Dromme</surname><given-names>IC</given-names></name><name><surname>Romero</surname><given-names>MC</given-names></name><name><surname>Vanduffel</surname><given-names>W</given-names></name><name><surname>Janssen</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Effective connectivity of depth-structure-selective patches in the lateral bank of the macaque intraparietal sulcus</article-title><source>PLOS Biology</source><volume>13</volume><elocation-id>e1002072</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002072</pub-id><pub-id pub-id-type="pmid">25689048</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Prince</surname><given-names>SJD</given-names></name><name><surname>Pointon</surname><given-names>AD</given-names></name><name><surname>Cumming</surname><given-names>BG</given-names></name><name><surname>Parker</surname><given-names>AJ</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Quantitative analysis of the responses of V1 neurons to horizontal disparity in dynamic random-dot stereograms</article-title><source>Journal of Neurophysiology</source><volume>87</volume><fpage>191</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1152/jn.00465.2000</pub-id><pub-id pub-id-type="pmid">11784742</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reynolds</surname><given-names>JH</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The normalization model of attention</article-title><source>Neuron</source><volume>61</volume><fpage>168</fpage><lpage>185</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.01.002</pub-id><pub-id pub-id-type="pmid">19186161</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roitman</surname><given-names>JD</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Response of neurons in the lateral intraparietal area during a combined visual discrimination reaction time task</article-title><source>The Journal of Neuroscience</source><volume>22</volume><fpage>9475</fpage><lpage>9489</lpage><pub-id pub-id-type="pmid">12417672</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenberg</surname><given-names>A</given-names></name><name><surname>Cowan</surname><given-names>NJ</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>The visual representation of 3D object orientation in parietal cortex</article-title><source>The Journal of Neuroscience</source><volume>33</volume><fpage>19352</fpage><lpage>19361</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3174-13.2013</pub-id><pub-id pub-id-type="pmid">24305830</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenberg</surname><given-names>A</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2014">2014a</year><article-title>Gravity influences the visual representation of object tilt in parietal cortex</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>14170</fpage><lpage>14180</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2030-14.2014</pub-id><pub-id pub-id-type="pmid">25339732</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenberg</surname><given-names>A</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2014">2014b</year><article-title>Reliability-dependent contributions of visual orientation cues in parietal cortex</article-title><source>PNAS</source><volume>111</volume><fpage>18043</fpage><lpage>18048</lpage><pub-id pub-id-type="doi">10.1073/pnas.1421131111</pub-id><pub-id pub-id-type="pmid">25427796</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruff</surname><given-names>DA</given-names></name><name><surname>Cohen</surname><given-names>MR</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Global cognitive factors modulate correlated response variability between V4 neurons</article-title><source>The Journal of Neuroscience</source><volume>34</volume><fpage>16408</fpage><lpage>16416</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2750-14.2014</pub-id><pub-id pub-id-type="pmid">25471578</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rushworth</surname><given-names>MFS</given-names></name><name><surname>Nixon</surname><given-names>PD</given-names></name><name><surname>Passingham</surname><given-names>RE</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Parietal cortex and movement</article-title><source>Experimental Brain Research</source><volume>117</volume><fpage>292</fpage><lpage>310</lpage><pub-id pub-id-type="doi">10.1007/s002210050224</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sauvan</surname><given-names>XM</given-names></name><name><surname>Peterhans</surname><given-names>E</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Orientation constancy in neurons of monkey visual cortex</article-title><source>Visual Cognition</source><volume>6</volume><fpage>43</fpage><lpage>54</lpage><pub-id pub-id-type="doi">10.1080/713756803</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seilheimer</surname><given-names>RL</given-names></name><name><surname>Rosenberg</surname><given-names>A</given-names></name><name><surname>Angelaki</surname><given-names>DE</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Models and processes of multisensory cue combination</article-title><source>Current Opinion in Neurobiology</source><volume>25</volume><fpage>38</fpage><lpage>46</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2013.11.008</pub-id><pub-id pub-id-type="pmid">24709599</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Britten</surname><given-names>KH</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name><name><surname>Movshon</surname><given-names>JA</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>A computational analysis of the relationship between neuronal and behavioral responses to visual motion</article-title><source>The Journal of Neuroscience</source><volume>16</volume><fpage>1486</fpage><lpage>1510</lpage><pub-id pub-id-type="pmid">8778300</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Motion perception: seeing and deciding</article-title><source>PNAS</source><volume>93</volume><fpage>628</fpage><lpage>633</lpage><pub-id pub-id-type="doi">10.1073/pnas.93.2.628</pub-id><pub-id pub-id-type="pmid">8570606</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smolyanskaya</surname><given-names>A</given-names></name><name><surname>Haefner</surname><given-names>RM</given-names></name><name><surname>Lomber</surname><given-names>SG</given-names></name><name><surname>Born</surname><given-names>RT</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>A modality-specific feedforward component of choice-related activity in MT</article-title><source>Neuron</source><volume>87</volume><fpage>208</fpage><lpage>219</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.06.018</pub-id><pub-id pub-id-type="pmid">26139374</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stevens</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="1983">1983</year><article-title>Slant-tilt: the visual encoding of surface orientation</article-title><source>Biological Cybernetics</source><volume>46</volume><fpage>183</fpage><lpage>195</lpage><pub-id pub-id-type="doi">10.1007/BF00336800</pub-id><pub-id pub-id-type="pmid">6850004</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Taira</surname><given-names>M</given-names></name><name><surname>Tsutsui</surname><given-names>KI</given-names></name><name><surname>Jiang</surname><given-names>M</given-names></name><name><surname>Yara</surname><given-names>K</given-names></name><name><surname>Sakata</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Parietal neurons represent surface orientation from the gradient of binocular disparity</article-title><source>Journal of Neurophysiology</source><volume>83</volume><fpage>3140</fpage><lpage>3146</lpage><pub-id pub-id-type="doi">10.1152/jn.2000.83.5.3140</pub-id><pub-id pub-id-type="pmid">10805708</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsao</surname><given-names>DY</given-names></name><name><surname>Vanduffel</surname><given-names>W</given-names></name><name><surname>Sasaki</surname><given-names>Y</given-names></name><name><surname>Fize</surname><given-names>D</given-names></name><name><surname>Knutsen</surname><given-names>TA</given-names></name><name><surname>Mandeville</surname><given-names>JB</given-names></name><name><surname>Wald</surname><given-names>LL</given-names></name><name><surname>Dale</surname><given-names>AM</given-names></name><name><surname>Rosen</surname><given-names>BR</given-names></name><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Livingstone</surname><given-names>MS</given-names></name><name><surname>Orban</surname><given-names>GA</given-names></name><name><surname>Tootell</surname><given-names>RBH</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Stereopsis activates V3A and caudal intraparietal areas in macaques and humans</article-title><source>Neuron</source><volume>39</volume><fpage>555</fpage><lpage>568</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(03)00459-8</pub-id><pub-id pub-id-type="pmid">12895427</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsutsui</surname><given-names>K</given-names></name><name><surname>Jiang</surname><given-names>M</given-names></name><name><surname>Yara</surname><given-names>K</given-names></name><name><surname>Sakata</surname><given-names>H</given-names></name><name><surname>Taira</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Integration of perspective and disparity cues in surface-orientation-selective neurons of area CIP</article-title><source>Journal of Neurophysiology</source><volume>86</volume><fpage>2856</fpage><lpage>2867</lpage><pub-id pub-id-type="doi">10.1152/jn.2001.86.6.2856</pub-id><pub-id pub-id-type="pmid">11731542</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsutsui</surname><given-names>K-I</given-names></name><name><surname>Sakata</surname><given-names>H</given-names></name><name><surname>Naganuma</surname><given-names>T</given-names></name><name><surname>Taira</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Neural correlates for perception of 3D surface orientation from texture gradient</article-title><source>Science</source><volume>298</volume><fpage>409</fpage><lpage>412</lpage><pub-id pub-id-type="doi">10.1126/science.1074128</pub-id><pub-id pub-id-type="pmid">12376700</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsutsui</surname><given-names>K-I</given-names></name><name><surname>Jiang</surname><given-names>M</given-names></name><name><surname>Sakata</surname><given-names>H</given-names></name><name><surname>Taira</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Short-term memory and perceptual decision for three-dimensional visual features in the caudal intraparietal sulcus (area CIP)</article-title><source>The Journal of Neuroscience</source><volume>23</volume><fpage>5486</fpage><lpage>5495</lpage><pub-id pub-id-type="pmid">12843248</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Dromme</surname><given-names>IC</given-names></name><name><surname>Premereur</surname><given-names>E</given-names></name><name><surname>Verhoef</surname><given-names>BE</given-names></name><name><surname>Vanduffel</surname><given-names>W</given-names></name><name><surname>Janssen</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Posterior parietal cortex drives inferotemporal activations during three-dimensional object vision</article-title><source>PLOS Biology</source><volume>14</volume><elocation-id>e1002445</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.1002445</pub-id><pub-id pub-id-type="pmid">27082854</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Essen</surname><given-names>DC</given-names></name><name><surname>Lewis</surname><given-names>JW</given-names></name><name><surname>Drury</surname><given-names>HA</given-names></name><name><surname>Hadjikhani</surname><given-names>N</given-names></name><name><surname>Tootell</surname><given-names>RB</given-names></name><name><surname>Bakircioglu</surname><given-names>M</given-names></name><name><surname>Miller</surname><given-names>MI</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Mapping visual cortex in monkeys and humans using surface-based atlases</article-title><source>Vision Research</source><volume>41</volume><fpage>1359</fpage><lpage>1378</lpage><pub-id pub-id-type="doi">10.1016/s0042-6989(01)00045-1</pub-id><pub-id pub-id-type="pmid">11322980</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeki</surname><given-names>S</given-names></name></person-group><year iso-8601-date="1980">1980</year><article-title>A direct projection from area V1 to area V3A of rhesus monkey visual cortex</article-title><source>PNAS</source><volume>207</volume><fpage>499</fpage><lpage>506</lpage><pub-id pub-id-type="doi">10.1098/rspb.1980.0038</pub-id><pub-id pub-id-type="pmid">6104816</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zohary</surname><given-names>E</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name><name><surname>Newsome</surname><given-names>WT</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Correlated neuronal discharge rate and its implications for psychophysical performance</article-title><source>Nature</source><volume>370</volume><fpage>140</fpage><lpage>143</lpage><pub-id pub-id-type="doi">10.1038/370140a0</pub-id><pub-id pub-id-type="pmid">8022482</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><p>Here, we show that the discrimination index is invariant to linear transformations of the neuronal responses using the example of z-scoring. The discrimination index is defined as<disp-formula id="equ4">.<mml:math id="m4"><mml:mrow><mml:mi>D</mml:mi><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mtext> </mml:mtext><mml:mfrac><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mtext> </mml:mtext><mml:mo>+</mml:mo><mml:mtext> </mml:mtext><mml:mn>2</mml:mn><mml:msqrt><mml:mfrac><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mfrac></mml:msqrt></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p> <p>where <inline-formula><mml:math id="inf12"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf13"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> are the maximum and minimum mean responses across the tuning curve, <italic>SSE</italic> is the sum squared error around the mean responses for each condition, <inline-formula><mml:math id="inf14"><mml:mi>N</mml:mi></mml:math></inline-formula> is the total number of trials, and <inline-formula><mml:math id="inf15"><mml:mi>M</mml:mi></mml:math></inline-formula> is the number of conditions.</p><p>The z-score transformation is defined as<disp-formula id="equ5">.<mml:math id="m5"><mml:mi>Z</mml:mi><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>σ</mml:mi></mml:mrow></mml:mfrac></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf16"><mml:mi>x</mml:mi></mml:math></inline-formula> is the observed value, <italic>µ</italic> is the sample mean, and <inline-formula><mml:math id="inf17"><mml:mi>σ</mml:mi></mml:math></inline-formula> is the sample standard deviation. We define <inline-formula><mml:math id="inf18"><mml:mi>D</mml:mi><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>Z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> as the discrimination index of the z-scored responses:<disp-formula id="equ6"><mml:math id="m6"><mml:mrow><mml:mi>D</mml:mi><mml:msub><mml:mi>I</mml:mi><mml:mrow><mml:mi>Z</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac></mml:mrow><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mi>μ</mml:mi></mml:mrow><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>+</mml:mo><mml:mi>Z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mfrac><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mfrac></mml:msqrt></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>σ</mml:mi><mml:mo>⋅</mml:mo><mml:mi>Z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mfrac><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mfrac></mml:msqrt></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula></p><p>Thus, if <inline-formula><mml:math id="inf19"><mml:mi>Z</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mfrac><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mfrac></mml:msqrt></mml:mrow></mml:mfenced></mml:math></inline-formula> = <inline-formula><mml:math id="inf20"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>⋅</mml:mo><mml:mn>2</mml:mn><mml:msqrt><mml:mfrac><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mfrac></mml:msqrt></mml:mrow></mml:mstyle></mml:math></inline-formula> , then <inline-formula><mml:math id="inf21"><mml:mi>D</mml:mi><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:mi>D</mml:mi><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>Z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> . The <inline-formula><mml:math id="inf22"><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:math></inline-formula> is given by<disp-formula id="equ7"><mml:math id="m7"><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mi> </mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mrow><mml:mi> </mml:mi></mml:mrow></mml:mrow><mml:msup><mml:mrow><mml:mfenced separators="|"><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf23"><mml:mi>M</mml:mi></mml:math></inline-formula> is the total number of conditions, <inline-formula><mml:math id="inf24"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the number of trials for the <italic>i</italic>th condition, <inline-formula><mml:math id="inf25"><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the response for the <italic>i</italic>th condition and <italic>j</italic>th trial, and <inline-formula><mml:math id="inf26"><mml:msub><mml:mrow><mml:mi>μ</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is the mean response for the <italic>i</italic>th condition. Since <inline-formula><mml:math id="inf27"><mml:mrow><mml:munderover><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> ,<disp-formula id="equ8"><mml:math id="m8"><mml:mrow><mml:mi>Z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mfrac><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mfrac></mml:msqrt></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>Z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mfrac><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mtext> </mml:mtext><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mtext> </mml:mtext><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mfrac></mml:msqrt></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula><disp-formula id="equ9"><mml:math id="m9"><mml:mrow><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:msqrt><mml:mfrac><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mtext> </mml:mtext><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mtext> </mml:mtext><mml:mfrac><mml:mn>1</mml:mn><mml:msup><mml:mi>σ</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mfrac></mml:msqrt><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>⋅</mml:mo><mml:mn>2</mml:mn><mml:msqrt><mml:mfrac><mml:mrow><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:munderover><mml:mtext> </mml:mtext><mml:munderover><mml:mo movablelimits="false">∑</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:munderover><mml:mtext> </mml:mtext><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>R</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mi>μ</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mfrac></mml:msqrt></mml:mrow></mml:math></disp-formula></p><p>Thus, <inline-formula><mml:math id="inf28"><mml:mi>Z</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mn>2</mml:mn><mml:msqrt><mml:mfrac><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>-</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mfrac></mml:msqrt></mml:mrow></mml:mfenced></mml:math></inline-formula> reduces to <inline-formula><mml:math id="inf29"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>σ</mml:mi></mml:mfrac><mml:mo>⋅</mml:mo><mml:mn>2</mml:mn><mml:msqrt><mml:mfrac><mml:mrow><mml:mi>S</mml:mi><mml:mi>S</mml:mi><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>N</mml:mi><mml:mo>−</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mfrac></mml:msqrt></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf30"><mml:mi>D</mml:mi><mml:mi>I</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>Z</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>.</p></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.78712.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Freedman</surname><given-names>David J</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/024mw5h28</institution-id><institution>The University of Chicago</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><related-object id="sa0ro1" object-id-type="id" object-id="10.1101/2022.03.22.485287" link-type="continued-by" xlink:href="https://sciety.org/articles/activity/10.1101/2022.03.22.485287"/></front-stub><body><p>This study compares the neuronal activity of two interconnected cortical areas in the dorsal visual pathway, V3A and CIP, during perceptual decisions based on judging the tilt of 3D visual patterns. This is a novel comparison between neural activity in these two cortical areas during perceptual decisions and gives insight into the hierarchical relationship and roles of these two areas. CIP shows higher-order spatial representations and more choice-correlated responses. Furthermore, the study finds modulation of V3A activity by extraretinal factors, suggesting that V3A be better characterized as contributing to higher-order behavioral functions as opposed to low-level visual feature processing.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.78712.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Freedman</surname><given-names>David J</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/024mw5h28</institution-id><institution>The University of Chicago</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Janssen</surname><given-names>Peter</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05f950310</institution-id><institution>KU Leuven</institution></institution-wrap><country>Belgium</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: (i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2022.03.22.485287">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2022.03.22.485287v1">the preprint</ext-link> for the benefit of readers; (ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Parallel processing, hierarchical transformations, and sensorimotor associations along the 'where' pathway&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Joshua Gold as the Senior Editor. The following individual involved in the review of your submission has agreed to reveal their identity: Peter Janssen (Reviewer #3).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>(1) R1: The manuscript should provide more information and analysis of behavioral performance in V3A and CIP sessions, to address the possibility that any differences in neuronal results observed between areas can be explained based on the performance of the animals.</p><p>(2) R1: The methods should be expanded to include additional information about the sequence and timing of V3A and CIP experimental sessions. For example, were all CIP sessions conducted first followed by V3A sessions, or were they interleaved?</p><p>(3) R1: The overall presentation of the results would be improved by adding information about the animal to animal variability in the results, and clarifying whether examples are shown from different animals (e.g. Figures 1, 2, 3)</p><p>4) R1: The presentation of results and rationale for pooling data between animals can be improved as described by point #4 from reviewer 1.</p><p>(5) R1: Regarding the analysis of presaccadic activity in V3A, it would be good to show that the results are robust to the assumptions and parameters of the analysis and justify the use of ANOVA as the statistical test.</p><p>6. R2 questions using the visually guided saccade to dissociate visual and saccade-related responses. The approach should be clarified regarding how &quot;CIP time courses approximately coalesced&quot;.</p><p>7. R2: The discrimination index should be described more clearly, including understanding what kind of index values are expected under different conditions.</p><p>8. R2 suggests clarifying the section entitled, &quot;Hierarchical refinement of 3D pose representation.&quot;</p><p>9. R2 suggests refining and clarifying the analysis of choice-related activity by assessing the amount of behavioral bias in the monkeys' choices.</p><p>(10) It is suggested by R3 to temper claims that the results are strong evidence for a hierarchical relationship between the two brain areas, and to place more emphasis on the novel results of pre-saccadic activity in V3A.</p><p>11) R3 recommends dropping statements regarding the conflict between anatomical and functional data, as it is not judged to be critical for the current study.</p><p>12) R3: Clarify whether the difference in timing of the onset of choice activity is significantly different between CIP and V3A.</p><p><italic>Reviewer #1 (Recommendations for the authors):</italic></p><p>The study would benefit from additional details about the experimental methods to understand the temporal relationship between recordings from V3A and CIP. Revisions to the analysis approach, as well as breaking down the analysis and results on a per animal basis, would strengthen the study as well.</p><p>(1) The CIP and V3a data were obtained from different recording sessions. The manuscript should provide more information and analysis of behavioral performance in V3A and CIP sessions, to address the possibility that any differences in neuronal results observed between areas can be explained based on the performance of the animals.</p><p>(2) Related to the comment above, additional information about the sequence and timing of V3A and CIP sessions should be included in the manuscript. For example, were all CIP sessions conducted first followed by V3A sessions, or were they interleaved?</p><p>(3) A general comment regarding the presentation of the results is that there is a notable lack of information about the animal to animal variability in the results, and in many cases, data is shown for only one animal or is not specified regarding whether data from multiple animals are shown.</p><p>(3a) Figures 1 &amp; 2 show imaging and behavioral data for only one of the monkeys. In both cases, data/results should be shown for all animals.</p><p>(3b) In figure 3, it should be made clear which animals each of the single neuron examples are from.</p><p>4) Related to point 3 – for many (but not all) of the population level analyses, data is apparently combined across animals and stats reported on the pooled data. This is not unusual and generally fine, but appropriate tests need to be done and reported regarding whether results were consistent between animals, and how they differ. It is not clear what rationale is being followed to determine which analyses are reported separately for each animal, and which are from pooled data. Also, it should be reported whether findings were statistically significant within each animal, or only when data is combined across animals. The study has recorded sizeable populations of neurons within each animal and brain area, so the data seems likely to support a more granular level of analysis animal by animal.</p><p>(5) Regarding the analysis of presaccadic activity in V3A, it would be good to show that the results are robust to the assumptions and parameters of the analysis. For example, picking the divergence time based on an ANOVA at P&lt;0.05 seems like a liberal criterion that could be prone to noise. Also, given the parametric tuning, is ANOVA really the most appropriate choice for a test?</p><p><italic>Reviewer #2 (Recommendations for the authors):</italic></p><p>I have a few suggestions to make, which I think, would improve the article and its clarity.</p><p>1. As stated in the public review, I don't think visually guided saccades allow you to dissociate from visual and saccade-related responses. Moreover, I don't understand how you compute how &quot;CIP time courses approximately coalesced&quot;.</p><p>2. I think the rationale between DI and how they behave could be better explained. I am not sure I truly understand how it is supposed to behave with different levels of response relative to different variability.</p><p>3. I'm a bit confused by the paragraph named Hierarchical refinement of 3D pose representation. Here you show that 3D orientation tuning is less distance dependent in CIP than in V3a (Figure 4a). I don't understand what is the difference with the following analysis of angular deviation.</p><p>4. In the analysis of choice-related activity, you focus on trials with 0 degrees tilt and use animals' behavior to infer how they interpret these ambiguous stimuli. The analysis you propose assumes that animals' choices are evenly distributed among the 8 possible directions. Are animals biased-free?</p><p><italic>Reviewer #3 (Recommendations for the authors):</italic></p><p>I am not convinced that the correspondence between the integrated V3A time courses and the CIP time courses really reflects a parallel hierarchy. It is also possible that these presaccadic signals originating from a higher area arrive differently in the two areas. In any case, the manuscript would be improved if the authors would de-emphasize and maybe reduce the first part of the results, and highlight more the novel results on pre-saccadic activity in V3A.</p><p>The authors try to rescue the fact that many results are expected by suggesting an apparent conflict between anatomical and functional data, but the lower selectivity for 3D orientation in CIP compared to V3A as reported in the Elmore study is a very small effect (SODI of 0.63 vs 0.68) with a small sample of V3A neurons which could be explained by other experimental factors. I would strongly recommend dropping these statements in the introduction and discussion (also on p.9) since it is not really necessary for this study.</p><p>It is not clear whether the difference in timing of the onset of choice activity is significantly different between CIP and V3A.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.78712.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) R1: The manuscript should provide more information and analysis of behavioral performance in V3A and CIP sessions, to address the possibility that any differences in neuronal results observed between areas can be explained based on the performance of the animals.</p></disp-quote><p>This is an excellent point that was not addressed in the first submission. We updated the analysis to test for a difference in performance between the V3A and CIP sessions. The analysis confirmed that there was no significant difference in performance between these sessions (lines: 143-149).</p><disp-quote content-type="editor-comment"><p>(2) R1: The methods should be expanded to include additional information about the sequence and timing of V3A and CIP experimental sessions. For example, were all CIP sessions conducted first followed by V3A sessions, or were they interleaved?</p></disp-quote><p>As suggested, we now report the sequence of the V3A and CIP recording sessions (lines: 898-901). Briefly, we first performed 41 V3A sessions (Monkeys L and F), then all 53 CIP sessions (Monkeys L and F), and then 50 additional V3A sessions (Monkeys L, F, and W).</p><disp-quote content-type="editor-comment"><p>(3) R1: The overall presentation of the results would be improved by adding information about the animal to animal variability in the results, and clarifying whether examples are shown from different animals (e.g. Figures 1, 2, 3)</p></disp-quote><p>We completely agree. For all main analyses, we added statistics for each animal to complement the population results. Where relevant, we now discuss between-animal variability (which was minimal). Analyses that distinguished whether neurons carried choice-related activity were performed at the population-level only because some of the individual sample sizes became rather small (see lines: 399-402). We now indicate from which animal each example neuron came (lines: 192-193).</p><disp-quote content-type="editor-comment"><p>4) R1: The presentation of results and rationale for pooling data between animals can be improved as described by point #4 from reviewer 1.</p></disp-quote><p>We agree that this was not clear in the first submission. To clarify, we ran behavioral analyses as well as comparisons between the behavioral and neuronal responses separately for each animal. The neuronal analyses were run at the population level. As indicated in our response to comment #3, the resubmission includes neuronal analyses for the individual animals as well as pooled across animals.</p><disp-quote content-type="editor-comment"><p>(5) R1: Regarding the analysis of presaccadic activity in V3A, it would be good to show that the results are robust to the assumptions and parameters of the analysis and justify the use of ANOVA as the statistical test.</p></disp-quote><p>We thank the reviewer for bringing up this point. In the first submission, we did not clearly indicate that the onset time was defined as the first time point at which the time courses significantly diverge (ANOVA, p &lt; 0.05) for at least 30 consecutive ms. The 30 ms criterion is widely used when calculating latencies because it makes the estimates more conservative and eliminates false positives. We have clarified this in the Materials and methods section (lines: 937-940 and 994-995).</p><p>We further verified the robustness of the results in two ways. First, we recalculated the onset of choice- and saccade-related activity using an ANOVA with more conservative parameters (significance values of 0.01, 0.001, and 0.0001). As expected, the onsets shifted to later times, but always by roughly equal amounts in V3A and CIP. In all cases the cross-area latency difference was within 2 ms of the reported difference, and the conclusions regarding the cross-area differences never changed. Second, we recalculated the onset of choice- and saccade-related activity using a Kruskal-Wallis test (nonparametric). In all cases, the onset times were within 3 ms of the times calculated using an ANOVA, and the conclusions regarding the cross-area differences did not change.</p><p>We also used an ANOVA to test if the responses of individual neurons depended on the saccade direction, which allowed for a direct comparison with previous work. Using a Kruskal-Wallis test (nonparametric), the classification (tuned vs. not tuned) was the same for 1053/1129 (93%) of the neurons. Additionally, we note that the saccade direction tuning curves of neurons with significant tuning were well described by von Mises functions (mean r = 0.92 ± 0.47x10<sup>-3</sup> SEM), which would not be expected if they were not accurately classified using the ANOVA.</p><disp-quote content-type="editor-comment"><p>6. R2 questions using the visually guided saccade to dissociate visual and saccade-related responses. The approach should be clarified regarding how &quot;CIP time courses approximately coalesced&quot;.</p></disp-quote><p>This is an important point which should have been addressed more thoroughly in the first submission. In the resubmission, we discuss that the current study cannot unambiguously distinguish the contributions of visual and presaccadic activity to the observed saccade-related activity (lines: 733-734). To be more agnostic about the possibility of presaccadic activity and to match the terminology used in Chang et al. (2020b), we now use the term “saccade-related activity”. We also added a supplemental figure which shows that the saccade-related activity follows a distinct time course from the visual flash responses measured during receptive field mapping (Figure 8―figure supplement 1). In the Discussion, we additionally highlight that several of the findings suggest that the observed saccade-related activity cannot be attributed to visual responses, and that future experiments will be required to thoroughly dissociate the contributions of visual and presaccadic activity in V3A/CIP (lines: 735-745).</p><p>In the Results section (lines: 565-566), we added additional pointers to the Materials and methods section (lines: 1003-1007) where we describe how we calculated the coalescent points for both the V3A and CIP time courses. At the same locations, we reference Chang et al. (2020b) which also used this method.</p><disp-quote content-type="editor-comment"><p>7. R2: The discrimination index should be described more clearly, including understanding what kind of index values are expected under different conditions.</p></disp-quote><p>As suggested, we expanded the description of the discrimination index (DI) to clarify its interpretation and how the mean and variance of the neuronal responses together determine the value (lines: 256-257 and 949-951).</p><disp-quote content-type="editor-comment"><p>8. R2 suggests clarifying the section entitled, &quot;Hierarchical refinement of 3D pose representation.&quot;</p></disp-quote><p>We thank the reviewer for this suggestion. We have clarified that the two analyses in this section are complementary to one another in that they provide an assessment of how the overall shape of the orientation tuning curve depends on distance (Tolerance) and how the preferred orientation (independent of tuning bandwidth) depends on distance (lines: 312-334). Together, they provide convergent evidence of a transformation from lower-level visual feature selectivity in V3A to higher-level 3D object representations in CIP.</p><disp-quote content-type="editor-comment"><p>9. R2 suggests refining and clarifying the analysis of choice-related activity by assessing the amount of behavioral bias in the monkeys' choices.</p></disp-quote><p>This is an excellent point that we did not address in the first submission. We now report that each of the monkeys chose all targets in every session and provide summary statistics which show that the choice distributions were very broad. We further report that the session-by-session mean choices of the monkeys and the preferred choice directions of the neurons were not significantly correlated for any monkey, suggesting that their choices were not associated with the neuronal choice preferences (lines: 980-985).</p><disp-quote content-type="editor-comment"><p>(10) It is suggested by R3 to temper claims that the results are strong evidence for a hierarchical relationship between the two brain areas, and to place more emphasis on the novel results of pre-saccadic activity in V3A.</p></disp-quote><p>This is a great point. As suggested, we tempered our interpretation of the differences in saccade-related activity between V3A and CIP as evidence of a hierarchy and focus more on the novel result of saccade-related activity in V3A.</p><disp-quote content-type="editor-comment"><p>(11) R3 recommends dropping statements regarding the conflict between anatomical and functional data, as it is not judged to be critical for the current study.</p></disp-quote><p>We agree that this point is secondary to the goals of the study and removed all such statements.</p><disp-quote content-type="editor-comment"><p>(12) R3: Clarify whether the difference in timing of the onset of choice activity is significantly different between CIP and V3A.</p></disp-quote><p>To statistically compare the V3A and CIP onsets of choice- and saccade-related activity at the population level, it was necessary to perform permutation tests based on bootstrapped values. These individual statistics were not significant, but the latency differences were highly consistent across all domains, supporting the proposed hierarchy. We now highlight in the Discussion that V3A activity preceded CIP activity by a similar amount in every domain: visual onset (6 ms; lines: 710-712), choice-related activity onset (11 ms; lines: 793-794), saccade-related activity onset aligned to the saccade initiation (6 ms; lines: 717-719), and inflection point in the time course of the saccade-related activity aligned to the target onset (7 ms; lines: 737-739). Notably, these analyses were performed using different neuronal subpopulations and experimental trials, providing convergent evidence of a V3A to CIP hierarchy.</p></body></sub-article></article>