<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN"  "JATS-archivearticle1-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.2"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">73276</article-id><article-id pub-id-type="doi">10.7554/eLife.73276</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational and Systems Biology</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>The geometry of robustness in spiking neural networks</article-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes" id="author-192551"><name><surname>Calaim</surname><given-names>Nuno</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-0317-3276</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-210482"><name><surname>Dehmelt</surname><given-names>Florian A</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0001-6135-4652</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" equal-contrib="yes" id="author-177423"><name><surname>Gonçalves</surname><given-names>Pedro J</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6987-4836</contrib-id><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="aff" rid="aff5">5</xref><xref ref-type="fn" rid="equal-contrib1">†</xref><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf2"/></contrib><contrib contrib-type="author" corresp="yes" id="author-41002"><name><surname>Machens</surname><given-names>Christian K</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-1717-1562</contrib-id><email>christian.machens@neuro.fchampalimaud.org</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund2"/><xref ref-type="other" rid="fund1"/><xref ref-type="fn" rid="con4"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03g001n57</institution-id><institution>Champalimaud Neuroscience Programme, Champalimaud Foundation</institution></institution-wrap><addr-line><named-content content-type="city">Lisbon</named-content></addr-line><country>Portugal</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00pjgxh97</institution-id><institution>Centre for Integrative Neuroscience, Tübingen University Hospital</institution></institution-wrap><addr-line><named-content content-type="city">Tübingen</named-content></addr-line><country>Germany</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05350h943</institution-id><institution>Center of Advanced European Studies and Research (CAESAR)</institution></institution-wrap><addr-line><named-content content-type="city">Bonn</named-content></addr-line><country>Germany</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02kkvpp62</institution-id><institution>Computational Neuroengineering, Department of Electrical and Computer Engineering, Technical University of Munich</institution></institution-wrap><addr-line><named-content content-type="city">Munich</named-content></addr-line><country>Germany</country></aff><aff id="aff5"><label>5</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/03a1kwz48</institution-id><institution>Machine Learning in Science, Excellence Cluster ‘Machine Learning’, Tübingen University</institution></institution-wrap><addr-line><named-content content-type="city">Tübingen</named-content></addr-line><country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Meister</surname><given-names>Markus</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05dxps055</institution-id><institution>California Institute of Technology</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Frank</surname><given-names>Michael J</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05gq02987</institution-id><institution>Brown University</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><author-notes><fn fn-type="con" id="equal-contrib1"><label>†</label><p>These authors contributed equally to this work</p></fn></author-notes><pub-date publication-format="electronic" date-type="publication"><day>30</day><month>05</month><year>2022</year></pub-date><pub-date pub-type="collection"><year>2022</year></pub-date><volume>11</volume><elocation-id>e73276</elocation-id><history><date date-type="received" iso-8601-date="2021-08-23"><day>23</day><month>08</month><year>2021</year></date><date date-type="accepted" iso-8601-date="2022-05-22"><day>22</day><month>05</month><year>2022</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint at bioRxiv.</event-desc><date date-type="preprint" iso-8601-date="2020-06-15"><day>15</day><month>06</month><year>2020</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2020.06.15.148338"/></event></pub-history><permissions><copyright-statement>© 2022, Calaim, Dehmelt, Gonçalves et al</copyright-statement><copyright-year>2022</copyright-year><copyright-holder>Calaim, Dehmelt, Gonçalves et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-73276-v2.pdf"/><abstract><p>Neural systems are remarkably robust against various perturbations, a phenomenon that still requires a clear explanation. Here, we graphically illustrate how neural networks can become robust. We study spiking networks that generate low-dimensional representations, and we show that the neurons’ subthreshold voltages are confined to a convex region in a lower-dimensional voltage subspace, which we call a 'bounding box'. Any changes in network parameters (such as number of neurons, dimensionality of inputs, firing thresholds, synaptic weights, or transmission delays) can all be understood as deformations of this bounding box. Using these insights, we show that functionality is preserved as long as perturbations do not destroy the integrity of the bounding box. We suggest that the principles underlying robustness in these networks — low-dimensional representations, heterogeneity of tuning, and precise negative feedback — may be key to understanding the robustness of neural systems at the circuit level.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>spiking neural networks</kwd><kwd>robustness</kwd><kwd>neural coding</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>None</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001871</institution-id><institution>Fundação para a Ciência e a Tecnologia</institution></institution-wrap></funding-source><award-id>FCT-PTDC/BIA-OUT/32077/2017-IC&amp;DT-LISBOA-01-0145-FEDER</award-id><principal-award-recipient><name><surname>Machens</surname><given-names>Christian K</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000893</institution-id><institution>Simons Foundation</institution></institution-wrap></funding-source><award-id>543009</award-id><principal-award-recipient><name><surname>Machens</surname><given-names>Christian K</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001871</institution-id><institution>Fundação para a Ciência e a Tecnologia</institution></institution-wrap></funding-source><award-id>SFRH / BD / 52217 / 2013</award-id><principal-award-recipient><name><surname>Calaim</surname><given-names>Nuno</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Spiking neural networks become robust to various perturbations of their parameters if their voltages are confined to a lower-dimensional subspace, and both dynamics and robustness can be visualised in this voltage subspace.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>The ability to maintain functionality despite perturbations is one of the defining properties of biological systems, from molecular signaling pathways to whole ecosystems (<xref ref-type="bibr" rid="bib15">Csete and Doyle, 2002</xref>; <xref ref-type="bibr" rid="bib33">Kitano, 2004</xref>; <xref ref-type="bibr" rid="bib59">Whitacre, 2012</xref>; <xref ref-type="bibr" rid="bib22">Félix and Barkoulas, 2015</xref>). Neural systems likewise withstand a certain amount of damage or external disturbances, which is evident from lesion studies or neurodegenerative diseases (<xref ref-type="bibr" rid="bib43">Morrison and Hof, 1997</xref>; <xref ref-type="bibr" rid="bib9">Bredesen et al., 2006</xref>; <xref ref-type="bibr" rid="bib46">Palop et al., 2006</xref>), as well as from perturbation experiments (<xref ref-type="bibr" rid="bib61">Wolff and Ölveczky, 2018</xref>; <xref ref-type="bibr" rid="bib35">Li et al., 2016</xref>; <xref ref-type="bibr" rid="bib55">Trouche et al., 2016</xref>; <xref ref-type="bibr" rid="bib24">Fetsch et al., 2018</xref>). However, the mechanisms that underlie this robustness are not entirely clear. Indeed, most models of neural networks, when faced with partial damage, lose their functionality quite rapidly (<xref ref-type="fig" rid="fig1">Figure 1A–C</xref>; <xref ref-type="bibr" rid="bib51">Seung et al., 2000</xref>; <xref ref-type="bibr" rid="bib34">Koulakov et al., 2002</xref>; <xref ref-type="bibr" rid="bib35">Li et al., 2016</xref>). Beyond its biological interest, understanding the robustness of neural systems is also crucial for the correct interpretation of experiments that seek to manipulate neural circuits (<xref ref-type="bibr" rid="bib61">Wolff and Ölveczky, 2018</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Neural systems are robust against a variety of perturbations.</title><p>(<bold>A</bold>) Biological neural networks operate under multiple perturbations. (<bold>B</bold>) The degree of robustness of a system can fall into three regimes: 1. Catastrophic failure (red), when small changes in the conditions lead to quick loss of function for the system. 2. Gradual degradation (gray), when the system’s performance is gradually lost when departing from optimal conditions. 3. Robust operation (black), when the network is able to maintain its function for a range of perturbations. (<bold>C</bold>) Most rate- and spike-based network models fail to withstand even small perturbations. Shown here is a rate network (composed of <inline-formula><mml:math id="inf1"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>1000</mml:mn></mml:mrow></mml:math></inline-formula> neurons) trained with FORCE-learning to generate a two-dimensional oscillation (<xref ref-type="bibr" rid="bib52">Sussillo and Abbott, 2009</xref>). The performance of the trained network declines rapidly when exposed to a diverse set of perturbations. Other learning schemes yield similar results. (<bold>D</bold>) By contrast, a network in which neurons coordinate their firing to correct any errors is robust to several, even cumulative perturbations. Shown here is a spiking network composed of initially <inline-formula><mml:math id="inf2"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula> neurons, designed to generate a two-dimensional oscillation (<xref ref-type="bibr" rid="bib7">Boerlin et al., 2013</xref>). <italic>Top</italic>: Schematic of the various perturbations. Vertical lines indicate when a new perturbation is added. The diffusion coefficient of the injected voltage noise is more than 5% of the neuronal threshold magnitude. The perturbation of all synaptic weights is random and limited to 5%. <italic>Middle</italic>: Two-dimensional output, as decoded from the network activity. <italic>Bottom</italic>: Raster plot of the network’s spike trains.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-73276-fig1-v2.tif"/></fig><p>Robustness has sometimes been attributed to various single-cell mechanisms, such as those that stabilize the dynamics of the stomatogastric ganglion of crustaceans against temperature fluctuations (<xref ref-type="bibr" rid="bib45">O’Leary and Marder, 2016</xref>; <xref ref-type="bibr" rid="bib27">Haddad and Marder, 2018</xref>), or the oculomotor integrator against instabilities in positive feedback loops (<xref ref-type="bibr" rid="bib34">Koulakov et al., 2002</xref>; <xref ref-type="bibr" rid="bib26">Goldman et al., 2003</xref>). On the circuit-level, robustness has been tied to the excitatory-inhibitory (EI) balance of synaptic inputs, either by linking such balance with the efficiency of neural population codes (<xref ref-type="bibr" rid="bib7">Boerlin et al., 2013</xref>; <xref ref-type="bibr" rid="bib8">Bourdoukan et al., 2012</xref>; <xref ref-type="bibr" rid="bib2">Barrett et al., 2013</xref>), or by using it as a corrective feedback for integrator models (<xref ref-type="bibr" rid="bib36">Lim and Goldman, 2013</xref>). The corresponding spiking networks can maintain functional representations of their inputs by re-balancing when faced with perturbations such as neuron loss (<xref ref-type="bibr" rid="bib3">Barrett et al., 2016</xref>; <xref ref-type="bibr" rid="bib36">Lim and Goldman, 2013</xref>). <xref ref-type="fig" rid="fig1">Figure 1D</xref> illustrates such a robust, spiking network model.</p><p>Here, we illustrate how circuits can be made robust through simple geometric insights that tie the low-dimensional representations found in many population recordings (<xref ref-type="bibr" rid="bib49">Saxena and Cunningham, 2019</xref>; <xref ref-type="bibr" rid="bib32">Keemink and Machens, 2019</xref>; <xref ref-type="bibr" rid="bib58">Vyas et al., 2020</xref>) to the biophysics of neurons, such as their voltages, thresholds, and synaptic inputs. We therefore provide a principled theory on how networks may have become robust to the many perturbations encountered in nature. We use this theory to illustrate two effects. First, we show that the resulting robustness mechanisms include the balanced regime, but are not limited to it. Indeed, networks can be robust without exhibiting any EI balance. Second, we predict a surprising asymmetry to perturbations: we find that robust networks are insensitive to broad inhibitory perturbations, yet quite sensitive to small excitatory perturbations, even if the latter are restricted to single neurons in large networks. This heightened sensitivity may explain the ability of animals to recognize exceedingly small, excitatory perturbations (<xref ref-type="bibr" rid="bib29">Houweling and Brecht, 2008</xref>; <xref ref-type="bibr" rid="bib31">Huber et al., 2008</xref>; <xref ref-type="bibr" rid="bib17">Dalgleish et al., 2020</xref>).</p><p>Beyond questions of robustness, our work also provides a new way of thinking about spiking networks, which complements and extends classical approaches such as mean-field or attractor dynamics. To simplify our exposition, we focus on generic networks of integrate-and-fire neurons, rather than modeling a specific system. Consequently, we ignore part of the biological complexity (e.g. Dale’s law, more complex computations or dynamics), and defer explanations on how the framework may generalize to more realistic network models to the discussion and the methods.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>Our first assumption is that neural networks generate low-dimensional representations of sensory or motor signals, which can be extracted from the spike trains of a neural population through filtering and summation. Here, ‘low-dimensional’ simply means that the number of signals (or dimensions) represented is far less than the number of neurons in a circuit, so that there exists a certain amount of redundancy. Such redundant representations have been observed in many brain circuits (<xref ref-type="bibr" rid="bib49">Saxena and Cunningham, 2019</xref>; <xref ref-type="bibr" rid="bib32">Keemink and Machens, 2019</xref>), and are an integral part of most mid- to large-scale network models (<xref ref-type="bibr" rid="bib57">Vogels et al., 2005</xref>; <xref ref-type="bibr" rid="bib19">Eliasmith and Anderson, 2004</xref>; <xref ref-type="bibr" rid="bib1">Barak, 2017</xref>). However, they do not per se guarantee robustness as shown in an example network in <xref ref-type="fig" rid="fig1">Figure 1C</xref>.</p><sec id="s2-1"><title>Passive redundancy</title><p>A classical example of a redundant, but non-robust representation is a sensory layer of <inline-formula><mml:math id="inf3"><mml:mi>N</mml:mi></mml:math></inline-formula> independent neurons acting as feature detectors. Here, each neuron receives the same <inline-formula><mml:math id="inf4"><mml:mi>M</mml:mi></mml:math></inline-formula> time-varying input signals, <inline-formula><mml:math id="inf5"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mo>…</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. Each signal is weighted at a neuron’s synapse, and the resulting synaptic currents are then summed in the neuron’s soma. If the synaptic weights are chosen differently for different neurons, the population generates a distributed code, whose redundancy we define as the number of neurons per signal dimension, or <inline-formula><mml:math id="inf6"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>N</mml:mi><mml:mo>/</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. We will call this redundancy 'passive' as each neuron fires completely independent of what other neurons are doing.</p><p>While actual sensory systems are obviously more complex, this layer of independent feature detectors still serves as a useful baseline. For instance, in such a layer, perturbing a set of neurons by exciting or inhibiting them will have an effect on the representation that is directly proportional to the number of neurons perturbed. Passive redundancy therefore leads to a gradual decline of functionality (<xref ref-type="fig" rid="fig1">Figure 1B</xref>) or a gradual response of a system to any perturbation.</p></sec><sec id="s2-2"><title>Autoencoder with low-dimensional readouts</title><p>To create robustness to perturbations, neurons cannot act independently, but rather need to coordinate their firing. We will now consider an example network that is generating a sensory representation at the population level, such that this representation is optimal with respect to a given linear readout (<xref ref-type="fig" rid="fig2">Figure 2A</xref>). We will focus on this simple scenario in order to highlight the mechanisms that endow networks with robustness. In the Discussion and Materials and methods, we will point out how to transfer these insights to more general networks.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Toy example of a network with coordinated redundancy (<inline-formula><mml:math id="inf7"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> inputs and <inline-formula><mml:math id="inf8"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> neurons).</title><p>(<bold>A</bold>) The task of the network is to encode two input signals (black) into spike trains (colored), such that the two signals can be reconstructed by filtering the spike trains postsynaptically (with an exponential kernel), and weighting and summing them with a decoding weight matrix <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>B</bold>) A neuron’s spike moves the readout in a direction determined by its vector of decoding weights. When the readout is in the ’spike’ region, then a spike from the neuron decreases the signal reconstruction error. Outside of this region ('no spike' region), a spike would increase the error and therefore be detrimental. (<bold>C</bold>) Schematic diagram of one neuron. Inputs arrive from the top. The neuron’s voltage measures the difference between the weighted input signals and weighted readouts. (<bold>D</bold>) Simulation of one neuron tracking the inputs. As one neuron can only monitor a single error direction, the reconstructed signal does not correctly track the full two-dimensional signal (arrow). (<bold>E</bold>) Voltage of the neuron (green) and example trajectory of the readout (gray). The dashed green lines correspond to points in space for which neuron <inline-formula><mml:math id="inf10"><mml:mi>i</mml:mi></mml:math></inline-formula> has the same voltage (voltage isoclines). The example trajectory shows the decay of the readout until the threshold is reached (I), the jump caused by the firing of a spike (II), and the subsequent decay (III). (<bold>F</bold>) Same as C, but considering two different neurons. (<bold>G</bold>) Voltages and spikes of the two neurons. (<bold>H</bold>) Voltage of the orange neuron during the same example trajectory as in E. Note that the neuron’s voltage jumps during the firing of the spike from the green neuron. (<bold>I</bold>) The negative feedback of the readout can be equivalently implemented through lateral connectivity with a weight matrix <inline-formula><mml:math id="inf11"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold">Ω</mml:mi><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mspace width="-0.083em"/><mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. (<bold>J</bold>) Simulation of five neurons tracking the inputs. Neurons coordinate their spiking such that the readout units can reconstruct the input signals up to a precision given by the size of the error bounding box. (<bold>K</bold>) The network creates an error bounding box around <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. Whenever the network estimate <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> hits an edge of the box, the corresponding neuron emits a spike pushing the readout estimate back inside the box (colored arrows).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-73276-fig2-v2.tif"/></fig><p>Just as above, we consider a network of <inline-formula><mml:math id="inf14"><mml:mi>N</mml:mi></mml:math></inline-formula> neurons which receive an <inline-formula><mml:math id="inf15"><mml:mi>M</mml:mi></mml:math></inline-formula>-dimensional vector of input signals, <inline-formula><mml:math id="inf16"><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The task of the network is to be an autoencoder, that is, to generate spike trains such that the input signals can be read out by a downstream area. We assume a linear readout, which filters each spike train with an exponential filter, similar to the postsynaptic potentials generated in a single synapse. Then, the filtered spike trains are weighted and summed, similar to the passive summation in a dendritic tree. Formally, we write<disp-formula id="equ1"><label>(1)</label><mml:math id="m1"><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msub><mml:mi>D</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf17"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the filtered spike train of the <inline-formula><mml:math id="inf18"><mml:mi>k</mml:mi></mml:math></inline-formula>-th neuron, <inline-formula><mml:math id="inf19"><mml:mi>N</mml:mi></mml:math></inline-formula> is the number of neurons, <inline-formula><mml:math id="inf20"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>M</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the vector of readouts, distinguished from the input signals by a hat, and <inline-formula><mml:math id="inf21"><mml:mrow><mml:msub><mml:mi mathvariant="bold">D</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>M</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the decoding vector of the <inline-formula><mml:math id="inf22"><mml:mi>k</mml:mi></mml:math></inline-formula>-th neuron, whose individual elements contain the respective decoding weights.</p><p>We can depict the geometrical consequences of this decoding mechanism by imagining a network of five neurons that is encoding two signals. At a given point in time, we can illustrate both the input signals and the readout produced by the network as two points in signal space (<xref ref-type="fig" rid="fig2">Figure 2B</xref>, black cross and gray dot). Now let us imagine that one of the neurons, say neuron <italic>i</italic>, spikes. When that happens, the spike causes a jump in its filtered output spike train. In turn, and according to <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>, the vector of readouts, <inline-formula><mml:math id="inf23"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, jumps in the direction of the decoding vector, <inline-formula><mml:math id="inf24"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, as illustrated in <xref ref-type="fig" rid="fig2">Figure 2B</xref>. Since the direction and magnitude of this jump are determined by the fixed readout weights, they are independent of the past spike history or the current values of the readouts. After this jump, and until another neuron fires, all components of the readout will decay. Geometrically, this decay corresponds to a movement of the readout towards the origin of the coordinate system.</p></sec><sec id="s2-3"><title>Coordinated redundancy and the error bounding box</title><p>We furthermore assume that a neuron spikes only when its spike moves the readout closer to the desired signal, <inline-formula><mml:math id="inf25"><mml:mi mathvariant="bold">x</mml:mi></mml:math></inline-formula>. For each neuron, this spike rule divides the whole signal space into two regions: a 'spike' half-space where the readout error decreases if the neuron spikes, and a 'no-spike' half-space where the readout error increases if the neuron spikes (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). The boundary between these two half spaces is the neuron’s spiking threshold, as seen in signal space. Consequently, the neuron’s voltage, <inline-formula><mml:math id="inf26"><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>, must be at threshold, <inline-formula><mml:math id="inf27"><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>, whenever the readout reaches this boundary, and the voltage must be below or above threshold on either side of it. We therefore identify the neuron’s voltage with the geometric projection of the readout error onto the decoding vector of the neuron,<disp-formula id="equ2"><label>(2)</label><mml:math id="m2"><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where, without loss of generality, we have assumed that <inline-formula><mml:math id="inf28"><mml:msub><mml:mi mathvariant="bold">D</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> has unit length (see Materials and methods, 'Coordinated spiking and the bounding box'). The effect of this definition is illustrated in <xref ref-type="fig" rid="fig2">Figure 2E</xref>, where the voltage increases or decreases with distance to the boundary. Accordingly, the voltage measures part of the error, given here by the distance of the readout to the neuron’s boundary.</p><p>In addition to its functional interpretation, the voltage equation has a simple biophysical interpretation, as illustrated in <xref ref-type="fig" rid="fig2">Figure 2C</xref>. Here, the two input signals, <italic>x</italic><sub>1</sub> and <italic>x</italic><sub>2</sub>, get weighted by two synaptic weights, <inline-formula><mml:math id="inf29"><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf30"><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, leading to two postsynaptic voltages that are then summed in the dendritic tree of neuron <italic>i</italic>. At the same time, the two readouts, <inline-formula><mml:math id="inf31"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>1</mml:mn></mml:msub></mml:math></inline-formula> and <inline-formula><mml:math id="inf32"><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula>, are fed back into the neuron via two exactly opposite synaptic weights, <inline-formula><mml:math id="inf33"><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mn>1</mml:mn><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf34"><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, thereby giving rise to the required subtraction. As a consequence, the neuron’s voltage becomes the projection of the readout error, as prescribed above. When the neuron’s voltage reaches the voltage threshold, <inline-formula><mml:math id="inf35"><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>, the neuron fires a spike, which changes the readout, <inline-formula><mml:math id="inf36"><mml:mover accent="true"><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:math></inline-formula>. In turn, this change is fed back into the neuron’s dendritic tree and leads to an effective reset of the voltage after a spike, as shown in <xref ref-type="fig" rid="fig2">Figure 2D</xref>.</p><p>One neuron alone can only improve the readout along one specific direction in signal space and thus cannot correct the readout for all possible input signals (<xref ref-type="fig" rid="fig2">Figure 2D</xref>, arrow). To properly bound the error, we therefore need several neurons, and each neuron needs to mix the input signals in different ways. As a consequence, the error will be corrected along different directions in signal space. A second neuron, say neuron <italic>j</italic>, is added in <xref ref-type="fig" rid="fig2">Figure 2F–H</xref>. Following the logic above, its voltage is given by <inline-formula><mml:math id="inf37"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">D</mml:mi><mml:mi>j</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi><mml:mo>-</mml:mo><mml:mover accent="true"><mml:mi mathvariant="bold">x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, and the respective voltage isoclines are shown in <xref ref-type="fig" rid="fig2">Figure 2H</xref>. We see that the voltage of neuron <italic>j</italic> jumps when neuron <italic>i</italic> spikes. Mathematically, the size of this jump is simply given by the dot product of the two decoding vectors, <inline-formula><mml:math id="inf38"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">D</mml:mi><mml:mi>j</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathvariant="bold">D</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. Biophysically, such a jump could be caused by negative feedback through the readout units, but it could also arise through a direct synaptic connection between the two neurons, in which case <inline-formula><mml:math id="inf39"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">D</mml:mi><mml:mi>j</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathvariant="bold">D</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> corresponds to the synaptic weight from neuron <italic>i</italic> to neuron <italic>j</italic>.</p><p>Finally, if we add three more neurons, and give them different sets of decoding weights, the network as a whole can restrict the readout to a bounded region in signal space (a polygon in two dimensions), as shown in <xref ref-type="fig" rid="fig2">Figure 2I–K</xref>. We will call this bounded region the 'error bounding box' or simply the 'bounding box.' Its overall size determines the error tolerance of the network. To highlight the structure of this network, we can change <xref ref-type="disp-formula" rid="equ2">Equation 2</xref> by inserting the definition of the readout, <xref ref-type="disp-formula" rid="equ1">Equation 1</xref>, to obtain<disp-formula id="equ3"><label>(3)</label><mml:math id="m3"><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Here, the term <inline-formula><mml:math id="inf40"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">D</mml:mi><mml:mi>i</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathvariant="bold">D</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> can be interpreted as a lateral connection between neurons <italic>i</italic> and <italic>k</italic> in the network (<xref ref-type="fig" rid="fig2">Figure 2I</xref>). The diagonal elements of the respective connectivity matrix, <inline-formula><mml:math id="inf41"><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, can be interpreted as the hyperpolarization of the membrane voltage following a spike. While the connectivity of the network is symmetric, this assumption can be relaxed (see Materials and methods, 'Generalization of the bounding box II'). The connectivity term shows that information about the readout can be relayed through lateral connections and self-resets (<xref ref-type="fig" rid="fig2">Figure 2I</xref>), rather than through explicit negative feedback from a downstream layer. In either case, the feedback causes neurons to coordinate their firing. We will refer to this mechanism as 'coordinated spike coding' (<xref ref-type="bibr" rid="bib6">Boahen, 2017</xref>) or 'coordinated redundancy'.</p><p>As shown previously (<xref ref-type="bibr" rid="bib8">Bourdoukan et al., 2012</xref>; <xref ref-type="bibr" rid="bib7">Boerlin et al., 2013</xref>), the temporal derivative of the above equation yields a network of current-based, leaky integrate-and-fire neurons (see Materials and methods, 'Coordinated spiking and the bounding box'). We emphasize that there are two distinct situations that cause neurons to emit spikes. First, the readout always leaks towards the origin, and when it hits one of the boundaries, the appropriate neuron fires and resets the readout into the bounding box. Second, any change in the input signal, <inline-formula><mml:math id="inf42"><mml:mi mathvariant="bold">x</mml:mi></mml:math></inline-formula>, causes a shift of the entire bounding box, since the signal is always at the centre of the box. A sudden shift may therefore cause the readout to fall outside of the box, in which case neurons whose boundaries have been crossed will fire to get the readout back into the box.</p><p>When the signal dimensionality is increased to <inline-formula><mml:math id="inf43"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula>, the thresholds of the neurons become planes, and the bounding box is determined by the intersection of all planes, thereby becoming a three-dimensional object such as a soccer ball. We strongly recommend to view <xref ref-type="video" rid="video1">Video 1</xref> for an animation of the operation of the network in two and three dimensions, which highlights the relation between the bounding box and the resulting spike trains produced by the network.</p><media mimetype="video" mime-subtype="mp4" id="video1" xlink:href="elife-73276-video1.mp4"><label>Video 1.</label><caption><title>Normal operation of a network with two- or three-dimensional inputs.</title><p>Shown are an animation of the bounding box dynamics, the input signal and readout, and the spike trains produced by the network.</p></caption></media></sec><sec id="s2-4"><title>The bounding box limits the coding error</title><p>The maximum coding error is limited by the size of the error bounding box, simply because the readout cannot deviate from the signal beyond the borders of the box. The size of the box is determined by the neurons’ thresholds. For simplicity, we will assume that all thresholds are identical, which could be regulated through homeostatic mechanisms (<xref ref-type="bibr" rid="bib56">Turrigiano, 2012</xref>). The more general scenario is explained in Materials and methods, 'Generalization of the bounding box I'.</p><p>Beyond changing the maximum allowable coding error, the size of the error bounding box also influences the resulting code in more subtle ways. First, the coding error can be split into a systematic bias and random fluctuations (see <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1A</xref>). As the box becomes wider, the systematic bias increases. This bias can be largely eliminated by rescaling the readouts with a constant factor. We will sometimes use this corrected readout (see Materials and methods, 'Readout biases and corrections'), but note that the corrected readout is not confined to stay within the bounding box. Second, if the box becomes very narrow, the readout can eventually jump beyond the boundary of the opposite side, thereby crossing the threshold(s) of oppositely tuned neurons (see also <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1B–D</xref>). By default, we will assume that the bounding box is sufficiently wide to avoid this effect.</p><p>Finally, while the bounding box may seem like a fairly abstract construction, we note that it also has a simple, physical manifestation. Since the neurons’ voltages are constrained to live in an <inline-formula><mml:math id="inf44"><mml:mi>M</mml:mi></mml:math></inline-formula>-dimensional subspace, a constraint given by the input dimensionality, the error bounding box delineates the borders of this voltage subspace, which is illustrated in <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>.</p></sec><sec id="s2-5"><title>Robustness to inhibitory, sensitivity to excitatory perturbations</title><p>We will now study how the network reacts to perturbations by contrasting two example networks at opposite ends of a spectrum. In the first network, neurons are independent. For a two-dimensional signal, we obtain this scenario when the bounding box consists of four neurons forming a square (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, left), in which case neighbouring decoding vectors are orthogonal to each other, and their recurrent connections disappear (<inline-formula><mml:math id="inf45"><mml:mrow><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">D</mml:mi><mml:mi>i</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathvariant="bold">D</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, see also Materials and methods, 'Generalization of the bounding box III'). The second network consists of <inline-formula><mml:math id="inf46"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>21</mml:mn></mml:mrow></mml:math></inline-formula> randomly tuned neurons with equidistant thresholds, in which case the bounding box approximates the shape of a circle (<xref ref-type="fig" rid="fig3">Figure 3B</xref>, left).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Geometry of perturbations.</title><p>(<bold>A</bold>, left) A network of four independent neurons without redundancy. The bias-corrected, average readout (blue circle) is identical to the input signal (white cross). (A, right) When one neuron dies, the bounding box opens to one side, and the readout is no longer contained in the respective direction. In turn, the time-averaged readout moves to the right (blue dot) for the applied input signal (cross). (<bold>B</bold>) In a network of <inline-formula><mml:math id="inf47"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>21</mml:mn></mml:mrow></mml:math></inline-formula> neurons with coordinated redundancy (left), neural death has almost no impact on bounding box shape and decoding error (right). (<bold>C</bold>) In the network without redundancy, an increase (left) or decrease (right) in the excitability of one neuron changes the size of the box, but the box remains bounded on all sides. The corrected readout shifts slightly in both cases. (<bold>D</bold>) In the same network, increased excitability (left) has the same effect as in a non-redundant network, unless the box is reduced enough to trigger ping-pong (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1C–D</xref>). Decreased excitability (right) has virtually no effect. (<bold>E,F</bold>) If several neurons are perturbed simultaneously, their relative decoder tuning determines the effect. (E, left) Increasing the excitability of multiple, randomly chosen neurons has the same qualitative effect as the perturbation of a single neuron. However, in this case, the smaller box size pushes the corrected readout away from the origin of the signal space. (E, right) Decreasing the excitability of multiple neurons has little effect. (<bold>F</bold>) If neurons with similar tuning are targeted, both higher (left) and lower (right) excitability significantly alter the box shape and alter the corrected readout.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-73276-fig3-v2.tif"/></fig><p>The first perturbation we consider is the death of a single neuron. Throughout an organism’s life, cells, including neurons, can undergo the process of cell death or apoptosis if they are damaged or unfit, as may happen in diseased states (<xref ref-type="bibr" rid="bib42">Moreno et al., 2015</xref>; <xref ref-type="bibr" rid="bib43">Morrison and Hof, 1997</xref>; <xref ref-type="bibr" rid="bib9">Bredesen et al., 2006</xref>; <xref ref-type="bibr" rid="bib14">Coelho et al., 2018</xref>). Geometrically, the death of a neuron is equivalent to the removal of its corresponding face from the bounding box (<xref ref-type="fig" rid="fig3">Figure 3A and B</xref>, and <xref ref-type="video" rid="video2">Video 2</xref>). When the bounding box is breached on one side, the readout can no longer contain changes of the input signal along the open direction. This is precisely what happens in the case without redundancy (<xref ref-type="fig" rid="fig3">Figure 3A</xref>, right). In contrast, with coordinated redundancy, the removal of a single neuron has an almost imperceptible impact on the shape of the bounding box (<xref ref-type="fig" rid="fig3">Figure 3B</xref>, right). Consequently, the coding error remains bounded with essentially unchanged precision. The bounding box provides therefore a straightforward and intuitive explanation for the robustness against neuron loss observed in these spiking networks (<xref ref-type="bibr" rid="bib3">Barrett et al., 2016</xref>; <xref ref-type="bibr" rid="bib7">Boerlin et al., 2013</xref>).</p><media mimetype="video" mime-subtype="mp4" id="video2" xlink:href="elife-73276-video2.mp4"><label>Video 2.</label><caption><title>Operation of a network with two-dimensional inputs, under different perturbations, namely neural death, voltage noise, change in voltage resets, synaptic perturbations, delays, and inhibitory and excitatory optogenetic perturbations.</title><p>Shown are the bounding box, input signals and readouts, and the spike trains produced by the network.</p></caption></media><p>The second perturbation we consider is a change in the excitability of one neuron. Such a change could come about through an experimentally injected current, for example, via patch clamp or optogenetics, or because of intrinsic plasticity. In either case, a change in excitability is equivalent to a change in the neuron’s threshold (see Materials and methods, 'Perturbations'). Within the bounding box picture, an inhibitory perturbation or decrease in excitability leads to an outward shift of the neuron’s threshold, and an excitatory perturbation or increase in excitability leads to an inward shift (<xref ref-type="fig" rid="fig3">Figure 3C and D</xref>). Without redundancy, the bounding box expands or shrinks, respectively (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). At first sight, changing the box size increases or decreases the maximum error of the readout. More subtly, however, it also introduces a bias in the corrected average readout (<xref ref-type="fig" rid="fig3">Figure 3C</xref>, arrows). With coordinated redundancy, inhibitory and excitatory perturbations do not have opposite effects. Whereas an excitatory perturbation has an effect equivalent in size to a non-redundant system, as the threshold that is pushed inwards shrinks the box (<xref ref-type="fig" rid="fig3">Figure 3D</xref>, left), an inhibitory perturbation does not affect the system at all, because the outward shift of the threshold is compensated by the presence of other neurons (<xref ref-type="fig" rid="fig3">Figure 3D</xref>, right, see also <xref ref-type="video" rid="video2">Video 2</xref>). We note that a strong excitatory perturbation could cause the readout to move beyond the boundary of the opposite side, thereby leading to the undesirable 'ping-pong' effect (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>). This effect can be avoided if the bounding box is sufficiently wide.</p><p>In most experimental settings, one will perturb many neurons at once. We illustrate the effects of two such perturbations in <xref ref-type="fig" rid="fig3">Figure 3E and F</xref>. In <xref ref-type="fig" rid="fig3">Figure 3E</xref>, left, we excite six randomly selected neurons so that their boundaries are pushed inwards. As a consequence, the bounding box shrinks equally from all sides (<xref ref-type="fig" rid="fig3">Figure 3E</xref>, right). Just as in <xref ref-type="fig" rid="fig3">Figure 3D</xref>, left panel, the respective inward shifts cause (input-signal-dependent) biases in the corrected readout. In contrast, when we randomly inhibit neurons as in <xref ref-type="fig" rid="fig3">Figure 3E</xref>, right, the respective boundaries are pushed outwards. The bounding box barely changes, as the remaining neurons contain the readout error with essentially unchanged precision, and the system remains functional. In <xref ref-type="fig" rid="fig3">Figure 3F</xref>, we excite and inhibit neurons with similar tuning. In this case, the inhibitory perturbation is so large that there are no longer any neurons that can compensate. As a consequence, the bounding box expands in the perturbed direction and the corrected readout becomes biased, even for inhibitory perturbations.</p><p>In summary, we observe that coordinated redundancy endows the system with robustness against perturbations that act inhibitorily on the neurons, such as neuron death or increases in spiking thresholds. The function of the system remains intact until the bounding box breaks open. However, coordinated redundancy also makes the system highly sensitive towards any excitatory perturbations or decreases in spiking thresholds. Indeed, perturbing only a single neuron is sufficient to generate a change in the readout. These results contrast with passively redundant systems, whose representation changes gradually with either excitatory or inhibitory perturbations.</p><p>We note that there is circumstantial evidence that cortical systems are indeed highly sensitive to excitatory perturbations, and potentially less sensitive to inhibitory perturbations. For instance, animals can detect excitatory currents injected into a few pyramidal cells in somatosensory cortex (<xref ref-type="bibr" rid="bib29">Houweling and Brecht, 2008</xref>; <xref ref-type="bibr" rid="bib31">Huber et al., 2008</xref>; <xref ref-type="bibr" rid="bib17">Dalgleish et al., 2020</xref>). To our knowledge, no study has shown that cortical systems are similarly sensitive to inhibitory perturbations in one or a few neurons. Rather, several studies have shown that neural systems can compensate for inhibitory perturbations in a sizeable fraction of pyramidal cells (<xref ref-type="bibr" rid="bib35">Li et al., 2016</xref>; <xref ref-type="bibr" rid="bib24">Fetsch et al., 2018</xref>; <xref ref-type="bibr" rid="bib55">Trouche et al., 2016</xref>).</p></sec><sec id="s2-6"><title>The neurophysiological signatures of perturbations</title><p>Besides insights into a system’s functionality, the bounding box also allows us to see immediately how perturbations affect the firing of the unperturbed neurons. For instance, when we excite a single neuron, its threshold moves inwards (<xref ref-type="fig" rid="fig3">Figure 3D</xref>) and occludes the thresholds of the neighboring neurons, that is, neurons with similar selectivity. Since the readout can no longer reach these neurons, they stop firing, as shown in a simulation of the network in <xref ref-type="fig" rid="fig4">Figure 4A</xref>. Conversely, if we inhibit one or more neurons, their thresholds become hidden and they no longer participate in containing the readout (<xref ref-type="fig" rid="fig3">Figure 3D–F</xref>). As a consequence, the surrounding neurons have to pick up the bill and fire more, so that their firing rates will increase, as shown in <xref ref-type="fig" rid="fig4">Figure 4A</xref>. Biophysically, these effects are of course mediated by an increase or decrease of lateral or recurrent inhibition. However, the bounding box provides a simple visualization of the effect and its purpose.</p><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Neurophysiological signatures of perturbations.</title><p>(<bold>A</bold>) Asymmetric effects of excitatory and inhibitory perturbations. Shown are the two input signals (black lines), corrected readouts (gray lines), and spike trains (raster plot) during different perturbations (blue boxes). The excitation of a single neuron (blue arrows) is sufficient to perturb the readout. In contrast, the network remains fully functional when a random subset of neurons is inhibited. Here, the remaining neurons compensate for the loss by firing more spikes. However, a bias occurs when a sufficiently large set of similarly tuned and active neurons are inhibited. Here, the compensation of neighboring neurons is not sufficient to contain the error. (<bold>B</bold>) Network with low redundancy (<inline-formula><mml:math id="inf48"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> neurons and <inline-formula><mml:math id="inf49"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> signals). The left panel illustrates the bounding box, and the trajectory of the readouts, color-coded by changes due to the neuron’s spikes (green), the feedforward inputs (red) and the recurrent inputs (blue). The right panel shows the spikes of the network (top, green neuron highlighted), the input currents into the green neuron as a function of time (middle), and the difference between the synaptic excitatory and inhibitory input currents (bottom). In this example, the currents are dominated by excitatory feedforward inputs and self-reset currents, thereby causing a positive E-I difference. (<bold>C</bold>) Network with high redundancy (<inline-formula><mml:math id="inf50"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> neurons and <inline-formula><mml:math id="inf51"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> signals). Same format as (<bold>B</bold>). In this example, the feedforward currents are balanced by recurrent inputs of equal strength, but opposite sign. The recurrent inputs here replace the self-reset currents and correspond to input spikes of other neurons that have hit their respective thresholds, and take care of the coding error. As a consequence, the green neuron is tightly balanced. (<bold>D</bold>) Average normalized E-I difference and average coding error as a function of the redundancy <inline-formula><mml:math id="inf52"><mml:mi>ρ</mml:mi></mml:math></inline-formula> (color-coded). The average coding error remains low even in a regime where substantial parts of the population are already imbalanced.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-73276-fig4-v2.tif"/></fig><p>The bounding box also allows us to visualize the relation between EI balance and robustness. We can again study two extreme examples, as illustrated in <xref ref-type="fig" rid="fig4">Figure 4B and C</xref>. Here, both bounding boxes are intact and contain the readout. The box in <xref ref-type="fig" rid="fig4">Figure 4B</xref> has low redundancy (<inline-formula><mml:math id="inf53"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> neurons for <inline-formula><mml:math id="inf54"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> signals), whereas the box in <xref ref-type="fig" rid="fig4">Figure 4C</xref> has high redundancy (<inline-formula><mml:math id="inf55"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula> neurons for <inline-formula><mml:math id="inf56"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:math></inline-formula> signals). In turn, we can visualize the synaptic current balance in these boxes by highlighting how the movements of the readout give rise to excitatory or inhibitory currents.</p><p>In the low redundancy case, the readout initially decays, and thereby moves towards the threshold of one of the neurons (shown in green). A movement towards threshold corresponds to a depolarization of the respective membrane potential and therefore an excitatory (or dis-inhibitory) current, here illustrated in red. The respective neuron spikes, and the readout jumps away from the threshold, which is mediated by a hyperpolarizing self-reset current, here illustrated in green. Since the excitatory drive is cancelled by self-resets following spiking, the synaptic inputs are not balanced, and the neuron fires spikes in a relatively regular rhythm (<xref ref-type="fig" rid="fig4">Figure 4B</xref>, right panel, see Materials and methods, 'Excitation-inhibition balance').</p><p>The situation is quite different for the high-redundancy network (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). Here, the readout decays towards the thresholds of multiple neurons (some of which are highlighted with gray lines), but only one of these neurons will fire. When that happens, all neurons in the vicinity immediately receive inhibitory currents that signal the concomitant change in the readout. These inhibitory currents thereby cancel the excitatory feedforward drive, and the respective neurons experience a tight EI balance, leading to sparse and irregular spike trains (<xref ref-type="fig" rid="fig4">Figure 4C</xref>, left panel). We note that this tight balance only holds in the neurons that are sufficiently close to the neuron whose threshold is crossed. Neurons further away will experience only small current fluctuations, or will, on average, be hyperpolarized.</p><p>As a result, we see that EI balance occurs in networks that are sufficiently redundant, but not in networks with no or low redundancy. Nonetheless, even networks with low redundancy have a measure of robustness: for instance, the network in <xref ref-type="fig" rid="fig4">Figure 4B</xref> is robust against the loss of one neuron. While previous work has suggested that networks recover functionality when perturbed by dynamically re-establishing EI balance (<xref ref-type="bibr" rid="bib36">Lim and Goldman, 2013</xref>; <xref ref-type="bibr" rid="bib7">Boerlin et al., 2013</xref>; <xref ref-type="bibr" rid="bib3">Barrett et al., 2016</xref>), our considerations here show that robustness extends beyond the regime of EI balance. <xref ref-type="fig" rid="fig4">Figure 4D</xref> illustrates this result by contrasting the performance and balance of networks as a function of their redundancy.</p></sec><sec id="s2-7"><title>Scaling up</title><p>While the simple toy networks we have studied so far are useful for illustration and intuition, biological neural networks, and especially cortical networks, consist of thousands of neurons that are thought to represent hundreds of signals simultaneously. To get closer to the biological reality, we therefore also need to study larger and more powerful networks. As we have shown above, the features of networks are tightly linked to the shape of the bounding box. For three-dimensional input signals, the threshold of each neuron becomes a plane, and the bounding box becomes a polyhedron (see also <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3A</xref> and <xref ref-type="video" rid="video1">Video 1</xref>). For higher dimensional signals, the precise shape of the bounding box is hard to visualize. However, if we assume that the number of neurons scales linearly with the number of signal dimensions, <inline-formula><mml:math id="inf57"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>M</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, one can show that the resulting, higher dimensional bounding boxes are somewhat closer to a hypercube than a hypersphere. (Some insights on the geometry of such higher dimensional bounding boxes can be found in <xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3</xref>.)</p><p>In <xref ref-type="fig" rid="fig3">Figure 3</xref>, we saw that all bounding boxes are sensitive to excitatory perturbations, but that only no-redundancy (or very low-redundancy) bounding boxes are sensitive to inhibitory perturbations. A key question when scaling up is therefore whether larger networks with finite redundancy become sensitive to inhibitory perturbations, or whether they remain insensitive. An extreme form of inhibitory perturbation is the loss of neurons. <xref ref-type="fig" rid="fig5">Figure 5</xref> shows that, even in high dimensions, networks are robust against such perturbations. As before, we assume that the decoding vectors of the neurons <inline-formula><mml:math id="inf58"><mml:msub><mml:mi mathvariant="bold">D</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> are of similar length, but otherwise random, and that the thresholds of all neurons are the same. As the death or birth of random neurons simply corresponds to a change in the overall redundancy of the network, we can understand how network performance and statistics change by simply moving along the redundancy axis in <xref ref-type="fig" rid="fig5">Figure 5A–C</xref>. We observe that changing the redundancy over a broad range (<inline-formula><mml:math id="inf59"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>≈</mml:mo><mml:mrow><mml:mn>5</mml:mn><mml:mo>-</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>) has negligible effects on the performance (<xref ref-type="fig" rid="fig5">Figure 5A</xref>). This contrasts with networks of independent neurons in which performance scales linearly with any change in redundancy for a fixed readout. We furthermore observe that decreasing redundancy, leads to higher firing rates (<xref ref-type="fig" rid="fig5">Figure 5B</xref>) and more regular firing, or lower CVs (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). The decrease of CVs here simply reflects a decrease in the number of spike patterns that can represent the constant input signal, given the smaller pool of neurons in the network. In other words, when we kill neurons, the neural code becomes less redundant, and the spike patterns of individual neurons lose some of their apparent randomness. Conversely, as the network size increases, so does the number of possible spike patterns, with the consequent increase of CV. As the number of neurons keeps increasing, it becomes more and more likely that the network has neurons optimally tuned to a given input signal, contributing to a decrease of the CV. Therefore, the increase and subsequent decrease in CV with increasing redundancy is the result of these two counteracting effects (<xref ref-type="fig" rid="fig5">Figure 5C</xref>).</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Median coding errors, firing rates, and CVs as a function of network redundancy and input dimensionality.</title><p>All networks use random decoding vectors. (<bold>A</bold>) Most networks, except for very low redundancies, are able to correctly code for the signal. (<bold>B</bold>) Networks with low redundancy need to fire at higher rates, compared to networks with high redundancy, in order to keep the coding error in check. (<bold>C</bold>) Networks with low redundancy fire spikes in a more regular fashion (low CVs) compared to networks with high redundancy. Indeed, for networks with <inline-formula><mml:math id="inf60"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>≈</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula> and dimensionality <inline-formula><mml:math id="inf61"><mml:mrow><mml:mi>M</mml:mi><mml:mo>≥</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:math></inline-formula>, CVs are close to one, so that individual neurons produce spike trains with Poisson statistics.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-73276-fig5-v2.tif"/></fig><p>In summary, when we scale up, networks with some redundancy remain robust to partial, inhibitory perturbations, even though the firing statistics of the neurons change.</p></sec><sec id="s2-8"><title>Natural perturbations</title><p>Biological systems should also be robust against the mistuning of any of their components. We will now show that many types of parameter mistuning can be understood as deformations of the bounding box. As shown in <xref ref-type="fig" rid="fig3">Figure 3</xref>, the simplest type of perturbation is a change in a neuron’s spiking threshold: an increase of a neuron’s spiking threshold will push the corresponding face of the bounding box outwards, and a decrease will push the face inwards.</p><p>While permanent changes in the threshold can come about through changes in conductances or reversal potentials, a neuron can also suffer from temporary changes in its effective spiking threshold through, for example, noise. Biological systems are constantly subject to noise at multiple levels such as sensory transduction noise, ion channel noise (<xref ref-type="bibr" rid="bib21">Faisal et al., 2008</xref>), or 'background' synaptic activity (<xref ref-type="bibr" rid="bib18">Destexhe et al., 2001</xref>; <xref ref-type="bibr" rid="bib23">Fellous et al., 2003</xref>). We can study the impact of such noise by injecting small, random currents into each neuron. These currents change how close the voltage of a neuron is to its spiking threshold. With regard to spike generation, the resulting voltage fluctuations are thus equivalent to fluctuations of the threshold, or random movements of all of the faces of the bounding box around their unperturbed positions (<xref ref-type="fig" rid="fig6">Figure 6A</xref>, see also <xref ref-type="video" rid="video2">Video 2</xref>).</p><fig id="fig6" position="float"><label>Figure 6.</label><caption><title>Network response to natural perturbations.</title><p>(<bold>A</bold>) Voltage noise can be visualized as jittery movement of each threshold. If a neuron’s threshold increases or decreases relative to its default value (solid orange), its respective boundary moves outward or inward. (<bold>B</bold>) Instead of a rigid box defining a permanent, unambiguous boundary between the spike and no-spike zones, any point in signal space now has a non-zero probability of falling outside the box, shown in color. Black lines represent the thresholds of individual neurons in the absence of noise. (left) At low redundancy, most points within the default box retain a low probability of exclusion. (centre) As redundancy increases, this low-probability volume disappears, increasing the likelihood of ping-pong spikes. (right) Networks with an expanded bounding box retain a large low-probability volume even at high redundancy. Dashed white lines show 6-neuron bounding box for comparison. (<bold>C</bold>) Temporary bounding box deformation caused by a mistuned reset. The deformation appears after a spike of the affected neuron and decays away with the time constant of the voltage leak. (<bold>D</bold>) Temporary bounding box deformation caused by a mistuned synapse. The deformation appears after a spike of the presynaptic neuron and decays away with the same time constant. (<bold>E</bold>) When noise level increases, performance (relative to an unperturbed network, see Methods, Network performance) drops only slightly. Lines show medians across random equidistant networks, and outlines represent interquartile ranges. (<bold>F</bold>) The ping-pong effect causes numerous unnecessary spikes for higher levels of noise, with more redundant networks affected more strongly. Networks with an expanded box retain healthy dynamics until much higher noise levels. (<bold>G,H</bold>) Each synapse is rescaled with a random factor taken from the interval <inline-formula><mml:math id="inf62"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">[</mml:mo></mml:mrow><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi mathvariant="normal">Ω</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf63"><mml:msub><mml:mi>δ</mml:mi><mml:mi mathvariant="normal">Ω</mml:mi></mml:msub></mml:math></inline-formula> is the maximal synaptic scaling factor (see Materials and methods, Synaptic perturbations'). Networks are initially robust against synaptic mistuning, but eventually performance degrades. Networks with higher redundancy are more sensitive to these perturbations, but, as in the case of voltage noise, this extra sensitivity can be counteracted by widening the box.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-73276-fig6-v2.tif"/></fig><p>For networks with low redundancy, <inline-formula><mml:math id="inf64"><mml:mi>ρ</mml:mi></mml:math></inline-formula>, small voltage fluctuations cause only minor deformations of the bounding box. In turn, the error tolerance remains roughly the same, and network performance is not affected (<xref ref-type="fig" rid="fig6">Figure 6B</xref>, left; <xref ref-type="fig" rid="fig6">Figure 6E and F</xref>). However, for networks with high redundancy, <inline-formula><mml:math id="inf65"><mml:mi>ρ</mml:mi></mml:math></inline-formula>, small voltage fluctuations can cause a fatal collapse of the system (<xref ref-type="fig" rid="fig6">Figure 6B</xref>, middle). The key reason is that the effective size of the bounding box is determined by the position of the thresholds that have moved furthest into the box. As more and more neurons are added, the likelihood that some of them have very decreased thresholds increases, and the effective size of the bounding box shrinks. In turn, the probability that the network moves into an 'epileptic seizure' (due to the 'ping-pong' effect, see <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>) increases as well. While the readouts may still be contained in this scenario (<xref ref-type="fig" rid="fig6">Figure 6E</xref>), the excessive number of spikes fired (<xref ref-type="fig" rid="fig6">Figure 6F</xref>) comes at a high metabolic cost and would be detrimental to biological systems. To avoid this failure mode, neurons need to lower their excitability, which in turn increases the size of the bounding box for a fixed redundancy (<xref ref-type="fig" rid="fig6">Figure 6B</xref>, right panel). Such a 'wide box' will be more resilient towards noise (<xref ref-type="fig" rid="fig6">Figure 6B</xref>, right panel, <xref ref-type="fig" rid="fig6">Figure 6E and F</xref>). More generally, our results suggest that more redundant networks may require a better control or suppression of intrinsic sources of noise than less redundant networks.</p><p>Next, we will study perturbations of a neuron’s reset potential, that is, the voltage reached directly after a spike. This voltage should ideally be <inline-formula><mml:math id="inf66"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mtext>reset</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">D</mml:mi><mml:mi>i</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathvariant="bold">D</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. Biophysically, when the neuron resets to a voltage above (below) this ideal reset potential, then its post-spike voltage is temporarily closer (further) from threshold. In terms of the neuron’s spiking output, a change in its reset voltage is therefore equivalent to a (temporary) change in its threshold. Within the bounding box, a reset voltage above (below) the optimal reset will lead to a push of the neuron’s threshold inwards (outwards) (<xref ref-type="fig" rid="fig6">Figure 6C</xref>). However, because of the voltage leak, the threshold will then decay back to its normal position. <xref ref-type="video" rid="video2">Video 2</xref> illustrates this effect in a system with a two-dimensional input. We note that positive and negative changes to the default reset potential will lead to asymmetric effects on robustness like those observed for excitatory and inhibitory perturbations. Specifically, if the resets become too small, and if the leak is insufficiently fast, then successive spiking of a single neuron will draw its threshold inwards, thereby leading to a collapse of the bounding box.</p><p>Finally, we study perturbations of the synaptic connectivity in the network. Synapses could be permanently mistuned or they could be temporarily mistuned, for instance through transmission failures or through stochastic fluctuations in the release of neurotransmitters (<xref ref-type="bibr" rid="bib21">Faisal et al., 2008</xref>). From a geometric perspective, a mistuned synapse causes a temporary change in the threshold of the postsynaptic neuron whenever a presynaptic spike arrives (<xref ref-type="fig" rid="fig6">Figure 6D</xref>). We again note an asymmetry: an excitatory synapse with decreased strength (or an inhibitory synapse with increased strength) leads to an outward move of the postsynaptic neuron’s threshold, which is generally harmless. In turn, an excitatory synapse with increased strength (or an inhibitory synapse with decreased strength) leads to an inward move, which could be a temporarily harmful perturbation. Accordingly, random synaptic failures in excitatory synapses (but not inhibitory synapses) leave the bounding box functionally intact.</p><p>When all synapses in the network are randomly mistuned, then each spike fired will cause a random, but transient deformation of the bounding box (see <xref ref-type="video" rid="video2">Video 2</xref>). Overall, we find that more redundant networks (with consequently more synapses) are typically more vulnerable to these perturbations. Just as for voltage noise, the amount of deformation of the bounding box therefore increases with the number of neurons. For large perturbations, the synaptic noise eventually leads to inefficient networks with high spike rate (<xref ref-type="fig" rid="fig6">Figure 6G and H</xref>). As shown in <xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4</xref>, the effects of (voltage or synaptic) noise on the networks hold independent of the signal dimensionality.</p></sec><sec id="s2-9"><title>Synaptic delays</title><p>So far, we have assumed that the propagation of action potentials is instantaneous. However, lateral excitation and inhibition in biological networks incur delays on the order of milliseconds. Previous work has shown that networks which coordinate their spiking as suggested here are extremely sensitive to delays when neurons are similarly tuned (<xref ref-type="bibr" rid="bib13">Chalk et al., 2016</xref>; <xref ref-type="bibr" rid="bib47">Rullán Buxó and Pillow, 2020</xref>). Indeed, when spikes are delayed, voltages no longer reflect an accurate estimate of the coding error. For neurons with identical decoders, delays can lead to uninformed spikes that actually increase the coding error (<xref ref-type="fig" rid="fig7">Figure 7A and B</xref>). With networks that represent M-dimensional signals at once, the effects of delays are more complex. However, the bounding box allows us to visualize them and explain how they can, in principle, be avoided. Below, we study the impact of these delays, which apply directly to recurrent excitation and inhibition. We also apply the same delays to the network readout for mathematical convenience, but those do not affect the network dynamics (see Materials and methods).</p><fig id="fig7" position="float"><label>Figure 7.</label><caption><title>Synaptic transmission delays cause uninformed spikes, but networks with high-dimensional inputs are less affected.</title><p>(<bold>A</bold>) In an undelayed network, when membrane potentials <italic>V</italic><sub>1</sub> and <italic>V</italic><sub>2</sub> of two identically tuned neurons approach firing threshold (dashed), the first neuron to cross it will spike and instantly inhibit the second. (<bold>B</bold>) If recurrent spikes are instead withheld for a delay <inline-formula><mml:math id="inf67"><mml:mi>θ</mml:mi></mml:math></inline-formula>, the second neuron may reach its own threshold before receiving this inhibition, emitting an 'uninformed' spike. (<bold>C</bold>) Readout dynamics in a delayed network that encodes a two-dimensional input. After the spike of the orange neuron, but before its arrival at synaptic terminals, the voltage of the orange neuron is temporarily too low, causing an effective retraction of its boundary. (<bold>D</bold>) For less orthogonal pairs of neurons, the retraction of the boundary of a spiking neuron may expose the boundary of a similarly tuned neuron, leading to a suboptimally fired spike, and increasing the likelihood of 'ping-pong'. (<bold>E</bold>) Permanently wider boxes or (<bold>F</bold>) temporarily wider boxes (excitatory connections between opposing neurons removed) are two effective strategies of avoiding ’ping-pong’. (<bold>C–F</bold>) Readout shown as gray circles and arrows, bounds of spiking neurons as colored lines, and the resulting shift of other bounds as colored arrows. (<bold>G</bold>) Simulations of networks with a synaptic delay of <inline-formula><mml:math id="inf68"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> msec. (Left) In standard networks, performance quickly degenerates when redundancy is increased. (Centre, Right) The detrimental effects of delays are eliminated in higher-dimensional bounding boxes that are widened (centre) or when the largest excitatory connections are removed (right). Note the exponential scaling of the y-axis. See <xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5</xref> for single trials with normal or wide boxes, and full or reduced connectivity (20 dimensions).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-73276-fig7-v2.tif"/></fig><p>To visualize the effect of a synaptic delay, we show the readout dynamics around a single spike in <xref ref-type="fig" rid="fig7">Figure 7C</xref> (see also <xref ref-type="video" rid="video2">Video 2</xref>). After hitting the threshold, the spiking neuron resets its own voltage immediately. However, due to the delay, neither a hypothetical readout unit nor other neurons in the network are aware of the spike. From the network perspective, the voltage of the spiking neuron appears temporarily too low (or its threshold too high), which we can visualize as an outward jump of its boundary (<xref ref-type="fig" rid="fig7">Figure 7C</xref>, second and third panels). When the spike finally arrives, the readout and all other voltages are updated, and the voltage of the firing neuron once again agrees with the network state. In our visualization, its boundary thus returns to its default position (<xref ref-type="fig" rid="fig7">Figure 7C</xref>, fourth panel).</p><p>The visualization illustrates that the effect of a delayed spike depends on the bounding box shape. In <xref ref-type="fig" rid="fig7">Figure 7C</xref>, the nearly orthogonal tuning of neighbouring neurons makes the delayed spike harmless. The situation is different if neurons are more similarly tuned as in <xref ref-type="fig" rid="fig7">Figure 7D</xref>. Here, a second neuron might cross its threshold before the delayed spike arrives. As a consequence, it also fires a spike, and its boundary also retracts (<xref ref-type="fig" rid="fig7">Figure 7D</xref>, third panel). Eventually, both spikes arrive, the readout is updated, and the bounding box regains its original shape (<xref ref-type="fig" rid="fig7">Figure 7D</xref>, fourth panel). At this point, the readout may overshoot, cross an opposite boundary, and trigger further 'ping-pong' spikes. The resulting 'epileptic seizures' are essentially unavoidable in highly redundant networks with synaptic delays. Consequently, we identify two problems with synaptic delays. The first problem is that multiple thresholds are crossed simultaneously. The second problem is that the resulting strong change in the readout can cause a 'ping-pong' of uninformed spikes.</p><p>For the first problem, we note that the impact of synaptic delays depends on the angles of neighbouring neurons, as shown in <xref ref-type="fig" rid="fig7">Figure 7C and D</xref>. For higher signal dimensions and fixed redundancy, these angles become more orthogonal (<xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3D</xref>), which alleviates the detrimental effect of delays. Numerically, however, we find that this effect is not sufficient to avoid all uninformed spikes (for signal spaces with up to <inline-formula><mml:math id="inf69"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:math></inline-formula> dimensions), and the networks still degenerate into ‘ping-pong’.</p><p>To avoid the second problem, we need to eliminate the crossing of opposite thresholds by widening the box, which can prevent 'ping-pong' (<xref ref-type="fig" rid="fig7">Figure 7E</xref>, <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>). However, permanently widening the bounding box in all directions can reduce coding accuracy, even when the readout is properly rescaled (<xref ref-type="fig" rid="fig7">Figure 7G</xref>, <xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5</xref>, see Materials and methods, 'Iterative adaptation of parameters to avoid ping-pong'). A better solution is therefore to 'widen' the box only temporarily. For instance, if we eliminate excitatory connections between pairs of neurons that are practically antipodes, we are setting the respective synapses to zero. This change in the network connectivity can be understood as a specific and targeted synaptic perturbation (<xref ref-type="fig" rid="fig6">Figure 6D</xref>), whose effect is to expand the thresholds of a neuron’s antipodes whenever it fires a spike, thereby temporarily widening the box exactly in the direction in which the readout overshoots (<xref ref-type="fig" rid="fig7">Figure 7F</xref>). As a consequence, the networks become less likely to initiate ping-pong. Moreover, as their widening is local and only temporary, performance is less affected. Indeed, for higher dimensional systems and biologically plausible delays (1–2 ms), performance of networks with delays reaches the performance of networks without delays (<xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5</xref>). The rapid increase in firing due to ping-pong is avoided as well (see also <xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5</xref>).</p></sec><sec id="s2-10"><title>Adding computations</title><p>The bounding box provides a useful tool even if we endow the networks with a set of slower connections to perform linear or non-linear computations (<xref ref-type="bibr" rid="bib7">Boerlin et al., 2013</xref>; <xref ref-type="bibr" rid="bib48">Savin and Deneve, 2014</xref>; <xref ref-type="bibr" rid="bib54">Thalmeier et al., 2016</xref>). Indeed, the simulation in <xref ref-type="fig" rid="fig1">Figure 1D</xref> used these slower connections to generate oscillatory dynamics (see Materials and methods, 'Generalization of the bounding box IV'). This extension to networks that generate persistent activity or dynamical patterns works because the mechanisms underlying the encoding of the signals into spike trains are decoupled from the mechanisms that generate the dynamics of the signals (or readouts). In fact, the extra currents generated by the slow recurrent connections can be seen as a perturbation of the bounding box thresholds. This perturbation shifts the bounding box in the space of readouts as illustrated in <xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref>.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>In this study, we characterized the functioning of networks with coordinated redundancy under normal conditions and under a diversity of perturbations, using a simple, geometric visualization, the bounding box. The bounding box delimits the error that such a network tolerates in approximating a set of input signals, and its geometry is found to be largely determined by the properties of its decoders. It allows us to visualize and thus understand the dynamics of coordinated spiking networks, including the firing of every single spike. We showed how various perturbations of the network can be mapped onto shape deformations of this bounding box. As long as the box stays intact, the network’s performance is essentially unaffected, in that downstream readouts of the network’s outputs will not notice the perturbation.</p><p>In many respects, the bounding box is a 'toy model' (a deliberately abstract model), which we see mainly as a tool to conceptualize and highlight generic circuit mechanisms, rather than an attempt to model any specific system. Nonetheless, it is worthwhile to point out that the bounding box is also a spiking version of classical sparse coding models of V1 (<xref ref-type="bibr" rid="bib44">Olshausen and Field, 1996</xref>). Indeed, previous work has demonstrated that these networks can explain various perturbation experiments in V1 (<xref ref-type="bibr" rid="bib3">Barrett et al., 2016</xref>). So, besides shedding light on the robustness of coordinated spike codes, the bounding box can also be seen as a simple model of a sensory system.</p><sec id="s3-1"><title>Robustness of networks with coordinated spike coding</title><p>Several overarching principles have been identified that allow systems to be robust (<xref ref-type="bibr" rid="bib15">Csete and Doyle, 2002</xref>; <xref ref-type="bibr" rid="bib33">Kitano, 2004</xref>; <xref ref-type="bibr" rid="bib59">Whitacre, 2012</xref>; <xref ref-type="bibr" rid="bib22">Félix and Barkoulas, 2015</xref>). These include (1) negative feedback, to correct perturbations and recover functionality; (2) heterogeneity of components, to avoid common modes of failure; and (3) modularity or 'bow-tie' architectures, to create alternative pathways or solutions in the case of a perturbation. Furthermore, (4) making a system robust against certain perturbations almost always involves a tradeoff, in that the system becomes fragile against other perturbations.</p><p>These core themes can also be found in the networks we studied here. (1) Negative feedback exists through extensive lateral connectivity (or, alternatively, through actual feedback of the readout, as in <xref ref-type="fig" rid="fig2">Figure 2F</xref>), and is precisely tuned such that it automatically corrects any perturbations. (2) Individual neurons are heterogeneous and thereby allow the system (as visualized by the bounding box) to remain functional for all types of input signals. (3) Since neuron space is always larger than signal space, there are many alternative neural codes ('alternative pathways') that give rise to the same linear readout, thus embodying a bow-tie architecture whose core is the signaling space. Shrinking the network’s redundancy, for example, by killing neurons, in turn eliminates these alternative codes and leads to more regular and reliable spike trains. (4) Furthermore, the networks are fragile against any perturbation that leads to a shrinking of the box. Paradoxically, this fragility may become more relevant if a system becomes more redundant. These four themes may relate the robustness of the networks studied here to the more general topic of tissue robustness (<xref ref-type="bibr" rid="bib33">Kitano, 2004</xref>).</p><p>Coordinated redundancy allows the construction of robust sub-circuits, that can self-correct problems instead of passing them on, so that downstream networks remain unaffected. These observations remain correct even if we move beyond the simple autoencoder networks that we have studied here. Indeed, we could generalize the connectivities we consider or abandon the idea that the readout must match the input without changing the robustness of the networks (see Materials and methods, 'Coordinated spiking and the bounding box'). We could also add slower recurrent synapses which allows to generate dynamics within the networks (<xref ref-type="bibr" rid="bib7">Boerlin et al., 2013</xref>; <xref ref-type="bibr" rid="bib48">Savin and Deneve, 2014</xref>; <xref ref-type="bibr" rid="bib54">Thalmeier et al., 2016</xref>), as explained above.</p></sec><sec id="s3-2"><title>Fragility of networks with coordinated spike coding</title><p>Despite their strong robustness, networks with coordinated redundancy are also surprisingly fragile against any perturbations that cause an effective shrinking of the box, and thereby lead to the ping-pong effect. These problems can be ameliorated by widening the box, which brings networks back into workable regimes if they represent high-dimensional signals with limited redundancy. However, a true 'fix' of this problem can only be achieved if neurons with opposite decoder weights (which are connected through excitatory connections) are prohibited. Such a change would break the symmetric treatment of excitatory and inhibitory connections, which causes neurons to both excite and inhibit different downstream partners, thereby violating Dale’s law. Future work will need to reconsider these issues which seem to be tightly connected. (We note that <xref ref-type="bibr" rid="bib7">Boerlin et al., 2013</xref> developed networks that obey Dale’s law, but did so without fixing the issue of the ping-pong effect.)</p></sec><sec id="s3-3"><title>Structural robustness of neural networks</title><p>Historically, the study of network-level mechanisms of robustness has received relatively little attention. A key focus has been the robustness of network attractors, defined as the ability of a system to remain in the same attractor landscape despite perturbations. For instance, systems such as the oculomotor integrator or the head direction system can be described as continuous attractors (<xref ref-type="bibr" rid="bib50">Seung, 1996</xref>; <xref ref-type="bibr" rid="bib62">Zhang, 1996</xref>). Such continuous attractors are structurally unstable, in that even small perturbations in single neurons can lead to rapid dynamic drifts (<xref ref-type="bibr" rid="bib50">Seung, 1996</xref>; <xref ref-type="bibr" rid="bib62">Zhang, 1996</xref>). However, this fragility to perturbations is not observed in biological neural networks.</p><p>In order to achieve the required robustness, several biophysical mechanisms have been proposed to enhance continuous attractors models, e.g. bistability at the somatic level (<xref ref-type="bibr" rid="bib34">Koulakov et al., 2002</xref>) or dendritic level (<xref ref-type="bibr" rid="bib26">Goldman et al., 2003</xref>). More recent work proposed network-level mechanisms based on derivative feedback, in order to solve the problem of robustness for continuous attractor networks (<xref ref-type="bibr" rid="bib36">Lim and Goldman, 2013</xref>). In our work, the problem is solved because perturbations such as neuron loss, noise, or tuning of synapses are compensated through the fast, lateral connections. As a consequence, perturbations of the single-neuron level (spiking) are uncoupled from perturbations of the population-level (readout). Consequently, only perturbations that manage to disturb the linear readout can impact the network attractor dynamics.</p><p>Models of neural networks implementing point attractors, such as the Hopfield model (<xref ref-type="bibr" rid="bib28">Hopfield, 1982</xref>), are typically considered structurally robust, meaning that perturbations up to certain magnitudes of their parameters and the introduction of dynamics noise do not disrupt the attractor. We note, however, that perturbations in these networks lead to changes in neurons’ firing rates, which may still cause changes in putative downstream linear readouts. From the point of view of a downstream observer, perturbations are therefore not compensated within classical attractor networks. The induced perturbations may be inconsequential, however, when the downstream readout is taken to be a classifier; only the combined system of attractor network and classifier readout can then be seen as a 'robust module', that is, a module that keeps problems to itself, rather than spreading them to all who listen.</p><p>Similar observations apply to studies of the robustness of deep networks against various perturbations such as the loss of neurons (<xref ref-type="bibr" rid="bib41">Morcos, 2018</xref>; <xref ref-type="bibr" rid="bib4">Barrett et al., 2019</xref>). In these cases, the network’s robustness is evaluated with respect to the output of a final classification step, such as the identification of an object. Indeed, a lot of work has been dedicated to making this final output robust to small perturbations, especially perturbations applied to the inputs (<xref ref-type="bibr" rid="bib53">Szegedy, 2013</xref>; <xref ref-type="bibr" rid="bib5">Biggio, 2013</xref>; <xref ref-type="bibr" rid="bib12">Carlini, 2019</xref>; <xref ref-type="bibr" rid="bib10">Brendel et al., 2020</xref>). Based on the arguments above, we similarly expect that the problem of making a graded output robust will be harder and fundamentally different.</p></sec><sec id="s3-4"><title>Insights on spiking networks</title><p>Spiking networks have traditionally been quite hard to understand, except for special cases (<xref ref-type="bibr" rid="bib38">Maass and Bishop, 1999</xref>; <xref ref-type="bibr" rid="bib57">Vogels et al., 2005</xref>; <xref ref-type="bibr" rid="bib25">Gerstner et al., 2014</xref>). Here, we have shown how the dynamics of (coordinated) spike coding networks can be understood within a lower-dimensional signal space, which is tightly linked to linear readouts. Since (low-dimensional) linear readouts are a ubiquitous finding in recordings from neural populations, we may speculate that our signal space is roughly equivalent to the latent subspaces discovered by linear projections of neural activities, as, for example, obtained through dimensionality reduction methods (<xref ref-type="bibr" rid="bib16">Cunningham and Yu, 2014</xref>; <xref ref-type="bibr" rid="bib32">Keemink and Machens, 2019</xref>). This link between a space of neural activities and a space of (latent) signals is common to all network models based on low-rank connectivities (<xref ref-type="bibr" rid="bib20">Eliasmith, 2005</xref>; <xref ref-type="bibr" rid="bib50">Seung, 1996</xref>; <xref ref-type="bibr" rid="bib40">Mastrogiuseppe and Ostojic, 2018</xref>). In contrast to these studies, however, and in line with (<xref ref-type="bibr" rid="bib7">Boerlin et al., 2013</xref>), our work focuses on spiking networks and introduces a third space, the voltage space, which represents the system’s coding errors. As we have shown here, the coding errors are confined to an error bounding box. Accordingly, the bounding box finds its physical—and in principle measurable—manifestation in a low-dimensional subspace of a network’s voltage space (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>).</p><p>We believe that the links we have made here—which allow us to jointly visualize a low-dimensional signal space, the spiking activity, and the subthreshold voltages—may provide useful insights into the functioning of spiking networks in the brain, and may well be expanded beyond the confines of the current study.</p></sec></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Coordinated spiking and the bounding box</title><p>Mathematically, our networks can be derived from a single objective function that quantifies coding accuracy. Step-by-step derivation for the autoencoder networks can be found in <xref ref-type="bibr" rid="bib3">Barrett et al., 2016</xref>; networks that additionally involve a set of slow connections are derived in <xref ref-type="bibr" rid="bib7">Boerlin et al., 2013</xref>. Here, we focus on the autoencoder networks which contain all the crucial elements needed to understand the spiking dynamics of the networks. Instead of starting with an objective function, we take a slightly different perspective in our derivation here, which ties more directly into our geometric interpretations.</p><p>In short, we assume that a network of <inline-formula><mml:math id="inf70"><mml:mi>N</mml:mi></mml:math></inline-formula> neurons encodes an <inline-formula><mml:math id="inf71"><mml:mi>M</mml:mi></mml:math></inline-formula>-dimensional input signal <inline-formula><mml:math id="inf72"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, in its spike trains <inline-formula><mml:math id="inf73"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, such that the signal can be read out from the filtered spike trains,<disp-formula id="equ4"><label>(4)</label><mml:math id="m4"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ5"><label>(5)</label><mml:math id="m5"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf74"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> is the <inline-formula><mml:math id="inf75"><mml:mi>M</mml:mi></mml:math></inline-formula>-dimensional linear readout or signal estimate, the <inline-formula><mml:math id="inf76"><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula> matrix <inline-formula><mml:math id="inf77"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> contains the decoding weights (and each column corresponds to a decoding vector <inline-formula><mml:math id="inf78"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>), the filtered spike trains are represented by an <inline-formula><mml:math id="inf79"><mml:mi>N</mml:mi></mml:math></inline-formula>-dimensional vector <inline-formula><mml:math id="inf80"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, and <inline-formula><mml:math id="inf81"><mml:mi>λ</mml:mi></mml:math></inline-formula> determines the filtering time constant.</p><p>The key idea of coordinated spike coding is to derive a spiking rule that bounds the difference between the input signal <inline-formula><mml:math id="inf82"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>, and the linear readout <inline-formula><mml:math id="inf83"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>,<disp-formula id="equ6"><label>(6)</label><mml:math id="m6"><mml:mrow><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mo>&lt;</mml:mo><mml:mi>T</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf84"><mml:mrow><mml:mo>∥</mml:mo><mml:mo>⋅</mml:mo><mml:mo>∥</mml:mo></mml:mrow></mml:math></inline-formula> denotes the Euclidean distance or L2 norm and <inline-formula><mml:math id="inf85"><mml:mi>T</mml:mi></mml:math></inline-formula> determines the maximally allowed difference. In the network implementation, we approximate this bound (which defines a hypersphere) by a set of linear bounds or inequalities, one for each neuron <italic>i</italic>,<disp-formula id="equ7"><label>(7)</label><mml:math id="m7"><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="-0.083em"/><mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>&lt;</mml:mo><mml:mi>T</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>For simplicity, we assume that the decoding vectors <inline-formula><mml:math id="inf86"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> have unit norm. Each inequality defines a half-space of solutions for the readout <inline-formula><mml:math id="inf87"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. For properly chosen <inline-formula><mml:math id="inf88"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, the intersection of all of these half-spaces is non-empty and bounded, and thus forms the interior of the bounding box. Geometrically, the equations define a polytope <inline-formula><mml:math id="inf89"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>B</mml:mi><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>∈</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mspace width="thickmathspace"/><mml:msup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mspace width="-0.083em"/><mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mspace width="negativethinmathspace"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:mrow><mml:mi mathvariant="bold">T</mml:mi></mml:mrow><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. If the thresholds are chosen sufficiently large, then crossing a bound and firing a spike keeps the readout inside the bounding box.</p><p>The dynamics of the network are obtained by identifying the left-hand side of the above equation with the neuron’s voltage, <inline-formula><mml:math id="inf90"><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula>, and then taking the temporal derivative (<xref ref-type="bibr" rid="bib7">Boerlin et al., 2013</xref>; <xref ref-type="bibr" rid="bib3">Barrett et al., 2016</xref>). If we also add some noise to the resulting equations, we obtain,<disp-formula id="equ8"><label>(8)</label><mml:math id="m8"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mspace width="-0.083em"/><mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mspace width="-0.083em"/><mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mi mathvariant="bold-italic">η</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>which describes a network of leaky integrate-and-fire neurons. The first term on the right-hand side is the leak, the second term corresponds to the feedforward input signals to the network, the third term captures the fast recurrent connectivity, with synaptic weights <inline-formula><mml:math id="inf91"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="-0.083em"/><mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, and the fourth term is added white current noise with standard deviation <inline-formula><mml:math id="inf92"><mml:msub><mml:mi>σ</mml:mi><mml:mi>V</mml:mi></mml:msub></mml:math></inline-formula>. When the voltage <inline-formula><mml:math id="inf93"><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula> reaches the threshold <inline-formula><mml:math id="inf94"><mml:mi>T</mml:mi></mml:math></inline-formula>, the self-connection <inline-formula><mml:math id="inf95"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="-0.083em"/><mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> causes a reset of the voltage to <inline-formula><mml:math id="inf96"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mtext>reset</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mi>T</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. For biological plausibility, we also consider a small refractory period of <inline-formula><mml:math id="inf97"><mml:mrow><mml:msub><mml:mi>τ</mml:mi><mml:mtext>ref</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mtext>ms</mml:mtext></mml:mrow></mml:mrow></mml:math></inline-formula> for each neuron. We implemented this refractory period by simply omitting any spikes coming from the saturated neuron during this period.</p><p>Mathematically, the voltages are thereby confined to a subspace given by the image of the transposed decoder matrix, <inline-formula><mml:math id="inf98"><mml:msup><mml:mi mathvariant="bold">D</mml:mi><mml:mo>⊤</mml:mo></mml:msup></mml:math></inline-formula>. The dynamics within this voltage subspace are then bounded according to <xref ref-type="disp-formula" rid="equ7">Equation 7</xref>, which can be seen as a physical manifestation of the bounding box (see also <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>).</p></sec><sec id="s4-2"><title>Generalization of the bounding box I: Heterogeneous thresholds</title><p>In our exposition, we generally assume that all decoding vectors are of the same length, and all thresholds are identical. For isotropically distributed input signals and isotropically distributed decoding vectors, this scenario will cause all neurons to fire the same average number of spikes over time. Indeed, to the extent that homeostatic plasticity sets synaptic weights and firing thresholds to guarantee this outcome (<xref ref-type="bibr" rid="bib56">Turrigiano, 2012</xref>), a network will automatically revert to a spherically symmetric bounding box for such input signals (see also <xref ref-type="bibr" rid="bib10">Brendel et al., 2020</xref>).</p><p>If input signals are not isotropically distributed then homeostatic plasticity would essentially lower the thresholds of neurons that receive overall less inputs, and it would increase the thresholds of neurons that receive overall more inputs. In turn, the bounding box would take more elliptical shapes. We have not considered this scenario here for simplicity, but the key findings on robustness will hold in this case, as well.</p></sec><sec id="s4-3"><title>Generalization of the bounding box II: Asymmetric connectivities</title><p>In the main text, we have assumed that the readout always jumps orthogonal to the threshold boundary (or face) of a neuron. This assumption leads to symmetric connectivities in the network, given by <inline-formula><mml:math id="inf99"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="-0.083em"/><mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. However, our results on robustness also hold if we decouple the orientation of a neuron’s face from the direction of the readout jump. This can be achieved if we define the voltage as <inline-formula><mml:math id="inf100"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">F</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, where <inline-formula><mml:math id="inf101"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">F</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes the norm vector of a bounding box face, but then let the readout jump in the direction <inline-formula><mml:math id="inf102"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. A non-orthogonal jump with respect to the face then simply requires <inline-formula><mml:math id="inf103"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>≠</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">F</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>. Indeed, for elliptically shaped bounding boxes, non-orthogonal jumps of the readout can be advantageous. The more general dynamical equation for the networks is then given by<disp-formula id="equ9"><label>(9)</label><mml:math id="m9"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="bold">F</mml:mi></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold">F</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mspace width="thinmathspace"/><mml:mi mathvariant="bold-italic">η</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>and was first described in <xref ref-type="bibr" rid="bib10">Brendel et al., 2020</xref>. In principle, these generalized networks include all spiking networks with low-rank connectivities. However, the bounding box interpretation is most useful when each spike is reset back into the bounding box, which will only happen if the net effect of a spike on neighboring neurons is inhibitory. Spikes that cause (temporary) jumps out of the box, and therefore have a net excitatory and error-amplifying effect, will be considered in future work.</p></sec><sec id="s4-4"><title>Generalization of the bounding box III: Opening the box</title><p>The equation for the synaptic connectivity, <inline-formula><mml:math id="inf104"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mspace width="-0.083em"/><mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>, implies that neurons with similar decoding vectors inhibit each other, neurons with orthogonal decoding vectors are unconnected, and neurons with opposite decoding vectors excite each other. Consequently, if the bounding box is a (hyper)cube, then almost all neurons are unconnected, except for neurons whose faces are opposite to each other. The excitatory connections between these neurons ensure that their voltages remain in sync. However, in practice, those voltages do not need to be tied, and the excitatory connections can therefore also be eliminated (as in <xref ref-type="fig" rid="fig7">Figure 7</xref>), which can help against the ping-pong effect.</p><p>Alternatively, we can choose decoding vectors such that all synapses are inhibitory, <inline-formula><mml:math id="inf105"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. In this case, the bounding box remains open on one side. The network no longer represents the input signal, but rather computes a piece-wise linear function of the input (<xref ref-type="bibr" rid="bib39">Mancoo, 2020</xref>). In turn, the network’s new function (piece-wise linear output) will now remain robust against perturbations for exactly the same reasons explained before. Indeed, the reader may notice that most of the results on robustness do not require the bounding box to be closed.</p></sec><sec id="s4-5"><title>Generalization of the bounding box IV: Slow connections</title><p>Throughout the manuscript, we focused on autoencoder networks. However, as illustrated in <xref ref-type="fig" rid="fig1">Figure 1</xref> and derived in <xref ref-type="bibr" rid="bib7">Boerlin et al., 2013</xref>, by introducing a second set of slower connections, we can endue these networks with computations,<disp-formula id="equ10"><label>(10)</label><mml:math id="m10"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mspace width="-0.083em"/><mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mspace width="-0.083em"/><mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mspace width="-0.083em"/><mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mspace width="negativethinmathspace"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold-italic">η</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>in which case the network approximates the dynamical system:<disp-formula id="equ11"><mml:math id="m11"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="bold">c</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>We note that all results on robustness hold for these more complicated networks as well. Indeed, the robustness of the autoencoder networks relies on the fast recurrent connections, which are present in these architectures as well. Due to the time scale separation, these mechanisms do not interfere with the slower recurrent connections, which create the slow dynamics of the readouts (see also <xref ref-type="fig" rid="app1fig6">Appendix 1—figure 6</xref>).</p></sec><sec id="s4-6"><title>Readout biases and corrections</title><p>When one of the neurons fires, its spike changes the readout, which jumps into the bounding box. In previous work (<xref ref-type="bibr" rid="bib7">Boerlin et al., 2013</xref>, <xref ref-type="bibr" rid="bib3">Barrett et al., 2016</xref>), the neurons’ thresholds were linked with the length of the jumps through the equation <inline-formula><mml:math id="inf106"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>. Accordingly, the jumps were generally taken to reach the opposing face of the bounding box, creating a tight error bounding box around <inline-formula><mml:math id="inf107"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>. This setting guarantees that the time-averaged readout matches the input signal.</p><p>When the jumps are significantly shorter than the average bounding box width, however, the time-averaged readout will be biased away from the input signal (see <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>). However, in many cases, this bias can be corrected by rescaling the readout. For instance, if the bounding box is shaped like a hypersphere (i.e. in the limit of an infinite number of neurons <inline-formula><mml:math id="inf108"><mml:mi>N</mml:mi></mml:math></inline-formula>), and assuming a constant (or slowly varying) stimulus, we can correct the readout as<disp-formula id="equ12"><label>(11)</label><mml:math id="m12"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where the angular brackets denote the time-averaged readout. Accordingly, in this case the bias only affects the length of the readout vectors, but not their direction.</p><p>If the bounding box is shaped like a hypercube, we alternatively correct the readout bias by assuming that a downstream decoder area has access to the identity of spiking neurons in the recent past. In this case, the downstream area can simply correct the readout according to the following equation:<disp-formula id="equ13"><label>(12)</label><mml:math id="m13"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mi>S</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>−</mml:mo><mml:mfrac><mml:mi>T</mml:mi><mml:mrow><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf109"><mml:mi>S</mml:mi></mml:math></inline-formula> is the set of active neurons for a given fixed time window in the past.</p><p>In all other cases, we empirically found that we can apply a correction to the readout using a similar scaling as in <xref ref-type="disp-formula" rid="equ11">Equation 11</xref> where <inline-formula><mml:math id="inf110"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>≈</mml:mo><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo fence="false" stretchy="false">‖</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. In other words, in most cases, the bias mainly affects the length of the readout vectors, whereas their direction is less affected.</p><p>In <xref ref-type="fig" rid="fig1">Figure 1</xref>, we used networks that involve an extra set of slow recurrent connections (<xref ref-type="bibr" rid="bib7">Boerlin et al., 2013</xref>). In this case, we additionally scaled the slow recurrent connectivity matrix <inline-formula><mml:math id="inf111"><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mtext>slow</mml:mtext></mml:msub></mml:math></inline-formula> with the same scaling factor as the corrected readout in <xref ref-type="disp-formula" rid="equ11">Equation 11</xref>:<disp-formula id="equ14"><label>(13)</label><mml:math id="m14"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mtext>slow</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mfrac><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mo>−</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mrow><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mi mathvariant="bold">D</mml:mi><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mo fence="false" stretchy="false">⟩</mml:mo></mml:mrow></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mspace width="-0.083em"/><mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold">A</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p></sec><sec id="s4-7"><title>Geometry of high-dimensional bounding boxes</title><p>The dimensionality of the bounding box is determined by the dimensionality <inline-formula><mml:math id="inf112"><mml:mi>M</mml:mi></mml:math></inline-formula> of the input signal. Throughout the illustrations in the Results section, we mostly used two-dimensional bounding boxes for graphical convenience. In order to illustrate some properties of higher-dimensional error bounding boxes (<xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3</xref>), we compared their behavior against that of hyperspheres and hypercubes. We defined the equivalent hypersphere as <inline-formula><mml:math id="inf113"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mi>M</mml:mi></mml:msup></mml:mrow><mml:mo>:</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>∥</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>≤</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula> and the equivalent hypercube as <inline-formula><mml:math id="inf114"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo>∈</mml:mo><mml:msup><mml:mi>ℝ</mml:mi><mml:mi>M</mml:mi></mml:msup></mml:mrow><mml:mo>:</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mo>∥</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo>∥</mml:mo></mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:msub><mml:mo>≤</mml:mo><mml:mi>T</mml:mi></mml:mrow><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula>, where <inline-formula><mml:math id="inf115"><mml:mrow><mml:msub><mml:mrow><mml:mo>∥</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>p</mml:mi><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:msubsup><mml:mo>+</mml:mo><mml:mi mathvariant="normal">…</mml:mi><mml:mo>+</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:msqrt></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf116"><mml:mrow><mml:msub><mml:mrow><mml:mo>∥</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo>∥</mml:mo></mml:mrow><mml:mi mathvariant="normal">∞</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mi>max</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. In practice, we chose the smallest box size, <inline-formula><mml:math id="inf117"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula> (<xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3</xref>).</p><p>For a first comparison, we took the intersection between the border of the <inline-formula><mml:math id="inf118"><mml:mi>M</mml:mi></mml:math></inline-formula>-dimensional polytope <inline-formula><mml:math id="inf119"><mml:mi>B</mml:mi></mml:math></inline-formula> and a random two-dimensional plane containing the centre of the polytope. We computed such intersections numerically by first choosing two random and orthogonal directions <inline-formula><mml:math id="inf120"><mml:mi>u</mml:mi></mml:math></inline-formula> and <inline-formula><mml:math id="inf121"><mml:mi>v</mml:mi></mml:math></inline-formula> in the full space defining the two-dimensional plane. Then for each <inline-formula><mml:math id="inf122"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi></mml:mrow><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> , we defined a ray in the two-dimensional plane, <inline-formula><mml:math id="inf123"><mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>u</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>, and then plotted<disp-formula id="equ15"><mml:math id="m15"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>θ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi>arg</mml:mi><mml:mo>⁡</mml:mo><mml:mo movablelimits="true" form="prefix">max</mml:mo></mml:mrow><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∈</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:munder><mml:mi>w</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>ρ</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>For a second comparison, we found the distribution of angles between neighbouring neurons by first randomly choosing one neuron, and then moving along the surface of the <inline-formula><mml:math id="inf124"><mml:mi>M</mml:mi></mml:math></inline-formula>-polytope in a random direction, until we found a point that belongs to the face of a different neuron. We then computed the angle between the decoding weights of those two neurons.</p><p>We tested whether the results obtained for random decoding vectors hold for more structured decoding vectors as well. For instance, if we want to represent natural visual scenes, we may consider that the receptive fields of simple cells in V1 roughly correspond to the decoding vectors of our neurons (<xref ref-type="bibr" rid="bib44">Olshausen and Field, 1996</xref>; <xref ref-type="bibr" rid="bib3">Barrett et al., 2016</xref>). We illustrated a high-dimensional bounding box with a set of Gabor patches defined as<disp-formula id="equ16"><label>(14)</label><mml:math id="m16"><mml:mrow><mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>;</mml:mo><mml:mi>λ</mml:mi><mml:mo>,</mml:mo><mml:mi>θ</mml:mi><mml:mo>,</mml:mo><mml:mi>σ</mml:mi><mml:mo>,</mml:mo><mml:mi>γ</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>exp</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mrow><mml:msup><mml:mi>γ</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>⁢</mml:mo><mml:msup><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:msup><mml:mi>σ</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>⁢</mml:mo><mml:mi>π</mml:mi><mml:mo>⁢</mml:mo><mml:mfrac><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mi>λ</mml:mi></mml:mfrac></mml:mrow><mml:mo>+</mml:mo><mml:mfrac><mml:mi>π</mml:mi><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf125"><mml:mrow><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf126"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo stretchy="false">~</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>y</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. For our purposes, we randomly chose the Gabor parameters: <inline-formula><mml:math id="inf127"><mml:mi>λ</mml:mi></mml:math></inline-formula>, the wavelength of the sinusoidal stripe pattern, was sampled uniformly from <inline-formula><mml:math id="inf128"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mn>5</mml:mn><mml:mo>,</mml:mo><mml:mn>10</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula> Hz; <inline-formula><mml:math id="inf129"><mml:mi>θ</mml:mi></mml:math></inline-formula>, the orientation of the stripes, was sampled uniformly in <inline-formula><mml:math id="inf130"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mi>π</mml:mi><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, the standard deviation of the Gaussian envelope, was sampled uniformly from <inline-formula><mml:math id="inf131"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo fence="false" stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1.5</mml:mn><mml:mo fence="false" stretchy="false">}</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>, the spatial aspect ratio, was sampled uniformly from <inline-formula><mml:math id="inf132"><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1.5</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:math></inline-formula>.</p><p>Finally we randomly centred the resulting Gabor patch in one of 9 different locations on the 13 × 13 grid. We computed the angle (in the 169-dimensional space) between the Gabor patches and found that roughly 80% of the neurons are quasi-orthogonal (their angle falls between 85 and 95 degrees) to a given example patch (<xref ref-type="fig" rid="app1fig3">Appendix 1—figure 3E</xref>).</p></sec><sec id="s4-8"><title>Perturbations</title><p>Perturbations to the excitability of a neuron, be it due to changes of the spiking threshold, changes of the reset potential, synaptic weights, etc., can all be formulated as extra currents, <inline-formula><mml:math id="inf133"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, which capture the temporal evolution of the perturbation. Adding a current to the voltage dynamics is equivalent to a transient change in the neuronal thresholds,<disp-formula id="equ17"><label>(15)</label><mml:math id="m17"><mml:mrow><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mspace width="-0.083em"/><mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mi/><mml:mo>≤</mml:mo><mml:mrow><mml:mi mathvariant="bold">T</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mspace width="14.226378pt"/><mml:mo stretchy="false">⇔</mml:mo><mml:mspace width="14.226378pt"/><mml:mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true"><mml:mtr><mml:mtd><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mtd><mml:mtd><mml:mi/><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mspace width="-0.083em"/><mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow><mml:mo>+</mml:mo><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="bold">V</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mi/><mml:mo>≤</mml:mo><mml:mrow><mml:mi mathvariant="bold">T</mml:mi></mml:mrow><mml:mo>−</mml:mo><mml:mi>h</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mtext>with</mml:mtext><mml:mtext> </mml:mtext><mml:mtext> </mml:mtext><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="normal">Θ</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msup><mml:mo>.</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>Here, <inline-formula><mml:math id="inf134"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes the vector of current perturbations, and <inline-formula><mml:math id="inf135"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>h</mml:mi><mml:mo>∗</mml:mo><mml:mrow><mml:mi mathvariant="bold">p</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> denotes a convolution of the perturbation currents with an exponential kernel, <inline-formula><mml:math id="inf136"><mml:mrow><mml:mi>h</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. Note that moving the perturbation onto the threshold does not change the spiking behavior of the neuron. <xref ref-type="table" rid="app1table1">Appendix 1—table 1</xref> includes the range of perturbations used throughout this manuscript.</p><sec id="s4-8-1"><title>Voltage noise</title><p>We implement voltage noise as an extra random current on the voltage dynamics. This extra current follows a Wiener process scaled by <inline-formula><mml:math id="inf137"><mml:msub><mml:mi>σ</mml:mi><mml:mi>V</mml:mi></mml:msub></mml:math></inline-formula>, which denotes the standard deviation of the noise process with Gaussian increments (see <xref ref-type="disp-formula" rid="equ8">Equation 8</xref>). In the absence of recurrence,<disp-formula id="equ18"><label>(16)</label><mml:math id="m18"><mml:mrow><mml:mi>d</mml:mi><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mi>λ</mml:mi><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>ν</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mspace width="thinmathspace"/><mml:msqrt><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:msqrt><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:mi>ν</mml:mi><mml:mo>∼</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>so that the leaky integration with time constant <inline-formula><mml:math id="inf138"><mml:mi>λ</mml:mi></mml:math></inline-formula> biases the random walk of the thresholds back towards their default values. For stationary inputs, the thresholds therefore follow an Ornstein-Uhlenbeck process.</p></sec><sec id="s4-8-2"><title>Synaptic perturbations</title><p>We perturb synapses between different neurons (<inline-formula><mml:math id="inf139"><mml:mrow><mml:mi>i</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:math></inline-formula>) by a multiplicative noise term<disp-formula id="equ19"><label>(17)</label><mml:math id="m19"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>←</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="normal">Ω</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>*</mml:mo><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mi mathvariant="normal">Ω</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:msup></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf140"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>u</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">U</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula>. Here, the parameter <inline-formula><mml:math id="inf141"><mml:msub><mml:mi>δ</mml:mi><mml:mi mathvariant="normal">Ω</mml:mi></mml:msub></mml:math></inline-formula> is the maximum weight change in percentage of each synapse, which in <xref ref-type="fig" rid="fig6">Figure 6G</xref> is referred to as maximal synaptic scaling.</p></sec><sec id="s4-8-3"><title>Synaptic delays</title><p>We implement delayed recurrent connections with the same constant delay length <inline-formula><mml:math id="inf142"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>≥</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> for all pairs of neurons. Regardless of whether or not lateral excitation and inhibition are delayed in this way, the self-reset of a neuron onto itself remains instantaneous. <xref ref-type="disp-formula" rid="equ3">Equation 3</xref> thus becomes<disp-formula id="equ20"><label>(18)</label><mml:math id="m20"><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:mo>⁢</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:munderover><mml:mo largeop="true" movablelimits="false" symmetric="true">∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:munderover><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mi>i</mml:mi><mml:mo>⊤</mml:mo></mml:msubsup><mml:mo>⁢</mml:mo><mml:msub><mml:mi>D</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⋅</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>⋅</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf143"><mml:msub><mml:mi>δ</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula> is Kronecker’s delta. We assume that the decoder readout is equally delayed.</p></sec></sec><sec id="s4-9"><title>Parameter choices</title><p>The spiking networks presented here depend on several parameters:</p><list list-type="order"><list-item><p>The number of neurons in the network, <inline-formula><mml:math id="inf144"><mml:mi>N</mml:mi></mml:math></inline-formula>.</p></list-item><list-item><p>The number of signals fed into the network, <inline-formula><mml:math id="inf145"><mml:mi>M</mml:mi></mml:math></inline-formula>, also called the dimensionality of the signal.</p></list-item><list-item><p>The <inline-formula><mml:math id="inf146"><mml:mrow><mml:mi>M</mml:mi><mml:mo>×</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula> matrix of decoding weights, <inline-formula><mml:math id="inf147"><mml:msub><mml:mi>D</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>⁢</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math></inline-formula>, where each column <inline-formula><mml:math id="inf148"><mml:msub><mml:mi mathvariant="bold">D</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:math></inline-formula>, corresponds to the decoding weights of one neuron.</p></list-item><list-item><p>The inverse time constant of the exponential decay of the readout, <inline-formula><mml:math id="inf149"><mml:mi>λ</mml:mi></mml:math></inline-formula>.</p></list-item><list-item><p>The threshold (or error tolerances) of the neurons, <inline-formula><mml:math id="inf150"><mml:mi>T</mml:mi></mml:math></inline-formula>.</p></list-item><list-item><p>The refractory period, <inline-formula><mml:math id="inf151"><mml:msub><mml:mi>τ</mml:mi><mml:mtext>ref</mml:mtext></mml:msub></mml:math></inline-formula>.</p></list-item><list-item><p>The current noise, <inline-formula><mml:math id="inf152"><mml:msub><mml:mi>σ</mml:mi><mml:mi>V</mml:mi></mml:msub></mml:math></inline-formula>.</p></list-item></list><p>These parameters fully define both the dynamics and architecture – in terms of feedforward and recurrent connectivity – of the networks, as well as the geometry of the bounding box. We studied networks with various number of neurons <inline-formula><mml:math id="inf153"><mml:mi>N</mml:mi></mml:math></inline-formula> and input dimensionality <inline-formula><mml:math id="inf154"><mml:mi>M</mml:mi></mml:math></inline-formula>. The decoding weights of each neuron were drawn from an <inline-formula><mml:math id="inf155"><mml:mi>M</mml:mi></mml:math></inline-formula>-dimensional standard normal distribution,<disp-formula id="equ21"><label>(19)</label><mml:math id="m21"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>and then normalized,<disp-formula id="equ22"><label>(20)</label><mml:math id="m22"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">←</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>/</mml:mo></mml:mrow><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>such that each neuronal decoding vector is of length 1. We then did a sweep on the remaining parameters (<inline-formula><mml:math id="inf156"><mml:mi>λ</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf157"><mml:mi>T</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math id="inf158"><mml:msub><mml:mi>τ</mml:mi><mml:mtext>ref</mml:mtext></mml:msub></mml:math></inline-formula>, <inline-formula><mml:math id="inf159"><mml:msub><mml:mi>σ</mml:mi><mml:mi>V</mml:mi></mml:msub></mml:math></inline-formula>), to narrow down the range of parameters that roughly matches key observational constraints, such as low median firing rates (<inline-formula><mml:math id="inf160"><mml:mrow><mml:mi/><mml:mo>∼</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula> Hz), as found in cortex (<xref ref-type="bibr" rid="bib30">Hromádka et al., 2008</xref>; <xref ref-type="bibr" rid="bib60">Wohrer et al., 2013</xref>; <xref ref-type="fig" rid="fig5">Figure 5B</xref>), and coefficients of variation of interspike intervals close to one for each neuron, corresponding to Poisson-like spike statistics (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). <xref ref-type="table" rid="app1table1">Appendix 1—table 1</xref> displays the range of parameters used to simulate baseline and perturbed networks.</p></sec><sec id="s4-10"><title>Input signal</title><p>We used two different types of inputs throughout our simulations. The results shown in <xref ref-type="fig" rid="fig4">Figure 4</xref> and <xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5</xref> are for a circular, 2-dimensional signal,<disp-formula id="equ23"><label>(21)</label><mml:math id="m23"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mi>sin</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>ω</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo><mml:mi>a</mml:mi><mml:mi>cos</mml:mi><mml:mo>⁡</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>ω</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mspace width="-0.083em"/><mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:mrow></mml:msup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>with constant amplitude <inline-formula><mml:math id="inf161"><mml:mi>a</mml:mi></mml:math></inline-formula> and constant frequency <inline-formula><mml:math id="inf162"><mml:mi>ω</mml:mi></mml:math></inline-formula>.</p><p>For all other simulations shown in figure panels, the input signal was a constant signal with additive noise. More precisely, for each trial, we sampled a single point in input space from an <inline-formula><mml:math id="inf163"><mml:mi>M</mml:mi></mml:math></inline-formula>-dimensional Gaussian distribution,<disp-formula id="equ24"><label>(22)</label><mml:math id="m24"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn mathvariant="bold">0</mml:mn><mml:mo>,</mml:mo><mml:msubsup><mml:mi>σ</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mi mathvariant="bold">I</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The input signal ramps linearly from zero to this point <inline-formula><mml:math id="inf164"><mml:msub><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mn>0</mml:mn></mml:msub></mml:math></inline-formula> during the first 400ms. For the rest of the trial, the input to the neurons is set to slowly vary around this chosen input vector. To generate the slow variability, we sampled from an <inline-formula><mml:math id="inf165"><mml:mi>M</mml:mi></mml:math></inline-formula>-dimensional Gaussian distribution as many times as there were time steps in the rest of the trial; we then twice-filtered the samples with a moving average window of 1s for each dimension of <inline-formula><mml:math id="inf166"><mml:mi mathvariant="bold">x</mml:mi></mml:math></inline-formula>, and for each dimension of <inline-formula><mml:math id="inf167"><mml:mi mathvariant="bold">x</mml:mi></mml:math></inline-formula> and across time, we normalized the individual slow variabilities to not exceed <inline-formula><mml:math id="inf168"><mml:mrow><mml:msub><mml:mi>η</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0.5</mml:mn></mml:mrow></mml:math></inline-formula> in magnitude. This procedure was chosen to mimic experimental trial-to-trial noise.</p></sec><sec id="s4-11"><title>Metrics and network benchmarking</title><p>To compare the behavior of our networks under baseline conditions to those under the different perturbations, we need reliable measures of both coding accuracy and firing statistics. Below, we describe the measures used in this study.</p><sec id="s4-11-1"><title>Distributions of firing rates and coefficients of variation</title><p>We measured the time-averaged firing rate for a given neuron by dividing the total number of spikes by the total duration of a trial. The coefficient of variation (CV) of a single spike train is computed as the ratio of the standard deviation of the interspike intervals (ISI) to their mean<disp-formula id="equ25"><label>(23)</label><mml:math id="m25"><mml:mrow><mml:mrow><mml:mtext>CV</mml:mtext><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>σ</mml:mi><mml:mtext>ISI</mml:mtext></mml:msub><mml:msub><mml:mi>μ</mml:mi><mml:mtext>ISI</mml:mtext></mml:msub></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>We recorded the full distributions of both the firing rates and CVs for a given network, pooling across neurons and different trials.</p></sec><sec id="s4-11-2"><title>Network performance</title><p>When our aim was to compare the relative network performance with and without the different perturbations, we opted to use a simple Euclidean distance or L2 norm to measure the average error of each network:<disp-formula id="equ26"><label>(24)</label><mml:math id="m26"><mml:mrow><mml:mi>E</mml:mi><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>To compute the relative performance, we divided the error of the perturbed network by the error of the equivalent, unperturbed network using the formula<disp-formula id="equ27"><label>(25)</label><mml:math id="m27"><mml:mrow><mml:mrow><mml:mi>P</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mtext>perturbed</mml:mtext></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mtext>dead</mml:mtext></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mtext>reference</mml:mtext></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>E</mml:mi><mml:mtext>dead</mml:mtext></mml:msub></mml:mrow></mml:mfrac></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf169"><mml:msub><mml:mi>E</mml:mi><mml:mtext>dead</mml:mtext></mml:msub></mml:math></inline-formula> is the error of a non-functional or dead network (<inline-formula><mml:math id="inf170"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> or <inline-formula><mml:math id="inf171"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>E</mml:mi><mml:mrow><mml:mtext>dead</mml:mtext></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo fence="false" stretchy="false">⟨</mml:mo><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo fence="false" stretchy="false">‖</mml:mo><mml:msub><mml:mo fence="false" stretchy="false">⟩</mml:mo><mml:mrow><mml:mi>t</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula>). We included this case to provide a baseline, worst-case scenario.</p><p>A key limitation with most error measures is that they scale in various ways with dimensionality. This becomes an issue in <xref ref-type="fig" rid="fig5">Figure 5</xref> as this hinders the comparison of errors across different signal dimensionalities. For this particular case, we chose to measure the coding errors in a dimensionality-independent way by pooling together the errors in each individual signal component, <inline-formula><mml:math id="inf172"><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>x</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow></mml:math></inline-formula>. We can then compute the median of this aggregated distribution in order to consistently compare the performance of these networks across different signal dimensionalities.</p></sec><sec id="s4-11-3"><title>Excitation-inhibition balance</title><p>In order to compute the EI balance of a given neuron <inline-formula><mml:math id="inf173"><mml:mi>j</mml:mi></mml:math></inline-formula>, we divided the total synaptic input throughout a given trial into its positive (<inline-formula><mml:math id="inf174"><mml:msubsup><mml:mi>C</mml:mi><mml:mi>j</mml:mi><mml:mo>+</mml:mo></mml:msubsup></mml:math></inline-formula>) and negative (<inline-formula><mml:math id="inf175"><mml:msubsup><mml:mi>C</mml:mi><mml:mi>j</mml:mi><mml:mo>-</mml:mo></mml:msubsup></mml:math></inline-formula>) components<disp-formula id="equ28"><label>(26)</label><mml:math id="m28"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mspace width="thickmathspace"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="-0.083em"/><mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mo movablelimits="true" form="prefix">max</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="-0.083em"/><mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula><disp-formula id="equ29"><label>(27)</label><mml:math id="m29"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mo>−</mml:mo></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mo>∫</mml:mo><mml:mi>d</mml:mi><mml:mi>t</mml:mi><mml:mspace width="thickmathspace"/><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="-0.083em"/><mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mover><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>˙</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>−</mml:mo><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>≠</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow><mml:mrow><mml:mspace width="-0.083em"/><mml:mrow><mml:mi mathvariant="sans-serif">T</mml:mi></mml:mrow></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi mathvariant="bold">D</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>The normalized E-I difference <italic>b</italic><sub><italic>j</italic></sub> of a neuron <inline-formula><mml:math id="inf176"><mml:mi>j</mml:mi></mml:math></inline-formula> was then computed as<disp-formula id="equ30"><label>(28)</label><mml:math id="m30"><mml:mrow><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mi>j</mml:mi><mml:mo>+</mml:mo></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mi>C</mml:mi><mml:mi>j</mml:mi><mml:mo>-</mml:mo></mml:msubsup></mml:mrow><mml:mrow><mml:msubsup><mml:mi>C</mml:mi><mml:mi>j</mml:mi><mml:mo>+</mml:mo></mml:msubsup><mml:mo>+</mml:mo><mml:msubsup><mml:mi>C</mml:mi><mml:mi>j</mml:mi><mml:mo>-</mml:mo></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>In other words, <inline-formula><mml:math id="inf177"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> if a neuron is perfectly balanced, <inline-formula><mml:math id="inf178"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>0</mml:mn><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>≤</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> if a neuron receives more excitation than inhibition and <inline-formula><mml:math id="inf179"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&lt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> if a neuron receives more inhibition than excitation.</p></sec><sec id="s4-11-4"><title>Benchmarking</title><p>To fully compare the behavior of the networks under baseline conditions to those under the different perturbations, we adopted the following benchmarking procedure: each simulated trial with a perturbation is compared to an otherwise identical trial without perturbation. For each trial, we generated a new network with a different random distribution of decoding weights, random input signal, and random voltage noise. These parameters were used for both the perturbed and unperturbed trial. We then applied our <inline-formula><mml:math id="inf180"><mml:mi>M</mml:mi></mml:math></inline-formula>-dimensional input signal <inline-formula><mml:math id="inf181"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> as described above, and recorded coding error and spiking statistics for both perturbed and unperturbed trial. This procedure was repeated multiple times (<inline-formula><mml:math id="inf182"><mml:mrow><mml:msub><mml:mi>N</mml:mi><mml:mtext>trials</mml:mtext></mml:msub><mml:mo>≥</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></inline-formula>), each repetition resulting in different network connectivity, inputs, and injected current noise, and each pair of trials returning one performance value as defined above.</p><p>We choose this benchmarking procedure to sample the space of input signals in an unbiased way. This ensures that network performance is not accidentally dominated by a perfect match, or mismatch, between the fixed decoding weights and a given random input. Particularly bad mismatches may still lead to high decoding errors, but because our error measure considers the median response, these extremes do not bias our benchmarking procedure.</p></sec><sec id="s4-11-5"><title>Number of simulations</title><p><xref ref-type="fig" rid="fig1">Figure 1D</xref> shows a single trial. <xref ref-type="fig" rid="fig5">Figure 5</xref> shows a total of 29,400 trials. <xref ref-type="fig" rid="fig6">Figure 6E and F</xref> show 16,830 pairs of trials, and <xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4</xref> shows 4996 pairs. Panels <xref ref-type="fig" rid="fig6">Figure 6G and H</xref> consist of 840 trials each. <xref ref-type="fig" rid="fig7">Figure 7G</xref> show 18,000 pairs of trials, or 200 pairs per data point, and <xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5</xref> shows 1 perturbed trial per row.</p></sec></sec><sec id="s4-12"><title>Numerical implementation</title><p>We numerically solve the differential equations (<xref ref-type="disp-formula" rid="equ8">Equation 8</xref>) describing the temporal evolution of membrane voltage by the forward Euler-Maruyama method. Because of finite simulation time steps, more than one neural threshold may be crossed during the same step, and more than one neuron may thus be eligible to spike. This problem can be circumvented by decreasing the time step, which, however, increases simulation time. To avoid this tradeoff, we essentially slow down time whenever multiple neurons crossed threshold (Appendix 1—algorithm 1). Note that when considering finite delays <inline-formula><mml:math id="inf183"><mml:mi>θ</mml:mi></mml:math></inline-formula>, delayed lateral recurrence arrives only at the end of each time step (Appendix 1—algorithm 2).</p><p>We implemented these methods in both MATLAB and Python, and both sets of code can be used interchangeably. Our code for simulation, analysis and figure generation, as well as sample data files can be found at <ext-link ext-link-type="uri" xlink:href="https://github.com/machenslab/boundingbox">https://github.com/machenslab/boundingbox</ext-link> (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:a76b55657d7ff144756c94b46ee5cc43941b0e7f;origin=https://github.com/machenslab/boundingbox;visit=swh:1:snp:5c97b1d5b5f1a966125908af7b4b4f8e4edd7dad;anchor=swh:1:rev:d9ce2cf52e833ecf67dccc796bd8c9dc505f2e00">swh:1:rev:d9ce2cf52e833ecf67dccc796bd8c9dc505f2e00</ext-link>, <xref ref-type="bibr" rid="bib11">Calaim, 2022</xref>), under a <ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons CC BY-NC-SA 4.0 license</ext-link>.</p></sec><sec id="s4-13"><title>Iterative adaptation of parameters to avoid ping-pong</title><p>In networks with delays, we can avoid ping-pong either by increasing box size or by removing a number of strongest excitatory connections. In both cases, we compute the minimum required value offline using an iterative procedure (Appendix 1—algorithm 3). Note that trials must be sufficiently long to avoid false-negative reports of ping-pong.</p></sec><sec id="s4-14"><title>Movie visualization</title><p>All movies (<xref ref-type="video" rid="video1">Videos 1</xref> and <xref ref-type="video" rid="video2">2</xref>) were produced in Python, with the exception of the three-dimensional visualization of a polytope, for which we used the <italic>bensolve</italic> toolbox for MATLAB (<xref ref-type="bibr" rid="bib37">Löhne and Weißing, 2017</xref>).</p></sec><sec id="s4-15"><title>FORCE-learning rate network and perturbations</title><p>We trained a recurrent network of 1000 rate units using FORCE learning (<xref ref-type="bibr" rid="bib52">Sussillo and Abbott, 2009</xref>) in the absence of any perturbation. The network dynamics are described by the following system of differential equations:<disp-formula id="equ31"><label>(29)</label><mml:math id="m31"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mi>τ</mml:mi><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>−</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mi>g</mml:mi><mml:mrow><mml:mi mathvariant="bold">J</mml:mi><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">J</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow></mml:mrow></mml:msub><mml:mrow><mml:mi mathvariant="bold">z</mml:mi></mml:mrow></mml:mstyle></mml:mrow></mml:math></disp-formula></p><p>where <inline-formula><mml:math id="inf184"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold">r</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mi>tanh</mml:mi><mml:mo>⁡</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mstyle></mml:math></inline-formula> corresponds to the firing rates, and where <inline-formula><mml:math id="inf185"><mml:mrow><mml:mi>τ</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula>ms, <inline-formula><mml:math id="inf186"><mml:mrow><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mn>1.5</mml:mn></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="inf187"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mi mathvariant="bold">J</mml:mi></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> is a sparse random matrix whose elements are zero with probability <inline-formula><mml:math id="inf188"><mml:mrow><mml:mn>1</mml:mn><mml:mo>-</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:math></inline-formula>. Each nonzero element is drawn independently from a Gaussian distribution with zero mean and variance equal to <inline-formula><mml:math id="inf189"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1000</mml:mn><mml:mi>p</mml:mi><mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula>. The entries of the matrix <inline-formula><mml:math id="inf190"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">J</mml:mi></mml:mrow><mml:mi>z</mml:mi></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> are uniformly distributed from –1 to 1.</p><p>We then applied one of three perturbations to the fully trained network: neuron death, rate noise, or synaptic perturbation. We emulated neural loss by setting the respective neural activities to zero, i.e. <inline-formula><mml:math id="inf191"><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. The rate noise perturbation was simulated by injecting white noise within the input-output non-linearity and its magnitude was chosen so that fluctuations on the network activities were of the same order of magnitude as the ones simulated for coordinated spiking networks. Finally, we simulated synaptic perturbations following the same procedure and magnitude as for the coordinated spiking networks, i.e., each element of the recurrent connectivity matrix was changed randomly up to 2.5% of its value.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Project administration, Software, Validation, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Data curation, Formal analysis, Investigation, Methodology, Project administration, Software, Validation, Visualization, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con3"><p>Project administration, Supervision, Writing – original draft, Writing – review and editing</p></fn><fn fn-type="con" id="con4"><p>Conceptualization, Funding acquisition, Methodology, Project administration, Resources, Software, Supervision, Visualization, Writing – original draft, Writing – review and editing, Formal analysis, Investigation, Validation</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media xlink:href="elife-73276-transrepform1-v2.pdf" mimetype="application" mime-subtype="pdf"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>The current manuscript is a computational study, so no data have been generated for this manuscript. Modelling code is uploaded on <ext-link ext-link-type="uri" xlink:href="https://github.com/machenslab/boundingbox">https://github.com/machenslab/boundingbox</ext-link>, (copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:a76b55657d7ff144756c94b46ee5cc43941b0e7f;origin=https://github.com/machenslab/boundingbox;visit=swh:1:snp:5c97b1d5b5f1a966125908af7b4b4f8e4edd7dad;anchor=swh:1:rev:d9ce2cf52e833ecf67dccc796bd8c9dc505f2e00">swh:1:rev:d9ce2cf52e833ecf67dccc796bd8c9dc505f2e00</ext-link>).</p></sec><ack id="ack"><title>Acknowledgements</title><p>We thank Alfonso Renart for helpful discussions and comments on the manuscript. This work was supported by the Fundação para a Ciência e a Tecnologia (project FCT-PTDC/BIA-OUT/32077/2017-IC&amp;DT-LISBOA-01-0145-FEDER) and by the Simons Foundation (Simons Collaboration on the Global Brain #543009).</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barak</surname><given-names>O</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Recurrent neural networks as versatile tools of neuroscience research</article-title><source>Current Opinion in Neurobiology</source><volume>46</volume><fpage>1</fpage><lpage>6</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2017.06.003</pub-id><pub-id pub-id-type="pmid">28668365</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Barrett</surname><given-names>DG</given-names></name><name><surname>Denève</surname><given-names>S</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Firing rate predictions in optimal balanced networks</article-title><conf-name>Advances in Neural Information Processing Systems 26</conf-name></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barrett</surname><given-names>DG</given-names></name><name><surname>Denève</surname><given-names>S</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Optimal compensation for neuron loss</article-title><source>eLife</source><volume>5</volume><elocation-id>e12454</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.12454</pub-id><pub-id pub-id-type="pmid">27935480</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barrett</surname><given-names>DG</given-names></name><name><surname>Morcos</surname><given-names>AS</given-names></name><name><surname>Macke</surname><given-names>JH</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Analyzing biological and artificial neural networks: challenges with opportunities for synergy?</article-title><source>Current Opinion in Neurobiology</source><volume>55</volume><fpage>55</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2019.01.007</pub-id><pub-id pub-id-type="pmid">30785004</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Biggio</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Evasion attacks against machine learning at test time</article-title><conf-name>Joint European conference on machine learning and knowledge discovery in databases</conf-name><fpage>387</fpage><lpage>402</lpage><pub-id pub-id-type="doi">10.1007/978-3-642-38709-8</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boahen</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A neuromorph’s prospectus</article-title><source>Computing in Science &amp; Engineering</source><volume>19</volume><fpage>14</fpage><lpage>28</lpage><pub-id pub-id-type="doi">10.1109/MCSE.2017.33</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boerlin</surname><given-names>M</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name><name><surname>Denève</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Predictive coding of dynamical variables in balanced spiking networks</article-title><source>PLOS Computational Biology</source><volume>9</volume><elocation-id>e1003258</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1003258</pub-id><pub-id pub-id-type="pmid">24244113</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bourdoukan</surname><given-names>R</given-names></name><name><surname>Barrett</surname><given-names>D</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name><name><surname>Deneve</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Learning optimal spike-based representations</article-title><conf-name>Advances in Neural Information Processing Systems 25</conf-name></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bredesen</surname><given-names>DE</given-names></name><name><surname>Rao</surname><given-names>RV</given-names></name><name><surname>Mehlen</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Cell death in the nervous system</article-title><source>Nature</source><volume>443</volume><fpage>796</fpage><lpage>802</lpage><pub-id pub-id-type="doi">10.1038/nature05293</pub-id><pub-id pub-id-type="pmid">17051206</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brendel</surname><given-names>W</given-names></name><name><surname>Bourdoukan</surname><given-names>R</given-names></name><name><surname>Vertechi</surname><given-names>P</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name><name><surname>Denève</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Learning to represent signals spike by spike</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1007692</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1007692</pub-id><pub-id pub-id-type="pmid">32176682</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="software"><person-group person-group-type="author"><name><surname>Calaim</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2022">2022</year><data-title>boundingbox</data-title><version designator="swh:1:rev:d9ce2cf52e833ecf67dccc796bd8c9dc505f2e00">swh:1:rev:d9ce2cf52e833ecf67dccc796bd8c9dc505f2e00</version><source>Software Heritage</source><ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:dir:a76b55657d7ff144756c94b46ee5cc43941b0e7f;origin=https://github.com/machenslab/boundingbox;visit=swh:1:snp:5c97b1d5b5f1a966125908af7b4b4f8e4edd7dad;anchor=swh:1:rev:d9ce2cf52e833ecf67dccc796bd8c9dc505f2e00">https://archive.softwareheritage.org/swh:1:dir:a76b55657d7ff144756c94b46ee5cc43941b0e7f;origin=https://github.com/machenslab/boundingbox;visit=swh:1:snp:5c97b1d5b5f1a966125908af7b4b4f8e4edd7dad;anchor=swh:1:rev:d9ce2cf52e833ecf67dccc796bd8c9dc505f2e00</ext-link></element-citation></ref><ref id="bib12"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Carlini</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>On Evaluating Adversarial Robustness</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1902.06705">https://arxiv.org/abs/1902.06705</ext-link></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chalk</surname><given-names>M</given-names></name><name><surname>Gutkin</surname><given-names>B</given-names></name><name><surname>Denève</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Neural oscillations as a signature of efficient coding in the presence of synaptic delays</article-title><source>eLife</source><volume>5</volume><elocation-id>e13824</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.13824</pub-id><pub-id pub-id-type="pmid">27383272</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coelho</surname><given-names>DS</given-names></name><name><surname>Schwartz</surname><given-names>S</given-names></name><name><surname>Merino</surname><given-names>MM</given-names></name><name><surname>Hauert</surname><given-names>B</given-names></name><name><surname>Topfel</surname><given-names>B</given-names></name><name><surname>Tieche</surname><given-names>C</given-names></name><name><surname>Rhiner</surname><given-names>C</given-names></name><name><surname>Moreno</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Culling Less Fit Neurons Protects against Amyloid-β-Induced Brain Damage and Cognitive and Motor Decline</article-title><source>Cell Reports</source><volume>25</volume><fpage>3661</fpage><lpage>3673</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2018.11.098</pub-id><pub-id pub-id-type="pmid">30590040</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Csete</surname><given-names>ME</given-names></name><name><surname>Doyle</surname><given-names>JC</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Reverse engineering of biological complexity</article-title><source>Science</source><volume>295</volume><fpage>1664</fpage><lpage>1669</lpage><pub-id pub-id-type="doi">10.1126/science.1069981</pub-id><pub-id pub-id-type="pmid">11872830</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cunningham</surname><given-names>JP</given-names></name><name><surname>Yu</surname><given-names>BM</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Dimensionality reduction for large-scale neural recordings</article-title><source>Nature Neuroscience</source><volume>17</volume><fpage>1500</fpage><lpage>1509</lpage><pub-id pub-id-type="doi">10.1038/nn.3776</pub-id><pub-id pub-id-type="pmid">25151264</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dalgleish</surname><given-names>HW</given-names></name><name><surname>Russell</surname><given-names>LE</given-names></name><name><surname>Packer</surname><given-names>AM</given-names></name><name><surname>Roth</surname><given-names>A</given-names></name><name><surname>Gauld</surname><given-names>OM</given-names></name><name><surname>Greenstreet</surname><given-names>F</given-names></name><name><surname>Thompson</surname><given-names>EJ</given-names></name><name><surname>Häusser</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>How many neurons are sufficient for perception of cortical activity?</article-title><source>eLife</source><volume>9</volume><elocation-id>e58889</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.58889</pub-id><pub-id pub-id-type="pmid">33103656</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Destexhe</surname><given-names>A</given-names></name><name><surname>Rudolph</surname><given-names>M</given-names></name><name><surname>Fellous</surname><given-names>JM</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Fluctuating synaptic conductances recreate in vivo-like activity in neocortical neurons</article-title><source>Neuroscience</source><volume>107</volume><fpage>13</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1016/s0306-4522(01)00344-x</pub-id><pub-id pub-id-type="pmid">11744242</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Eliasmith</surname><given-names>C</given-names></name><name><surname>Anderson</surname><given-names>CH</given-names></name></person-group><year iso-8601-date="2004">2004</year><source>Neural Engineering: Computation, Representation, and Dynamics in Neurobiological Systems</source><publisher-name>MIT Press</publisher-name></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eliasmith</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>A unified approach to building and controlling spiking attractor networks</article-title><source>Neural Computation</source><volume>17</volume><fpage>1276</fpage><lpage>1314</lpage><pub-id pub-id-type="doi">10.1162/0899766053630332</pub-id><pub-id pub-id-type="pmid">15901399</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faisal</surname><given-names>AA</given-names></name><name><surname>Selen</surname><given-names>LPJ</given-names></name><name><surname>Wolpert</surname><given-names>DM</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Noise in the nervous system</article-title><source>Nature Reviews. Neuroscience</source><volume>9</volume><fpage>292</fpage><lpage>303</lpage><pub-id pub-id-type="doi">10.1038/nrn2258</pub-id><pub-id pub-id-type="pmid">18319728</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Félix</surname><given-names>M-A</given-names></name><name><surname>Barkoulas</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Pervasive robustness in biological systems</article-title><source>Nature Reviews. Genetics</source><volume>16</volume><fpage>483</fpage><lpage>496</lpage><pub-id pub-id-type="doi">10.1038/nrg3949</pub-id><pub-id pub-id-type="pmid">26184598</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fellous</surname><given-names>JM</given-names></name><name><surname>Rudolph</surname><given-names>M</given-names></name><name><surname>Destexhe</surname><given-names>A</given-names></name><name><surname>Sejnowski</surname><given-names>TJ</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Synaptic background noise controls the input/output characteristics of single cells in an in vitro model of in vivo activity</article-title><source>Neuroscience</source><volume>122</volume><fpage>811</fpage><lpage>829</lpage><pub-id pub-id-type="doi">10.1016/j.neuroscience.2003.08.027</pub-id><pub-id pub-id-type="pmid">14622924</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fetsch</surname><given-names>CR</given-names></name><name><surname>Odean</surname><given-names>NN</given-names></name><name><surname>Jeurissen</surname><given-names>D</given-names></name><name><surname>El-Shamayleh</surname><given-names>Y</given-names></name><name><surname>Horwitz</surname><given-names>GD</given-names></name><name><surname>Shadlen</surname><given-names>MN</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Focal optogenetic suppression in macaque area MT biases direction discrimination and decision confidence, but only transiently</article-title><source>eLife</source><volume>7</volume><elocation-id>e36523</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.36523</pub-id><pub-id pub-id-type="pmid">30051817</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gerstner</surname><given-names>W</given-names></name><name><surname>Kistler</surname><given-names>WM</given-names></name><name><surname>Naud</surname><given-names>R</given-names></name><name><surname>Paninski</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2014">2014</year><source>Neuronal Dynamics: From Single Neurons to Networks and Models of Cognition</source><publisher-name>Cambridge University Press</publisher-name><pub-id pub-id-type="doi">10.1017/CBO9781107447615</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldman</surname><given-names>MS</given-names></name><name><surname>Levine</surname><given-names>JH</given-names></name><name><surname>Major</surname><given-names>G</given-names></name><name><surname>Tank</surname><given-names>DW</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>Robust persistent neural activity in a model integrator with multiple hysteretic dendrites per neuron</article-title><source>Cerebral Cortex</source><volume>13</volume><fpage>1185</fpage><lpage>1195</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhg095</pub-id><pub-id pub-id-type="pmid">14576210</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haddad</surname><given-names>SA</given-names></name><name><surname>Marder</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Circuit Robustness to Temperature Perturbation Is Altered by Neuromodulators</article-title><source>Neuron</source><volume>100</volume><fpage>609</fpage><lpage>623</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.08.035</pub-id><pub-id pub-id-type="pmid">30244886</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hopfield</surname><given-names>JJ</given-names></name></person-group><year iso-8601-date="1982">1982</year><article-title>Neural networks and physical systems with emergent collective computational abilities</article-title><source>PNAS</source><volume>79</volume><fpage>2554</fpage><lpage>2558</lpage><pub-id pub-id-type="doi">10.1073/pnas.79.8.2554</pub-id><pub-id pub-id-type="pmid">6953413</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Houweling</surname><given-names>AR</given-names></name><name><surname>Brecht</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Behavioural report of single neuron stimulation in somatosensory cortex</article-title><source>Nature</source><volume>451</volume><fpage>65</fpage><lpage>68</lpage><pub-id pub-id-type="doi">10.1038/nature06447</pub-id><pub-id pub-id-type="pmid">18094684</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hromádka</surname><given-names>T</given-names></name><name><surname>DeWeese</surname><given-names>MR</given-names></name><name><surname>Zador</surname><given-names>AM</given-names></name><name><surname>Plenz</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Sparse Representation of Sounds in the Unanesthetized Auditory Cortex</article-title><source>PLOS Biology</source><volume>6</volume><elocation-id>e60016</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0060016</pub-id><pub-id pub-id-type="pmid">18232737</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huber</surname><given-names>D</given-names></name><name><surname>Petreanu</surname><given-names>L</given-names></name><name><surname>Ghitani</surname><given-names>N</given-names></name><name><surname>Ranade</surname><given-names>S</given-names></name><name><surname>Hromádka</surname><given-names>T</given-names></name><name><surname>Mainen</surname><given-names>Z</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Sparse optical microstimulation in barrel cortex drives learned behaviour in freely moving mice</article-title><source>Nature</source><volume>451</volume><fpage>61</fpage><lpage>64</lpage><pub-id pub-id-type="doi">10.1038/nature06445</pub-id><pub-id pub-id-type="pmid">18094685</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Keemink</surname><given-names>SW</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Decoding and encoding (de)mixed population responses</article-title><source>Current Opinion in Neurobiology</source><volume>58</volume><fpage>112</fpage><lpage>121</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2019.09.004</pub-id><pub-id pub-id-type="pmid">31563083</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kitano</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Biological robustness</article-title><source>Nature Reviews. Genetics</source><volume>5</volume><fpage>826</fpage><lpage>837</lpage><pub-id pub-id-type="doi">10.1038/nrg1471</pub-id><pub-id pub-id-type="pmid">15520792</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koulakov</surname><given-names>AA</given-names></name><name><surname>Raghavachari</surname><given-names>S</given-names></name><name><surname>Kepecs</surname><given-names>A</given-names></name><name><surname>Lisman</surname><given-names>JE</given-names></name></person-group><year iso-8601-date="2002">2002</year><article-title>Model for a robust neural integrator</article-title><source>Nature Neuroscience</source><volume>5</volume><fpage>775</fpage><lpage>782</lpage><pub-id pub-id-type="doi">10.1038/nn893</pub-id><pub-id pub-id-type="pmid">12134153</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>N</given-names></name><name><surname>Daie</surname><given-names>K</given-names></name><name><surname>Svoboda</surname><given-names>K</given-names></name><name><surname>Druckmann</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Robust neuronal dynamics in premotor cortex during motor planning</article-title><source>Nature</source><volume>532</volume><fpage>459</fpage><lpage>464</lpage><pub-id pub-id-type="doi">10.1038/nature17643</pub-id><pub-id pub-id-type="pmid">27074502</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lim</surname><given-names>S</given-names></name><name><surname>Goldman</surname><given-names>MS</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Balanced cortical microcircuitry for maintaining information in working memory</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>1306</fpage><lpage>1314</lpage><pub-id pub-id-type="doi">10.1038/nn.3492</pub-id><pub-id pub-id-type="pmid">23955560</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Löhne</surname><given-names>A</given-names></name><name><surname>Weißing</surname><given-names>B</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>The vector linear program solver Bensolve – notes on theoretical background</article-title><source>European Journal of Operational Research</source><volume>260</volume><fpage>807</fpage><lpage>813</lpage><pub-id pub-id-type="doi">10.1016/j.ejor.2016.02.039</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Maass</surname><given-names>W</given-names></name><name><surname>Bishop</surname><given-names>CM</given-names></name></person-group><year iso-8601-date="1999">1999</year><source>Pulsed Neural Networks</source><publisher-name>MIT press</publisher-name><pub-id pub-id-type="doi">10.7551/mitpress/5704.001.0001</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Mancoo</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Understanding spiking networks through convex optimization</article-title><conf-name>Advances in Neural Information Processing Systems 33</conf-name></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mastrogiuseppe</surname><given-names>F</given-names></name><name><surname>Ostojic</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Linking Connectivity, Dynamics, and Computations in Low-Rank Recurrent Neural Networks</article-title><source>Neuron</source><volume>99</volume><fpage>609</fpage><lpage>623</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.07.003</pub-id><pub-id pub-id-type="pmid">30057201</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Morcos</surname><given-names>AS</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>On the Importance of Single Directions for Generalization</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1803.06959">https://arxiv.org/abs/1803.06959</ext-link></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moreno</surname><given-names>E</given-names></name><name><surname>Fernandez-Marrero</surname><given-names>Y</given-names></name><name><surname>Meyer</surname><given-names>P</given-names></name><name><surname>Rhiner</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Brain regeneration in <italic>Drosophila</italic> involves comparison of neuronal fitness</article-title><source>Current Biology</source><volume>25</volume><fpage>955</fpage><lpage>963</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2015.02.014</pub-id><pub-id pub-id-type="pmid">25754635</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Morrison</surname><given-names>JH</given-names></name><name><surname>Hof</surname><given-names>PR</given-names></name></person-group><year iso-8601-date="1997">1997</year><article-title>Life and death of neurons in the aging brain</article-title><source>Science</source><volume>278</volume><fpage>412</fpage><lpage>419</lpage><pub-id pub-id-type="doi">10.1126/science.278.5337.412</pub-id><pub-id pub-id-type="pmid">9334292</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Olshausen</surname><given-names>BA</given-names></name><name><surname>Field</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Emergence of simple-cell receptive field properties by learning a sparse code for natural images</article-title><source>Nature</source><volume>381</volume><fpage>607</fpage><lpage>609</lpage><pub-id pub-id-type="doi">10.1038/381607a0</pub-id><pub-id pub-id-type="pmid">8637596</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>O’Leary</surname><given-names>T</given-names></name><name><surname>Marder</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Temperature-Robust Neural Function from Activity-Dependent Ion Channel Regulation</article-title><source>Current Biology</source><volume>26</volume><fpage>2935</fpage><lpage>2941</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2016.08.061</pub-id><pub-id pub-id-type="pmid">27746024</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palop</surname><given-names>JJ</given-names></name><name><surname>Chin</surname><given-names>J</given-names></name><name><surname>Mucke</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>A network dysfunction perspective on neurodegenerative diseases</article-title><source>Nature</source><volume>443</volume><fpage>768</fpage><lpage>773</lpage><pub-id pub-id-type="doi">10.1038/nature05289</pub-id><pub-id pub-id-type="pmid">17051202</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rullán Buxó</surname><given-names>CE</given-names></name><name><surname>Pillow</surname><given-names>JW</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Poisson balanced spiking networks</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1008261</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008261</pub-id><pub-id pub-id-type="pmid">33216741</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Savin</surname><given-names>C</given-names></name><name><surname>Deneve</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Spatio-temporal representations of uncertainty in spiking neural networks</article-title><conf-name>Advances in Neural Information Processing Systems 27</conf-name></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saxena</surname><given-names>S</given-names></name><name><surname>Cunningham</surname><given-names>JP</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Towards the neural population doctrine</article-title><source>Current Opinion in Neurobiology</source><volume>55</volume><fpage>103</fpage><lpage>111</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2019.02.002</pub-id><pub-id pub-id-type="pmid">30877963</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seung</surname><given-names>HS</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>How the brain keeps the eyes still</article-title><source>PNAS</source><volume>93</volume><fpage>13339</fpage><lpage>13344</lpage><pub-id pub-id-type="doi">10.1073/pnas.93.23.13339</pub-id><pub-id pub-id-type="pmid">8917592</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seung</surname><given-names>HS</given-names></name><name><surname>Lee</surname><given-names>DD</given-names></name><name><surname>Reis</surname><given-names>BY</given-names></name><name><surname>Tank</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>Stability of the memory of eye position in a recurrent network of conductance-based model neurons</article-title><source>Neuron</source><volume>26</volume><fpage>259</fpage><lpage>271</lpage><pub-id pub-id-type="doi">10.1016/s0896-6273(00)81155-1</pub-id><pub-id pub-id-type="pmid">10798409</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Generating coherent patterns of activity from chaotic neural networks</article-title><source>Neuron</source><volume>63</volume><fpage>544</fpage><lpage>557</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2009.07.018</pub-id><pub-id pub-id-type="pmid">19709635</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Szegedy</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Intriguing Properties of Neural Networks</article-title><source>arXiv</source><ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1312.6199">https://arxiv.org/abs/1312.6199</ext-link></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thalmeier</surname><given-names>D</given-names></name><name><surname>Uhlmann</surname><given-names>M</given-names></name><name><surname>Kappen</surname><given-names>HJ</given-names></name><name><surname>Memmesheimer</surname><given-names>RM</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Learning Universal Computations with Spikes</article-title><source>PLOS Computational Biology</source><volume>12</volume><elocation-id>e1004895</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1004895</pub-id><pub-id pub-id-type="pmid">27309381</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Trouche</surname><given-names>S</given-names></name><name><surname>Perestenko</surname><given-names>PV</given-names></name><name><surname>van de Ven</surname><given-names>GM</given-names></name><name><surname>Bratley</surname><given-names>CT</given-names></name><name><surname>McNamara</surname><given-names>CG</given-names></name><name><surname>Campo-Urriza</surname><given-names>N</given-names></name><name><surname>Black</surname><given-names>SL</given-names></name><name><surname>Reijmers</surname><given-names>LG</given-names></name><name><surname>Dupret</surname><given-names>D</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Recoding a cocaine-place memory engram to a neutral engram in the hippocampus</article-title><source>Nature Neuroscience</source><volume>19</volume><fpage>564</fpage><lpage>567</lpage><pub-id pub-id-type="doi">10.1038/nn.4250</pub-id><pub-id pub-id-type="pmid">26900924</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Turrigiano</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Homeostatic synaptic plasticity: local and global mechanisms for stabilizing neuronal function</article-title><source>Cold Spring Harbor Perspectives in Biology</source><volume>4</volume><elocation-id>a005736</elocation-id><pub-id pub-id-type="doi">10.1101/cshperspect.a005736</pub-id><pub-id pub-id-type="pmid">22086977</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vogels</surname><given-names>TP</given-names></name><name><surname>Rajan</surname><given-names>K</given-names></name><name><surname>Abbott</surname><given-names>LF</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Neural network dynamics</article-title><source>Annual Review of Neuroscience</source><volume>28</volume><fpage>357</fpage><lpage>376</lpage><pub-id pub-id-type="doi">10.1146/annurev.neuro.28.061604.135637</pub-id><pub-id pub-id-type="pmid">16022600</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vyas</surname><given-names>S</given-names></name><name><surname>Golub</surname><given-names>MD</given-names></name><name><surname>Sussillo</surname><given-names>D</given-names></name><name><surname>Shenoy</surname><given-names>KV</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Computation Through Neural Population Dynamics</article-title><source>Annual Review of Neuroscience</source><volume>43</volume><fpage>249</fpage><lpage>275</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-092619-094115</pub-id><pub-id pub-id-type="pmid">32640928</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whitacre</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Biological robustness: paradigms, mechanisms, and systems principles</article-title><source>Frontiers in Genetics</source><volume>3</volume><elocation-id>67</elocation-id><pub-id pub-id-type="doi">10.3389/fgene.2012.00067</pub-id><pub-id pub-id-type="pmid">22593762</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wohrer</surname><given-names>A</given-names></name><name><surname>Humphries</surname><given-names>MD</given-names></name><name><surname>Machens</surname><given-names>CK</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Population-wide distributions of neural activity during perceptual decision-making</article-title><source>Progress in Neurobiology</source><volume>103</volume><fpage>156</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1016/j.pneurobio.2012.09.004</pub-id><pub-id pub-id-type="pmid">23123501</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolff</surname><given-names>SB</given-names></name><name><surname>Ölveczky</surname><given-names>BP</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The promise and perils of causal circuit manipulations</article-title><source>Current Opinion in Neurobiology</source><volume>49</volume><fpage>84</fpage><lpage>94</lpage><pub-id pub-id-type="doi">10.1016/j.conb.2018.01.004</pub-id><pub-id pub-id-type="pmid">29414070</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>K</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Representation of spatial orientation by the intrinsic dynamics of the head-direction cell ensemble: a theory</article-title><source>The Journal of Neuroscience</source><volume>16</volume><fpage>2112</fpage><lpage>2126</lpage><pub-id pub-id-type="pmid">8604055</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><table-wrap id="inlinetable1" position="anchor"><table frame="hsides" rules="groups"><tbody><tr><td align="left" valign="bottom"><bold>Appendix 1—algorithm 1.</bold> Numerical implementation of a general network with voltage noise <inline-formula><mml:math id="inf192"><mml:msub><mml:mi>σ</mml:mi><mml:mi>V</mml:mi></mml:msub></mml:math></inline-formula> and refractory period <inline-formula><mml:math id="inf193"><mml:msub><mml:mi>τ</mml:mi><mml:mtext>ref</mml:mtext></mml:msub></mml:math></inline-formula>.</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf194"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>K</mml:mi><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mspace width="thickmathspace"/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mspace width="thickmathspace"/><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mi mathvariant="double-struck">N</mml:mi></mml:mrow><mml:mo>:</mml:mo><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>k</mml:mi><mml:mo>≤</mml:mo><mml:mi>N</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>                   //all neurons initialise <break/><bold>for</bold> <inline-formula><mml:math id="inf195"><mml:mrow><mml:mi>t</mml:mi><mml:mo mathvariant="normal">=</mml:mo><mml:mn mathvariant="normal">0</mml:mn></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf196"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> in steps <inline-formula><mml:math id="inf197"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo mathvariant="italic">⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> <bold>do</bold><break/> <inline-formula><mml:math id="inf198"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>R</mml:mi><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mspace width="thickmathspace"/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mspace width="thickmathspace"/><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mi>K</mml:mi><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:munder><mml:mtext>arg\,max</mml:mtext><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>&lt;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>            //in refraction<break/> <inline-formula><mml:math id="inf199"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mspace width="thickmathspace"/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mspace width="thickmathspace"/><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mi>K</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>R</mml:mi><mml:mo>:</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>                  //spike candidates<break/><bold> while</bold> <inline-formula><mml:math id="inf200"><mml:mrow><mml:mi>C</mml:mi><mml:mo mathvariant="normal">≠</mml:mo><mml:mi mathvariant="normal">∅</mml:mi></mml:mrow></mml:math></inline-formula> <bold>do</bold><break/>  <inline-formula><mml:math id="inf201"><mml:mrow><mml:mi>w</mml:mi><mml:mo>←</mml:mo><mml:mrow><mml:munder accentunder="true"><mml:mtext>arg max</mml:mtext><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:munder><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>                 // furthest above threshold<break/>  <inline-formula><mml:math id="inf202"><mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>w</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>←</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>                                  //spike<break/>  <inline-formula><mml:math id="inf203"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mpadded lspace="-0.8pt" width="-0.8pt"><mml:mi>T</mml:mi></mml:mpadded></mml:msup><mml:mo>⁢</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mi>w</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>                      //instant recurrence<break/>  <inline-formula><mml:math id="inf204"><mml:mrow><mml:mi>R</mml:mi><mml:mo>←</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>∪</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>                             // refraction<break/>  <inline-formula><mml:math id="inf205"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mspace width="thickmathspace"/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mspace width="thickmathspace"/><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mi>K</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>R</mml:mi><mml:mo>:</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>                 // spike candidates<break/> <bold>end</bold><break/> sample <inline-formula><mml:math id="inf206"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">η</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn mathvariant="bold">0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula><break/> <inline-formula><mml:math id="inf207"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:msqrt><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+1.7pt"><mml:mi>t</mml:mi></mml:mpadded></mml:mrow></mml:msqrt></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">η </mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula><break/><bold>end</bold><break/></td></tr></tbody></table></table-wrap><table-wrap id="inlinetable2" position="anchor"> <table frame="hsides" rules="groups"><tbody><tr><td align="left" valign="bottom"><bold>Appendix 1—algorithm 2.</bold> Numerical implementation of a general network with finite delays <inline-formula><mml:math id="inf208"><mml:mi>θ</mml:mi></mml:math></inline-formula>, refractory period <inline-formula><mml:math id="inf209"><mml:msub><mml:mi>τ</mml:mi><mml:mtext>ref</mml:mtext></mml:msub></mml:math></inline-formula>, current noise <inline-formula><mml:math id="inf210"><mml:msub><mml:mi>σ</mml:mi><mml:mi>V</mml:mi></mml:msub></mml:math></inline-formula>, time-varying synaptic noise <inline-formula><mml:math id="inf211"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold">Ω</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and time-varying optogenetic currents <inline-formula><mml:math id="inf212"><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>.</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf213"><mml:mrow><mml:mi>K</mml:mi><mml:mo>←</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mpadded width="+2.8pt"><mml:mi>k</mml:mi></mml:mpadded><mml:mo rspace="5.3pt" stretchy="false">|</mml:mo><mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mi>ℕ</mml:mi></mml:mrow><mml:mo>:</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>≤</mml:mo><mml:mi>k</mml:mi><mml:mo>≤</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>                    // all neurons initialise<break/><inline-formula><mml:math id="inf214"><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo rspace="5.3pt" stretchy="false">)</mml:mo></mml:mrow><mml:mo>⁢</mml:mo><mml:mrow><mml:mo rspace="5.3pt">∀</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mrow><mml:mo>∈</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></inline-formula><break/><inline-formula><mml:math id="inf215"><mml:mrow><mml:mi mathvariant="bold">Ω</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mpadded lspace="-0.8pt" width="-0.8pt"><mml:mi>T</mml:mi></mml:mpadded></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">D</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>                           // standard recurrent matrix<break/><bold>if</bold> <inline-formula><mml:math id="inf216"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> <bold>then</bold><break/> <inline-formula><mml:math id="inf217"><mml:mrow><mml:msup><mml:mi mathvariant="bold">Ω</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mtext>diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="bold">Ω</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>                         // instant self-reset vector<break/> <inline-formula><mml:math id="inf218"><mml:mrow><mml:msup><mml:mi mathvariant="bold">Ω</mml:mi><mml:mi>θ</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="bold">Ω</mml:mi><mml:mo>-</mml:mo><mml:mrow><mml:mtext>diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold">Ω</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>                      // delayed recurrence matrix<break/><bold>end</bold><break/><bold>for</bold> <inline-formula><mml:math id="inf219"><mml:mrow><mml:mi>t</mml:mi><mml:mo mathvariant="normal">=</mml:mo><mml:mn mathvariant="normal">0</mml:mn></mml:mrow></mml:math></inline-formula> to <inline-formula><mml:math id="inf220"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mrow><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">x</mml:mi></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> in steps <inline-formula><mml:math id="inf221"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo mathvariant="italic">⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula> <bold>do</bold><break/> sample <inline-formula><mml:math id="inf222"><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">Ω</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mi mathvariant="bold">Ω</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold">Ω</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>                       // synaptic noise<break/> <bold>if</bold> <inline-formula><mml:math id="inf223"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> <bold>then</bold><break/>  <inline-formula><mml:math id="inf224"><mml:mrow><mml:msup><mml:mi mathvariant="bold">Ω</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mtext>diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">Ω</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>                      // instant self-reset vector<break/>  <inline-formula><mml:math id="inf225"><mml:mrow><mml:msup><mml:mi mathvariant="bold">Ω</mml:mi><mml:mi>θ</mml:mi></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mi mathvariant="bold">Ω</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mtext>diag</mml:mtext><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi mathvariant="bold">Ω</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>                  // delayed recurrence matrix<break/> <bold>end</bold><break/><break/> <inline-formula><mml:math id="inf226"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>R</mml:mi><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mspace width="thickmathspace"/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mspace width="thickmathspace"/><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mi>K</mml:mi><mml:mo>:</mml:mo><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:munder><mml:mtext>arg\,max</mml:mtext><mml:mrow><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>&lt;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:munder><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">(</mml:mo></mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">)</mml:mo></mml:mrow><mml:mo>&lt;</mml:mo><mml:msub><mml:mi>τ</mml:mi><mml:mrow><mml:mtext>ref</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>            // in refraction<break/> <inline-formula><mml:math id="inf227"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mspace width="thickmathspace"/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mspace width="thickmathspace"/><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mi>K</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>R</mml:mi><mml:mo>:</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>                   // spike candidates<break/> <bold>while</bold> <inline-formula><mml:math id="inf228"><mml:mrow><mml:mi>C</mml:mi><mml:mo mathvariant="normal">≠</mml:mo><mml:mi mathvariant="normal">∅</mml:mi></mml:mrow></mml:math></inline-formula> <bold>do</bold><break/>  <inline-formula><mml:math id="inf229"><mml:mrow><mml:mi>w</mml:mi><mml:mo>←</mml:mo><mml:mrow><mml:munder accentunder="true"><mml:mtext>arg max</mml:mtext><mml:mrow><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:munder><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msub><mml:mi>T</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>                // furthest above threshold<break/>  <inline-formula><mml:math id="inf230"><mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>w</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>←</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>                                  // spike<break/>  <bold>if</bold> <inline-formula><mml:math id="inf231"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> <bold>then</bold><break/>    <inline-formula><mml:math id="inf232"><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>w</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>w</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msubsup><mml:mi mathvariant="bold">Ω</mml:mi><mml:mi>w</mml:mi><mml:mi>f</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>                      // instant self-reset<break/>  <bold>else</bold><break/>    <inline-formula><mml:math id="inf233"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:msubsup><mml:mi mathvariant="bold">Ω</mml:mi><mml:mi>w</mml:mi><mml:mo>*</mml:mo></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>                       // instant recurrence<break/>  <bold>end</bold><break/>   <inline-formula><mml:math id="inf234"><mml:mrow><mml:mi>R</mml:mi><mml:mo>←</mml:mo><mml:mrow><mml:mi>R</mml:mi><mml:mo>∪</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mi>w</mml:mi><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>                               // refraction<break/>   <inline-formula><mml:math id="inf235"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>C</mml:mi><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mspace width="thickmathspace"/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mspace width="thickmathspace"/><mml:mi>k</mml:mi><mml:mo>∈</mml:mo><mml:mi>K</mml:mi><mml:mi mathvariant="normal">∖</mml:mi><mml:mi>R</mml:mi><mml:mo>:</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&gt;</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>                 // spike candidates<break/>  <bold>end</bold><break/>  <inline-formula><mml:math id="inf236"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo maxsize="120%" minsize="120%">(</mml:mo><mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi>λ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">x</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow><mml:mo maxsize="120%" minsize="120%">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>              // dynamics unperturbed network<break/>  sample <inline-formula><mml:math id="inf237"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi mathvariant="bold-italic">η</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>∼</mml:mo><mml:mrow><mml:mi mathvariant="script">N</mml:mi></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn mathvariant="bold">0</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mi>σ</mml:mi><mml:mrow><mml:mi>V</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mstyle></mml:math></inline-formula><break/>  <inline-formula><mml:math id="inf238"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mpadded width="+1.7pt"><mml:msqrt><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+1.7pt"><mml:mi>t</mml:mi></mml:mpadded></mml:mrow></mml:msqrt></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">η </mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>                       // current noise<break/>  <inline-formula><mml:math id="inf239"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mpadded width="+1.7pt"><mml:mi>t</mml:mi></mml:mpadded><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>                     // optogenetic currents<break/>  <bold>if</bold> <inline-formula><mml:math id="inf240"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>θ</mml:mi><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> <bold>then</bold><break/>   <inline-formula><mml:math id="inf241"><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow><mml:mo>-</mml:mo><mml:mrow><mml:msup><mml:mi mathvariant="bold">Ω</mml:mi><mml:mi>θ</mml:mi></mml:msup><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo>-</mml:mo><mml:mi>θ</mml:mi></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>                 // delayed recurrence<break/>  <bold>end</bold><break/><break/>  <inline-formula><mml:math id="inf242"><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>←</mml:mo><mml:mrow><mml:mrow><mml:mi mathvariant="bold-italic">V</mml:mi><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi mathvariant="bold-italic">V</mml:mi></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula><break/><bold>end</bold><break/></td></tr></tbody></table></table-wrap><table-wrap id="inlinetable3" position="anchor"><table frame="hsides" rules="groups"><tbody><tr><td align="left" valign="bottom"><bold>Appendix 1—algorithm 3.</bold> Numerical search for the &quot;safe width&quot; of a bounding box, avoiding ping-pong. Typical parameters are <inline-formula><mml:math id="inf243"><mml:mrow><mml:mpadded width="-1.7pt"><mml:msub><mml:mi>T</mml:mi><mml:mtext>min</mml:mtext></mml:msub></mml:mpadded><mml:mo rspace="0.8pt">=</mml:mo><mml:mn>0.55</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf244"><mml:mrow><mml:mpadded width="-1.7pt"><mml:mi>α</mml:mi></mml:mpadded><mml:mo rspace="0.8pt">=</mml:mo><mml:mn>1.5</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf245"><mml:mrow><mml:mpadded width="-1.7pt"><mml:mi>β</mml:mi></mml:mpadded><mml:mo rspace="0.8pt">=</mml:mo><mml:mn>0.95</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf246"><mml:mrow><mml:mpadded width="-1.7pt"><mml:mi>γ</mml:mi></mml:mpadded><mml:mo rspace="0.8pt">=</mml:mo><mml:mn>0.1</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf247"><mml:mrow><mml:mpadded width="-1.7pt"><mml:mi>ϵ</mml:mi></mml:mpadded><mml:mo rspace="0.8pt">=</mml:mo><mml:mrow><mml:mrow><mml:mn>0.05</mml:mn><mml:mo>⋅</mml:mo><mml:mn>2</mml:mn></mml:mrow><mml:mo>⁢</mml:mo><mml:mi>θ</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf248"><mml:mrow><mml:mpadded width="-1.7pt"><mml:mi>N</mml:mi></mml:mpadded><mml:mo rspace="0.8pt">=</mml:mo><mml:mn>100</mml:mn></mml:mrow></mml:math></inline-formula>. In each trial, all neurons <inline-formula><mml:math id="inf249"><mml:mi>j</mml:mi></mml:math></inline-formula> have the same threshold <inline-formula><mml:math id="inf250"><mml:msub><mml:mi>T</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:math></inline-formula>, and the box is thus widened or narrowed symmetrically.</td></tr><tr><td align="left" valign="bottom">initialise <inline-formula><mml:math id="inf251"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>T</mml:mi><mml:mo stretchy="false">←</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mrow><mml:mtext>min</mml:mtext></mml:mrow></mml:msub><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula>                        // current box width<break/>initialise <inline-formula><mml:math id="inf252"><mml:mrow><mml:msup><mml:mi>T</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mo>←</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>                          // best box width so far<break/>initialise <inline-formula><mml:math id="inf253"><mml:mrow><mml:mi>k</mml:mi><mml:mo>←</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>                              // trial counter<break/><bold>while</bold> <inline-formula><mml:math id="inf254"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>k</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> <bold>do</bold><break/> <inline-formula><mml:math id="inf255"><mml:mrow><mml:mi>k</mml:mi><mml:mo>←</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula><break/> simulate network with <inline-formula><mml:math id="inf256"><mml:mi>N</mml:mi></mml:math></inline-formula> neurons and box width <inline-formula><mml:math id="inf257"><mml:mi>T</mml:mi></mml:math></inline-formula><break/> <bold>for</bold> <inline-formula><mml:math id="inf258"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mn>1</mml:mn><mml:mo>&lt;</mml:mo><mml:mi>j</mml:mi><mml:mo>≤</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula> <bold>do</bold><break/>  <inline-formula><mml:math id="inf259"><mml:mrow><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>←</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mpadded width="+2.8pt"><mml:mi>t</mml:mi></mml:mpadded><mml:mo rspace="5.3pt" stretchy="false">|</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>⁢</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>                         // spike times<break/>  <inline-formula><mml:math id="inf260"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">{</mml:mo></mml:mrow><mml:mi>t</mml:mi><mml:mo>−</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mspace width="thickmathspace"/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mspace width="thickmathspace"/><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup><mml:mo>∈</mml:mo><mml:msub><mml:mi mathvariant="normal">Θ</mml:mi><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="thickmathspace"/><mml:mo>∧</mml:mo><mml:mspace width="thickmathspace"/><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mspace width="thinmathspace"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">n</mml:mi></mml:mrow><mml:mi>x</mml:mi></mml:munder><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>&gt;</mml:mo><mml:msup><mml:mi>t</mml:mi><mml:mrow><mml:mi mathvariant="normal">′</mml:mi></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo maxsize="1.2em" minsize="1.2em">}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>            // intervals<break/> <bold>end</bold><break/> <inline-formula><mml:math id="inf261"><mml:mrow><mml:mi>S</mml:mi><mml:mo>←</mml:mo><mml:mrow><mml:msubsup><mml:mo largeop="true" symmetric="true">⋃</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>N</mml:mi></mml:msubsup><mml:msub><mml:mi>S</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>                        // pool interspike intervals<break/> <inline-formula><mml:math id="inf262"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>A</mml:mi><mml:mo stretchy="false">←</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>∈</mml:mo><mml:mi>S</mml:mi><mml:mspace width="thickmathspace"/><mml:mrow><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:mspace width="thickmathspace"/><mml:mn>2</mml:mn><mml:mi>θ</mml:mi><mml:mo>−</mml:mo><mml:mi>ϵ</mml:mi><mml:mo>&lt;</mml:mo><mml:mi>a</mml:mi><mml:mo>&lt;</mml:mo><mml:mn>2</mml:mn><mml:mi>θ</mml:mi><mml:mo>+</mml:mo><mml:mi>ϵ</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula>            // SISIs near double-delay<break/> <inline-formula><mml:math id="inf263"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>P</mml:mi><mml:mo stretchy="false">←</mml:mo><mml:mfrac><mml:mrow><mml:mo>|</mml:mo><mml:mi>A</mml:mi><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>S</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mfrac><mml:mo>&gt;</mml:mo><mml:mi>γ</mml:mi></mml:mrow></mml:mstyle></mml:math></inline-formula>                     // Boolean: ping-pong present?<break/> <bold>if</bold> <inline-formula><mml:math id="inf264"><mml:mi>P</mml:mi></mml:math></inline-formula> <bold>then</bold><break/>  <bold>if</bold> <inline-formula><mml:math id="inf265"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>w</mml:mi><mml:mrow><mml:mo>∗</mml:mo></mml:mrow></mml:msup><mml:mo>&gt;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mstyle></mml:math></inline-formula> <bold>then</bold><break/>   <inline-formula><mml:math id="inf266"><mml:mrow><mml:mi>w</mml:mi><mml:mo>←</mml:mo><mml:msup><mml:mi>T</mml:mi><mml:mo>∗</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>                         // use previous estimate...<break/>   <inline-formula><mml:math id="inf267"><mml:mrow><mml:mi>k</mml:mi><mml:mo>←</mml:mo><mml:mi>K</mml:mi></mml:mrow></mml:math></inline-formula>                                //...and quit<break/>  <bold>else</bold><break/>   <inline-formula><mml:math id="inf268"><mml:mrow><mml:mi>T</mml:mi><mml:mo>←</mml:mo><mml:mrow><mml:mi>α</mml:mi><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>                            // increase box size<break/>   <inline-formula><mml:math id="inf269"><mml:mrow><mml:mi>k</mml:mi><mml:mo>←</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>                             // restart trial counter<break/>  <bold>end</bold><break/> <bold>else if</bold> <inline-formula><mml:math id="inf270"><mml:mrow><mml:mi>k</mml:mi><mml:mo mathvariant="normal">=</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:math></inline-formula> <bold>then</bold><break/>  <inline-formula><mml:math id="inf271"><mml:mrow><mml:msup><mml:mi>T</mml:mi><mml:mo>∗</mml:mo></mml:msup><mml:mo>←</mml:mo><mml:mi>w</mml:mi></mml:mrow></mml:math></inline-formula>                            // update best estimate<break/>  <inline-formula><mml:math id="inf272"><mml:mrow><mml:mi>T</mml:mi><mml:mo>←</mml:mo><mml:mrow><mml:mi>β</mml:mi><mml:mo>⁢</mml:mo><mml:mi>T</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>                         // slightly decrease box size<break/>  <inline-formula><mml:math id="inf273"><mml:mrow><mml:mi>k</mml:mi><mml:mo>←</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>                             // restart trial counter<break/><break/> <bold>end</bold><break/><bold>end</bold></td></tr></tbody></table></table-wrap><table-wrap id="app1table1" position="float"><label>Appendix 1—table 1.</label><caption><title>Network parameter values.</title></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" valign="bottom"/><th align="left" valign="bottom">Variable (Unit)</th><th align="left" valign="bottom">baseline value</th><th align="left" valign="bottom">value range</th></tr></thead><tbody><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf274"><mml:mi>N</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom">network size</td><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">[2, 5,000]</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf275"><mml:mi>M</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom">signal dimensions</td><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">[1, 100]</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf276"><mml:mi>ρ</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom">network redundancy N/M</td><td align="left" valign="bottom"/><td align="char" char="." valign="bottom">[2, 50]</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf277"><mml:msub><mml:mrow><mml:mo>∥</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>∥</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">decoder norms</td><td align="char" char="." valign="bottom">1</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf278"><mml:mfrac><mml:mn>1</mml:mn><mml:mi>λ</mml:mi></mml:mfrac></mml:math></inline-formula></td><td align="left" valign="bottom">decoder time constant (ms)</td><td align="char" char="." valign="bottom">10</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf279"><mml:msub><mml:mi>T</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">threshold (a.u.)</td><td align="char" char="." valign="bottom">0.55</td><td align="left" valign="bottom">[0.5, 1.55<xref ref-type="table-fn" rid="app1table1fn1">*</xref>]</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf280"><mml:msub><mml:mi>t</mml:mi><mml:mtext>max</mml:mtext></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">trial duration (s)</td><td align="char" char="." valign="bottom">5</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf281"><mml:mrow><mml:mi mathvariant="normal">Δ</mml:mi><mml:mo>⁢</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula></td><td align="left" valign="bottom">simulation time step (ms)</td><td align="char" char="." valign="bottom">0.1</td><td align="char" char="." valign="bottom">[0.01 0.1]</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf282"><mml:msub><mml:mi>σ</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">standard deviation of each signal component</td><td align="char" char="." valign="bottom">3</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf283"><mml:msub><mml:mi>η</mml:mi><mml:mi>x</mml:mi></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">signal noise</td><td align="char" char="." valign="bottom">0.5</td><td align="left" valign="bottom"/></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf284"><mml:msub><mml:mi>τ</mml:mi><mml:mtext>ref</mml:mtext></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">refractory period (ms)</td><td align="char" char="." valign="bottom">2</td><td align="char" char="." valign="bottom">[0, 10]</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf285"><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mtext>reset</mml:mtext></mml:mrow></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">reset (a.u.)</td><td align="char" char="." valign="bottom">1.014</td><td align="char" char="." valign="bottom">[1, 1.5]</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf286"><mml:msub><mml:mi>σ</mml:mi><mml:mi>V</mml:mi></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">current noise (a.u.)</td><td align="char" char="." valign="bottom">0.5</td><td align="char" char="." valign="bottom">[0, 3]</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf287"><mml:msub><mml:mi>δ</mml:mi><mml:mi mathvariant="normal">Ω</mml:mi></mml:msub></mml:math></inline-formula></td><td align="left" valign="bottom">synaptic scaling/noise</td><td align="char" char="." valign="bottom">0</td><td align="char" char="." valign="bottom">[0, 0.2]</td></tr><tr><td align="left" valign="bottom"><inline-formula><mml:math id="inf288"><mml:mi>θ</mml:mi></mml:math></inline-formula></td><td align="left" valign="bottom">recurrent delay (ms)</td><td align="char" char="." valign="bottom">0</td><td align="char" char="." valign="bottom">[0, 2]</td></tr></tbody></table><table-wrap-foot><fn id="app1table1fn1"><label>*</label><p>To counteract synaptic delays as in <xref ref-type="fig" rid="fig7">Figure 7</xref>, thresholds <italic>T</italic> &gt; 1.55 were also used.</p></fn></table-wrap-foot></table-wrap><fig id="app1fig1" position="float"><label>Appendix 1—figure 1.</label><caption><title>Wide and narrow boxes, ping-pong, and readout correction.</title><p>(<bold>A</bold>) Wide box. Upon each spike, the readout (light blue) jumps into the box, but without reaching its opposite end, and then decays back to the border of the box. As a consequence, the readout fluctuates around a mean readout vector (light blue, solid circle) that is shorter than the input signal vector (white cross). The coding error therefore has two components, one corresponding to the readout fluctuations, and one to the systematic bias. This bias can be corrected for (Methods, 'Readout biases and corrections'; mean shown as dark blue solid circle). (<bold>B</bold>) Narrow box. When the box diameter is the size of the decoding vectors, the systematic bias vanishes, and both corrected and uncorrected readout are virtually identical. (<bold>C</bold>) Ping-pong. In narrow boxes, a spike will take the readout all the way across the box, increasing the likelihood that even a small amount of noise will trigger unwanted 'pong' spikes (orange arrow) in the opposite direction, followed by further 'ping' spikes in the original direction (red arrows). Such extended barrages lead to excessive increases in firing rates and are referred to as the 'ping-pong' effect. (<bold>D</bold>) Avoiding ping-pong. In wide boxes, when the readout hits one of the bounds (red line), the resulting spike (red arrow) will take it well inside the box. Even in the presence of e.g. voltage or threshold noise, this is unlikely to result in additional spikes in the opposite direction. (However, note that at high dimensionality or very low redundancy, the complex geometry of the bounding box can sometimes result in a finite number of instantaneous compensatory spikes).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-73276-app1-fig1-v2.tif"/></fig><fig id="app1fig2" position="float"><label>Appendix 1—figure 2.</label><caption><title>Physical manifestation of the bounding box in the network’s voltage space.</title><p>(<bold>A</bold>) A (noise-free) network with <inline-formula><mml:math id="inf289"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:math></inline-formula> neurons tracking a two-dimensional signal. We assume that the neuron’s decoding vectors are regularly spaced. In this case, the voltages of neurons with opposite decoding vectors (<inline-formula><mml:math id="inf290"><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">D</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>∈</mml:mo><mml:mrow><mml:mo stretchy="false">{</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo stretchy="false">}</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>) can be collapsed into single dimensions (since <inline-formula><mml:math id="inf291"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>). In turn, we can plot the six-dimensional voltage space in three dimensions, as done here. The inside of the cube corresponds to the subthreshold voltages of the neurons, and the faces of the cube to the six neural thresholds. The network’s voltage trajectory is shown in blue and lives in a two-dimensional subspace (orange). The limits of this subspace, given by the neuron’s thresholds, delineate the (hexagonal) bounding box. (<bold>B</bold>) We apply Principal Component Analysis to the original six-dimensional voltage traces to uncover that the system only spans a lower two-dimensional subspace which shows the original bounding box. (<bold>C</bold>) Same as B, but for a high-dimensional and high-redundancy system (<inline-formula><mml:math id="inf292"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf293"><mml:mrow><mml:mi>N</mml:mi><mml:mo>=</mml:mo><mml:mn>1000</mml:mn></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="inf294"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></inline-formula>). In this case, the first two principal components only provide a projection of the original bounding box, and the voltage trajectories are unlikely to exactly trace out the projection’s boundaries.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-73276-app1-fig2-v2.tif"/></fig><fig id="app1fig3" position="float"><label>Appendix 1—figure 3.</label><caption><title>The geometry of the bounding box changes with input dimensionality and redundancy.</title><p>(<bold>A</bold>) In networks tracking two-dimensional signals, the bounding box is geometrically depicted as a polygon with as many sides as the number of neurons. For three dimensional systems, the bounding box corresponds to a polyhedron. For four or more dimensions, the corresponding bounding boxes are mathematically described as convex polytopes, but their visualization is hard (see Materials and methods, 'Geometry of high-dimensional bounding boxes'). (<bold>B</bold>) Example two-dimensional cuts of bounding boxes (orange) for a given network size and space dimensionality. Cuts for a hypersphere (green) and a hypercube (dashed blue) are shown for comparison. For low dimensionality, high redundancy bounding boxes are similar to hyperspheres whereas for high dimensionality they are more similar to hypercubes. (<bold>C</bold>) Median radius of bounding boxes as a function of dimensionality and redundancy. The blue line illustrates the average radius of a hypercube (thresholds of individual neurons are here set at T=0.5). (<bold>D</bold>) Median angle between neighbouring neurons, i.e., neurons that share an 'edge' in the bounding box. Neighbouring neurons in high dimensional signal spaces are almost orthogonal to each other (<bold>E</bold>) Random 13 × 13 Gabor Patches representing the readout weights of neurons in a high dimensional space. Most Gabor patches are quasi-orthogonal to each other (angles within <inline-formula><mml:math id="inf295"><mml:mrow><mml:mn>90</mml:mn><mml:mo>±</mml:mo><mml:msup><mml:mn>5</mml:mn><mml:mo>∘</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula>). Some neurons have overlapping receptive fields and non-orthogonal orientations.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-73276-app1-fig3-v2.tif"/></fig><fig id="app1fig4" position="float"><label>Appendix 1—figure 4.</label><caption><title>Robustness to noise for different signal dimensionalities (<inline-formula><mml:math id="inf296"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="inf297"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>50</mml:mn></mml:mrow></mml:math></inline-formula>) and different redundancies .</title><p>(Left column) Network performance relative to an identical reference network without noise. Different curves lie on top of each other. (Central column) Population firing rate. (Right column) Coefficient of variation of the interspike intervals, averaged across neurons. Overall, dimensionality does not qualitatively affect robustness to noise. Threshold is <inline-formula><mml:math id="inf298"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>0.55</mml:mn></mml:mrow></mml:math></inline-formula> by default, unless labeled ‘wide’, which corresponds to an expanded threshold of <inline-formula><mml:math id="inf299"><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mn>1.0</mml:mn></mml:mrow></mml:math></inline-formula>. Lines show medians, and shaded regions indicate interquartile ranges.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-73276-app1-fig4-v2.tif"/></fig><fig id="app1fig5" position="float"><label>Appendix 1—figure 5.</label><caption><title>Single trials of delayed and undelayed networks for intermediate dimensionalities (number of input signals <inline-formula><mml:math id="inf300"><mml:mrow><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>20</mml:mn></mml:mrow></mml:math></inline-formula>, redundancy <inline-formula><mml:math id="inf301"><mml:mrow><mml:mi>ρ</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:math></inline-formula>).</title><p>The input signals are a sine and cosine along the first two dimensions, and constant along the remaining dimensions. (<bold>A,B</bold>) Undelayed, fully connected network with a default box (<inline-formula><mml:math id="inf302"><mml:mrow><mml:mpadded width="-1.7pt"><mml:mi>T</mml:mi></mml:mpadded><mml:mo rspace="0.8pt">=</mml:mo><mml:mn>0.55</mml:mn></mml:mrow></mml:math></inline-formula>), (<bold>C,D</bold>) Delayed, fully connected network with a default box, (<bold>E,F</bold>) delayed fully connected network with optimally widened box, (<bold>G,H</bold>) delayed network with default box and optimally reduced excitation. (<bold>C–H</bold>) Delay is <inline-formula><mml:math id="inf303"><mml:mrow><mml:mpadded width="-1.7pt"><mml:mi>θ</mml:mi></mml:mpadded><mml:mo rspace="0.8pt">=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>ms. Panels (<bold>A,C,E,G</bold>) show the readout in each of the first four signal dimensions as a separate line. Dimensions 5–20 are hidden to avoid clutter. Panels (<bold>B,D,F,H</bold>) show corresponding spike-time raster plots (left) and trial-averaged single-neuron firing rates (centre), as well as the same rates ordered from largest to smallest (right).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-73276-app1-fig5-v2.tif"/></fig><fig id="app1fig6" position="float"><label>Appendix 1—figure 6.</label><caption><title>Generalisation of the bounding box.</title><p>(<bold>A</bold>) In a simple autoencoder, the input is directly fed into the network. During a spike, the bounding box maintains its overall shape due to the network’s fast recurrent connectivity. (<bold>B</bold>) When we add dynamics, the resulting networks have the same fast recurrent connectivity matrix as the auto-encoder networks, and this fast recurrency maintains the bounding box during a spike. Additionally, the networks have a slow, recurrent connectivity matrix. We can visualize the effect of this slow recurrent connectivity by treating it as a perturbation, similarly to the other perturbations discussed in the paper. The effect of the slow connectivities is then to move the bounds of the neurons according to the evolution of the dynamical system. Perturbations for which the autoencoder is robust, i.e., for which the readout error is kept within normal range, will therefore not affect the slow dynamics.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-73276-app1-fig6-v2.tif"/></fig></app></app-group></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.73276.sa0</article-id><title-group><article-title>Editor's evaluation</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Meister</surname><given-names>Markus</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05dxps055</institution-id><institution>California Institute of Technology</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><related-object id="sa0ro1" link-type="continued-by" object-id="10.1101/2020.06.15.148338" object-id-type="id" xlink:href="https://sciety.org/articles/activity/10.1101/2020.06.15.148338"/></front-stub><body><p>The article introduces a geometrical interpretation for the dynamics and function of certain spiking networks, based on the earlier work of Machens and Deneve. Given that spiking networks are notoriously hard to understand, the approach could prove useful for many computational neuroscientists. Here, that visualization tool serves to assess how fragile the network is to perturbation of its parameters, such as neuronal death, or spurious noise in excitation and inhibition.</p></body></sub-article><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.73276.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Meister</surname><given-names>Markus</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05dxps055</institution-id><institution>California Institute of Technology</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Doiron</surname><given-names>Brent</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/01an3r305</institution-id><institution>University of Pittsburgh</institution></institution-wrap><country>United States</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Meister</surname><given-names>Markus</given-names></name><role>Reviewer</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/05dxps055</institution-id><institution>California Institute of Technology</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text id="sa2-box1"><p>Our editorial process produces two outputs: i) <ext-link ext-link-type="uri" xlink:href="https://sciety.org/articles/activity/10.1101/2020.06.15.148338">public reviews</ext-link> designed to be posted alongside <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/2020.06.15.148338v2">the preprint</ext-link> for the benefit of readers; ii) feedback on the manuscript for the authors, including requests for revisions, shown below. We also include an acceptance summary that explains what the editors found interesting or important about the work.</p></boxed-text><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;Robustness in spiking networks: a geometric perspective&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by 3 peer reviewers, including Markus Meister as Reviewing Editor and Reviewer #3, and the evaluation has been overseen by Michael Frank as the Senior Editor. The following individual involved in review of your submission has agreed to reveal their identity: Brent Doiron (Reviewer #2).</p><p>The reviewers have discussed their reviews with one another, and the Reviewing Editor has drafted this to help you prepare a revised submission.</p><p>Essential revisions:</p><p>Domain of applicability:</p><p>1. The authors analyze a very specific network, with carefully tuned feedback designed for a specific cost function (Equation 3). Do such tuned networks exist in Nature? The reader would benefit from knowing what the domain of applicability really is.</p><p>2. How would the framework generalize to settings other than an auto-encoder, e.g., for the dynamical systems approach in Boerlin et al.?</p><p>Consistency of the bounding box picture:</p><p>3. A central assumption of the framework is a coherence between the readout from the network and the dynamics and connectivity of the network. This allows the bounding box to follow the input vector around, so one can easily assess decoding errors. However, it seems that some of the perturbations break the assumptions that lead to the bounding box. For example, exciting a single neuron decreases its threshold and thereby shrinks the bounding box (Figure 3D). As the bounding box limits the error in the readout, this should mean that the error decreases. However, the opposite is the case (Figure 4A). Presumably the discrepancy arises from changing the threshold without changing the readout at the same time, so the bounding box loses its meaning. By contrast the loss of a neuron, or its inhibition, leaves the remaining network adjusted properly, so the bounding box retains its meaning. The authors should address this question, and whether the bounding box loses its meaning under some perturbations and not others.</p><p>4. A related question applies to delays. Where exactly are the delays? In the readout and then the network is optimised for that? Or is the network the optimal one assuming no delays and then delays are added in the recurrent connections and/or the readout? Clarifying that will make it easier for the reader to follow the argument.</p><p>5. In the section on perturbations of the reset potential: Is there again an asymmetry, e.g., do changes up or down in the optimal reset potential have very different consequences?</p><p>Robustness claims:</p><p>6. There are frequent comparisons between networks with few neurons and networks with many neurons. The idea that networks with more neurons are more robust seems kind of obvious. But the authors analyze a very specific network tuned for coordinated redundancy (Equation 3). How does that network compare to one with the same number of neurons but no coordinated redundancy? This would seem a more interesting comparison than varying the number of neurons.</p><p>7. Intuitively one might expect that the performance is fragile to changes in the recurrent coupling, since the decoding vector is tied to the feedforward and recurrent weights (Equation 10). Because of this the claimed robustness to perturbations in synaptic weight seems surprising. Is the 'synapse scaling factor' in Figure 6G,H the parameter \δ_{\Omega} in Equation 17? The way it is defined it is the maximal change, however most synapses are perturbed to a much smaller extent. Also, for \δ approaching 0.2 the performance only drops by 20% (Figure 6G). However, for such large \δ's the firing rates in the network seem unreasonably high (Figure 6H), suggesting it no longer performs efficiently. Overall it is hard to judge from the current presentation how robust the network is to synaptic perturbation. Perhaps the firing rates could be bounded, or the performance penalized for using very high rates?</p><p>Relation to plasticity:</p><p>8. Prior work (e.g. Bourdoukan 2012) proposed a Hebbian learning process that could tune up such a network automatically. If this plasticity is &quot;always on&quot; how would it respond to the various perturbations being considered? How might that contribute to robustness on a longer time scale? How does the size/shape of the bounding box depend on the parameters of the learning rule? Can one get looser and tighter boxes, as needed here for certain types of robustness?</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.73276.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>Domain of applicability:</p><p>1. The authors analyze a very specific network, with carefully tuned feedback designed for a specific cost function (Equation 3). Do such tuned networks exist in Nature? The reader would benefit from knowing what the domain of applicability really is.</p></disp-quote><p>The reviewers are correct in that our networks require carefully tuned inhibitory feedback. We first notice that this is not a new proposal. For instance, in previous work we have shown that the loss functions we minimize are identical to classical sparse coding networks (Olshausen and Field, 1996). Indeed, the type of connectivity we find in our networks is exactly the same as that in sparse coding <italic>rate</italic> networks (compare e.g., Figure 10.6 in Dayan Abbott with Equation (8) in our paper). So we could say a potential applicability are sensory systems, such as primary visual cortex. Do such tuned networks really exist in nature? That is a more difficult question to answer. There is currently an ongoing debate on whether inhibitory tuning is precise or broad, and so we would say that the jury is still out (see e.g., Najafi et al., (2020) Neuron 105:165-79, for an argument that inhibitory tuning is precise or selective). We have sought to clarify these points in the discussion where we now write:</p><p>&quot;In many respects, the bounding box is a &quot;toy model&quot; (borrowing the term from physics, in the sense of a deliberately abstract model), which we see mainly as a tool to conceptualize and highlight generic circuit mechanism, rather than an attempt to model any specific system. Nonetheless, it is worthwhile to point out that the bounding box is also a spiking version of classical sparse coding models of V1 [44]. Indeed, previous work has demonstrated that these spiking networks can explain various perturbation experiments in V1 [21]. So, besides shedding light on the robustness of coordinated spike codes, the bounding box can also be seen as a simple model of a sensory system.&quot;</p><disp-quote content-type="editor-comment"><p>2. How would the framework generalize to settings other than an auto-encoder, e.g., for the dynamical systems approach in Boerlin et al.?</p></disp-quote><p>The framework fully generalizes. In the case of an auto-encoder, the positions of bounding box faces are fully defined by the input. For the more general dynamical systems approach of Boerlin et al., there still is a bounding box that arises from the fast recurrent connectivity, and the position of its faces evolves in signal space according to the chosen dynamical system. See Supplementary Figure 6 for a graphical explanation of this comparison. We also note that the simulation in Figure 1D of the main paper is actually a dynamical system à la Boerlin et al., and not an auto-encoder.</p><p>To address these concerns, we added Supplementary Figure 6, and we introduced a new section at the end of the Results to clarify that our framework generalizes to Boerlin et al., Specifically, we wrote:</p><p>&quot;The bounding box provides a useful tool even if we endow the networks with a set of slower connections to perform linear or non-linear computations [17, 42, 43]. Indeed, the simulation in Figure 1D used these slower connections to generate oscillatory dynamics (see Methods, section ’Generalisation of the bounding box IV’, for mathematical details). This extension to networks that generate persistent activity or dynamical patterns works because the mechanisms underlying the encoding of the signals into spike trains are decoupled from the mechanisms that generate the dynamics of the signals (or readouts). Accordingly, the extra currents generated by the slow recurrent connections can be seen as a perturbation of the bounding box thresholds. This perturbation shifts the bounding box in the space of readouts as illustrated in Supplementary Figure 6.&quot;</p><disp-quote content-type="editor-comment"><p>Consistency of the bounding box picture:</p><p>3. A central assumption of the framework is a coherence between the readout from the network and the dynamics and connectivity of the network. This allows the bounding box to follow the input vector around, so one can easily assess decoding errors. However, it seems that some of the perturbations break the assumptions that lead to the bounding box. For example, exciting a single neuron decreases its threshold and thereby shrinks the bounding box (Figure 3D). As the bounding box limits the error in the readout, this should mean that the error decreases. However, the opposite is the case (Figure 4A). Presumably the discrepancy arises from changing the threshold without changing the readout at the same time, so the bounding box loses its meaning. By contrast the loss of a neuron, or its inhibition, leaves the remaining network adjusted properly, so the bounding box retains its meaning. The authors should address this question, and whether the bounding box loses its meaning under some perturbations and not others.</p></disp-quote><p>The reviewers are correct that the readout is a central pillar of our analysis. There is one important subtlety, though. For wide bounding boxes, i.e., for bounding boxes in which the readout jump caused by a spike does not transverse the whole box, we need to correct the readout for a bias (see <xref ref-type="fig" rid="sa2fig1">Author response image 1</xref>, replotted from Supplementary Figure 1A). This bias-correction is done by rescaling the readout with a scalar. The bias correction achieves that the average rescaled readout will match the signal.</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><caption><title>Wide box, and readout correction.</title><p>Upon each spike, the readout (light blue) jumps into the box, but without reaching its opposite end, and then decays back to the border of the box. As a consequence, the readout fluctuates around a mean readout vector (light blue, solid circle) that is shorter than the input signal vector (white cross). The coding error therefore has two components, one corresponding to the readout fluctuations, and one to the systematic bias. This bias can be corrected for (Methods, ’Readout biases’), and we will sometimes work with the corrected readout (mean shown as dark blue solid circle).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-73276-sa2-fig1-v2.tif"/></fig><p>The bounding box only limits the coding error of the actual readout, but not the rescaled, bias corrected readout. In other words, the bounding box only has meaning for the original readout, not the corrected readout. When we shrink the bounding box from one side, we decrease the maximum error of the original readout. The bias-corrected, <italic>rescaled</italic> readout, however, will now, on average, no longer match the signal. That is the effect we plot in Figure 3D.</p><p>To make these issues clearer, we now clearly specify throughout the text whether we use the readout or the corrected readout. When explaining readout and corrected readout, we explain the limits of the bounding box picture: &quot;This bias can be largely eliminated by rescaling the readouts with a constant factor. We will sometimes use this corrected readout (see Methods, ’Readout biases’), but note that the corrected readout is not confined to stay within the bounding box.&quot;</p><p>We also added the following sentence when explaining changes in the excitability of neurons:</p><p>&quot;At first sight, changing the box size increases or decreases the maximum error of the readout. More subtly, however, it also introduces a bias in the corrected average readout (Figure 3C, arrows).&quot;</p><disp-quote content-type="editor-comment"><p>4. A related question applies to delays. Where exactly are the delays? In the readout and then the network is optimised for that? Or is the network the optimal one assuming no delays and then delays are added in the recurrent connections and/or the readout? Clarifying that will make it easier for the reader to follow the argument.</p></disp-quote><p>Crucially, the delays are in the recurrent connections. The reviewers’ second assertion is correct: Network connectivity is optimized for the delay-free case, and the delays are then added to the recurrent connections. In addition to these recurrent delays, we have also assumed a delay of identical length in the readout. This latter delay is not crucial, but facilitates the geometric visualisation, as the arrival of a delayed recurrent spike and the update of the readout thus happen at the exact same time and can thus be shown in the same figure panel.</p><p>We now clarify our choices in the Results section, where we have inserted the following statement:</p><p>&quot;Below, we study the impact of these delays, which apply directly to recurrent excitation and inhibition. We also apply the same delays to the network readout for mathematical convenience, but those do not affect network dynamics (see Methods).&quot;</p><disp-quote content-type="editor-comment"><p>5. In the section on perturbations of the reset potential: Is there again an asymmetry, e.g., do changes up or down in the optimal reset potential have very different consequences?</p></disp-quote><p>The reviewers are correct. A change in reset potential leads to a transient change in the corresponding face of the bounding box, and inward changes (a transient shrinkage of the box) can have very different effects than an outward change. Indeed, a reset that is too small can cause a successive shrinking of the box if the respective neuron fires repeatedly.</p><p>We now included the following statement in the Results section:</p><p>“We note that positive and negative changes to the default reset potential will lead to asymmetric effects on robustness like those observed for excitatory and inhibitory perturbations. Specifically, if the resets become too small, and if the leak is insufficiently fast, then successive spiking of a single neuron will draw its threshold inwards, thereby leading to a collapse of the bounding box.&quot;</p><disp-quote content-type="editor-comment"><p>Robustness claims:</p><p>6. There are frequent comparisons between networks with few neurons and networks with many neurons. The idea that networks with more neurons are more robust seems kind of obvious. But the authors analyze a very specific network tuned for coordinated redundancy (Equation 3). How does that network compare to one with the same number of neurons but no coordinated redundancy? This would seem a more interesting comparison than varying the number of neurons.</p></disp-quote><p>We agree with the reviewer that a more systematic comparison with other types of networks would be preferable, but we have found that there are two key problems. First, there is no agreed, default network model that we could compare our framework against. Second, almost all standard network models are not built to be robust, so that systematic comparisons are not very illuminating.</p><p>We have addressed these issues in the following way:</p><p>First, we note that we include a comparison with networks without coordinated redundancy. We simply compare our networks against a set of unconnected neurons (Section ’passive redundancy’). A set of unconnected neurons is a simple example, as any perturbation effect scales linearly with the number of neurons perturbed. Here, increasing the number of neurons will not guard against the elimination of a certain fraction of the network (say 25%). In the bounding box picture, however, increasing the number of neurons (or the redundancy) will indeed increase robustness against killing one fourth of the network, as smaller networks are not necessarily robust. (We note that in both cases, we assume the same downstream readout before and after the perturbation.) This illustrates that more redundancy is not trivially better, at least not if the perturbation size scales with the network size. To highlight this better, we added the following sentence in the section &quot;Scaling up&quot;: &quot;This contrasts with networks of independent neurons in which performance will scale linearly with any change in redundancy for a fixed readout.&quot;</p><p>Second, we note that we illustrated the response of a trained network model without coordinated redundancy to various perturbations. This network is not robust to our cumulative perturbations, yet our identically sized network with coordinated redundancy is robust (Figure 1C vs 1D). While we only include one example simulation, we emphasize that this simulation is representative (which any reader can see by simulating our code).</p><p>Third, we would like to point out that we also show that more redundancy is not always better. Notably, our work suggests that including more neurons makes the network more sensitive to certain kinds of perturbations (e.g., synaptic noise in Figure 6G-H, or delays in Figure 7G).</p><disp-quote content-type="editor-comment"><p>7. Intuitively one might expect that the performance is fragile to changes in the recurrent coupling, since the decoding vector is tied to the feedforward and recurrent weights (Equation 10). Because of this the claimed robustness to perturbations in synaptic weight seems surprising. Is the 'synapse scaling factor' in Figure 6G,H the parameter \δ_{\Omega} in Equation 17? The way it is defined it is the maximal change, however most synapses are perturbed to a much smaller extent. Also, for \δ approaching 0.2 the performance only drops by 20% (Figure 6G). However, for such large \δ's the firing rates in the network seem unreasonably high (Figure 6H), suggesting it no longer performs efficiently. Overall it is hard to judge from the current presentation how robust the network is to synaptic perturbation. Perhaps the firing rates could be bounded, or the performance penalized for using very high rates?</p></disp-quote><p>The reviewer is correct that the synapse scaling factor in Figure 6G,H is the parameter <italic>δ</italic><sub>Ω</sub> in Equation 17, and that this corresponds to the maximal possible scaling rather than the actual scaling of the synaptic strengths.</p><p>To explain the robustness of the network against changes in the synapses, we have to first note the asymmetry of perturbations: a synapse that is smaller than its ideal value will lead to a temporary shift of the postsynaptic neuron’s threshold away from the bounding box when the presynaptic neuron spikes (Figure 6D). Just as with inhibitory perturbations, this perturbations is harmless as it does not really change the overall shape of the box in redundant systems. A synapse that is larger than its ideal value will lead to a temporary shift into the bounding box which can be harmful, depending on how long it lasts (or how fast the synaptic input decays).</p><p>We have now sought to clarify this section by writing:</p><p>&quot;We again note an asymmetry: a synapse with decreased strength leads to an outward move of the postsynaptic neuron’s threshold, which is generally harmless. Random synaptic failures, which cause temporary decreases in synaptic strength, do therefore not influence the bounding box functionality. However, a synapse with increased strength leads to an inward move, which could be a temporarily harmful perturbation.&quot;</p><p>We also agree with the reviewer that synaptic scaling can make these networks less inefficient in terms of number of spikes (Figure 6H). We now write:</p><p>&quot;Overall, we find that more redundant networks (with consequently more synapses) are typically more vulnerable to these perturbations, and that synaptic scaling can lead to highly inefficient networks in terms of spike rate, regardless of the network redundancy.&quot;</p><disp-quote content-type="editor-comment"><p>Relation to plasticity:</p><p>8. Prior work (e.g. Bourdoukan 2012) proposed a Hebbian learning process that could tune up such a network automatically. If this plasticity is &quot;always on&quot; how would it respond to the various perturbations being considered? How might that contribute to robustness on a longer time scale? How does the size/shape of the bounding box depend on the parameters of the learning rule? Can one get looser and tighter boxes, as needed here for certain types of robustness?</p></disp-quote><p>The learning rules we have previously developed (Bourdoukan et al., 2012, Neurips; Brendel et al., 2020, PLOS CB), will learn an optimally arranged bounding box with a pre-defined width. We have not systematically studied how perturbations would affect the learning—a very interesting question, but we believe beyond the confines of the current study.</p><p>Still, a few answers we already know. Specifically, perturbations that lower the excitability of neurons are unlikely to affect learning. For instance, when eliminating neurons, the target connectivity of the learning rules does not change. Moreover, the learning rules we developed will still push synapses in the remaining neurons towards this target connectivity. In machine-learning language, the networks are fully capable of dealing with the dropout of neurons, and dropout may even help in speeding up learning (although we have not full studied this effect). More generally, inhibiting neurons does not affect learning because of the network’s compensatory properties. Perturbations that excite neurons (e.g. synaptic noise) are different. We would speculate that they are likely to strongly perturb the learning process.</p></body></sub-article></article>