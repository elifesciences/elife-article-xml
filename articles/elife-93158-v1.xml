<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.3 20210610//EN"  "JATS-archivearticle1-3-mathml3.dtd"><article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn publication-format="electronic" pub-type="epub">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">93158</article-id><article-id pub-id-type="doi">10.7554/eLife.93158</article-id><article-id pub-id-type="doi" specific-use="version">10.7554/eLife.93158.3</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>Shared structure facilitates working memory of multiple sequences</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Huang</surname><given-names>Qiaoli</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0003-4592-9270</contrib-id><email>qiaolihuang0818@gmail.com</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="aff" rid="aff4">4</xref><xref ref-type="other" rid="fund3"/><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Luo</surname><given-names>Huan</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-8349-9796</contrib-id><email>huan.luo@pku.edu.cn</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="aff" rid="aff3">3</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf2"/></contrib><aff id="aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>School of Psychological and Cognitive Sciences, Peking University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>PKU-IDG/McGovern Institute for Brain Research, Peking University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/02v51f717</institution-id><institution>Beijing Key Laboratory of Behavior and Mental Health, Peking University</institution></institution-wrap><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff><aff id="aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ror">https://ror.org/0387jng26</institution-id><institution>Max Planck Institute for Human Cognitive and Brain Sciences</institution></institution-wrap><addr-line><named-content content-type="city">Leipzig</named-content></addr-line><country>Germany</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="editor"><name><surname>Peelen</surname><given-names>Marius V</given-names></name><role>Reviewing Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/016xsfp80</institution-id><institution>Radboud University Nijmegen</institution></institution-wrap><country>Netherlands</country></aff></contrib><contrib contrib-type="senior_editor"><name><surname>Colgin</surname><given-names>Laura L</given-names></name><role>Senior Editor</role><aff><institution-wrap><institution-id institution-id-type="ror">https://ror.org/00hj54h04</institution-id><institution>University of Texas at Austin</institution></institution-wrap><country>United States</country></aff></contrib></contrib-group><pub-date publication-format="electronic" date-type="publication"><day>24</day><month>07</month><year>2024</year></pub-date><volume>12</volume><elocation-id>RP93158</elocation-id><history><date date-type="sent-for-review" iso-8601-date="2023-10-11"><day>11</day><month>10</month><year>2023</year></date></history><pub-history><event><event-desc>This manuscript was published as a preprint.</event-desc><date date-type="preprint" iso-8601-date="2023-07-19"><day>19</day><month>07</month><year>2023</year></date><self-uri content-type="preprint" xlink:href="https://doi.org/10.1101/2023.07.18.549616"/></event><event><event-desc>This manuscript was published as a reviewed preprint.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2023-12-15"><day>15</day><month>12</month><year>2023</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.93158.1"/></event><event><event-desc>The reviewed preprint was revised.</event-desc><date date-type="reviewed-preprint" iso-8601-date="2024-06-19"><day>19</day><month>06</month><year>2024</year></date><self-uri content-type="reviewed-preprint" xlink:href="https://doi.org/10.7554/eLife.93158.2"/></event></pub-history><permissions><copyright-statement>© 2023, Huang and Luo</copyright-statement><copyright-year>2023</copyright-year><copyright-holder>Huang and Luo</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-93158-v1.pdf"/><self-uri content-type="figures-pdf" xlink:href="elife-93158-figures-v1.pdf"/><abstract><p>Daily experiences often involve the processing of multiple sequences, yet storing them challenges the limited capacity of working memory (WM). To achieve efficient memory storage, relational structures shared by sequences would be leveraged to reorganize and compress information. Here, participants memorized a sequence of items with different colors and spatial locations and later reproduced the full color and location sequences one after another. Crucially, we manipulated the consistency between location and color sequence trajectories. First, sequences with consistent trajectories demonstrate improved memory performance and a trajectory correlation between reproduced color and location sequences. Second, sequences with consistent trajectories show neural reactivation of common trajectories, and display spontaneous replay of color sequences when recalling locations. Finally, neural reactivation correlates with WM behavior. Our findings suggest that a shared common structure is leveraged for the storage of multiple sequences through compressed encoding and neural replay, together facilitating efficient information organization in WM.</p></abstract><abstract abstract-type="plain-language-summary"><title>eLife digest</title><p>When we memorize a grocery list before heading into the store, we make use of our working memory. This type of neural process allows us to temporarily store the knowledge needed for a task, yet its capacity is limited. Having to recall more than one type of information at the same time, in particular, can quickly create challenges. Exactly how the brain maximizes the use of this limited working memory space remains unclear.</p><p>One possible strategy would be to take advantage of the patterns or connections that exist between seemingly unrelated pieces of information – for example, by remembering to buy apples, oranges and bananas under one broader ‘fruit’ category. To explore if this may be the case, Qiaoli Huang and Huan Luo designed a memory task in which two types of information were either connected through an underlying pattern (aligned trajectory condition) or completely independent (misaligned trajectory condition). Participants watched three colored dots appearing on screen one after the other, in such a way that they seemed to ‘travel’ around an imaginary circle. The volunteers were then asked to recall, in order, the location and color of each dot. Performance increased when color and location information were structured in the same way – that is, when both emerged from the three dots traveling around a circle or a color wheel with the same trajectory.</p><p>Recording the brain activity of the participants ‘live’ as they performed the task indicates that, in the aligned trajectory condition, the brain ‘compresses’ both types of information and extracts their common structure. Even when participants were asked to recall only the location of the dots, their brain also spontaneously replayed the related color information. Taken together, these findings provide new insights into how working memory aids in multitasking, a crucial aspect of our daily lives, and lay the groundwork for further exploration of this capability.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>working memory</kwd><kwd>sequence</kwd><kwd>neural replay</kwd><kwd>common trjectory</kwd><kwd>cognitive map</kwd><kwd>efficient coding</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution>National Science and Technology Innovation STI2030-Major Project</institution></institution-wrap></funding-source><award-id>2021ZD0204103</award-id><principal-award-recipient><name><surname>Luo</surname><given-names>Huan</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/501100001809</institution-id><institution>National Natural Science Foundation of China</institution></institution-wrap></funding-source><award-id>31930052</award-id><principal-award-recipient><name><surname>Luo</surname><given-names>Huan</given-names></name></principal-award-recipient></award-group><award-group id="fund3"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100005156</institution-id><institution>Humboldt Foundation</institution></institution-wrap></funding-source><award-id>Humboldt Research Fellowship</award-id><principal-award-recipient><name><surname>Huang</surname><given-names>Qiaoli</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication. Open access funding provided by Max Planck Society.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Common cognitive maps across feature dimensions are spontaneously leveraged to facilitate storage of multiple sequences via compressed encoding and neural replay in human working memory.</meta-value></custom-meta><custom-meta specific-use="meta-only"><meta-name>publishing-route</meta-name><meta-value>prc</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>A well-known feature of working memory (WM) is its limited capacity (<xref ref-type="bibr" rid="bib5">Baddeley, 2000</xref>; <xref ref-type="bibr" rid="bib18">Cowan, 2001</xref>), which constrains the amount of information that can be temporarily retained for future behavior. Meanwhile, in daily experiences, memorized items do not exist independently but are always part of a common framework or share the same structure, which could be leveraged to compress information and overcome the WM capacity challenge (<xref ref-type="bibr" rid="bib13">Brady et al., 2011</xref>). For example, while shopping at a supermarket, numerous items could be grouped into a few categories, such as drinks, vegetables, fruits, and meats, to facilitate memory. Other types of abstract associations such as relational regularities and structure schema could also mediate WM organization (<xref ref-type="bibr" rid="bib2">Al Roumi et al., 2021</xref>; <xref ref-type="bibr" rid="bib31">Gathercole and Baddeley, 2014</xref>; <xref ref-type="bibr" rid="bib45">Mathy and Feldman, 2012</xref>). Computational modeling also suggests that higher-order structures (e.g. summaries and relative relations) would reduce memory uncertainty by constraining individual-item representations (<xref ref-type="bibr" rid="bib14">Brady and Tenenbaum, 2013</xref>; <xref ref-type="bibr" rid="bib22">Ding et al., 2017</xref>).</p><p>Cognitive maps, as one type of spatial schema (<xref ref-type="bibr" rid="bib25">Farzanfar et al., 2023</xref>; <xref ref-type="bibr" rid="bib32">Gilboa and Marlatte, 2017</xref>), provide a general structure framework for organizing information in different tasks and across various domains (<xref ref-type="bibr" rid="bib62">Tolman, 1948</xref>; <xref ref-type="bibr" rid="bib65">Whittington et al., 2020</xref>). They were first identified as representations of physical maps during navigation, but recently have been shown to also support other higher-level processes, such as conceptual knowledge, reasoning, planning, and decision-making (<xref ref-type="bibr" rid="bib9">Behrens et al., 2018</xref>; <xref ref-type="bibr" rid="bib10">Bellmund et al., 2018</xref>; <xref ref-type="bibr" rid="bib47">O’keefe and Nadel, 1978</xref>). Two major neural signatures of cognitive maps, grid-like code (<xref ref-type="bibr" rid="bib17">Constantinescu et al., 2016</xref>; <xref ref-type="bibr" rid="bib23">Doeller et al., 2010</xref>; <xref ref-type="bibr" rid="bib34">Hafting et al., 2005</xref>; <xref ref-type="bibr" rid="bib50">Park et al., 2021</xref>), and neural replay in the hippocampal-entorhinal system (<xref ref-type="bibr" rid="bib26">Foster and Wilson, 2006</xref>; <xref ref-type="bibr" rid="bib41">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="bib43">Liu et al., 2021b</xref>; <xref ref-type="bibr" rid="bib56">Schuck and Niv, 2019</xref>; <xref ref-type="bibr" rid="bib58">Skaggs and McNaughton, 1996</xref>), are identified in both spatial and non-spatial tasks. Neural replay, the rapid item-by-item reactivation in a forward or backward direction, is posited to not only repeat past experiences, but also reflect an internal model of the world (<xref ref-type="bibr" rid="bib38">Kurth-Nelson et al., 2023</xref>; <xref ref-type="bibr" rid="bib48">Ólafsdóttir et al., 2018</xref>).</p><p>Accordingly, many higher-level processes could be described as mental explorations of a sequence of states within an abstract map, similar to tracing a route on a physical map. As a result, a cognitive map can serve as a common reference for aligning different features or domains. In line with the view, conjoined cognitive maps have been recently revealed in the rodent hippocampus (i.e. physical space and abstract task variables) (<xref ref-type="bibr" rid="bib46">Nieh et al., 2021</xref>), and alignment of different feature maps speeds learning performance (<xref ref-type="bibr" rid="bib1">Aho et al., 2022</xref>). Moreover, both spatial and conceptual distances are relied on to generalize when searching for correlated rewards in value-guided learning, supporting a cognitive-map-dependent computational mechanism (<xref ref-type="bibr" rid="bib68">Wu et al., 2020</xref>). Based on these findings, we hypothesize that cognitive maps might be employed to reorganize memory information across domains to overcome capacity bottlenecks in WM.</p><p>Here, we examined whether cognitive maps shared by multiple feature domains would be naturally leveraged to make efficient use of limited WM capacity. To address this question, participants were asked to memorize a color sequence presented at a list of spatial locations and later reproduce both the color and location sequences on two rings, one after another. In other words, subjects need to retain in WM two sequences of features, i.e., color and location, both of which could be characterized as sequence trajectories along their respective rings on a spatial map. Crucially, we manipulate the consistency between color and location sequence trajectories on the rings. Specifically, for the aligned condition, the color and location sequence share a common spatial trajectory, i.e., separated by the same distance between successive items between maps (<xref ref-type="fig" rid="fig1">Figure 1B</xref>), whereas, for the misaligned condition, they have distinct relative trajectories (<xref ref-type="fig" rid="fig1">Figure 1C</xref>). We hypothesize that humans would spontaneously combine the structure shared by the two sequences to facilitate memory formation, even though it is unsupervised and non-mandatory.</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Experimental paradigm.</title><p>(<bold>A</bold>) Participants were presented with a sequence of disks of different colors and at different locations. They were asked to memorize both the location and color of the sequence and later reproduce the full location and color sequences one after another by clicking the corresponding positions on the respective report rings. During the ‘recall location’ phase, a gray ring appeared and participants prepared for subsequent location recall without motor movement, to ensure memory decoding without motor interventions. During the following ‘response period,’ subjects serially selected memorized spatial locations on a ‘location ring.’ Next, a color ring appeared (‘recall color’) for subjects to be ready for subsequent color recall. They then clicked the remembered colors on a ‘color ring’ (‘response period’). (<bold>B</bold>) Aligned trajectory condition (AT) wherein the trajectory distances between consecutive items (i.e. first to second,second to third) of location and color sequences are identical, although the two sequences occupy different locations within their respective rings. (<bold>C</bold>) Misaligned condition (MAT), wherein the trajectory distances between consecutive items are different for location and color sequences.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93158-fig1-v1.tif"/></fig><p>To preview the results, we provide converging behavioral and neural evidence for spontaneously leveraging common structures to facilitate WM. Behaviorally, sequences with consistent color-location trajectories (aligned condition) show enhanced memory precision and a significant correlation between reproduced color and location sequence trajectories. Neurally, aligned location-color sequences demonstrate reactivation of shared trajectory during both encoding and retention periods and interestingly, spontaneous replay of color sequences when recalling location sequences. Together, shared common structures enable the storage of multiple sequences in WM through compressed encoding and neural replay.</p></sec><sec id="s2" sec-type="results"><title>Results</title><sec id="s2-1"><title>Experimental procedure and behavior performance</title><p>Thirty-three human participants performed a visual sequence WM task while their brain activities were recorded using EEG. As shown in <xref ref-type="fig" rid="fig1">Figure 1A</xref>, at the beginning of each trial, three disks with different spatial locations and colors were sequentially presented. Participants were required to concurrently remember their locations and colors as well as their orders, i.e., one location sequence and one color sequence. After a 2 s memory delay, a gray ring (location ring) was presented to instruct participants to prepare for subsequent location sequence recall without making motor responses (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, ‘recall location’ period). This is to ensure memory signals are decoded without explicit motor interventions. Next, a cursor appeared at the center of the screen (‘response period’), and participants clicked the three spatial locations on a ‘location ring’ in their correct order. Upon completion of location recall, participants were instructed to prepare for color sequence recall (‘recall color’), and they clicked three locations on the color ring based on the color sequence (‘response period’). One key aspect was manipulating the consistency between location and color trajectories so that the two sequences share or do not share a common structure in a cognitive map. Specifically, in the aligned trajectory condition (<italic>AT</italic> condition), despite the location and color sequences occupying different positions within their respective rings, their trajectory distances (between first and second items and between second and third) were the same (<xref ref-type="fig" rid="fig1">Figure 1B</xref>). In other words, by rotating certain angles, the three points in the two rings can exactly match, and the rotated angles varied from trial to trial, which allowed us to separately decode the location sequence and color sequence in the following analysis. In contrast, the location and color sequences in the misaligned trajectory condition (<italic>MAT</italic> condition) differed both in positions and trajectory distances within rings (<xref ref-type="fig" rid="fig1">Figure 1C</xref>).</p></sec><sec id="s2-2"><title>Aligned color-location trajectory improves memory performance</title><p>We first estimated memory precision for color and location sequences by calculating the reciprocal of the circular standard deviation of response error (circular difference between reported location (color) and correct location (color)) across trials (<inline-formula><mml:math id="inf1"><mml:mn>1</mml:mn><mml:mo>∕</mml:mo><mml:mi mathvariant="normal">σ</mml:mi></mml:math></inline-formula>) (<xref ref-type="bibr" rid="bib8">Bays et al., 2009</xref>). As shown in <xref ref-type="fig" rid="fig2">Figure 2A</xref>, two-way repeated ANOVA (alignment (AT vs. MAT)×task (location vs. color)) revealed significant main effects for alignment (F<sub>(1,32)</sub> = 4.279, p=0.047, η<sub>p</sub><sup>2</sup> = 0.118) and task (F<sub>(1,32)</sub> = 139.382, p&lt;0.001, η<sub>p</sub><sup>2</sup> = 0.813), but nonsignificant interaction effect (F<sub>(1,32)</sub> = 0.618, p=0.438, η<sub>p</sub><sup>2</sup> = 0.019). Specifically, the AT condition had better memory performance than the MAT condition, supporting our hypothesis that shared structure facilitates memory of multiple sequences. Moreover, location memory performed better than color memory. Further comparison revealed that the aligned condition mainly enhanced color memory (paired-t test, t<sub>(32)</sub> = 2.446, p=0.020, Cohen’s d=0.426) but not location (paired-t test, t<sub>(32)</sub> = 1.538, p=0.134, Cohen’s d=0.268). Better location vs. color memory performance indicates that alignment operation is less effective in improving memory (i.e. location sequence) that is already very robust (<xref ref-type="bibr" rid="bib68">Wu et al., 2020</xref>). In terms of serial position in sequence, color sequences demonstrated better memory performance under AT versus MAT conditions, especially for the second and third items (paired-t test, first: t<sub>(32)</sub> = –0.315, p=0.755, Cohen’s d=0.055; second: t<sub>(32)</sub> = 4.069, p&lt;0.001, Cohen’s d=0.709; third: t<sub>(32)</sub> = 2.583, p=0.015, Cohen’s d=0.450) (<xref ref-type="fig" rid="fig2">Figure 2B</xref>). Meanwhile, the location sequences exhibited similar performance for all positions (paired-t test, first: t<sub>(32)</sub> = 0.972, p=0.338, Cohen’s d=0.169; second: t<sub>(32)</sub> = 1.245, p=0.222, Cohen’s d=0.216; third: t<sub>(32)</sub> = 1.290, p=0.206, Cohen’s d=0.225) (<xref ref-type="fig" rid="fig2">Figure 2C</xref>). Overall, behavioral findings demonstrate an improvement in WM performance with a common trajectory across feature domains, and indicate that the aligned trajectories (first to second, second to third) may be applied to reduce the memory uncertainty for the second and third colors.</p><fig-group><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Behavioral performance.</title><p>(<bold>A</bold>) Memory precision performance of location (black) and color (green) sequences for aligned trajectory (AT) (dark color) and misaligned condition (MAT) (light color) conditions. Horizontal line in the boxplots denotes the median; box outlines denote the 25<sup>th</sup> and 75<sup>th</sup> percentiles; whiskers denote 1.5 × the interquartile range. Extreme values are denoted by crosses. (N = 33, *p&lt;0.05; **p&lt;0.01; ***p&lt;0.001). (<bold>B</bold>) Memory precision of first (purple), second (turquoise), and third (blue) items of location sequence, for AT (dark color) and MAT (light color) conditions. (<bold>C</bold>) Memory precision of first (purple), second (turquoise), and third (blue) items of color sequence, for AT (dark color) and MAT (light color) conditions. (<bold>D</bold>) Grand average (mean ± SEM) correlation coefficients of recalled trajectory error between location and color sequences, for first-to-second trajectory (brown), second -to-third trajectory (brickred), and first-to-third trajectory (orange), under AT (dark color) and MAT (light color) conditions. Dots indicate individual participants. (<bold>E</bold>) Scatterplot of first-to-second trajectory memory error for location sequence (X-axis) and Color sequence (Y-axis) under AT condition. Note that the trajectory error of all trials within each subject was divided into four bins according to the location trajectory error, resulting in 33 (subject number)*4 (bins) dots in the plot. The brown line represents the best linear fit. (<bold>F</bold>) Same as E, but for the second-to-third trajectory. (<bold>G</bold>) Same as E, but for the first-to-third trajectory.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93158-fig2-v1.tif"/></fig><fig id="fig2s1" position="float" specific-use="child-fig"><label>Figure 2—figure supplement 1.</label><caption><title>Behavioral performance and trajectory representation for misaligned condition.</title><p>(<bold>A</bold>) Scatterplot of first-to-second trajectory memory error for location sequence (X-axis) and Color sequence (Y-axis) under misaligned condition (MAT). Note that the trajectory error of all trials within each subject was divided into four bins according to the location trajectory error, resulting in 33 (subject number)*4 (bins) dots in the plot. The brown line represents the best linear fit. (<bold>B</bold>) Same as A, but for second-to-third trajectory. (<bold>C</bold>) Same as A, but for first-to-third trajectory. (<bold>D</bold>) Grand average (mean ± SEM) neural decoding of first-to-second as a function of time during the encoding period, for MAT condition. (<bold>E</bold>) Same as A, but for second-to-third trajectory. (<bold>F</bold>) Same as A, but for first-to-third trajectory.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93158-fig2-figsupp1-v1.tif"/></fig></fig-group></sec><sec id="s2-3"><title>Aligned color-location trajectory elicits color-location correlation in recalled trajectories</title><p>We further investigated whether the location-color trajectory alignment was truly leveraged in the memory process. Note that participants reproduced the color and location sequences by clicking three positions on the respective rings, i.e., reproducing two spatial trajectories, one for location and one for color (<xref ref-type="fig" rid="fig1">Figure 1A</xref>, reporting period). We, therefore, could examine the correlation between the reported location and color trajectories in their maps to determine whether the AT condition would result in a correlated pattern based on the reported sequences.</p><p>Specifically, we first calculated trajectory error (the circular difference between the reported trajectory and the true trajectory) for location and color features, and then accessed the correlation between the (signed) trajectory error of location and color features, for each subject. As shown in <xref ref-type="fig" rid="fig2">Figure 2D</xref>, the AT condition showed significant correlations for both first-second (one-sample t-test, t <sub>(32)</sub>=5.022, p&lt;0.001) and second-third (one-sample t-test, t <sub>(32)</sub>=3.113, p=0.004) trajectories, but not for first- third trajectory (one-sample t-test, t <sub>(32)</sub>=1.579, p=0.124). In contrast, the MAT condition did not display any significant correlation (one-sample t-test; first- second: t <sub>(32)</sub>=1.361, p=0.183; second-third: t <sub>(32)</sub>=0.490, p=0.628; first-third: t <sub>(32)</sub>=–0.582, p=0.565).</p><p>At the group level, motivated by a previous study (<xref ref-type="bibr" rid="bib40">Li et al., 2021b</xref>), we quantified the trajectory correlations by first binning all trials based on the location trajectory error, then extracting the color trajectory error for each bin, for each subject and pooling the data across subjects. As shown in <xref ref-type="fig" rid="fig2">Figure 2</xref> EFG, a significant correlation was observed for the first-second (<italic>r</italic>=0.270, p=0.002) and second-third trajectory (<italic>r</italic>=0.279, p=0.002), but not for the first-third trajectory (<italic>r</italic>=0.077, p=0.375). Similarly, the MAT condition did not exhibit any location-color correlation in trajectories (first-second: <italic>r</italic>=0.097, p=0.277; second-third: <italic>r</italic>=0.025, p=0.790; first-third: <italic>r</italic>=–0.065, p=0.443; also see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1A–C</xref>), which excludes the possibility that the reported trajectory correlation was solely due to systematic response bias. We further confirmed the trajectory errors correlations using a generalized linear mixed-effects model (AT: first-second trajectory, <italic>β</italic>=0.071, t=4.215, p&lt;0.001; second-third trajectory, <italic>β</italic>=0.077, t=3.570, p&lt;0.001; first-third trajectory, <italic>β</italic>=0.019, t=1.118, p=0.264; MAT: first-second trajectory, <italic>β</italic>=0.031, t=1.572, p=0.116; second-third trajectory, <italic>β</italic>=–0.002, t=0.128, p=0.898; first-third trajectory, <italic>β</italic>=–0.017, t=–1.024, p=0.306).</p><p>Together, behavioral findings indicate that memory facilitation arises from an automatic alignment of recalled trajectories across feature domains to compress information. In other words, instead of memorizing two three-item sequences independently, subjects may just maintain their common trajectories.</p></sec><sec id="s2-4"><title>Neural decoding of location and color features during encoding</title><p>We employed a time-resolved inverted encoding model (IEM) (<xref ref-type="bibr" rid="bib15">Brouwer and Heeger, 2009</xref>; <xref ref-type="bibr" rid="bib16">Brouwer and Heeger, 2011</xref>) on EEG signals to examine the neural representation of location and color. Specifically, the slope of the reconstructed channel response was estimated to quantify the time-resolved decoding performance for the first, second, and third location and color, respectively (see details in Materials and methods) at each time point. We first focused on the encoding period when the three-disk sequence was physically presented.</p><p>As shown in <xref ref-type="fig" rid="fig3">Figure 3A</xref>, the location of each of the three disks could be successfully decoded from EEG signals for both AT (first location: 0.03–0.56 s, 1.14–1.26 s, 1.55–1.84 s; second location: 1.56–2.10 s, 2.65–2.92 s, 3.12–3.35 s; third location: 3.06–3.50 s; corrected cluster p&lt;0.001) and MAT conditions (first location: 0.03–0.52 s, 1.15–1.39 s, 1.58–1.84 s,; second location: 1.52–2.10 s, 3.11–3.36 s; third location: 3.06–3.54 s; corrected cluster p&lt;0.001) during stimulus presentation period. Similarly, color information could also be decoded for both AT (first color: 0.09–0.50 s, corrected cluster p&lt;0.001;second color: 1.57–2.01 s, corrected cluster p&lt;0.001; third color: 3.11–3.49 s, corrected cluster p=0.002) and MAT conditions (first color: 0.04–0.45 s; second color: 1.57–1.91 s, corrected cluster p&lt;0.001; third color: 3.11–3.55 s; corrected cluster p&lt;0.001) (<xref ref-type="fig" rid="fig3">Figure 3B</xref>). It is noteworthy that location and color features were generated with the constraint that they could not occupy the same position within their respective rings. This thereby ensured the independent decoding of location and color features from the same neural signals. Moreover, the color feature exhibited weaker decoding strength than location, also consistent with behavioral results (<xref ref-type="fig" rid="fig2">Figure 2A</xref>).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Neural representation of memory contents during the encoding period.</title><p>(<bold>A</bold>) Grand average (mean ± SEM) neural decoding (slope of channel response) of location information for the first (purple), second (turquoise), and third (blue) disk as a function of time during the encoding period, for aligned trajectory (AT) (left panel) and misaligned conditions (MAT) (right panel). Horizontal lines with corresponding colors denote significant time ranges (cluster-based permutation test, cluster-defining threshold p&lt;0.001, corrected significance level p&lt;0.001) (<bold>B</bold>) Same as A, but for color feature decoding.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93158-fig3-v1.tif"/></fig></sec><sec id="s2-5"><title>Spontaneous replay of color sequence during location recall</title><p>After confirming location and color representations during the encoding period, we next examined the neuronal correlates of sequence memory during retrieval. We are particularly interested in the ‘recall location’ period, during which subjects need to remain still without making motor responses but at the same time prepare for subsequent location recall (see <xref ref-type="fig" rid="fig1">Figure 1A</xref>, and upper panel of <xref ref-type="fig" rid="fig4">Figure 4</xref>). During this period, subjects need to maintain two sequences: the location sequence which is immediately task-relevant, and the color sequence which is not task-relevant right now but will be recalled later. That is to say, we posit that memories should be converted to sequences as outputs during this period. Behavioral analysis indicates the correlation between recalled location and color trajectories for AT condition (<xref ref-type="fig" rid="fig2">Figure 2</xref>), which suggests an active combination of common trajectories across features. As a result, we sought neural evidence for the reintegration between the color sequence and the location sequence for the AT condition during this period.</p><fig-group><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Spontaneous color sequence replay during ‘location recall’.</title><p>(<bold>A</bold>) Grand average (mean ± SEM) decoding performance for first (purple), second (turquoise), and third (blue) locations as a function of time during the ‘“recall location’ period, for aligned trajectory (AT) (left panel) and misaligned (MAT) conditions (right panel). (<bold>B</bold>) Grand average (mean ± SEM) decoding performance for first (purple), second (turquoise), and third (blue) colors as a function of time during ‘recall location’ period, for AT (left panel) and MAT conditions (right panel). (Horizontal solid line: cluster-based permutation test, cluster-defining threshold p&lt;0.05, corrected significance level p&lt;0.05; Horizontal dashed line: marginal significance, cluster-defining threshold p&lt;0.1, 0.05&lt;cluster p&lt;0.1) (<bold>C</bold>) Grand average decoding performance within the respective significant time range, for first (purple), second (turquoise) and third (blue) colors, under AT (dark color) and MAT (light color) conditions. (<bold>D</bold>) Cross-correlation coefficient, calculated to quantify the extent of the neural representations of adjacent two items followed a forward (positive y) or backward (negative y) transition as a funciton of time lag, between first and second colors (brown color) and between second and third (brick red color) colors, and their average (gray color). Dashed vertical line denotes the peak of the averaged cross-correlation time courses. Dashed horizontal lines denote the nonparametric statistical significance threshold (p&lt;0.05, permutation test). (<bold>E</bold>) Left panel: theoretical transition pattern for three-item forward replay, i.e., first-second-third, characterized by cross-correlation at certain time lag. Right panel: empirical transitional pattern (actual cross-correlation matrix) at 130 ms time lag. A significant correlation was found between the two matrices (<italic>r</italic>=0.690, p=0.040), further confirming the forward replay of color sequence.</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93158-fig4-v1.tif"/></fig><fig id="fig4s1" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 1.</label><caption><title>Color and location representations during &quot;color recall&quot;.</title><p>(<bold>A</bold>) Left panel: grand average (mean ± SEM) time courses of the decoding performance for the first (purple), second (turquoise), and third (blue) working memory (WM) colors during color recalling period. Right panel: grand average (mean ± SEM) time courses of the decoding performance in misaligned condition (MAT) condition. (<bold>B</bold>) Left panel: grand average (mean ± SEM) time courses of the decoding performance for the first, second, and third WM locations during color recalling period. Right panel: grand average (mean ± SEM) time courses of the decoding performance in MAT condition. (Horizontal solid line: cluster-based permutation test, cluster-defining threshold p&lt;0.05, corrected significance level p&lt;0.05; Horizontal dashed line: marginal significance, cluster-defining threshold p&lt;0.1, 0.05&lt;cluster p&lt;0.1).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93158-fig4-figsupp1-v1.tif"/></fig><fig id="fig4s2" position="float" specific-use="child-fig"><label>Figure 4—figure supplement 2.</label><caption><title>Participants were divided into two groups based on the average of trajectory decoding performance within the respective significant time range.</title><p>(<bold>A</bold>) Grand average (mean ± SEM) time courses of the decoding performance for the first, second and third colors during location recalling period for high trajectory representation group. (<bold>B</bold>) Left panel: theoretical transition pattern for three-item forward replay. Right panel: empirical transitional pattern (actual cross-correlation matrix) at 130 ms time lag defined in <xref ref-type="fig" rid="fig4">Figure 4D</xref>. A significant correlation was found between the two matrices (<italic>r</italic>=0.715, p=0.030), further confirming the forward replay of color sequence for high trajectory representation group. (<bold>C</bold>) Same as A, but for low trajectory representation group. (<bold>D</bold>) Same as B, but for low trajectory representation group, nonsignificant correlation between the two matrices was observed (<italic>r</italic>=0.230, p=0.553). (Horizontal solid line: time window with significnat activation t-test, p&lt;0.05, without correction across time).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93158-fig4-figsupp2-v1.tif"/></fig></fig-group><p>As shown in <xref ref-type="fig" rid="fig4">Figure 4A</xref> (left panel), the currently task-relevant location sequence during AT condition displayed strong decoding performance for the first location (0.11–0.46 s, corrected cluster p=0.003), weak but significant decoding performance for the third location (0.27–0.41 s, corrected cluster p=0.011), but not for the second location. Moreover, The MAT condition (<xref ref-type="fig" rid="fig4">Figure 4A</xref>, right panel) showed the similar location decoding profiles (first location: 0.11–0.46 s, corrected cluster p&lt;0.001; third location: 0.13–0.35 s, corrected cluster p=0.002). The primacy effect might be due to the fact that the first location is the first to be recalled afterward, and therefore it denotes either the most task-relevant feature or motor preparation. In fact, a similar position effect has also been observed for color sequence during the color recalling period (<xref ref-type="fig" rid="fig4s1">Figure 4—figure supplement 1</xref>).</p><p>Most importantly, we asked whether the ‘recall location’ period also contains color sequence information, which is not task-relevant at the moment but will be recalled later. As shown in the left panel of <xref ref-type="fig" rid="fig4">Figure 4B</xref>, we observed significant reactivation of color sequence for the AT condition. Specifically, the color sequence undergoes a temporally compressed, forward reply (first color: 0.10–0.16 s, corrected cluster p=0.048; second color: 0.21–0.27 s, corrected cluster p=0.046; third color: 0.31–0.38 s, corrected cluster p=0.089). In contrast, the MAT condition did not display any neural reactivation of the color sequence (<xref ref-type="fig" rid="fig4">Figure 4B</xref>, right panel). Direct comparison between AT and MAT conditions showed a significant reactivation difference (two-way repeated ANOVA, F<sub>(1,32)</sub> = 14.213, p=0.001, η<sub>p</sub><sup>2</sup> = 0.308). Further analysis (<xref ref-type="fig" rid="fig4">Figure 4C</xref>) reveals that the AT-MAT difference is mainly due to the first (paired test, t<sub>(32)</sub> = 3.151, p=0.004, Cohen’s d=0.548) and second items (t<sub>(32)</sub> = 1.914, p=0.065, Cohen’s d=0.334).</p><p>We next used a ‘sequences’ approach (<xref ref-type="bibr" rid="bib37">Kurth-Nelson et al., 2016</xref>; <xref ref-type="bibr" rid="bib41">Liu et al., 2019</xref>) to characterize the sequential replay profile. Specifically, we calculated the cross-correlation coefficients between consecutive items, and then performed a permutation test to examine the statistical significance of the sequential replay profile by shuffling color labels across participants. <xref ref-type="fig" rid="fig4">Figure 4D</xref> shows a significant temporal lag around 110 ms and 140 ms for the first-second and second-third color pairs, respectively, indicating a forward replay profile with temporal compression within approximately 130 ms (peak of the average of the two cross-correlation time courses).</p><p>Moreover, motivated by previous studies (<xref ref-type="bibr" rid="bib42">Liu et al., 2021a</xref>; <xref ref-type="bibr" rid="bib43">Liu et al., 2021b</xref>), we first constructed the theoretical transitional pattern for the three-item sequence by assuming a Δt temporal lag between consecutive items (i.e. cross-correlation matrix). As shown in <xref ref-type="fig" rid="fig4">Figure 4E</xref> (left panel), the first item at time T could predict the reactivation of the second item at T+Δt, and the second item at time T could predict the appearance of the third item at T+Δt. We then calculated the actual cross-correlation matrix (empirical transitional pattern) at 130 ms time lag which denotes the time lag of consecutive items in our findings (see <xref ref-type="fig" rid="fig4">Figure 4D</xref>, gray line), resulting in a 3×3 matrix (<xref ref-type="fig" rid="fig4">Figure 4E</xref>, right panel). A significant correlation was found between the empirical cross-correlation matrix and the theoretical transitional pattern (<italic>r</italic>=0.690, p=0.040), further confirming the forward replay of the color sequence.</p><p>Together, when subjects prepare to reproduce location sequence during ‘recall location,’ the currently task-irrelevant color sequence demonstrates a spontaneous sequential replay profile, which highlights the close bond between color and location sequences when they share a common trajectory. Together with the color-location trajectory correlation in behavior, the findings suggest that replay-based neural mechanisms in WM mediate sequence combinations based on common structures.</p></sec><sec id="s2-6"><title>Neural representation of common trajectory and its behavioral correlates</title><p>Finally, we accessed the neural representations of the common trajectory structure during encoding and retention periods. Specifically, a linear support vector machine (SVM) was employed to decode the first-to-second and second-to-third trajectory distance, with the first-to-third trajectory as a control. Since there are only eight possible circular distances between every two locations on a ring, the chance level of decoding performance is 0.125.</p><p>During the encoding period (<xref ref-type="fig" rid="fig5">Figure 5A</xref>), the first-to-second trajectory appeared right after the presentation of the second item for AT condition (1.55–2.11 s, corrected cluster p&lt;0.001), which is expected since the relationship between the first and second items along the trajectory can only be established when the second item occurs. Similarly, the second-to-third trajectory appeared after onset of the third item (3.10–3.48 s, corrected cluster p&lt;0.001) (<xref ref-type="fig" rid="fig5">Figure 5B</xref>). In contrast, the first-third trajectory showed nonsignificant neural decoding (<xref ref-type="fig" rid="fig5">Figure 5C</xref>), consistent with the nonsignificant color-location trajectory correlation in behavior. Most interestingly, the first-to-second trajectory was reactivated right after the third item (3.19–3.48 s, corrected cluster p=0.006; <xref ref-type="fig" rid="fig5">Figure 5A</xref>), implicating the formed link between the two trajectories (first-second and second-third) for aligned location-color sequences. Therefore, when the color and location sequences share the same trajectory (i.e. AT condition), brain activities tend to co-represent the previously formed first-to-second trajectory (reactivation) and the newly formed second-to-third trajectory during encoding to establish the full trajectory (see <xref ref-type="fig" rid="fig2s1">Figure 2—figure supplement 1D, E, F</xref> for MAT condition). The trajectory reactivation was also related to WM behavior. Specifically, we divided all participants into two groups based on their first-to-second color-location trajectory memory correlations in behavior (<xref ref-type="fig" rid="fig2">Figure 2D</xref>) and calculated their corresponding neural representation of the first-to-second trajectory, respectively. Both the higher- and lower-correlation groups displayed significant neural decoding of the first-to-second trajectory right after the second item (<xref ref-type="fig" rid="fig5">Figure 5D</xref>; higher group: 1.56–1.99 s, corrected cluster p&lt;0.001; lower group: 1.64–1.97 s, corrected cluster p&lt;0.001). Meanwhile, only the higher-correlation group exhibited a significant reactivation of the first-to-second trajectory after the onset of the third item (3.25–3.46 s, corrected cluster p=0.018, 3.55–3.68 s, corrected cluster p=0.088; Higher group vs. Lower group: bootstrap test, p=0.037, two-side). Moreover, we were curious about the correlation between the common trajectory representation and latter forward replay pattern. Therefore, based on the average of trajectory neural representation (first-second and second-third trajectories) during presentation of the third item when common trajectory reactivation was observed, we divided all participants into two groups, and observed higher trajectory representation group was accompanied with clearer forward replay (see <xref ref-type="fig" rid="fig4s2">Figure 4—figure supplement 2</xref>). This finding indicates that memory reorganization formed during encoding can predict serial replay during recalling.</p><fig-group><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Common trajectory representation and its behavioral relevance.</title><p>(<bold>A</bold>) Grand average (mean ± SEM) neural decoding of first-to-second as a function of time during the encoding period, for aligned trajectory (AT) condition. (<bold>B</bold>) Same as A, but for second-to-third trajectory. (<bold>C</bold>) Same as A, but for first-to-third trajectory. (<bold>D</bold>) Participants were divided into two groups (higher-correlation group and lower-correlation group), based on their first-to-second color-location trajectory memory behavioral correlation. Grand average (mean ± SEM) neural decoding of first-to-second trajectory as a function of time, for higher-correlation group (n=16; left panel) and lower-correlation group (n=16; right panel). (Horizontal solid line: cluster-based permutation test, cluster-defining threshold p&lt;0.05, corrected significance level p&lt;0.05; Horizontal dashed line: cluster-based permutation test, cluster-defining threshold p&lt;0.05, corrected significance level p&lt;0.1).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93158-fig5-v1.tif"/></fig><fig id="fig5s1" position="float" specific-use="child-fig"><label>Figure 5—figure supplement 1.</label><caption><title>Trajectory representation during memory maintaining period.</title><p>(<bold>A</bold>) Grand average (mean ± SEM) neural decoding of first-to-second as a function of time during maintaining period, for aligned trajectory (AT) condition. Significant reactivation was observed during a relatively late stage of memory maintenanace. (<bold>B</bold>) Same as A, but for second-to-third trajectory. No significant reactivation was observed. (<bold>C, D</bold>) Condidering alpha-band power plays a crucial role in holding information during maintaining period, we also applied the same decoding approach on alpha band power during maintaining period. Specifically, we first conducted a time-frequency analysis using Morlet wavelets with a width of seven cycles (Fieldtrip toolbox) and then extracted alpha-band (8–12 Hz) power time courses. A linear support vector machine (SVM) was then employed on alpha-band power. Both first-to-second and second-to-third trajectories showed significant reactivation. (<bold>E, F</bold>) Same as A, B, but for misaligned trajectory condition. (<bold>G, H</bold>) Same as CD, but for misaligned trajectory condition. (Horizontal solid line: cluster-based permutation test, cluster-defining threshold p&lt;0.05, corrected significance level p&lt;0.05; Horizontal dashed line: cluster-based permutation test, cluster-defining threshold <italic>P</italic>&lt;0.05, corrected significance level p&lt;0.1).</p></caption><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93158-fig5-figsupp1-v1.tif"/></fig></fig-group><p>With regards to the retention period, based on previous literatures (<xref ref-type="bibr" rid="bib21">de Vries et al., 2020</xref>; <xref ref-type="bibr" rid="bib27">Foster et al., 2016</xref>; <xref ref-type="bibr" rid="bib29">Fukuda et al., 2016</xref>; <xref ref-type="bibr" rid="bib60">Sutterer et al., 2019</xref>), we chose to rely on the alpha-band activities to decode shared trajectories (see decoding results based on raw signals in <xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1A, B</xref>). The aligned condition showed significant and long-lasting decoding of compression trajectories (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1C, D</xref>), while the misaligned condition only showed decoding at the beginning, which might be due to the non- offset response of the third item (<xref ref-type="fig" rid="fig5s1">Figure 5—figure supplement 1G, H</xref>). The results, although not as clear as those during encoding and recalling periods, also supports compression trajectory is spontaneously leveraged to reorganize multiple information.</p></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>Identifying the underlying structure to facilitate efficient information storage in WM is crucial to human intelligence. Here, we investigated whether common structures shared across different feature domains would be spontaneously employed to facilitate memory of multiple sequences and its neural correlates. Since both location and color features could be characterized by positions along a continuous ring, we systematically manipulated the trajectory consistency between the location and color sequences. We show that color-location trajectory alignment is associated with better memory performance than the misaligned condition, and the memory benefit is attributed to structure-induced constraints on individual items that decrease representational uncertainty. EEG recordings provide neural evidence for the employed ‘compressive’ strategy, i.e., reactivation of shared trajectories during encoding and retention, and spontaneous replay of color sequences during location recall. Finally, structure reactivation is related to WM behavior and neural replay. Together, shared common structure is leveraged for storage of multiple sequences through compressed encoding and neural replay, together facilitating efficient information organization in WM.</p><p>Events in daily experiences are not isolated but are always linked to each other. Therefore, instead of treating individual events as independent information, a more efficient way is to seek the link between seemingly unrelated events, i.e., ‘connecting the dots’ in the WM system. Here the trajectories for both location and color sequences are defined in a ring coordinate system, providing an abstract-level cognitive map for memory formation. Our results demonstrate that subjects spontaneously realign sequence trajectories across features to facilitate memory of two sequences. In other words, instead of memorizing two three-item sequences, subjects could just maintain two starting points and a common trajectory, an apparently more efficient way. Not that the trajectory alignment manipulation differs from the Gestalt principles of perceptual organization such as proximity and similarity principles (<xref ref-type="bibr" rid="bib33">Goldstone and Medin, 1994</xref>), and it instead reflects a higher-order relationship between maps. The alignment manipulation also could not be accounted for by associative memory (<xref ref-type="bibr" rid="bib1">Aho et al., 2022</xref>; <xref ref-type="bibr" rid="bib52">Roads and Love, 2020</xref>), since the rotational orientation for alignments between the two maps differed on a trial-by-trial basis. Finally, our study is also different from recent works on structure learning and generalization (<xref ref-type="bibr" rid="bib20">Dekker et al., 2022</xref>; <xref ref-type="bibr" rid="bib30">Garvert et al., 2017</xref>; <xref ref-type="bibr" rid="bib43">Liu et al., 2021b</xref>; <xref ref-type="bibr" rid="bib51">Ren et al., 2022</xref>; <xref ref-type="bibr" rid="bib53">Schapiro et al., 2013</xref>), as our task does not involve pre-exposure training or task-related rewards.</p><p>Notably, our findings could also be understood in terms of schematic abstraction, which plays pivotal roles in memory formation (<xref ref-type="bibr" rid="bib32">Gilboa and Marlatte, 2017</xref>; <xref ref-type="bibr" rid="bib63">Tse et al., 2007</xref>), such that a congruent schema would facilitate memory retrieval compared to an incongruent condition (<xref ref-type="bibr" rid="bib4">Audrain and McAndrews, 2022</xref>; <xref ref-type="bibr" rid="bib64">van Kesteren et al., 2010</xref>). In fact, cognitive map refers to the internal representation of spatial relations in a specific environment (<xref ref-type="bibr" rid="bib62">Tolman, 1948</xref>), while schematic abstraction denotes a more broad range of circumstances, whereby the gist or structure of multiple environments or episodes can be integrated (<xref ref-type="bibr" rid="bib7">Bartlett, 1932</xref>; <xref ref-type="bibr" rid="bib25">Farzanfar et al., 2023</xref>). In other words, schema refers to a highly abstract framework of prior knowledge that captures common patterns across related experiences, which does not necessarily occur in a spatial framework as cognitive maps do. In the current design, as we specifically manipulate the consistency of spatial trajectory distance between color and location sequences defined in a spatial map, cognitive map might be a more conservative term to frame our findings, although in essence it reflects general schema-based WM reorganization.</p><p>The fact that without task requirement, human participants still spontaneously extracted underlying common structure and leveraged it to organize multiple item storage reflects the intelligence of our brain to achieve efficient information coding (<xref ref-type="bibr" rid="bib3">Attneave, 1954</xref>). Indeed, there is a mountain of research suggesting that participants exploit statistical regularities to form efficient WM representation without explicit instructions to do so (e.g. <xref ref-type="bibr" rid="bib12">Brady et al., 2009</xref>; <xref ref-type="bibr" rid="bib14">Brady and Tenenbaum, 2013</xref>). However, it remains largely unknown about the underlying neural mechanism. Here, the common structure we manipulated is inspired by the theory of cognitive map (<xref ref-type="bibr" rid="bib9">Behrens et al., 2018</xref>; <xref ref-type="bibr" rid="bib10">Bellmund et al., 2018</xref>; <xref ref-type="bibr" rid="bib47">O’keefe and Nadel, 1978</xref>), which has argued that reasoning in abstract domains follows similar computational principles as in spatial domains. This theory has been supported by accumulated neuroscientific evidence suggesting common neural substrates for knowledge representation across domains (<xref ref-type="bibr" rid="bib17">Constantinescu et al., 2016</xref>; <xref ref-type="bibr" rid="bib30">Garvert et al., 2017</xref>; <xref ref-type="bibr" rid="bib50">Park et al., 2021</xref>; <xref ref-type="bibr" rid="bib55">Schuck et al., 2016</xref>; <xref ref-type="bibr" rid="bib59">Solomon et al., 2019</xref>; <xref ref-type="bibr" rid="bib61">Theves et al., 2019</xref>). In line with these evidence, recent behavioral studies further prove the integration of information representation across domains based on common computing principles. For example, learning process is accelerated when two different feature maps are aligned (<xref ref-type="bibr" rid="bib1">Aho et al., 2022</xref>), and distance-dependent generalization is observed across two different domains in order to search for correlated rewards (<xref ref-type="bibr" rid="bib68">Wu et al., 2020</xref>). Here, we extend the functional role of cognitive map in efficiently organizing information across domains in human WM and reveal compressive encoding and neural replay in facilitating multiple sequence storage.</p><p>Neural replay refers to the sequential reactivation in the same or reversed order as previous experience. It was first observed in the rodent hippocampus and mainly for spatial navigation (<xref ref-type="bibr" rid="bib66">Wilson and McNaughton, 1994</xref>), but has recently been found in many higher-level non-spatial tasks in human brains (<xref ref-type="bibr" rid="bib37">Kurth-Nelson et al., 2016</xref>; <xref ref-type="bibr" rid="bib41">Liu et al., 2019</xref>; <xref ref-type="bibr" rid="bib43">Liu et al., 2021b</xref>; <xref ref-type="bibr" rid="bib54">Schapiro et al., 2018</xref>; <xref ref-type="bibr" rid="bib56">Schuck and Niv, 2019</xref>; <xref ref-type="bibr" rid="bib70">Zhang et al., 2018</xref>). In fact, neural replay has been posited to represent abstract structure (<xref ref-type="bibr" rid="bib36">Huang et al., 2021</xref>; <xref ref-type="bibr" rid="bib41">Liu et al., 2019</xref>), structure-based inference (<xref ref-type="bibr" rid="bib43">Liu et al., 2021b</xref>), and generalization (<xref ref-type="bibr" rid="bib6">Barry and Love, 2022</xref>). Here, when subjects prepare to recall location sequences (‘location recall’), neural replay occurs for color sequences but not for location sequences, supporting the spontaneous nature of neural replay, since color features are not task-relevant right now. The results also exclude other interpretations, such as motor preparation, eye movements, attentional sampling, sequential rehearsal, etc., since if that is the case, we would expect a similar neural replay profile for location sequences that are to be serially recalled soon. Furthermore, color neural replay only appears for the color-location aligned sequence (AT condition) but not for the misaligned sequences (MAT condition), implicating that neural replay serves to consolidate sequences that share a common structure. Therefore, our findings demonstrate new roles of neural replay in structure representation, that is, mediating structure alignment between sequences in the WM system.</p><p>It is posited that structure and content are represented in a factorized manner (<xref ref-type="bibr" rid="bib9">Behrens et al., 2018</xref>; <xref ref-type="bibr" rid="bib11">Bengio et al., 2013</xref>), and sequence structure representation that is independent of attached contents guides the replay of new experiences (<xref ref-type="bibr" rid="bib41">Liu et al., 2019</xref>). Factorization representation is thought to help fast generalization of a previously learned structure to new contents (<xref ref-type="bibr" rid="bib57">Sheahan et al., 2021</xref>; <xref ref-type="bibr" rid="bib72">Zhou et al., 2021</xref>). Indeed, the ability to spontaneously perceive relational structures is posited to signify the major distinction between human and nonhuman primates (<xref ref-type="bibr" rid="bib19">Dehaene et al., 2015</xref>; <xref ref-type="bibr" rid="bib71">Zhang et al., 2022</xref>). Meanwhile, previous modeling works also suggest that higher-order structures incorporated in WM would serve as constraints on individual-item representations to reduce representational uncertainty (<xref ref-type="bibr" rid="bib14">Brady and Tenenbaum, 2013</xref>; <xref ref-type="bibr" rid="bib22">Ding et al., 2017</xref>). In this work, we provide behavioral and neural evidence that structure is not only dissociated from content representation, i.e., factorization coding, but also can be aligned in a spontaneous manner, i.e., linking structures, which together contribute to efficient representation of memory information.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Participants</title><p>Thirty-six participants (18 males, age ranging from 17 to 25 years) were recruited to accomplish our multi-sequence working memory task. Three participants were removed, since they could not finish the whole experiment. No statistical methods were used to predetermine sample sizes, but our sample sizes are similar to previous studies (<xref ref-type="bibr" rid="bib39">Li et al., 2021a</xref>; <xref ref-type="bibr" rid="bib67">Wolff et al., 2017</xref>). All participants had normal or corrected-to-normal vision with no history of neurological disorders. They were naïve to the purpose of the experiments, and provided written informed consent prior to the start of the experiment. This study received ethical approval from the Peking University Research Ethics Committee (reference number 2020-03-03). This study was carried out in accordance with the Declaration of Helsinki.</p><p>Participants sat in a dark room, 60 cm in front of a Display ++ monitor with 100 Hz refresh rate and a resolution of 1920 × 1080, and their head stabilized on a chin rest. At the beginning of trial, three disks (1.5° × 1.5° visual angle) were sequentially presented at different locations of the screen, with different colors. The spatial location of each disk was independently drawn from a fixed set of 9 locations, which were evenly distributed on an imaginary circle with radius of 7° visual angle from central fixation and spaced 40° from the nearest locations, with a small random jitter (±1° – ±3°) added to each. The color of the each disk was also independently selected from a fixed set of nine colors, which were evenly distributed along a circle in Commission Internationale de l’Eclairage (CIE) L*a*b* space, and equidistant from the gray point at L*=50, a*=0, and b*=0 (<xref ref-type="bibr" rid="bib15">Brouwer and Heeger, 2009</xref>), and spaced by 40°, with a small random jitter (±1° – ±3°). Each disk was presented for 1 s, with 0.5 s interval between two adjacent disks. After 2 s delay during which only the fixation point remained on screen, a gray ring appeared for 0.5 s with the same radius (7° visual angle) from central fixation to instruct participants to recall three spatial locations without any movement. Then, a cursor appeared at fixation, and participants should report the remembered locations sequentially in their presented order by using a mouse to click on the gray location ring. After delivering three spatial location responses, a color ring was presented for 0.5 s (7° visual angle in radius) to instruct participants to recall three colors without any movement. Similarly, a cursor then appeared, and participants were asked to report the remembered colors sequentially in their presented order by clicking on the color ring. To reduce the complexity of the task, the color wheel was oriented the same way for individual participant.</p><p>Note that even though color and location were different features, their values were both chosen from nine positions/values based on their respective ring (0° – 320° in 40° increments), with the constraint that the color value and location value for the same item can’t be the same. In order to investigate whether common structure would organize multiple information storage in different domains, we modulated trajectory consistency. Specifically, in the aligned trajectory condition (AT), both the first-to-second and second-to-third disk trajectory distances in location domain were the same as that in color domain. In other words, by rotating certain degree, the whole trajectory (from the first to third point) was matched in the location and color maps. At the same time, we varied the rotated degree to align the two maps on a trial-by-trial basis, such that we could not predict color sequence solely based on location sequence. This manipulation was critical to independently decode color sequence and location sequence. In misaligned trajectory condition (MAT), the whole trajectories (first-second-third) in the two maps were different, while partial trajectory (either first-second or second-third) can be the same for some trials. Therefore, in MAT condition, we couldn’t rotate one map to exactly match the other map. Note that random selection for individual item both for AT and MAT conditions resulted in varied trajectories, which can move in clockwise or anticlockwise direction and the direction can even be reversed on the third item. Trials from AT and MAT conditions were interleaved, aiming to investigate the spontaneous information organization process in a more natural way and avoid prediction about trial type. In each trial three locations were chosen independently from 9 values (0° – 320° in 40° increments, each occurred 36 times with random order), but with a constraint that they should at least differ by 40°. The same rule was applied to three colors. Moreover, the color and location value from the same object were also constrained to be different. Participants should complete 648 trials in total, which was divided into two sessions on two separate days, separated by at most one week. It took approximately 3 hr to accomplish one session (including breaks).</p></sec><sec id="s4-2"><title>EEG acquisition and preprocessing</title><p>The EEG data was recorded using a 64-channel EasyCap and two BrainAmp amplifiers (BrainProducts). Horizontal electrooculography (EOG) was recorded by an additional electrode around the participants’ right eye. The impedances of all electrodes were kept below 10 k. The EEG data was preprocessed offline using FieldTrip software (<xref ref-type="bibr" rid="bib49">Oostenveld et al., 2011</xref>). Specifically, the data was first referenced to the average value of all channels, band-pass filtered between 2 and 50 Hz, and down-sampled to 100 Hz. The data was then baseline-corrected, by selecting the time range from 300 ms to 100 ms before the presentation of the first disk in each trial as baseline to be subtracted. Then, independent component analysis (ICA) was performed independently for each participant to remove eye movement and artifact components, and the remaining components were back-projected onto the EEG electrode space. To further identify artifacts, we calculated the variance (collapsed over channels and time) for each trial. Trials with excessive variances were removed. Note that the following decoding approach was based on the whole electrodes, except that location decoding in the encoding period was based on the posterior electrodes (P7, P5, P3, P1, Pz, P4, P6, P8, PO7, PO3, POz, PO4, PO8, O1, Oz, and O2), considering eye movement was not strictly controlled in the present study.</p></sec><sec id="s4-3"><title>Data analysis</title><sec id="s4-3-1"><title>Behavioral performance analysis</title><p>For each spatial location and color, the response error was first quantified by the circular difference between the reported location (color) and the true target location (color) in each trial. The memory precision was then estimated by calculating the reciprocal of circular standard deviation of response error. To explore the similarity of the perceived trajectory in spatial location and color domains, we calculated the circular correlation of the perceived trajectory (trajectory memory error) between the two domains for each participant. Trajectory response error was quantified by the circular difference between the reported trajectory and the true trajectory, e.g., the first-to-second trajectory error in location was calculated by the difference between the first location error and second location error. In group level, we quantified the circular correlations of trajectory error by first sorting trials into four bins based on their location trajectory error for each participant, then binning the trials, computing the color trajectory error for each bin, and pooling the data across participants.</p></sec><sec id="s4-3-2"><title>Time-resolved location and color decoding</title><p>Similar as previous studies (<xref ref-type="bibr" rid="bib15">Brouwer and Heeger, 2009</xref>; <xref ref-type="bibr" rid="bib16">Brouwer and Heeger, 2011</xref>; <xref ref-type="bibr" rid="bib36">Huang et al., 2021</xref>), in order to assess the time-resolved location and color information from the EEG signals, we implemented the inverted encoding model (IEM) to reconstruct the location and color information from the neural activities at each time point. The IEM assumes that the response in each sensor could be approximated as a linear sum of underlying neural populations encoding different values of the feature-of-interest (i.e. tuning channels). Here, the number of location and color tuning channels were both set to 9. Following previous work (<xref ref-type="bibr" rid="bib24">Ester et al., 2015</xref>; <xref ref-type="bibr" rid="bib69">Yu et al., 2020</xref>), the idealized feature tuning curves of nine channels were defined as nine half-wave rectified sinusoids centered at different location (color) values (0°, 40°, 80°, and so on) and raised to the eighth power.</p><p>We began by modeling the response of each EEG sensor as a linear sum of nine information channels, characterized by <inline-formula><mml:math id="inf2"><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mi>W</mml:mi><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> , in the training data set, where <inline-formula><mml:math id="inf3"><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> (m sensors × n trials) represents the observed response at each sensor, <inline-formula><mml:math id="inf4"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> (k channels × n trials) represents the predicted channel responses, <inline-formula><mml:math id="inf5"><mml:mi>W</mml:mi></mml:math></inline-formula> (m sensors ×k channels) represents the weight matrix that characterizes the linear mapping from ‘channel space’ to ‘sensor space.’ Therefore, given <inline-formula><mml:math id="inf6"><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> , and <inline-formula><mml:math id="inf7"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> , the weight matrix <inline-formula><mml:math id="inf8"><mml:mi>W</mml:mi></mml:math></inline-formula> (m sensors × k channels) was calculated by using least-squares regression <inline-formula><mml:math id="inf9"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msubsup><mml:mi>C</mml:mi><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:math></inline-formula> . Finally, the channel responses (<inline-formula><mml:math id="inf10"><mml:msub><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>) for the test data set (<inline-formula><mml:math id="inf11"><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula>) could be extracted using the estimated <inline-formula><mml:math id="inf12"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow><mml:mrow><mml:mover><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow></mml:mstyle></mml:math></inline-formula> , by <inline-formula><mml:math id="inf13"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mrow><mml:mover><mml:mi>C</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>−</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mrow><mml:mrow><mml:mover><mml:mi>W</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msup><mml:msub><mml:mi>B</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> .</p><p>Regarding the division of training and test set, a leave one-out cross-validation was implemented, such that data from all but one block was acted as <inline-formula><mml:math id="inf14"><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> to estimate <inline-formula><mml:math id="inf15"><mml:mover accent="true"><mml:mrow><mml:mi>W</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> , while data from the remaining block was acted as <inline-formula><mml:math id="inf16"><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> to estimate <inline-formula><mml:math id="inf17"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> . This procedure ensures the independence between training set and testing set. The entire analysis was repeated until all blocks could be held out as a test set. The observed channel responses <inline-formula><mml:math id="inf18"><mml:msub><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>C</mml:mi></mml:mrow><mml:mo>^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub></mml:math></inline-formula> were then circularly shifted to a common center (0°) in reference to the location/color-of-interest in each trial, and averaged across trials for further analysis.</p><p>Consistent with previous studies (<xref ref-type="bibr" rid="bib28">Foster et al., 2017</xref>; <xref ref-type="bibr" rid="bib36">Huang et al., 2021</xref>), decoding performance was characterized by the slope of the estimated channel responses at each time by flipping the reconstructed curves across the center, averaging both sides, and performing linear regression. We further smoothed the slope time courses with a Gaussian kernel (s.d.=40 ms) (<xref ref-type="bibr" rid="bib36">Huang et al., 2021</xref>; <xref ref-type="bibr" rid="bib67">Wolff et al., 2017</xref>).</p><p>Note that considering the color wheel is always oriented the same way for each participant, it is possible that participants tend to map colors to locations and remembered in a location code. However, this possibility shouldn’t affect the interpretation of the comparison between AT and MAT conditions. In fact, the underlying logic of the current design is based on the facts that thinking spatially is intuitive and color and location sequences can be spontaneously combined or integrated based on the shared common trajectory structure. In other words, decoding of color sequences could be understood as neural representation of a series of corresponding locations along the ring that are independent of the physical locations of the items.</p></sec><sec id="s4-3-3"><title>Forward sequence measure</title><p>Following previous studies (<xref ref-type="bibr" rid="bib35">Huang et al., 2018</xref>; <xref ref-type="bibr" rid="bib37">Kurth-Nelson et al., 2016</xref>; <xref ref-type="bibr" rid="bib41">Liu et al., 2019</xref>), cross-correlation was applied to examine whether the color reactivation pattern tended to follow certain order, e.g., a forward (first-secondthird) or reverse order (third-second -first). If it was a forward sequence, the decoded performance of the first item at time T should be correlated with the decoding performance of second item at time T + Δt, and correlated with the decoding performance of third item at time T+2*Δt, where Δt defines a lag between neural representations of two consecutive items. We first calculated the cross-correlation between the first and second items and between second and third items at each time lag. Then we subtracted the reverse direction (second-first; 3<sup>rd</sup>-second) from the forward direction (first-second; second-third) respectively at each time-lag, in order to exclude the autocorrelation effect (<xref ref-type="bibr" rid="bib37">Kurth-Nelson et al., 2016</xref>). The resulting cross-correlation time courses were then averaged to determine the time lag for two consecutive items, here, the time point of the peak of the averaged cross-correlation time course. As mentioned above, for a forward replay pattern, at time lag Δt, we would expect to observe significant transition from the first to second items, and from the second to third items, while nonsignificant transition/correlation for the rest pairs, characterized by a theoretical forward transition pattern in <xref ref-type="fig" rid="fig4">Figure 4E</xref> (left panel). Meanwhile, the actual cross-correlation matrix can be estimated by computing the correlation coefficients for every pair (first-firstfirst-second, first-third; second-first, second-second, second-third; third-first, third-second, third-third) at the defined time lag (<xref ref-type="fig" rid="fig4">Figure 4D</xref>). Finally, we quantified the similarity between the observed transition pattern and theoretical forward transition pattern.</p></sec><sec id="s4-3-4"><title>Time-resolved trajectory decoding</title><p>We implemented a linear support vector machine (SVM) to decode trajectory distance. Considering there were eight possible distances between every two items, i.e., ±160°, ±120°, ±80°, ±40° (chance level is 1/8), an eight-way decoder (One-VS-rest multiclass classifier) was used to decode trajectory. A fivefold cross-validation scheme was used, and the classification accuracy was averaged across the folds. We repeated this process 50 times with each containing a new random partition of data into fivefolds, and then computed their mean accuracy. Note that color and location sequences shared the same trajectory distances in AT condition, while MAT condition involved different trajectories for location and color. The trajectory decoding in MAT condition was based on the trajectory distance in location domain, considering location information showed much stronger representation than color information (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Same decoding approach was then employed on alpha band power during maintaining period. Here, alpha-band (8–12 Hz) power time courses was extracted by conducting a time-frequency analysis using Morlet wavelets with a width of seven cycles (Fieldtrip toolbox).</p></sec></sec><sec id="s4-4"><title>Statistical analysis</title><p>To determine statistical significance of decoding performance time courses, we performed cluster-based permutation test (FieldTrip, cluster-based permutation test, 1000 permutations) (<xref ref-type="bibr" rid="bib44">Maris and Oostenveld, 2007</xref>). We first identified clusters of contiguous significant time points (p&lt;0.05 or p&lt;0.001(during encoding period), two-tailed) from the calculated statistics (one-sample t-test, against 0 (slope value of the reconstructed channel response) for location/color decoding, or against 0.125 (classifier chance level) for trajectory distance decoding), and cluster-level statistics was calculated by computing the size of the clusters. Next, a Monte Carlo randomization procedure was conducted to estimate the significance probabilities for each cluster. Specifically, 0 (for location/color decoding) or 0.125 (for trajectory decoding) with the same sample size was generated and shuffled with the original data 1000 times, and the cluster-level statistics were then calculated from the surrogate data to estimate the significance probabilities for each original cluster.</p><p>To determine statistical significance of cross-correlation coefficient (forward direction minus reverse direction), we performed a permutation test by shuffling color labels across participants 1000 times and followed the same procedure to calculate the cross-correlation time courses of the surrogate data, from which the 0.05 threshold level was estimated.</p></sec></sec></body><back><sec sec-type="additional-information" id="s5"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn><fn fn-type="COI-statement" id="conf2"><p>Reviewing editor, <italic>eLife</italic></p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Resources, Data curation, Software, Formal analysis, Validation, Investigation, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Resources, Supervision, Funding acquisition, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>This study received ethical approval from the Peking University Research Ethics Committee (reference number 2020-03-03). This study was carried out in accordance with the Declaration of Helsinki. All participants provided written informed consent prior to the start of the experiment.</p></fn></fn-group></sec><sec sec-type="supplementary-material" id="s6"><title>Additional files</title><supplementary-material id="mdar"><label>MDAR checklist</label><media xlink:href="elife-93158-mdarchecklist1-v1.docx" mimetype="application" mime-subtype="docx"/></supplementary-material></sec><sec sec-type="data-availability" id="s7"><title>Data availability</title><p>Behavioral data, EEG decoding results and associated code have been deposited at the Open Science Framework (<ext-link ext-link-type="uri" xlink:href="https://osf.io/pswxu/">https://osf.io/pswxu/</ext-link>).</p><p>The following dataset was generated:</p><p><element-citation publication-type="data" specific-use="isSupplementedBy" id="dataset1"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>Q</given-names></name><name><surname>Luo</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2024">2024</year><data-title>Shared structure facilitates working memory of multiple sequences</data-title><source>Open Science Framework</source><pub-id pub-id-type="accession" xlink:href="https://osf.io/pswxu/">pswxu</pub-id></element-citation></p></sec><ack id="ack"><title>Acknowledgements</title><p>This work was supported by the National Science and Technology Innovation STI2030-Major Project (2021ZD0204103 to HL), National Natural Science Foundation of China (31930052 to HL), and Humboldt Research Fellowship for Postdocs to QH. We thank Christian F Doeller and Muzhi Wang for their helpful comments.</p></ack><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aho</surname><given-names>K</given-names></name><name><surname>Roads</surname><given-names>BD</given-names></name><name><surname>Love</surname><given-names>BC</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>System alignment supports cross-domain learning and zero-shot generalisation</article-title><source>Cognition</source><volume>227</volume><elocation-id>105200</elocation-id><pub-id pub-id-type="doi">10.1016/j.cognition.2022.105200</pub-id><pub-id pub-id-type="pmid">35717766</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Al Roumi</surname><given-names>F</given-names></name><name><surname>Marti</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Amalric</surname><given-names>M</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Mental compression of spatial sequences in human working memory using numerical and geometrical primitives</article-title><source>Neuron</source><volume>109</volume><fpage>2627</fpage><lpage>2639</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.06.009</pub-id><pub-id pub-id-type="pmid">34228961</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Attneave</surname><given-names>F</given-names></name></person-group><year iso-8601-date="1954">1954</year><article-title>Some informational aspects of visual perception</article-title><source>Psychological Review</source><volume>61</volume><fpage>183</fpage><lpage>193</lpage><pub-id pub-id-type="doi">10.1037/h0054663</pub-id><pub-id pub-id-type="pmid">13167245</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Audrain</surname><given-names>S</given-names></name><name><surname>McAndrews</surname><given-names>MP</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Schemas provide a scaffold for neocortical integration of new memories over time</article-title><source>Nature Communications</source><volume>13</volume><elocation-id>5795</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-022-33517-0</pub-id><pub-id pub-id-type="pmid">36184668</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baddeley</surname><given-names>A</given-names></name></person-group><year iso-8601-date="2000">2000</year><article-title>The episodic buffer: A new component of working memory?</article-title><source>Trends in Cognitive Sciences</source><volume>4</volume><fpage>417</fpage><lpage>423</lpage><pub-id pub-id-type="doi">10.1016/S1364-6613(00)01538-2</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barry</surname><given-names>DN</given-names></name><name><surname>Love</surname><given-names>BC</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>A neural network account of memory replay and knowledge consolidation</article-title><source>Cerebral Cortex</source><volume>33</volume><fpage>83</fpage><lpage>95</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhac054</pub-id><pub-id pub-id-type="pmid">35213689</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Bartlett</surname><given-names>FC</given-names></name></person-group><year iso-8601-date="1932">1932</year><source>Remembering: A Study in Experimental and Social Psychology</source><publisher-name>Cambridge university press</publisher-name><pub-id pub-id-type="doi">10.1111/j.2044-8279.1933.tb02913.x</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bays</surname><given-names>PM</given-names></name><name><surname>Catalao</surname><given-names>RFG</given-names></name><name><surname>Husain</surname><given-names>M</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>The precision of visual working memory is set by allocation of a shared resource</article-title><source>Journal of Vision</source><volume>9</volume><elocation-id>7</elocation-id><pub-id pub-id-type="doi">10.1167/9.10.7</pub-id><pub-id pub-id-type="pmid">19810788</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Muller</surname><given-names>TH</given-names></name><name><surname>Whittington</surname><given-names>JCR</given-names></name><name><surname>Mark</surname><given-names>S</given-names></name><name><surname>Baram</surname><given-names>AB</given-names></name><name><surname>Stachenfeld</surname><given-names>KL</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>What is a cognitive map</article-title><source>Organizing Knowledge for Flexible Behavior. Neuron</source><volume>100</volume><fpage>490</fpage><lpage>509</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2018.10.002</pub-id><pub-id pub-id-type="pmid">30359611</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellmund</surname><given-names>JLS</given-names></name><name><surname>Gärdenfors</surname><given-names>P</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Navigating cognition: Spatial codes for human thinking</article-title><source>Science</source><volume>362</volume><elocation-id>eaat6766</elocation-id><pub-id pub-id-type="doi">10.1126/science.aat6766</pub-id><pub-id pub-id-type="pmid">30409861</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bengio</surname><given-names>Y</given-names></name><name><surname>Mesnil</surname><given-names>G</given-names></name><name><surname>Dauphin</surname><given-names>Y</given-names></name><name><surname>Rifai</surname><given-names>S</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Better mixing via deep representations</article-title><conf-name>International Conference on Machine Learning</conf-name><fpage>552</fpage><lpage>560</lpage></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brady</surname><given-names>TF</given-names></name><name><surname>Konkle</surname><given-names>T</given-names></name><name><surname>Alvarez</surname><given-names>GA</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Compression in visual working memory: using statistical regularities to form more efficient memory representations</article-title><source>Journal of Experimental Psychology. General</source><volume>138</volume><fpage>487</fpage><lpage>502</lpage><pub-id pub-id-type="doi">10.1037/a0016797</pub-id><pub-id pub-id-type="pmid">19883132</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brady</surname><given-names>TF</given-names></name><name><surname>Konkle</surname><given-names>T</given-names></name><name><surname>Alvarez</surname><given-names>GA</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A review of visual memory capacity: Beyond individual items and toward structured representations</article-title><source>Journal of Vision</source><volume>11</volume><elocation-id>4</elocation-id><pub-id pub-id-type="doi">10.1167/11.5.4</pub-id><pub-id pub-id-type="pmid">21617025</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brady</surname><given-names>TF</given-names></name><name><surname>Tenenbaum</surname><given-names>JB</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>A probabilistic model of visual working memory: Incorporating higher order regularities into working memory capacity estimates</article-title><source>Psychological Review</source><volume>120</volume><fpage>85</fpage><lpage>109</lpage><pub-id pub-id-type="doi">10.1037/a0030779</pub-id><pub-id pub-id-type="pmid">23230888</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brouwer</surname><given-names>GJ</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>Decoding and reconstructing color from responses in human visual cortex</article-title><source>The Journal of Neuroscience</source><volume>29</volume><fpage>13992</fpage><lpage>14003</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3577-09.2009</pub-id><pub-id pub-id-type="pmid">19890009</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brouwer</surname><given-names>GJ</given-names></name><name><surname>Heeger</surname><given-names>DJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>Cross-orientation suppression in human visual cortex</article-title><source>Journal of Neurophysiology</source><volume>106</volume><fpage>2108</fpage><lpage>2119</lpage><pub-id pub-id-type="doi">10.1152/jn.00540.2011</pub-id><pub-id pub-id-type="pmid">21775720</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Constantinescu</surname><given-names>AO</given-names></name><name><surname>O’Reilly</surname><given-names>JX</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Organizing conceptual knowledge in humans with a gridlike code</article-title><source>Science</source><volume>352</volume><fpage>1464</fpage><lpage>1468</lpage><pub-id pub-id-type="doi">10.1126/science.aaf0941</pub-id><pub-id pub-id-type="pmid">27313047</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cowan</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>The magical number 4 in short-term memory: A reconsideration of mental storage capacity</article-title><source>The Behavioral and Brain Sciences</source><volume>24</volume><fpage>87</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1017/s0140525x01003922</pub-id><pub-id pub-id-type="pmid">11515286</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Meyniel</surname><given-names>F</given-names></name><name><surname>Wacongne</surname><given-names>C</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name><name><surname>Pallier</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>The neural representation of sequences: From transition probabilities to algebraic patterns and linguistic Trees</article-title><source>Neuron</source><volume>88</volume><fpage>2</fpage><lpage>19</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.09.019</pub-id><pub-id pub-id-type="pmid">26447569</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dekker</surname><given-names>RB</given-names></name><name><surname>Otto</surname><given-names>F</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Curriculum learning for human compositional generalization</article-title><source>PNAS</source><volume>119</volume><elocation-id>e2205582119</elocation-id><pub-id pub-id-type="doi">10.1073/pnas.2205582119</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>de Vries</surname><given-names>IEJ</given-names></name><name><surname>Slagter</surname><given-names>HA</given-names></name><name><surname>Olivers</surname><given-names>CNL</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Oscillatory control over representational states in working memory</article-title><source>Trends in Cognitive Sciences</source><volume>24</volume><fpage>150</fpage><lpage>162</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2019.11.006</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>S</given-names></name><name><surname>Cueva</surname><given-names>CJ</given-names></name><name><surname>Tsodyks</surname><given-names>M</given-names></name><name><surname>Qian</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Visual perception as retrospective Bayesian decoding from high- to low-level features</article-title><source>PNAS</source><volume>114</volume><fpage>E9115</fpage><lpage>E9124</lpage><pub-id pub-id-type="doi">10.1073/pnas.1706906114</pub-id><pub-id pub-id-type="pmid">29073108</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Doeller</surname><given-names>CF</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Evidence for grid cells in a human memory network</article-title><source>Nature</source><volume>463</volume><fpage>657</fpage><lpage>661</lpage><pub-id pub-id-type="doi">10.1038/nature08704</pub-id><pub-id pub-id-type="pmid">20090680</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ester</surname><given-names>EF</given-names></name><name><surname>Sprague</surname><given-names>TC</given-names></name><name><surname>Serences</surname><given-names>JT</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Parietal and frontal cortex encode stimulus-specific mnemonic representations during visual working memory</article-title><source>Neuron</source><volume>87</volume><fpage>893</fpage><lpage>905</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2015.07.013</pub-id><pub-id pub-id-type="pmid">26257053</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farzanfar</surname><given-names>D</given-names></name><name><surname>Spiers</surname><given-names>HJ</given-names></name><name><surname>Moscovitch</surname><given-names>M</given-names></name><name><surname>Rosenbaum</surname><given-names>RS</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>From cognitive maps to spatial schemas</article-title><source>Nature Reviews. Neuroscience</source><volume>24</volume><fpage>63</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1038/s41583-022-00655-9</pub-id><pub-id pub-id-type="pmid">36414839</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>DJ</given-names></name><name><surname>Wilson</surname><given-names>MA</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>Reverse replay of behavioural sequences in hippocampal place cells during the awake state</article-title><source>Nature</source><volume>440</volume><fpage>680</fpage><lpage>683</lpage><pub-id pub-id-type="doi">10.1038/nature04587</pub-id><pub-id pub-id-type="pmid">16474382</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>JJ</given-names></name><name><surname>Sutterer</surname><given-names>DW</given-names></name><name><surname>Serences</surname><given-names>JT</given-names></name><name><surname>Vogel</surname><given-names>EK</given-names></name><name><surname>Awh</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>The topography of alpha-band activity tracks the content of spatial working memory</article-title><source>Journal of Neurophysiology</source><volume>115</volume><fpage>168</fpage><lpage>177</lpage><pub-id pub-id-type="doi">10.1152/jn.00860.2015</pub-id><pub-id pub-id-type="pmid">26467522</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Foster</surname><given-names>JJ</given-names></name><name><surname>Bsales</surname><given-names>EM</given-names></name><name><surname>Jaffe</surname><given-names>RJ</given-names></name><name><surname>Awh</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Alpha-band activity reveals spontaneous representations of spatial position in visual working memory</article-title><source>Current Biology</source><volume>27</volume><fpage>3216</fpage><lpage>3223</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.09.031</pub-id><pub-id pub-id-type="pmid">29033335</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fukuda</surname><given-names>K</given-names></name><name><surname>Kang</surname><given-names>MS</given-names></name><name><surname>Woodman</surname><given-names>GF</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Distinct neural mechanisms for spatially lateralized and spatially global visual working memory representations</article-title><source>Journal of Neurophysiology</source><volume>116</volume><fpage>1715</fpage><lpage>1727</lpage><pub-id pub-id-type="doi">10.1152/jn.00991.2015</pub-id><pub-id pub-id-type="pmid">27440249</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garvert</surname><given-names>MM</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>A map of abstract relational knowledge in the human hippocampal-entorhinal cortex</article-title><source>eLife</source><volume>6</volume><elocation-id>e17086</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.17086</pub-id><pub-id pub-id-type="pmid">28448253</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Gathercole</surname><given-names>SE</given-names></name><name><surname>Baddeley</surname><given-names>AD</given-names></name></person-group><year iso-8601-date="2014">2014</year><source>Working Memory and Language</source><publisher-name>Psychology Press</publisher-name><pub-id pub-id-type="doi">10.4324/9781315804682</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gilboa</surname><given-names>A</given-names></name><name><surname>Marlatte</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Neurobiology of schemas and schema-mediated memory</article-title><source>Trends in Cognitive Sciences</source><volume>21</volume><fpage>618</fpage><lpage>631</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2017.04.013</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldstone</surname><given-names>RL</given-names></name><name><surname>Medin</surname><given-names>DL</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Time course of comparison</article-title><source>Journal of Experimental Psychology</source><volume>20</volume><fpage>29</fpage><lpage>50</lpage><pub-id pub-id-type="doi">10.1037//0278-7393.20.1.29</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hafting</surname><given-names>T</given-names></name><name><surname>Fyhn</surname><given-names>M</given-names></name><name><surname>Molden</surname><given-names>S</given-names></name><name><surname>Moser</surname><given-names>MB</given-names></name><name><surname>Moser</surname><given-names>EI</given-names></name></person-group><year iso-8601-date="2005">2005</year><article-title>Microstructure of a spatial map in the entorhinal cortex</article-title><source>Nature</source><volume>436</volume><fpage>801</fpage><lpage>806</lpage><pub-id pub-id-type="doi">10.1038/nature03721</pub-id><pub-id pub-id-type="pmid">15965463</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>Q</given-names></name><name><surname>Jia</surname><given-names>J</given-names></name><name><surname>Han</surname><given-names>Q</given-names></name><name><surname>Luo</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Fast-backward replay of sequentially memorized items in humans</article-title><source>eLife</source><volume>7</volume><elocation-id>e35164</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.35164</pub-id><pub-id pub-id-type="pmid">30334735</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>Q</given-names></name><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>Luo</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Sequence structure organizes items in varied latent states of working memory neural network</article-title><source>eLife</source><volume>10</volume><elocation-id>e67589</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.67589</pub-id><pub-id pub-id-type="pmid">34308840</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Economides</surname><given-names>M</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Dayan</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Fast sequences of non-spatial state representations in humans</article-title><source>Neuron</source><volume>91</volume><fpage>194</fpage><lpage>204</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.05.028</pub-id><pub-id pub-id-type="pmid">27321922</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Behrens</surname><given-names>T</given-names></name><name><surname>Wayne</surname><given-names>G</given-names></name><name><surname>Miller</surname><given-names>K</given-names></name><name><surname>Luettgau</surname><given-names>L</given-names></name><name><surname>Dolan</surname><given-names>R</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Schwartenbeck</surname><given-names>P</given-names></name></person-group><year iso-8601-date="2023">2023</year><article-title>Replay and compositional computation</article-title><source>Neuron</source><volume>111</volume><fpage>454</fpage><lpage>469</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2022.12.028</pub-id><pub-id pub-id-type="pmid">36640765</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Huang</surname><given-names>Q</given-names></name><name><surname>Han</surname><given-names>Q</given-names></name><name><surname>Mi</surname><given-names>Y</given-names></name><name><surname>Luo</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2021">2021a</year><article-title>Temporally coherent perturbation of neural dynamics during retention alters human multi-item working memory</article-title><source>Progress in Neurobiology</source><volume>201</volume><elocation-id>102023</elocation-id><pub-id pub-id-type="doi">10.1016/j.pneurobio.2021.102023</pub-id><pub-id pub-id-type="pmid">33617918</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>HH</given-names></name><name><surname>Sprague</surname><given-names>TC</given-names></name><name><surname>Yoo</surname><given-names>AH</given-names></name><name><surname>Ma</surname><given-names>WJ</given-names></name><name><surname>Curtis</surname><given-names>CE</given-names></name></person-group><year iso-8601-date="2021">2021b</year><article-title>Joint representation of working memory and uncertainty in human cortex</article-title><source>Neuron</source><volume>109</volume><fpage>3699</fpage><lpage>3712</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.08.022</pub-id><pub-id pub-id-type="pmid">34525327</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Human replay spontaneously reorganizes experience</article-title><source>Cell</source><volume>178</volume><fpage>640</fpage><lpage>652</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2019.06.012</pub-id><pub-id pub-id-type="pmid">31280961</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name><name><surname>Higgins</surname><given-names>C</given-names></name><name><surname>Penagos</surname><given-names>H</given-names></name><name><surname>Woolrich</surname><given-names>MW</given-names></name><name><surname>Ólafsdóttir</surname><given-names>HF</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Kurth-Nelson</surname><given-names>Z</given-names></name><name><surname>Behrens</surname><given-names>TE</given-names></name></person-group><year iso-8601-date="2021">2021a</year><article-title>Temporally delayed linear modelling (TDLM) measures replay in both animals and humans</article-title><source>eLife</source><volume>10</volume><elocation-id>e66917</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.66917</pub-id><pub-id pub-id-type="pmid">34096501</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Mattar</surname><given-names>MG</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Daw</surname><given-names>ND</given-names></name><name><surname>Dolan</surname><given-names>RJ</given-names></name></person-group><year iso-8601-date="2021">2021b</year><article-title>Experience replay is associated with efficient nonlocal learning</article-title><source>Science</source><volume>372</volume><elocation-id>6544</elocation-id><pub-id pub-id-type="doi">10.1126/science.abf1357</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Oostenveld</surname><given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Nonparametric statistical testing of EEG- and MEG-data</article-title><source>Journal of Neuroscience Methods</source><volume>164</volume><fpage>177</fpage><lpage>190</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2007.03.024</pub-id><pub-id pub-id-type="pmid">17517438</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mathy</surname><given-names>F</given-names></name><name><surname>Feldman</surname><given-names>J</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>What’s magic about magic numbers? Chunking and data compression in short-term memory</article-title><source>Cognition</source><volume>122</volume><fpage>346</fpage><lpage>362</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2011.11.003</pub-id><pub-id pub-id-type="pmid">22176752</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nieh</surname><given-names>EH</given-names></name><name><surname>Schottdorf</surname><given-names>M</given-names></name><name><surname>Freeman</surname><given-names>NW</given-names></name><name><surname>Low</surname><given-names>RJ</given-names></name><name><surname>Lewallen</surname><given-names>S</given-names></name><name><surname>Koay</surname><given-names>SA</given-names></name><name><surname>Pinto</surname><given-names>L</given-names></name><name><surname>Gauthier</surname><given-names>JL</given-names></name><name><surname>Brody</surname><given-names>CD</given-names></name><name><surname>Tank</surname><given-names>DW</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Geometry of abstract learned knowledge in the hippocampus</article-title><source>Nature</source><volume>595</volume><fpage>80</fpage><lpage>84</lpage><pub-id pub-id-type="doi">10.1038/s41586-021-03652-7</pub-id><pub-id pub-id-type="pmid">34135512</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>O’keefe</surname><given-names>J</given-names></name><name><surname>Nadel</surname><given-names>L</given-names></name></person-group><year iso-8601-date="1978">1978</year><source>The Hippocampus as a Cognitive Map</source><publisher-loc>Oxford</publisher-loc><publisher-name>Clarendon Press</publisher-name><pub-id pub-id-type="doi">10.1016/j.neuron.2015.06.013</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ólafsdóttir</surname><given-names>HF</given-names></name><name><surname>Bush</surname><given-names>D</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>The role of hippocampal replay in memory and planning</article-title><source>Current Biology</source><volume>28</volume><fpage>R37</fpage><lpage>R50</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2017.10.073</pub-id><pub-id pub-id-type="pmid">29316421</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oostenveld</surname><given-names>R</given-names></name><name><surname>Fries</surname><given-names>P</given-names></name><name><surname>Maris</surname><given-names>E</given-names></name><name><surname>Schoffelen</surname><given-names>JM</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>FieldTrip: Open source software for advanced analysis of MEG, EEG, and invasive electrophysiological data</article-title><source>Computational Intelligence and Neuroscience</source><volume>2011</volume><elocation-id>156869</elocation-id><pub-id pub-id-type="doi">10.1155/2011/156869</pub-id><pub-id pub-id-type="pmid">21253357</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>SA</given-names></name><name><surname>Miller</surname><given-names>DS</given-names></name><name><surname>Boorman</surname><given-names>ED</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Inferences on a multidimensional social hierarchy use a grid-like code</article-title><source>Nature Neuroscience</source><volume>24</volume><fpage>1292</fpage><lpage>1301</lpage><pub-id pub-id-type="doi">10.1038/s41593-021-00916-3</pub-id><pub-id pub-id-type="pmid">34465915</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ren</surname><given-names>X</given-names></name><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>Luo</surname><given-names>H</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Dynamic emergence of relational structure network in human brains</article-title><source>Progress in Neurobiology</source><volume>219</volume><elocation-id>102373</elocation-id><pub-id pub-id-type="doi">10.1016/j.pneurobio.2022.102373</pub-id><pub-id pub-id-type="pmid">36370880</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roads</surname><given-names>BD</given-names></name><name><surname>Love</surname><given-names>BC</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Learning as the unsupervised alignment of conceptual systems</article-title><source>Nature Machine Intelligence</source><volume>2</volume><fpage>76</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1038/s42256-019-0132-2</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name><name><surname>Cordova</surname><given-names>NI</given-names></name><name><surname>Turk-Browne</surname><given-names>NB</given-names></name><name><surname>Botvinick</surname><given-names>MM</given-names></name></person-group><year iso-8601-date="2013">2013</year><article-title>Neural representations of events arise from temporal community structure</article-title><source>Nature Neuroscience</source><volume>16</volume><fpage>486</fpage><lpage>492</lpage><pub-id pub-id-type="doi">10.1038/nn.3331</pub-id><pub-id pub-id-type="pmid">23416451</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schapiro</surname><given-names>AC</given-names></name><name><surname>McDevitt</surname><given-names>EA</given-names></name><name><surname>Rogers</surname><given-names>TT</given-names></name><name><surname>Mednick</surname><given-names>SC</given-names></name><name><surname>Norman</surname><given-names>KA</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Human hippocampal replay during rest prioritizes weakly learned information and predicts memory performance</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>3920</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-06213-1</pub-id><pub-id pub-id-type="pmid">30254219</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schuck</surname><given-names>NW</given-names></name><name><surname>Cai</surname><given-names>MB</given-names></name><name><surname>Wilson</surname><given-names>RC</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>Human orbitofrontal cortex represents a cognitive map of state space</article-title><source>Neuron</source><volume>91</volume><fpage>1402</fpage><lpage>1412</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2016.08.019</pub-id><pub-id pub-id-type="pmid">27657452</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schuck</surname><given-names>NW</given-names></name><name><surname>Niv</surname><given-names>Y</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Sequential replay of nonspatial task states in the human hippocampus</article-title><source>Science</source><volume>364</volume><elocation-id>eaaw5181</elocation-id><pub-id pub-id-type="doi">10.1126/science.aaw5181</pub-id><pub-id pub-id-type="pmid">31249030</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheahan</surname><given-names>H</given-names></name><name><surname>Luyckx</surname><given-names>F</given-names></name><name><surname>Nelli</surname><given-names>S</given-names></name><name><surname>Teupe</surname><given-names>C</given-names></name><name><surname>Summerfield</surname><given-names>C</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Neural state space alignment for magnitude generalization in humans and recurrent networks</article-title><source>Neuron</source><volume>109</volume><fpage>1214</fpage><lpage>1226</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2021.02.004</pub-id><pub-id pub-id-type="pmid">33626322</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Skaggs</surname><given-names>WE</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1996">1996</year><article-title>Replay of neuronal firing sequences in rat hippocampus during sleep following spatial experience</article-title><source>Science</source><volume>271</volume><fpage>1870</fpage><lpage>1873</lpage><pub-id pub-id-type="doi">10.1126/science.271.5257.1870</pub-id><pub-id pub-id-type="pmid">8596957</pub-id></element-citation></ref><ref id="bib59"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Solomon</surname><given-names>EA</given-names></name><name><surname>Lega</surname><given-names>BC</given-names></name><name><surname>Sperling</surname><given-names>MR</given-names></name><name><surname>Kahana</surname><given-names>MJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Hippocampal theta codes for distances in semantic and temporal spaces</article-title><source>PNAS</source><volume>116</volume><fpage>24343</fpage><lpage>24352</lpage><pub-id pub-id-type="doi">10.1073/pnas.1906729116</pub-id></element-citation></ref><ref id="bib60"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sutterer</surname><given-names>DW</given-names></name><name><surname>Foster</surname><given-names>JJ</given-names></name><name><surname>Adam</surname><given-names>KCS</given-names></name><name><surname>Vogel</surname><given-names>EK</given-names></name><name><surname>Awh</surname><given-names>E</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Item-specific delay activity demonstrates concurrent storage of multiple active neural representations in working memory</article-title><source>PLOS Biology</source><volume>17</volume><elocation-id>e3000239</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3000239</pub-id><pub-id pub-id-type="pmid">31026274</pub-id></element-citation></ref><ref id="bib61"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Theves</surname><given-names>S</given-names></name><name><surname>Fernandez</surname><given-names>G</given-names></name><name><surname>Doeller</surname><given-names>CF</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>The hippocampus encodes distances in multidimensional feature space</article-title><source>Current Biology</source><volume>29</volume><fpage>1226</fpage><lpage>1231</lpage><pub-id pub-id-type="doi">10.1016/j.cub.2019.02.035</pub-id><pub-id pub-id-type="pmid">30905602</pub-id></element-citation></ref><ref id="bib62"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tolman</surname><given-names>EC</given-names></name></person-group><year iso-8601-date="1948">1948</year><article-title>Cognitive maps in rats and men</article-title><source>Psychological Review</source><volume>55</volume><fpage>189</fpage><lpage>208</lpage><pub-id pub-id-type="doi">10.1037/h0061626</pub-id><pub-id pub-id-type="pmid">18870876</pub-id></element-citation></ref><ref id="bib63"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tse</surname><given-names>D</given-names></name><name><surname>Langston</surname><given-names>RF</given-names></name><name><surname>Kakeyama</surname><given-names>M</given-names></name><name><surname>Bethus</surname><given-names>I</given-names></name><name><surname>Spooner</surname><given-names>PA</given-names></name><name><surname>Wood</surname><given-names>ER</given-names></name><name><surname>Witter</surname><given-names>MP</given-names></name><name><surname>Morris</surname><given-names>RGM</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Schemas and memory consolidation</article-title><source>Science</source><volume>316</volume><fpage>76</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.1126/science.1135935</pub-id><pub-id pub-id-type="pmid">17412951</pub-id></element-citation></ref><ref id="bib64"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van Kesteren</surname><given-names>MTR</given-names></name><name><surname>Fernández</surname><given-names>G</given-names></name><name><surname>Norris</surname><given-names>DG</given-names></name><name><surname>Hermans</surname><given-names>EJ</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Persistent schema-dependent hippocampal-neocortical connectivity during memory encoding and postencoding rest in humans</article-title><source>PNAS</source><volume>107</volume><fpage>7550</fpage><lpage>7555</lpage><pub-id pub-id-type="doi">10.1073/pnas.0914892107</pub-id></element-citation></ref><ref id="bib65"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Whittington</surname><given-names>JCR</given-names></name><name><surname>Muller</surname><given-names>TH</given-names></name><name><surname>Mark</surname><given-names>S</given-names></name><name><surname>Chen</surname><given-names>G</given-names></name><name><surname>Barry</surname><given-names>C</given-names></name><name><surname>Burgess</surname><given-names>N</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>The tolman-eichenbaum machine: unifying space and relational memory through generalization in the hippocampal formation</article-title><source>Cell</source><volume>183</volume><fpage>1249</fpage><lpage>1263</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2020.10.024</pub-id><pub-id pub-id-type="pmid">33181068</pub-id></element-citation></ref><ref id="bib66"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilson</surname><given-names>MA</given-names></name><name><surname>McNaughton</surname><given-names>BL</given-names></name></person-group><year iso-8601-date="1994">1994</year><article-title>Reactivation of hippocampal ensemble memories during sleep</article-title><source>Science</source><volume>265</volume><fpage>676</fpage><lpage>679</lpage><pub-id pub-id-type="doi">10.1126/science.8036517</pub-id><pub-id pub-id-type="pmid">8036517</pub-id></element-citation></ref><ref id="bib67"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolff</surname><given-names>MJ</given-names></name><name><surname>Jochim</surname><given-names>J</given-names></name><name><surname>Akyürek</surname><given-names>EG</given-names></name><name><surname>Stokes</surname><given-names>MG</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Dynamic hidden states underlying working-memory-guided behavior</article-title><source>Nature Neuroscience</source><volume>20</volume><fpage>864</fpage><lpage>871</lpage><pub-id pub-id-type="doi">10.1038/nn.4546</pub-id><pub-id pub-id-type="pmid">28414333</pub-id></element-citation></ref><ref id="bib68"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wu</surname><given-names>CM</given-names></name><name><surname>Schulz</surname><given-names>E</given-names></name><name><surname>Garvert</surname><given-names>MM</given-names></name><name><surname>Meder</surname><given-names>B</given-names></name><name><surname>Schuck</surname><given-names>NW</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Similarities and differences in spatial and non-spatial cognitive maps</article-title><source>PLOS Computational Biology</source><volume>16</volume><elocation-id>e1008149</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1008149</pub-id><pub-id pub-id-type="pmid">32903264</pub-id></element-citation></ref><ref id="bib69"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yu</surname><given-names>Q</given-names></name><name><surname>Teng</surname><given-names>C</given-names></name><name><surname>Postle</surname><given-names>BR</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Different states of priority recruit different neural representations in visual working memory</article-title><source>PLOS Biology</source><volume>18</volume><elocation-id>e3000769</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.3000769</pub-id><pub-id pub-id-type="pmid">32598358</pub-id></element-citation></ref><ref id="bib70"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>Fell</surname><given-names>J</given-names></name><name><surname>Axmacher</surname><given-names>N</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Electrophysiological mechanisms of human memory consolidation</article-title><source>Nature Communications</source><volume>9</volume><elocation-id>4103</elocation-id><pub-id pub-id-type="doi">10.1038/s41467-018-06553-y</pub-id><pub-id pub-id-type="pmid">30291240</pub-id></element-citation></ref><ref id="bib71"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>H</given-names></name><name><surname>Zhen</surname><given-names>Y</given-names></name><name><surname>Yu</surname><given-names>S</given-names></name><name><surname>Long</surname><given-names>T</given-names></name><name><surname>Zhang</surname><given-names>B</given-names></name><name><surname>Jiang</surname><given-names>X</given-names></name><name><surname>Li</surname><given-names>J</given-names></name><name><surname>Fang</surname><given-names>W</given-names></name><name><surname>Sigman</surname><given-names>M</given-names></name><name><surname>Dehaene</surname><given-names>S</given-names></name><name><surname>Wang</surname><given-names>L</given-names></name></person-group><year iso-8601-date="2022">2022</year><article-title>Working memory for spatial sequences: developmental and evolutionary factors in encoding ordinal and relational structures</article-title><source>The Journal of Neuroscience</source><volume>42</volume><fpage>850</fpage><lpage>864</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.0603-21.2021</pub-id><pub-id pub-id-type="pmid">34862186</pub-id></element-citation></ref><ref id="bib72"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>J</given-names></name><name><surname>Jia</surname><given-names>C</given-names></name><name><surname>Montesinos-Cartagena</surname><given-names>M</given-names></name><name><surname>Gardner</surname><given-names>MPH</given-names></name><name><surname>Zong</surname><given-names>W</given-names></name><name><surname>Schoenbaum</surname><given-names>G</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Evolving schema representations in orbitofrontal ensembles during learning</article-title><source>Nature</source><volume>590</volume><fpage>606</fpage><lpage>611</lpage><pub-id pub-id-type="doi">10.1038/s41586-020-03061-2</pub-id><pub-id pub-id-type="pmid">33361819</pub-id></element-citation></ref></ref-list></back><sub-article article-type="editor-report" id="sa0"><front-stub><article-id pub-id-type="doi">10.7554/eLife.93158.3.sa0</article-id><title-group><article-title>eLife assessment</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Peelen</surname><given-names>Marius V</given-names></name><role specific-use="editor">Reviewing Editor</role><aff><institution>Radboud University Nijmegen</institution><country>Netherlands</country></aff></contrib></contrib-group><kwd-group kwd-group-type="evidence-strength"><kwd>Solid</kwd></kwd-group><kwd-group kwd-group-type="claim-importance"><kwd>Valuable</kwd></kwd-group></front-stub><body><p>This <bold>valuable</bold> study uses a novel experimental design to elegantly demonstrate how we exploit stimulus structure to overcome working memory capacity limits. The presented behavioural and neural evidence are <bold>solid</bold> and in line with the proposed information compression mechanism. This study will be of interest to cognitive neuroscientists studying structure learning and memory.</p></body></sub-article><sub-article article-type="referee-report" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.93158.3.sa1</article-id><title-group><article-title>Reviewer #1 (Public Review):</article-title></title-group><contrib-group><contrib contrib-type="author"><anonymous/><role specific-use="referee">Reviewer</role></contrib></contrib-group></front-stub><body><p>Summary:</p><p>Huang and Luo investigated whether regularities between stimulus features can be exploited to facilitate the encoding of each set of stimuli in visual working memory, improving performance. They recorded both behavioural and neural (EEG) data from human participants during a sequential delayed response task involving three items with two properties: location and colour. In the key condition ('aligned trajectory'), the distance between locations of successively presented stimuli was identical to their 'distance' in colour space, permitting a compression strategy of encoding only the location and colour of the first stimulus and the relative distance of the second and third stimulus (as opposed to remembering 3 locations and 3 colours, this would only require remembering 1 location, 1 colour, and 2 distances). Participants recalled the location and colour of each item after a delay.</p><p>Consistent with the compression account, participants' location and colour recall errors were correlated and overall lower compared to a non-compressible condition ('misaligned trajectory'). Multivariate analysis of the neural data permitted decoding of the locations and colours during encoding. Crucially, the relative distance could also be decoded - a necessary ingredient for the compression strategy.</p><p>Strengths:</p><p>The main strength of this study is a novel experimental design that elegantly demonstrates how we exploit stimulus structure to overcome working memory capacity limits. The behavioural results are robust and support the main hypothesis of compressed encoding across a number of analyses. The simple and well-controlled design is suited to neuroimaging studies and paves the way for investigating the neural basis of how environmental structure is detected and represented in memory. Prior studies on this topic have primarily studied behaviour only (e.g., Brady &amp; Tenenbaum, 2013).</p><p>Weaknesses:</p><p>The main weakness of the study is that the EEG results could make a clearer case for compression. There is some evidence that distance decoding is present in alpha-band activity in the maintenance delay, but the strongest evidence for this occurs only briefly in the late encoding phase (the re-activation of decoding of the distance between items 1 and 2, Fig. 5A). The link to behaviour (Fig. 5D) seems fairly weak and based on a potentially circular analysis. During location recall, colour decoding re-emerges and is reactivated in sequence, but this finding is consistent both with compression-based and conventional rehearsal mechanisms. Nevertheless, the balance of evidence appears to favour the compression account.</p><p>Impact:</p><p>This important study elegantly demonstrates that the use of shared structure can improve capacity-limited visual working memory. The paradigm and approach explicitly link this field to recent findings on the role of replay in structure learning and will therefore be of interest to neuroscientists studying both topics.</p></body></sub-article><sub-article article-type="author-comment" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.93158.3.sa2</article-id><title-group><article-title>Author response</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Huang</surname><given-names>Qiaoli</given-names></name><role specific-use="author">Author</role><aff><institution>Peking University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib><contrib contrib-type="author"><name><surname>Luo</surname><given-names>Huan</given-names></name><role specific-use="author">Author</role><aff><institution>Peking University</institution><addr-line><named-content content-type="city">Beijing</named-content></addr-line><country>China</country></aff></contrib></contrib-group></front-stub><body><p>The following is the authors’ response to the original reviews.</p><disp-quote content-type="editor-comment"><p><bold>eLife assessment</bold></p><p>This valuable study uses a novel experimental design to elegantly demonstrate how we exploit stimulus structure to overcome working memory capacity limits. While the behavioural evidence is convincing, the neural evidence is incomplete, as it only provides partial support for the proposed information compression mechanism. This study will be of interest to cognitive neuroscientists studying structure learning and memory.</p><p><bold>Public Reviews:</bold></p><p><bold>Reviewer #1 (Public Review):</bold></p><p>Summary:</p><p>Huang and Luo investigated whether regularities between stimulus features can be exploited to facilitate the encoding of each set of stimuli in visual working memory, improving performance. They recorded both behavioural and neural (EEG) data from human participants during a sequential delayed response task involving three items with two properties: location and colour. In the key condition ('aligned trajectory'), the distance between locations of successively presented stimuli was identical to their 'distance' in colour space, permitting a compression strategy of encoding only the location and colour of the first stimulus and the relative distance of the second and third stimulus (as opposed to remembering 3 locations and 3 colours, this would only require remembering 1 location, 1 colour, and 2 distances). Participants recalled the location and colour of each item after a delay.</p><p>Consistent with the compression account, participants' location and colour recall errors were correlated and were overall lower compared to a non-compressible condition ('misaligned trajectory'). Multivariate analysis of the neural data permitted decoding of the locations and colours during encoding. Crucially, the relative distance could also be decoded - a necessary ingredient for the compression strategy.</p><p>Strengths:</p><p>The main strength of this study is a novel experimental design that elegantly demonstrates how we exploit stimulus structure to overcome working memory capacity limits. The behavioural results are robust and support the main hypothesis of compressed encoding across a number of analyses. The simple and well-controlled design is suited to neuroimaging studies and paves the way for investigating the neural basis of how environmental structure is detected and represented in memory. Prior studies on this topic have primarily studied behaviour only (e.g., Brady &amp; Tenenbaum, 2013).</p></disp-quote><p>Thanks for the positive comments and excellent summary.</p><disp-quote content-type="editor-comment"><p>Weaknesses:</p><p>The main weakness of the study is that the EEG results do not make a clear case for compression or demonstrate its neural basis. If the main aim of this strategy is to improve memory maintenance, it seems that it should be employed during the encoding phase. From then on, the neural representation in memory should be in the compressed format. The only positive evidence for this occurs in the late encoding phase (the re-activation of decoding of the distance between items 1 and 2, Fig. 5A), but the link to behaviour seems fairly weak (p=0.068).</p></disp-quote><p>Thanks for raising this important concern. The reviewer is correct that in principle subjects should employ the compression strategy during the encoding phase when sequence stimuli are presented, yet our results show that the 1-2 trajectory could only be decoded during the late encoding phase.</p><p>Meanwhile, subjects could not get enough information to form the compressed strategy for the location and color sequences until the appearance of the 3rd item. Specifically, based on the first two items, the 1st and 2nd item, they only learn whether the 1st-2nd trajectories are congruent between location and color features. However, they could not predict whether it would also apply to the incoming 2nd-3rd trajectory. This is exactly what we found in neural decoding results. The 1st-2nd trajectory could be decoded after the 2nd item presentation, and the 2nd-3rd trajectory appears after the 3rd item onset. Most critically, the 1st-2nd trajectory is reactivated after the 3rd item but only for alignment condition, implicating formation of the full-sequence compression strategy wherein the previously formed 1st-2nd trajectory is reactivated to be connected to the 2nd-3rd trajectory.</p><p>Regarding the difference between higher- and lower-correlation groups, previously we used the time window based on the overall 2nd-3rd neural reactivations, which might not be sensitive to reactivation strength. We now re-chose the time window based on the higher-correlation group (bootstrap test, p = 0.037, two sides).</p><p>Results have been updated (Figure 5; Results, Page 16). Interpretations about the formation of compression strategy during encoding phase have been added to Results (Page 15-16) and Discussion (Page 18).</p><disp-quote content-type="editor-comment"><p>Stronger evidence would be showing decoding of the compressed code during memory maintenance or recall, but this is not presented. On the contrary, during location recall (after the majority of memory maintenance is already over), colour decoding re-emerges, but in the un-compressed item-by-item code (Fig. 4B). The authors suggest that compression is consolidated at this point, but its utility at this late stage is not obvious.</p></disp-quote><p>Thank you for the important question we apologize for omitting previously - neural evidence for the compressive account.</p><p>The reason we did not perform neural decoding during maintenance is that previous EEG/MEG studies including our own failed to reveal robust and sustained time-resolved memory decoding during this period. This is posited to arise from “activity-silent” WM states, wherein memories are not necessarily retained in sustained firing but silently stored within connection weights of WM networks (Stokes, <italic>Trends Cogn. Sci.,</italic> 2015; Rose, <italic>Curr Dir Psychol Sci</italic>, 2020). Our previous work showed that by transiently perturbing the 'activity-silent' WM using a retrocue or neutral impulse, memories could be reactivated and robustly decoded from neural activities (Huang et al., eLife, 2021). However, due to the lack of transient events during retention in the current design, we do not expect robust decoding results during maintenance. As shown below (AB), this is indeed what we have observed, i.e., no robust neural decoding of trajectories during retention.</p><p>We further used alpha-band (8-11 Hz) neural activities, which have been shown to carry WM information (de Vries et al., Trends Cogn. Sci, 2020; Foster et al., Curr. Biol, 2016; Fukuda et al., J. Neurophysiol, 2016; Sutterer et al., PLOS Biol., 2019) to perform decoding analysis of compression trajectories during maintenance. As shown below, the alpha-band decoding results are indeed stronger than raw activities. Importantly, as shown below (CD), the aligned condition indeed showed significant and long-lasting decoding of compression trajectories (1st-2nd, 2nd-3rd) during retention, while the misaligned condition only showed decoding at the beginning (GH), which might be due to the non-specific offset response of the 3rd item. The results, although not as clear as those during encoding and recalling periods, support the reviewer’s hypothesis that the compressive strategy, if exploited, would be demonstrated during both encoding and maintenance periods. New results and related discussion have been added (Page 16, Supplementary Figure 4).</p><p>With regards to the observed item-by-item color replay during location recall, the reviewer was concerned that this was not consistent with the compressive account, given the lack of trajectory decoding.</p><p>First, item sequences stored in compressive formats need to be converted to sequences during serial recall. In other words, even though color and location sequences are retained in a compressive format (i.e., common 1st-2nd, 2nd-3rd trajectories) throughout the encoding and retention phases, they should be transferred to two sequences as outputs. This is exactly why we performed decoding analysis on individual color and location items rather than trajectories.</p><p>Second and most importantly, we observed serial replay of color sequences when recalling locations. In our view, these results constitute strong evidence for common structure, since the spontaneous color replay during location recall for aligned condition highlights the close bound between color and location sequences stored in WM. In fact, item-by-item serial replay has been well acknowledged as a critical neural index of cognitive maps, not only for spatial navigation but also for higher-order tasks (e.g., Liu et al., Cell, 2019; Liu et al., Science, 2021). Therefore, spontaneous color sequence replay during location sequence recall supports their shared underlying cognitive map.</p><p>Finally, spontaneous serial replay is also correlated with the reactivation of compressive trajectories during encoding (Supplementary Figure 3). This further indicates that serial replay during recalling is associated with memory reorganization formed during encoding.</p><p>Taken together, we posit that memories need to be converted to sequences as outputs, which leads to serial reactivations during recalling. Importantly, the observed spontaneous replay of color sequences for the aligned condition provides strong evidence supporting the associations between color and location sequences in WM.</p><p>We have now added relevant interpretations and discussions (Page 11&amp;13).</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Public Review):</bold></p><p>Summary:</p><p>In this study, the authors wanted to test if using a shared relational structure by a sequence of colors in locations can be leveraged to reorganize and compress information.</p><p>Strength:</p><p>They applied machine learning to EEG data to decode the neural mechanism of reinstatement of visual stimuli at recall. They were able to show that when the location of colors is congruent with the semantically expected location (for example, green is closer to blue-green than purple) the related color information is reinstated at the probed location. This reinstatement was not present when the location and color were not semantically congruent (meaning that x displacement in color ring location did not displace colors in the color space to the same extent) and semantic knowledge of color relationship could not be used for reducing the working memory load or to benefit encoding and retrieval in short term memory.</p><p>Weakness:</p><p>The experiment and results did not address any reorganization of information or neural mechanism of working memory (that would be during the gap between encoding and retrieval).</p></disp-quote><p>We apologize for not presenting clear neural evidence for memory reorganization, particularly neural decoding during WM maintenance and retrieval, in the previous version. As below, we explain why the findings provide converging neural evidence for WM reorganization based on a shared cognitive map.</p><p>First, during the encoding phase when location and color sequences are serially presented, our results reveal reactivation of the 1st-2nd trajectories upon the onset of the 3rd item when location and color sequences are aligned with each other. The reactivation of 1st-2nd trajectory right after the emergence of 2nd-3rd trajectory for aligned but not for misaligned sequences strongly supports WM reorganization, since only stimulus sequences that could be compressed based on shared trajectories (aligned condition) show the co-occurrence of 1st-2nd and 2nd-3rd trajectories. Moreover, the relevance of 1st-2nd reactivation to behavioral measurements of color-location reorganization (i.e., behavioral trajectory correlation, Figure 5D) further indicates its link to WM reorganization.</p><p>Second, the reason we originally did not perform neural decoding during maintenance is that previous EEG/MEG studies including our own failed to reveal robust and sustained time-resolved memory decoding during this period. This is posited to arise from “activity-silent” WM states, wherein memories are not necessarily retained in sustained firing but silently stored within connection weights of WM networks (Stokes, <italic>Trends Cogn. Sci.,</italic> 2015; Wolff et al., Nat. Neurosci, 2017; Rose et al., <italic>Curr Dir Psychol Sci</italic>, 2020). Our previous work showed that by transiently perturbing the 'activity-silent' WM using a retrocue or neutral impulse, memories could be reactivated and robustly decoded from neural activities (Huang et al., eLife, 2021). However, due to the lack of transient events during retention in the current design, we do not expect robust decoding results during maintenance. As shown in Supplementary Figure 4(AB), this is indeed what we have observed, i.e., no robust neural decoding of trajectories during retention.</p><p>We then used alpha-band (8-11 Hz) neural activities, which have been found to carry WM information (de Vries et al., Trends Cogn. Sci, 2020; Foster et al., Curr. Biol, 2016; Fukuda et al., J. Neurophysiol, 2016; Sutterer et al., PLOS Biol., 2019) to perform decoding analysis of compression trajectories during maintenance. As shown below, the alpha-band decoding results are indeed stronger than raw activities. Importantly, as shown in Supplementary Figure 4(CD), the aligned condition indeed showed significant and long-lasting decoding of compression trajectories (1st-2nd, 2nd-3rd) during retention, while the misaligned condition only showed decoding at the beginning (GH), which might be due to the non-specific offset response of the 3rd item. The results, although not as clear as those during encoding and recalling periods, thus also support WM reorganization.</p><p>Finally, during the recalling period, we observed automatic serial replay of color sequences when recalling locations. In our view, these results constitute strong evidence for common structure, since the spontaneous color replay during location recall for aligned condition highlights the close bound between color and location sequences stored in WM. In fact, item-by-item serial replay has been well acknowledged as a critical neural index of cognitive maps, not only for spatial navigation but also for higher-order tasks (e.g., Liu et al., Cell, 2019; Liu et al., Science, 2021). Therefore, spontaneous replay of color sequence during location recall supports their shared underlying cognitive map. Moreover, the spontaneous serial replay is correlated with the reactivation of compressive trajectories during encoding (Supplementary Figure 3). This further indicates that serial replay during recalling is associated with memory reorganization formed during encoding.</p><p>Taken together, we have added updated results about the maintenance period (Page 16, Supplementary Figure 4) and included clarifications and interpretations about why the findings during the encoding and retrieval periods support the WM reorganization view (Page 15-16).</p><disp-quote content-type="editor-comment"><p>There was also a lack of evidence to rule out that the current observation can be addressed by schematic abstraction instead of the utilization of a cognitive map.</p><p>The likely impact of the initial submission of the study would be in the utility of the methods that would be helpful for studying a sequence of stimuli at recall. The paper was discussed in a narrow and focused context, referring to limited studies on cognitive maps and replay. The bigger picture and long history of studying encoding and retrieval of schema-congruent and schema-incongruent events is not discussed.</p></disp-quote><p>We agree with the reviewer that cognitive map referred here could be understood as schematic abstraction. Cognitive map refers to the internal representation of spatial relations in a specific environment (Tolman 1948). Schematic abstraction denotes a more broad range of circumstances, whereby the gist or structure of multiple environments or episodes can be integrated (Bartlett, 1932; Farzanfar et al., <italic>Nat. Rev. Neurosci</italic>, 2023).</p><p>In other words, schema refers to highly abstract framework of prior knowledge that captures common patterns across related experiences, which does not necessarily occur in a spatial framework as cognitive maps do. Meanwhile, in the current design, we specifically manipulate the consistency of spatial trajectory distance between color and location sequences. Therefore, we would argue that cognitive map is a more conservative and appropriate term to frame our findings.</p><p>Relevant discussions have been added (Page 3&amp;19).</p><p>We apologize for the lack of more generalized discussion and have added schema-related literatures. Thanks for the suggestion.</p><disp-quote content-type="editor-comment"><p><bold>Recommendations for the authors:</bold></p><p><bold>Reviewer #1 (Recommendations For The Authors):</bold></p><p>(1) Do time-frequency-domain data (e.g., alpha-band power) in the delay provide evidence for delay-period decoding of trajectory lengths? This might strengthen the case for compression.</p></disp-quote><p>Thanks for the suggestion. We now performed decoding analysis of the delay period based on alpha-band power. As shown in supplementary figure 4, both the 1st-2nd and 2nd-3rd trajectories could be decoded for the aligned condition.</p><p>Added in supplementary figure 4 and Page 16.</p><disp-quote content-type="editor-comment"><p>(2) Do participants erroneously apply the compression strategy in the misaligned condition? This would not show up in the trajectory error correlation analysis, but might be visible when examining correlations between raw trajectory lengths.</p></disp-quote><p>Thanks for raising this interesting suggestion. To test the hypothesis, we chose a typical misaligned condition where 1st-2nd trajectory distances are same between location and color sequences, while the 2nd-3rd trajectory distances are different between the two features.</p><p>In this case, participants might exploit the compression strategy for the first two items and erroneously apply the strategy to the 3rd item. If so, we would expect better memory performance for the first two items but worse memory for the 3rd item, compared to the rest of misaligned trials. As shown below, the 1st-2nd aligned trials showed marginally significant higher performance than misaligned trials for the first two items (t(32) = 1.907, p = 0.066, Cohen’s d = 0.332) . Unfortunately, we did not find significant worse performance for the 3rd item between the two conditions (t(32) = -0.4847, p = 0.631, Cohen’s d = -0.084). We observed significant interactions between the last two items and the alignment effect (t(32) = 2.082, p = 0.045, Cohen’s d = 0.362), indicating a trend of applying wrong compression strategy to the 3nd item.</p><fig id="sa2fig1" position="float"><label>Author response image 1.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93158-sa2-fig1-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>(3a) Some more detail on some of the methods might help readers. For instance, did trajectories always move in a clockwise direction? Could the direction reverse on the third item? If not, did this induce a response bias? Could such a bias possibly account for the trajectory error correlations</p></disp-quote><p>Sorry for the unclear statement. For individual trial, both the color and location features of the three items are randomly selected from nine possible values without any constraint about the directions. That is to say, the trajectories can move in a clockwise or anticlockwise direction, and the direction can also reverse on the third item in some trials. Thus, we think the current design can actually help us to reduce the influence of response bias. Taking a step back, if trajectory error correlations are due to response bias, we should expect consistent significant correlation for all conditions, instead of only observing significant correlation for 1st-2nd and 2nd-3rd trajectories but not for 1st-3rd trajectory and only in aligned trajectory condition but not in misaligned condition. Therefore, we think the trajectory error correlations cannot be simply explained by response bias.</p><p>Details have been added (Page 23).</p><disp-quote content-type="editor-comment"><p>(3b) Is the colour wheel always oriented the same way for a participant? If so, given there are only nine colors, it seems possible that colors are mapped to locations and remembered in a location code instead. This does not seem to be a problem in principle for the behavioural findings, but might change the interpretation of what is being decoded from the EEG. If this is a possibility then this might be acknowledged.</p></disp-quote><p>The color wheel is always oriented the same way for each participant. We agree with the reviewer that it is possible that participants tend to map colors to locations and remembered in a location code. We don’t have sufficient evidence to rule out this possibility. One possible way could be running another experiment with varied color wheel during response period. Meanwhile, we would like to point out that the underlying logic of the current design is based on the facts that thinking spatially is intuitive and spatial metaphors like “location” and “distance” is commonly used to describe world, e.g., the well-known mental number line (Dehaene et al., <italic>JEP: General,</italic> 1993). Therefore, we expected participants to associate or integrate location and color maps based on trajectory distance.</p><p>The reviewer is correct that the color decoding would reflect spatial location rather than the genuine color feature. This is actually the point of the experimental design, whereby two irrelevant features could be possibly combined within a common cognitive map. Without the realignment of the two feature maps defined in space, subjects could not at all form the strategy to compress the two sequences. In other words, decoding of color sequences could be understood as neural representation of a series of corresponding locations along the ring that are independent of the physical locations of the items.</p><p>Interpretations and clarifications have been added (Page 23&amp;26).</p><disp-quote content-type="editor-comment"><p>(4) Does the discretisation of the stimulus distribution (to only 9 possible locations) make the compression strategy easier to use? If the features had been continuously distributed across the location/colour circle, would participants still pick up on and use the shared trajectory structure?</p></disp-quote><p>Thanks for the question. Without further data, it’s hard to say whether the discretization of the stimulus distribution would make the compression strategy easier to use or not, compared to continuous distribution. Both outcomes seem possible. On the one hand, discrete stimulus distribution would result in discrete trajectory distribution, which helps participants to realize the common trajectory strategy. On the other hand, discrete stimulus distribution would result in category or label representation, which may weaken the effectiveness of structure compression strategy. We postulate that our findings could be generalized to continuous trajectories in a cognitive map within certain resolution.</p><disp-quote content-type="editor-comment"><p>(5a) Minor point: I disagree that avoiding the same points for location and colour for a given item allows them to be independently decoded. I would argue the contrary - this kind of constraint should create a small anti-correlation that in principle could lead to spurious decoding of one variable (although this seems unlikely here).</p></disp-quote><p>We appreciate the concern. As mentioned above, with discrete stimulus distribution (9 possible values for both color and location domains), it is quite possible that a fraction of trials would share same values in location and color. Therefore, the neural decoding for one domain might be confounded by another domain. To dissociate their neural representations, we imposed constraints that color and location could not occupy the same value for a given item.</p><p>We agree that this kind of constraint might create a small anti-correlation, even though it is not observed here. Future studies using continuous stimulus distribution would reduce the correlation or anti-correlation between stimuli.</p><disp-quote content-type="editor-comment"><p>(5b) Very minor point: 1,000 permutations for significance testing seems on the low side. Since some of the p-values are close to 0.05 it may be worth running more permutations.</p></disp-quote><p>Thanks for this suggestion. We got similar results using 1000 or 10000 permutations.</p><disp-quote content-type="editor-comment"><p>(6) Missing reference: H. H. Li et al., 2021 (line 213) seems not to be on the list of references.</p></disp-quote><p>Sorry for the mistake. Added.</p><disp-quote content-type="editor-comment"><p><bold>Reviewer #2 (Recommendations For The Authors):</bold></p><p>The study aimed to discuss the working memory mechanism, instead, it seems to be focused on the encoding and recall strategies after a short while, I recommend updating the manuscript to refer to the relevant cognitive mechanism.</p><p>There was a strong voice on the effect of using the cognitive map in working memory, without any tests on if indeed a cognitive map was used (for example the novel link between stimuli and how a cognitive map can be used to infer shortcuts). Was the participant required to have any mental map beyond the schema of the shown color ring?</p><p>In the current experiment, to discuss if the effect is driven by utilizing a cognitive map or schematic abstraction of color-relatedness, further analysis is required to possibly assess the effects of schema on neural activity and behavior. Namely,</p><p>(1) Was there any reinstatement of schematically congruent (expected) colors that were probed by location 1, at locations 2 and 3 in the MAT condition?</p></disp-quote><p>Thanks for pointing out this possibility. However, we don’t think there will be stable color expectations given location information under the MAT condition. First, as the trajectory distance varied on a trial-by-trial basis, no prior common trajectory knowledge could be used to make inference about the current stimuli in individual trial. Second, the starting points for color and location (1st item) were randomly and independently selected, such that color sequence could not be predicted based on the location sequence for both aligned and misaligned conditions.</p><disp-quote content-type="editor-comment"><p>(2) Given that response time can be a behavioral marker of schematic conflict, was the response time faster for congruent than incongruent conditions?</p></disp-quote><p>Thanks for this question. Unfortunately, due to the experimental design, the response time could not be used as a behavioral marker to infer mental conflicts, since participants were not required to respond as fast as possible. Instead, they took their own pace to reproduce sequences without time limit. They could even take a short break before submitting their response to initiate the next trial.</p><disp-quote content-type="editor-comment"><p>(3) In case you cannot rule out that utilizing schema is the cognitive mechanism that supports working memory performance (the behavior), please add the classical literature (on the memory of schematically congruent and incongruent events) to the discussion.</p></disp-quote><p>Thanks for this suggestion and we have added relevant literatures now (Page 3&amp;19).</p><disp-quote content-type="editor-comment"><p>(4) On page 6, 'common structure in the cognitive map' is the schema, isn't it?</p></disp-quote><p>Correct. Based on our understanding, ‘common structure in the cognitive map’ is a spatial schema.</p><disp-quote content-type="editor-comment"><p>(5) In Figure 2 EFG, would you please use a mixed effect model or show evidence that all participants demonstrated a correlation between the location trajectory error and color trajectory error?</p></disp-quote><p>Thanks for the suggestion. We have added the mixed effect model results, which are consistent with Figure 2EFG (AT: 1st-2nd trajectory, β = 0.071, t = 4.215, p &lt; 0.001; 2nd-3rd trajectory, β = 0.077, t = 3.570, p &lt; 0.001; 1st-3rd trajectory, β = 0.019, t = 1.118, p = 0.264; MAT: 1st-2nd trajectory, β = 0.031, t = 1.572, p = 0.116; 2nd-3rd trajectory, β = 0.002, t = 0.128 , p = 0.898; 1st-3rd trajectory, β = -0.017, t = -1.024, p = 0.306).</p><disp-quote content-type="editor-comment"><p>In general, doesn't such correlation just show that good participants/trials were good (some did well in the study and some did poorly throughout?)</p></disp-quote><p>We don’t think the trajectory error correlation results just reveal that some participants did well and some participants did poorly. If that is the case, we shouldn’t observe significant correlation in Figure 2D, where we first run correlation for each participant and then test correlation significance at group level. Indeed, trajectory error correlation between color and location domains characterizes the consistent changes between the two domains.</p><p>It is worth to note that the correlation was estimated with signed trajectory errors in color and location domains, which meant that we indeed cared about whether the errors in the two domains were consistently varied in the same direction, i.e., whether longer trajectory memory compared to the actual trajectory in location domain would predict longer trajectory memory in color domain.</p><p>Moreover, as shown in Figure 2EFG, by dividing trials into 4 bins according to the location trajectory error for each participant and pooling the data across participants, we observed 4 clusters along x-axis (location trajectory error). This suggests that participants’ memory performance is rather consistent instead of being extremely good or bad. Besides, if trajectory error correlation is due to different overall memory performance between participants, we should observe significant trajectory error correlations both in AT and MAT conditions, instead of only under AT condition and for 1st-2nd and 2nd-3rd trajectories but not for 1st-3rd trajectory.</p><disp-quote content-type="editor-comment"><p>In Figure 2 G, is the marginal error just too big to be sensitive? I am not sure what we are learning here, please clarify.</p></disp-quote><p>Sorry for the confusion. To examine this possibility, we excluded errors which are beyond 2.5 * σ, and still observed non-significant 1st-3rd trajectory error correlation between color and location domains (r = 0.119, p = 0.167).</p><p>The 1st-3rd trajectory showed nonsignificant behavioral correlation and neural representation, which suggests that the current sequential memory task would encourage participants to organize all information by relying more on the adjacent items and their distance. Thus, we think the 1st-3rd trajectory would serve as a control trajectory, which helps us not only exclude other possible explanation (e.g., systematic response bias), but also validate current findings both in behavioral and neural level.</p><p>Results and statements (Page 10-11) added now.</p><fig id="sa2fig2" position="float"><label>Author response image 2.</label><graphic mimetype="image" mime-subtype="tiff" xlink:href="elife-93158-sa2-fig2-v1.tif"/></fig><disp-quote content-type="editor-comment"><p>(6) Regarding the first lines on page 11, did you do qualitative research to know if less information was encoded in congruent conditions?</p></disp-quote><p>The current experimental design is inspired by the mental compression of spatial sequence studies from Dehaene’s lab (Amalric er al., 2017; Roumi et al., 2021), in which they propose that human brain compresses spatial sequence using an abstract language and formalize minimal description length of a sequence as the “language-of-thought complexity.” Based on this evidence, we think less information is required to describe congruent condition compared to incongruent condition. This idea is supported by better memory performance for congruent condition. Unfortunately, we couldn’t manage to quantify how less information was encoded in congruent condition.</p></body></sub-article></article>