<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN"  "JATS-archivearticle1.dtd"><article article-type="research-article" dtd-version="1.1" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink"><front><journal-meta><journal-id journal-id-type="nlm-ta">elife</journal-id><journal-id journal-id-type="publisher-id">eLife</journal-id><journal-title-group><journal-title>eLife</journal-title></journal-title-group><issn pub-type="epub" publication-format="electronic">2050-084X</issn><publisher><publisher-name>eLife Sciences Publications, Ltd</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="publisher-id">64058</article-id><article-id pub-id-type="doi">10.7554/eLife.64058</article-id><article-categories><subj-group subj-group-type="display-channel"><subject>Research Article</subject></subj-group><subj-group subj-group-type="heading"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title>The neural basis of intelligence in fine-grained cortical topographies</article-title></title-group><contrib-group><contrib contrib-type="author" id="author-177627"><name><surname>Feilong</surname><given-names>Ma</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6838-3971</contrib-id><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="fn" rid="con1"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" id="author-81336"><name><surname>Guntupalli</surname><given-names>J Swaroop</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-0677-5590</contrib-id><xref ref-type="aff" rid="aff2">2</xref><xref ref-type="fn" rid="con2"/><xref ref-type="fn" rid="conf1"/></contrib><contrib contrib-type="author" corresp="yes" id="author-19763"><name><surname>Haxby</surname><given-names>James V</given-names></name><contrib-id authenticated="true" contrib-id-type="orcid">https://orcid.org/0000-0002-6558-3118</contrib-id><email>james.v.haxby@dartmouth.edu</email><xref ref-type="aff" rid="aff1">1</xref><xref ref-type="other" rid="fund1"/><xref ref-type="other" rid="fund2"/><xref ref-type="fn" rid="con3"/><xref ref-type="fn" rid="conf1"/></contrib><aff id="aff1"><label>1</label><institution>Center for Cognitive Neuroscience, Dartmouth College</institution><addr-line><named-content content-type="city">Hanover, NH</named-content></addr-line><country>United States</country></aff><aff id="aff2"><label>2</label><institution>Vicarious AI</institution><addr-line><named-content content-type="city">Union City, CA</named-content></addr-line><country>United States</country></aff></contrib-group><contrib-group content-type="section"><contrib contrib-type="senior_editor"><name><surname>de Lange</surname><given-names>Floris P</given-names></name><role>Senior Editor</role><aff><institution>Radboud University</institution><country>Netherlands</country></aff></contrib><contrib contrib-type="editor"><name><surname>Yeo</surname><given-names>Thomas</given-names></name><role>Reviewing Editor</role><aff><institution>National University of Singapore</institution><country>Singapore</country></aff></contrib></contrib-group><pub-date date-type="publication" publication-format="electronic"><day>08</day><month>03</month><year>2021</year></pub-date><pub-date pub-type="collection"><year>2021</year></pub-date><volume>10</volume><elocation-id>e64058</elocation-id><history><date date-type="received" iso-8601-date="2020-10-15"><day>15</day><month>10</month><year>2020</year></date><date date-type="accepted" iso-8601-date="2021-03-05"><day>05</day><month>03</month><year>2021</year></date></history><permissions><copyright-statement>© 2021, Feilong et al</copyright-statement><copyright-year>2021</copyright-year><copyright-holder>Feilong et al</copyright-holder><ali:free_to_read/><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><ali:license_ref>http://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This article is distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use and redistribution provided that the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="elife-64058-v2.pdf"/><abstract><p>Intelligent thought is the product of efficient neural information processing, which is embedded in fine-grained, topographically organized population responses and supported by fine-grained patterns of connectivity among cortical fields. Previous work on the neural basis of intelligence, however, has focused on coarse-grained features of brain anatomy and function because cortical topographies are highly idiosyncratic at a finer scale, obscuring individual differences in fine-grained connectivity patterns. We used a computational algorithm, hyperalignment, to resolve these topographic idiosyncrasies and found that predictions of general intelligence based on fine-grained (vertex-by-vertex) connectivity patterns were markedly stronger than predictions based on coarse-grained (region-by-region) patterns. Intelligence was best predicted by fine-grained connectivity in the default and frontoparietal cortical systems, both of which are associated with self-generated thought. Previous work overlooked fine-grained architecture because existing methods could not resolve idiosyncratic topographies, preventing investigation where the keys to the neural basis of intelligence are more likely to be found.</p></abstract><kwd-group kwd-group-type="author-keywords"><kwd>fMRI</kwd><kwd>intelligence</kwd><kwd>cortical topography</kwd><kwd>functional connectivity</kwd><kwd>hyperalignment</kwd><kwd>individual differences</kwd></kwd-group><kwd-group kwd-group-type="research-organism"><title>Research organism</title><kwd>Human</kwd></kwd-group><funding-group><award-group id="fund1"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>1607845</award-id><principal-award-recipient><name><surname>Haxby</surname><given-names>James V</given-names></name></principal-award-recipient></award-group><award-group id="fund2"><funding-source><institution-wrap><institution-id institution-id-type="FundRef">http://dx.doi.org/10.13039/100000001</institution-id><institution>National Science Foundation</institution></institution-wrap></funding-source><award-id>1835200</award-id><principal-award-recipient><name><surname>Haxby</surname><given-names>James V</given-names></name></principal-award-recipient></award-group><funding-statement>The funders had no role in study design, data collection and interpretation, or the decision to submit the work for publication.</funding-statement></funding-group><custom-meta-group><custom-meta specific-use="meta-only"><meta-name>Author impact statement</meta-name><meta-value>Individual differences in intelligence are based on information processing that is embedded in fine-scale structure in cortical systems for self-generated thought, which was revealed by resolving topographic idiosyncrasies with hyperalignment.</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1" sec-type="intro"><title>Introduction</title><p>Intelligent thought is the product of efficient neural information processing, but the neural architecture that makes some brains capable of quick wit and deep insight, while others struggle with simple problems, remains an open question. Previous work on the neural basis of intelligence has focused on coarse-grained features of brain anatomy and function, such as the size and shape of the brain and its parts (e.g., <xref ref-type="bibr" rid="bib11">Cox et al., 2019</xref>; <xref ref-type="bibr" rid="bib42">Luders et al., 2007</xref>; <xref ref-type="bibr" rid="bib50">Schmitt et al., 2019</xref>) or the size and strength of connections between large cortical fields (e.g., <xref ref-type="bibr" rid="bib14">Dubois et al., 2018</xref>; <xref ref-type="bibr" rid="bib17">Finn et al., 2015</xref>; <xref ref-type="bibr" rid="bib39">Kong et al., 2019</xref>; <xref ref-type="bibr" rid="bib51">Shen et al., 2017</xref>). Neural information processing, however, is embedded in fine-grained, topographically organized population responses (<xref ref-type="bibr" rid="bib32">Haxby et al., 2014</xref>; <xref ref-type="bibr" rid="bib30">Haxby et al., 2001</xref>). Functional connectivity varies vertex-by-vertex (<xref ref-type="bibr" rid="bib27">Guntupalli et al., 2018</xref>), and even neuron-by-neuron (<xref ref-type="bibr" rid="bib44">Park et al., 2017</xref>), to support such information processing. Therefore, fine-grained functional connectivity depicts in detail how information is exchanged and processed between cortical regions, in contrast to coarse-grained region-by-region connectivity, which depicts the overall synchronization between regions. We investigated whether individual differences in general intelligence are a function of information embedded in fine-grained cortical architecture.</p><p>Fine-grained patterns of activity and connectivity can be studied with functional magnetic resonance imaging (fMRI), but the topographies of these patterns are idiosyncratic, impeding study of their role in the neural basis of individual differences in cognitive ability. We used hyperalignment (<xref ref-type="bibr" rid="bib16">Feilong et al., 2018</xref>; <xref ref-type="bibr" rid="bib27">Guntupalli et al., 2018</xref>; <xref ref-type="bibr" rid="bib25">Guntupalli et al., 2016</xref>; <xref ref-type="bibr" rid="bib33">Haxby et al., 2020</xref>; <xref ref-type="bibr" rid="bib31">Haxby et al., 2011</xref>) to resolve the interindividual variation of fine-grained topographies of functional connectivity. Hyperalignment remixes the connectivity profiles of loci in a cortical field into a high-dimensional common space to maximize the similarity across brains in fine-grained, vertex-by-vertex patterns. Individual variations in the residuals around common fine-grained patterns are more reliable than individual variations around common coarse-grained patterns after resolving idiosyncratic topographies with hyperalignment (<xref ref-type="bibr" rid="bib16">Feilong et al., 2018</xref>). We found that predictions of general intelligence based on fine-grained (vertex-by-vertex) patterns of connectivity were markedly stronger than predictions based on coarse-grained (region-by-region) patterns. Intelligence was best predicted by fine-grained connectivity in the default and frontoparietal cortical systems, both of which are associated with self-generated thought. These results demonstrate that the neural mechanisms of intelligence reside more in fine-grained interactions of cortical regions than in synchronization of oscillations in large cortical fields.</p></sec><sec id="s2" sec-type="results"><title>Results</title><p>We used data from 876 participants of the Human Connectome Project (HCP) (<xref ref-type="bibr" rid="bib55">Van Essen et al., 2013</xref>). Each participant had about 47 min of task fMRI data, collected during the performance of seven tasks, 1 hr of resting-state fMRI data, and scores on 10 cognitive tests. We used connectivity hyperalignment (<xref ref-type="bibr" rid="bib27">Guntupalli et al., 2018</xref>) to factor out idiosyncrasies in fine-grained topographies and model information encoded in local functional connectivity patterns that is shared across brains. We hyperaligned both the HCP task fMRI and resting fMRI datasets. Connectivity hyperalignment projects idiosyncratic cortical topographies for individual brains into a common model connectivity space in which the patterns of connectivity across vertices in a cortical field with connectivity targets elsewhere in the brain are maximally similar across brains. We measured general intelligence (<xref ref-type="bibr" rid="bib53">Spearman, 1904</xref>) as a general factor based on 10 cognitive test scores included in the HCP database (<xref ref-type="bibr" rid="bib14">Dubois et al., 2018</xref>).</p><p>For each of the 360 cortical regions, from a parcellation tailored to the HCP dataset (<xref ref-type="bibr" rid="bib20">Glasser et al., 2016</xref>), we computed fine-grained task fMRI and resting fMRI connectivity profiles for each individual (<xref ref-type="fig" rid="fig1">Figure 1</xref>). The connectivity profile for each cortical vertex differs from profiles for other vertices in the region with a granularity in the common model space that is equivalent to spatial variation across cortical loci within individual brains (<xref ref-type="bibr" rid="bib27">Guntupalli et al., 2018</xref>). We factored out the effect of coarse-grained connectivity by subtracting the mean connectivities between pairs of regions (coarse-grained connectivity profiles; <xref ref-type="fig" rid="fig1">Figure 1</xref>, middle row) from the vertex-wise connectivities (full fine-grained connectivity profiles; <xref ref-type="fig" rid="fig1">Figure 1</xref>, top row), to examine the predictive power of fine-grained connectivity unconfounded with prediction based on coarse-grained connectivity. These residual fine-grained connectivity profiles were used throughout the analysis, and we refer to them as fine-grained connectivity profiles for short. Results based on these residual profiles were very similar to those based on full fine-grained connectivity profiles (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>). We calculated coarse-grained connectivity on the same hyperaligned data used for calculation of fine-grained connectivity (see <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>).</p><fig id="fig1" position="float"><label>Figure 1.</label><caption><title>Schematic illustration of coarse- and fine-grained functional connectivity.</title><p>Each brain region (e.g., area 150 shown here) comprises multiple cortical vertices (on average 165). Correlations between their time series and time series for all 59,412 vertices in the whole cortex form that region’s full fine-grained connectivity matrix (top row). The fine-grained connectivity profiles for 360 brain regions each have approximately 10 million such correlations. The coarse-grained connectivity profile for the same region (middle row) comprises the average functional connectivity between all of the vertices in that region and all of the vertices in each of the 360 brain regions. Thus, the coarse-grained connectivity profiles for 360 brain regions each have 360 mean correlations. The residual fine-grained connectivity profile (bottom row) for each region is obtained by subtracting the mean correlation for a pair of regions (e.g., regions 1 and 150) from the full fine-grained connectivity profile for that pair and is, thus, unconfounded with coarse-grained functional connectivities. We refer to these unconfounded profiles as fine-grained connectivity profiles for short.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64058-fig1-v2.tif"/></fig><p>We built prediction models based on regional connectivity profiles using cross-validated principal component regression with ridge regularization. We divided the data into <italic>k</italic> test participants from one family (<italic>k</italic> = 1–6) and the remaining 876 - <italic>k</italic> training set participants (<xref ref-type="fig" rid="fig2">Figure 2</xref>). Thus, each test participant’s intelligence was predicted using regression weights derived from other participants’ data. We assessed the performance of these models using a coefficient of determination (<italic>R<sup>2</sup></italic>), which denotes the percent of intelligence score variance accounted for (VAF) by the prediction models. We made separate prediction models for hyperaligned fine-scale task and resting connectivity, coarse-grained task and resting connectivity, and non-hyperaligned fine-scale task and resting connectivity.</p><fig id="fig2" position="float"><label>Figure 2.</label><caption><title>Schematic illustration of analysis pipeline.</title><p>We used a leave-one-family-out cross-validation scheme. For each data fold, we built a prediction model based on the training subjects' data (yellow color) to predict general intelligence (<italic>g</italic>) from the connectivity profile of a cortical region and applied the model to test subjects' connectivity profiles to predict their general intelligence scores (steps 1 and 2). We aggregated predicted and actually measured <italic>g</italic> across all cross-validation folds to assess model performance with cross-validated <italic>R</italic><sup>2</sup> (step 3) and repeated this procedure for other cortical regions' connectivity profiles (step 4). After the entire pipeline, we obtained an <italic>R</italic><sup>2</sup> for each of the 360 cortical regions, which stands for the amount of variance in <italic>g</italic> that can be accounted for by the region's connectivity profile. We repeated the pipeline for different kinds of connectivity profiles (spatial granularity, dataset, and alignment method) and compared them systematically (<xref ref-type="fig" rid="fig3">Figure 3, Figure 4, Figure 5</xref>), and these repetitions only differ in the connectivity profiles fed into the pipeline.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64058-fig2-v2.tif"/></fig><sec id="s2-1"><title>Hyperaligned fine-grained versus coarse-grained connectivity profiles</title><p>Regional hyperaligned fine-grained task and resting connectivity profiles were highly predictive of general intelligence (<xref ref-type="fig" rid="fig3">Figure 3A, Figure 4A</xref>) and accounted for twice as much variance in general intelligence compared to coarse-grained connectivity profiles (<xref ref-type="fig" rid="fig3">Figure 3B, C, Figure 4B, C</xref>).</p><fig id="fig3" position="float"><label>Figure 3.</label><caption><title>Predicting general intelligence based on regional task functional magnetic resonance imaging (fMRI) connectivity profiles.</title><p>Prediction based on hyperaligned fine-grained (<bold>A</bold>) and coarse-grained (<bold>B</bold>) connectivity profiles, assessed by the variance in general intelligence accounted for. The scatterplot (<bold>C</bold>) shows that predictions based on hyperaligned fine-grained profiles accounted for more variance in all 360 regions of interest (ROIs). Prediction models based on each region's fine-grained hyperaligned task functional connectivity profile accounted for 1.85 (95% CI: [1.70, 2.05]) times more variance in general intelligence on average than did models based on coarse-grained functional connectivity profiles. Each circle is a cortical region, and the color of each circle corresponds to the cortical system where it resides, using the same color scheme as in (<bold>E</bold>). Dashed lines denote average difference in <italic>R</italic><sup>2</sup> (gray) or identical <italic>R</italic><sup>2</sup> (black). (<bold>D</bold>) The 30 regions whose hyperaligned fine-grained connectivity best predicted general intelligence are colored as in (<bold>A</bold>) and (<bold>B</bold>). The default mode network is outlined in red, and the frontoparietal network is outlined in orange (<xref ref-type="bibr" rid="bib58">Yeo et al., 2011</xref>). (<bold>E</bold>) Proportion of vertices in these regions that are in seven cortical systems delineated with resting state fMRI functional connectivity (<xref ref-type="bibr" rid="bib58">Yeo et al., 2011</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64058-fig3-v2.tif"/></fig><fig id="fig4" position="float"><label>Figure 4.</label><caption><title>Predicting general intelligence based on regional hyperaligned resting functional magnetic resonance imaging (fMRI) connectivity profiles.</title><p>Prediction based on fine-grained (<bold>A</bold>) and coarse-grained (<bold>B</bold>) connectivity profiles. The scatterplot (<bold>C</bold>) shows that regional predictions based on hyperaligned fine-grained profiles accounted for more variance in all 360 ROIs. Prediction models based on each region's fine-grained hyperaligned resting functional connectivity profile accounted for 2.48 (95% CI: [2.18, 2.93]) times more variance in general intelligence on average than did models based on coarse-grained functional connectivity profiles. Each circle is a cortical region, and the color of each circle corresponds to the cortical system where it resides, using the same color scheme as in (<bold>E</bold>). Dashed lines denote average difference in <italic>R</italic><sup>2</sup> (gray) or identical <italic>R</italic><sup>2</sup> (black). (<bold>D</bold>) The 30 regions whose hyperaligned fine-grained connectivity best predicted general intelligence are colored as in (<bold>A</bold>) and (<bold>B</bold>). The default mode network is outlined in red, and the frontoparietal network is outlined in orange (<xref ref-type="bibr" rid="bib58">Yeo et al., 2011</xref>). (<bold>E</bold>) Proportion of vertices in these regions that are in seven cortical systems delineated with resting state fMRI functional connectivity (<xref ref-type="bibr" rid="bib58">Yeo et al., 2011</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64058-fig4-v2.tif"/></fig><sec id="s2-1-1"><title>Prediction of intelligence based on task fMRI connectivity profiles</title><p>On average across all cortical regions, prediction models based on hyperaligned fine-grained task fMRI connectivity accounted for 27.3% of variance in general intelligence (min: 11.2%; max: 38.9%). In other words, the correlation between predicted and measured intelligence scores ranged from <italic>r</italic> = 0.34 in the least predictive brain region to <italic>r</italic> = 0.62 in the most predictive brain region. By contrast, prediction models based on coarse-grained task fMRI connectivity (<xref ref-type="fig" rid="fig3">Figure 3B</xref>) accounted on average for only 14.9% of variance (min: 3.3%; max: 26.5%), which is only 54.2% (95% CI: [48.7%, 58.8%]) of VAF by hyperaligned fine-grained connectivity overall. VAF by hyperaligned fine-grained task connectivity was higher than VAF by coarse-grained connectivity in all 360 ROIs (<xref ref-type="fig" rid="fig3">Figure 3C</xref>). These results suggest that the information encoded in fine-grained interaction patterns between brain regions affords markedly stronger predictions of intelligence than the information in coarse-grained patterns.</p><p>The 30 most predictive regions (<xref ref-type="fig" rid="fig3">Figure 3D, E</xref>; 33.8–38.9% VAF) were in bilateral inferior parietal cortex (15 regions), bilateral medial and superior prefrontal cortex (11 regions), bilateral medial parietal (2 regions), and bilateral posterior lateral temporal cortex (2 regions). The cortices in these regions were predominantly part of the default mode and frontoparietal systems (38.9% and 34.5% of cortical vertices, respectively) with small portions in the ventral and dorsal attention systems (11.3% and 10.6%, respectively; <xref ref-type="fig" rid="fig3">Figure 3D, E</xref>; <xref ref-type="bibr" rid="bib58">Yeo et al., 2011</xref>). Assignment to cortical systems in a different parcellation tailored to the Glasser parcellation (<xref ref-type="bibr" rid="bib34">Ji et al., 2019</xref>) similarly revealed the dominant role played by the default and frontoparietal systems (<xref ref-type="fig" rid="app1fig11">Appendix 1—figure 11</xref>).</p></sec><sec id="s2-1-2"><title>Prediction of intelligence based on resting fMRI connectivity profiles</title><p>Prediction of general intelligence based on resting fMRI connectivity showed a similar advantage for hyperaligned fine-grained profiles, relative to coarse-grained profiles (<xref ref-type="fig" rid="fig4">Figure 4</xref>), but performance was substantially lower than for task fMRI connectivity, consistent with previous reports (<xref ref-type="bibr" rid="bib24">Greene et al., 2018</xref>; <xref ref-type="bibr" rid="bib36">Jiang et al., 2020</xref>). Models based on hyperaligned fine-grained resting fMRI connectivity accounted on average for 19.8% of variance (<xref ref-type="fig" rid="fig4">Figure 4A</xref>; min: 4.7%; max: 31.2%), whereas models based on coarse-grained connectivity accounted on average for 8.1% of variance (<xref ref-type="fig" rid="fig4">Figure 4B</xref>; min: −1.2%; max: 17.4%), which is only 40.5% [CI: 34.2%, 45.8%] of VAF by hyperaligned fine-grained resting connectivity. Hyperaligned fine-grained resting fMRI connectivity, compared to coarse-grained resting fMRI connectivity, accounted for more variance in all 360 ROIs (<xref ref-type="fig" rid="fig4">Figure 4C</xref>). The vertices of 30 regions whose resting hyperaligned fine-grained connectivity was most predictive of general intelligence (25.3–31.2% VAF) had a distribution that was similar to that for hyperaligned task connectivity, sharing 68.3% of cortical vertices (compare <xref ref-type="fig" rid="fig3">Figure 3D, Figure 4D</xref>), with vertices mostly in the default mode network (49.0%) and smaller parts in the frontoparietal (19.4%), dorsal attention (15.8%), and ventral attention (10.0%) systems (<xref ref-type="fig" rid="fig4">Figure 4E</xref>; see also <xref ref-type="fig" rid="app1fig11">Appendix 1—figure 11</xref>).</p><p>Consistent with previous reports (<xref ref-type="bibr" rid="bib24">Greene et al., 2018</xref>; <xref ref-type="bibr" rid="bib36">Jiang et al., 2020</xref>), task fMRI connectivity was significantly more predictive of general intelligence than was resting fMRI connectivity for both hyperaligned fine-grained data (difference = 7.6% VAF; 95% CI: [5.3%, 9.9%]) and coarse-grained data (difference = 6.8% VAF; 95% CI: [5.0%, 8.6%]). Task connectivity accounted for more variance than did resting connectivity in 358 of 360 ROIs for hyperaligned fine-grained data and in 343 of 360 ROIs for coarse-grained data (<xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>).</p></sec></sec><sec id="s2-2"><title>Hyperaligned versus MSM-aligned fine-grained connectivity profiles</title><p>To test the efficacy of hyperalignment for revealing predictive individual differences in fine-grained connectivity topographies, we trained another set of models based on fine-grained functional connectivity of data without hyperalignment. These data were aligned with multimodal surface matching (MSM) (<xref ref-type="bibr" rid="bib48">Robinson et al., 2014</xref>). Models based on MSM-aligned fine-grained task connectivity and resting connectivity accounted for, on average across ROIs, 17.6% (min: 5.1%; max: 28.7%) and 11.1% (min: 0.8%; max: 22.5%), respectively, of variance in general intelligence, which was 64.3% (95% CI: [59.9%, 68.3%]) and 56.0% (95% CI: [49.7%, 61.7%]) of that accounted for by models using hyperaligned data (<xref ref-type="fig" rid="fig5">Figure 5</xref>). Predictions based on hyperaligned fine-grained task connectivity were better than predictions based on MSM-aligned fine-grained connectivity in all 360 regions (<xref ref-type="fig" rid="fig5">Figure 5C</xref>). Predictions based on hyperaligned fine-grained resting connectivity were better than predictions based on MSM-aligned fine-grained connectivity in 357 of 360 regions (<xref ref-type="fig" rid="fig5">Figure 5D</xref>). The difference in model performance was larger for brain regions with more functional topographic idiosyncrasy for both task and resting connectivity (<italic>r</italic> = 0.435 and 0.425, respectively, <italic>p </italic>&lt; 10<sup>−14</sup>), with two- to threefold increases in VAF in the most idiosyncratic regions. As for hyperaligned fine-scale connectivity and coarse-scale connectivity, MSM-aligned fine-scale task connectivity was more predictive of intelligence than was MSM-aligned fine-scale resting connectivity (difference = 6.5% VAF; 95% CI: [5.0%, 8.0%]; <xref ref-type="fig" rid="app1fig1">Appendix 1—figure 1</xref>C). Consistent with our previous findings (<xref ref-type="bibr" rid="bib16">Feilong et al., 2018</xref>), these results show that hyperalignment factors out idiosyncrasies in functional topography to reveal how individuals differ in information encoded in fine-grained cortical functional architecture.</p><fig id="fig5" position="float"><label>Figure 5.</label><caption><title>Predicting general intelligence based on multimodal surface matching (MSM)-aligned fine-grained connectivity profiles.</title><p>Prediction based on task functional magnetic resonance imaging (fMRI) (<bold>A</bold>) and resting fMRI (<bold>B</bold>) connectivity. Scatterplots compare regional predictions based on MSM-aligned to predictions based on hyperaligned task connectivity (<bold>C</bold>) and resting connectivity (<bold>D</bold>) data (comparison to results in <xref ref-type="fig" rid="fig3">Figure 3A , Figure 4A</xref>).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64058-fig5-v2.tif"/></fig></sec></sec><sec id="s3" sec-type="discussion"><title>Discussion</title><p>The results show that individual differences in fine-grained patterns of functional connectivity are a markedly better predictor of general intelligence than are coarse-grained patterns, indicating that differences in cortical architecture that underlie inter-individual variation in the efficiency of information processing are more evident at the same spatial scale as topographic patterns that encode information. Discovering the dominant role of fine-grained connectivity patterns in the neural basis of intelligence required a method that resolves individual differences in these idiosyncratic patterns, a method that was not available prior to hyperalignment (<xref ref-type="bibr" rid="bib16">Feilong et al., 2018</xref>; <xref ref-type="bibr" rid="bib27">Guntupalli et al., 2018</xref>; <xref ref-type="bibr" rid="bib25">Guntupalli et al., 2016</xref>; <xref ref-type="bibr" rid="bib33">Haxby et al., 2020</xref>; <xref ref-type="bibr" rid="bib31">Haxby et al., 2011</xref>; <xref ref-type="bibr" rid="bib43">Nastase et al., 2020</xref>).</p><p>Differences in intelligence are indexed by tests of the ability to understand and manipulate information embedded in the meanings of words, logical relations, and visual patterns. We predicted that differences in performance would be more related to the fine-grained topographic patterns that represent these kinds of information than to coarse-grained patterns that blur fine distinctions. The results confirm our hypothesis. Hyperaligned, fine-grained, vertex-by-vertex connectivity patterns accounted for 1.85–2.48 times more variance in general intelligence than did coarse-grained, region-to-region connectivity patterns.</p><p>To examine the predictive power of fine-grained connectivity unconfounded with coarse-grained connectivity, we built models using the residual fine-grained connectivity profiles. In separate analyses, we built models on the full fine-grained patterns and found that adding coarse-grained information contributed little to VAF (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>), underscoring the stronger role that fine-grained cortical architecture plays in the neural basis of intelligence than that played by coarse-grained architecture.</p><p>Functional connectivity shows fine-grained variation vertex-by-vertex within a cortical field (<xref ref-type="bibr" rid="bib27">Guntupalli et al., 2018</xref>) and even neuron-by-neuron within an fMRI voxel (<xref ref-type="bibr" rid="bib44">Park et al., 2017</xref>). Transmission of information between cortical fields, therefore, involves more than simple synchronization of global activity. Information is transformed, as evidenced by changes in the representational geometries that are embedded in the fine-grained structure of local topographies (<xref ref-type="bibr" rid="bib10">Connolly et al., 2016</xref>; <xref ref-type="bibr" rid="bib26">Guntupalli et al., 2017</xref>; <xref ref-type="bibr" rid="bib41">Kriegeskorte et al., 2008</xref>). Our results indicate that investigating the efficiency of information processing should focus on fine-grained patterns of connectivity that support information processing.</p><p>Hyperalignment resolves functional topographic idiosyncrasies at both coarse and fine spatial scales (see <xref ref-type="bibr" rid="bib35">Jiahui et al., 2020</xref> for an example of aligning functional topographies), which is critical for assessing individual differences in information processing. Alternatively, individualized parcellations (e.g., <xref ref-type="bibr" rid="bib39">Kong et al., 2019</xref>; <xref ref-type="bibr" rid="bib20">Glasser et al., 2016</xref>) can be used to resolve coarse-scale topographic idiosyncrasies, which also improves prediction performance (<xref ref-type="bibr" rid="bib40">Kong et al., 2021</xref>). However, the improvement for coarse-grained functional connectivity was smaller than for fine-grained functional connectivity in predicting general intelligence (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>).</p><p>Previous work could not reveal the role that information embedded in fine-scale topographies plays in the neural basis of intelligence because individual differences in information were concealed by idiosyncrasies in fine-scale topographies that could not be aligned with prior methods. Hyperalignment resolves the shared information embedded in idiosyncratic topographies, making it possible to investigate these individual differences (<xref ref-type="bibr" rid="bib16">Feilong et al., 2018</xref>). Fine-grained information in hyperaligned data accounted for 1.56–1.79 times more individual variation in intelligence than did fine-grained information in non-hyperaligned data.</p><p>Results also show that fMRI data collected during performance of cognitive tasks better predict intelligence than resting state fMRI data, consistent with previous reports (<xref ref-type="bibr" rid="bib24">Greene et al., 2018</xref>; <xref ref-type="bibr" rid="bib36">Jiang et al., 2020</xref>). Previous studies used whole-brain, coarse-grained connectivity for prediction. Here, we show that the added predictive power of task fMRI data, relative to resting fMRI data, extends to both hyperaligned and MSM-aligned fine-grained connectivity patterns.</p><p>Our results show further that the neural basis of intelligence resides mostly in the fine-grained structure of connectivity in the default mode and frontoparietal networks (<xref ref-type="bibr" rid="bib7">Buckner et al., 2008</xref>; <xref ref-type="bibr" rid="bib46">Raichle et al., 2001</xref>; <xref ref-type="bibr" rid="bib58">Yeo et al., 2011</xref>). Small parts of the most predictive regions were in the dorsal and ventral attention networks, and an even smaller proportion was in the visual system. The most predictive brain regions did not encroach on the systems for auditory, somatosensory, motor, or limbic function. The predominance of the default mode network was found for both task connectivity and resting connectivity, suggesting that the efficiency of these connections is evident in both. A strong role for the frontoparietal network was more evident in task connectivity, suggesting that the efficiency of this system’s connections is better revealed during performance of tasks that increase its activity.</p><p>The predominant role of the default and frontoparietal systems in our results suggests that intelligence rests on self-generated and stimulus-independent thinking (<xref ref-type="bibr" rid="bib3">Andrews-Hanna et al., 2014</xref>; <xref ref-type="bibr" rid="bib7">Buckner et al., 2008</xref>; <xref ref-type="bibr" rid="bib13">Dixon et al., 2018</xref>; <xref ref-type="bibr" rid="bib46">Raichle et al., 2001</xref>), or on the apperceptive mass that provides the foundation and context for perception and thought (<xref ref-type="bibr" rid="bib47">Raichle, 2006</xref>), for finding correct solutions to problems and generating novel insights. The functions of the default system are mostly ill-defined because it does not respond to features of external stimuli in a consistent way (<xref ref-type="bibr" rid="bib3">Andrews-Hanna et al., 2014</xref>; <xref ref-type="bibr" rid="bib7">Buckner et al., 2008</xref>; <xref ref-type="bibr" rid="bib23">Golland et al., 2007</xref>). Although default system activity during movie watching and in the resting state is idiosyncratic, it is highly correlated across default areas (<xref ref-type="bibr" rid="bib7">Buckner et al., 2008</xref>; <xref ref-type="bibr" rid="bib23">Golland et al., 2007</xref>) and has a fine-scale structure that can be modeled with hyperalignment (<xref ref-type="bibr" rid="bib16">Feilong et al., 2018</xref>; <xref ref-type="bibr" rid="bib27">Guntupalli et al., 2018</xref>), indicating that this activity has structure and meaning. It has been associated with thinking about others’ mental states (<xref ref-type="bibr" rid="bib7">Buckner et al., 2008</xref>; <xref ref-type="bibr" rid="bib18">Frith and Frith, 1999</xref>; <xref ref-type="bibr" rid="bib21">Gobbini et al., 2007</xref>; <xref ref-type="bibr" rid="bib49">Saxe and Kanwisher, 2003</xref>), activation of person knowledge about familiar others (<xref ref-type="bibr" rid="bib22">Gobbini and Haxby, 2007</xref>), autobiographical memory and envisioning the future (<xref ref-type="bibr" rid="bib1">Addis et al., 2007</xref>), as well as other aspects of internally driven cognition. The most predictive regions overlapped only a portion of the default network involving primarily the dorsal medial subsystem with smaller parts in the core subsystem (<xref ref-type="bibr" rid="bib3">Andrews-Hanna et al., 2014</xref>; <xref ref-type="bibr" rid="bib2">Andrews-Hanna et al., 2010</xref>). The dorsal medial subsystem has been associated with mentalizing, social cognition, story comprehension, and semantic conceptual processing (<xref ref-type="bibr" rid="bib3">Andrews-Hanna et al., 2014</xref>).</p><p>The frontoparietal system may similarly reflect the role of self-directed thought in the neural basis of general intelligence. <xref ref-type="bibr" rid="bib13">Dixon et al., 2018</xref> have identified a subdivision of the frontoparietal network that interacts primarily with the default mode system. They propose that this part of the frontoparietal system is involved in the regulation of introspective processes.</p><p>The efficiency of the default system apparently rests more on fine-grained features of its functional connectivity than on coarse-grained functional connectivity. The bases for the organization of its fine-grained topographies and the transformations of representational geometries between default regions are unknown, but the keys to understanding the neural basis of intelligent thought may reside in the information processing embedded in these topographies.</p></sec><sec id="s4" sec-type="materials|methods"><title>Materials and methods</title><sec id="s4-1"><title>Dataset</title><p>We used data from the Human Connectome Project (HCP) (<xref ref-type="bibr" rid="bib55">Van Essen et al., 2013</xref>) for our analysis. The final S1200 data release of the HCP Young Adult dataset contains multimodal MR imaging and behavioral data from 1206 participants that are 22–35 years old. This includes about 1 hr of resting-state fMRI data (four runs, 14.5 min each), 47 min of task fMRI data (seven tasks, two runs each), and extensive cognitive tests for each participant. Out of the 1206 participants, 888 have complete task and resting fMRI data, 1181 have complete scores of 10 cognitive tests, and 876 participants have both. In our analysis, we always used as many participants with complete data as possible to maximize statistical power. That is, we used data from the 1181 participants to derive the general intelligence score, data from the 888 participants to derive hyperalignment models and compute topographic idiosyncrasy, and data from the overlapping 876 participants for prediction analysis.</p><p>We used a multimodal cortical parcellation tailored to this dataset (<xref ref-type="bibr" rid="bib20">Glasser et al., 2016</xref>) to delineate cortical regions and compute connectivity targets for hyperalignment as described below. This parcellation is usually labeled as ‘Q1-Q6_RelatedParcellation210’ or ‘210P’ in the HCP dataset, and sometimes referred to as HCP MMP 1.0.</p></sec><sec id="s4-2"><title>Measuring general intelligence</title><p>General intelligence is a common factor, often referred to as <italic>g</italic>, underlying all cognitive abilities (<xref ref-type="bibr" rid="bib53">Spearman, 1904</xref>). In this study, we measured general intelligence as the general factor obtained based on 10 cognitive test scores using a factor analysis with a bi-factor model (<xref ref-type="bibr" rid="bib14">Dubois et al., 2018</xref>). These cognitive tests (<xref ref-type="bibr" rid="bib4">Barch et al., 2013</xref>) include those from the NIH Toolbox for Assessment of Neurological and Behavioral Function (<ext-link ext-link-type="uri" xlink:href="http://www.nihtoolbox.org">http://www.nihtoolbox.org</ext-link>) and additional computerized tests (<xref ref-type="bibr" rid="bib6">Bilker et al., 2012</xref>; <xref ref-type="bibr" rid="bib28">Gur et al., 2010</xref>), covering a range of memory, attention, language, and reasoning abilities. General intelligence can be accurately and consistently identified through different test batteries (<xref ref-type="bibr" rid="bib38">Johnson et al., 2008</xref>; <xref ref-type="bibr" rid="bib37">Johnson et al., 2004</xref>), and our findings are robust over choices of intelligence measures (<xref ref-type="fig" rid="app1fig6">Appendix 1—figures 6</xref> and <xref ref-type="fig" rid="app1fig7">7</xref>). For this dataset, the general factor of intelligence was derived from the code of <xref ref-type="bibr" rid="bib14">Dubois et al., 2018</xref>, and it accounts for 58% of the covariance structure of cognitive tasks (<xref ref-type="bibr" rid="bib14">Dubois et al., 2018</xref>).</p></sec><sec id="s4-3"><title>MRI acquisition</title><p>MRI data were acquired with a Siemens 3 T Skyra MRI scanner and a 32-channel head coil at Washington University (<xref ref-type="bibr" rid="bib55">Van Essen et al., 2013</xref>). The scanner was customized with a gradient coil and gradient power. Each subject has 2 T1w and 2 T2w scans with 0.7 mm isotropic voxels, which were used to reconstruct high-resolution cortical surfaces.</p><p>Functional MRI data were acquired with a repetition time (TR) of 0.72 s, 2 mm isotropic voxels, and a multi-band acceleration factor of 8. Every volume comprised 72 slices with 208 × 180 mm<sup>2</sup> field of view each. Half of the fMRI runs were scanned with the LR phase encoding direction, and the other half were with RL. Spin-echo field maps were collected along with the fMRI data that allow susceptibility distortion correction.</p><p>Resting fMRI data were acquired with four runs of 1200 TRs each. Each of the seven tasks were acquired with two runs, and the duration of each run varied across tasks (min: 176 TRs; max: 405 TRs). In total, for each participant, 57.6 min of resting fMRI data and 46.6 min of task fMRI data were acquired. See <xref ref-type="bibr" rid="bib54">Uğurbil et al., 2013</xref> for additional details of MRI acquisition.</p></sec><sec id="s4-4"><title>MRI preprocessing</title><p>We used the same standard procedure to preprocess fMRI data for all task and resting fMRI data. Our preprocessing was based on the minimally preprocessed version of the dataset (<xref ref-type="bibr" rid="bib19">Glasser et al., 2013</xref>), where data had been corrected for distortion and head motion, and aligned to a standard cortical surface mesh using MSM (<xref ref-type="bibr" rid="bib48">Robinson et al., 2014</xref>), which aims to match multimodal properties across individuals while preserving topology. These data were labeled as ‘MSMAll’ in the HCP data files, and we refer to them as ‘MSM’ for short.</p><p>We first normalized all fMRI data to percent signal change units, then used linear regression to remove nuisance components from them. These nuisance components include six motion parameters and their derivatives, five principal components from white matter and cerebrospinal fluid (<xref ref-type="bibr" rid="bib5">Behzadi et al., 2007</xref>), global signal, and polynomial trends up to the third order. The white matter and cerebrospinal fluid components were extracted from volumetric data based on eroded anatomical masks. Both the regressors and data were low-pass filtered with a Gaussian kernel (standard deviation = 1 TR) prior to regression. These preprocessing steps were analogous to previous work (<xref ref-type="bibr" rid="bib14">Dubois et al., 2018</xref>; <xref ref-type="bibr" rid="bib17">Finn et al., 2015</xref>; <xref ref-type="bibr" rid="bib24">Greene et al., 2018</xref>; <xref ref-type="bibr" rid="bib51">Shen et al., 2017</xref>).</p></sec><sec id="s4-5"><title>Hyperalignment</title><p>We performed hyperalignment using these preprocessed data to align the fine-grained cortical functional architecture across individuals and obtained two sets of hyperaligned data (one based on task fMRI data, one based on resting fMRI data) besides the original MSM-aligned dataset. Specifically, we used connectivity hyperalignment (<xref ref-type="bibr" rid="bib27">Guntupalli et al., 2018</xref>) to align fine-grained cortical functional architecture across individuals. We used regional average time series of the 360-region multimodal cortical parcellation (<xref ref-type="bibr" rid="bib20">Glasser et al., 2016</xref>) as connectivity targets. For each of the 59,412 cortical vertices, we computed its connectivity profile as the correlations between its own time series and the 360 regional average time series. Therefore, each connectivity profile is a vector comprising 360 correlation coefficients. In each brain region, we derived a transformation matrix for each individual using these connectivity profiles, which remixes each individual's vertices into a common set of model dimensions through an improper rotation of a high-dimensional space. Each model dimension has similar functional properties across individuals instead of the same anatomical position, and these model dimensions together constitute a common model space. The common model space is usually instantiated as a reference brain, where each vertex corresponds to a model dimension. The information content in each individual's data—the configuration of connectivity vectors in the high-dimensional feature space—is perfectly preserved during the rotation, whereas how and where this information is encoded in idiosyncratic topographies is factored out into the transformation matrix.</p><p>In this study, hyperalignment was performed for each brain region separately (i.e., in a similar manner to <xref ref-type="bibr" rid="bib31">Haxby et al., 2011</xref> rather than <xref ref-type="bibr" rid="bib25">Guntupalli et al., 2016</xref>), and the transformation was constrained to be an improper rotation (i.e., rotation that allows reflection) with no scaling. This was to strictly ensure that the information content within a brain region was identical before and after hyperalignment, and only the cortical topography of the information was changed (i.e., better aligned). Searchlight hyperalignment (<xref ref-type="bibr" rid="bib25">Guntupalli et al., 2016</xref>) allows information to be moved in and out of a brain region to some extent, which is preferable in general because the same function does not always reside in the same anatomical region for all participants (<xref ref-type="bibr" rid="bib15">Eickhoff et al., 2018</xref>). However, in this case it can make it difficult to interpret the results. For example, an improvement of prediction performance after searchlight hyperalignment can be caused by better alignment of information in a region, but it can also be caused by additional information moved into the region or noise moved out of the region.</p><p>We used the HCP task fMRI dataset to derive the hyperalignment common model and transformations (i.e., to train hyperalignment) when we analyzed the task fMRI data, and resting fMRI dataset when we analyzed the resting fMRI data. Therefore, the task and resting fMRI datasets remain independent throughout the analysis. It is possible to train hyperalignment using one dataset and apply it to another, and such results are summarized in <xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>.</p></sec><sec id="s4-6"><title>Functional connectivity profiles</title><p>We used functional connectivity profiles to depict a brain region's functional interactions with the entire cerebral cortex. These connectivity profiles are different from the connectivity profiles used in connectivity hyperalignment as described above.</p><p>For each of 360 cortical regions, we computed a fine-grained connectivity matrix for each participant (<xref ref-type="fig" rid="fig1">Figure 1</xref>, top row), which comprises pairwise interactions between all vertices in the region (165 vertices on average) and all vertices of the cerebral cortex (59,412 vertices). We vectorized this connectivity matrix to form a long vector comprising millions of connectivity strengths (9.8 million on average across all regions), which we refer to as the participant's full fine-grained connectivity profile of the region. This fine-grained connectivity profile depicts in detail the region's information exchange with the rest of the cortex, and it contains information encoded in fine-grained connectivity patterns up to the same resolution as the input fMRI data (2 mm for this dataset).</p><p>To separate information encoded in different spatial scales, we split the full fine-grained connectivity profile into a coarse-grained connectivity profile and a residual fine-grained connectivity profile. The coarse-grained connectivity profile for a given region is a vector comprising 360 elements, where each element is the average connectivity strength between all cortical vertices in this region and all vertices in another region (<xref ref-type="fig" rid="fig1">Figure 1</xref>, middle row). Similar to previous work (<xref ref-type="bibr" rid="bib14">Dubois et al., 2018</xref>; <xref ref-type="bibr" rid="bib17">Finn et al., 2015</xref>; <xref ref-type="bibr" rid="bib51">Shen et al., 2017</xref>), coarse-grained connectivity profiles depict the information exchange between a pair of regions with a single connectivity strength. A residual fine-grained connectivity profile comprises pattern residuals obtained by subtracting the mean connectivity with each region (an element of the coarse-grained connectivity profile) from each element of the vertex-by-vertex connectivity pattern with the region (part of the full fine-grained connectivity profile). Because a coarse-grained connectivity profile comprises region-by-region averages of the corresponding fine-grained connectivity profile, a regression model using coarse-grained connectivity profile (expanded to the same size as the fine-grained connectivity profile) as the independent variable and fine-grained connectivity profile as the dependent variable will always have a slope of 1. Therefore, the difference between the two profiles is also the residual of the regression model. Similar to a full fine-grained connectivity profile, a residual fine-grained connectivity profile comprises millions of elements, and the only difference is that these elements are connectivity residuals instead of connectivities. In other words, a residual fine-grained connectivity profile contains only fine-scale information instead of combined fine- and coarse-scale information.</p><p>The analysis involves data aligned in three different ways: MSM, hyperalignment based on task fMRI data, and hyperalignment based on resting fMRI data. For each alignment method, we computed these three kinds of connectivity profiles for each participant and each region. The results of fine-grained connectivity profiles reported in the main text are based on residual fine-grained connectivity profiles, and similar results were obtained using full fine-grained connectivity profiles (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>).</p></sec><sec id="s4-7"><title>Topographic idiosyncrasy</title><p>We measured the level of each region's functional topographic idiosyncrasy as the average dissimilarity of hyperalignment transformation matrices across participant pairs for that region, after correcting for region size. Specifically, for each brain region, we computed the Frobenius norm of the difference between the two transformation matrices for each pair of participants and averaged it across all participant pairs to obtain an average matrix dissimilarity (i.e., average difference matrix norm) for the region. The 360 cortical regions differ in size (measured as the number of vertices in each region). As a result, transformation matrices also differ in size for different regions, and the average matrix norm was predominantly determined by region size. Across all 360 regions, the average matrix norm and the square root of region size had a correlation of <italic>r</italic> &gt; 0.9999. To remove the confounding effects of region size, we fit a linear regression model across the 360 regions using sqrt(region size) as the independent variable and the average matrix dissimilarity as the dependent variable. We used the residual of the linear regression model to depict the heterogeneity of a region's functional topography across individuals.</p><p>We performed hyperalignment twice in our analysis—once using task fMRI data, once using resting fMRI data—and therefore obtained two sets of transformation matrices for each region. Topographic idiosyncrasy indices based on each of the two sets are essentially identical (<italic>r</italic> = 0.960, <italic>p </italic>= 4 × 10<sup>−200</sup>). When we analyzed task fMRI data, we used topographic idiosyncrasy based on task fMRI (<xref ref-type="fig" rid="fig5">Figure 5C</xref>), and when we analyzed resting fMRI data, we used that based on resting fMRI (<xref ref-type="fig" rid="fig5">Figure 5D</xref>).</p></sec><sec id="s4-8"><title>Cross-validation scheme</title><p>We used leave-one-family-out cross-validation (<xref ref-type="bibr" rid="bib14">Dubois et al., 2018</xref>) to assess prediction models. The 876 participants were from 411 families, and each family had 2.13 members on average (range: 1–5; with 103 participants with no other family members and 177, 107, 22, and 2 families with 2–5 participants, respectively). Therefore, this cross-validation scheme divided the entire dataset into 411 folds. Each time we leave out a family of <italic>k</italic> individuals (i.e., related to each other) as test data, and use the remaining 876 - <italic>k</italic> individuals (i.e., not related to test participants) as training data to train the model. We repeated this procedure, each time using a different family as test data. Therefore, after looping through all families, each individual's general intelligence score was predicted by a model trained with unrelated individuals.</p><p>For each cross-validation fold (i.e., each family as test data), we further split the training data into three sub-folds and used nested cross-validation to choose the optimal model parameters. In other words, model parameters were always chosen based only on training data.</p><p>To test the robustness of our prediction models against particular ways of splitting data, we replicated our analysis using an alternative cross-validation scheme. Instead of the leave-one-family-out cross-validation, we repeated tenfold cross-validation 50 times, and each time the data was split randomly into 10 chunks in a different way. To accommodate the family structure of the dataset, we ensured that each time individuals from the same family were always in the same chunk. The average model performance across the 50 repetitions was highly similar to that based on leave-one-family-out cross-validation across all regions and connectivity profile types (<xref ref-type="fig" rid="app1fig8">Appendix 1—figure 8</xref>), suggesting that our prediction model performance evaluation was accurate and unbiased.</p></sec><sec id="s4-9"><title>Regression models</title><p>We used principal component regression with ridge regularization to predict general intelligence based on functional connectivity. First, we used principal component analysis (PCA) to derive principal components (PCs) from functional connectivity patterns based on training data. Dimensions in the PC space capture principal ways that individuals’ connectivity profiles differ. Thus, the connectivity profile for a region in each training set participant was transformed into a set of scores across PC dimensions. Then, we trained a ridge regression model to predict general intelligence based on these PC scores. The PCA and ridge regression models were then applied to test data to obtain the model predicted general intelligence scores. Model parameters (the number of PCs and the regularization parameter) were always chosen using nested cross-validation as stated above. Candidate model parameters were distributed evenly on a logarithmic scale. Choices for the number of PCs were 10, 20, 40, 80, 160, 320, and all PCs (i.e., no dimensionality reduction). The maximum number of PCs was usually 360 for coarse-grained connectivity profile and 876k for fine-grained connectivity profile. Choices for the regularization parameter α were 81 values from 10<sup>−20</sup> to 10<sup>20</sup>.</p></sec><sec id="s4-10"><title>Model evaluation</title><p>We evaluated our models using the cross-validated coefficient of determination (<italic>R</italic><sup>2</sup>). <italic>R</italic><sup>2</sup> denotes the percent of variance in general intelligence that was accounted for (VAF) by prediction models. The formula is<disp-formula id="equ1"><mml:math id="m1"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msup><mml:mi>R</mml:mi><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>−</mml:mo><mml:mfrac><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:msub><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:munder><mml:mo>∑</mml:mo><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>−</mml:mo><mml:mtext> </mml:mtext><mml:msub><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">¯</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mtext> </mml:mtext><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:math></disp-formula>where <inline-formula><mml:math id="inf1"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the measured score for subject <italic>i</italic>, <inline-formula><mml:math id="inf2"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mi>y</mml:mi><mml:mo stretchy="false">^</mml:mo></mml:mover></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mstyle></mml:math></inline-formula> is the model predicted score for subject <italic>i</italic>, and <inline-formula><mml:math id="inf3"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>¯</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is the prediction by the null model. The prediction of the null model is simply the average score of all training data, and thus it does not use any information from the features (fine- or coarse-grained functional connectivity in this case) at all. <italic>R</italic><sup>2</sup> maximizes at 100%, which means perfect prediction; 0 means model performance is only the same as the null model. In rare cases, cross-validated <italic>R</italic><sup>2</sup> can also be negative, which suggests the model performance is even worse than the null model.</p><p>To assess model performance against chance, we used permutation testing to create a null distribution of <italic>R</italic><sup>2</sup>. The HCP dataset has subjects that are from the same family, and they are more likely to have similar general intelligence scores compared with non-related subjects (<xref ref-type="bibr" rid="bib45">Plomin and Deary, 2015</xref>). Therefore, the subject labels are not fully exchangeable, and we used multi-level block permutation (<xref ref-type="bibr" rid="bib57">Winkler et al., 2015</xref>) to resolve the issue. With this hierarchical permutation approach, the data exchangeability is properly modeled, providing more accurate estimates of false positive rates.</p><p>For each of the 2160 conditions (360 brain regions × 3 connectivity profile types × 2 fMRI data types), we ran a permutation test by training and evaluating prediction models 100 times based on shuffled subject labels. Each time, we permuted general intelligence scores across the entire dataset in the beginning and re-ran the entire prediction pipeline with these permuted scores. That is, for each cross-validation fold, we chose the optimized parameters using a nested cross-validation based on the training participants and their permuted scores, and used these parameters to train a new model based on the entire training set, which was used to predict the scores of the left-out family. After looping through all cross-validation folds (i.e., all families), we assessed model performance based on the permuted scores. In other words, we repeated the entire process—including parameter optimization, prediction, and model evaluation—using permuted general intelligence score as the target variable instead of the original general intelligence score.</p><p>Across conditions (<xref ref-type="fig" rid="app1fig4">Appendix 1—figure 4</xref>), the maximum <italic>R</italic><sup>2</sup> of all 100 permutations was less than the value obtained with the prediction model (i.e., <italic>p</italic> &lt; 0.01) for all models based on hyperaligned fine-grained connectivity or on MSM-aligned fine-grained task connectivity and for all models based on coarse-scale connectivity or on MSM-aligned fine-grained resting connectivity that had an <italic>R</italic><sup>2</sup> over 1.3%.</p></sec><sec id="s4-11"><title>Estimating confidence intervals</title><p>We used bootstrap tests to estimate confidence intervals (CIs) for contrasts between VAF by different prediction models. In each of the 1,000,000 repetitions, we randomly sampled a group of 876 individuals used for model evaluation by sampling with replacement from the 876 original individuals. In other words, in each bootstrapped sample, a participant might be selected once, multiple times, or not selected at all. For each bootstrapped sample, we computed VAF differences and VAF ratios. The 95% CI of a difference or ratio is estimated as the 2.5th and 97.5th percentiles of the difference or ratio from the bootstrapped samples (i.e., the sampling distribution of the difference or ratio estimated by bootstrapping participants). The bootstrapping procedure used here only affects the participants used for model evaluation (i.e., the test set), and the model used to predict a participant's score was always trained with the same training set (i.e., participants who are not from the same family as the test participant). This was because prediction performance depends on training sample size (<xref ref-type="fig" rid="app1fig8">Appendix 1—figure 8</xref>), and duplicate instances in the training data do not have the same effect on machine learning algorithms as ‘real’ new data (e.g., noise from two duplicate instances are not independent), which makes the bootstrapped sample no longer representative of the population. Therefore, we only bootstrapped the participants used for model evaluation, so that the sampling distribution is not biased by training sample size or dependency.</p></sec><sec id="s4-12"><title>Pearson correlation</title><p>We used the Pearson correlation coefficient to assess the relationship between regional topographic idiosyncrasy and the difference in prediction performance based on hyperaligned and MSM-aligned data (<xref ref-type="fig" rid="fig5">Figure 5</xref>C, D), and the relationship between the square root of a region's size and the average transformation matrix dissimilarity. In both cases, <italic>n</italic> (the number of regions) is always 360, and the degrees of freedom is always 358.</p></sec><sec id="s4-13"><title>Dice coefficient</title><p>We used the <xref ref-type="bibr" rid="bib12">Dice, 1945</xref> similarity coefficient to quantify the amount of overlap between the 30 most predictive regions based on task fMRI data and those based on resting fMRI data. The formula is<disp-formula id="equ2"><mml:math id="m2"><mml:mrow><mml:mi>D</mml:mi><mml:mi>S</mml:mi><mml:mi>C</mml:mi><mml:mo> </mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mrow><mml:mo>|</mml:mo> <mml:mrow><mml:mi>A</mml:mi><mml:mo>∩</mml:mo><mml:mi>B</mml:mi></mml:mrow> <mml:mo>|</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo>|</mml:mo> <mml:mi>A</mml:mi> <mml:mo>|</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:mo>|</mml:mo> <mml:mi>B</mml:mi> <mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:math></disp-formula>where <italic>A</italic> is the set of vertices covered by the 30 most predictive regions based on task fMRI data, and <italic>B</italic> is that based on resting fMRI data. |⋅| denotes set cardinality. <italic>DSC</italic> is short for Dice similarity coefficient.</p></sec><sec id="s4-14"><title>Overlap with cortical systems</title><p>The cerebral cortex can be divided into seven cortical systems based on functional connectivity (<xref ref-type="bibr" rid="bib58">Yeo et al., 2011</xref>). For each of the 360 regions, we computed the percentage of vertices belonging to each of the seven systems as the number of vertices belonging to the system divided by the total number of vertices in the region. For the 30 most predictive regions, we computed the percentage of vertices across all 30 regions that belonged to each system (<xref ref-type="fig" rid="fig3">Figure 3E, Figure 4E</xref>). Similar results were found with an alternative division into 12 cortical systems by <xref ref-type="bibr" rid="bib34">Ji et al., 2019</xref> (see <xref ref-type="fig" rid="app1fig11">Appendix 1—figure 11</xref>). In the scatterplots (<xref ref-type="fig" rid="fig3">Figure 3C, Figure 4C</xref>), each region was assigned to one of the cortical systems, which is the system that had the largest amount of vertices in the region.</p></sec><sec id="s4-15"><title>Software used</title><p>We implemented our analysis using Python and Python packages including NumPy (<ext-link ext-link-type="uri" xlink:href="https://numpy.org/">https://numpy.org/</ext-link>), SciPy (<ext-link ext-link-type="uri" xlink:href="https://www.scipy.org/">https://www.scipy.org/</ext-link>), and NiBabel (<ext-link ext-link-type="uri" xlink:href="https://nipy.org/nibabel/">https://nipy.org/nibabel/</ext-link>). The code for performing hyperalignment and nuisance regression was adapted from PyMVPA (<ext-link ext-link-type="uri" xlink:href="http://www.pymvpa.org/">http://www.pymvpa.org/</ext-link>) (<xref ref-type="bibr" rid="bib29">Hanke et al., 2009</xref>).</p></sec></sec></body><back><ack id="ack"><title>Acknowledgements</title><p>We thank Guo Jiahui, Samuel Nastase, Jeremy Huckins, and Maria Ida Gobbini for helpful comments, suggestions, and discussion. We also thank Yaroslav Halchenko for support with software. Data were provided by the Human Connectome Project, WU-Minn Consortium (principal investigators: David Van Essen and Kamil Ugurbil; 1U54MH091657) funded by the 16 NIH Institutes and Centers that support the NIH Blueprint for Neuroscience Research; and by the McDonnell Center for Systems Neuroscience at Washington University. This work was supported with funds from NSF grants 1607845 and 1835200.</p></ack><sec id="s5" sec-type="additional-information"><title>Additional information</title><fn-group content-type="competing-interest"><title>Competing interests</title><fn fn-type="COI-statement" id="conf1"><p>No competing interests declared</p></fn></fn-group><fn-group content-type="author-contribution"><title>Author contributions</title><fn fn-type="con" id="con1"><p>Conceptualization, Software, Formal analysis, Validation, Visualization, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con2"><p>Conceptualization, Software, Methodology, Writing - original draft, Writing - review and editing</p></fn><fn fn-type="con" id="con3"><p>Conceptualization, Funding acquisition, Visualization, Methodology, Writing - original draft, Project administration, Writing - review and editing</p></fn></fn-group><fn-group content-type="ethics-information"><title>Ethics</title><fn fn-type="other"><p>Human subjects: Human research participants in the Human Connectome Project gave written informed consent for their participation in accordance with guidelines at participating institutions.</p></fn></fn-group></sec><sec id="s6" sec-type="supplementary-material"><title>Additional files</title><supplementary-material id="transrepform"><label>Transparent reporting form</label><media mime-subtype="docx" mimetype="application" xlink:href="elife-64058-transrepform-v2.docx"/></supplementary-material></sec><sec id="s7" sec-type="data-availability"><title>Data availability</title><p>The Human Connectome Project data can be downloaded from its database (<ext-link ext-link-type="uri" xlink:href="https://db.humanconnectome.org/data/projects/HCP_1200">https://db.humanconnectome.org/data/projects/HCP_1200</ext-link>). Code for the analysis is available at (<ext-link ext-link-type="uri" xlink:href="https://github.com/feilong/IDM_pred">https://github.com/feilong/IDM_pred</ext-link> copy archived at <ext-link ext-link-type="uri" xlink:href="https://archive.softwareheritage.org/swh:1:rev:ab3f031ab42909774d02f770f4a94d6a2b045eff/">https://archive.softwareheritage.org/swh:1:rev:ab3f031ab42909774d02f770f4a94d6a2b045eff/</ext-link>.</p><p>The following previously published dataset was used:</p><p><element-citation id="dataset1" publication-type="data" specific-use="references"><person-group person-group-type="author"><name><surname>Van</surname><given-names>Essen DC</given-names></name><name><surname>Smith</surname><given-names>SM</given-names></name><name><surname>Barch</surname><given-names>DM</given-names></name><name><surname>Behrens</surname><given-names>TEJ</given-names></name><name><surname>Yacoub</surname><given-names>E</given-names></name><name><surname>Ugurbil</surname><given-names>K</given-names></name><collab>WU-MinnHCP Consortium</collab></person-group><year iso-8601-date="2013">2013</year><data-title>Human Connectome Project</data-title><source>ConnectomeDB</source><pub-id assigning-authority="other" pub-id-type="accession" xlink:href="https://db.humanconnectome.org/data/projects/HCP_1200">S1200</pub-id></element-citation></p></sec><ref-list><title>References</title><ref id="bib1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Addis</surname> <given-names>DR</given-names></name><name><surname>Wong</surname> <given-names>AT</given-names></name><name><surname>Schacter</surname> <given-names>DL</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Remembering the past and imagining the future: common and distinct neural substrates during event construction and elaboration</article-title><source>Neuropsychologia</source><volume>45</volume><fpage>1363</fpage><lpage>1377</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2006.10.016</pub-id><pub-id pub-id-type="pmid">17126370</pub-id></element-citation></ref><ref id="bib2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andrews-Hanna</surname> <given-names>JR</given-names></name><name><surname>Reidler</surname> <given-names>JS</given-names></name><name><surname>Sepulcre</surname> <given-names>J</given-names></name><name><surname>Poulin</surname> <given-names>R</given-names></name><name><surname>Buckner</surname> <given-names>RL</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>Functional-anatomic fractionation of the brain's default network</article-title><source>Neuron</source><volume>65</volume><fpage>550</fpage><lpage>562</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2010.02.005</pub-id><pub-id pub-id-type="pmid">20188659</pub-id></element-citation></ref><ref id="bib3"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Andrews-Hanna</surname> <given-names>JR</given-names></name><name><surname>Smallwood</surname> <given-names>J</given-names></name><name><surname>Spreng</surname> <given-names>RN</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>The default network and self-generated thought: component processes, dynamic control, and clinical relevance</article-title><source>Annals of the New York Academy of Sciences</source><volume>1316</volume><fpage>29</fpage><lpage>52</lpage><pub-id pub-id-type="doi">10.1111/nyas.12360</pub-id><pub-id pub-id-type="pmid">24502540</pub-id></element-citation></ref><ref id="bib4"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barch</surname> <given-names>DM</given-names></name><name><surname>Burgess</surname> <given-names>GC</given-names></name><name><surname>Harms</surname> <given-names>MP</given-names></name><name><surname>Petersen</surname> <given-names>SE</given-names></name><name><surname>Schlaggar</surname> <given-names>BL</given-names></name><name><surname>Corbetta</surname> <given-names>M</given-names></name><name><surname>Glasser</surname> <given-names>MF</given-names></name><name><surname>Curtiss</surname> <given-names>S</given-names></name><name><surname>Dixit</surname> <given-names>S</given-names></name><name><surname>Feldt</surname> <given-names>C</given-names></name><name><surname>Nolan</surname> <given-names>D</given-names></name><name><surname>Bryant</surname> <given-names>E</given-names></name><name><surname>Hartley</surname> <given-names>T</given-names></name><name><surname>Footer</surname> <given-names>O</given-names></name><name><surname>Bjork</surname> <given-names>JM</given-names></name><name><surname>Poldrack</surname> <given-names>R</given-names></name><name><surname>Smith</surname> <given-names>S</given-names></name><name><surname>Johansen-Berg</surname> <given-names>H</given-names></name><name><surname>Snyder</surname> <given-names>AZ</given-names></name><name><surname>Van Essen</surname> <given-names>DC</given-names></name><collab>WU-Minn HCP Consortium</collab></person-group><year iso-8601-date="2013">2013</year><article-title>Function in the human connectome: task-fmri and individual differences in behavior</article-title><source>NeuroImage</source><volume>80</volume><fpage>169</fpage><lpage>189</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.033</pub-id><pub-id pub-id-type="pmid">23684877</pub-id></element-citation></ref><ref id="bib5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Behzadi</surname> <given-names>Y</given-names></name><name><surname>Restom</surname> <given-names>K</given-names></name><name><surname>Liau</surname> <given-names>J</given-names></name><name><surname>Liu</surname> <given-names>TT</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>A component based noise correction method (CompCor) for BOLD and perfusion based fMRI</article-title><source>NeuroImage</source><volume>37</volume><fpage>90</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.04.042</pub-id><pub-id pub-id-type="pmid">17560126</pub-id></element-citation></ref><ref id="bib6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bilker</surname> <given-names>WB</given-names></name><name><surname>Hansen</surname> <given-names>JA</given-names></name><name><surname>Brensinger</surname> <given-names>CM</given-names></name><name><surname>Richard</surname> <given-names>J</given-names></name><name><surname>Gur</surname> <given-names>RE</given-names></name><name><surname>Gur</surname> <given-names>RC</given-names></name></person-group><year iso-8601-date="2012">2012</year><article-title>Development of abbreviated nine-item forms of the raven's standard progressive matrices test</article-title><source>Assessment</source><volume>19</volume><fpage>354</fpage><lpage>369</lpage><pub-id pub-id-type="doi">10.1177/1073191112446655</pub-id><pub-id pub-id-type="pmid">22605785</pub-id></element-citation></ref><ref id="bib7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Buckner</surname> <given-names>RL</given-names></name><name><surname>Andrews-Hanna</surname> <given-names>JR</given-names></name><name><surname>Schacter</surname> <given-names>DL</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>The brain's default network: anatomy, function, and relevance to disease</article-title><source>Annals of the New York Academy of Sciences</source><volume>1124</volume><fpage>1</fpage><lpage>38</lpage><pub-id pub-id-type="doi">10.1196/annals.1440.011</pub-id><pub-id pub-id-type="pmid">18400922</pub-id></element-citation></ref><ref id="bib8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ciric</surname> <given-names>R</given-names></name><name><surname>Wolf</surname> <given-names>DH</given-names></name><name><surname>Power</surname> <given-names>JD</given-names></name><name><surname>Roalf</surname> <given-names>DR</given-names></name><name><surname>Baum</surname> <given-names>GL</given-names></name><name><surname>Ruparel</surname> <given-names>K</given-names></name><name><surname>Shinohara</surname> <given-names>RT</given-names></name><name><surname>Elliott</surname> <given-names>MA</given-names></name><name><surname>Eickhoff</surname> <given-names>SB</given-names></name><name><surname>Davatzikos</surname> <given-names>C</given-names></name><name><surname>Gur</surname> <given-names>RC</given-names></name><name><surname>Gur</surname> <given-names>RE</given-names></name><name><surname>Bassett</surname> <given-names>DS</given-names></name><name><surname>Satterthwaite</surname> <given-names>TD</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Benchmarking of participant-level confound regression strategies for the control of motion artifact in studies of functional connectivity</article-title><source>NeuroImage</source><volume>154</volume><fpage>174</fpage><lpage>187</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.03.020</pub-id><pub-id pub-id-type="pmid">28302591</pub-id></element-citation></ref><ref id="bib9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ciric</surname> <given-names>R</given-names></name><name><surname>Rosen</surname> <given-names>AFG</given-names></name><name><surname>Erus</surname> <given-names>G</given-names></name><name><surname>Cieslak</surname> <given-names>M</given-names></name><name><surname>Adebimpe</surname> <given-names>A</given-names></name><name><surname>Cook</surname> <given-names>PA</given-names></name><name><surname>Bassett</surname> <given-names>DS</given-names></name><name><surname>Davatzikos</surname> <given-names>C</given-names></name><name><surname>Wolf</surname> <given-names>DH</given-names></name><name><surname>Satterthwaite</surname> <given-names>TD</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Mitigating head motion artifact in functional connectivity MRI</article-title><source>Nature Protocols</source><volume>13</volume><fpage>2801</fpage><lpage>2826</lpage><pub-id pub-id-type="doi">10.1038/s41596-018-0065-y</pub-id><pub-id pub-id-type="pmid">30446748</pub-id></element-citation></ref><ref id="bib10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Connolly</surname> <given-names>AC</given-names></name><name><surname>Sha</surname> <given-names>L</given-names></name><name><surname>Guntupalli</surname> <given-names>JS</given-names></name><name><surname>Oosterhof</surname> <given-names>N</given-names></name><name><surname>Halchenko</surname> <given-names>YO</given-names></name><name><surname>Nastase</surname> <given-names>SA</given-names></name><name><surname>di Oleggio Castello</surname> <given-names>MV</given-names></name><name><surname>Abdi</surname> <given-names>H</given-names></name><name><surname>Jobst</surname> <given-names>BC</given-names></name><name><surname>Gobbini</surname> <given-names>MI</given-names></name><name><surname>Haxby</surname> <given-names>JV</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>How the human brain represents perceived dangerousness or &quot;Predacity&quot; of Animals</article-title><source>The Journal of Neuroscience</source><volume>36</volume><fpage>5373</fpage><lpage>5384</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.3395-15.2016</pub-id><pub-id pub-id-type="pmid">27170133</pub-id></element-citation></ref><ref id="bib11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cox</surname> <given-names>SR</given-names></name><name><surname>Ritchie</surname> <given-names>SJ</given-names></name><name><surname>Fawns-Ritchie</surname> <given-names>C</given-names></name><name><surname>Tucker-Drob</surname> <given-names>EM</given-names></name><name><surname>Deary</surname> <given-names>IJ</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Structural brain imaging correlates of general intelligence in UK biobank</article-title><source>Intelligence</source><volume>76</volume><elocation-id>101376</elocation-id><pub-id pub-id-type="doi">10.1016/j.intell.2019.101376</pub-id><pub-id pub-id-type="pmid">31787788</pub-id></element-citation></ref><ref id="bib12"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dice</surname> <given-names>LR</given-names></name></person-group><year iso-8601-date="1945">1945</year><article-title>Measures of the amount of ecologic association between species</article-title><source>Ecology</source><volume>26</volume><fpage>297</fpage><lpage>302</lpage><pub-id pub-id-type="doi">10.2307/1932409</pub-id></element-citation></ref><ref id="bib13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dixon</surname> <given-names>ML</given-names></name><name><surname>De La Vega</surname> <given-names>A</given-names></name><name><surname>Mills</surname> <given-names>C</given-names></name><name><surname>Andrews-Hanna</surname> <given-names>J</given-names></name><name><surname>Spreng</surname> <given-names>RN</given-names></name><name><surname>Cole</surname> <given-names>MW</given-names></name><name><surname>Christoff</surname> <given-names>K</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Heterogeneity within the frontoparietal control network and its relationship to the default and dorsal attention networks</article-title><source>PNAS</source><volume>115</volume><fpage>E1598</fpage><lpage>E1607</lpage><pub-id pub-id-type="doi">10.1073/pnas.1715766115</pub-id><pub-id pub-id-type="pmid">29382744</pub-id></element-citation></ref><ref id="bib14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dubois</surname> <given-names>J</given-names></name><name><surname>Galdi</surname> <given-names>P</given-names></name><name><surname>Paul</surname> <given-names>LK</given-names></name><name><surname>Adolphs</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A distributed brain network predicts general intelligence from resting-state human neuroimaging data</article-title><source>Philosophical Transactions of the Royal Society B: Biological Sciences</source><volume>373</volume><elocation-id>20170284</elocation-id><pub-id pub-id-type="doi">10.1098/rstb.2017.0284</pub-id></element-citation></ref><ref id="bib15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eickhoff</surname> <given-names>SB</given-names></name><name><surname>Constable</surname> <given-names>RT</given-names></name><name><surname>Yeo</surname> <given-names>BTT</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Topographic organization of the cerebral cortex and brain cartography</article-title><source>NeuroImage</source><volume>170</volume><fpage>332</fpage><lpage>347</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2017.02.018</pub-id><pub-id pub-id-type="pmid">28219775</pub-id></element-citation></ref><ref id="bib16"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feilong</surname> <given-names>M</given-names></name><name><surname>Nastase</surname> <given-names>SA</given-names></name><name><surname>Guntupalli</surname> <given-names>JS</given-names></name><name><surname>Haxby</surname> <given-names>JV</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Reliable individual differences in fine-grained cortical functional architecture</article-title><source>NeuroImage</source><volume>183</volume><fpage>375</fpage><lpage>386</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.08.029</pub-id><pub-id pub-id-type="pmid">30118870</pub-id></element-citation></ref><ref id="bib17"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Finn</surname> <given-names>ES</given-names></name><name><surname>Shen</surname> <given-names>X</given-names></name><name><surname>Scheinost</surname> <given-names>D</given-names></name><name><surname>Rosenberg</surname> <given-names>MD</given-names></name><name><surname>Huang</surname> <given-names>J</given-names></name><name><surname>Chun</surname> <given-names>MM</given-names></name><name><surname>Papademetris</surname> <given-names>X</given-names></name><name><surname>Constable</surname> <given-names>RT</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Functional connectome fingerprinting: identifying individuals using patterns of brain connectivity</article-title><source>Nature Neuroscience</source><volume>18</volume><fpage>1664</fpage><lpage>1671</lpage><pub-id pub-id-type="doi">10.1038/nn.4135</pub-id><pub-id pub-id-type="pmid">26457551</pub-id></element-citation></ref><ref id="bib18"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frith</surname> <given-names>CD</given-names></name><name><surname>Frith</surname> <given-names>U</given-names></name></person-group><year iso-8601-date="1999">1999</year><article-title>Interacting minds--a biological basis</article-title><source>Science</source><volume>286</volume><fpage>1692</fpage><lpage>1695</lpage><pub-id pub-id-type="doi">10.1126/science.286.5445.1692</pub-id><pub-id pub-id-type="pmid">10576727</pub-id></element-citation></ref><ref id="bib19"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasser</surname> <given-names>MF</given-names></name><name><surname>Sotiropoulos</surname> <given-names>SN</given-names></name><name><surname>Wilson</surname> <given-names>JA</given-names></name><name><surname>Coalson</surname> <given-names>TS</given-names></name><name><surname>Fischl</surname> <given-names>B</given-names></name><name><surname>Andersson</surname> <given-names>JL</given-names></name><name><surname>Xu</surname> <given-names>J</given-names></name><name><surname>Jbabdi</surname> <given-names>S</given-names></name><name><surname>Webster</surname> <given-names>M</given-names></name><name><surname>Polimeni</surname> <given-names>JR</given-names></name><name><surname>Van Essen</surname> <given-names>DC</given-names></name><name><surname>Jenkinson</surname> <given-names>M</given-names></name><collab>WU-Minn HCP Consortium</collab></person-group><year iso-8601-date="2013">2013</year><article-title>The minimal preprocessing pipelines for the human connectome project</article-title><source>NeuroImage</source><volume>80</volume><fpage>105</fpage><lpage>124</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.04.127</pub-id><pub-id pub-id-type="pmid">23668970</pub-id></element-citation></ref><ref id="bib20"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Glasser</surname> <given-names>MF</given-names></name><name><surname>Coalson</surname> <given-names>TS</given-names></name><name><surname>Robinson</surname> <given-names>EC</given-names></name><name><surname>Hacker</surname> <given-names>CD</given-names></name><name><surname>Harwell</surname> <given-names>J</given-names></name><name><surname>Yacoub</surname> <given-names>E</given-names></name><name><surname>Ugurbil</surname> <given-names>K</given-names></name><name><surname>Andersson</surname> <given-names>J</given-names></name><name><surname>Beckmann</surname> <given-names>CF</given-names></name><name><surname>Jenkinson</surname> <given-names>M</given-names></name><name><surname>Smith</surname> <given-names>SM</given-names></name><name><surname>Van Essen</surname> <given-names>DC</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A multi-modal parcellation of human cerebral cortex</article-title><source>Nature</source><volume>536</volume><fpage>171</fpage><lpage>178</lpage><pub-id pub-id-type="doi">10.1038/nature18933</pub-id><pub-id pub-id-type="pmid">27437579</pub-id></element-citation></ref><ref id="bib21"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gobbini</surname> <given-names>MI</given-names></name><name><surname>Koralek</surname> <given-names>AC</given-names></name><name><surname>Bryan</surname> <given-names>RE</given-names></name><name><surname>Montgomery</surname> <given-names>KJ</given-names></name><name><surname>Haxby</surname> <given-names>JV</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Two takes on the social brain: a comparison of theory of mind tasks</article-title><source>Journal of Cognitive Neuroscience</source><volume>19</volume><fpage>1803</fpage><lpage>1814</lpage><pub-id pub-id-type="doi">10.1162/jocn.2007.19.11.1803</pub-id><pub-id pub-id-type="pmid">17958483</pub-id></element-citation></ref><ref id="bib22"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gobbini</surname> <given-names>MI</given-names></name><name><surname>Haxby</surname> <given-names>JV</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Neural systems for recognition of familiar faces</article-title><source>Neuropsychologia</source><volume>45</volume><fpage>32</fpage><lpage>41</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2006.04.015</pub-id><pub-id pub-id-type="pmid">16797608</pub-id></element-citation></ref><ref id="bib23"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Golland</surname> <given-names>Y</given-names></name><name><surname>Bentin</surname> <given-names>S</given-names></name><name><surname>Gelbard</surname> <given-names>H</given-names></name><name><surname>Benjamini</surname> <given-names>Y</given-names></name><name><surname>Heller</surname> <given-names>R</given-names></name><name><surname>Nir</surname> <given-names>Y</given-names></name><name><surname>Hasson</surname> <given-names>U</given-names></name><name><surname>Malach</surname> <given-names>R</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Extrinsic and intrinsic systems in the posterior cortex of the human brain revealed during natural sensory stimulation</article-title><source>Cerebral Cortex</source><volume>17</volume><fpage>766</fpage><lpage>777</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhk030</pub-id></element-citation></ref><ref id="bib24"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Greene</surname> <given-names>AS</given-names></name><name><surname>Gao</surname> <given-names>S</given-names></name><name><surname>Scheinost</surname> <given-names>D</given-names></name><name><surname>Constable</surname> <given-names>RT</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>Task-induced brain state manipulation improves prediction of individual traits</article-title><source>Nature Communications</source><volume>9</volume><fpage>1</fpage><lpage>13</lpage><pub-id pub-id-type="doi">10.1038/s41467-018-04920-3</pub-id></element-citation></ref><ref id="bib25"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guntupalli</surname> <given-names>JS</given-names></name><name><surname>Hanke</surname> <given-names>M</given-names></name><name><surname>Halchenko</surname> <given-names>YO</given-names></name><name><surname>Connolly</surname> <given-names>AC</given-names></name><name><surname>Ramadge</surname> <given-names>PJ</given-names></name><name><surname>Haxby</surname> <given-names>JV</given-names></name></person-group><year iso-8601-date="2016">2016</year><article-title>A model of representational spaces in human cortex</article-title><source>Cerebral Cortex</source><volume>26</volume><fpage>2919</fpage><lpage>2934</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw068</pub-id><pub-id pub-id-type="pmid">26980615</pub-id></element-citation></ref><ref id="bib26"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guntupalli</surname> <given-names>JS</given-names></name><name><surname>Wheeler</surname> <given-names>KG</given-names></name><name><surname>Gobbini</surname> <given-names>MI</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Disentangling the representation of identity from head view along the human face processing pathway</article-title><source>Cerebral Cortex</source><volume>27</volume><fpage>46</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw344</pub-id><pub-id pub-id-type="pmid">28051770</pub-id></element-citation></ref><ref id="bib27"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guntupalli</surname> <given-names>JS</given-names></name><name><surname>Feilong</surname> <given-names>M</given-names></name><name><surname>Haxby</surname> <given-names>JV</given-names></name></person-group><year iso-8601-date="2018">2018</year><article-title>A computational model of shared fine-scale structure in the human connectome</article-title><source>PLOS Computational Biology</source><volume>14</volume><elocation-id>e1006120</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1006120</pub-id><pub-id pub-id-type="pmid">29664910</pub-id></element-citation></ref><ref id="bib28"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gur</surname> <given-names>RC</given-names></name><name><surname>Richard</surname> <given-names>J</given-names></name><name><surname>Hughett</surname> <given-names>P</given-names></name><name><surname>Calkins</surname> <given-names>ME</given-names></name><name><surname>Macy</surname> <given-names>L</given-names></name><name><surname>Bilker</surname> <given-names>WB</given-names></name><name><surname>Brensinger</surname> <given-names>C</given-names></name><name><surname>Gur</surname> <given-names>RE</given-names></name></person-group><year iso-8601-date="2010">2010</year><article-title>A cognitive neuroscience-based computerized battery for efficient measurement of individual differences: standardization and initial construct validation</article-title><source>Journal of Neuroscience Methods</source><volume>187</volume><fpage>254</fpage><lpage>262</lpage><pub-id pub-id-type="doi">10.1016/j.jneumeth.2009.11.017</pub-id><pub-id pub-id-type="pmid">19945485</pub-id></element-citation></ref><ref id="bib29"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hanke</surname> <given-names>M</given-names></name><name><surname>Halchenko</surname> <given-names>YO</given-names></name><name><surname>Sederberg</surname> <given-names>PB</given-names></name><name><surname>Hanson</surname> <given-names>SJ</given-names></name><name><surname>Haxby</surname> <given-names>JV</given-names></name><name><surname>Pollmann</surname> <given-names>S</given-names></name></person-group><year iso-8601-date="2009">2009</year><article-title>PyMVPA: a Python toolbox for multivariate pattern analysis of fMRI data</article-title><source>Neuroinformatics</source><volume>7</volume><fpage>37</fpage><lpage>53</lpage><pub-id pub-id-type="doi">10.1007/s12021-008-9041-y</pub-id><pub-id pub-id-type="pmid">19184561</pub-id></element-citation></ref><ref id="bib30"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haxby</surname> <given-names>JV</given-names></name><name><surname>Gobbini</surname> <given-names>MI</given-names></name><name><surname>Furey</surname> <given-names>ML</given-names></name><name><surname>Ishai</surname> <given-names>A</given-names></name><name><surname>Schouten</surname> <given-names>JL</given-names></name><name><surname>Pietrini</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>Distributed and overlapping representations of faces and objects in ventral temporal cortex</article-title><source>Science</source><volume>293</volume><fpage>2425</fpage><lpage>2430</lpage><pub-id pub-id-type="doi">10.1126/science.1063736</pub-id><pub-id pub-id-type="pmid">11577229</pub-id></element-citation></ref><ref id="bib31"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haxby</surname> <given-names>JV</given-names></name><name><surname>Guntupalli</surname> <given-names>JS</given-names></name><name><surname>Connolly</surname> <given-names>AC</given-names></name><name><surname>Halchenko</surname> <given-names>YO</given-names></name><name><surname>Conroy</surname> <given-names>BR</given-names></name><name><surname>Gobbini</surname> <given-names>MI</given-names></name><name><surname>Hanke</surname> <given-names>M</given-names></name><name><surname>Ramadge</surname> <given-names>PJ</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>A common, High-Dimensional model of the representational space in human ventral temporal cortex</article-title><source>Neuron</source><volume>72</volume><fpage>404</fpage><lpage>416</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2011.08.026</pub-id></element-citation></ref><ref id="bib32"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haxby</surname> <given-names>JV</given-names></name><name><surname>Connolly</surname> <given-names>AC</given-names></name><name><surname>Guntupalli</surname> <given-names>JS</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>Decoding neural representational spaces using multivariate pattern analysis</article-title><source>Annual Review of Neuroscience</source><volume>37</volume><fpage>435</fpage><lpage>456</lpage><pub-id pub-id-type="doi">10.1146/annurev-neuro-062012-170325</pub-id><pub-id pub-id-type="pmid">25002277</pub-id></element-citation></ref><ref id="bib33"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Haxby</surname> <given-names>JV</given-names></name><name><surname>Guntupalli</surname> <given-names>JS</given-names></name><name><surname>Nastase</surname> <given-names>SA</given-names></name><name><surname>Feilong</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Hyperalignment: modeling shared information encoded in idiosyncratic cortical topographies</article-title><source>eLife</source><volume>9</volume><elocation-id>e56601</elocation-id><pub-id pub-id-type="doi">10.7554/eLife.56601</pub-id><pub-id pub-id-type="pmid">32484439</pub-id></element-citation></ref><ref id="bib34"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ji</surname> <given-names>JL</given-names></name><name><surname>Spronk</surname> <given-names>M</given-names></name><name><surname>Kulkarni</surname> <given-names>K</given-names></name><name><surname>Repovš</surname> <given-names>G</given-names></name><name><surname>Anticevic</surname> <given-names>A</given-names></name><name><surname>Cole</surname> <given-names>MW</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Mapping the human brain's cortical-subcortical functional network organization</article-title><source>NeuroImage</source><volume>185</volume><fpage>35</fpage><lpage>57</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2018.10.006</pub-id><pub-id pub-id-type="pmid">30291974</pub-id></element-citation></ref><ref id="bib35"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiahui</surname> <given-names>G</given-names></name><name><surname>Feilong</surname> <given-names>M</given-names></name><name><surname>Visconti di Oleggio Castello</surname> <given-names>M</given-names></name><name><surname>Guntupalli</surname> <given-names>JS</given-names></name><name><surname>Chauhan</surname> <given-names>V</given-names></name><name><surname>Haxby</surname> <given-names>JV</given-names></name><name><surname>Gobbini</surname> <given-names>MI</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Predicting individual face-selective topography using naturalistic stimuli</article-title><source>NeuroImage</source><volume>216</volume><elocation-id>116458</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116458</pub-id><pub-id pub-id-type="pmid">31843709</pub-id></element-citation></ref><ref id="bib36"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname> <given-names>R</given-names></name><name><surname>Zuo</surname> <given-names>N</given-names></name><name><surname>Ford</surname> <given-names>JM</given-names></name><name><surname>Qi</surname> <given-names>S</given-names></name><name><surname>Zhi</surname> <given-names>D</given-names></name><name><surname>Zhuo</surname> <given-names>C</given-names></name><name><surname>Xu</surname> <given-names>Y</given-names></name><name><surname>Fu</surname> <given-names>Z</given-names></name><name><surname>Bustillo</surname> <given-names>J</given-names></name><name><surname>Turner</surname> <given-names>JA</given-names></name><name><surname>Calhoun</surname> <given-names>VD</given-names></name><name><surname>Sui</surname> <given-names>J</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Task-induced brain connectivity promotes the detection of individual differences in brain-behavior relationships</article-title><source>NeuroImage</source><volume>207</volume><elocation-id>116370</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2019.116370</pub-id><pub-id pub-id-type="pmid">31751666</pub-id></element-citation></ref><ref id="bib37"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname> <given-names>W</given-names></name><name><surname>Bouchard</surname> <given-names>TJ</given-names></name><name><surname>Krueger</surname> <given-names>RF</given-names></name><name><surname>McGue</surname> <given-names>M</given-names></name><name><surname>Gottesman</surname> <given-names>II</given-names></name></person-group><year iso-8601-date="2004">2004</year><article-title>Just one g: consistent results from three test batteries</article-title><source>Intelligence</source><volume>32</volume><fpage>95</fpage><lpage>107</lpage><pub-id pub-id-type="doi">10.1016/S0160-2896(03)00062-X</pub-id></element-citation></ref><ref id="bib38"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname> <given-names>W</given-names></name><name><surname>Nijenhuis</surname> <given-names>Jte</given-names></name><name><surname>Bouchard</surname> <given-names>TJ</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Still just 1 g: consistent results from five test batteries</article-title><source>Intelligence</source><volume>36</volume><fpage>81</fpage><lpage>95</lpage><pub-id pub-id-type="doi">10.1016/j.intell.2007.06.001</pub-id></element-citation></ref><ref id="bib39"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kong</surname> <given-names>R</given-names></name><name><surname>Li</surname> <given-names>J</given-names></name><name><surname>Orban</surname> <given-names>C</given-names></name><name><surname>Sabuncu</surname> <given-names>MR</given-names></name><name><surname>Liu</surname> <given-names>H</given-names></name><name><surname>Schaefer</surname> <given-names>A</given-names></name><name><surname>Sun</surname> <given-names>N</given-names></name><name><surname>Zuo</surname> <given-names>XN</given-names></name><name><surname>Holmes</surname> <given-names>AJ</given-names></name><name><surname>Eickhoff</surname> <given-names>SB</given-names></name><name><surname>Yeo</surname> <given-names>BTT</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>Spatial topography of Individual-Specific cortical networks predicts human cognition, personality, and emotion</article-title><source>Cerebral Cortex</source><volume>29</volume><fpage>2533</fpage><lpage>2551</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhy123</pub-id><pub-id pub-id-type="pmid">29878084</pub-id></element-citation></ref><ref id="bib40"><element-citation publication-type="preprint"><person-group person-group-type="author"><name><surname>Kong</surname> <given-names>R</given-names></name><name><surname>Yang</surname> <given-names>Q</given-names></name><name><surname>Gordon</surname> <given-names>E</given-names></name><name><surname>Xue</surname> <given-names>A</given-names></name><name><surname>Yan</surname> <given-names>X</given-names></name><name><surname>Orban</surname> <given-names>C</given-names></name><name><surname>Zuo</surname> <given-names>X-N</given-names></name><name><surname>Spreng</surname> <given-names>N</given-names></name><name><surname>Ge</surname> <given-names>T</given-names></name><name><surname>Holmes</surname> <given-names>A</given-names></name><name><surname>Eickhoff</surname> <given-names>S</given-names></name><name><surname>Yeo</surname> <given-names>BTT</given-names></name></person-group><year iso-8601-date="2021">2021</year><article-title>Individual-Specific Areal-Level parcellations improve functional connectivity prediction of behavior</article-title><source>bioRxiv</source><pub-id pub-id-type="doi">10.1101/2021.01.16.426943</pub-id></element-citation></ref><ref id="bib41"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kriegeskorte</surname> <given-names>N</given-names></name><name><surname>Mur</surname> <given-names>M</given-names></name><name><surname>Bandettini</surname> <given-names>P</given-names></name></person-group><year iso-8601-date="2008">2008</year><article-title>Representational similarity analysis - connecting the branches of systems neuroscience</article-title><source>Frontiers in Systems Neuroscience</source><volume>2</volume><elocation-id>4</elocation-id><pub-id pub-id-type="doi">10.3389/neuro.06.004.2008</pub-id><pub-id pub-id-type="pmid">19104670</pub-id></element-citation></ref><ref id="bib42"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Luders</surname> <given-names>E</given-names></name><name><surname>Narr</surname> <given-names>KL</given-names></name><name><surname>Bilder</surname> <given-names>RM</given-names></name><name><surname>Thompson</surname> <given-names>PM</given-names></name><name><surname>Szeszko</surname> <given-names>PR</given-names></name><name><surname>Hamilton</surname> <given-names>L</given-names></name><name><surname>Toga</surname> <given-names>AW</given-names></name></person-group><year iso-8601-date="2007">2007</year><article-title>Positive correlations between corpus callosum thickness and intelligence</article-title><source>NeuroImage</source><volume>37</volume><fpage>1457</fpage><lpage>1464</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2007.06.028</pub-id><pub-id pub-id-type="pmid">17689267</pub-id></element-citation></ref><ref id="bib43"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nastase</surname> <given-names>SA</given-names></name><name><surname>Liu</surname> <given-names>YF</given-names></name><name><surname>Hillman</surname> <given-names>H</given-names></name><name><surname>Norman</surname> <given-names>KA</given-names></name><name><surname>Hasson</surname> <given-names>U</given-names></name></person-group><year iso-8601-date="2020">2020</year><article-title>Leveraging shared connectivity to aggregate heterogeneous datasets into a common response space</article-title><source>NeuroImage</source><volume>217</volume><elocation-id>116865</elocation-id><pub-id pub-id-type="doi">10.1016/j.neuroimage.2020.116865</pub-id><pub-id pub-id-type="pmid">32325212</pub-id></element-citation></ref><ref id="bib44"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname> <given-names>SH</given-names></name><name><surname>Russ</surname> <given-names>BE</given-names></name><name><surname>McMahon</surname> <given-names>DBT</given-names></name><name><surname>Koyano</surname> <given-names>KW</given-names></name><name><surname>Berman</surname> <given-names>RA</given-names></name><name><surname>Leopold</surname> <given-names>DA</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Functional subpopulations of neurons in a macaque face patch revealed by Single-Unit fMRI mapping</article-title><source>Neuron</source><volume>95</volume><fpage>971</fpage><lpage>981</lpage><pub-id pub-id-type="doi">10.1016/j.neuron.2017.07.014</pub-id><pub-id pub-id-type="pmid">28757306</pub-id></element-citation></ref><ref id="bib45"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Plomin</surname> <given-names>R</given-names></name><name><surname>Deary</surname> <given-names>IJ</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Genetics and intelligence differences: five special findings</article-title><source>Molecular Psychiatry</source><volume>20</volume><fpage>98</fpage><lpage>108</lpage><pub-id pub-id-type="doi">10.1038/mp.2014.105</pub-id><pub-id pub-id-type="pmid">25224258</pub-id></element-citation></ref><ref id="bib46"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raichle</surname> <given-names>ME</given-names></name><name><surname>MacLeod</surname> <given-names>AM</given-names></name><name><surname>Snyder</surname> <given-names>AZ</given-names></name><name><surname>Powers</surname> <given-names>WJ</given-names></name><name><surname>Gusnard</surname> <given-names>DA</given-names></name><name><surname>Shulman</surname> <given-names>GL</given-names></name></person-group><year iso-8601-date="2001">2001</year><article-title>A default mode of brain function</article-title><source>PNAS</source><volume>98</volume><fpage>676</fpage><lpage>682</lpage><pub-id pub-id-type="doi">10.1073/pnas.98.2.676</pub-id><pub-id pub-id-type="pmid">11209064</pub-id></element-citation></ref><ref id="bib47"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raichle</surname> <given-names>ME</given-names></name></person-group><year iso-8601-date="2006">2006</year><article-title>The brain’s Dark Energy</article-title><source>Science</source><volume>314</volume><fpage>1249</fpage><lpage>1250</lpage><pub-id pub-id-type="doi">10.1126/science.1134405</pub-id></element-citation></ref><ref id="bib48"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robinson</surname> <given-names>EC</given-names></name><name><surname>Jbabdi</surname> <given-names>S</given-names></name><name><surname>Glasser</surname> <given-names>MF</given-names></name><name><surname>Andersson</surname> <given-names>J</given-names></name><name><surname>Burgess</surname> <given-names>GC</given-names></name><name><surname>Harms</surname> <given-names>MP</given-names></name><name><surname>Smith</surname> <given-names>SM</given-names></name><name><surname>Van Essen</surname> <given-names>DC</given-names></name><name><surname>Jenkinson</surname> <given-names>M</given-names></name></person-group><year iso-8601-date="2014">2014</year><article-title>MSM: a new flexible framework for multimodal surface matching</article-title><source>NeuroImage</source><volume>100</volume><fpage>414</fpage><lpage>426</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.05.069</pub-id><pub-id pub-id-type="pmid">24939340</pub-id></element-citation></ref><ref id="bib49"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saxe</surname> <given-names>R</given-names></name><name><surname>Kanwisher</surname> <given-names>N</given-names></name></person-group><year iso-8601-date="2003">2003</year><article-title>People thinking about thinking people. the role of the temporo-parietal junction in &quot;theory of mind&quot;</article-title><source>NeuroImage</source><volume>19</volume><fpage>1835</fpage><lpage>1842</lpage><pub-id pub-id-type="doi">10.1016/S1053-8119(03)00230-1</pub-id><pub-id pub-id-type="pmid">12948738</pub-id></element-citation></ref><ref id="bib50"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schmitt</surname> <given-names>JE</given-names></name><name><surname>Neale</surname> <given-names>MC</given-names></name><name><surname>Clasen</surname> <given-names>LS</given-names></name><name><surname>Liu</surname> <given-names>S</given-names></name><name><surname>Seidlitz</surname> <given-names>J</given-names></name><name><surname>Pritikin</surname> <given-names>JN</given-names></name><name><surname>Chu</surname> <given-names>A</given-names></name><name><surname>Wallace</surname> <given-names>GL</given-names></name><name><surname>Lee</surname> <given-names>NR</given-names></name><name><surname>Giedd</surname> <given-names>JN</given-names></name><name><surname>Raznahan</surname> <given-names>A</given-names></name></person-group><year iso-8601-date="2019">2019</year><article-title>A comprehensive quantitative genetic analysis of cerebral surface area in youth</article-title><source>The Journal of Neuroscience</source><volume>39</volume><fpage>3028</fpage><lpage>3040</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2248-18.2019</pub-id><pub-id pub-id-type="pmid">30833512</pub-id></element-citation></ref><ref id="bib51"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shen</surname> <given-names>X</given-names></name><name><surname>Finn</surname> <given-names>ES</given-names></name><name><surname>Scheinost</surname> <given-names>D</given-names></name><name><surname>Rosenberg</surname> <given-names>MD</given-names></name><name><surname>Chun</surname> <given-names>MM</given-names></name><name><surname>Papademetris</surname> <given-names>X</given-names></name><name><surname>Constable</surname> <given-names>RT</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Using connectome-based predictive modeling to predict individual behavior from brain connectivity</article-title><source>Nature Protocols</source><volume>12</volume><fpage>506</fpage><lpage>518</lpage><pub-id pub-id-type="doi">10.1038/nprot.2016.178</pub-id><pub-id pub-id-type="pmid">28182017</pub-id></element-citation></ref><ref id="bib52"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Siegel</surname> <given-names>JS</given-names></name><name><surname>Mitra</surname> <given-names>A</given-names></name><name><surname>Laumann</surname> <given-names>TO</given-names></name><name><surname>Seitzman</surname> <given-names>BA</given-names></name><name><surname>Raichle</surname> <given-names>M</given-names></name><name><surname>Corbetta</surname> <given-names>M</given-names></name><name><surname>Snyder</surname> <given-names>AZ</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Data quality influences observed links between functional connectivity and behavior</article-title><source>Cerebral Cortex</source><volume>27</volume><fpage>4492</fpage><lpage>4502</lpage><pub-id pub-id-type="doi">10.1093/cercor/bhw253</pub-id><pub-id pub-id-type="pmid">27550863</pub-id></element-citation></ref><ref id="bib53"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spearman</surname> <given-names>C</given-names></name></person-group><year iso-8601-date="1904">1904</year><article-title>&quot;General Intelligence,&quot; Objectively Determined and Measured</article-title><source>The American Journal of Psychology</source><volume>15</volume><fpage>201</fpage><lpage>292</lpage><pub-id pub-id-type="doi">10.2307/1412107</pub-id></element-citation></ref><ref id="bib54"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uğurbil</surname> <given-names>K</given-names></name><name><surname>Xu</surname> <given-names>J</given-names></name><name><surname>Auerbach</surname> <given-names>EJ</given-names></name><name><surname>Moeller</surname> <given-names>S</given-names></name><name><surname>Vu</surname> <given-names>AT</given-names></name><name><surname>Duarte-Carvajalino</surname> <given-names>JM</given-names></name><name><surname>Lenglet</surname> <given-names>C</given-names></name><name><surname>Wu</surname> <given-names>X</given-names></name><name><surname>Schmitter</surname> <given-names>S</given-names></name><name><surname>Van de Moortele</surname> <given-names>PF</given-names></name><name><surname>Strupp</surname> <given-names>J</given-names></name><name><surname>Sapiro</surname> <given-names>G</given-names></name><name><surname>De Martino</surname> <given-names>F</given-names></name><name><surname>Wang</surname> <given-names>D</given-names></name><name><surname>Harel</surname> <given-names>N</given-names></name><name><surname>Garwood</surname> <given-names>M</given-names></name><name><surname>Chen</surname> <given-names>L</given-names></name><name><surname>Feinberg</surname> <given-names>DA</given-names></name><name><surname>Smith</surname> <given-names>SM</given-names></name><name><surname>Miller</surname> <given-names>KL</given-names></name><name><surname>Sotiropoulos</surname> <given-names>SN</given-names></name><name><surname>Jbabdi</surname> <given-names>S</given-names></name><name><surname>Andersson</surname> <given-names>JL</given-names></name><name><surname>Behrens</surname> <given-names>TE</given-names></name><name><surname>Glasser</surname> <given-names>MF</given-names></name><name><surname>Van Essen</surname> <given-names>DC</given-names></name><name><surname>Yacoub</surname> <given-names>E</given-names></name><collab>WU-Minn HCP Consortium</collab></person-group><year iso-8601-date="2013">2013</year><article-title>Pushing spatial and temporal resolution for functional and diffusion MRI in the human connectome project</article-title><source>NeuroImage</source><volume>80</volume><fpage>80</fpage><lpage>104</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.012</pub-id><pub-id pub-id-type="pmid">23702417</pub-id></element-citation></ref><ref id="bib55"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Van Essen</surname> <given-names>DC</given-names></name><name><surname>Smith</surname> <given-names>SM</given-names></name><name><surname>Barch</surname> <given-names>DM</given-names></name><name><surname>Behrens</surname> <given-names>TE</given-names></name><name><surname>Yacoub</surname> <given-names>E</given-names></name><name><surname>Ugurbil</surname> <given-names>K</given-names></name><collab>WU-Minn HCP Consortium</collab></person-group><year iso-8601-date="2013">2013</year><article-title>The WU-Minn human connectome project: an overview</article-title><source>NeuroImage</source><volume>80</volume><fpage>62</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2013.05.041</pub-id><pub-id pub-id-type="pmid">23684880</pub-id></element-citation></ref><ref id="bib56"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Varoquaux</surname> <given-names>G</given-names></name><name><surname>Raamana</surname> <given-names>PR</given-names></name><name><surname>Engemann</surname> <given-names>DA</given-names></name><name><surname>Hoyos-Idrobo</surname> <given-names>A</given-names></name><name><surname>Schwartz</surname> <given-names>Y</given-names></name><name><surname>Thirion</surname> <given-names>B</given-names></name></person-group><year iso-8601-date="2017">2017</year><article-title>Assessing and tuning brain decoders: cross-validation, caveats, and guidelines</article-title><source>NeuroImage</source><volume>145</volume><fpage>166</fpage><lpage>179</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2016.10.038</pub-id><pub-id pub-id-type="pmid">27989847</pub-id></element-citation></ref><ref id="bib57"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Winkler</surname> <given-names>AM</given-names></name><name><surname>Webster</surname> <given-names>MA</given-names></name><name><surname>Vidaurre</surname> <given-names>D</given-names></name><name><surname>Nichols</surname> <given-names>TE</given-names></name><name><surname>Smith</surname> <given-names>SM</given-names></name></person-group><year iso-8601-date="2015">2015</year><article-title>Multi-level block permutation</article-title><source>NeuroImage</source><volume>123</volume><fpage>253</fpage><lpage>268</lpage><pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.05.092</pub-id><pub-id pub-id-type="pmid">26074200</pub-id></element-citation></ref><ref id="bib58"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yeo</surname> <given-names>BT</given-names></name><name><surname>Krienen</surname> <given-names>FM</given-names></name><name><surname>Sepulcre</surname> <given-names>J</given-names></name><name><surname>Sabuncu</surname> <given-names>MR</given-names></name><name><surname>Lashkari</surname> <given-names>D</given-names></name><name><surname>Hollinshead</surname> <given-names>M</given-names></name><name><surname>Roffman</surname> <given-names>JL</given-names></name><name><surname>Smoller</surname> <given-names>JW</given-names></name><name><surname>Zöllei</surname> <given-names>L</given-names></name><name><surname>Polimeni</surname> <given-names>JR</given-names></name><name><surname>Fischl</surname> <given-names>B</given-names></name><name><surname>Liu</surname> <given-names>H</given-names></name><name><surname>Buckner</surname> <given-names>RL</given-names></name></person-group><year iso-8601-date="2011">2011</year><article-title>The organization of the human cerebral cortex estimated by intrinsic functional connectivity</article-title><source>Journal of Neurophysiology</source><volume>106</volume><fpage>1125</fpage><lpage>1165</lpage><pub-id pub-id-type="doi">10.1152/jn.00338.2011</pub-id><pub-id pub-id-type="pmid">21653723</pub-id></element-citation></ref></ref-list><app-group><app id="appendix-1"><title>Appendix 1</title><sec id="s8" sec-type="appendix"><title>Supplemental material</title><boxed-text><sec id="s9"><title>Comparison of predictions based on task fMRI and resting fMRI data</title><fig id="app1fig1" position="anchor"><label>Appendix 1—figure 1.</label><caption><title>Scatterplots comparing variance accounted for by regional prediction models using task functional magnetic resonance imaging (fMRI) and resting fMRI connectivity.</title><p>(<bold>A</bold>) Hyperaligned, fine-grained connectivity. (<bold>B</bold>) Coarse-grained connectivity. (<bold>C</bold>) Multimodal surface matching-aligned fine-grained connectivity. Each circle represents one region. The color of each circle corresponds to the cortical system that each region is part of (based on a plurality of vertices), using the same color scheme as in <xref ref-type="fig" rid="fig3">Figure 3D and Figure 4D</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64058-app1-fig1-v2.tif"/></fig><p>Results showed that task fMRI data produced better predictions of general intelligence than did resting fMRI for hyperaligned residual fine-grained, coarse-grained, and MSM-aligned residual fine-grained connectivity.</p></sec><sec id="s10"><title>Comparison of alignments and predictions based on single task connectivity</title><fig id="app1fig2" position="anchor"><label>Appendix 1—figure 2.</label><caption><title>Histograms of variance accounted for by predictions of general intelligence using different functional magnetic resonance imaging connectivity datasets and different alignment methods.</title><p>(<bold>A</bold>) Prediction based on residual fine-grained connectivity. (<bold>B</bold>) Predictions based on coarse-grained connectivity. (<bold>C</bold>) Predictions based on full fine-grained connectivity, which includes information in both fine-grained and coarse-grained patterns. CHA: connectivity hyperalignment.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64058-app1-fig2-v2.tif"/></fig><p>Connectivity hyperalignment based on task fMRI data produced stronger predictions of general intelligence based on task connectivity than did connectivity hyperalignment based on resting fMRI data. Predictions based on resting connectivity were equivalent for connectivity hyperalignment based on task fMRI and resting fMRI. Prediction based on hyperaligned residual fine-grained connectivity and on hyperaligned full fine-grained connectivity profiles (A and C) were essentially identical.</p><p>Hyperalignment transformations remix the time series for cortical vertices, which alters the mean of correlations between the vertices of two regions, namely, the coarse-scale functional connectivity between these regions (B). Analyses of hyperaligned fine-grained connectivity profiles all used the coarse-grained connectivity profiles calculated on the same hyperaligned data for comparison. In practice, the effect of calculating coarse-grained connectivity profiles on task hyperaligned task fMRI, hyperaligned resting fMRI, and MSM-aligned fMRI is small and does not affect the results of these analyses (<xref ref-type="fig" rid="app1fig2">Appendix 1—figure 2</xref>).</p></sec><sec id="s11"><title>Predicting intelligence based on connectivity during single tasks</title><fig id="app1fig3" position="anchor"><label>Appendix 1—figure 3.</label><caption><title>Histograms of variance accounted for by regional prediction models based on connectivity calculated from functional magnetic resonance imaging (fMRI) during single tasks.</title><p>For every single fMRI task (4.2–9.7 min), fine-scale hyperaligned connectivity data produced better predictions of general intelligence than did coarse-scale connectivity. The strongest predictions from single task fMRI were obtained from data during performance of the working memory (WM), language, and social cognition tasks.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64058-app1-fig3-v2.tif"/></fig></sec><sec id="s12"><title>Null distribution of model performance based on permutation testing</title><fig id="app1fig4" position="anchor"><label>Appendix 1—figure 4.</label><caption><title>Permutation testing. For each of the 2160 conditions (360 brain regions × 3 connectivity profile types × 2 functional magnetic resonance imaging data types), we ran a permutation test by training and evaluating prediction models 100 times based on shuffled subject labels. (<bold>A</bold>) and (<bold>B</bold>) show results based on task fMRI data and resting fMRI data, respectively.</title><p>For 2148 out of 2160 conditions (99.4%), the actual <italic>R</italic><sup>2</sup> was larger than all 100 permuted <italic>R</italic><sup>2</sup>s. For the remaining 12 conditions, the actual <italic>R</italic><sup>2</sup> was close to 0 (all &lt;1.3%). In other words, for any model that had an <italic>R</italic><sup>2</sup> of at least 1.3%, it is also larger than the maximum <italic>R</italic><sup>2</sup> of all 100 permutations (i.e., <italic>p</italic> &lt; 0.01).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64058-app1-fig4-v2.tif"/></fig></sec><sec id="s13"><title>Distribution of model parameter choices based on nested cross-validation</title><fig id="app1fig5" position="anchor"><label>Appendix 1—figure 5.</label><caption><title>Distribution of regularization parameters α and number of principal components (PCs) for prediction models.</title><p>For each kind of functional magnetic resonance imaging (fMRI) data (<bold>A</bold>: task fMRI; <bold>B</bold>: resting fMRI) and each kind of connectivity profile (hyperaligned fine-grained, multimodal surface matching-aligned fine-grained, coarse-grained), we summarize the distribution of model parameters (the regularization parameter, α, and the number of PCs) across all cross-validation folds (411 families × 360 regions = 147,960). The maximum number of PCs was usually 360 for coarse-grained connectivity profile and close to 876 for fine-grained connectivity profile (depending on training sample size). Models trained on fine-grained connectivity profiles (left and middle columns) tend to use less regularization (smaller αs) and more PCs compared with models trained on coarse-grained connectivity profiles (right column), especially models trained on hyperaligned fine-grained connectivity profiles. More PCs used by the model suggest that there are more dimensions in the connectivity profiles that are related to general intelligence, and less regularization suggests these PCs contain more signal relative to noise.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64058-app1-fig5-v2.tif"/></fig></sec><sec id="s14"><title>Predicting alternative measures of intelligence</title><fig id="app1fig6" position="anchor"><label>Appendix 1—figure 6.</label><caption><title>Predicting alternative measures of intelligence based on connectivity profiles.</title><p>Our prediction models and connectivity profiles can also be trained to predict other measures of intelligence, such as fluid intelligence measured with the Penn Matrices (<bold>A</bold>, variable ‘PMAT24_A_CR’ in the dataset) and general intelligence measured as the cognitive function composite score of the NIH Toolbox (<bold>B</bold>, ‘CogTotalComp_Unadj’). Similar to the results of the main paper (shown here as <bold>C</bold> for comparisons), predictions based on fine-grained hyperaligned connectivity profiles account for approximately two times more variance in intelligence compared with coarse-grained connectivity profiles for task functional magnetic resonance imaging (fMRI) data, and three times more for resting fMRI data. The four columns on the left side are based on connectivity profiles computed from task fMRI data, and the four on the right from resting fMRI data. For each kind of data, we computed fine-grained connectivity profiles based on three different alignment methods (multimodal surface matching, hyperalignment based on resting fMRI data, and hyperalignment based on task fMRI data), which we colored as blue, orange, and red, respectively. The orange and red colors denote the kind of data used to derive hyperalignment transformations. In the results shown in this figure, they may not be the same as data used to compute connectivity profiles.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64058-app1-fig6-v2.tif"/></fig><fig id="app1fig7" position="anchor"><label>Appendix 1—figure 7.</label><caption><title>Predicting alternative intelligence measures based on regional hyperaligned fine-grained task functional magnetic resonance imaging connectivity profiles.</title><p>Regional connectivity profiles that were more predictive of factor analysis-based general intelligence scores were more likely to be more predictive of matrix reasoning-based fluid intelligence scores (top row, <italic>r</italic> = 0.92) and NIH Toolbox-based general intelligence scores (bottom row, <italic>r</italic> = 0.96). This suggests that our results were robust over intelligence measure choices.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64058-app1-fig7-v2.tif"/></fig></sec><sec id="s15"><title>Alternative cross-validation schemes and the effect of training sample size</title><fig id="app1fig8" position="anchor"><label>Appendix 1—figure 8.</label><caption><title>Comparison between cross-validation schemes.</title><p>We replicated our analysis using the tenfold cross-validation scheme (repeated for 50 times) and compared model performance based on tenfold cross-validation (average across 50 repetitions) with that based on leave-one-family-out cross-validation (<bold>A</bold>, <bold>C</bold>). Each dot denotes a brain region, and error bars denote the standard deviation of <italic>R</italic><sup>2</sup> across the 50 repetitions. All dots were close to the identity line (gray dotted line), which indicates that model performance was highly similar for leave-one-family-out cross-validation and tenfold cross-validation. On average across all regions, model performance based on leave-one-family-out cross-validation was slightly higher than that based on tenfold cross-validation, which was likely driven by the difference in training sample size (i.e., approximately 90% versus 99.8% of the entire dataset). This was confirmed by additional analysis showing further reduction of model performance based on smaller k values and correspondingly smaller training sample sizes (<bold>B</bold>, <bold>D</bold>; k = 2, 3, or 5 for k-fold cross-validation; training data was 50%, 66.7%, and 80% of the entire dataset, respectively).</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64058-app1-fig8-v2.tif"/></fig><fig id="app1fig9" position="anchor"><label>Appendix 1—figure 9.</label><caption><title>Overestimation of model performance due to lack of data independence.</title><p>We trained new prediction models based on the k-fold cross-validation scheme, but without controlling for family structure. That is, for each testing participant, other members from the same family might be in training data. Compared with the k-fold results that controlled for family structure (<xref ref-type="fig" rid="app1fig8">Appendix 1—figure 8</xref>; dashed lines in this figure), results without controlling for family structure consistently overestimate model performance (average <italic>R</italic><sup>2</sup> difference across regions: 0.9–2.1%; solid lines in this figure). This demonstrates the necessity of ensuring data independence between training and testing data to avoid biased model evaluations (see <xref ref-type="bibr" rid="bib56">Varoquaux et al., 2017</xref> for a similar issue with leave-one-trial-out). Specifically, training and testing data should not have members from the same family.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64058-app1-fig9-v2.tif"/></fig></sec><sec id="s16"><title>The effect of hyperparameter choices on model performance</title><fig id="app1fig10" position="anchor"><label>Appendix 1—figure 10.</label><caption><title>The effect of hyperparameter choices on prediction performance.</title><p>Besides using fine-tuned hyperparameters based on nested cross-validation (rightmost columns in gray), we trained prediction models based on another eight sets of hyperparameter choices. These eight sets of hyperparameters are combinations of four levels of dimensionality reduction (80 principal components [PCs], 160 PCs, 320 PCs, or all PCs) and two levels of regularization (α = 0.1 or α = 10<sup>−20</sup>). These hyperparameter levels are the levels most frequently chosen based on nested cross-validation (<xref ref-type="fig" rid="app1fig5">Appendix 1—figure 5</xref>). The histograms denote <italic>R</italic><sup>2</sup> distribution across brain regions, and horizontal bars are the average <italic>R</italic><sup>2</sup> across regions. For prediction models based on coarse-grained connectivity profiles, regularization is critical for prediction model performance, and with insufficient regularization models overfit dramatically with more PCs. When the regularization is large enough, the model performance slightly increases with higher number of PCs. For prediction models based on fine-grained connectivity profiles, model performance is hardly affected by regularization level and consistently increases with higher number of PCs. This suggests that PCs based on fine-grained connectivity profiles contain more information related to individual differences in intelligence and less noise. Note that even with only 80 PCs prediction models based on hyperaligned fine-grained connectivity profiles still account for approximately two times more variance than those based on coarse-grained connectivity profiles.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64058-app1-fig10-v2.tif"/></fig></sec><sec id="s17"><title>Alternative definition of cortical networks</title><fig id="app1fig11" position="anchor"><label>Appendix 1—figure 11.</label><caption><title>Proportion of vertices of the 30 most predictive regions in 12 cortical networks defined in <xref ref-type="bibr" rid="bib34">Ji et al., 2019</xref>.</title><p>(<bold>A</bold>) The 30 regions that are most predictive of general intelligence based on hyperaligned fine-grained task functional magnetic resonance imaging (fMRI) connectivity are in the default (34.0% of vertices in the 30 regions), frontoparietal (33.0%), cingulo-opercular (20.2%), dorsal attention (5.7%), and visual 2 (6.7%) networks. (<bold>B</bold>) The 30 regions that are most predictive of general intelligence based on hyperaligned fine-grained resting fMRI connectivity are in the default (39.3%), frontoparietal (22.5%), cingulo-opercular (14.4%), dorsal attention (13.9%), visual 2 (4.9%), language (2.8%), and visual 1 (1.7%) networks. The 12 cortical networks are defined based on <xref ref-type="bibr" rid="bib34">Ji et al., 2019</xref>. Note that different cortical network parcellations are in agreement with each other in general, and the proportion of cortical vertices in these 12 networks is similar to the proportion in the seven cortical systems based on <xref ref-type="bibr" rid="bib58">Yeo et al., 2011</xref>. Most of the vertices are in default, frontoparietal, and dorsal attention networks based on both <xref ref-type="bibr" rid="bib58">Yeo et al., 2011</xref> and <xref ref-type="bibr" rid="bib34">Ji et al., 2019</xref>; some regions in the ventral attention network based on <xref ref-type="bibr" rid="bib58">Yeo et al., 2011</xref> are labeled as cingulo-opercular in <xref ref-type="bibr" rid="bib34">Ji et al., 2019</xref>.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64058-app1-fig11-v2.tif"/></fig></sec><sec id="s18"><title>Assessing the effects of head motion</title><p>The level of in-scanner head motion (usually measured as framewise displacement [FD]) is correlated with many subject measures, and participants who move more in the scanner are more likely to have lower cognitive test scores (<xref ref-type="bibr" rid="bib52">Siegel et al., 2017</xref>). Therefore, when the connectivity pattern is affected by motion-related artifacts, it is possible for prediction models to take advantage of these spurious patterns and predict these subject measures to some extent. For the dataset used in this study, the correlation between <italic>g</italic> and FD is <italic>r</italic>(874) = −0.29, <italic>p </italic>&lt; 10<sup>−18</sup>, which means a perfect head motion predictor can account for 8.6% of variance in general intelligence (<xref ref-type="fig" rid="app1fig12">Appendix 1—figure 12A</xref>). To assess the influence of head motion on our prediction models, we performed two additional analyses.</p><fig id="app1fig12" position="anchor"><label>Appendix 1—figure 12.</label><caption><title>Prediction performance based on a low head motion sub-sample.</title><p>General intelligence has a moderate correlation with head motion (<bold>A</bold>), and a ‘motion detector’ can predict general intelligence to some extent. To assess the effect of head motion variation on prediction performance, we trained another set of models based on a sub-sample of participants with minimal head motion (framewise displacement &lt;0.15 mm, n = 437, <bold>B</bold>), and another 10 sets of models based on control sub-samples (see <bold>C</bold> for an example control sub-sample). The control sub-samples had similar general intelligence variation but larger head motion variation compared with the low-motion sub-sample (<bold>D</bold>). Prediction performance was similar between the low-motion sub-sample and the control sub-samples (<bold>E</bold>), suggesting larger variation in head motion level (while keeping sample size constant) has little effect on the prediction performance for general intelligence.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64058-app1-fig12-v2.tif"/></fig><p>In the first analysis, we created a low-motion sub-sample of the dataset and evaluated prediction performance based on this sub-sample. This sub-sample comprises participants whose average FD is less than 0.15 mm across all fMRI runs and has a sample size of 437. Because sample size has a great influence on prediction performance (<xref ref-type="fig" rid="app1fig8">Appendix 1—figure 8</xref>), we created 10 control sub-samples. These control sub-samples have the same sample size and almost identical mean and standard deviation of <italic>g</italic> as the low-motion sub-sample (<xref ref-type="fig" rid="app1fig12">Appendix 1—figure 12</xref>D), but have the full spectrum of head motion (C). Therefore, if the prediction models take advantage of the correlation between <italic>g</italic> and head motion to predict <italic>g</italic>, we expect the model performance based on the control sub-samples to outperform the low-motion sub-sample.</p><p>Across all three kinds of connectivity profiles (coarse-grained, MSM-aligned fine-grained, hyperaligned fine-grained) and two kinds of fMRI data (task fMRI, resting fMRI), we observed no difference in prediction performance between models based on the low-motion sub-sample and models based on control sub-samples (all <italic>p </italic>&gt; 0.11; <xref ref-type="fig" rid="app1fig12">Appendix 1—figure 12</xref>E). This suggests that head motion has little influence on the performance of our prediction models.</p><p>Note that in the low-motion sub-sample, small variation in head motion still exists (<xref ref-type="fig" rid="app1fig12">Appendix 1—figure 12</xref>D) and is slightly correlated with <italic>g</italic> (<italic>r</italic> = −0.14). Therefore, it is possible for a prediction model to take advantage of motion-related connectivity patterns and account for up to 1.9% of variance in <italic>g</italic> if it can detect motion from functional connectivity perfectly. To further assess the effect of head motion, we performed a second analysis in a more strict way.</p><p>In the second analysis, we regressed out FD from functional connectivity profiles and used the residual profiles to build our prediction models. This allows us to completely remove the variance in functional connectivity that covariates with head motion. Traditionally certain preprocessing pipelines are used to mitigate the effects of head motion on functional connectivity and reduce the prediction performance overestimation caused by head motion (<xref ref-type="bibr" rid="bib52">Siegel et al., 2017</xref>; <xref ref-type="bibr" rid="bib8">Ciric et al., 2017</xref>; <xref ref-type="bibr" rid="bib9">Ciric et al., 2018</xref>). However, it is unclear which preprocessing pipeline is most effective in removing motion-related artifacts in fine-grained connectivity and it is practically challenging to compute fine-grained functional connectivity using multiple preprocessing pipelines. Therefore, we chose to use regression to remove covariation between functional connectivity and head motion. Note that regression is an aggressive approach and will also remove variance in ‘true’ functional connectivity that covariates with FD. As a result, the maximal possible <italic>R</italic><sup>2</sup> is no longer 100% but rather 91.4% because the 8.6% of variance in <italic>g</italic> that covaries with FD can never be accounted for by these residual profiles.</p><p>To account for the effect of the new <italic>R<sup>2</sup> </italic>ceiling, we trained another 100 sets of prediction models, where each set was based on functional connectivity residuals after regressing out a random variable that had the same level of correlation with <italic>g</italic> (i.e., <italic>r</italic> = 0.29), and therefore had the same <italic>R<sup>2</sup></italic> ceiling. For simplicity, we will refer to these models as control models and the models based on regressing out FD as FD-residual models. With these models, it is possible to separate the effect of <italic>R<sup>2</sup></italic> ceiling by comparing original models and control models, and the effect specific to head motion by comparing control models with FD-residual models.</p><p>Compared with the original models, control models had lower <italic>R<sup>2</sup></italic>, and the difference was 2.8%, 3.1%, and 4.2% for coarse-grained, MSM-aligned fine-grained, and hyperaligned fine-grained connectivity profiles respectively based on task fMRI data; the difference was 1.9%, 2.5%, and 3.9% respectively based on resting fMRI data. This demonstrates that regressing out variables correlating with <italic>g</italic> from functional connectivity profiles will reduce model performance in general. Note that the <italic>R<sup>2</sup></italic> difference was larger for connectivity profiles that are more predictive of <italic>g</italic> (e.g., hyperaligned fine-grained connectivity profiles for both task and resting fMRI data), suggesting that high-performance models are more influenced by the <italic>R<sup>2</sup></italic> ceiling, probably because their performances are closer to the ceiling.</p><p>FD-residual models had lower <italic>R</italic><sup>2</sup> compared with these control models, and the difference was 2.5%, 2.8%, and 2.7% respectively based on task fMRI data, and 1.3%, 2.0%, and 1.1% respectively based on resting fMRI data (<xref ref-type="fig" rid="app1fig13">Appendix 1—figure 13</xref>). These results suggest that head motion has a small (1.1–2.8%) but statistically significant effect on predicting <italic>g</italic> based on functional connectivity. Based on resting fMRI data, the effect of head motion was smaller for fine-grained connectivity profiles that are hyperaligned compared with those MSM-aligned (Δ<italic>R</italic><sup>2</sup> = 0.9%, <italic>p</italic>=0.01). This suggests that using functional connectivity based on hyperaligned data may reduce the influence of head motion on prediction models.</p><fig id="app1fig13" position="anchor"><label>Appendix 1—figure 13.</label><caption><title>Regressing out head motion from functional connectivity.</title><p>We regressed out head motion (measured as framewise displacement) from functional connectivity profiles and built prediction models based on the residual connectivity profiles, and compared their performance with 100 sets of control models. Each dot is a brain region, and error bars denote the standard deviation across 100 control model sets. For each set of control models, a random variable that has the same level of correlation with <italic>g</italic> was regressed out from functional connectivity profiles instead of head motion to control for the effect of lower <italic>R</italic><sup>2</sup> ceiling caused by regression. Compared with the control models, models based on regressing out head motion had slightly lower performance (range: 1.1–2.8%), as demonstrated by that the dots are slightly below the diagonal in general. This difference suggests that the shared variance between functional connectivity and head motion may cause a slight overestimation of model performance. However, the effect is small and cannot explain the difference between models based on different types of connectivity profiles.</p></caption><graphic mime-subtype="tiff" mimetype="image" xlink:href="elife-64058-app1-fig13-v2.tif"/></fig></sec></boxed-text></sec></app></app-group></back><sub-article article-type="decision-letter" id="sa1"><front-stub><article-id pub-id-type="doi">10.7554/eLife.64058.sa1</article-id><title-group><article-title>Decision letter</article-title></title-group><contrib-group><contrib contrib-type="editor"><name><surname>Yeo</surname><given-names>Thomas</given-names></name><role>Reviewing Editor</role><aff><institution>National University of Singapore</institution><country>Singapore</country></aff></contrib></contrib-group><contrib-group><contrib contrib-type="reviewer"><name><surname>Bijsterbosch</surname><given-names>Janine Diane</given-names></name><role>Reviewer</role><aff><institution>University of Oxford</institution><country>United Kingdom</country></aff></contrib><contrib contrib-type="reviewer"><name><surname>Gordon</surname><given-names>Evan</given-names> </name><role>Reviewer</role><aff><institution>Veterans Health Administration</institution><country>United States</country></aff></contrib></contrib-group></front-stub><body><boxed-text><p>In the interests of transparency, eLife publishes the most substantive revision requests and the accompanying author responses.</p></boxed-text><p><bold>Acceptance summary:</bold></p><p>In this work, Feilong and colleagues investigated the degree to which the strength of functional connectivity is predictive of general intelligence, and the degree to which that predictive power is improved using hyperalignment procedures. More specifically, the authors showed a two-fold increase in variance explained in general intelligence when using fine-grained hyperaligned connectivity compared with coarse-grained hyperaligned connectivity. This is a very clearly written paper that presents an important result, which has the potential of great impact on the field of behavioral prediction.</p><p><bold>Decision letter after peer review:</bold></p><p>Thank you for submitting your article &quot;The neural basis of intelligence in fine-grained cortical topographies&quot; for consideration by <italic>eLife</italic>. Your article has been reviewed by three peer reviewers, one of whom is a member of our Board of Reviewing Editors, and the evaluation has been overseen by Floris de Lange as the Senior Editor. The following individuals involved in review of your submission have agreed to reveal their identity: Janine Diane Bijsterbosch (Reviewer #2); Evan Gordon (Reviewer #3).</p><p>The reviewers have discussed the reviews with one another and the Reviewing Editor has drafted this decision to help you prepare a revised submission.</p><p>As the editors have judged that your manuscript is of interest, but as described below that additional experiments are required before it is published, we would like to draw your attention to changes in our revision policy that we have made in response to COVID-19 (https://elifesciences.org/articles/57162). First, because many researchers have temporarily lost access to the labs, we will give authors as much time as they need to submit revised manuscripts. We are also offering, if you choose, to post the manuscript to bioRxiv (if it is not already there) along with this decision letter and a formal designation that the manuscript is &quot;in revision at <italic>eLife</italic>&quot;. Please let us know if you would like to pursue this option. (If your work is more suitable for medRxiv, you will need to post the preprint yourself, as the mechanisms for us to do so are still in development.)</p><p>Summary:</p><p>In this work, Feilong and colleagues use the Human Connectome Project fMRI data to investigate the degree to which the strength of functional connectivity is predictive of general intelligence, and the degree to which that predictive power is improved using the hyperalignment procedures their lab has developed. More specifically, the authors predict general intelligence using either coarse-grained functional connectivity (based on 360 ROIs) or fine-grained functional connectivity (vertex-wise) after hyperalignment. The results show a two-fold increase in variance explained in general intelligence between coarse-grained and fine-grained connectivity. This is a very clearly-written paper that presents an important result, which has the potential of great impact on the field of behavioral prediction. However, the reviewers and editors do have some significant concerns with the predictive modeling presented in this work.</p><p>Essential revisions:</p><p>1) A major contribution of this study is the massive improvement in prediction performance using connectivity hyperalignment and fine-grained functional connectivity. As such it is important that code for this study be made publicly available, so that other researchers can test and replicate the authors' analyses under new conditions and datasets. Our understanding is that the connectivity hyperalignment code from the previous study (Guntupalli et al., 2018) is available in PyMVPA. However, our experience is that the code is not easy to use. As such, we believe it is important that the code specific to this study be made publicly available. More specifically, code utilized in this study to apply the existing connectivity hyperalignment code to the HCP dataset should be made available. Furthermore, code for computing fine-grained functional connectivity together with PCA+ridge regression and nested cross-validation should also be made available.</p><p>2) With regards to the leave-one-family-out nested cross-validation procedure, previous studies (e.g., Varoquaux et al., 2017) have suggested a single round of cross-validation can be sensitive to the particular split of the data. A more robust procedure would be to perform 10-fold nested cross-validation procedure 50 times. The prediction performance is then averaged across the 50 x 10 = 500 folds. In the case of the HCP data, care should be taken to handle family structure, i.e., within a single 10-fold nested cross-validation procedure, a family should not be split across the 10 folds. We believe that such a procedure is especially important for this study because the major result here is the huge improvement in prediction performance.</p><p>3) The authors should clarify what hyperparameters were tuned in their nested cross-validation. Our understanding is that the authors tune the number of PCA components and ridge regularization parameter. However, hyperalignment has a few hyperparameters as well. Did the authors use the exact same hyperalignment parameters as their previous studies? If so, this should be clearly stated in this study. If different hyperalignment parameters were used, then these hyperalignment hyperparameters should also be tuned within the nested cross-validation framework.</p><p>4) The residuals of fine-grained connectivity profiles were obtained after subtracting coarse-grain connectivity. Why was subtraction used here, rather than regressing out (i.e., orthogonalizing with respect to) the coarse-grained connectivity?</p><p>5) The authors have generally done a good job controlling for motion-related confounds, which can be a serious issue in the HCP data. In fact, Siegel et al., 2016, demonstrated that many behavioral measures, including intelligence, appeared to be spuriously related to motion effects. This is a particular concern for predictive modeling of the type done in the current work, as it is never clear when predictions are being made based on real aspects of the data vs. when predictions are being made based on intelligence-correlated motion artifact. However, the authors did not &quot;scrub&quot; their data (completely remove high-motion frames), as Siegel et al. did. This could be an issue, as Siegel et al. appeared to show that scrubbing by itself could remove a good portion of spurious behavioral covariance, and Ciric et al., 2017, showed that scrubbing removes different portions of the motion-related artifact than nuisance regression of the type performed by the authors does. Have the authors tested whether their strong FC-behavior predictive power survives more stringent removal of motion frames?</p><p>6) Glasser et al., 2016, showed that machine learning approaches could generate individual-specific versions of their parcellation in HCP data that were substantially variable across subjects (even after MSM alignment). This is, of course, a different approach to hyperalignment, at the parcel level rather than the fine-grained vertex level. Have the authors considered testing whether hyperalignment results in better predictive power than such individualized parcel estimates?</p><p>7) How does the bootstrapping handle the family structure in the data? If family structure is not taken into account, the authors should justify why that is the case.</p><p>8) The Materials and methods states that a linear regression model was used to control for area size in dissimilarity estimates. It would be useful to provide more details here please? For example, is the model fit across subjects or across regions within subject?</p><p>9) Some more details about the implementation of permutation testing of the model would be helpful. For example, was each model fully re-trained in each permutation, including the parameter optimization?</p><p>10) The fine-grained functional connectivity has richer features than coarse-grained, leading to higher dimensionality in the PCA step (Figure 3—figure supplement 5). We wonder if this might contribute to improved prediction accuracy. Related to this, it appears that there may also be a relationship between PCA dimensionality and regularization parameter, such that more regularization may be needed when more PCs are used in the model. It would be interesting to test the effect of fixing the PCA dimensionality (and perhaps also the regularization) across all models to control model complexity.</p></body></sub-article><sub-article article-type="reply" id="sa2"><front-stub><article-id pub-id-type="doi">10.7554/eLife.64058.sa2</article-id><title-group><article-title>Author response</article-title></title-group></front-stub><body><disp-quote content-type="editor-comment"><p>Essential revisions:</p><p>1) A major contribution of this study is the massive improvement in prediction performance using connectivity hyperalignment and fine-grained functional connectivity. As such it is important that code for this study be made publicly available, so that other researchers can test and replicate the authors' analyses under new conditions and datasets. Our understanding is that the connectivity hyperalignment code from the previous study (Guntupalli et al., 2018) is available in PyMVPA. However, our experience is that the code is not easy to use. As such, we believe it is important that the code specific to this study be made publicly available. More specifically, code utilized in this study to apply the existing connectivity hyperalignment code to the HCP dataset should be made available. Furthermore, code for computing fine-grained functional connectivity together with PCA+ridge regression and nested cross-validation should also be made available.</p></disp-quote><p>We thank the reviewers for bringing this up. We do plan to release the code and the derived data in full. We have prepared the code for prediction and cross-validation, as well as the data used in these steps, so that they will be released as soon as the final revision is accepted for publication. Researchers can use these resources to build their own prediction models and study other measures of interest.</p><p>Execution of the code for computing fine-grained functional connectivity together with performing PCA on functional connectivity usually requires a high-performance computing cluster due to the size of the dataset and the nature of fine-grained functional connectivity. We will also release the code for these steps to maximize the replicability, but the precomputed data is recommended for most users.</p><p>All code will be published openly, and derived data of the HCP dataset will be released according to the Data Use Terms of the dataset (https://www.humanconnectome.org/study/hcp-young-adult/document/wu-minn-hcp-consortium-open-access-data-use-terms).</p><disp-quote content-type="editor-comment"><p>2) With regards to the leave-one-family-out nested cross-validation procedure, previous studies (e.g., Varoquaux et al., 2017) have suggested a single round of cross-validation can be sensitive to the particular split of the data. A more robust procedure would be to perform 10-fold nested cross-validation procedure 50 times. The prediction performance is then averaged across the 50 x 10 = 500 folds. In the case of the HCP data, care should be taken to handle family structure, i.e., within a single 10-fold nested cross-validation procedure, a family should not be split across the 10 folds. We believe that such a procedure is especially important for this study because the major result here is the huge improvement in prediction performance.</p></disp-quote><p>We repeated our analysis using 50 repetitions of 10-fold cross-validation, and found very similar results as leave-one-family-out cross-validation. The small difference can be explained by the difference in training data size (90% vs. 99.8% of the dataset). We summarized these results (along with results based on 2-fold, 3-fold, and 5-fold) in Figure 3—figure supplement 8.</p><p>The issue with leave-one-trial-out cross-validation discussed in Varoquaux et al., 2017, was because trials from the same run were split between training and testing data during leave-one-trial-out cross-validation, even though they are not independent. We assessed a similar issue in the individual differences context, that is, allowing members from the same family to be split between training and testing data. We found a consistent overestimation of prediction performance when the family structure was not controlled. We added these results as Figure 3—figure supplement 9.</p><disp-quote content-type="editor-comment"><p>3) The authors should clarify what hyperparameters were tuned in their nested cross-validation. Our understanding is that the authors tune the number of PCA components and ridge regularization parameter. However, hyperalignment has a few hyperparameters as well. Did the authors use the exact same hyperalignment parameters as their previous studies? If so, this should be clearly stated in this study. If different hyperalignment parameters were used, then these hyperalignment hyperparameters should also be tuned within the nested cross-validation framework.</p></disp-quote><p>We used the same hyperparameters as in our previous studies. Specifically, we used the solution to the orthogonal Procrustes problem to derive the transformation matrices (i.e., an improper rotation in a high-dimensional space), which translates to “reflection=True, scaling=False” in PyMVPA terms. Other parameters are identical to the default parameters of PyMVPA's “Hyperalignment” class, except for that “zscore_common” was turned off because the input was connectivity rather than zscored response time series. We have expanded the corresponding subsection in the Materials and methods to explain the algorithm and parameter choices:</p><p>“In this study, hyperalignment was performed for each brain region separately (i.e., in a similar manner to Haxby et al., 2011 rather than Guntupalli et al., 2016), and the transformation was constrained to be an improper rotation (i.e., rotation that allows reflection) with no scaling. […] For example, an improvement of prediction performance after searchlight hyperalignment can be caused by better alignment of information in a region, but it can also be caused by additional information moved into the region or noise moved out of the region.”</p><disp-quote content-type="editor-comment"><p>4) The residuals of fine-grained connectivity profiles were obtained after subtracting coarse-grain connectivity. Why was subtraction used here, rather than regressing out (i.e., orthogonalizing with respect to) the coarse-grained connectivity?</p></disp-quote><p>In this special case, the residual obtained by subtraction is equivalent to the residual obtained by regression. We have added the following text to the Materials and methods to clarify this detail:</p><p>“Because a coarse-grained connectivity profile is comprised of region-by-region averages of the corresponding fine-grained connectivity profile, a regression model using coarse-grained connectivity profile (expanded to the same size as the fine-grained connectivity profile) as the independent variable and fine-grained connectivity profile as the dependent variable will always have a slope of 1. Therefore, the difference between the two profiles is also the residual of the regression model.”</p><disp-quote content-type="editor-comment"><p>5) The authors have generally done a good job controlling for motion-related confounds, which can be a serious issue in the HCP data. In fact, Siegel et al., 2016, demonstrated that many behavioral measures, including intelligence, appeared to be spuriously related to motion effects. This is a particular concern for predictive modeling of the type done in the current work, as it is never clear when predictions are being made based on real aspects of the data vs. when predictions are being made based on intelligence-correlated motion artifact. However, the authors did not &quot;scrub&quot; their data (completely remove high-motion frames), as Siegel et al. did. This could be an issue, as Siegel et al. appeared to show that scrubbing by itself could remove a good portion of spurious behavioral covariance, and Ciric et al., 2017, showed that scrubbing removes different portions of the motion-related artifact than nuisance regression of the type performed by the authors does. Have the authors tested whether their strong FC-behavior predictive power survives more stringent removal of motion frames?</p></disp-quote><p>We performed two additional analyses to assess the effect of motion on our prediction models, and added a new subsection “Assessing the effects of head motion” and two supplementary figures (Figure 3—figure supplement 12 and Figure 3—figure supplement 13).</p><p>In the first analysis, we created a low motion sub-sample (average FD &lt; 0.15 mm) and compared prediction performance based on this sub-sample with 10 control sub-samples. Each control sub-sample had the same sample size and a similar distribution of intelligence as the low motion sub-sample, but the distribution of head motion was more similar to the entire sample (i.e., including large motion participants). Prediction performance was similar between the low motion sub-sample and the control sub-samples (Figure 3—figure supplement 12).</p><p>In the second analysis, we completely regressed out head motion (measured as FD) from the connectivity profiles and built the prediction models based on the residuals. Compared with the baseline (regressing out a random variable correlated with <italic>g</italic>), by regressing out FD from functional connectivity the average model performance across 360 regions dropped by 1.1% to 2.8% for different kinds of connectivity profiles (Figure 3—figure supplement 13).</p><p>Together these results demonstrate that functional connectivity patterns correlated with head motion may cause a small overestimation of model performance. However, this effect is small (Δ<italic>R<sup>2</sup></italic> = 1.1% to 2.8%) for our models and doesn't explain the large difference between different connectivity profile types.</p><disp-quote content-type="editor-comment"><p>6) Glasser et al., 2016, showed that machine learning approaches could generate individual-specific versions of their parcellation in HCP data that were substantially variable across subjects (even after MSM alignment). This is, of course, a different approach to hyperalignment, at the parcel level rather than the fine-grained vertex level. Have the authors considered testing whether hyperalignment results in better predictive power than such individualized parcel estimates?</p></disp-quote><p>Hyperalignment and individualized parcellations both can resolve idiosyncratic region boundaries on the anatomy (e.g., Jiahui et al., 2020). In this work (Figure 3—figure supplement 2) and our previous work (Feilong et al., 2018) we found that hyperalignment benefits individual differences analysis at both coarse and fine spatial scales, but the effect was much larger for fine-scale information than coarse-scale information. A very recent work, Kong et al., 2021, shows that individual-specific parcellations also improve prediction performance. Our prediction performance for fluid intelligence (Figure 3—figure supplement 6A) seems to surpass Kong et al., 2021 (Figure 11). However, many methodological details differ and a systematic comparison in future work is more appropriate for conclusions. We have added discussions on alternative approaches for aligning coarse-scale information:</p><p>“Hyperalignment resolves functional topographic idiosyncrasies at both coarse and fine spatial scales (see Jiahui et al., 2020, for an example of aligning functional regions), which is critical for assessing individual differences in information processing. […] However, the improvement for coarse-grained functional connectivity was smaller than for fine-grained functional connectivity in predicting general intelligence (Figure 3—figure supplement 2).”</p><disp-quote content-type="editor-comment"><p>7) How does the bootstrapping handle the family structure in the data? If family structure is not taken into account, the authors should justify why that is the case.</p></disp-quote><p>We ensured that the training data didn't contain participants from the same family as the test participant. Specifically, our bootstrapping procedure only resamples participants used for model evaluation, so that the sampling distribution is representative of the original training data amount. We have added a more detailed description of this procedure:</p><p>“The bootstrapping procedure used here only affects the participants used for model evaluation (i.e., the test set), and the model used to predict a participant's score was always trained with the same training set (i.e., participants who are not from the same family as the test participant). […] Therefore, we only bootstrapped the participants used for model evaluation, so that the sampling distribution is not biased by training sample size or dependency.”</p><disp-quote content-type="editor-comment"><p>8) The Materials and methods states that a linear regression model was used to control for area size in dissimilarity estimates. It would be useful to provide more details here please? For example, is the model fit across subjects or across regions within subject?</p></disp-quote><p>We averaged the matrix norm across all participant pairs for each region, and used the average in the regression model, so it is a single regression model across 360 brain regions. We have rewritten the description to clarify the details:</p><p>“We measured the level of each region's functional topographic idiosyncrasy as the average dissimilarity of hyperalignment transformation matrices across participant pairs for that region, after correcting for region size. […] We used the residual of the linear regression model to depict the heterogeneity of a region's functional topography across individuals.”</p><disp-quote content-type="editor-comment"><p>9) Some more details about the implementation of permutation testing of the model would be helpful. For example, was each model fully re-trained in each permutation, including the parameter optimization?</p></disp-quote><p>In each permutation, we permuted general intelligence scores using multi-level block permutation, and used these permuted scores for the entire process, including parameter optimization, model training, prediction, and evaluation. We have added the following text in the methods description to make it clearer:</p><p>“Each time, we permuted general intelligence scores across the entire dataset in the beginning, and re-ran the entire prediction pipeline with these permuted scores. […] In other words, we repeated the entire process – including parameter optimization, training, prediction, and model evaluation – using permuted general intelligence score as the target variable instead of the original general intelligence score.”</p><disp-quote content-type="editor-comment"><p>10) The fine-grained functional connectivity has richer features than coarse-grained, leading to higher dimensionality in the PCA step (Figure 3—figure supplement 5). We wonder if this might contribute to improved prediction accuracy. Related to this, it appears that there may also be a relationship between PCA dimensionality and regularization parameter, such that more regularization may be needed when more PCs are used in the model. It would be interesting to test the effect of fixing the PCA dimensionality (and perhaps also the regularization) across all models to control model complexity.</p></disp-quote><p>We trained another 8 sets of prediction models, each with a fixed hyperparameter combination, to assess the effect of hyperparameter choices. These 8 combinations are 4 levels of dimensionality reduction (80 PCs, 160 PCs, 320 PCs, or all PCs) × 2 levels of regularization (α = 0.1 or α = 10<sup>-20</sup>) that were most frequently chosen by nested cross-validation (Figure 3—figure supplement 5). We found that reducing the number of PCs reduced model performance for both coarse- and fine-grained connectivity profiles (except for overfit models due to insufficient regularization). However, even with the same number of PCs, prediction models based on hyperaligned fine-grained connectivity profiles still had a great advantage over those based on MSM-aligned fine-grained and coarse-grained connectivity profiles. We have added a new supplementary figure (Figure 3—figure supplement 10) to demonstrate the effect of hyperparameter choices.</p></body></sub-article></article>